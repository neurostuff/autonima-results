<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>False Positives at Fulltext Stage</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        .study {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 20px;
            margin-bottom: 20px;
            background-color: #f9f9f9;
        }
        .metadata, .screening, .content {
            margin-bottom: 15px;
            padding: 10px;
            border-left: 3px solid #3498db;
        }
        .metadata {
            border-left-color: #3498db;
        }
        .screening {
            border-left-color: #e74c3c;
        }
        .content {
            border-left-color: #2ecc71;
        }
        .annotation {
            border-left-color: #f39c12;
            background-color: #fff8e1;
        }
        strong {
            color: #2c3e50;
        }
        .study-list {
            margin-top: 20px;
        }
        footer {
            margin-top: 40px;
            text-align: center;
            font-size: 0.9em;
            color: #7f8c8d;
        }
        
        /* Accordion styles */
        .accordion {
            background-color: #f1f1f1;
            color: #444;
            cursor: pointer;
            padding: 10px;
            width: 100%;
            border: none;
            text-align: left;
            outline: none;
            font-size: 14px;
            font-weight: bold;
            margin-top: 10px;
            margin-bottom: 10px;
            border-radius: 4px;
        }
        .accordion:hover {
            background-color: #ddd;
        }
        .accordion:after {
            content: ' \25BC'; /* Down arrow */
            font-size: 10px;
            color: #777;
            float: right;
        }
        .accordion.active:after {
            content: ' \25B2'; /* Up arrow */
        }
        .panel {
            padding: 0 18px;
            background-color: white;
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.2s ease-out;
            border: 1px solid #ddd;
            border-top: none;
            border-radius: 0 0 4px 4px;
        }
        .panel-content {
            padding: 15px;
        }
        .fulltext-content {
            white-space: pre-wrap;
            font-family: monospace;
            font-size: 12px;
            line-height: 1.4;
        }
    </style>
</head>
<body>
<button id="saveButton" onclick="saveAnnotations()" style="position: fixed; top: 10px; right: 10px; z-index: 1000; background-color: #27ae60; color: white; border: none; padding: 10px 20px; border-radius: 5px; cursor: pointer;">Save Annotations</button>
<script>
    function toggleAccordion(btn) {
        btn.classList.toggle("active");
        var panel = btn.nextElementSibling;
        if (panel.style.maxHeight) {
            panel.style.maxHeight = null;
        } else {
            panel.style.maxHeight = panel.scrollHeight + "px";
        }
    }
    
    function saveAnnotations() {
        // Collect all annotations
        var annotations = [];
        var studies = document.getElementsByClassName('study');
        
        for (var i = 0; i < studies.length; i++) {
            var study = studies[i];
            var studyId = study.id;
            var pmid = study.querySelector('h2').textContent.split(':')[1].trim().split(' ')[0];
            
            // Get judgment
            var agreeRadio = document.getElementById('agree-' + (i+1));
            var disagreeRadio = document.getElementById('disagree-' + (i+1));
            var judgment = '';
            if (agreeRadio && agreeRadio.checked) {
                judgment = 'agree';
            } else if (disagreeRadio && disagreeRadio.checked) {
                judgment = 'disagree';
            }
            
            // Get comment
            var commentElement = document.getElementById('comment-' + (i+1));
            var comment = commentElement ? commentElement.value : '';
            
            annotations.push({
                'pmid': pmid,
                'judgment': judgment,
                'comment': comment
            });
        }
        
        // Create and download JSON file
        var dataStr = "data:text/json;charset=utf-8," + encodeURIComponent(JSON.stringify(annotations, null, 2));
        var downloadAnchorNode = document.createElement('a');
        downloadAnchorNode.setAttribute("href", dataStr);
        downloadAnchorNode.setAttribute("download", "annotations.json");
        document.body.appendChild(downloadAnchorNode);
        downloadAnchorNode.click();
        downloadAnchorNode.remove();
        
        // Show confirmation
        alert('Annotations saved successfully!');
    }
</script>
<h1>False Positives Papers at Fulltext Stage</h1>
<p>Total papers: 99</p>
<div class='study-list'>
<div class='study' id='study-1'>
<h2>1. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/23639347/' target='_blank'>23639347</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study of social-related processing in healthy adults (n=22, mean age 23.6). The task manipulated social context (holding a friend’s hand, a stranger’s hand, or alone) during threat-of-shock anticipation — a social-affiliation/attachment-related paradigm. The paper reports group-level, voxelwise whole-brain analyses (threat vs. safe contrast) used to identify functional ROIs via cluster-wise tests (Z>2.3, cluster p<.05) and provides coordinates/tables and figures of activations for the healthy sample. Participants are within the 17–65 age range and results for the healthy group are presented. No exclusion criteria (e.g., ROI-only, connectivity-only, or non-healthy-only samples) are violated. Therefore the study meets all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-1' name='judgment-1' value='agree'>
<label for='agree-1'>Agree</label>
<input type='radio' id='disagree-1' name='judgment-1' value='disagree'>
<label for='disagree-1'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-1' name='comment-1' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-2'>
<h2>2. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/25253279/' target='_blank'>25253279</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social perception (biological motion) in healthy adults (N=26 analyzed; ages 18–39). The task is social-related (perception/understanding of others). The paper reports group-level whole-brain univariate analyses: whole-brain biological-motion-selectivity analyses projected to a FreeSurfer average surface with correction for multiple comparisons (Monte Carlo simulation) and a significant cluster in right pSTS is reported. Although ROI analyses are also performed, whole-brain task-evoked results for the healthy adult sample are clearly presented. No exclusion criteria apply (not resting-state-only, not clinical-only, and participants are within 17–65). Therefore it meets all inclusion criteria for the review.</p>
<p><strong>Fulltext Confidence:</strong> 0.94</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-2' name='judgment-2' value='agree'>
<label for='agree-2'>Agree</label>
<input type='radio' id='disagree-2' name='judgment-2' value='disagree'>
<label for='disagree-2'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-2' name='comment-2' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-3'>
<h2>3. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22371086/' target='_blank'>22371086</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social perception (affiliation vs isolation) in healthy adults. It reports whole-brain, voxelwise, group-level univariate analyses (GLM, random-effects) with thresholded results and coordinate tables/figures for task contrasts (social vs nonsocial; affiliation vs isolation) and age-group contrasts. The sample includes a healthy younger adult group (mean age 20.75), which falls within the 17–65 inclusion range; results for healthy younger adults are analyzed and reported (e.g., conjunctions and Younger > Older contrasts), satisfying the requirement for a healthy adult group. The study is not ROI-only and does not report only connectivity or non-empirical data. Although an older group (>65) is included, that does not preclude inclusion because a qualifying healthy adult subgroup is present and reported separately.</p>
<p><strong>Fulltext Confidence:</strong> 0.88</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-3' name='judgment-3' value='agree'>
<label for='agree-3'>Agree</label>
<input type='radio' id='disagree-3' name='judgment-3' value='disagree'>
<label for='disagree-3'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-3' name='comment-3' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-4'>
<h2>4. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/23770622/' target='_blank'>23770622</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study of social cognition (theory-of-mind/emotion/pain judgments) in healthy adults (N=46 female, ages 18–31). The paper reports group-level, whole-brain univariate task contrasts and cluster-corrected results (tables of coordinates and whole-brain maps are provided), fulfilling the requirement for whole-brain task-evoked statistical maps generalizable to healthy adults. The task and constructs (mentalizing, perception/understanding of others) are clearly social-related. No exclusion criteria apply (not ROI-only, not connectivity/resting-only, healthy adult sample within age range).</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-4' name='judgment-4' value='agree'>
<label for='agree-4'>Agree</label>
<input type='radio' id='disagree-4' name='judgment-4' value='disagree'>
<label for='disagree-4'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-4' name='comment-4' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-5'>
<h2>5. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/24412433/' target='_blank'>24412433</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study reports task-based fMRI comparing responses to familiar (partner, child, friend) versus unfamiliar faces in a healthy control group (n=13). The task probes social/person-related processing (affiliation/attachment and perception/understanding of others). The paper provides group-level, whole-brain univariate contrasts for the control group (e.g., partner > unfamiliar faces with FWE-corrected whole-brain results and coordinates). Although the sample is older adults (mean age 64.5 ±5.7), a healthy control group is reported separately from the clinical case, satisfying the criterion that healthy-group whole-brain task effects are available. Therefore it meets the inclusion criteria for fMRI studies of social-related processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.85</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-5' name='judgment-5' value='agree'>
<label for='agree-5'>Agree</label>
<input type='radio' id='disagree-5' name='judgment-5' value='disagree'>
<label for='disagree-5'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-5' name='comment-5' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-6'>
<h2>6. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/23887806/' target='_blank'>23887806</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical, task-based fMRI study in healthy adults (participants aged 19–28; initial N=45 with group-level analyses on 31–35 subjects). The tasks target social-related processes (implicit/explicit detection of eye-gaze shifts and self-propelling motion; an implicit mental-inference role-playing task). The paper reports group-level, univariate whole-brain voxelwise contrasts (e.g., E–O and S–X), provides peak coordinates and cluster statistics in tables and figures, and applies correction for multiple comparisons. Results for the healthy/control group are reported and generalizable to healthy adults. The study does not rely solely on ROI, connectivity-only, resting-state, or between-group-only contrasts. Therefore it meets all inclusion criteria and violates no exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-6' name='judgment-6' value='agree'>
<label for='agree-6'>Agree</label>
<input type='radio' id='disagree-6' name='judgment-6' value='disagree'>
<label for='disagree-6'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-6' name='comment-6' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-7'>
<h2>7. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/18431500/' target='_blank'>18431500</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study of theory-of-mind (social cognition: cooperation/deception) in healthy adults (n=13, ages 22–38). The authors report group-level, random-effects whole-brain univariate analyses (ToM conditions vs. non-ToM baseline) with cluster peaks/coordinates and figures, and they transformed maxima into Talairach space. Results are not limited to ROI-only, connectivity-only, or between-group contrasts; healthy-group whole-brain task activation maps are clearly described and generalizable to healthy adults. All inclusion criteria are satisfied and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-7' name='judgment-7' value='agree'>
<label for='agree-7'>Agree</label>
<input type='radio' id='disagree-7' name='judgment-7' value='disagree'>
<label for='disagree-7'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-7' name='comment-7' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-8'>
<h2>8. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/18633845/' target='_blank'>18633845</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social-related processing (perception of socially relevant facial expressions/mimicry). Sample: healthy adult participants (N=17, right-handed males, mean age 25.9) within the 17–65 range. The paper reports group-level, whole-brain univariate (voxelwise) analyses using an FIR model with random-effects inference and reports significant activations (thresholds, coordinates, SPM maps/tables) for the main effect of social interaction (time-bin 5). Results are clearly reported for the healthy control group and generalizable to healthy adults. No exclusion criteria (ROI-only, connectivity-only, non-empirical, or out-of-range sample) apply. Therefore it meets all inclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-8' name='judgment-8' value='agree'>
<label for='agree-8'>Agree</label>
<input type='radio' id='disagree-8' name='judgment-8' value='disagree'>
<label for='disagree-8'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-8' name='comment-8' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-9'>
<h2>9. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/17100784/' target='_blank'>17100784</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study of social cognition: participants (healthy adult undergraduates, mean age 19.5) made affective/social judgments of pictures of social groups (perception/understanding of others). The paper reports group-level, whole-brain, univariate task-evoked analyses (random-effects contrasts, Talairach coordinates, and voxelwise activations for mPFC, insula, amygdala), not ROI-only or connectivity-only results. Healthy adult sample falls within the 17–65 range and results are reported for the healthy group. Therefore all inclusion criteria are met and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-9' name='judgment-9' value='agree'>
<label for='agree-9'>Agree</label>
<input type='radio' id='disagree-9' name='judgment-9' value='disagree'>
<label for='disagree-9'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-9' name='comment-9' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-10'>
<h2>10. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/24880954/' target='_blank'>24880954</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social processing in healthy adults (n=16, ages 18–25) using a social competitive task (matching-pennies vs human, android, robots, computer). Analyses report group-level, whole-brain, univariate GLM results (random-effects one-sample t-tests; voxel-wise threshold p<.001 with cluster FWE correction) and list peak coordinates/tables for activations modulated by impression components. Healthy adult results are reported separately and are generalizable to the healthy group. No exclusion criteria are met (not ROI-only, not resting-state/connectivity-only, not between-group-only). Therefore the paper satisfies all inclusion criteria for whole-brain task-evoked fMRI evidence in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.93</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-10' name='judgment-10' value='agree'>
<label for='agree-10'>Agree</label>
<input type='radio' id='disagree-10' name='judgment-10' value='disagree'>
<label for='disagree-10'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-10' name='comment-10' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-11'>
<h2>11. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/25338630/' target='_blank'>25338630</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study of social-related processing (dynamic social tie formation during a repeated public-good game). Sample: healthy adult participants (25 scanned subjects, ages ~22–23), within the 17–65 range. The paper reports group-level, voxelwise whole-brain univariate GLM results (parametric modulations of tie, impulse, contribution magnitude) with reported MNI coordinates and cluster-wise FWE correction (initial z=2.3, cluster p<0.05), satisfying whole-brain evidence requirements. Although connectivity (PPI, beta-seed) is also reported, whole-brain task activation maps for the healthy group are clearly provided. No ROI-only, no patient-only, and not a non-empirical paper. Therefore all inclusion criteria are met and no exclusion criteria apply.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-11' name='judgment-11' value='agree'>
<label for='agree-11'>Agree</label>
<input type='radio' id='disagree-11' name='judgment-11' value='disagree'>
<label for='disagree-11'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-11' name='comment-11' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-12'>
<h2>12. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/15327630/' target='_blank'>15327630</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> excluded</p>
<p><strong>Fulltext Reasoning:</strong> The study is an fMRI investigation of social gaze in healthy adult participants and uses voxelwise analyses; however, the reported group-level whole-brain activation maps were created by averaging normalized data across subjects using a fixed-effects analysis. Fixed-effects group maps are not generalizable to the healthy adult population (they only reflect the sampled subjects) and therefore do not meet the inclusion requirement for a group-level, population-generalizable whole-brain task-evoked statistical map. Additionally, after discarding 3 subjects for motion, the effective fMRI sample was very small (n≈5), further limiting population inference. Although the task and sample are appropriate, the use of fixed-effects group analysis (and the small final N) violates the requirement that whole-brain results be generalizable to healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-12' name='judgment-12' value='agree'>
<label for='agree-12'>Agree</label>
<input type='radio' id='disagree-12' name='judgment-12' value='disagree'>
<label for='disagree-12'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-12' name='comment-12' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-13'>
<h2>13. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/30389840/' target='_blank'>30389840</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social cognition (mental state representation and prediction) in healthy adults (imaging sample n=28 after one exclusion; ages 18–22). The task required participants to judge others’ mental states (social-related task). The paper reports group-level, voxelwise whole-brain analyses: searchlight representational similarity mapping (whole-brain map with TFCE-corrected results in dorsal mPFC) and a univariate, voxelwise repetition-suppression analysis with permutation TFCE correction (posterior precuneus, p < 0.05). These are group-level, task-evoked, whole-brain results generalizable to the healthy adult sample. No exclusion criteria are met (not ROI-only, not resting-state/connectivity-only, includes appropriate age range and healthy participants). Therefore the study meets all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-13' name='judgment-13' value='agree'>
<label for='agree-13'>Agree</label>
<input type='radio' id='disagree-13' name='judgment-13' value='disagree'>
<label for='disagree-13'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-13' name='comment-13' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-14'>
<h2>14. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22290781/' target='_blank'>22290781</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study of social-related processing (in-group vs out-group action perception/affiliation) in healthy adult participants (ages 17–43). Group-level, univariate whole-brain task-evoked analyses are reported (e.g., single-video vs fixation, own-team vs other-team, paired-judgment vs press) using random-effects SPM5; results are thresholded with cluster-level FWE correction for the whole-brain search and coordinates/clusters are reported. Sample meets age and health criteria and healthy-group results are clearly described. The paper does not rely solely on ROI or connectivity analyses and is not a review or methods-only paper. Therefore it meets all inclusion criteria and violates no exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.98</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-14' name='judgment-14' value='agree'>
<label for='agree-14'>Agree</label>
<input type='radio' id='disagree-14' name='judgment-14' value='disagree'>
<label for='disagree-14'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-14' name='comment-14' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-15'>
<h2>15. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/28289200/' target='_blank'>28289200</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This paper reports task-based functional MRI studies of social/person-related cognition (person knowledge retrieval), meeting the review’s content requirement. Participants were healthy adults in the target age range (study 1: n=24, Mage≈23.2; study 2: n=26, Mage≈20.4). The manuscript presents group-level univariate, whole-brain task contrasts (e.g., all-memory > baseline, status memory > baseline, trait memory > baseline) with voxelwise FWE-corrected maps and coordinates (Figures S3, Table S6), satisfying the whole-brain evidence inclusion criterion. The study also includes MVPA, PPI, and DCM analyses, but these are supplementary to and do not replace the presence of univariate whole-brain task activation maps. No exclusion criteria are triggered (not ROI-only; healthy-group whole-brain results are reported). Therefore the study should be included.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-15' name='judgment-15' value='agree'>
<label for='agree-15'>Agree</label>
<input type='radio' id='disagree-15' name='judgment-15' value='disagree'>
<label for='disagree-15'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-15' name='comment-15' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-16'>
<h2>16. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/25820129/' target='_blank'>25820129</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social cognition in healthy adults (N=18, ages 18–44) investigating prediction of others’ behavior (theory-of-mind vs deontic reasoning). The paper reports group-level, univariate whole-brain voxelwise analyses with tables of coordinates and cluster-corrected results (see Tables 2 and 3, whole-brain and small-volume corrections, and multiple whole-brain contrasts/figures). It is not limited to ROI-only or connectivity/resting-state analyses, and results for the healthy adult sample are reported and generalizable. Therefore it meets all inclusion criteria and violates no exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-16' name='judgment-16' value='agree'>
<label for='agree-16'>Agree</label>
<input type='radio' id='disagree-16' name='judgment-16' value='disagree'>
<label for='disagree-16'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-16' name='comment-16' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-17'>
<h2>17. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22439896/' target='_blank'>22439896</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social evaluation (impression formation) in healthy adults, directly addressing social processing. It includes a healthy younger adult group (ages 20–29) within the 17–65 inclusion range and reports group-level, whole-brain univariate task contrasts (social vs non-social; social-meaningful vs social-irrelevant) using random-effects analyses, corrected cluster thresholds, and coordinate tables/figures. Results for healthy groups are reported separately (young and older), and whole-brain maps/peaks are described, satisfying the whole-brain evidence requirement. Although an older group extends beyond 65, the presence of a healthy adult subgroup within 17–65 with reported whole-brain results makes the study eligible. The study is empirical original fMRI research (not ROI-only or connectivity-only). Therefore it meets all inclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-17' name='judgment-17' value='agree'>
<label for='agree-17'>Agree</label>
<input type='radio' id='disagree-17' name='judgment-17' value='disagree'>
<label for='disagree-17'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-17' name='comment-17' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-18'>
<h2>18. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/29396415/' target='_blank'>29396415</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This fMRI study includes a healthy adult group (final N=21 adults) within the target age range and uses a naturalistic, socially engaging movie clip (Toy Story) designed to elicit social-cognitive processing. The paper reports whole-brain, group-level voxel/nodewise statistical maps of inter-subject correlation (inter-SC) for the Adult group and provides peak coordinates and corrected cluster results. Although the analytic approach is inter-subject synchrony (rather than a conventional GLM contrast), it yields whole-brain task-evoked group-level maps generalizable to healthy adults and is not limited to ROIs or seed-based connectivity. Therefore it meets the inclusion criteria for whole-brain task-evoked fMRI of social processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-18' name='judgment-18' value='agree'>
<label for='agree-18'>Agree</label>
<input type='radio' id='disagree-18' name='judgment-18' value='disagree'>
<label for='disagree-18'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-18' name='comment-18' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-19'>
<h2>19. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/20943931/' target='_blank'>20943931</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study in healthy adult participants (n=98 across four experiments; mean age 20.7) that uses task-based paradigms probing social processes (self/close others/strangers; perception and understanding of self and others, affiliation/closeness). The paper reports group-level, voxelwise whole-brain task-evoked contrasts (e.g., self > Bush, friends > strangers) and presents whole-brain maps and region-level analyses; whole-brain results are explicitly described and thresholded (p<0.001 uncorrected). Results for the healthy adult sample are reported separately and are generalizable to healthy adults. The study therefore meets all inclusion criteria (task-based social fMRI, healthy adult sample, and whole-brain univariate group maps) and does not violate any exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-19' name='judgment-19' value='agree'>
<label for='agree-19'>Agree</label>
<input type='radio' id='disagree-19' name='judgment-19' value='disagree'>
<label for='disagree-19'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-19' name='comment-19' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-20'>
<h2>20. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/23110882/' target='_blank'>23110882</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical task-based fMRI study that directly investigates social cognition (reasoning about others’ mental states) in a sample of healthy adults (n=45, ages 19–23). The paper reports group-level, whole-brain univariate task contrasts (social > mechanical, mechanical > social, task > rest) with random-effects analyses and provides peak coordinates (Appendix A) and statistical maps/figures, satisfying the whole-brain evidence requirement. The healthy/control group results are reported and generalizable to healthy adults; analyses are not limited to ROIs or connectivity-only methods. No exclusion criteria are met (not ROI-only, not resting-only, participants are within age range). Therefore the study should be INCLUDED.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-20' name='judgment-20' value='agree'>
<label for='agree-20'>Agree</label>
<input type='radio' id='disagree-20' name='judgment-20' value='disagree'>
<label for='disagree-20'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-20' name='comment-20' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-21'>
<h2>21. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/27358450/' target='_blank'>27358450</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of healthy adult participants (N=34, mean age 22.2) who performed a social-related task (naturalistic movie viewing emphasizing social interactions). The paper reports group-level task-evoked analyses including whole-brain voxelwise reverse-correlation results (χ2 goodness-of-fit maps and corrected statistical parametric maps visualized in Figure 3) and intersubject correlation statistics, all derived from the healthy adult sample. Results are not limited to ROI-only or connectivity-only analyses; whole-brain, group-level univariate results are clearly described and corrected for multiple comparisons. Participants fall within the 17–65 age range and the healthy group results are reported directly. No exclusion criteria are violated. Therefore the study meets all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-21' name='judgment-21' value='agree'>
<label for='agree-21'>Agree</label>
<input type='radio' id='disagree-21' name='judgment-21' value='disagree'>
<label for='disagree-21'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-21' name='comment-21' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-22'>
<h2>22. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/34409940/' target='_blank'>34409940</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study in healthy adults (N=43, age range mean 26.7 within 17–65). The task probes social-related processing (empathy, perception/understanding of others’ pain and self–other distinction). The paper reports group-level, whole-brain mass-univariate analyses (contrasts: genuine pain – no pain; pretended pain – no pain; interaction) with cluster-level FWE correction and activation maps/coordinates across whole brain (bilateral aIns, aMCC, rSMG), and also presents brain–behavior regression results. Thus it provides univariate task-evoked whole-brain results for a healthy adult sample. It does not rely solely on ROI-only or connectivity-only findings. Therefore it meets all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-22' name='judgment-22' value='agree'>
<label for='agree-22'>Agree</label>
<input type='radio' id='disagree-22' name='judgment-22' value='disagree'>
<label for='disagree-22'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-22' name='comment-22' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-23'>
<h2>23. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/21569855/' target='_blank'>21569855</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an original, task-based fMRI study in healthy adult participants (N=18, ages 19–30) using a social cognition task (impression formation/expectancy violation about politicians). The paper reports group-level whole-brain, voxelwise contrasts (incongruent > congruent) with random-effects analyses and FDR-corrected activations, and provides a table of coordinates and figures. Results are reported for the healthy sample separately and are generalizable to healthy adults. It therefore satisfies the fMRI social-processing, healthy adult sample, and whole-brain reporting inclusion criteria, and does not violate exclusion criteria (not ROI-only, not connectivity-only, and empirical original data).</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-23' name='judgment-23' value='agree'>
<label for='agree-23'>Agree</label>
<input type='radio' id='disagree-23' name='judgment-23' value='disagree'>
<label for='disagree-23'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-23' name='comment-23' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-24'>
<h2>24. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/28551067/' target='_blank'>28551067</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study in healthy adults (N=19 for imaging analyses; ages 18–30) using a social task (modified Trust Game) probing reciprocity, a social cognitive construct. The paper reports group-level, univariate whole-brain task-evoked contrasts (e.g., Gave $1.5X vs Gave $0; Gave $1.5X After Receiving, etc.) with cluster results and MNI coordinates in Table 3 and corresponding figures, satisfying the whole-brain evidence requirement. Although the paper also includes ICA and other analyses, it clearly provides univariate voxelwise task activation maps for the healthy control group. The sample falls within the 17–65 age range, and results are reported for the healthy group separately. No exclusion criteria (ROI-only, resting-state only, non-empirical, out-of-range sample) are violated. Therefore the study meets all inclusion criteria for the review.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-24' name='judgment-24' value='agree'>
<label for='agree-24'>Agree</label>
<input type='radio' id='disagree-24' name='judgment-24' value='disagree'>
<label for='disagree-24'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-24' name='comment-24' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-25'>
<h2>25. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/19199417/' target='_blank'>19199417</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an event-related fMRI study of empathy/social cognition in healthy adults (n=23, ages 19–34). The task is explicitly social (empathizing with similar vs. dissimilar others), fitting ‘‘Perception and Understanding of Others.’’ The paper reports group-level, whole-brain random-effects univariate contrasts (e.g., Pain > No Pain: Similar, Pain > No Pain: Dissimilar, No Pain: Dissimilar > Similar) with statistical thresholding and tables/figures of activations (coordinates and images). Although PPI connectivity analyses are included, the paper also provides univariate whole-brain task-evoked maps for the healthy group. No exclusion criteria are violated (not ROI-only, not resting-state only, participants are within age range). Therefore the study meets all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-25' name='judgment-25' value='agree'>
<label for='agree-25'>Agree</label>
<input type='radio' id='disagree-25' name='judgment-25' value='disagree'>
<label for='disagree-25'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-25' name='comment-25' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-26'>
<h2>26. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/21761508/' target='_blank'>21761508</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of self-related social processing (self-face recognition) in healthy adults (N=16 analyzed for fMRI; ages 19–24). The paper reports group-level, univariate whole-brain task contrasts (e.g., Morph 50% recognized as self vs. friend) with thresholding and coordinates (MPFC, PCC, right precuneus reported at voxel/cluster-corrected thresholds). While ROI analyses are also presented, whole-brain SPM results are clearly reported and generalizable to healthy adults. The sample falls within the 17–65 age range and results are reported for the healthy group. The study does not rely solely on ROI, connectivity, between-group-only contrasts, or non-empirical methods. Therefore it meets all inclusion criteria for the review.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-26' name='judgment-26' value='agree'>
<label for='agree-26'>Agree</label>
<input type='radio' id='disagree-26' name='judgment-26' value='disagree'>
<label for='disagree-26'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-26' name='comment-26' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-27'>
<h2>27. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/25987597/' target='_blank'>25987597</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social working memory (social cognition) in a healthy adult sample (N=25; mean age 21.6). The task explicitly manipulates social content (trait-based reordering) versus a non-social control and reports group-level, whole-brain, voxelwise univariate analyses (parametric modulation, contrasts SWM vs CWM, conjunctions) with cluster and voxelwise thresholds, tables of activated clusters, and surface-rendered maps. Results for the healthy participant group are reported separately and are generalizable to healthy adults. No exclusion criteria (e.g., ROI-only, connectivity-only, non-empirical, or out-of-range ages) are violated. Therefore the study meets all inclusion criteria for the review.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-27' name='judgment-27' value='agree'>
<label for='agree-27'>Agree</label>
<input type='radio' id='disagree-27' name='judgment-27' value='disagree'>
<label for='disagree-27'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-27' name='comment-27' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-28'>
<h2>28. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/27122031/' target='_blank'>27122031</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Study used task-based fMRI in healthy adult sample (N=33; ages 20–34) probing social processes (empathy, perspective taking, attention) during a charitable-donation paradigm and complementary social/attention tasks. The paper reports group-level whole-brain analyses: univariate GLMs and at least one significant group-level whole-brain voxelwise contrast (low > high donations; visual cortex cluster, p < 0.05 FWE) and multiple group-level random-effects searchlight results. Results for healthy participants are reported separately; no ROI-only or resting-state–only limitation. Thus it meets inclusion criteria for fMRI social-processing in healthy adults with whole-brain task-evoked maps.</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-28' name='judgment-28' value='agree'>
<label for='agree-28'>Agree</label>
<input type='radio' id='disagree-28' name='judgment-28' value='disagree'>
<label for='disagree-28'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-28' name='comment-28' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-29'>
<h2>29. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22308468/' target='_blank'>22308468</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical task-based fMRI study of social cognition (social working memory) in healthy adults (n=16, mean age 20). The paper reports group-level, whole-brain univariate analyses (parametric load regressors) with voxelwise results and coordinate tables/figures, random-effects group inference, and thresholding procedures. The task explicitly probes social constructs (perspective-taking, mentalizing). It is not ROI-only, not connectivity-only, includes healthy adult behavioral and neural results generalizable to the healthy group, and falls within the 17–65 age range. Therefore it meets all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-29' name='judgment-29' value='agree'>
<label for='agree-29'>Agree</label>
<input type='radio' id='disagree-29' name='judgment-29' value='disagree'>
<label for='disagree-29'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-29' name='comment-29' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-30'>
<h2>30. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/21775952/' target='_blank'>21775952</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study reports task-based fMRI of observing virtual social interactions, addressing social processing. Participants (group-level results from N=15) are described as typical recruited subjects with informed consent, implying healthy adults. The paper presents group-level, univariate whole-brain activation maps/contrast results (t-value activation maps and time courses) showing activity in social cognition regions (STS, mPFC, amygdala), meeting the whole-brain evidence requirement. It is not limited to ROI, connectivity-only, or resting-state analyses. Therefore all inclusion criteria are met.</p>
<p><strong>Fulltext Confidence:</strong> 0.85</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-30' name='judgment-30' value='agree'>
<label for='agree-30'>Agree</label>
<input type='radio' id='disagree-30' name='judgment-30' value='disagree'>
<label for='disagree-30'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-30' name='comment-30' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-31'>
<h2>31. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/28169323/' target='_blank'>28169323</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Social pain and social gain in the adolescent brain: A common neural circuitry underlying both positive and negative social evaluation</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Sci Rep</p>
<p><strong>Publication Year:</strong> 2017</p>
<p><strong>DOI:</strong> 10.1038/srep42010</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5294419/' target='_blank'>5294419</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social evaluation (social inclusion/exclusion) using a task explicitly targeting social-related processing. The sample comprises healthy participants aged 17–20 (N=56 analyzed), which falls within the review’s adult age range (17–65) and are reported as a healthy group. The paper reports group-level, univariate whole-brain voxelwise task contrasts (positive>neutral, negative>neutral, conjunction analyses) with whole-brain FWE-corrected results and coordinates, satisfying the whole-brain evidence requirement. It is not limited to ROI-only, connectivity-only, patient-only, or non-empirical analyses. Therefore all inclusion criteria are met and no exclusion criteria are triggered.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Social interaction inherently involves the subjective evaluation of cues salient to social inclusion and exclusion. Testifying to the importance of such social cues, parts of the neural system dedicated to the detection of physical pain, the dorsal anterior cingulate cortex (dACC) and anterior insula (AI), have been shown to be equally sensitive to the detection of social pain experienced after social exclusion. However, recent work suggests that this dACC-AI matrix may index   any   socially pertinent information. We directly tested the hypothesis that the dACC-AI would respond to cues of   both   inclusion and exclusion, using a novel social feedback fMRI paradigm in a population-derived sample of adolescents. We show that the dACC and left AI are commonly activated by feedback cues of inclusion and exclusion. Our findings suggest that theoretical accounts of the dACC-AI network as a neural alarm system restricted within the social domain to the processing of signals of exclusion require significant revision. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (27902 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
Humans are fundamentally social. We create and reside within a diversity of emergent social systems ranging from couples, families, and groups to cities, countries and civilizations. These social structures have evolved in tandem with biological and psychological mechanisms that support social behavior, and the consequent rich capacity for social interaction has enabled humans to survive, reproduce, and flourish. Central among these mechanisms is the ability to detect and respond to diverse signals of social inclusion and social exclusion – behavioral dynamics that are critical to the establishment and maintenance of relationships, groups and social hierarchies. Indeed, acceptance by our desired social partners is so fundamental that social exclusion has profound negative consequences for affect, health and well-being  and is particularly toxic during adolescence . 

There is burgeoning evidence to indicate that the mental ‘pain’ described by those experiencing such exclusion is more than just a metaphor. Brain imaging data suggest that the neural response to social rejection co-opts components of the well-established physical pain signature in the brain . Cues of rejection have reliably been shown to activate a network of so-called ‘social pain’ regions that overlaps with the neural response to nociceptive stimulation and primarily includes the dorsal anterior-cingulate-cortex (dACC) and the anterior insula (AI) . This account has been extended to suggest that the dACC in particular is involved in domain-general processing of pain information as it pertains to survival-relevant goal conflicts such as hunger or thirst and that social exclusion represents just one form of such survival threat . 

However, recent neuroimaging investigations within the social domain, have raised interesting questions about this social pain account of dACC-AI functioning . For example, multi-level kernel density meta-analyses  of the two prototypical social rejection paradigms used in neuroimaging studies – Cyberball (in which participants are excluded in a virtual ball-tossing game), and the reliving of memories of romantic rejection – have provided equivocal support for the claim that rejection activates the same neural matrix identified in studies of physical pain. Consistent with this, multivariate functional magnetic resonance imaging (fMRI) pattern analyses suggest that separate neural representations code physical pain and mental pain within this identified shared network . Parallel to this, some have argued the broad dACC-AI overlap between social pain and physical pain can be simply explained as salience, and hence trigger multimodal cognitive processes involved in detecting, orienting attention towards, and/or reacting to salient events . 

An alternative possibility is that this pattern of dACC-AI co-activation emergent from the social exclusion literature is not simply a form of ‘pain’, but instead a more sophisticated index of the social dynamic . One compelling candidate is that this network operates as a gauge of social inclusivity, a form of sociometer . If true, then this system would subserve the processing of any signal that provides salient information about social inclusivity, whether it indexes social pain or ‘social gain’. 

We therefore investigated the hypothesis that the dACC-AI matrix prototypically identified in studies of social rejection is in fact critically involved in processing signals of   both   social pain and social gain. We used a novel Social Feedback fMRI task that provides participants with comparably intense signals pertaining to either social exclusion or social inclusion, within the same paradigm, thus allowing us to identify their common and discrete neural substrates. 

Participants believed that they were competing with other contestants in a multi-round game. Participants were told that: at the end of each round, one contestant is excluded from the game while the others are included in the next round; each round involves each contestant individually performing a social task and performance is evaluated by a panel of judges; that these ratings form the basis of the inclusion/exclusion decisions; and that the game is played in a hyperscanning context  where each contestant is in a separate MRI scanner. In fact the judges and other contestants were confederates, only the participants were in a scanner, and only one round of the game, comprising our Social Feedback Task ( ; see also  ), was ever played. 

## Results 
  
Our results showed that participants rated negative social feedback as more upsetting than neutral feedback (  t   = 12.6, df = 55, p < 0.001) and positive feedback as less upsetting than neutral (  t   = 13.5, df = 55, p < 0.001), as expected ( ). Consistent with the social pain literature , the fMRI data (all whole brain,   p   < 0.05, FWE corrected) revealed greater activation in the bilateral dACC and left AI when receiving negative compared to neutral social feedback ( ). Critically, however, these same regions were also activated when receiving positive (relative to neutral) social feedback, along with the ventromedial prefrontal cortex (vmPFC) and ventral striatum bilaterally ( ). In fact, there were no regions that were significantly more activated for negative social feedback relative to positive (negative > positive contrast), even when we explored the data using lower activation thresholds (  p   < 0.005, uncorrected). Furthermore, the reverse contrast (positive > negative) simply revealed activations in the aforementioned ventral striatum and vmPFC regions, areas traditionally associated with reward processing ( )  ( ). These findings indicate that a common dACC-AI network subsumes the processing of information pertaining to both social exclusion and social inclusion. 

This was supported by a logical ‘AND’ conjunction analysis  of ‘negative > neutral social feedback ( )’ AND ‘positive > neutral social feedback ( )’, which revealed clusters in the left AI (peak voxel x = −28, y = 18, z = −10) and the dACC (peak voxel x = 2, y = 32, z = 24) that were significantly active across both conditions (whole brain   p   < 0.05, FWE corrected;  ). The conjunction contrast was masked inclusively using the contrasts ‘positive feedback > baseline’ and ‘negative feedback > baseline’ (see  ) to ensure activation was not a product of the neutral condition, though it should be noted the results were the same without masking the conjunction. Furthermore, separate psychophysiological interaction (PPI) functional connectivity analyses, seeded from these AI and dACC regions, showed comparable results for the positive and negative social feedback conditions (relative to neutral feedback) with significant (p < 0.05, FWE corrected) associations with activity in the right fusiform gyrus and inferior occipital lobe for both contrasts ( ,  , and  ). 

Is the common dACC-AI network identified here the same as that emerging from prior studies of social rejection ? An overlay of the results of our conjunction analysis ( ) on the clusters identified in the whole brain meta-analysis of social rejection studies  suggested that the conjunctive regions identified in the current data map closely onto the meta-analytic findings ( ), indicating that our Social Feedback Task is activating the same network as the Cyberball and romantic rejection paradigms reviewed therein. A similar overlay ( ), this time using just the results of our positive > neutral social feedback contrast, confirms that the network specifically underlying responses to positive evaluative information in the present data conjoins the social rejection network identified in the meta-analysis. In fact, if we extract the parameter estimates from our data that correspond to the peak dACC and AI coordinates from this whole-brain meta-analysis, they show the greatest activation during   positive  , rather than negative feedback in our data, suggesting that this network (hitherto associated with social pain) is actually more strongly activated in a social inclusion context. This is replicated when plotting the peak coordinates from a meta-analysis of social rejection tasks with a restricted focus on ACC activity  ( ,  ) and in structural and functional region of interest (ROI) analyses of the same regions ( ). 

Are there other potential accounts of the present data that merit consideration? One possibility (see   for a full discussion) is that the dACC-AI network activation found here in the context of signals of social inclusion simply occurs as a result of expectancy or carry-over effects from negative social feedback elsewhere in the task. However, these putative influences would also be present for the neutral feedback trials, for which the relevant activations were subtracted out in our critical positive social feedback contrast term, making this explanation less compelling. A related possibility is that positive and negative feedback activate a common neural network because they both involve some form of expectancy violation . However, again this seems unlikely because, if for illustration we focus on the critical positive feedback findings, the pattern of dACC-AI activation remains even for the subset of participants (  n   = 10) who (by their own ratings) expected to be consistently judged as best across all social domains and for whom the positive feedback was therefore unlikely to violate expectancies ( ). 

The shared dACC-AI activation also seems unlikely to be a simple function of emotional arousal as the effects remain after regressing out skin conductance responses (a reliable marker of psychophysiological arousal  recorded during the feedback epochs ( ). Similarly, applying an exclusive mask of the neural correlates of rating the affective impact of feedback (Rating Slide;  ) still revealed significant dACC-AI feedback conjunction clusters, suggesting that this shared activation is not simply attributable to affect processing ( ). Analogously, the pattern of dACC-AI activation in our feedback conjunction remained after applying either an exclusive meta-analysis mask of ‘salience’ (from neurosynth.org)  ( ), or a mask created by re-binning the feedback trials as a function of trial-by-trial stasis/change in social rank  ( ), suggesting that simple explanations based on general salience or social rank processing are also unlikely to account for the results. 


## Discussion 
  
The dACC and AI regions of the brain are implicated in a diverse range of psychological processes . Within social contexts, the dACC-AI network has hitherto been associated with experiences of social exclusion and rejection . However, our results show comparable patterns of involvement of this network in the processing of signals of social inclusion and of social acceptance. By comparable patterns, we mean we report significant independent contrasts of positive versus control conditions (either neutral or low-level baseline), and negative versus control conditions, and a significant conjunction (FWE corrected) for those separate effects. We are not intending to imply that those effects are identical in magnitude, although we failed to find any support for greater activation in this network in the face of negative social feedback relative to positive, or vice versa. These findings suggest that theoretical accounts of the dACC-AI network as a neural alarm system targeted at processing signals of exclusion within social contexts, and the resultant mental pain, require significant revision and extension. The current data are more consistent with a framework in which the dACC-AI matrix indexes signals of social inclusivity more generally within social contexts - a neural sociometer . This accords with functional level models emphasizing the integration of signals of social inclusion and exclusion as a gauge of fluctuating social status , and mirrors a similar theoretical shift concerning the brain’s so-called physical pain networks which have also been shown to be heavily implicated in the processing of physical pleasure . 

Several notable strengths of the current study bolster confidence in these conclusions, including the relatively large (for fMRI) and population-derived sample (  n   = 56), the use of a novel task targeted at the key research question, the application of a comprehensive analytic approach to address common potential confounds in the social pain literature , and the stringent use of familywise error-corrected statistics. 

Other findings from the wider social neuroscience literature are also consistent with this view that the prototypical dACC-AI social pain network is involved in the processing of inclusive social signals. Somerville   et al  . , in a study ostensibly examining social feedback in the context of expectancy violations, report comparable levels of dACC activation when subjects viewed pictures of people who reportedly dislike them   or   like them . Similarly, rostral ACC activation increases in tandem with increasing expectation of positive social feedback . Furthermore, μ-opioid receptors (MOR) that moderate physical pain appear to respond to positive social feedback in key social pain structures . Using Positron Emission Tomography (PET) combined with a social feedback task examining whether one is liked (social acceptance) or disliked (social rejection), MOR activation during social rejection was positively correlated with MOR activation during social acceptance in the anterior insula (left, r  = 0.79; right, r  = 0.62) and dACC (left, r  = 0.86; right, r  = 0.92) with no significant differences in levels of MOR activation in these structures between positive or negative social feedback conditions . 

Interestingly, potentially inconsistent data come from studies using the prototypical social rejection paradigm – Cyberball . Cyberball invariably contains a social ‘inclusion’ comparison condition where the participant is included in the virtual ball tossing game. Unlike social rejection, though, inclusion within Cyberball does not appear to activate the dACC-AI network . However, ‘inclusion’ here simply means not being excluded from the virtual ball tossing game. Such inclusion in this game playing context would be considered the social norm  and consequently is unlikely to be overt or salient enough to markedly activate any putative inclusivity-related brain network. To address this, some studies have adapted Cyberball by using an ‘over-inclusion’ condition in which participants receive the ball 80% of the time . However, if inclusion is the social norm as opposed to an overt, socially positive event, then increasing the number of social inclusion trials is likely to simply accentuate this. Indeed, although the fMRI results in these over-inclusion studies mirrored the usual Cyberball findings in showing that the dACC was more active during exclusion compared to over-inclusion, there was no behavioural difference in the level of subjective social pain reported between inclusion and over-inclusion conditions. This suggests that participants did not find over-inclusion any more socially rewarding than standard inclusion. Hence, while the Cyberball paradigm creates valid socially painful experiences through exclusion, it may be ill-suited to assess the social pleasure associated with inclusion. 

Some potential limitations merit comment. With the absence of a non-social comparison condition we were unable to evaluate the social specificity of our data, and hence rule out interpretations within the broader context of salience processing , although our findings remain even when exclusively masking brain regions prototypically associated with salience processing. Secondly, our GSR data suggest that the neutral condition was not equidistant from the negative and positive conditions in terms of elicited arousal, with the neutral condition being more similar to the negative condition. However, our findings remain the same when comparing positive and negative feedback to our low-level baseline (i.e., without the neutral condition) and when regressing out GSRs in the analyses, suggesting that this does not account for the results. Importantly, the neutral condition was well titrated in terms of its emotional impact relative to the positive and negative conditions ( ). Finally, as more resources and importance appear to be bestowed upon social evaluation in adolescence , our data may not be generalizable to the adult population. Future research into such questions would be beneficial. 

In summary, we show that the classic social pain network in the human brain, centered on the dACC and AI, shows similar patterns of sensitivity to signals of social inclusion as it does to social rejection. These findings have strong theoretical implications for our understanding of the role of this neural network in social cognition and are consistent with a neural sociometer that gauges the implications of all pertinent social information with respect to the organism’s social inclusion status. 


## Methods 
  
### Participants 
  
Participants were adolescents/young adults [  N   = 60; Mean (SD) age = 18 (0.7), range 17–20 years; 31 females] recruited from the population-representative ROOTS cohort (Total   N   = 1143) . We selected adolescents/young adults as we felt the Social Feedback Task would resonate strongly with that demographic. Inclusion criteria were: normal or corrected-to-normal vision; and English speaking. Exclusion criteria were: any history of neurological trauma resulting in loss of consciousness; current psychotropic medication use; current neurological disorder; current Axis 1 psychiatric disorder according to the Diagnostic and Statistical Manual of Mental Disorders (DSM-IV; ref.  ); presence of metal in body; diagnosed specific learning disability; or IQ < 85 on the Wechsler Abbreviated Scale of Intelligence (WASI; ref.  ). 

Participants recruited to the study showed no significant selection bias compared to the total ROOTS sample in terms of gender ratio or socioeconomic status as assessed using the ACORN (A Classification Of Residential Neighbourhoods) geodemographic measure  (  http://www.caci.co.uk  ). 

One participant was removed from further analysis due to a failure of imaging acquisition. Additionally, in the post-scan questioning (see below) three subjects reported some disbelief concerning the veracity of the cover story and were removed from all subsequent analyses, leaving a total of 56 participants for analysis (See   for participant data). 

The study was carried out in accordance with the Declaration of Helsinki and Good Clinical Practice guidelines and approved by the Cambridgeshire Research Ethics Committee. All participants provided written informed consent. 


### The Social Feedback Task 
  
The paradigm was styled as a ‘Big Brother’ game, where participants competed against other contestants (in fact these were confederates) to impress a set of six judges (also confederates) on a series of tasks in order to win through successive rounds of the game (they were told that one contestant per round was rejected from the game) and to eventually win the game. During the study participants were told they would be competing against three other contestants who were each located in MRI scanners located across the U.K, electronically linked so they can play the game interactively (hyperscanning) (see also  ). 

Participants were told that there would be three rounds of the game in total, with one person being rejected on each round until there was one winner remaining. In fact, this was a cover story and only one round of the game was played with all participants being voted off at the end of round one before being fully debriefed following a series of post-scan questions. For this first (and only) round of the game, each participant made a one-minute video recording to be rated by the panel of six judges. Participants were told that these ratings decided which contestant would be rejected from the game and who would progress to the subsequent (fictitious) rounds. The participants were told the six judges were together in a room at a separate location where they could be e-mailed the video recordings and from where they could submit their ratings. The participants were shown pictures of the six judges who were all just a few years older than the participants and were told that the judges had been extensively trained in making social judgments from video recordings. 

For the video recording, participants were asked to describe themselves, talk about what they enjoy doing, say what is important to them in life, outline their aims and achievements and say what was the most important thing that has happened to them was. Participants were given time before the video was recorded to think about these issues, and were shown a video made by a previous participant as an example. A still photograph of each participant was taken at this point for subsequent use in the fMRI session. Participants were informed that, for round one of the game, the judges would be rating these videos on a series of social dimensions (social competence, motivation, self-confidence, personal strength, social attractiveness and emotional sensitivity) that had been reliably linked to social success, prosperity and satisfaction across the life course, and that had been reliably shown to be easily rated on the basis of short video clips. They were told that, for each attribute, each judge would rank the participant and the other three contestants in terms of who was the best on that attribute (positive social feedback), who was the worst on that attribute (negative social feedback), and who was intermediate (neutral feedback) on that attribute. The decisions of each judge for each attribute (36 sets of feedback) were then shown to each participant during the fMRI session, prior to the final decision about who was rejected from the game on Round 1. Participants were told the design of the game was intended to build tension, akin to the voting on ‘Big Brother’ style game shows. 

To encourage believability in the other contestants, having made their own video recording, participants were asked to rate their competitors’ videos along the same social dimensions as the judges were using. Participants were told that each of the other contestants would be doing the same with their (the participant’s) video in the other contestants’ separate locations. 

Participants were told that different recordings for Rounds 2 and 3 would be completed following potential success on Round 1 (which never in fact happened, but was described in order to maintain believability). 

In the MRI scanner (See  ), each judgment epoch began with an 8-second ‘Judge Slide’ showing which judge would be judging which attribute (e.g.   David will now be judging you on social attractiveness  ). This was followed by an 8-second anticipation period of fixation, and an 8-second ‘Feedback Slide’, showing whether each contestant was judged to be the best (positive feedback), intermediate (neutral feedback) or worst (negative feedback) on that particular attribute by that particular judge. Following this ‘Feedback Slide’, and a 2-second fixation, a 10-second ‘Rating Slide’ of how the participants felt about the feedback (ranging from 0 (disappointed) – 10 (pleased)) was completed. This sequence was repeated 36 times for each social attribute from each judge, resulting in 12 ‘best’ judgments, 12 ‘neutral/intermediate’ judgments and 12 ‘worst’ judgments. Attribute and judge orders were counterbalanced across participants. At the end of the 36 judgments, overall judgments were made by each judge detailing whether the participant had made it through to the next round, a total of 6 such final judgments was made (one by each judge); 5 of which were ‘worst’ and one ‘middle’ resulting in the participant being rejected on round one of the game. Following the scan, as a manipulation check, participants were asked a series of questions aimed at assessing believability of the task and of the hyperscanning environment. 

All personally identifiable information (videos and photographs) was deleted immediately following debriefing. 


### Data Acquisition and Analysis Approaches 
  
#### Image acquisition and preprocessing 
  
MRI scanning was conducted at the Medical Research Council Cognition and Brain Sciences Unit on a 3-Tesla Tim Trio Magnetic Resonance Imaging scanner (Siemens, Germany) by using a head coil gradient set. Whole-brain data were acquired with echoplanar T2*-weighted imaging (EPI), sensitive to BOLD signal contrast (48 sagittal slices, 3 mm thickness; TR = 2000 ms; TE = 30 ms; flip angle = 78°; FOV 192 mm; voxel size: 3 × 3 × 3 mm). To provide for equilibration effects the first 5 volumes were discarded. T1 weighted structural images were acquired at a resolution of 1 × 1 × 1 mm. 

SPM8 software (  www.fil.ion.ucl.ac.uk/spm/  ) was used for data analysis. The EPI images were sinc interpolated in time for correction of slice timing differences and realignment to the first scan by rigid body transformations to correct for head movements. Field maps were estimated from the phase difference between the images acquired at the short and long TE and unwrapped, employing the FieldMap toolbox. Field map and EPI imaging parameters were used to establish voxel displacements in the EPI image. Application of the inverse displacement to the EPI images served the correction of distortions. Utilising linear and non-linear transformations, and smoothing with a Gaussian kernel of full-width-half-maximum (FWHM) 8-mm, EPI and structural images were co-registered and normalised to the T1 standard template in Montreal Neurological Institute (MNI) space. Global changes were removed by proportional scaling and high-pass temporal filtering with a cut-off of 128 s was used to remove low-frequency drifts in signal. 


#### Statistical analysis approach to fMRI data 
  
After preprocessing, statistical analysis was performed using the general linear model. Analysis was carried out to establish each participant’s voxel-wise activation during the Feedback and Rating Slides (see  ). Activated voxels in each experimental context were identified using an epoch-related statistical model representing each of the three feedback trial types and subsequent affect ratings, convolved with a canonical haemodynamic response function and mean-corrected. Six head-motion parameters defined by the realignment were added to the model as regressors of no interest. Multiple linear regression modelling was then applied to generate parameter estimates for each regressor at every voxel. At the first level, the following feedback contrasts were generated; ‘positive feedback’; ‘neutral feedback’; ‘negative feedback’; ‘positive feedback’ minus ‘neutral feedback’; ‘negative feedback’ minus ‘neutral feedback’; ‘positive feedback’ minus ‘negative feedback’ and ‘negative feedback’ minus ‘positive feedback’. The same contrasts were also generated for the ratings of affect (Rating Slides) following each Feedback Slide. For group statistics, random effects analysis was utilized. A conservative voxel-wise statistical threshold of P < 0.05 familywise error (FWE) corrected for multiple comparisons across the whole-brain was used for all analyses. 




## Additional Information 
  
 How to cite this article:   Dalgleish, T.   et al  . Social pain and social gain in the adolescent brain: A common neural circuitry underlying both positive and negative social evaluation.   Sci. Rep.   7  , 42010; doi: 10.1038/srep42010 (2017). 

 Publisher's note:   Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-31' name='judgment-31' value='agree'>
<label for='agree-31'>Agree</label>
<input type='radio' id='disagree-31' name='judgment-31' value='disagree'>
<label for='disagree-31'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-31' name='comment-31' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-32'>
<h2>32. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31100434/' target='_blank'>31100434</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Dyadic interaction processing in the posterior temporal cortex</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Neuroimage</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1016/j.neuroimage.2019.05.027</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6610332/' target='_blank'>6610332</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study of social interaction perception in healthy adults (N=21; ages 18–35). The task explicitly probes social interaction processing (arguing, celebrating, laughing) during fMRI. The manuscript describes GLM estimation and group-level whole-brain analyses used for functional localizers (interaction > scrambled; bodies > objects; faces > objects; mentalizing > pain) to define ROIs, and reports a whole-brain searchlight analysis. Thus the paper provides group-level, task-evoked whole-brain univariate contrasts (localizers) and multivariate whole-brain searchlight results appropriate for healthy adults. The sample is within the 17–65 range and healthy-group results are reported. The study does not meet any exclusion criteria (not limited to ROI-only, not resting-state, not between-group-only). Therefore it meets all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Recent behavioural evidence shows that visual displays of two individuals interacting are not simply encoded as separate individuals, but as an interactive unit that is 'more than the sum of its parts'. Recent functional magnetic resonance imaging (fMRI) evidence shows the importance of the posterior superior temporal sulcus (pSTS) in processing human social interactions, and suggests that it may represent human-object interactions as qualitatively 'greater' than the average of their constituent parts. The current study aimed to investigate whether the pSTS or other posterior temporal lobe region(s): 1) Demonstrated evidence of a dyadic information effect - that is, qualitatively different responses to an interacting dyad than to averaged responses of the same two interactors, presented in isolation, and; 2) Significantly differentiated between different types of social interactions. 

Multivoxel pattern analysis was performed in which a classifier was trained to differentiate between qualitatively different types of dyadic interactions. Above-chance classification of interactions was observed in 'interaction selective' pSTS-I and extrastriate body area (EBA), but not in other regions of interest (i.e. face-selective STS and mentalizing-selective temporo-parietal junction). A dyadic information effect was not observed in the pSTS-I, but instead was shown in the EBA; that is, classification of dyadic interactions did not fully generalise to averaged responses to the isolated interactors, indicating that dyadic representations in the EBA contain unique information that cannot be recovered from the interactors presented in isolation. These findings complement previous observations for congruent grouping of human bodies and objects in the broader lateral occipital temporal cortex area. 
   Highlights  
  
pSTS and EBA classify between different dynamic interactions. 
  
EBA is sensitive to (uniquely) dyadic interaction information. 
  
These findings support previous evidence for grouping of interacting people/objects in LOTC. 
  
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (38608 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Social interactions are ubiquitous, yet little research has investigated visual perceptual responses to these common social scenarios, relative to individual-person perception ( ). Interestingly, recent behavioural evidence demonstrates that visual responses to two human individuals that are positioned to imply an interaction evoke different responses than when not positioned in this manner. These effects are demonstrated most strikingly by the findings of  : In this study, subjects viewed pairs of briefly presented (30 ms) human bodies or control objects (i.e. chairs), that either faced   towards   or   away   from each other, in either upright or inverted orientation, and were instructed to respond to the stimulus category they saw (i.e. bodies or chairs). Greater recognition accuracy was shown for upright than inverted dyads when an interaction was implied by the two bodies facing towards each other, but crucially, not when facing away from each other. Similarly, visual search facilitation is shown for full body dyads that are positioned to   face towards   – rather than   away   from – each other ( ), while facing direction effects are shown to modulate the evaluation of facial emotion of a target face (i.e. the perceived emotional expression of a target face is modulated by the emotion of a simultaneously presented non-target face, but only when positioned to   face towards   the target;  ). 

Together, these behavioural findings demonstrate that interacting individuals are not merely perceived as separate individuals, but as an   interactive dyad  . Indeed, similar   non-linear   neural responses have been observed recently – that is,   that responses to dyadic interaction stimuli are not the same as a linear combination of responses to the isolated elements of an interaction  . Specifically,   demonstrated evidence of non-linear responses to human-object interaction stimuli in the posterior temporal cortex; the authors used a pattern classification approach to test whether responses to images of human-object interactions (e.g. a person pushing a shopping cart) are distinct from   the mean-averaged response   to the constituent parts of the interaction (i.e. the averaged response to an isolated human and isolated cart); it was found that voxel patterns for human-object interactions in the posterior superior temporal sulcus (pSTS) and lateral occipital cortex (LOC) were statistically distinct from the averaged patterns evoked by isolated ‘interaction parts’. These findings suggest that these regions are sensitive to   unique   interactive information that is accessed only through holistic processing of interactions, and not through part-wise analysis (i.e. processing of constituent ‘interaction parts’ in isolation). 

Interestingly, this response in the pSTS complements previous findings that this region plays an important role in the visual processing of dynamic social interactions; for example, greater pSTS responses are shown for interacting point-light human dyads relative to two non-interacting figures, as well as for similar stimuli depicted by moving geometric shapes that do not contain body information ( ;  ). This region also differentiates between types of interactions performed by live-action human stimuli ( ), and is sensitive to ‘interactive’ motion cues such as the movement contingency between two interacting human figures ( ), or the degree of correlated motion between interacting animate geometric shapes ( ;  ). These findings implicate the pSTS as a region that may be optimized for processing social interaction information. 

The main aim of the present study was to determine whether pSTS encodes dynamic human interactions between two individuals in a non-linear fashion, using a similar approach to  . We herein adopt the phrase ‘  dyadic information effect  ’ rather than ‘non-linear’ effect, to emphasize a   sensitivity to unique information that is only present in dyadic interactions and not the averaged responses evoked by each interactor, presented in isolation  . Specifically, we used support vector machine (SVM) classification to test whether voxel-pattern responses to dyadic stimuli in the pSTS were statistically differentiable from   averaged response patterns   of isolated interactors. Additionally, it was predicted that significantly differentiable responses to   different types   of dyadic interaction would be observed in the pSTS, replicating previous findings (e.g.  ;  ). Responses were also tested in 3 other functionally localized regions of interest (ROIs) that are selective for social information that likely contributes to social interaction processing, and therefore might also plausibly show the hypothesized effects: Extrastriate body area (EBA), mentalizing-selective temporo-parietal junction (TPJ-M), and face-selective STS (STS-F). 


## Material & methods 
  
### Participants 
  
21 right-handed adults (mean age = 23.40 years; SD = 3.74; range = 18–35; 12 females) participated in the study. Participants gave informed consent and received monetary compensation for taking part. Ethical procedures were approved by the Bangor University psychology ethics board. 


### Stimuli 
  
Stimuli consisted of 4 s (s) video clips that were taken from custom footage of paired actors engaging in semi-improvised interactions. Actors were instructed to improvise these scenarios while enacting scripted ‘  action-gestures  ’; for example, for a given arguing scenario, one actor might be instructed to   point angrily   at the other person while the other   shook their fists   in frustration. Therefore, each interaction depicted two individuals performing a given pair of complementary action-gestures that they were encouraged to enact in a natural, authentic way (see supplementary materials A for example videos). An initial set of   dyad stimuli   were created (along with a separate set of   alone stimuli  , as described below; see   for examples of both dyad and alone stimuli). Dyad stimuli depicted two actors engaging in one of 3   interactive scenarios  :   Arguing   (i.e. both actors engaging in an angry/frustrated confrontation),   celebrating   (i.e. both actors celebrating together, excitedly), and   laughing   (i.e. both actors were laughing together, or at each other). These specific scenarios were chosen for the ‘tonal consistency’ of actions performed by a given pair of interactors, such that the intentions, emotions, and valence information conveyed by both individuals in a given scenario were always similar (e.g. angry/frustrated) rather than contrasting (e.g. angry/sad). This ensured that successful classification of the different scenarios was not driven by systematic differences in intentional, emotional, or valence content   between   interactors. Therefore, these scenarios represented three interactive scenarios that were intended to be easily distinguishable.   
a. Example video frames from the dyad versions of the three interaction scenarios. Each row represents one of three unique female-male interactor pairs. b. Two example alone stimuli (created from a given dyad stimulus). 
  Fig. 1   

Within each interaction scenario (e.g. arguing), 4 exemplar videos were created, each using a unique pair of action-gestures, such that each video showed the two individuals performing a complementary pair of action-gestures (e.g. while arguing, interactor A accusatorily points at interactor B who is shaking their hands in frustration). Importantly, no gestures were ‘reused’ in any of the other action-gesture pairings (i.e. a total of 8 action gestures were used across the 4 exemplar videos for each scenario). Similarly, 3 different female-male   interactor pairs   enacted these scenarios, yielding a total of 36 dyad stimuli: 3 interaction scenarios (arguing, celebrating, laughing) x 4 unique action-gesture pairings x 3 interactor pairs. The final stimuli were chosen from a wider set of stimuli based on the highest ‘interactive-ness’ and ‘naturalness’ ratings from a pilot study (N = 10; see supplementary materials A). 

For these stimuli, the average horizontal distance between actors was closely matched – the visual angle between the centre of each actor's torso was approximately 4.80°, and actor height ranged between 3.73 and 4.26°. As dynamic facial information is known to activate the STS (e.g.  ), the presence of facial information was controlled such that classification could not be attributed to different facial expressions. Accordingly, these stimuli did not contain high spatial frequency face information, but body information was preserved. To achieve this, a circle-shaped Gaussian blur mask was placed on each of the actors' heads for each video frame. This preserved the overall shape of the head, preventing the potentially eerie appearance of headless interacting bodies. 

To test neural responses to the same interactive information – but without specifically   dyadic information   (i.e. information available from two interactors presented simultaneously) – a separate set of 72   alone stimuli   were created by removing either individual from each of the 36 dyad stimuli (see  b for examples of two alone stimuli). It is important to note that although these stimuli depicted an isolated interactor by themselves, they still conveyed interactive information (e.g. communicative gesturing towards an implied interactor). Two horizontally-flipped variants of these 108 unique stimuli (36 dyad ​+ ​72 alone stimuli) resulted in a final set of 216 stimuli. 


### Design & procedure 
  
A rapid event-related design was used, and each run was optimized using optseq2 (  http://surfer.nmr.mgh.harvard.edu/optseq  ), based on differentiating 6 conditions (i.e. both dyad and alone variants of the arguing, celebrating, and laughing interaction scenarios), with an inter-stimulus interval range between 0 and 10s (along with 8s fixation at the beginning of each run, and 16 s at the end to capture most of the haemodynamic response). The 6 designs with the highest detection sensitivity were selected to determine event timings for runs. 

Inside the scanner, participants viewed stimuli that were presented centrally on the screen within a 9.17 × 5.11° rectangular space. 6 runs were completed, each lasted exactly 7 minutes and contained 8 stimuli for each dyad version and 16 stimuli for each alone version of each of the 3 scenarios, resulting in 72 experimental stimuli per run. Three important stimulus ordering considerations are also noted here: Firstly, left and right horizontal presentations of each stimulus were balanced within the design, such that any resulting effects could not be attributed to low-level confounds in the horizontal position of interactors (i.e. left and right horizontally-flipped variants of the stimuli appeared equally often); secondly, that any given pair of alone stimuli (i.e. that originated from the same dyad stimulus) were always presented in the same run as each other so that classification of alone stimuli did not contain additional between-run variance that was not present for the dyad stimuli; thirdly, to minimize repetition effects (i.e. seeing the exact same action-gestures from a given dyad stimulus and the corresponding pair of alone stimuli), alone stimuli that appeared in any given run were always from dyad stimuli that were allocated to a different run. 

In addition to the stimuli already described, nine additional catch stimuli were presented (three dyad stimuli, and six alone stimuli) but were not later analysed. These trials contained a ‘frame-freeze’ in which 12 consecutive video frames (duration = 500 ms) were randomly removed from the video and replaced with one repeated frame for that period, creating the impression of a momentary video pause. Participants were instructed to simply watch the videos and to give a button-press response whenever a frame-freeze was detected, and to refrain from making explicit judgements about the interactors. 


### Localizer tasks & ROI creation 
  
Participants completed several localizer tasks in a separate scanning session, on a separate day (see supplementary materials B for full description of these tasks). Briefly explained, three different video tasks were used to localize brain regions that are sensitive to different types of social information: 1) A point-light figure social interaction task similar to that used previously ( ;  ) was used to localize interaction-selective pSTS (pSTS-I) regions of interest (ROI) with the interaction > scrambled interaction contrast (i.e. two intact human figures interacting vs. spatially scrambled versions of the same stimuli in which body and interactive information was disrupted). 2) A dynamic body and face localizer that was adapted from stimuli used previously ( ) – this served to localize body-selective EBA and face-selective STS cortex (i.e. STS-F), with the bodies > objects, and faces > objects contrasts, respectively. 3) A free-viewing animated film (‘Partly Cloudy’; Pixar Animation Studios:   https://www.pixar.com/partly-cloudy  ) identical to that used previously ( ) was used to localize mentalizing-selective TPJ-M with the mentalizing > pain contrast (i.e. mentalizing > pain time-points). 

These tasks allowed for the localization of 4 bilateral subject-specific ROIs (i.e. pSTS-I, EBA, STS-F, & TPJ-M; see supplementary materials C for a visualization of these ROIs). These ROIs were created with a group-constrained definition procedure (e.g.  ) as follows. For a given subject and contrast (e.g. interaction > scrambled interaction, for the pSTS-I), a 5 mm-radius ‘search sphere’ was created by running a whole-brain analysis for N-1 group subjects (i.e. with the ‘current’ subject excluded) and centring the sphere at the peak voxel (i.e. highest t-value) in the designated region. This relatively small sphere was chosen to ensure subject's ROIs did not deviate too far from a given designated anatomical region (e.g. pSTS). To determine the position of the final ROI, a whole-brain analysis for the current subject (for the same contrast) was run, and resulting activation was constrained to the search sphere. A 7 mm-radius sphere was then centred at the peak voxel in this search region; this ROI sphere size was chosen as an ideal compromise between capturing a relatively large number of voxels that would benefit classification performance (e.g.  ), and ensuring minimal overlap between neighbouring STS ROIs. 

All ROIs contained 179 voxels, with the exception of two subjects that had small regions of overlap between the right pSTS-I and right TPJ-M, and a further two subjects with similar overlap between the right pSTS-I and right STS-F. Across these four subjects, a mean overlap of 18 voxels (range: 12–24) was found. To ensure independence of ROI voxels within each of these four subjects, overlapping voxels were removed and ROIs were recreated (respective final ROI sizes for these four subjects were: 167, 161, 161, 155 voxels; all other ROIs for these subjects contained 179 voxels). 


### MRI parameters, pre-processing, & GLM estimation 
  
Scanning was performed with a Philips 3T scanner at Bangor University. Functional images were acquired with the following parameters: T2*-weighted gradient-echo single-shot EPI pulse sequence; TR ​= ​2000 ​ms, TE ​= ​30 ​ms, flip angle ​= ​83°, FOV(mm) ​= ​240 ​× ​240 x 108, acquisition matrix ​= ​80 ​× ​78 (reconstruction matrix ​= ​80); 36 contiguous axial slices were acquired, with a reconstructed voxel size of 3 mm . Four dummy scans were discarded prior to image acquisition for each run. Structural images were obtained with the following parameters: T1-weighted image acquisition using a gradient echo, multi-shot turbo field echo pulse sequence, with a five echo average; TR = 12 ms, average TE = 3.4 ms, in 1.7 ms steps, total acquisition time = 136s, FA = 8°, FOV = 240 × 240, acquisition matrix = 240 × 224 (reconstruction matrix = 240); 128 contiguous axial slices, acquired voxel size (mm) = 1.0 × 1.07 x 2.0 (reconstructed voxel size = 1 mm ). 

Pre-processing was performed with SPM12 (fil.ion.ucl.ac.uk/spm/software/spm12). This entailed slice-timing correction, re-alignment (and re-slicing), co-registration, segmentation, normalization, and smoothing. All default parameters were used except for a 6 mm FWHM Gaussian smoothing kernel. General linear model (GLM) estimation was performed in SPM12 on participants’ normalized images. For the main task, whole-brain beta maps were generated on a run-wise basis with events estimated as 6   classification conditions   – both dyad and alone variants of the arguing, celebrating, and laughing stimuli. One further set of maps were created where each event was modelled separately, to allow for stimulus-wise analyses (see supplementary materials D). 


### SVM classification analyses 
  
Leave-one-run-out linear support vector machine (SVM) classification was implemented with CoSMoMVPA ( ). Briefly explained, for a given subject, an SVM classifier was trained on ROI voxels (i.e. beta values) for the conditions of interest (e.g. dyad variants of the arguing, celebrating, and laughing conditions) in all but one run of data – with the ‘left-out’ run of data used to independently test classification performance on. This was iterated 6 times with each run serving as the left-out test run, and classification accuracy was averaged across iterations. These values were then entered into group level   t  -tests. All reported tests were significant at the corrected Bonferroni threshold (α) unless otherwise stated. A different threshold was calculated separately for each set of analyses (i.e. based on 8, 8, & 4 comparisons for dyad, alone, and cross-classification analyses, respectively), as stated in each sub-section in the results. All   t  -test   p-  values are one-tailed. 

This approach was almost identical for both ‘standard’ classification (e.g. between the three dyad conditions, or between the three alone conditions) and   cross-classification   analyses except that the allocation of training and test conditions differed; that is, for cross-classification, the classifier was trained on the three dyad conditions, but   tested   on the three alone conditions. Significant cross-classification demonstrates that the patterns underlying the two sets of conditions are similar to each other, and therefore are largely driven by the same information. However, we reasoned that if a region showed significantly greater dyad classification than cross-classification (i.e. between dyad and alone conditions), this would indicate sensitivity to dyadic information that could not be ‘recovered’ from the individual interactors presented in isolation (i.e. averaged responses to alone stimuli). As explained previously (see section  ) several stimulus ordering constraints were imposed within each run, and importantly, alone stimuli from a given dyad stimulus were always presented in a different run to minimize repetition effects. Notably, this likely resulted in a   more conservative   estimation of the dyadic information effect due to greater similarity between stimuli in test and train data splits for cross-classification, than for ‘standard’ classification (see supplementary materials E for further details). 



## Results 
  
### SVM classification analyses 
  
For each of the 8 functionally localized ROIs, a series of analyses were performed in which a linear SVM classifier was trained and tested on different variants of the 3 interaction scenarios (i.e. arguing, celebrating, and laughing). One-sample   t  -tests were used to determine whether classification accuracy was above chance level (i.e. 100% / 3 categories = 33.3% chance accuracy; Bonferroni corrected α = 0.006). 

Significant above-chance classification of the three interaction scenarios of dyad stimuli (see  ) was observed in the right pSTS-I (Classification accuracy (%):   M   = 41.39,   SD   = 9.10;   t   (19) = 3.96,   p   < .001) and both the right EBA (  M   = 49.38,   SD   = 12.19;   t   (17) = 5.59,   p   < .001) and left EBA (  M   = 50.88,   SD   = 13.00;   t   (18) = 5.88,   p   < .001), and at an uncorrected threshold in the left pSTS-I (  M   = 38.60,   SD   = 10.55;   t   (18) = 2.17,   p   = .022). None of the 4 other ROIs – bilateral STS-F and TPJ-M – showed above-chance classification of the dyad stimuli (all   ps   > .100; see  ; see supplementary materials F for full statistics).   
A bar chart showing classification accuracy values for dyad, alone, and cross-classification analyses for bilateral pSTS-I and EBA ROIs. Dashed line represents chance-level accuracy (33.3%). *** ​= ​  p   ​≤ ​.001; ** ​= ​  p   ​≤ ​.010; * ​= ​  p   ​≤ ​.05; +=   p = .  073. Error bars are SEM. 
  Fig. 2     
A bar chart showing classification accuracy values for dyad and alone classification for bilateral STS-F and TPJ-M ROIs. Dashed line represents chance-level accuracy (33.3%). No results were significant. Error bars are SEM. 
  Fig. 3   

It is possible that significant classification of dyad stimuli in the bilateral pSTS-I and EBA does not completely rely on inherently dyadic information, and may also encode information conveyed by isolated individuals (e.g. interactive gestures directed towards an implied – but physically absent – interaction partner). To test if this was true, another classification analysis (Bonferroni corrected α = 0.006) was run to see if these regions could differentiate the three interaction scenarios for the alone stimuli (see  ,  ). It is worth reiterating that the   same overall information   was present as in the dyad classification analysis (i.e. same scenarios, actors, & gestures). Above-chance classification was shown in right pSTS-I (  M   = 43.33,   SD   = 12.57;   t   (19) = 3.56,   p   = .001) but only marginally in left pSTS-I (  M   = 37.43,   SD   = 12.81;   t   (18) = 1.39,   p   = .090). Both right EBA (  M   = 46.30,   SD   = 7.86;   t   (17) = 7.00,   p   < .001), and left EBA (  M   = 46.49,   SD   = 6.73;   t   (18) = 8.52,   p   < .001) also showed significant classification. As for dyad classification, bilateral STS-F and TPJ-M ROIs did not show above-chance classification (all   ps   > .088), and therefore, these regions were excluded from further analyses. 

Together, these two classification analyses demonstrate interaction sensitive responses in the right pSTS-I and bilateral EBA regions, and to a marginal extent in the left pSTS-I; specifically, these regions were able to differentiate between the three different interaction scenarios, both when observing an intact dyad and when observing the same constituent interactors presented in isolation. However, although these regions are sensitive to both modes of presentation, this does not mean that the underlying information driving classification in both dyadic and alone scenarios is the same (e.g. information about the spatial-relations between interactors may contribute to classification of the dyad stimuli, but not the alone stimuli). Indeed, if voxel pattern classification in any region does not fully generalise from dyad stimuli to the alone stimuli, this would suggest that there is information encoded by these regions during dyadic interaction perception that cannot be recovered by the same information presented in the alone stimuli. 

Next, a cross-classification analysis was implemented (Bonferroni corrected α = 0.013) whereby an SVM classifier was trained to discriminate responses to the three interaction scenarios with the dyad stimuli, but performance was tested on responses to the alone stimuli. Significant cross-classification was shown for all 4 ROIs (right pSTS-I:   M   = 41.39,   SD   = 8.92;   t   (19) = 4.04,   p   < .001; left pSTS-I:   M   = 40.64,   SD   = 9.63;   t   (18) = 3.31,   p   = .002; right EBA:   M   = 43.21,   SD   = 7.75;   t   (17) = 5.40,   p   < .001; left EBA:   M   = 46.20,   SD   = 11.27;   t   (18) = 4.97,   p   < .001), demonstrating that these regions encode similar information in both the dyad and alone stimuli. 

To test for the main hypothesis (i.e. a dyadic information effect) paired   t  -tests were then performed (Bonferroni corrected α = 0.013) between dyad classification accuracy scores and cross-classification accuracy scores. No difference was observed for either the right pSTS-I (  t   (19) = 0.00,   p   = .500) or left pSTS-I (  t   (18) = −0.73,   p   = .763), showing no dyadic information effect, indicating that the main hypothesis was not supported. However, significantly greater accuracy for dyad classification than cross-classification was shown in the right EBA at an uncorrected level (  t   (17) = 2.07,   p   = .027). A similar, although weaker, marginal effect was also shown in the left EBA (  t   (18) = 1.52,   p   = .073). Therefore, evidence suggestive of a dyadic information effect was shown in the bilateral EBA only. 

To determine whether regions outside the functionally defined ROIs demonstrated a dyadic information effect, whole-brain searchlight analyses ( ) were performed (see supplementary materials G for a full description of searchlight methods and results). Peak classification accuracies (i.e. for dyad and alone classification separately, and also for cross-classification) were observed in the bilateral lateral occipito-temporal cortex (LOTC) and pSTS, along with weaker responses in other areas. However, no dyadic information effects were observed in the LOTC/EBA for this analysis (or in any other brain region), further demonstrating the subtle nature of the effect in the ROI analysis. 


### Reliability of the dyadic information effect in EBA 
  
Due to the marginal nature of these results in the EBA, several follow up tests were performed to determine the reliability of this effect. First, Cohen's   d   effect-sizes were calculated for both the right and left EBA. A medium effect-size was found for the right EBA (  d   = 0.60), and a small-to-medium effect was shown in the left EBA (  d   = 0.38). 

To ensure that these effects were not spuriously driven by the ‘direction’ of cross-classification training and testing roles, cross-classification was performed again, but with the training and testing roles reversed. That is, the classifier was now trained on the   alone   stimuli and tested on the   dyad   stimuli. Both right EBA (  M   = 43.83, SD = 7.60;   t   (17) = 5.86,   p   < .001) and left EBA (  M   = 46.20, SD = 10.32;   t   (17) = 5.43,   p   < .001) showed significant cross-classification. Crucially, dyadic information effects were replicated; greater accuracy for dyad classification than cross-classification was again shown in the right EBA (  t   (17) = 2.03,   p   = .029;   d   = 0.55) and marginally in the left EBA (  t   (18) = 1.41,   p   = .088;   d   = 0.40). 

One further test was performed to determine how reliable these effects were across different ROI sizes (i.e. in addition to the original 7 mm radius ROIs, 5, 6, 8, 9, 10, 11, & 12 mm radius ROIs were created). Consistent with the dyadic information effect in the in the original right EBA ROI, greater accuracy for dyad classification than cross-classification was shown across all ROI sizes, but was most pronounced in larger ROIs (i.e.   ps   < .05 for 8, 9, 11, & 12 mm radii; see supplementary materials H). By contrast, in the left EBA, the dyadic information trend was only shown for smaller ROI sizes (i.e. 5 mm radius:   p   < .05; 6 and 7 mm radii: marginal   ps   ≤ .073); indeed, these hemispheric differences appear to be consistent with larger regions of body selectivity in the right than left EBA as previously reported ( ). 


### Results summary 
  
In summary, although right pSTS-I – and marginally, left pSTS-I – differentiated between the three interaction scenarios, no evidence for specific   dyadic information   encoding was observed in these regions. Instead, this effect was observed in the right EBA at an uncorrected threshold (the data for this analysis are available to download; see supplementary materials I). Follow-up analyses demonstrated that this effect was reliable and interpretable, and is further supported by similar (although weaker) effects in left EBA. Control analyses revealed that these effects are not accounted for by low-level differences in stimulus motion energy between conditions (see supplementary materials J). Additionally, exploratory representational similarity analyses were also performed to further characterize EBA responses to dyad and alone stimuli (see supplementary materials D). 



## Discussion 
  
### Overview of results 
  
The present study aimed to determine whether the pSTS – or any other posterior temporal lobe region – showed sensitivity to   unique   dyadic information in visually observed interactive scenarios that is not present for isolated individual interactors. Two main findings were shown: 1) EBA – but not pSTS – showed evidence consistent with the encoding of unique dyadic information; 2) pSTS (and EBA) classified between three interaction scenarios (i.e. arguing, celebrating, & laughing) replicating similar differentiation of types of interactions between abstract moving shapes ( ;  ). 


### Interaction classification in the pSTS & EBA 
  
Specifically, which type of information might drive differentiation of interaction scenarios in the pSTS and EBA? The pSTS plays an important role in biological motion perception (e.g.  ;  ;  ), and is strongly responsive to movement contingencies between interacting figures (e.g.  ), as well as dynamic cues that imply interactive behaviour between animate moving shapes ( ;  ). Similarly, the pSTS is also sensitive to the intentional contents of actions ( ;  ;  ). It therefore seems plausible that classification in the pSTS is driven by differential intentional content between interaction scenarios that is extracted from different dynamic contingencies between interactors. 

Additionally, the EBA also classified between interaction scenarios. A direct interpretation of this result is that body posture information contributes strongly to the differentiation of these three scenarios. EBA is shown to be sensitive to dynamic postural information (i.e. continuous sequences of body postures that form coherent actions) and is suggested to encode body-based actions ( ). In the current study, distinctively different sequences of coherent body postures – or action-gestures – may have driven classification of interaction scenarios. Although distinct action-gestures were used within each interactive scenario, these tended to be relatively similar to each other (e.g. arguing gestures usually depicted short, sharp movements, while laughing gestures typically contained convulsive torso movements). Therefore, it seems possible that classification of interaction scenarios in the EBA was likely the result of similar action-gestures   within   each scenario, that were markedly different   across   the three scenarios. 


### No dyadic information effect in the pSTS 
  
Despite the pSTS classifying interactive scenarios, the main prediction was not supported; no   dyadic information effect   was observed for the pSTS. This contrasts with the findings of   that showed an analogous effect in the pSTS for static depictions of human-object (inter)actions compared to the averaged responses to isolated objects and humans. One possible explanation for this concerns STS sensitivity to implied biological motion in static images ( ;  ); static human-object interactions might imply greater biological motion or more effortful movement that is not ‘recoverable’ from isolated human and objects; for example, an image of a person pushing a cart implies greater movement than the same body pose and cart presented separately, by virtue of greater physical effort required to move the cart, along with the corresponding impression that the cart is moving. Additionally, pSTS sensitivity to causal contingencies (e.g. a billiard ball hitting another, causing a transfer in motion;  ) suggests the strong influence of physical contact in human-object interactions that was not present in the isolated stimuli. By contrast, the current study used dynamic stimuli that contained biological motion information but no physical contact, and as such, the dyad and alone stimuli were closely matched for these two sources of information that might have driven responses to the stimuli used by  . 

Although no dyadic information effect was found in the pSTS, it is important to note that interactive information was still conveyed in the alone stimuli (e.g. communicative gesturing to an unseen interactive partner was strongly implied). Therefore, successful classification of the alone stimuli does not necessarily reflect that pSTS responses are non-interactive. Indeed, in the context of the sorts of gestural interactions used in the current study, it is possible that classification of the alone and dyad stimuli relied on the same cues (i.e. communicative gestures). Similarly, the current data supports the possibility that representations of interactions in this region may encode the presence of two interactors in a linear fashion (i.e. dyad = the average of the two individuals). Alternatively, it is possible that the pSTS responses to both dyad and alone stimuli are driven by interactive gestures ‘directed’ at another individual, regardless of whether the other individual is present or not. 


### Dyadic information processing in the EBA 
  
Although not observed for the pSTS, a dyadic information effect was shown for the right EBA and to a lesser extent, the left EBA. Although not predicted, this does fit with previous findings observed in the wider LOTC area. Specifically,   observed differentiable responses to human-object interactions than averaged responses to humans and objects in object-selective LOTC (i.e. LOC – in close proximity to EBA); however, this trend did not quite reach significance in the EBA, likely due to weaker responses to object stimuli, suggesting that the currently observed EBA responses could be specific to human body information. Recent evidence also shows that object-selective LOTC is sensitive to ‘regular’ spatial configurations of objects that imply a congruent scene (e.g. different responses are shown for scenes that depict a sofa positioned in front of a television, rather than behind it;  ). Similarly, object-selective LOTC is sensitive to spatial configurations of objects that imply an action (e.g. a pitcher tilted towards an empty cup), relative to configurations that do not ( ). 

Broadly, these findings might suggest a converging role for configural processing of   distinct   objects and people in the LOTC. In relation to the present findings, it is conceivable that LOTC – and here the EBA specifically – performs similar configural processing or grouping based on the action-, body-, and movement information conveyed by interactors. If true, to what extent does   dynamic   information contribute to this effect? In contrast to previous work investigating LOTC grouping responses for static stimuli ( ;  ;  ), the current study used dynamic stimuli. Although the EBA is highly sensitive to static pose information, and may process body movements as a series of static ‘snapshots’ ( ;  ) body (and face) responses are shown to generalise across static and dynamic depictions in broad regions of the posterior temporal cortex ( ). Similarly, representations in the LOTC generalise across dynamic and static depictions of actions and are invariant to other low-level features such as movement direction, or the specific hand used to perform an action ( ;  ). 

In line with these findings, it is likely that dyadic representations of (inter)actions in the EBA generalise across static-dynamic depictions. While dynamic information may not be necessary to encode such scenarios, it may, potentially, allow for more elaborate encoding of body-based actions than similar, static depictions. Additionally, other spatial cues (e.g. interpersonal distance, physical contact, and facing direction), and temporal cues (e.g. movement contingencies and correlated motion) may also contribute to dyadic encoding in the EBA, and further research may directly clarify which cues contribute most prominently. 

It is also worth briefly considering the extent to which dyadic information processing is present for other types of interaction, for example, interactions depicted by moving geometric shapes that do not contain body information. These types of stimuli are known to drive responses in LOTC, ostensibly due to the presence of simple actions such as pushing and pulling movements ( ). As mentioned previously, the wider LOTC area shows some sensitivity to spatial-temporal relations between interacting or scene entities, and therefore cortex in close proximity to (and overlapping with) EBA might plausibly encode dyadic information for these abstract scenarios. 

The present stimuli consisted of interactions between individuals that did not involve physical contact, a potentially powerful interaction cue that is worthy of further investigation; indeed, stronger dyadic information effects might be predicted for contact-based interactions (e.g. two individuals shaking hands), by virtue of categorical differences in physical contact (i.e. presence of physical contact in dyadic interactions vs. absence of physical contact in ‘alone’ variants of these stimuli). 


### Conclusion 
  
In summary, the present results show that both EBA and pSTS differentiate between different types of social interactions. Crucially, representations of dyadic social interactions in the EBA are sensitive to information beyond that which is encoded by the simple average of two separate interactors presented in isolation. This so-called   dyadic information effect   suggests that the EBA is sensitive to unique interactive information that is present only when two individuals interact simultaneously. These findings complement previously observed sensitivity in the wider LOTC area to spatial configurations of objects or bodies that support the processing of holistic, congruent scenarios. 



## Author contributions 
  
J.W & K.K: study design, data-collection, analysis, writing, and editing. 


## Conflicts of interest 
  
None declared. 


## Funding 
  
This work has received funding from the   under the   (ERC starting grant: Becoming Social). 

 </div>
</div>
</div>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-32' name='judgment-32' value='agree'>
<label for='agree-32'>Agree</label>
<input type='radio' id='disagree-32' name='judgment-32' value='disagree'>
<label for='disagree-32'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-32' name='comment-32' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-33'>
<h2>33. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/29408539/' target='_blank'>29408539</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study reports task-based fMRI activation for social cognition (TOM vs Random) in a large sample of healthy adults (Human Connectome Project, n=787; ages 22–>35). The paper provides group-level, univariate whole-brain task-evoked statistical maps (Cohen's d and level-3 z maps) and describes cerebellar and whole-brain activation clusters for the social contrast. Healthy-control results are reported clearly and are generalizable to the healthy adult population. Although resting-state and seed-based analyses are also included, the paper contains the required task activation whole-brain maps (not ROI-only, connectivity-only, nor between-group-only contrasts). Therefore it meets all inclusion criteria and violates none of the exclusion criteria for the review.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-33' name='judgment-33' value='agree'>
<label for='agree-33'>Agree</label>
<input type='radio' id='disagree-33' name='judgment-33' value='disagree'>
<label for='disagree-33'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-33' name='comment-33' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-34'>
<h2>34. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22490923/' target='_blank'>22490923</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social cognition (impression formation/updating) in healthy adult participants (N=24, ages 18–45). The paper reports group-level, whole-brain univariate task-evoked analyses (e.g., interaction of trial number and evaluative consistency; L2>F3 contrasts for inconsistent targets) with thresholding and cluster results presented in tables and figures. Results are not limited to ROI-only or connectivity/resting-state analyses; whole-brain voxelwise maps and coordinates are reported and described. All inclusion criteria are met and no exclusion criteria apply.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-34' name='judgment-34' value='agree'>
<label for='agree-34'>Agree</label>
<input type='radio' id='disagree-34' name='judgment-34' value='disagree'>
<label for='disagree-34'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-34' name='comment-34' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-35'>
<h2>35. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/21981758/' target='_blank'>21981758</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social processing (social exclusion using the Cyberball task) in healthy adults (final sample n=20, mean age ~25, within 17–65). The paper reports univariate, whole-brain task-evoked contrasts (e.g., social exclusion > fair play; same-gender vs other-gender exclusion) with cluster correction, tables of activation (coordinates) and figures, and random-effects group analyses generalizable to healthy adults. Although ROI analyses are also reported, whole-brain voxelwise results are clearly presented. No exclusion criteria are met (not ROI-only, not connectivity-only, not a review, and participants are within the required age range). Therefore the study meets all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-35' name='judgment-35' value='agree'>
<label for='agree-35'>Agree</label>
<input type='radio' id='disagree-35' name='judgment-35' value='disagree'>
<label for='disagree-35'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-35' name='comment-35' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-36'>
<h2>36. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/20350187/' target='_blank'>20350187</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study of social cognition (mentalizing/attribution of agency) in healthy adult participants. The sample comprises healthy heterosexual male adults (final n=21, age range within 17–65). The paper reports group-level, whole-brain voxelwise task contrasts (deviant-cell contrast: sexualized female vs other targets) with voxelwise thresholding (p<.001) and cluster correction (AlphaSim), tables/figures of activations, and correlations between hostile sexism and whole-brain activity—fulfilling the requirement for univariate whole-brain task-evoked maps. The task probes perception/understanding of others, matching the review’s social-related constructs. Although the sample is restricted to heterosexual male undergraduates (a demographic limitation), it nonetheless meets the inclusion criteria of healthy adult whole-brain fMRI task data, so the study should be INCLUDED.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-36' name='judgment-36' value='agree'>
<label for='agree-36'>Agree</label>
<input type='radio' id='disagree-36' name='judgment-36' value='disagree'>
<label for='disagree-36'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-36' name='comment-36' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-37'>
<h2>37. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/26514295/' target='_blank'>26514295</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI hyperscanning study in healthy adult participants (mean ages ~21–23, within 17–65). Tasks are social in nature (mutual gaze, initiating/responding joint attention), fulfilling the social-processing objective. The paper reports group-level, whole-brain voxelwise results: inter-individual neural synchronization maps (cluster-level FWE-corrected whole-brain results in Tables 2–4 and Figures 3), task-evoked activation maps for eye-blink-related responses (Table 5, Fig. 5), and an EBA localizer (Table 1) — all univariate whole-brain findings generalizable to healthy adults. Analyses are not limited to ROI-only or solely connectivity/seed-based/resting-state approaches. No exclusion criteria apply. Therefore the study meets all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-37' name='judgment-37' value='agree'>
<label for='agree-37'>Agree</label>
<input type='radio' id='disagree-37' name='judgment-37' value='disagree'>
<label for='disagree-37'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-37' name='comment-37' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-38'>
<h2>38. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/30852994/' target='_blank'>30852994</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Meets all inclusion criteria: (1) Task fMRI of social processing — live bidirectional conversations (human–human vs human–robot) probing social communication, mentalizing and social motivation. (2) Healthy adult sample reported separately — 21 neurotypical participants (mean age 25.8, within 17–65). (3) Group-level, univariate whole-brain task contrasts are reported (main effects and HHI vs HRI contrasts), with cluster-level FDR-corrected inference; group maps are available on NeuroVault and raw data on OpenNeuro. (4) Not ROI-only; not limited to connectivity or resting-state analyses. No exclusion criteria are violated. Therefore this study is appropriate for inclusion in the meta-analysis of fMRI studies of social processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-38' name='judgment-38' value='agree'>
<label for='agree-38'>Agree</label>
<input type='radio' id='disagree-38' name='judgment-38' value='disagree'>
<label for='disagree-38'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-38' name='comment-38' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-39'>
<h2>39. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22905026/' target='_blank'>22905026</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Meets all inclusion criteria: (1) Uses task-based fMRI probing social-related processing (naturalistic audiovisual clips targeting eight social features such as faces, social interaction, emotion, speech). (2) Sample consists of healthy adult participants (N=19; ages 21–34). (3) Reports group-level, whole-brain univariate task analyses (first- and second-level GLM, one-sample t-tests across subjects) with voxelwise statistics (FDR-corrected p<0.05), figures and coordinate tables. (4) Not limited to ROI-only, not resting-state or connectivity-only. No exclusion criteria are violated. Therefore this study should be INCLUDED in the meta-analysis of healthy adult fMRI social processing.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-39' name='judgment-39' value='agree'>
<label for='agree-39'>Agree</label>
<input type='radio' id='disagree-39' name='judgment-39' value='disagree'>
<label for='disagree-39'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-39' name='comment-39' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-40'>
<h2>40. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/28540647/' target='_blank'>28540647</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study of social processing in healthy adults. The neuroimaging cohort included healthy participants aged 18–53 (n=62 after exclusions), within the 17–65 range. The authors conducted whole-brain, group-level univariate GLM analyses (random-effects), reported voxelwise results (thresholded p<.001, permutation correction), and described specific whole-brain activations (e.g., dACC, bilateral dlPFC, parietal cortex, insula). Statistical maps are available on NeuroVault. The task explicitly probes social influence/understanding of others in a decision-making paradigm. No exclusion criteria (e.g., only ROI, only connectivity, non-empirical) apply. Therefore the paper meets all inclusion requirements for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.94</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-40' name='judgment-40' value='agree'>
<label for='agree-40'>Agree</label>
<input type='radio' id='disagree-40' name='judgment-40' value='disagree'>
<label for='disagree-40'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-40' name='comment-40' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-41'>
<h2>41. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/30949039/' target='_blank'>30949039</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study using a socioemotional Face Processing Task (fearful vs neutral faces) in a sample of healthy adults (N=49, ages 18–33). The paper reports group-level, whole-brain univariate task activation results (F> N and N>F contrasts) with FWE-corrected voxelwise analyses (TFCE, 5,000 permutations) and provides coordinates and figures for these effects. Although ROI and FC analyses are included, whole-brain task-evoked maps for the healthy/control sample are clearly reported and generalizable to healthy adults. No exclusion criteria apply (not ROI-only, not resting-state-only, and participants are within the 17–65 age range). Therefore the study meets all inclusion criteria for the review.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-41' name='judgment-41' value='agree'>
<label for='agree-41'>Agree</label>
<input type='radio' id='disagree-41' name='judgment-41' value='disagree'>
<label for='disagree-41'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-41' name='comment-41' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-42'>
<h2>42. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/27579051/' target='_blank'>27579051</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study reports task-based fMRI of social-related processing (Face Matching Task with fearful and neutral faces — perception/understanding of others). The sample comprises healthy adults (n=10, mean age 25), within the 17–65 range. The paper includes group-level, univariate whole-brain GLM analyses (first-level contrasts and second-level one-sample t-tests for contrasts such as fear>neutral and neutral+fear>control) with reported thresholding and results presented (Table S2 and Figures S1–S3), satisfying the requirement for a whole-brain task-evoked statistical map from the healthy group. Although the paper also presents ICA (connectivity) analyses, this does not conflict with inclusion since univariate whole-brain results are provided. Therefore all inclusion criteria are met and no exclusion criteria are triggered.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-42' name='judgment-42' value='agree'>
<label for='agree-42'>Agree</label>
<input type='radio' id='disagree-42' name='judgment-42' value='disagree'>
<label for='disagree-42'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-42' name='comment-42' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-43'>
<h2>43. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/30085122/' target='_blank'>30085122</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Oxytocin Facilitates Approach Behavior to Positive Social Stimuli via Decreasing Anterior Insula Activity</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Int J Neuropsychopharmacol</p>
<p><strong>Publication Year:</strong> 2018</p>
<p><strong>DOI:</strong> 10.1093/ijnp/pyy068</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6165955/' target='_blank'>6165955</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social-related processing using a task contrasting social vs nonsocial positive and negative scenes (approach–avoidance), meeting the review’s construct (affiliation/social perception). Sample comprises healthy adult participants (final N=76, males, mean age ~21) within the 17–65 range. The paper reports group-level univariate task contrasts and second-level analyses; although many a priori ROI/SVC analyses are reported, the Methods state and Results reference additional whole-brain exploratory analyses (thresholds and reporting of clusters), indicating availability of whole-brain task-evoked group maps (reported in main text/supplement). Therefore it meets the requirement for whole-brain, group-level univariate task activation in healthy adults. No exclusion criteria (ROI-only, resting-state only, non-empirical, or out-of-range sample) apply.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
## Background 
  
The neuropeptide oxytocin can extensively modulate human social behavior and affective processing, and its effects can be interpreted in terms of mediating approach-avoidance motivational processes. However, little is known about how oxytocin mediates approach-avoidance behavior and particularly the underlying neural mechanisms. 


## Methods 
  
In a randomized, double-blind, between-subject design, the present pharmaco-fMRI study used an approach-avoidance paradigm to investigate oxytocin’s effects on approach-avoidance behavior and associated neural mechanisms. 


## Results 
  
Results revealed that oxytocin generally decreased activity in the right striatum irrespective of response (approach/avoidance) and social context, suggesting an inhibitory effect on motivational representation during both appetitive approach and aversive avoidance. Importantly, while on the behavioral level oxytocin selectively enhanced accuracy when approaching social positive stimuli, on the neural level it decreased left ventral and right dorsal anterior insula activity in response to social vs nonsocial positive stimuli compared with the placebo treatment. The left ventral anterior insula activity was negatively correlated with the corresponding accuracy difference scores in the oxytocin but not in the placebo group. 


## Conclusion 
  
Given the role of the ventral anterior insula in emotional processing and the dorsal anterior insula in salience processing, the oxytocin-induced suppression of activity in these regions may indicate that oxytocin is acting to reduce interference from hyper-activity in core regions of the emotional and salience networks when approaching salient positive social stimuli and thereby to promote social interaction. Thus, oxytocin may be of potential therapeutic benefit for psychiatric disorders exhibiting avoidance of social stimuli. 

 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (26657 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'>  
## Significance Statement 
  
The hypothalamic neuropeptide oxytocin (OT) plays an important role in modulating human social behavior. These effects can be interpreted in terms of OT’s actions on basal approach-avoidance (AA) motivational processes, as proposed by the general AA hypothesis of OT (GAAO). However, few studies have evaluated the proposed OT effects on AA behavior and particularly the underlying neural mechanisms. Using neuroimaging combined with intranasal OT administration, the present study revealed that while OT selectively enhanced behavioral accuracy when approaching social positive stimuli, it decreased left ventral and right dorsal anterior insula (AI) activity in response to social vs nonsocial positive stimuli compared to the PLC treatment, with the left ventral AI activity being negatively correlated with the corresponding behavioral accuracy only in the OT group. These findings provide the first confirmatory evidence for the GAAO by demonstrating that OT facilitates human approach behavior to social positive stimuli via inhibiting AI activity. 

 
## Introduction 
  
Across species, the hypothalamic neuropeptide oxytocin (OT) regulates social behavior, particularly bonding and maternal care ( ;  ). During the last 2 decades, the number of studies examining oxytocinergic regulation of human behavior via intranasal administration of OT has steadily increased. While OT can facilitate appetitive approach behaviors, such as interpersonal trust and generosity ( ;  ), pair bonding and maternal behavior ( ;  ) and emotional empathy and face recognition ( ;  ), it can also promote aversive avoidance behavior by increasing envy and schadenfreude ( ), ethnocentrism (e.g., trust and empathy;  ;  ), group-serving dishonesty ( ), and noncooperation ( ;  ). 

To account for these complex and somewhat contradictory findings,   proposed in their general approach-avoidance (AA) hypothesis of OT (GAAO) that the broad effects of OT on human behavior are mediated by its actions on basal AA motivational processes. More specifically, within this extended overarching framework, OT’s complex behavioral effects are considered to be rooted in its modulation of the salience of personally relevant and emotionally evocative stimuli not necessarily restricted to social contexts ( ; cf.   for the social-approach/withdrawal hypothesis and   for the social salience hypothesis). However, surprisingly few studies have experimentally evaluated the proposed effects of OT on AA behavior and particularly the underlying neural mechanisms. 

In a previous study that examined the effects of intranasal OT on human AA behavior, OT was found to accelerate both approach and avoidance behavior towards emotionally negative stimuli such as disgusted faces ( ;  ). Using similar paradigms, OT also facilitated approach towards angry faces with a direct gaze ( ). Furthermore, in the context of pair bonding, OT was found to modulate interpersonal space by decreasing the preferred distance men in a romantic relationship kept between themselves and an unknown attractive woman ( ). However, these studies predominantly used emotional faces to investigate OT’s actions on AA behavior and were thus unable to determine whether observed effects were driven by its well-established actions on increased attention and attraction to faces per se ( ;  ;  ;  ;  ). Moreover, the neural substrates mediating OT’s effects on AA behavior also remain unclear, with initial evidence showing decreased amygdala activity only when approaching angry faces ( ). Since this latter study also used facial stimuli, this again precludes any definitive conclusion as to whether findings simply reflect the well-documented anxiolytic effect of OT in decreasing amygdala responses to threatening facial expressions ( ;  ) rather than specific effects on AA behavior. 

The present study has therefore employed a face-independent AA task combined with fMRI to investigate OT’s specific effects on AA behavior and the underlying neural mechanisms involved. Thus, social and nonsocial scenes rather than facial experimental stimuli were used to determine specific effects of OT on AA behavior per se to avoid its potential confounding effects on face processing. Participants were instructed to approach positive (appetitive approach) and avoid negative (aversive avoidance) stimuli during the AA task. In accordance with the GAAO that OT modulates salience of cues that are personally relevant and emotionally evocative but not necessarily specific to social contexts ( ), we hypothesized that OT would (1) facilitate approach behavior to positive stimuli, particularly more emotionally evocative social ones, and associated activity in the motivational and emotional salience core regions such as the striatum and anterior insula, and (2) decrease avoidance behavior via attenuating amygdala reactivity to negative stimuli, particularly more emotionally evocative negative social ones. 


## Methods And Materials 
  
### Participants and Treatment 
  
A total of 83 healthy male students (mean age=21.35 years, SD=2.48) participated in a randomized, double-blind, between-subject experiment and were randomly assigned to receive either intranasal OT (40 IU; Oxytocin Spray, Sichuan Meike Pharmacy Co. Ltd, China) or placebo (PLC; same ingredients other than OT, i.e., sodium chloride and glycerin). To control for potential confounding effects from personality traits or mood states, subjects completed Chinese versions of validated psychometric questionnaires before treatment, including the Positive and Negative Affect Schedule ( ), Autism Spectrum Quotient ( ), Empathy Quotient ( ), and NEO 5-factor inventory ( ). To further control for a potentially confounding influence of altered mood states, subjects were asked to complete the Positive and Negative Affect Schedule 3 times: after they first arrived (pretreatment), before MRI scanning (posttreatment), and finally after scanning (post-scan). Subjects received OT/PLC treatment in accordance with a standardized protocol ( ), and fMRI acquisition started 45 minutes after treatment. A total of 7 subjects were excluded due to technical issues during data acquisition (4 subjects) or excessive head movement (3 subjects). Thus, 39 subjects in the OT group and 37 subjects in the PLC group were included in the final analysis. In postscan interviews, subjects were unable to identify better than chance whether they had received OT or PLC (χ =0.21,   P  =.646). Written informed consent was obtained from all subjects before study inclusion. All procedures were in accordance with the latest version of the Declaration of Helsinki and approved by the ethical committee of University of Electronic Science and Technology of China. 


### The AA Task 
  
In a revised AA task ( ), participants were instructed to make approach responses to positive social or nonsocial stimuli (e.g., happy friends meeting or beautiful landscapes) and avoidance responses to social or nonsocial negative stimuli (e.g., victims or environmental pollution). In a prestudy, we selected 620 pictures mostly from the International Affective Picture System ( ) and additionally from the Internet that were rated in terms of valence and arousal (9-point Likert scale) by an independent sample of 34 healthy volunteers (18 males). Based on this data, a total of 112 stimuli (28 pictures per category, positive vs negative and social vs nonsocial) were selected: social positive (valence: mean±SD=2.36±0.27; arousal: 6.27±0.35), social negative (valence: 2.47±0.26; arousal: 6.65±0.46), nonsocial positive (valence: 1.68±0.39; arousal: 6.25±0.42), and nonsocial negative (valence: 1.87±0.55; arousal: 6.10±0.70). Note that the valence rating scores were transformed to the distance from the neutral midpoint of the 9-point scale. Each picture was presented for 3 seconds at a 624- × 468-pixel resolution followed by a jittered inter-stimulus interval of 2 to 6 seconds. Subjects were instructed to pull the positive stimuli towards their body by pressing the “down” key and push the negative stimuli away from their body by pressing the “up” key successively via a response pad during the 3-second presentation. To realistically convey approach and avoidance of the stimuli for the subjects, each pulling-associated button press would enlarge the picture by 100×75 pixels while each pushing response would decrease the size of the picture by 100×75 pixels. All subjects preformed 10 practice trials before entering the scanner and were instructed to respond as fast and accurately as possible during the experiment. 


### Image Acquisition and Data Analysis 
  
Images were collected using a 3 Tesla, GE Discovery MR750 system (General Electric Medical System, Milwaukee, WI). During each fMRI scan, a time series of volumes was acquired using a T2*-weighted echo-planar pulse sequence (repetition time: 2000 ms; echo time: 30 ms; number of slices: 39; slice thickness: 4 mm; gap: 1 mm; field of view: 240×240 mm; resolution: 64×64; flip angle: 90°). To control for any anatomic abnormalities and increase normalization accuracy during preprocessing, additional T1-weighted images were acquired obliquely with a 3-dimensional spoiled gradient echo pulse sequence (repetition time: 6 milliseconds; echo time: 2 milliseconds; flip angle: 9°; field of view: 256×256 mm; acquisition matrix: 256×256; number of slices: 156; slice thickness: 1 mm). 

Images were processed using SPM8 (Wellcome Department of Cognitive Neurology, London;   https://www.fil.ion.ucl.ac.uk/spm/software/spm8/  ) ( ). The first 5 functional images were deleted to achieve magnet-steady images, and the remaining images were realigned to correct for head movement based on a 6-parameter rigid body algorithm. After co-registering the mean functional image and the T1 image, the T1 image was segmented to determine the parameters for normalizing the functional images to Montreal Neurological Institute (MNI) space. These normalized images were finally spatially smoothed using a Gaussian kernel (8 mm full-width at half maximum). 

The first-level design matrix included 4 condition-specific regressors (social positive/negative, nonsocial positive/negative) convolved with the canonical hemodynamic response function and the 6 head-motion parameters as nuisance regressors. Contrast images for each stimulus condition, all positive and all negative were created separately. On the second level, group differences were analyzed using 2-sample   t   tests. Interactions were tested using an ANOVA model implemented in a flexible factorial design. Based on our region-specific hypotheses, the analysis focused on core regions involved in salience processing ( ;  ) and appetitive/approach (social/nonsocial reward) and withdrawal/avoidance (punishment/threat) motivational processes ( ;  ,  ;  ;  ;  ), that is, the amygdala, the AI, and the striatum. Importantly, these regions strongly overlap with the network mediating the social cognitive and affective effects of intranasal OT ( ;  ;  ;  ;  ). Regions-of-interest (ROIs) were anatomically defined using the Automated Anatomic Labeling atlas ( ). Within the unilateral a priori ROIs, a threshold of   P  <.05 family-wise error (FWE) peak-level correction was set for multiple comparisons using small volume correction (SVC). Parameter estimates used for plotting and brain behavior associations analysis were extracted for each subject from a 6-mm sphere centered on the peak voxel within corresponding ROIs. For additional exploratory whole-brain analyses, a threshold of   P  <.05 corrected at peak level was used and only clusters >10 voxels are reported. 



## Results 
  
### Questionnaires 
  
Two-sample   t   tests on questionnaires measuring mood, autistic traits, empathy, and personality traits revealed no significant differences between the treatment groups (Ps>.136;  ). 


### Behavioral Results 
  
For response times, a repeated-measures ANOVA was performed with social context (social vs nonsocial) and response type (approach vs avoidance) as within-subject factors and treatment (OT vs PLC) as between-subject factor. This revealed a significant main effect of response type (F(1, 74)=250.46,   P  <.001), with subjects being significantly faster to approach positive than to avoid negative stimuli (1617.33±176.84 vs 1776.95±184.28). The interaction between social context and response was also significant (F(1, 74)=19.04,   P  <.001), with posthoc tests reavealing that subjects were faster to approach social compared with nonsocial positive stimuli (1600.86±172.73 vs 1633.79±180.49) but slower to avoid social than nonsocial negative stimuli (1784.72±181.76 vs 1769.18±187.65). There were no other significant effects (  P  >.106). 

In terms of response accuracy (RA), there was a significant main effect of social context (F(1, 74)=15.75,   P  <.001), with a higher accuracy for social compared with nonsocial stimuli (95.4%±5.7% vs 93.7%±5.4%). The main effect of response type was also significant (F(1, 74)=109.59,   P  <.001), with a higher accuracy for approaching positive than avoiding negative stimuli (97.5%±3.4% vs 91.7%±5.8%). While the interaction between social context, response type, and treatment was not significant (F(1, 74)=0.76,   P  =.385), an exploratory pairwise comparison revealed a significantly higher RA only for social (  P  =.031) but not nonsocial positive stimuli (  P  =.568) in the OT relative to the PLC group ( ). The interaction between social context and response type was marginally significant (F(1, 74)=3.18,   P  =.079), suggesting a trend of higher accuracy to social vs nonsocial stimuli for positive (  P  <.001; 98.8%±2.1% vs 96.2%±4.0%) but not negative stimuli (  P  =.280; 92.1%±6.1% vs 91.3%±5.6%). There were no other significant effects (  P  >.361). Given the slightly higher valence scores for social compared with nonsocial positive stimuli, to clarify whether the valence difference would confound the significant OT’s effects, we further conducted a correlation analysis between valence scores for individual pictures by independent raters and RA for social and nonsocial positive stimuli in the experimental subjects and found no significant associations either for social (Pearson r=0.061, df=28,   P  =.759) or nonsocial positive stimuli (Pearson r=- 0.044, df=28,   P  =.823). Thus, the magnitude of the positive valence score for the individual pictures did not influence response accuracy. 
  
Response accuracy in response to each condition in the oxytocin and placebo groups. Error bars show standard errors. 
  

### fMRI Results 
  
We first examined unspecific effects of treatment (OT vs PLC) independent of response type and social context using a 2-sample   t   test. This revealed decreased right striatum activity (MNI=22, 2, 8, t=4.05,   P  =.025 SVC, voxels=48;  ) in the OT compared with the PLC group (OT  <PLC  ). 
  
(A) Decreased right striatum activity in the oxytocin (OT) compared with the placebo (PLC) group. (B) Decreased activity in the right striatum and the left dorsal anterior insula (AI) in the OT compared with the PLC group during appetitive approach. (C) Decreased activity in the right striatum and the right amygdala in the OT compared with the PLC group during aversive avoidance. Statistic maps were displayed with a   P  <.005 uncorrected threshold. Error bars show standard errors. 
  
Next, we examined treatment effects and interactions between treatment and social context on appetitive approach and aversive avoidance separately. For appetitive approach, decreased activity in the right striatum (MNI=20, 2, 6, t=3.96,   P  =.031 SVC, voxels=29) and the left dorsal AI (MNI=-38, 12, 6, t=3.52,   P  =.040 SVC, voxels=11;  ) was found in the OT compared with the PLC group (OT  <PLC  ). Examining the interaction between treatment and social context (OT  <PLC  ) during approach behavior revealed significant interaction effects in the left ventral AI (MNI=-42, 6, -6, t=3.57,   P  =.022 SVC, voxels=14;  ) and the right dorsal AI (MNI=48, 12, 2, t=3.40,   P  =.036 SVC, voxels=7;  ), suggesting that OT decreased activity in these regions during approach of social relative to nonsocial positive stimuli. 
  
Oxytocin (OT) decreased the left ventral anterior insula (AI) (A) and the right dorsal AI (B) activity in response to social relative to nonsocial positive stimuli (OT  <placebo [PLC]  ). Statistic maps were displayed with a   P  <.005 uncorrected threshold. Error bars show standard errors. 
  
With respect to aversive avoidance, OT decreased activity in the right striatum (MNI=24, 2, 10, t=4.31,   P  =.011 SVC, voxels=58) and the right amygdala (MNI=28, -4, -18, t=3.34,   P  =.025 SVC, voxels=2;  ) irrespective of social context (OT  <PLC  ). Examination of interaction effects between treatment and social context during avoidance behavior (OT  <PLC  ) revealed no significant effects (  P  <.05 SVC). There were also no other significant effects in the a priori ROIs (  P  <.05 SVC). For completeness, additional effects beyond the a priori ROIs on the whole-brain level are reported in   (  P  <.05). 


### Brain Behavior Associations 
  
Correlation analyses between extracted parameter estimates from the left ventral and the right dorsal AI (social positive>nonsocial positive) and RA difference scores (social positive − nonsocial positive) were conducted separately to explore associations between OT-induced modulation on neural responses and corresponding behavioral indices. Results showed a significant negative correlation between activity in the left ventral AI (MNI=-42, 6, -6) and RA difference scores in the OT (Pearson r=- 0.346, df=39,   P  =.031;  ) but not in the PLC group (Pearson r=0.039, df=37;   P  =.818). The correlation difference between groups was tested using the Fisher z-transformation test and revealed a marginally significant difference between the OT and PLC groups (Fishers z-score=-1.672,   P  =.094). 



## Discussion 
  
The present study investigated OT’s effects on AA behavior and corresponding neural mechanisms using emotional scenes and specifically examined whether the effects generalize across social and nonsocial contexts. On the neural level, a significant main effect of treatment was observed in the right striatum, with OT generally decreasing activity in this region irrespective of response type and social context. Furthermore, separate examination of appetitive approach and aversive avoidance revealed that while OT specifically decreased the left dorsal AI activity during approaching positive stimuli, it decreased right amygdala activity during avoidance of negative stimuli. Additionally, exploring the role of social context revealed evidence for a selective enhancement effect of OT on RA when approaching social relative to nonsocial positive stimuli. This behavioral effect was accompanied by decreased left ventral and right dorsal AI activity in response to social vs nonsocial positive stimuli in the OT compared with the PLC group, with the relative difference in left ventral AI activity and RA for social vs nonsocial positive stimuli exhibiting a negative association following OT. By contrast, during aversive avoidance, no evidence for the social specificity of OT was observed. These findings provide support for the GAAO by showing that OT modulates activation of motivational and emotional salience core regions during both approach to positive and avoidance to negative stimuli across social and nonsocial contexts and that OT specifically facilitates approach behavior to more personally relevant and emotionally evocative stimuli, namely positive social stimuli, via inhibiting AI activity. 

Examination of unspecific OT effects on AA behavior revealed significantly decreased activity in the right striatum following OT across both response type and social contexts. The striatum has been strongly involved in both approach (social/nonsocial reward) and avoidance (punishment/threat)-motivated behavior ( ;  ,  ;  ;  ). Thus, OT may inhibit motivational representation both during appetitive approach and aversive avoidance. Furthermore, OT additionally decreased left dorsal AI activity during approach to positive stimuli across social and nonsocial contexts. As a core hub of the salience network ( ;  ), the reduced dorsal AI activity may thus reflect an OT-evoked decrease in the salience of positive stimuli when subjects approached them. 

The observed inhibitory effects of OT on striatum and AI activity seem to conflict with both the proposal that it enhances the salience of social cues ( ) and some previous findings that OT-induced alterations on human social behavior are associated with increased activity in the striatum and AI ( ;  ;  ;  ). Given that OT effects on social behavior are often highly context and person dependent ( ), this inconsistency could be due to different paradigms and contexts used in these previous studies. In previous studies, subjects were asked to passively process certain stimuli, whereas the present study using an AA task required subjects to actively approach or avoid them. 

It is notable that OT also decreased activation of the left ventral and right dorsal AI during approaching social relative to nonsocial positive stimuli. Given the role of the ventral AI in emotional processing ( ;  ;  ) and the dorsal AI in salience processing ( ;  ), these attenuated AI activities may indicate a more robust inhibitory effect of OT on decreasing both the emotional and salience processing of social positive stimuli that are more personally relevant and emotionally evocative ( ). Consistent with previous observations that OT can enhance processing of positive facial emotion ( ;  ;  ;  ), the present study found evidence that OT may specifically facilitate RA during approaching social but not nonsocial positive stimuli. Thus, the oxytocinergic downregulation of AI activation may act to attenuate interference caused by hyperactivation of the AI when subjects approach external social positive stimuli, resulting in enhanced accuracy of social information processing and facilitation of social interaction. This assumption is further supported by the presence of a significant negative correlation between the left ventral AI activity and the RA difference between social and nonsocial positive stimuli following OT but not PLC administration. However, it should be noted that the difference in brain-behavior correlation between groups was only marginally significant, and thus inferences regarding this effect of OT need to be drawn with caution. 

Additionally, OT was found to decrease amygdala activity during avoidance responses to negative stimuli independent of social context. This finding is in line with the anxiolytic action of OT via inhibiting amygdala responses to threatening stimuli ( ;  ). Based on the GAAO ( ), the absence of a social-specific effect of OT on avoiding negative stimuli suggests that threatening social and nonsocial stimuli may be comparable in terms of personal relevance and emotional evocation, perhaps due to the high survival relevance of threating events during evolution ( ). 

Given that we found no significant personality and mood difference between OT and PLC groups, this argues against confounding effects of pretreatment between-group differences on the observed effects of OT. However, individual differences in personality traits have been shown to mediate approach and avoidance behavior, as proposed by the (revised) Reinforcement Sensitivity Theory ( ;  ). More specifically, previous studies have demonstrated associations between the functional organization of the salience network, particularly the AI, and its interactions with anxiety-related traits such as harm avoidance ( ;  ,  ). Thus, future studies should consider examining the role of individual differences in personality traits on AA behavior and their potential modulatory effects on the effects of OT in this domain. Moreover, within this context, the present findings may lend support for potential therapeutic benefits of OT for psychiatric disorders such as social anxiety and autism exhibiting altered approach/avoidance towards social stimuli ( ;  ;  ;  ). 

There are several limitations in the present study. Firstly, considering that organisms have primarily evolved mechanisms to approach stimuli associated with positive outcomes and to avoid those associated with aversive ones, we only asked subjects to approach positive and avoid negative stimuli. Effects of OT on approaching negative and avoiding positive stimuli thus remain to be determined. Secondly, we used only male subjects to avoid possible confounding effects from menstrual cycle; thus, the present conclusions are limited to males and sex differences remain to be explored. Thirdly, another potential limitation is that we cannot completely exclude the possibility of a complex interaction involving differences in social and nonsocial stimuli valence and OT effects on response accuracy during approach behavior. However, for positive valence stimuli, we found no association between individual picture valence and response accuracy for either social or nonsocial stimuli, suggesting that valence differences are unlikely to have had a major impact on our results. Finally, we do not know if the effects we observed with a 40-IU dose of OT may also be observed with lower doses. A previous study has revealed a dose-dependent effect of OT (12, 24, and 48 IU), with the 24-IU dose being most effective in inhibiting amygdala activity during negative emotional processing ( ). However, in 2 previous studies from our group, we reported evidence for comparable effects of 24- and 40-IU doses on both behavioral and neural changes in the context of empathy and self-processing in humans ( ;  ). 

In conclusion, the present study provides first evidence for the GAAO by demonstrating that while OT inhibits motivational representations both during appetitive approach and aversive avoidance, it facilitates human approach behavior to more general positive social stimuli via inhibiting AI activity. This inhibitory effect of OT may reduce interference from emotion-facilitated hyperactivation of core regions of the emotional and salience networks when approaching external social salient positive stimuli and consequently be of benefit in promoting social interaction. 


## Supplementary Materials 
  
Supplementary data are available at International Journal of Neuropsychopharmacology (IJNPPY) online. 

 </div>
</div>
</div>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-43' name='judgment-43' value='agree'>
<label for='agree-43'>Agree</label>
<input type='radio' id='disagree-43' name='judgment-43' value='disagree'>
<label for='disagree-43'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-43' name='comment-43' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-44'>
<h2>44. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/19199419/' target='_blank'>19199419</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social cognition using the Reading the Mind in the Eyes task (mental state decoding), a social-related construct (perception/understanding of others). Sample comprises healthy adult participants (14 right-handed white American and 14 right-handed native Japanese adults aged 18–27). The paper reports group-level, whole-brain univariate task contrasts (RME - gender baseline and same- vs other-culture contrasts) with tables of activated regions and coordinates (including family-wise corrected results), satisfying the requirement for whole-brain task-evoked maps generalizable to healthy adults. The study is not ROI-only, not connectivity- or resting-state-only, and reports healthy-group results separately. Therefore it meets all inclusion criteria and violates no exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-44' name='judgment-44' value='agree'>
<label for='agree-44'>Agree</label>
<input type='radio' id='disagree-44' name='judgment-44' value='disagree'>
<label for='disagree-44'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-44' name='comment-44' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-45'>
<h2>45. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/24144548/' target='_blank'>24144548</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study uses task-based fMRI of live verbal communication (social communication). Sample comprises 22 healthy adult right-handed women (mean age 27.2), within the 17–65 range. The paper reports group-level, whole-brain univariate voxelwise analyses (first-level regressors and second-level voxel-wise t-tests with cluster correction), with activation maps, figures and supplementary tables of coordinates. It is empirical fMRI data in healthy adults and does not rely solely on ROI, connectivity-only, or resting-state analyses. Therefore it meets all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-45' name='judgment-45' value='agree'>
<label for='agree-45'>Agree</label>
<input type='radio' id='disagree-45' name='judgment-45' value='disagree'>
<label for='disagree-45'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-45' name='comment-45' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-46'>
<h2>46. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/26048954/' target='_blank'>26048954</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> excluded</p>
<p><strong>Fulltext Reasoning:</strong> Although the study uses fMRI in healthy adult participants and examines social-related tasks (ToM, face/voice perception, biological motion, language), all group-level task analyses were explicitly restricted to a bilateral STS mask rather than reported as unmasked whole-brain voxelwise task activation maps. The paper therefore does not provide an unmasked, group-level whole-brain task-evoked statistical map for the healthy/control group (resting-state connectivity and masked/ROI-limited results do not satisfy the ‘whole-brain’ inclusion criterion). Excluded for failing the whole-brain evidence requirement.</p>
<p><strong>Fulltext Confidence:</strong> 0.85</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-46' name='judgment-46' value='agree'>
<label for='agree-46'>Agree</label>
<input type='radio' id='disagree-46' name='judgment-46' value='disagree'>
<label for='disagree-46'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-46' name='comment-46' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-47'>
<h2>47. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/25489093/' target='_blank'>25489093</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social communication/mutual understanding in healthy adults (54 right-handed male participants, ages 18–27). The task is explicitly social (creation and negotiation of shared meanings between Communicator and Addressee). The paper reports group-level, whole-brain univariate analyses (model-based whole-brain search for BOLD dynamics matching behavioral mutual understanding; random-effects analysis with cluster-level correction, reported regional findings including rSTG), not limited to ROI-only or connectivity-only results. Healthy adult results are reported separately and are generalizable (random-effects, whole-brain inference). Therefore all inclusion criteria are met and no exclusion criteria are triggered.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-47' name='judgment-47' value='agree'>
<label for='agree-47'>Agree</label>
<input type='radio' id='disagree-47' name='judgment-47' value='disagree'>
<label for='disagree-47'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-47' name='comment-47' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-48'>
<h2>48. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/19384602/' target='_blank'>19384602</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Audiovisual Non-Verbal Dynamic Faces Elicit Converging fMRI and ERP Responses</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Brain Topogr</p>
<p><strong>Publication Year:</strong> 2009</p>
<p><strong>DOI:</strong> 10.1007/s10548-009-0093-6</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/2707948/' target='_blank'>2707948</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study of social-related processing (integration of non-verbal vocalizations and facial movements — social communication/perception of others) in healthy adults (fMRI sample: 10 right-handed males, ages 24–37). The paper reports group-level, voxelwise univariate fMRI analyses (voxel-by-voxel t tests, percent signal change maps, corrected with AlphaSim) with group activation maps and difference maps (AV, VIS, AUD vs rest and contrasts), presented in figures/tables. Whole-brain voxelwise results are clearly reported for the healthy group (even though slice coverage emphasized temporal cortex), and healthy adult results are reported separately. No exclusion criteria apply (not ROI-only, not connectivity-only, not between-group-only). Therefore it meets all inclusion criteria for the review.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
In an everyday social interaction we automatically integrate another’s facial movements and vocalizations, be they linguistic or otherwise. This requires audiovisual integration of a continual barrage of sensory input—a phenomenon previously well-studied with human audiovisual speech, but not with non-verbal vocalizations. Using both fMRI and ERPs, we assessed neural activity to viewing and listening to an animated female face producing non-verbal, human vocalizations (i.e. coughing, sneezing) under audio-only (AUD), visual-only (VIS) and audiovisual (AV) stimulus conditions, alternating with Rest (R). Underadditive effects occurred in regions dominant for sensory processing, which showed AV activation greater than the dominant modality alone. Right posterior temporal and parietal regions showed an AV maximum in which AV activation was greater than either modality alone, but not greater than the sum of the unisensory conditions. Other frontal and parietal regions showed Common-activation in which AV activation was the same as one or both unisensory conditions. ERP data showed an early superadditive effect (AV > AUD + VIS, no rest), mid-range underadditive effects for auditory N140 and face-sensitive N170, and late AV maximum and common-activation effects. Based on convergence between fMRI and ERP data, we propose a mechanism where a multisensory stimulus may be signaled or facilitated as early as 60 ms and facilitated in sensory-specific regions by increasing processing speed (at N170) and efficiency (decreasing amplitude in auditory and face-sensitive cortical activation and ERPs). Finally, higher-order processes are also altered, but in a more complex fashion. 

## Electronic supplementary material 
  
The online version of this article (doi:10.1007/s10548-009-0093-6) contains supplementary material, which is available to authorized users. 

 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (41009 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Everyday social interactions involve the integration of auditory and visual information from speech and non-verbal social cues. These latter cues are often underemphasized in humans, as most attention tends to focus on the spoken word (Campbell et al.  ; Capek et al.  ; Frith and Frith  ; Kawashima et al.  ; Macaluso et al.  ; MacSweeney et al.  ). Humans generate many non-verbal vocalizations that are accompanied by readily identifiable stereotypical facial gestures (Howell  ). Non-verbal vocalizations likely engage higher-order processing, and can be overlooked, misused, or misinterpreted by those with social cognition disorders (Golarai et al.  ; Luyster et al.  ; Sarfati et al.  ; Troisi et al.  ). Non-verbal vocalizations can be communicative as one may purposely vocalize or exaggerate non-verbal cues to send a message, such as burp to signal the deliciousness of a meal, or one may purposely suppress a sign or yawn to conceal dissatisfaction or boredom. Social and other advantages may thus come from the ability to interpret information about the mental, emotional, or homeostatic state of individuals as conveyed through multisensory non-verbal cues. This is supported by studies that show greater activation to human non-verbal stimuli versus other non-human categories in multiple regions including STS, frontal parietal regions, and insula (Fecteau et al.  ; Lewis et al.  ). 

In a normal context, the accurate interpretation of socially related non-verbal information requires appropriate integration of multisensory input, usually visual and auditory information, which can change based on incoming information quality. In a noisy situation like a crowded bar, one observes lip and face movements more than in a quiet setting, as the visual information can effectively amplify the audio by up to 11 dB (MacLeod and Summerfield  ). Behavioral studies of both speech and non-speech stimuli indicate that multiple (congruent) stimulus modalities lead to improved processing, with both shorter reaction times and increased accuracy compared to either modality alone (Grant and Walden  ; Miller  ; Sumby and Pollack  ). 

These behavioral advantages for multisensory stimuli manifest as differences in timing, amount and type of brain activity compared to unisensory stimuli. However, studies have revealed conflicting results including both facilitation, in the form of faster and   decreased   brain responses (for fMRI Martuzzi et al.  ; Wright et al.  ; for ERPs Besle et al.  ; van Wassenhove et al.  ), and enhancement, or   increased   activation, for multisensory versus unisensory stimuli (Hubbard et al.  ; Kayser et al.  ). The reasons for these differences in multisensory effects are not understood, although some studies suggest that they may be related to factors such as congruency (Puce et al.  ; Saint-Amour et al.  ), whether one modality predicts the other (Ghazanfar et al.  ; Stekelenburg and Vroomen  ), or neuronal population properties (Laurienti et al.  ; Stevenson et al.  ). Even more complex results have been seen for higher-order regions, with effects (in speech-related studies) seen in posterior superior temporal sulcus (pSTS), inferior parietal lobule (IPL), and inferior frontal cortex (IFC) (Calvert et al.  ; Kawashima et al.  ). In the current study we were particularly interested in multisensory effects in pSTS due to its postulated role in social related processes (Redcay  ), and links to different visual, auditory, and motor processes (Beauchamp et al.  ). 

To investigate multisensory effects related to human non-verbal vocalizations and accompanying facial movements, we studied neural responses elicited to an animated synthetic female face producing various non-verbal vocalizations (i.e. coughing, yawning), using both functional magnetic resonance imaging (fMRI) and event-related potentials (ERPs). We presented stimuli under three conditions. In the audiovisual (AV) condition participants saw the animated face and heard congruent human vocalizations. In the visual (VIS) condition, only the animated face was seen, whereas in the auditory (AUD) condition only the vocalizations were heard. Randomized blocked presentations of AV, VIS and AUD conditions were alternated with rest (R). Two participant groups (  n   = 10 for fMRI,   n   = 13 for ERPs) responded to infrequent unisensory targets (animated face blinking, or uttering “mmm” without a visual change to the face). Our hypothesis predicted that sensory-specific regions specialized for a given unisensory condition, would show facilitated processing (faster times to peak and reduced amplitudes) in the presence of a multisensory stimulus. Specifically, for the fMRI experiment, we predicted a reduced BOLD signal for the AV versus either unimodal condition in sensory regions. For the ERP experiment, we predicted reduced amplitudes and faster latencies for early ERP components. In addition, we predicted that higher-order regions, especially right pSTS, would show greater AV activation (versus unisensory conditions) due to specialization in multisensory and/or social processes. 


## Materials and Methods 
  
### Participants 
  
For the fMRI study 10 right-handed healthy males participated (ages: 24–37 years, mean 28 years). For the ERP study, there were 13 right-handed participants (18 originally collected, 5 excluded, for the 13 included participants: 7 males, ages: 19–43 years, mean 29 years). All participants had either normal or corrected-to-normal vision and gave informed consent in a study approved by the Institutional Review Board for the Protection of Human Participants at West Virginia University. 


### Stimuli and Task 
  
Participants viewed 4 × 4 degree videos of a synthetic female face producing facial movements and vocalizations. Stimuli were seven non-speech vocalizations with accompanying face movements consisting of a cough, sneeze, burp, yawn, laugh, sigh and whistle. Two infrequently presented unisensory target stimuli, a blink (visual) and an uttered ‘mmm’ (auditory), made participants focus on visual and auditory sensory input equally. In the Audiovisual condition, there was a 33 ms (or 1 video frame) delay between the peak movement (i.e. fully opened mouth) and sound. Animations were based on filmed real life movements associated with the seven non-verbal vocalizations of three different actors. 

Stimulus type was pseudorandomly ordered within 20 s stimulus blocks consisting of 10 trials each of combined Audiovisual stimulation (AV), Auditory stimulation only (AUD), and Visual stimulation only (VIS) (Fig.  ). In the AV participants saw the face making the facial movements and heard the associated non-speech vocalizations. In VIS, participants observed the face making movements without hearing the vocalizations. In AUD, participants viewed a neutral colored plain background (RGB = 140, 132, 127) and heard the vocalizations. The absence of the face for the AUD condition prevented an ‘incongruent’ stimulus (face still but vocalization present), but made an event-related design difficult due to onset effects. Visual motion duration and sound duration was 600 and 567 ms respectively, for all non-target stimulus types. Participants maintained their gaze on an ever-present green fixation cross and pressed a single response button when either of one of the two specified unisensory targets were seen or heard. Behavioral responses were monitored to ensure attentional alertness. Minor variations in timing occurred for the fMRI versus ERP paradigms.   
Example of a stimulus still frame depicted at the middle of an animation.   a   In the AV condition, the face is present and the non-verbal vocalization accompanies the visual stimulus. Here a yawn is depicted and the open mouth and narrowing eyes can be clearly seen.   b   In the VIS condition only the moving face is present.   c   In the AUD condition only the vocalizations are heard. For all conditions a green fixation cross was located in same position on the screen throughout scans (between the eyes when the face present in the AV and VIS conditions) 
  


### Data Acquisition 
  
#### Functional MRI Study 
  
Data were acquired on a 3 Tesla GE Horizon LX MRI scanner and quadrature birdcage headcoil. We used a 14 slice split-sagittal acquisition (Puce et al.  ), where 7 sagittal slices (3 mm thickness + 1 mm gap) were taken in each hemisphere to maximally visualize the cortex of the STS and STG (see Supplementary Fig.  ). A series of 125 gradient echo echoplanar volumes were acquired over each of the three, 4 min 10 s stimulation periods (after before and after rest period removal, total = 375 volumes) using the following parameters: TE = 35, TR = 2000, α = 70°, NEX = 1, BW = 125, FOV = 24 mm, matrix = 128 × 128 (in-plane resolution of 1.875 mm), slice thickness = 3 mm, gap = 1 mm. In the Talaraich   x   plane, sagittal slice coverage was from   x   = −34 to −67, and   x   = 34 to 67. 

A T1-weighted whole brain volume which was acquired as a high-resolution spoiled gradient-recalled acquisition in a steady state (SPGR) (voxel size = 1.2 × 0.9375 × 0.9375 mm; FOV = 240; matrix = 256 × 256; 124 slices). 


#### EEG/ERP Study 
  
Participants were seated comfortably in an armchair in a dimly lit room with a white noise generator. A continuous 128-channel recording of 124 channels of scalp EEG (QuikCap, Compumedics Neuroscan, El Paso, TX, USA) and 4 channels of horizontal and vertical electrooculograph (EOG) was taken using Neuroscan 4.3 software (Compumedics, Neuroscan, El Paso, TX, USA). Data were sampled at 250 Hz/channel and bandpass filtered from 0.1 to 100 Hz and amplified with a gain of 5,000. A reference consisted of two electrodes placed either side of the nose or on the cheek close to the nose. The midline frontal ground electrode was sited on the electrode cap itself. Electrode impedances were kept below 10 kΩ. 



### Data Analysis 
  
#### Functional MRI 
  
Data reconstruction was implemented via Analysis of Functional Neural Images (AFNI), version 2.31 software (Cox  ). Data processing steps included offline image reconstruction in conjunction with smoothing in Fourier space via a Fermi window (full width at half maximum = 1 voxel), correction for differences in slice-timing, and 6-parameter rigid-body motion correction. The motion estimates over the course of the scan for translation (inferior–superior, right–left, and anterior–posterior) and rotation (yaw, pitch, roll) parameter estimates were used as covariates in further analyses. 

Each image time series was spatially registered to the volume closest in time to the high-resolution structural scan both within-plane and then in all three planes using an iterative linear least squares method, to reduce the effects of head motion. AUD, VIS, and AV blocks were analyzed with a least-squares general linear model (GLM) fit that modeled each activation block and head motion parameters. Each regressor consisted of an ideal hemodynamic response function for the specified block type, obtained by convolving the event time file (across 3 concatenated imaging runs) with a γ-variate function. The beta-weights resulting from the GLM analysis were converted to percent signal change using the mean overall baseline and spatially smoothed using a 4 mm Gaussian filter. These percentage signal change maps were transformed into standardized Talaraich space. 

A voxel-by-voxel parametric two-tailed   t   test was used on the percent signal change maps for a group comparison of each condition (versus rest) separately, plus AV versus AUD + VIS.   P  -value correction for multiple comparisons was based on a combination of threshold cutoff and cluster extent using 3dmerge (AFNI). Minimal cluster size was calculated using Monte Carlo simulation program AlphaSim (AFNI). For a masked AFNI image, AlphaSim ran 1,000 iterations, with a radius connectivity of 4.1 (since slice thickness + gap was 4 mm) and image defined Gaussian filters with FWHM determined with 3dFWHM. The minimal cluster size to avoid false cluster detection was 57 voxels for   P   < 0.05, 16 voxels for   P   < 0.01, 11 voxels for   P   < 0.005, 6 voxels for   P   < 0.001. Alpha maps were overlaid on inflated PALS atlas cortical model brains (Van Essen  ; Van Essen et al.  ). 

Regions of interest (ROIs) were based on significant activation from the analyses above. The average time course of the MR BOLD response in select ROIs was generated using the AFNI 3dDeconvolve program with the iresp option. The average time courses for each condition (AUD, VIS, AV, ApV) were averaged within each ROI and normalized across datasets. For a given hemisphere, we took voxels showing significant activation from that hemisphere plus its mirror opposite correlate (using 3dLRflip in AFNI), such that each ROI had equivalent right and left hemisphere volumes. 


#### Event-Related Potentials 
  
ERP analysis was performed using Neuroscan 4.3 Software (Neurosoft, Inc., Sterling, VA, USA). EEG data were first segmented into 1500 ms epochs with 100 ms pre-stimulus baseline based on the event markers which identified each trial type. The EEG data of the target trials were not included in subsequent analyses (similar to the fMRI study). Epochs containing artifact registering greater than ±100 μV, due primarily to eye blinks, or electromyographic activity due to face or head motion, were excluded from subsequent analyses. We excluded data from five of the eighteen participants (three participants had technically suboptimal studies due to excessive eye blinks/muscle activity in their EEG data, and two participants were deemed to be overly familiar with the stimuli and showed low alertness levels during the study), leaving thirteen participants in the final ERP analyses. 

The zero time point was the start of the audio, visual or simultaneous audiovisual stimulus. Individual epochs were normalized relative to a 100 ms prestimulus baseline, and linear trend was calculated and removed across the entire epoch, based on the prestimulus baseline. Stimulus types for each condition (AUD, VIS, AV) were averaged across all 6 runs. Each participant’s averaged ERP data were then digitally smoothed with a zero phase-shift low pass filter (cut-off 30 Hz, 6 dB/octave). 

Group averages were constructed and the averaged ERPs were scrutinized to identify ERP peaks and troughs. P100, N170, P250, and P500 ERP components were identified in the group average waveforms. Area under the curve (AUC) ranges were also selected for certain broader peaks. Latency ranges (windows) were selected for each grand average ERP peak or trough, and an automated peak picking routine was then run on the averaged ERP data of each individual subject. Area under the curve (AUC) measures were also taken for selected ERP components. Each subject’s ERP waveforms and ERP peak amplitude and latency measures and AUCs were exported as sets of ASCII files. 

Topographic voltage maps were created from the grand average ERP data at peak and trough timepoints to examine the regional distribution of ERP activity. Data from multiple sensors showing similar ERP behavior were then averaged as noted in the results section, with location of sensor markers determined by averaging Polhemus digitizer locations. 

Data at eye channels were also displayed in order to determine whether ERP signals may have been influenced by systematic, but subtle, eye movements. The signal excursion for the artifact free data in the eye channels was small (on the order of μV) and therefore did not appear to be due to actual eye movements which typically generate signals on the order of mV. In addition, the lower horizontal EOG channels did not show an equal and opposite negativity, suggesting that the positivity in the upper vertical EOG channel, located on the forehead, was likely due to frontal brain activity and not to eye related activity per se. 


#### Statistical Analysis of ERP Data 
  
Student’s   t   tests, one-way (Condition) and two-way (Condition by Hemisphere) ANOVAs of peak amplitudes, latencies, and AUC for particular ERP components were analyzed using SPSS V15. In order to objectively determine the timepoints for AUC measures, we calculated timepoint by timepoint values for the   t   test difference for AV versus AUD plus VIS. Thus, we set as time regions for AUC, periods of sustained (20 ms, 5 timepoints) significant differences (  t   > 1.67 for   n   = 60 epochs) between the multisensory and sum of the unisensory conditions. We used similar calculations to measure the time elapsed, after which no significant peaks occurred, an effective Return to Baseline (RTB). To determine the RTB we first calculated the   t   value versus zero for each point on the waveform. The RTB was defined as the end of the last significant peak of sustained (20 ms, 5 timepoints) significance. 




## Results 
  
### fMRI Data 
  
Ten participants completed the non-verbal unisensory target detection task in a 3T MRI scanner. A split sagittal slice acquisition optimized sampling of temporal cortex, but excluded medial regions as well as more medial aspects of frontal parietal cortex, fusiform and early visual cortex. 

All three conditions produced robust activation in sensory and higher-order cognitive regions. AUD and AV conditions produced additional and extensive activation of mid- to anterior STS and mid-insula (Fig.  a, c), whereas VIS and AV conditions produced activation of lateral occipital and posterior middle temporal gyrus (LO/pMTG) and lateral fusiform gyrus (Fig.  b, c). Brain regions showed multisensory relationships that fell into four main categories (Fig.  ):   
Group fMRI activation maps for each stimulus condition, AUD (  a  ) VIS (  b  ) and AV (  c  ) versus REST.   Warm colors   represent net positive BOLD signal,   cool colors   represent net negative BOLD signal.   d   Difference maps for VIS versus AUD. Regions more active in the VIS condition are represented by   warm colors   (  P   < 0.01 corrected).   e   Common activation maps (  black  ) for AV, VIS and AUD (  P   < 0.001 corrected). Overlaid regions show mathematical superadditivity (  solid white lines  ) and underadditivity (  dashed white lines   P   < 0.05 corrected) 
    
Group fMRI data ROI analyses: underadditive BOLD responses. Histograms depict relative fMRI percent signal change for all three conditions in   underadditive   ROIs (  a  –  c  )   AV maximum   (  d  –  e  ) and   common-activation   ROIs (  f  ).   Asterisks   indicate pairwise   t   test significance: *   P   < 0.05, **   P   < 0.01, ***   P   < 0.001 
    
 superadditive  , defined as audiovisual greater than the sum of auditory alone and visual alone i.e. AV > ApV; 
  
 underadditive  , defined as audiovisual less than the sum of auditory and visual alone, and audiovisual less than the dominant sensory modality e.g. AV < ApV and AV < AUD or VIS; 
  
 AV maximum  , defined as audiovisual greater than either unisensory condition along (AV > VIS and AV > AUD, and VIS > 0, AUD > 0). 
  
 Common activation  , defined as AV activation equal to one or both conditions (AV = AUD and/or VIS. Note that for both AV maximum and Common activation, audiovisual would be less than the sum of the unisensory conditions (AV < ApV). 
  

Two regions showed mathematical   superadditivity,   the right insula/frontal operculum and left angular gyrus. However, this resulted from negative activation versus baseline in one or in all three conditions, and neither region showed significant positive activation for the AV condition (solid white outlines, Fig.  d). 

Several regions showed significant or near-significant   underadditive   effects including MTG, LO/pMTG, and lateral fusiform gyri, with the AV condition showing decreased activation compared with either unisensory condition or the sum of the unisensory conditions, ApV (Table  A). The AUD-preferred region, left mid-MTG, showed a trend (  P   < 0.1) of AV < AUD. Similarly, for the VIS-preferred regions, LO and fusiform gyrus, there was a significant difference and trend, respectively, of AV < VIS. LO and fusiform also showed a right-hemisphere bias (Table  A).   
Summary of significant and trend effects resulting from 2-way ANOVA comparisons for (A) fMRI and (B) ERPs 
  
The middle columns show the results of AV versus ApV, while the right columns show the effects for AV versus VIS and AV versus AUD. B has an additional set of columns for ERP latency effects.   Asterisks   indicate   P  -value of   F   statistic: *   P   < 0.05, **   P   < 0.01, ***   P   < 0.001, ****   P   < 0.00001. All effects were tested, but non-significant interactions are listed as n.s. or are omitted. In several cases, noteworthy   t   tests are listed 
  

 AV maximum   and Common activation   effects were seen in frontal, parietal and temporal regions (Black overlay at   P   < 0.001, Fig.  d). The pSTS, TPJ, IFG, and DLPFC all showed strong condition effects for AV < ApV (Table  B). Portions of these regions were also revealed in a voxelwise   t   test of AV versus ApV (dashed white lines in Fig.  d). The pSTS showed a significant hemisphere effect (right > left), with the VIS condition showing the strongest lateralization (  t   = 4.98,   P   < 0.005).   AV maximum   activation was seen in several of these regions, including right posterior pSTG (  P   < 0.01 versus VIS,   P   < 0.001 versus AUD), and TPJ (  P   < 0.01, versus VIS,   P   < 0.05 versus AUD). IFG and DLPFC showed   common activation,   with the AUD condition showing the least activation in DLPFC. 

The STS and IFG regions, in addition to showing at least a trend towards hemisphere effects for amplitude of activation (Table  A), also showed a greater number of active voxels in the right versus left hemisphere (Right STS: 134 versus Left STS: 0; Right IFG: 1871 mm  versus Left IFG: 157 mm ), thus showing right hemisphere dominance in both magnitude and extent of activation. 

A separate group of 13 participants participated in the ERP version of the experiment. Since the neutral, eyes forward face was present as a baseline for the duration of VIS and AV blocks (except during movements), the zero time point for ERP measurements is at the onset of the facial movement and/or simultaneous vocalization (for AUD, onset of vocalization). In general, ERP waveforms revealed modality-specific early components with characteristic topographies and morphologies, in addition to a late positivity (Fig.  ). Stimuli containing auditory stimulation (AUD and AV conditions) showed the typical auditory N140 with an amplitude maximum at midline central electrodes. Stimuli containing visual stimulation (VIS and AV conditions) showed the typical face-specific N170 at bilateral temporo-occipital electrodes, showing delayed latencies typical of dynamic visual stimuli. In addition to showing both typical auditory and face-related components, the AV condition also elicited a unique early positivity in left parieto-occipital electrodes. All three conditions showed a diffuse late positivity which lasted up to 1500 ms, and varied in amplitude between conditions. A   t   test of AV versus ApV was used to search for regions of potential multisensory effects. Again, effects were grouped into the four categories of   superadditive  ,   underadditive, AV maximum   and   common-activated  .   
Group average topographic ERP maps as a function of condition and time. Topographic maps are depicted at post-stimulus time points of 80, 140, 270 ms, and then every 100 ms for all three stimulus conditions (  top three rows  ). The   bottom row   shows difference maps for the AV condition minus the sum of the unisensory conditions (ApV).   Red-yellow   shows positive ERP activity,   blue-aqua   show negative ERP activity. Topographic maps showing timepoints analyzed in subsequent figures are labeled 
  

#### Superadditivity at 60–148 ms 
  
At this relatively early post-stimulus time range, the AV condition elicited an early positivity in bilateral temporo-occipital electrodes that was not seen in either unisensory condition (Figs.  ,  a). We performed a timepoint-by-timepoint   t   test analysis to determine the time range showing significant differences between AV and AUD plus VIS (i.e. AV versus ApV), and performed an AUC analysis for this time range (60–148 ms). A two-way ANOVA revealed superadditivity, with main effects of Hemisphere [  F  (2,24) = 16.67,   P   < 0.01].   
Superadditivity in group ERP averaged data at bilateral temporo-occipital electrodes (from 60 to 148 ms). Histograms for area under the curve (AUC) analysis for time range 60–148 ms. Topographic map shows 12 sampled electrodes (  white dots  ). Waveform for 6 averaged right temporal occipital electrodes shows unique peak for AV (  black circle  ).   Asterisks   indicate pairwise   t   test significance 
  


#### Trend Towards Underadditivity for N140 
  
AUD and AV, but not VIS, conditions elicited a central negativity at 144.7 ms, typical for auditory stimuli (Fig.  a). Peak amplitude analysis revealed a trend for AUD > AV (Table  B), but found no significant super- or underadditivity.   
Underadditivity in group averaged ERP data in relatively early post-stimulus timeranges. Histograms for peak amplitude for   a   N140 and both peak amplitude and latency for   b   N170. Averaged ERP waveforms for sampled electrode sites (  white dots   on topographic maps), appear at the right of the histograms.   Asterisks   indicate pairwise   t   test significance.   P  -values listed for non-significant trends 
  


#### Underadditivity for N170 
  
All three conditions produced a negativity at an average 276.7 ms, with preference for conditions including visual stimuli (Fig.  b). The waveform was characteristic of the N170 which is elicited by dynamic faces, peaking at temporo-occipital electrodes, with a right hemisphere bias (Fig.  c, white dots). As the stimulus was dynamic, the N170 was considerably delayed relative to the 170 ms typical for the presentation of static face stimuli (see Puce et al.  ). Face movement began at 0 ms and was generally identifiable as a particular “vocalization” by 33 ms. Although the AV and VIS N170 s were larger, the AUD condition also elicited a negativity that had a similar timecourse at these electrodes (274.8 ms). The N170 was underadditive, such that AV < ApV, and showed condition and hemisphere main effects (Table  B). Peak analysis revealed reduced amplitude and decreased latency for the AV versus VIS condition, as well as a right hemisphere bias for amplitude (Table  B). 


#### AV Maximum and Common Activation for Late Positivities 
  
All three conditions elicited widely distributed late positivities (Fig.  ). A strict AV versus ApV   t   test revealed an underadditivity at bilateral temporo-parietal electrodes at 230–304 ms (timepoint-by-timepoint   t   test, Fig.  a). Even though the peaks were broad, we used a semi-automated peak analysis with verification of peaks in individual subjects data. We wanted to examine the data for latency differences, and more strictly apply multisensory criteria (at the time of the AV and AUD peaks, the VIS peak has yet to appear). The temporo-parietal peak occurred at 240 and 244 ms respectively for the AUD and AV conditions, but was delayed at 328 ms for the VIS condition. This peak was considered a   common activation,   as analysis, using the homologous peaks for all three conditions, did not show any significant amplitude differences between conditions (Table  B).   
Later ERPs histograms and waveforms. Charts showing peak amplitude and latency analysis for Common activation   a   12 temporo-parietal electrodes (6 in each hemisphere) in the post-stimulus timerange, 230–304 ms and AV maximum,   b   8 frontal-temporal electrodes in the timerange 460–616 ms. Rightmost panel in each row shows ERP waveforms for each condition along with AV-ApV topographic maps (sampled electrodes are   white dots  ).   Asterisks   indicate pairwise   t   test significance. Very late timeranges show common activation in occipital and frontal electrode sites (  c  –  e  ) 
  

An underadditivity was seen at right fronto-temporal electrodes at 460–616 ms (timepoint-by-timepoint   t   test, Fig.  b). Latency of this broad peak was also greatest for the VIS condition (492 ms) and was similar across the AUD and AV conditions (384 and 400 ms, respectively). Analysis of homologous peaks revealed a Condition effect, with the AUD condition showing the smallest amplitude (Table  B). This peak was considered an   AV maximum  , as the AV condition was significantly greater than either unisensory condition in the right hemiscalp, and a similar trend was seen in the mirror opposite electrodes (Fig.  b). 

 Common activation   was seen at several other electrode sites, include occipital and frontal electrodes. Occipital electrodes showed equivalent sustained activation for all three conditions in the 700–800 ms range (Fig.  c). In contrast, for frontal electrodes, F5 and FPZ, late sustained activation was only seen for AV and VIS conditions and not the AUD condition (rectangles, Fig.  d, e). Note at F5 the   AV maximum   peaks at the 250 ms and 450 ms ranges (circle, Fig.  d). 



### Results Summary 
  
The ERP data showed a unique early positivity for the AV condition starting at 60 ms. In sum, however, there was convergence of ERP and fMRI data. Both the N140 (generated in the superior temporal plane) (Giard et al.  ; Godey et al.  ; Ponton et al.  ), and the auditory STS showed non-significant trends towards underadditivity. For VIS related processing, AV activation was significantly reduced (smaller amplitude ERPs and BOLD responses) compared to the preferred unisensory stimuli (VIS). Finally, multiple “higher-order” cortical regions, as well as late time ranges typically associated with more higher-order processes showed significant or near significant trends of AV maximum activation (AV greater than either condition alone). Other regions/timeranges showed common activation in which AV and one or both conditions showed similar degrees of activation. Several of these regions and timeranges showed a right hemisphere bias. 



## Discussion 
  
Using an animated synthetic face and associated real human non-verbal vocalizations we elicited reliable fMRI activation to unisensory and multisensory stimulation in an imaging study designed to optimally image the STS/STG in its entirety, while still including face-sensitive and auditory regions in lateral sensory cortex. In a second group of subjects we elicited reproducible and consistent ERPs to the relatively long durations of the facial motion and associated vocalizations. Subjects were asked to detect unisensory target stimuli (a blink and an “mmm” sound) so that we could study audiovisual integration without a bias to a particular sensory modality. We discuss our results, summarized in Fig.  , in the context of other audiovisual non-biological and speech integration studies, and in more general terms of social cognition.   
Summary of main fMRI and ERP findings in terms of time of occurrence relative to stimulus onset and type of multisensory phenomenon 
  

### Multisensory Effects in Sensory-Related Processes 
  
Multisensory effects were seen in early regions (fMRI data) and ERP components which supported our hypotheses predicting facilitation effects. Interestingly, we also observed a unique early AV ERP component. This AV positivity peaking around 60–80 ms is similar to that seen in recent audiovisual integration studies (Giard and Peronnet  ; Shams et al.  ). Somewhat surprisingly, these studies, which used   non-biological   stimuli, showed early AV integration effects whose laterality was opposite to ours. Giard and Perronet ( ) proposed that their early ERP response may stem from the recruitment of specific multisensory cells in or near striate cortex, where bisensory cells have been seen observed in animals (Fishman and Michael  ; Morrell  ). Due to our slice selection in our fMRI study, we could not confirm whether multisensory effects occurred in early visual cortex, however, such early effects in humans have been seen in other studies (Martuzzi et al.  ). 

Aside from the unique AV ERP signal, AUD and VIS-related sensory-related regions and ERP signals showed multisensory effects characteristic of facilitation, as predicted by our hypothesis. Significant effects were seen in VIS-related regions (LO) and ERP components (N170), and trends in the same direction were seen in fMRI activated AUD-related regions and ERP components (mid-MTG and N140). The strongest case of fMRI and ERP convergence was at mid-level visual processes, characterized by a right hemisphere bias and decrease in both amplitude (fMRI and ERP) and speed (ERP) of AV versus VIS. 

The auditory trend towards facilitation was consistent with the role of the centrally located N140 in multisensory integration (Besle et al.  ; Puce et al.  ; van Wassenhove et al.  ). A study by Puce et al. ( ) showed the largest N140s were elicited when a dynamic human face (relative to house and primate face stimuli) was paired with incongruous sounds, suggesting that the context provided by a conspecific (human) face influences associated auditory processing. Additionally, when congruous sounds were presented, the N140 was largest to both human and primate faces when paired with species-appropriate vocalizations relative to a house stimulus whose front door opened with a creaking door sound (Puce et al.  ). However, unlike previous ERP studies using speech stimuli (Besle et al.  ; van Wassenhove et al.  ), our results here did not reach significance, perhaps due to differences in timing of facial movements relative to vocalizations. In our paradigm, face movement and audio were simultaneous, although there was a natural delay in the movement peaking for our non-verbal stimuli (e.g. fully open mouth, upturned eyes in the sigh in Fig.  ), which is opposite to speech stimuli. Ghazanfar et al. (Ghazanfar et al.  ) also have shown that timing plays a critical role in multisensory effects in an experiment in which monkeys were presented conspecific coos and grunts along with images of primate faces, however, in this experiment static faces of primates were utilized. Multisensory neurons in the auditory core and belt regions showed more enhancement when the face versus audio delay was less than 100 ms, and facilitation when the delay was greater than 200 ms. The variance of these studies based on timing underscores the importance of subtle audio versus visual onset time differences in multisensory processing. 

Reduced activation in the AV condition could be due to various causes, including less energy demands brought about by facilitated processing. Alternatively, the relative decrease in amplitude in the multisensory relative to the unisensory conditions may be due a smaller population of neurons with exclusively multisensory versus unisensory preferences (Beauchamp  ; Laurienti et al.  ). Alternatively, the distribution of resources available to process these stimuli might be limited over multiple sensory cortical regions. We favor the increased efficiency explanation in the light of the behavioral facilitation effects observed in many studies (Bolognini et al.  ; Gondan et al.  ; Grant and Walden  ; Miller  ; Sumby and Pollack  ), although all three explanations are plausible and cannot be differentiated in the current dataset. Multisensory optimization may also take the form of synchronization of the phase of oscillatory stimuli (such as gamma band activity) (Engel et al.  ; Schroeder et al.  ; Senkowski et al.  ), which can produce important behavioral sequelae (Schroeder et al.  ). Future studies quantifying ERP amplitudes and latencies, oscillatory activity and behavior in a combined manner might better clarify the underlying nature of these processes. 

#### Higher-Order Underadditive Effects 
  
We saw significant activation by all three conditions in putative higher-order cognitive processes (based on latencies (ERP data) and origins (fMRI data); Doeller et al.  ; van Herten et al.  ; Vuilleumier and Pourtois  ). Here a clear case for convergence is more difficult to make since later ERPs are typically diffusely distributed, making source localization challenging, as they can potentially come from multiple sources (Siedenberg et al.  ; Soltani and Knight  ). However in our study, later ERPs, and activation in higher-order brain regions as revealed by fMRI showed spatially distributed responses and a combination of   AV maximum   and   Common activation   responses. From the fMRI side, this network of frontal, temporal and parietal regions has been implicated in other studies as playing an important role in multisensory perception (for review see Ghazanfar and Schroeder  ), as well as for understanding speech and socially related stimuli (Calvert et al.  ; Moll and de Oliveira-Souza  ). For the ERPs, there were multiple distributed late peaks that showed an AV response with properties from both unisensory conditions (AV elicited larger amplitudes like the VIS condition and faster latencies like the AUD condition). 

It is much more difficult to attribute higher-order activation as being specifically related to multisensory processing, as these regions did not show superadditivity, perhaps due to ceiling effects from these robust stimuli (Stevenson et al.  ). In addition, higher order processes can be non-specific and can be very sensitive to other factors such as attention. The target stimuli were always unisensory, and therefore there were two possible unisensory targets in the AV blocks. It is possible that in the AV and VIS conditions responding to the corresponding unisensory target stimulus may have resulted in potentially greater stimulus-driven attentional effects. Having said that, the STS, IFG, and TPJ have shown potential multisensory behavior in other studies where the task requirements did not involve such contingencies (Calvert et al.  ; Kawashima et al.  ). Additionally, the blocked-event design in this study could conceivably have produced some refractoriness effects in the data, and in other studies (Calvert et al.  ; Kawashima et al.  ), albeit unlikely. Ideally, an event-related design would circumvent these kinds of issues. 

Notably, all three conditions in our study activated right pSTS, a region previously shown to be important in social-related multisensory processing (Redcay  ). Right pSTS along with right TPJ, were the only regions in which there was maximum activation in the AV condition. Further evidence of pSTS importance in both multisensory and social processing come from prior research on a possible pSTS homologue in monkeys, the Anterior Superior Temporal Polysensory Area (STPa), which responds to visual biological motion, faces, and head and body view and direction (Jellema et al.  ; Oram and Perrett  ), and projects to higher order cognitive and emotional processing regions such as the amygdala and prefrontal regions (Oram and Perrett  ). 

In addition, we saw right-hemisphere dominated effects in STS and frontal regions, which is typically not seen in most speech related studies (Campbell et al.  ; Capek et al.  ; Hubbard et al.  ; Kawashima et al.  ; Macaluso et al.  ; MacSweeney et al.  ; Skipper et al.  ). However, left lateralized activation has been less strongly observed in multisensory studies of simple speech, syllables, and emotional prosody (Kreifelts et al.  ; Olson et al.  ; Wright et al.  ). It is possible that higher-order regions in both hemispheres have multisensory properties and are recruited based on verbal versus non-verbal relevance. 



### Summary 
  
Both imaging modalities produced datasets that were very complex, yet there was a surprising degree of convergence between the ERP and fMRI data (Fig.  ). Underadditivity dominated the multisensory effects in earlier regions as supported by the significant (VIS areas) and trend towards (AUD) smaller and faster responses for AV versus unisensory stimuli. These data, along with previous behavioral studies, suggest that early or mid-sensory regions may be optimized to process multisensory stimuli, if information from multiple modalities is available (Foxe and Schroeder  ). Multiple “higher-order” cortical regions, as well as late ERP activity typically associated with more higher-order processes showed underadditive effects driven by common activation for all conditions of non-verbal human stimuli, with a dominance of the AV condition in temporal regions. In particular the unique right pSTS effects confirm the important role of pSTS in social cognition, and again show the tendency toward right lateralization for social-related stimuli. 



## Electronic supplementary material 
  
 </div>
</div>
</div>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-48' name='judgment-48' value='agree'>
<label for='agree-48'>Agree</label>
<input type='radio' id='disagree-48' name='judgment-48' value='disagree'>
<label for='disagree-48'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-48' name='comment-48' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-49'>
<h2>49. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/19630891/' target='_blank'>19630891</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of self-related social cognition (direct and reflected self-appraisals), involving a healthy adult sample (N=12, ages 22.6–30.4). The paper reports group-level, univariate whole-brain task contrasts and conjunction analyses for adults (e.g., direct and reflected appraisals vs. rest; reflected>direct), with coordinates and descriptions of whole-brain results. The study is empirical, not ROI-only or connectivity/resting-state only, and healthy adult results are reported separately alongside adolescent data. Therefore it meets all inclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.98</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-49' name='judgment-49' value='agree'>
<label for='agree-49'>Agree</label>
<input type='radio' id='disagree-49' name='judgment-49' value='disagree'>
<label for='disagree-49'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-49' name='comment-49' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-50'>
<h2>50. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22403154/' target='_blank'>22403154</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Meets all inclusion criteria: (1) Task is social-related (self- vs other-referential processing of valenced adjectives), directly relevant to ‘Perception and Understanding of Self/Other’. (2) Sample comprises healthy adult participants aged 18–52 (N=20 women), within 17–65. (3) The paper reports group-level, whole-brain univariate task-evoked results (voxelwise GLM results and contrasts: S-N, S-P, O-N, O-P vs fixation and planned contrasts; whole-brain maps reported with voxel-wise thresholds and cluster tables/figures). (4) Not ROI-only: although ROI/SVC analyses are included, whole-brain results are clearly presented. No exclusion criteria are violated (not resting-state/seed-only, not only between-group contrasts, empirical fMRI data in healthy adults). Therefore include.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-50' name='judgment-50' value='agree'>
<label for='agree-50'>Agree</label>
<input type='radio' id='disagree-50' name='judgment-50' value='disagree'>
<label for='disagree-50'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-50' name='comment-50' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-51'>
<h2>51. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/30455187/' target='_blank'>30455187</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social decision-making (iterated Prisoner’s Dilemma) in healthy adult participants (N=20 males, age range 21–37). The paper reports group-level, univariate whole-brain task-evoked results: one-sample t tests for task phases in the placebo (healthy) condition and flexible factorial whole-brain analyses (FWE cluster-corrected) with tables/figures of activations (Tables 5–6; Figures 4–6). The sample is within the 17–65 range, and results for the healthy group are clearly reported. The study therefore meets all inclusion criteria (task-based fMRI of social processing, healthy adult sample, and whole-brain group-level maps). No exclusion criteria apply (not ROI-only, not connectivity/resting-state only, and includes within-group healthy-task effects).</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-51' name='judgment-51' value='agree'>
<label for='agree-51'>Agree</label>
<input type='radio' id='disagree-51' name='judgment-51' value='disagree'>
<label for='disagree-51'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-51' name='comment-51' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-52'>
<h2>52. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/27978778/' target='_blank'>27978778</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study of social processing (face perception/emotional valence and attention) in healthy adult participants (final N=25, ages 21–33). The paper reports group-level, whole-brain univariate analyses: a random-effects faces>objects contrast from the localizer (group t-map, k>9, p<.001) used to define face-responsive ROIs, and whole-brain searchlight results (SnPM corrected). Group-level task-evoked statistical maps are clearly described and generalizable to healthy adults. The study therefore meets the inclusion criteria (social-related fMRI task, healthy adult sample, and reported whole-brain group-level task activation), and does not violate exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-52' name='judgment-52' value='agree'>
<label for='agree-52'>Agree</label>
<input type='radio' id='disagree-52' name='judgment-52' value='disagree'>
<label for='disagree-52'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-52' name='comment-52' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-53'>
<h2>53. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/29915004/' target='_blank'>29915004</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This paper reports task-based fMRI in healthy adult participants (N=59 across three unique participant samples) performing social-related tasks (person knowledge, famous faces/names, socially relevant concept words). Group-level, whole-brain, voxelwise contrasts are reported (e.g., social > non-social semantics) with thresholding and peak MNI coordinates and whole-brain maps described in the text and tables. The sample is healthy adults and results for the healthy groups are reported separately. The study is empirical and not ROI-only, and does not rely solely on connectivity/resting-state or between-group-only contrasts. Therefore it meets all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-53' name='judgment-53' value='agree'>
<label for='agree-53'>Agree</label>
<input type='radio' id='disagree-53' name='judgment-53' value='disagree'>
<label for='disagree-53'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-53' name='comment-53' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-54'>
<h2>54. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/27167401/' target='_blank'>27167401</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study of social cognition in healthy adults (final N=18, mean age 23.7 within 17–65). The task is explicitly social (inferring others’ emotions from visual/verbal cues with feedback). The paper reports whole-brain, group-level univariate analyses of task-evoked signals (value and prediction-error regressors) with tables of coordinates and conjunction/contrast maps, meeting the whole-brain evidence requirement. Results are presented for the healthy/control sample (no clinical subgroup confound). Analyses are task-based, not limited to ROI-only, connectivity-only, or resting-state approaches. Therefore all inclusion criteria are satisfied and no exclusion criteria apply.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-54' name='judgment-54' value='agree'>
<label for='agree-54'>Agree</label>
<input type='radio' id='disagree-54' name='judgment-54' value='disagree'>
<label for='disagree-54'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-54' name='comment-54' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-55'>
<h2>55. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/27405334/' target='_blank'>27405334</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study reports task-based fMRI in healthy adults (N=110, age 19–31) using a social cognition paradigm (self-reference vs other-reference). Group-level, whole-brain univariate GLM results are presented (second-level analyses; FWE-corrected whole-brain inference) including contrasts of interest (social > baseline, self > other, other > self) and accompanying tables/figures. Although the paper also includes DCM effective-connectivity analyses, it clearly reports whole-brain task-evoked activation maps for the healthy sample rather than ROI-only or resting-state results. All inclusion criteria are therefore satisfied and no exclusion criteria are met.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-55' name='judgment-55' value='agree'>
<label for='agree-55'>Agree</label>
<input type='radio' id='disagree-55' name='judgment-55' value='disagree'>
<label for='disagree-55'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-55' name='comment-55' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-56'>
<h2>56. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/30639176/' target='_blank'>30639176</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Trustworthiness appraisal deficits in borderline personality disorder are associated with prefrontal cortex, not amygdala, impairment</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Neuroimage Clin</p>
<p><strong>Publication Year:</strong> 2018</p>
<p><strong>DOI:</strong> 10.1016/j.nicl.2018.101616</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6411618/' target='_blank'>6411618</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> excluded</p>
<p><strong>Fulltext Reasoning:</strong> While this is an fMRI study of social-related processing (trustworthiness/fear appraisal) and includes a healthy adult control group (n=17, ages 18–45), the manuscript does not clearly report a group-level, univariate whole-brain task activation map that is explicitly and separably identified as coming from the healthy/control group. The reported whole-brain analyses appear to be across all participants or focused on between-group contrasts (BPD vs controls), and the healthy-group-specific results presented in the paper are primarily ROI-based analyses. Inclusion requires at least one whole-brain (voxelwise) healthy-group task map (or equivalent coordinate table/figure clearly labeled for the healthy group). Because that criterion is not clearly met in the text provided, the study must be excluded.</p>
<p><strong>Fulltext Confidence:</strong> 0.85</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
## Background 
  
Borderline Personality Disorder (BPD) is associated with sensitivity to signals of interpersonal threats and misplaced trust in others. The amygdala, an integral part of the threat evaluation and response network, responds to both fear- and trust-related stimuli in non-clinical samples, and is more sensitive to emotional stimuli in BPD compared to controls. However, it is unknown whether the amygdalar response can account for deficits of trust and elevated sensitivity to interpersonal threat in BPD. 


## Methods 
  
Facial stimuli were presented to 16 medication-free women with BPD and 17 demographically-matched healthy controls (total n = 33). Participants appraised fearfulness or trustworthiness of the stimuli while BOLD fMRI was obtained. 


## Results 
  
Though BPD participants judged stimuli as less trustworthy compared to controls, trustworthiness did not correlate with amygdalar activity in either group. Trustworthiness correlated with prefrontal regional activity in the insula and lateral prefrontal cortex. Prefrontal BOLD activity while appraising trustworthiness was smaller in BPD compared to controls, and the size of the reduction was proportional to each participant's response bias. 


## Conclusions 
  
Neural substrates of trustworthiness appraisal are associated with the lateral prefrontal cortex and insula, not amygdala, suggesting that untrustworthy stimuli do not elicit a subcortical threat response. Current models of BPD and its treatment may need to include a focus on improving impairments in frontally mediated trustworthiness appraisal in addition to amygdala- driven emotional hyper-reactivity. 

   Highlights  
  
BPD is associated with sensitivity to signals of interpersonal betrayal and misplaced trust in others. 
  
BPD subjects judged faces to be less trustworthy than controls. 
  
Amygdala activity did not correlate with trustworthiness, but was modulated robustly by fearfulness of the stimulus. 
  
Prefrontal cortex, not amygdala, was modulated by trustworthiness. 
  
BPD was associated with reduced prefrontal activity, and the reduction was proportional to each individual’s response bias. 
  
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (30045 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Heightened sensitivity to threat signals in interpersonal relationships and a misplaced trust in others are common vulnerabilities in Borderline Personality Disorder (BPD) ( ;  ;  ). Individuals with BPD are prone to judge others as more hostile ( ), are more likely to detect anger in ambiguous faces ( ), to recognize angry faces faster than healthy controls ( ), and to exhibit an elevated affective startle reflex ( ). BPD is also associated with greater mistrust of others, characterized by a response bias during trustworthiness appraisal ( ;  ). Furthermore, the emotional valence of a neutral face, i.e., the degree to which the face appears to be happy or angry, influences the visual assessment of trustworthiness in non-clinical individuals and has led to the hypothesis that appraisal of trustworthiness is actually an assessment of interpersonal threat ( ). Thus, greater sensitivity to cues of interpersonal threat in BPD ( ;  ;  ) may explain its association with elevated mistrust of others ( ). 

The neural mechanisms of threat appraisal have been studied extensively, and, it is widely accepted that the amygdala is an integral part of the threat appraisal and response system ( ;  ;  ). The amygdala has also been proposed to be an important structure in the appraisal of trustworthiness ( ;  ;  ;  ). Bilateral lesions of the amygdala result in appraisals of elevated trustworthiness and approachability in both monkeys ( ) and humans ( ). Faces judged to be untrustworthy are associated with greater amygdala activity than trustworthy faces ( ;  ;  ). Furthermore, after interpersonal betrayal, nasally administered oxytocin reduces amygdala activity, and preserves trust and cooperation ( ). These findings suggest that, in non-clinical adults, appraisal of trustworthiness involves the amygdala, and cues of interpersonal threat, such as expressions of anger or aggression, lead to an amygdala-based threat signal. By extension, greater mistrust of others in BPD may plausibly be a consequence of amygdala hyperactivity ( ). In fact, several studies have reported that individuals with BPD exhibit greater amygdala activation to a wide range of interpersonal and emotional stimuli compared to controls ( ;  ;  ;  ), though hypoactivation has also been reported ( ). However, though BPD has been associated with elevated amygdala activity to emotional stimuli and reduced interpersonal trust, a direct link between the elevated amygdala activity and impairment in trustworthiness appraisal has not been established. In the present study, facial expressions were systematically varied along the fearfulness or trustworthiness dimensions, and appraised by a BPD and a healthy control group. We tested the hypothesis that the response bias toward judging faces as untrustworthy, characteristic of BPD, will be correlated with amygdala hyperactivity. We also performed whole-brain analyses to determine whether other regions were related to trustworthiness appraisal deficits in BPD. 


## Methods and materials 
  
### Participant characteristics 
  
All participants were female between the ages of 18 and 45 years; 17 were healthy controls and 16 had a DSM-IV diagnosis of BPD ( ). Participants were recruited via advertisements and referral through a large, metropolitan hospital as part of ongoing clinical studies in mood disorders, suicidal behavior, and BPD. None of those with BPD were taking psychotropic medications while participating in the study, though 60% had a history of use of psychiatric medication. Exclusion criteria for the BPD group included a current major depressive episode, psychotic disorder, current substance use disorder, or a recent suicide attempt (in the last 6 months). The healthy control group was matched on demographics (age, ethnic/racial frequency, marital status), education level, and verbal IQ (the vocabulary subtest of the Wechsler Adult Intelligence Scale)( ), and was assessed with semi-structured interview to rule out a history of psychiatric or substance use disorder. Institutional Review Boards at two institutions approved the study. Fifty-eight participants signed consent, and 43 completed all assessments and the fMRI scan.   summarizes the demographic and clinical descriptions, and Supplementary Table 1 summarizes the clinical diagnoses of the BPD sample. Notably, 37.5% of the BPD group reported past of substance abuse or dependence, 68.8% had a past major depressive disorder, and none had a current or past bipolar or PTSD diagnosis.   
Demographic and Clinical Characteristics. 
  Table 1     


### Clinical assessment 
  
For individuals with BPD and controls, diagnoses were determined by Structured Clinical Interview for DSM-IV, Patient Edition (SCID-I) ( ) and the Structured Clinical Interview for DSM-IV Axis II Personality Disorders (SCID-II) ( ). Reliability studies within our research division yielded the following intra-class correlation coefficients (ICCs) (criterion levels are shown in parentheses): Axis I diagnosis/SCID-I, ICC = 0.80 (0.70); Axis II diagnosis/SCID-II, ICC = 0.70 (0.70); BPD diagnosis, ICC = 0.89 (0.70). Depression severity was assessed using the Hamilton Depression Rating Scale (Ham-D; ( )). Concurrent negative emotional state was assessed with the Profile of Mood States ( ) a 65-item self-report questionnaire that provides a total score of state negative emotion scores based on 6 transient emotional states: tension-anxiety, depression-dejection, anger-hostility, confusion-bewilderment, vigor-activity, and fatigue. Hostility and aggression were assessed using the Buss Durkee Hostility Inventory (BDHI; ( )). Abuse history was assessed as part of the demographic interview, which asks participants whether they have experienced physical and sexual abuse before age 18. We assessed the number of prior suicide attempts from the Columbia Suicide History interview ( ). The Rejection Sensitivity Questionnaire was used to assess anxious anticipation and expectation of interpersonal rejection ( ) (See   for clinical characteristics). 


### Trustworthiness-fear face appraisal task 
  
We utilized a task developed and validated by our group ( ;  ) to measure an individual's capacity to make subtle discriminations between facial features that indicate potential interpersonal threats, expressions of fear and of trustworthiness. Trustworthy faces were male, computer generated avatars selected from the stimuli developed and psychometrically validated by Todorov and colleagues ( ). Facial fear stimuli were selected from the NimStim Face database ( ) and identical to those used in Fertuck et al. ( ). 

Faces at opposite extremes (neutral vs. fearful) or (trustworthy vs. untrustworthy) were morphed together in steps of 10% to create intermediate fear and trust values (Morpher software for Windows, version 3.1, M. Fujimiya). Individuals were presented with faces that varied along the fear or trustworthiness dimensions and asked to judge each face on a five-point Likert scale (where 1 is neutral or trustworthy and 5 is fearful or untrustworthy). (See ( ) for more details on the development of the task and Supplementary Fig. 1 and Supplementary Methods for sample stimuli and further elaboration of the procedure). 

Subjective appraisal parameters were determined by fitting the behavioral data (i.e. rating versus % morph) to a logistic function of the form, (y = α + β/(1+ e ) where x is the morph percentage of the stimulus, y is the mean subjective rating, and the free parameters are α (the offset or bias), β (the scaling or sensitivity), and λ (the slope or discriminability) of the psychometric function. Each participant's responses were checked to confirm that they completed the tasks as instructed (i.e. that subjective responses were not random but showed a monotonically increasing relationship with morph value). From those participants who completed the fMRI task, 2 BPD participants were excluded due to corruption of the data, and 4 BPD and 4 control participants were excluded because their ratings of either the trust or fear stimuli indicated a lack of discrimination between the most and least untrustworthy or fearful stimuli. All results, then, were based on data from 16 BPD patients and 17 healthy controls. 


### Functional imaging 
  
#### fMRI parameters 
  
Functional MRI was performed on a 1.5 Tesla GE Signa scanner using the EPI-BOLD sequence (TR = 2.0, TE = 86, flip angle = 34, number of slices = 27, array size = 64 × 64, voxel size = 3.1 mm × 3.1 mm × 4.0 mm, number of volumes = 150, duration of run = 6 min. Structural scans were performed using the 3D SPGR sequence (124 slices, 256 × 256, FOV = 200 mm). 


#### fMRI data analysis 
  
All analysis was done using the FMRIB Software Library (FSL 5.0.10; ( ) and Matlab 2017a. Preprocessing consisted of motion correction (McFlirt), slice timing correction, high-pass filtering (> 50 s), and spatial filtering (FWHM = 5 mm). Relative head motion of 0.5 mm was set as a threshold and runs exceeding this value were excluded (none reached the threshold). Motion parameters (3 translations, 3 rotations, derivative and quadratic terms; 18 regressors total), CSF and white matter activity were included as confound regressors. Standard statistical parametric mapping techniques (FEAT) were performed in original T2* space. Group analyses were performed using FEAT in MNI152 space at 2 mm isotropic resolution. Voxel-wise activation thresholds were set at p = 0.05, correction for multiple comparisons was done using Gaussian Random Field Theory with a cluster threshold of p = 0.001. A whole brain mask was used to exclude voxels outside the brain. 

For each functional run, a regression model was created assuming three neural processes: (1) an unmodulated process, (2) the subjective appraisal of the stimulus, and (3) the quadratic term of the appraisal. The unmodulated regressor consisted of a set of boxcars in which each boxcar began at stimulus onset and ended when the subject made a response. The height of each boxcar was equal to 1 and represented any task-general activity (e.g. working memory, spatial attention, sensory processing, and other processes) that do not differ between conditions). The appraisal regressor had an identical temporal structure to the unmodulated regressor but the height of each boxcar was proportional to the participant's subjective mean rating of the stimulus for the trust or fear decision. The quadratic regressor used an identical temporal structure to the appraisal regressor but with amplitude generated by demeaning the subject's ratings and taking the absolute value. Trials with response times >2.5 standard deviations outside the mean were excluded from the behavioral and imaging analyses. Each regressor was convolved with a custom HRF, which was individually estimated for each participant from their primary visual activity ( ); custom HRFs have been shown to reduce both model error ( ) and bias ( ) relative to the canonical HRF. A fixed effects (2nd level, within subject) and a mixed-effects (3rd level, between subjects) analysis was done to compare patients with controls for the trust and fear appraisal regressors. We performed two ROI analyses of the amygdala. First, we created a mask by searching the Neurosynth database ( ) using the keyword “threat”. The reverse inference map was thresholded at 7 and binarized resulting in a bilateral amygdala mask positioned primarily over the lateral nuclei of the amygdala (MNI: −22, −2, −20; 24, −4, −20). A second analysis was performed subject-specific masks of threat-sensitive voxels. These voxels were identified as voxels modulated by subjective appraisal of fearfulness, thresholded at >1.6) and intersected with a whole amygdala mask. Both the Neurosynth mask and the subject-specific mask were used to average the parameter estimates of the masked voxels during trustworthiness appraisal. The Kolmogorov-Smirinov Test was used test for deviations from Normality for all   t  -tests (Supplementary Results). Cohen's D (  d  ) was computed as the group mean divided by sample standard deviation. 


#### Assumptions 
  
Our goal was to determine whether subjective appraisal of trustworthiness depends on threat signals generated by the amygdala. We assumed that fearfulness appraisal elicits threat signals in the amygdala and that any activity in the amygdala that increased with untrustworthiness would also represent a threat signal. Given these assumptions, if our paradigm could generate threat signals in the amygdala using fearful stimuli, it should also be able to generate amygdala threat signals using untrustworthy stimuli. Furthermore, since BPD is associated with elevated sensitivity to social threat and a bias toward judging others as untrustworthy, BPD subjects should show elevated threat activity in the amygdala compared to controls using untrustworthy stimuli. 




## Results 
  
Consistent with our previous study ( ), the BPD group showed a response bias to judge faces as untrustworthy (  t  -test of bias: control, M = 1.6, SD = 0.15; BPD, M = 2.1, SD = 0.16, t(28) = 2.44, z = 3.23, p = 0.02) and had a smaller dynamic range, or, sensitivity (t-test for scale: control, M = 3.08, SD = 0.41; BPD, M = 1.71, SD = 0.23, t(28) = 2.8, z = 3.98, p < 0.01). Trustworthiness appraisal did not result in significant group differences in discriminability ( ). Appraisal of fearfulness did not show any significant group differences for bias (p = 0.47), sensitivity (p = 0.14), or discriminability (p = 0.49). An analysis of variance showed that the BPD group exhibited longer RTs than controls ( ) for trustworthiness (rating, p = 0.002; group, p < 0.0001) and fearfulness (rating, p < 1 × 10 ; group, p = 0.007), and no significant interactions.   
Appraisal of trustworthiness and fearfulness. (A) For both tasks, participants demonstrated categorical judgments (i.e. a sigmoidal, monotonically increasing relationship). Behavioral responses were fit with logistic functions using three parameters: offset, scale, and slope. A comparison of the three parameters showed that, consistent with our previous work, the offset parameter in the trustworthiness task was significantly higher in the BPD group, indicating a bias toward judging others as “untrustworthy.” In addition, the scale parameter was smaller for BPD than controls, indicating a reduced dynamic range of responses. Remaining parameters for the two tasks were not significantly different. (B) Response times were greater for patients than controls on both tasks (ANOVA). 
  Fig. 1   

To identify the neural structures associated with the two types of appraisals, we performed a whole brain analysis, regressing the appraisal ratings made by each subject on the BOLD data. Consistent with most fMRI studies of fear processing ( ;  ), both amygdalae were robustly modulated by subjective appraisals of the fearful stimuli – BOLD magnitude increased as a function of the subjective rating of intensity of the stimulus ( A; peak response, MNI: 24, −8, −14, Z = 3.83; −24, −4, −14, Z = 3.56; Supplementary Table 2). If the threat-related cues detected by the amygdala are also important for trustworthiness appraisal, then amygdala activity should be modulated by trustworthiness. However, the whole brain analysis showed no activity in the amygdala that was significantly modulated by stimulus trustworthiness ( B; Supplementary Table 2).   
Monotonically increasing activity. (A) Robust, bilateral activation of the amygdala increased with fearfulness of the stimulus across all participants. A similar, monotonically increasing relationship with untrustworthiness was not present. (B) For each subject, a mask was created representing voxels sensitive to fearfulness within the amygdala and the mean of the parameter estimates was computed. No significant relationship for trustworthiness was present for control or BPD participants, suggesting that untrustworthy stimuli do not produce an amygdala-based fear response. Finally, during trustworthiness appraisal, amygdala activity in BPD participants showed a small, but significant, reduction of response, contrary to the amygdala hyperactivity found in previous BPD studies. 
  Fig. 2   

Averaging across voxels can improve the signal to noise ratio; thus, we performed an ROI analysis of the amygdala using a mask generated on Neurosynth using the keyword “threat”. In healthy controls, the mean activity of voxels within the mask showed robust amygdala modulation by subjective fear ratings (p = 0.01, d = 0.70) but contrary to previous work ( ;  ), no significant modulation by subjective trust ratings (p = 0.33, d = 0.25). In the BPD group, no significant activity was detected either by fear (p = 0.33, d = 0.25) or trust (p = 0.56, d = −0.15) ratings. Since BPD is associated with elevated sensitivity to interpersonal threats ( ;  ), if the amygdala were sensitive to untrustworthiness, then BPD subjects should show greater amygdala activation than controls as the stimuli become less trustworthy. However, a comparison of the two groups showed no significant difference between groups for trust (p = 0.26, d = 0.40) or fear (p = 0.33, d = 0.35).  .   
Quadratically modulated activity. (A) A weak, but significant, quadratic relationship with fearfulness was present in the amygdala. Some voxels with a quadratic relationship to trustworthiness were detected on the striatum-amygdala and csf-amygdala boundaries, though the peak responses of these clusters were outside the amygdala. (B) Using an amygdala mask, the mean response was quadratically related to fearfulness, but not trustworthiness. 
  Fig. 3   

Previous studies have suggested that the effect of trustworthiness appraisal on amygdala activity in healthy controls is best described by a quadratic relationship ( ), ( ;  ). Though our controls showed a significant quadratic relationship for fear (p = 0.04, d = 0.53), no significant quadratic relationship for trust (p = 0.80, d = 0.06) was found. In the BPD group, the quadratic model was not significant for fear (p = 0.68, d = 0.18), but was significant for trust (p = 0.02, d = 0.65). 

To determine whether the two tasks activate similar brain networks, we compared whole-brain activations ( A). Fearfulness appraisal activated primarily sub-cortical regions, whereas trustworthiness appraisal was associated primarily with cortical activity. To dissociate activity specific to fearfulness and trustworthiness appraisal from general decision-making activity related to stimulus intensity, we performed a contrast between task conditions (contrasting fearfulness > trustworthiness and trustworthiness > fearfulness on the appraisal regressor;  B). Using a cluster threshold of p = 0.001, fearfulness > trustworthiness did not result in significant activations. However, because the amygdala nuclei are small structures, p = 0.001 may result in elevated Type II error in subcortical structures. At a cluster threshold of p = 0.05, fearfulness-specific activity was localized to subcortical regions, i.e., amygdala and ventral striatum (peak response, MNI: 22, −6, −8), consistent with the previous ROI analysis (i.e.  ). Moreover, even at a more liberal threshold, no fearfulness-specific activity in the cortex was detected. In contrast, trustworthiness-specific activity was present only in cortical regions, broadly distributed across posterior parietal cortex, and dorsolateral and mediolateral prefrontal cortex, and no spatial overlap of amygdala (Supplementary Table 3).   
Whole brain comparison. (A) A whole-brain analysis demonstrates that the monotonic fearfulness response activates primarily subcortical structures i.e. amygdala and ventral striatum, whereas, the trustworthiness response was primarily cortical. (B) To identify activity unique to fearfulness and trustworthiness, and not to general decision processes common to both tasks, fearfulness > trustworthiness and trustworthiness > fearfulness contrasts were performed. Fearfulness-specific activity was localized to amygdala, ventral striatum, and left frontal pole. There was no trustworthiness-specific activity in subcortical structures. 
  Fig. 4   

Because BPD is associated with behavioral abnormalities in trustworthiness appraisal, we hypothesized that the trustworthiness-specific network (i.e. trustworthiness > fearfulness) would show activity differences between BPD and control subjects. We, thus, performed the following contrast: (trustworthiness > fearfulness)  > (trustworthiness > fearfulness) . BPD participants had lower trustworthiness-specific activity in prefrontal cortex ( A), especially anterior insula and lateral PFC (Supplementary Table 3). Finally, to determine whether these group differences were related to individual subjects' decision variables, we intersected voxels that showed activity specific for trustworthiness appraisal ( B, trustworthiness > fearfulness) with voxels that differed between groups (5A, (trustworthiness > fearfulness)  > (trustworthiness > fearfulness) ) and compared them to individual differences in response bias and sensitivity. The anterior insula and lateral PFC ( B) activity was related to the degree of bias (  r   = 0.457, p = 0.007) and sensitivity (  r   = 0.597, p = 0.0005) impairment in trustworthiness appraisal ( C), such that, the weaker the network activity, the greater the bias toward untrustworthy ratings and the smaller the range of responses.   
BPD-related deficits. (A) BPD participants showed reduced trust-specific activity in the anterior insula and lateral prefrontal cortex. (B) The intersection of voxels that were sensitive to trustworthiness and significantly reduced in BPD localized to anterior insula and lateral prefrontal cortex. (C) These intersecting voxels were negatively related to bias (i.e. the greater the bias toward mistrusting others, the larger the reduction in activation) and positively correlated to scale (i.e. the smaller the dynamic range of responses, the larger the reduction in activation). Dashed lines represent 95% confidence interval. 
  Fig. 5   


## Discussion 
  
The amygdala is an integral part of the threat detection system in humans ( ;  ;  ), and to the extent that untrustworthy faces represent interpersonal threats, investigators have argued that the amygdala is integral to the appraisal of trustworthiness in non-clinical adults ( ;  ;  ). Furthermore, individuals with BPD have been shown to have response biases toward mistrusting others ( ;  ;  ) and hyperactive responses of the amygdala to emotional stimuli ( ;  ;  ;  ). Our goal was to test whether amygdala hyperactivity could explain the response biases in BPD during the appraisal of trustworthiness ( ;  ;  ). Surprisingly, we found no relationship between trustworthiness appraisal and amygdala activity, and no difference in amygdala activity between BPD and control participants. Instead, trustworthiness appraisal deficits in BPD were associated with blunted prefrontal activity in anterior insula and lateral PFC compared to controls. 

Evidence that trustworthiness activates the amygdala has been inconsistent. Studies that categorically compared trustworthy versus untrustworthy stimuli typically find greater amygdala responses to untrustworthy faces ( ;  ;  ;  ). Similarly, some parametric studies have demonstrated that amygdala activity increases monotonically with untrustworthiness ( ;  ). However, others found a quadratic, not monotonic, relationship, between trustworthiness and amygdala responses ( ;  ). Contrary to these previous studies, we found no evidence that amygdala activity increases monotonically or quadratically with untrustworthiness in healthy controls. This lack of response was not due to sensitivity of our behavioral paradigm. In fact, consistent with our previous studies ( ;  ;  ), our behavioral data showed a sigmoidal relationship between stimulus and response, and a response bias in BPD for judging stimuli as less trustworthy, but not more fearful. Moreover, the trustworthiness-stimuli were psychometrically discriminable by both groups with a dynamic range similar to the fearful stimuli and the fearful stimuli elicited robust, bilateral amygdala responses that scaled parametrically with subjective intensity. This suggests that if trustworthiness decisions depended on threat-related amygdala activity, modulation of amygdala by trustworthiness would have been detectable with our paradigm. 

Previous parametric studies focused mostly on “implicit,” or sub-conscious, processing of trustworthiness, distracting subjects from the trustworthiness dimension with an irrelevant task ( ;  ;  ) or using very short (200 ms) stimulus durations ( ). While implicit trustworthiness processing is commonly referred to as “trustworthiness decisions,” it is not clear that any amygdala activity that is correlated with trustworthiness, but also lacks an associated behavioral response, actually represents a decision process. Instead, this activity is more likely to be related to low-level, perceptual processing ( ;  ;  ;  ;  ;  ;  ). In fact, trustworthiness has been shown to be decomposable into two perceptual factors – dominance and emotional valence, where emotional valence is expressed as facial features ranging from happy to angry ( ;  ). However, while anger has been shown to represent a cue for untrustworthiness, a meta-analysis of 105 imaging studies has not found it to reliably activate the amygdala ( ). Moreover, because the amygdala generally responds to emotional faces ( ), even at sub-threshold levels ( ;  ;  ;  ;  ;  ;  ), the implicit or rapid processing of trustworthiness by the amygdala may actually reflect the emotional valence detectable in the stimulus rather than the appraisal of trustworthiness per se. 

Facial cues associated with low trustworthiness are not necessarily reliable or immediate expressions of threat, compared to reliable cues such as an image of a snake or a pointed gun. Rather, trustworthiness appraisal may be better conceptualized as a probabilistic prediction about the likelihood of interpersonal betrayal or exploitation by others. Probabilistic reasoning, especially in social contexts, has been associated with prefrontal cortical processing ( ;  ;  ). Our results show that trustworthiness is mediated by prefrontal cortical (posterior parietal cortex, anterior insula, and lateral PFC) activity and that trustworthiness appraisal deficits in BPD are also mediated by the same regions. 

The trustworthiness appraisal impairments identified here may help elucidate mechanisms of turbulent relationships in BPD. Individuals with BPD maintain unstable interpersonal ties, as they oscillate between establishing new relationships and ending them ( ). Some of the most high risk diagnostic criteria of BPD such as self-injury, suicidality, intense and inappropriate anger, impulsivity, and heightened emotional sensitivity are mediated by the quality of interpersonal bonds between the person with BPD and significant others ( ). Facial expressions within in interpersonal contexts are salient stimuli, and can anticipate mistrust and the expectation of rejection ( ;  ;  ;  ). Consequently, the trustworthiness appraisal impairments in BPD can increase their propensity interpersonal conflicts, lead to uncooperative exchanges in social interactions, threaten the formation of new relationships, and undermine long-term relationships. The trustworthiness discriminability impairment mediated by prefrontal cortex processes may help clinicians to understand commonly observed interpersonal dynamics in BPD. For instance, individuals with BPD often reflexively enter into new relations with questionable partners, while simultaneously expressing extreme caution and suspiciousness toward presumably helpful and supportive others. 

Improving accurate appraisal of trustworthiness in interpersonal and therapeutic relationships in BPD may be crucial to therapeutic improvement, and dissociating the roles of prefrontal cortex and amygdala in trustworthiness appraisal may aid in sharpening intervention targets. Prominent, evidence-based therapies for BPD such as Transference Focused Psychotherapy (TFP, ( )) and Mentalization-Based Therapy (MBT, ( )), focus implicitly and explicitly ( ) on enhancing trustworthiness appraisal by fostering frontally-mediated social reappraisal processes. However, there may yet be untapped strategies and interventions that those with BPD, such as improving accurate probabilistic reasoning around trustworthiness appraisals. 

### Limitations 
  
Without a psychiatric control group, the specificity of the trustworthiness impairment findings has yet to be established. However, we have published work using the same trustworthiness and fear tasks in a PTSD sample compared to a trauma-exposed/no PTSD control group and a healthy control group. The PTSD group showed a response bias toward judging stimuli as more trustworthy compared to the trauma-exposed controls ( ). This is opposite to our BPD findings, which show a bias toward less trustworthy appraisals, and suggests some clinical specificity of our results. Finally, although our BPD sample has relatively few co-morbidities, the mean Global Assessment of Functioning (GAF) score of the group was 55.12, consistent with multi-site, longitudinal studies of BPD ( ) and suggesting that our BPD group had comparable severity of illness. 


### Conclusions 
  
In summary, we found no evidence of amygdala hyperactivity in BPD subjects during appraisal of trustworthiness. Our results show, however, that trustworthiness biases in BPD involve higher order prefrontal cortical regions. 

Additionally, further study is needed to clarify impact of emotional expressions (e.g., appraisal of anger in facial stimuli may overlap with untrustworthiness perception) on trustworthiness appraisal and amygdala activity in BPD and comparison groups. 


 </div>
</div>
</div>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-56' name='judgment-56' value='agree'>
<label for='agree-56'>Agree</label>
<input type='radio' id='disagree-56' name='judgment-56' value='disagree'>
<label for='disagree-56'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-56' name='comment-56' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-57'>
<h2>57. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/26302673/' target='_blank'>26302673</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social cognition (race-based impression formation) using a task-evoked impression-formation paradigm assessing perception/understanding of others. Sample comprises healthy adult participants (Caucasian Americans aged 19–34; N=44 after exclusions), meeting the age and health criteria. The paper reports group-level, univariate whole-brain task contrasts and tables of peak coordinates (see Table 2 and Table 3) and describes whole-brain exploratory regression results (thresholds, cluster-correction via AlphaSim), satisfying the whole-brain evidence requirement. The study also includes ROI analyses but crucially provides univariate, group-level whole-brain activation maps/contrasts for the healthy/control group. No exclusion criteria (ROI-only, connectivity-only, non-healthy sample, or non-empirical) apply. Therefore it meets all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-57' name='judgment-57' value='agree'>
<label for='agree-57'>Agree</label>
<input type='radio' id='disagree-57' name='judgment-57' value='disagree'>
<label for='disagree-57'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-57' name='comment-57' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-58'>
<h2>58. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/23142071/' target='_blank'>23142071</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is a task-based fMRI study of social perception (emotional facial expressions) including a healthy adult human sample (n=23, ages 24–34). The paper reports group-level, random-effects whole-brain univariate analyses with voxelwise maps and cluster correction, includes stereotactic coordinates and figures, and presents results for the healthy control group separately from the monkey data. Thus it meets all inclusion criteria (social-related fMRI task; healthy adult sample within 17–65; whole-brain group-level task activation maps).</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-58' name='judgment-58' value='agree'>
<label for='agree-58'>Agree</label>
<input type='radio' id='disagree-58' name='judgment-58' value='disagree'>
<label for='disagree-58'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-58' name='comment-58' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-59'>
<h2>59. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31747689/' target='_blank'>31747689</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of action perception—clearly within ‘Perception and Understanding of Others’ (social-related processing). It reports task-evoked, group-level voxelwise whole-brain analyses (e.g., ActionOBS–CtrlOBS and weight-discrimination contrasts) with thresholded statistical maps and localization, described for healthy adult participants across three experiments (total N=79) and separate analyses comparing healthy controls to SCA6 patients. Healthy adult results are reported independently of clinical groups. The paper therefore meets: (1) social-related fMRI task, (2) healthy adult sample in the 17–65 range, (3) whole-brain univariate group-level voxelwise maps, and (4) no exclusion criteria (not ROI-only, not connectivity-only, and includes healthy-group whole-brain effects).</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-59' name='judgment-59' value='agree'>
<label for='agree-59'>Agree</label>
<input type='radio' id='disagree-59' name='judgment-59' value='disagree'>
<label for='disagree-59'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-59' name='comment-59' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-60'>
<h2>60. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/25885446/' target='_blank'>25885446</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study in healthy adults (19 pairs; 38 individuals; ages 18–33) using a face-to-face eye-contact task—clearly a social-related paradigm (social interaction/mentalizing). The paper reports group-level, voxelwise GLM results for Task A and B and paired t-test contrasts to define exogenous/endogenous systems, with whole-brain statistical maps (thresholds reported, cluster reporting, atlas labels, MNI coordinates). Whole-brain, univariate task-evoked maps are described and used to create CCRI masks; atlas labels and coordinates are provided. The sample falls within the 17–65 age range and results for the healthy group are reported. The study is not ROI-only, not resting-state only, and presents generalizable group maps. Therefore it meets all inclusion criteria and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-60' name='judgment-60' value='agree'>
<label for='agree-60'>Agree</label>
<input type='radio' id='disagree-60' name='judgment-60' value='disagree'>
<label for='disagree-60'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-60' name='comment-60' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-61'>
<h2>61. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/23267322/' target='_blank'>23267322</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI task study of social cognition contrasting interactive vs. observational conditions using dynamic video stimuli. Sample: 22 healthy adult participants (mean age 25) within the 17–65 range. Group-level, task-evoked analyses were conducted (two group RFX whole-brain ANOVAs) and reported; although ROI small-volume corrections were emphasized for main effects, the authors also report exploratory whole-brain results (early visual/V1) and describe group-level task effects thresholded at p<0.05 FWE. Thus the paper reports univariate, group-level task-evoked maps from healthy adults during a social-related task and meets the inclusion criteria (not limited to ROI/connectivity-only results).</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-61' name='judgment-61' value='agree'>
<label for='agree-61'>Agree</label>
<input type='radio' id='disagree-61' name='judgment-61' value='disagree'>
<label for='disagree-61'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-61' name='comment-61' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-62'>
<h2>62. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/28583386/' target='_blank'>28583386</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is a task-based fMRI study in healthy adult participants (N=34 males, ages 19–31 and 22–29), well within the 17–65 range. The task probes social processing (vicarious embarrassment/fremdscham and schadenfreude) — directly relevant to social-affective/Perception and Understanding of Others constructs. The paper reports group-level, univariate whole-brain task contrasts (SIT>NEUT) with FWE-corrected results and tables of activations (Table 1), and describes within-group parametric modulators and second-level random-effects GLMs. It is not ROI-only, not resting-state/ connectivity-only, and healthy-group whole-brain effects are clearly reported. Therefore it meets all inclusion criteria and violates no exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-62' name='judgment-62' value='agree'>
<label for='agree-62'>Agree</label>
<input type='radio' id='disagree-62' name='judgment-62' value='disagree'>
<label for='disagree-62'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-62' name='comment-62' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-63'>
<h2>63. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22125232/' target='_blank'>22125232</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of affective (social) touch in a sample of 22 healthy adults aged 19–35. The task targets social-affiliative touch (C-tactile/affective touch), which falls squarely under social-related processing. The paper reports group-level, whole-brain univariate task contrasts (arm > baseline, palm > baseline, and arm > palm) with voxelwise thresholds, cluster corrections, and tables of peak coordinates and figures. Results for the healthy adult group are reported separately and are generalizable to healthy adults. No exclusion criteria are met (not ROI-only, not connectivity-only, includes whole-brain task activations, participants within age range). Therefore the study meets all inclusion criteria for the review.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-63' name='judgment-63' value='agree'>
<label for='agree-63'>Agree</label>
<input type='radio' id='disagree-63' name='judgment-63' value='disagree'>
<label for='disagree-63'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-63' name='comment-63' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-64'>
<h2>64. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/30624029/' target='_blank'>30624029</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study in healthy adults (ages 18–22) using an explicitly social task (iterated Prisoner’s Dilemma). The paper reports group-level, voxelwise whole-brain univariate GLM analyses (thresholded Z images and cluster-corrected results) and provides coordinates/tables/figures describing these effects in the healthy sample (OT vs placebo and genotype-restricted analyses). All inclusion criteria are met (social task, healthy adult sample, whole-brain task-evoked maps reported). No exclusion criteria apply (not ROI-only, not resting-state/connectivity only, healthy-group results clearly reported).</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-64' name='judgment-64' value='agree'>
<label for='agree-64'>Agree</label>
<input type='radio' id='disagree-64' name='judgment-64' value='disagree'>
<label for='disagree-64'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-64' name='comment-64' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-65'>
<h2>65. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/27109357/' target='_blank'>27109357</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study in healthy adult participants (age range 19–38; fMRI subsample n=163) using a social interactive task (Prisoner’s Dilemma) that elicits mentalizing/social cognition. The paper reports whole-brain, group-level univariate task contrasts (ment > cont) and provides whole-brain activation results (tables/figures and cluster-level FWE-corrected maps) for the healthy sample. Results are not limited to ROI-only or connectivity/resting-state analyses. All inclusion criteria are met and no exclusion criteria apply (healthy adults, task-evoked whole-brain maps reported).</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-65' name='judgment-65' value='agree'>
<label for='agree-65'>Agree</label>
<input type='radio' id='disagree-65' name='judgment-65' value='disagree'>
<label for='disagree-65'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-65' name='comment-65' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-66'>
<h2>66. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/24760733/' target='_blank'>24760733</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of face perception (Perception and Understanding of Others), a social-related process. Participants: 25 healthy adults (mean age 25.24), within 17–65. The paper reports group-level, voxelwise whole-brain task contrast (natural-colored face vs natural-scrambled) with peak coordinates, cluster sizes (Table 1) and figures, i.e., univariate whole-brain activation maps generalizable to healthy adults. Although ROI analyses are also presented, whole-brain results are explicitly reported. No exclusion criteria are met (not ROI-only, not connectivity/resting-state only, healthy adult group reported separately). Therefore the study meets all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-66' name='judgment-66' value='agree'>
<label for='agree-66'>Agree</label>
<input type='radio' id='disagree-66' name='judgment-66' value='disagree'>
<label for='disagree-66'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-66' name='comment-66' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-67'>
<h2>67. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/24412687/' target='_blank'>24412687</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI task study of social processing (multiround Ultimatum Game). It includes a healthy adult group (n=15; ages 19–28) reported separately from child and adolescent groups. The paper reports group-level, whole-brain univariate analyses: one-sample t-tests per group and between-group full-factorial ANOVAs, and the primary contrast (unfair > fair offers) is presented with whole-brain statistical maps and coordinate tables (Table 1) thresholded at p<.001 uncorrected. Results for the healthy adult group are explicitly reported and generalizable to healthy adults (within the 17–65 range). The study is empirical and provides whole-brain task-evoked activation maps/coordinates for the healthy adult sample, so it meets all inclusion criteria and does not violate exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-67' name='judgment-67' value='agree'>
<label for='agree-67'>Agree</label>
<input type='radio' id='disagree-67' name='judgment-67' value='disagree'>
<label for='disagree-67'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-67' name='comment-67' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-68'>
<h2>68. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/28455517/' target='_blank'>28455517</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Neural Activity while Imitating Emotional Faces is Related to Both Lower and Higher-Level Social Cognitive Performance</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Sci Rep</p>
<p><strong>Publication Year:</strong> 2017</p>
<p><strong>DOI:</strong> 10.1038/s41598-017-01316-z</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5430668/' target='_blank'>5430668</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Meets inclusion criteria: (1) Uses task-based fMRI of social processing (imitate/observe emotional faces — social perception/affiliation/communication). (2) Sample comprises healthy adults (initial N=28, final N=20 after preprocessing; ages 18–55 within 17–65 range) with group-level analyses reported. (3) Provides whole-brain, voxelwise results: authors ran a GLM in SPM8 (reported as showing similar whole-brain activation patterns; Supplementary Figure 1) and present whole-brain voxel maps from the PLS analysis (voxelwise bootstrap ratio maps). Not ROI-only or connectivity-only. No exclusion criteria violated. Therefore include as an fMRI whole-brain study of social processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Imitation and observation of actions and facial emotional expressions activates the human fronto-parietal mirror network. There is skepticism regarding the role of this low-level network in more complex high-level social behaviour. We sought to test whether neural activation during an observation/imitation task was related to both lower and higher level social cognition. We employed an established observe/imitate task of emotional faces during functional MRI in 28 healthy adults, with final analyses based on 20 individuals following extensive quality control. Partial least squares (PLS) identified patterns of relationships between spatial activation and a battery of objective out-of-scanner assessments that index lower and higher-level social cognitive performance, including the Penn emotion recognition task, reading the mind in the eyes, the awareness of social inference test (TASIT) parts 1, 2, and 3, and the relationships across domains (RAD) test. Strikingly, activity in limbic, right inferior frontal, and inferior parietal areas during imitation of emotional faces correlated with performance on emotion evaluation (TASIT1), social inference - minimal (TASIT2), social inference - enriched (TASIT3), and the RAD tests. These results show a role for this network in both lower-level and higher-level social cognitive processes which are collectively critical for social functioning in everyday life. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (34238 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Social interactions are complex processes which are built upon the perception and understanding of the actions, intentions, and mental state of others. Social cognitive neuroscience has suggested a dichotomy between low-level processes such as understanding motor actions or emotional processing and higher-level processes such as inferring the mental states of others (e.g. theory of mind) or detecting deception and sarcasm. This apparent dichotomy between lower level and higher level social cognitive processes is supported by behavioral , neuroimaging  and lesion studies . Neuroimaging studies have primarily examined these processes with two approaches: using tasks relevant to the perception of and interaction with other people’s actions (action observation and imitation), and using tasks relevant to infer the beliefs and desires of the other person (mentalizing). Lower level social cognitive processes such as action interpretation have been associated with activation of a lateral frontal-parietal network, the putative human analogue to the mirror neuron system observed in monkeys . Higher-level social cognitive processes, such as theory of mind, have been associated with activation of cortical midline regions, including the medial prefrontal cortex, posterior cingulate cortex, and precuneus, as well as temporoparietal junction and temporal pole. This network is also known as the ‘mentalizing’ system. Dual processing models have been proposed in which the lateral fronto-parietal network supports relatively automatic processes such as identifying motor actions while the mentalizing network supports controlled processes of attributing actions to complex social causes . 

Most neuroimaging studies examining the lateral fronto-parietal network have made use of hand actions or other forms of simple motor stimuli . As such, the role of this system has been mainly considered in the context of perceiving gross motor actions. Some have taken the concept of mirroring one step further, by arguing that the lateral fronto-parietal network is important for emotional empathy by permitting humans to feel what others feel, and potentially to assess or interpret emotional cues and social behaviour . Investigating this issue may be best served by paradigms utilizing socially relevant stimuli as opposed to simple motor acts. One such paradigm is the imitation and observation of emotional faces, which has been shown to activate the lateral fronto-parietal ‘mirror’ network . This is consistent with the notion that activation of this network can play a role in allowing people to empathize by imitating emotions . Activity in the right IFG has been positively correlated with self-report measures of empathy in healthy children , and has been shown to be more active in normally developing children than those with autism , with activity in autistic children inversely correlated with social impairment. However, the IFG has also been implicated in some higher level social cognitive processes, specifically the inhibiting self-perspective in social judgements . Recent work has also shown structural changes in right fronto-parietal cortex in more socially impaired people with schizophrenia , a group of individuals in whom higher-level social cognitive processes such as theory of mind are more prominently affected . These findings raise the question of whether neural activation during basic mirroring tasks is related to higher-level social cognitive abilities. 

Meta-analysis of fMRI data has shown little overlap between activity in the brain regions associated with the mirroring and mentalizing systems across a range of tasks , and brain lesion studies have suggested a dissociation between mirroring and mentalizing regions . As such, mirroring and mentalizing were initially thought to represent dichotomous systems which function relatively independently, and the role of mirroring in higher-level social cognition is a contentious issue . However, there is a growing body of evidence that the mentalizing and mirroring systems may interact during more complex social cognitive processing, such as watching social videos . Co-activation of mentalizing and mirroring regions has also been noted when viewing agents performing irrational actions, suggesting aspects of the mentalizing system may facilitate interpreting unexpected actions . The mirroring and mentalizing system may work together during social cognitive processing, although a specific role of the mirror system in higher-level cognitive processing has yet to be established. 

The purpose of this study is to determine whether brain regions activated during a facial emotion mirroring task are related to lower-level social cognitive performance, higher-level social cognitive performance, or both. We utilized a process specific social mirroring task (the facial imitate/observe task ) inside the fMRI, along with a battery of objective out-of-scanner social tests ranging from basic emotional-perception tasks to complex higher level social cognitive tasks such as detection of lies or sarcasm. Brain-behavior relationships were examined using the spatio-temporal partial least squares (PLS), a non-parametric multivariate approach . PLS identifies latent variables (LVs), linear combinations of fMRI signal amplitude at each voxel across time and a design matrix which can consist of either experimental conditions or correlations across conditions with behavioral scores. Each LV expresses a pattern of the common covariance between the design and the fMRI data. PLS is designed to handle data with high collinearity while simultaneously capturing essential non-redundant relationships among the data , overcoming the confounding influence of collinear variables in traditional multiple regression . This makes PLS an excellent approach to uncover relationships between brain activity and a set of social cognitive scores which are likely highly interrelated. We hypothesized that a) consistent with previous studies, imitating emotional faces would activate the mirroring network, more prominently in the imitate than the observe condition, and b) neural activity during imitation of emotional faces specifically (rather than imitating neutral faces or observing faces) would be associated with both lower-level and higher-level social cognitive performance. 


## Results 
  
### Task Effects 
  
Task PLS is a multivariate model-free approach to identify spatial patterns which share relationships across the experimental conditions. A task PLS was run on the data to replicate previous task-based analysis, and examine the underlying pattern of task task-evoked spatial activity. PLS generated 6 LVs (as there were three trial types, emotional faces, neutral faces, and fixation, and two conditions, Imitate and Observe). Permutation analysis (see methods below) showed significance (p < 0.05) in the first three LVs, which accounted for 61.6%, and 14.5%, and 12.9% of crossblock covariance respectively (Fig.  ). LV 1 was related to viewing faces as opposed to fixation trials, and showed a pattern related to the lateral frontal-parietal network similar to the results of previous studies . LV 1 was related to viewing faces in general rather than distinguishing between emotional and neutral faces, demonstrating that this pattern of faces >fixation in the mirroring network is the dominant pattern of neural activity within this task analysis. LVs 2 and 3 explain some of the remaining variance in the data not accounted for the pattern presented in LV 1, representing interaction effects showing different patterns of activity across the Imitate and Observe conditions. LV 2 shows a large amount of overlap with LV 1, suggesting some of the variance within those regions is explained by aspects of both LVs 1 and 2. The majority of the variance explained by LV 1, but some additional variance within those voxels is explained by the pattern of emotional faces >neutral and fixation in Imitate and increased activity in fixation trials for Observe, as seen in LV 2. LV 3 represents an interaction in which the relative effects of neutral faces and fixation are different in the Imitate and Observe tasks.   
Results from the first latent variable using task PLS analysis. Data is shown for LV1, 2 and 3. The top panel shows the design pattern (the contribution of each condition to the LV). Error bars are 95% confidence interval derived from the bootstrap analysis. The bottom panel shows the voxel pattern from the first lag of the PLS analysis rendered on the cortex. Sagittal slices are shown for X = −10 (left) and X = 10 (right). Voxel intensity is displayed as bootstrap ratio, a measure of reliability of voxels within the LV. Red-yellow regions show the pattern described by the design pattern, while blue regions show the opposite pattern. 
  

For consistency and replication of previous studies, we also ran a general linear model (GLM) in SPM8. The GLM showed a similar pattern as in previous studies and LV1 of the task PLS (see supplementary methods and Supplementary Figure 1). 


### Behavioral PLS 
  
Behavioral PLS examined the relationships between patterns of activity in the brain and social cognitive test scores. Scores from six social cognitive tasks were included: the Emotion Recognition (ER40) , the Reading the Mind in the Eyes Test, RMET , the Relationships Across Domains test (RAD) , and the three subtests of the Awareness of Social Inference Test Revised (TASIT-R) . TASIT1 can be considered a test of lower-level social cognitive functioning, while TASIT2 and TASIT3 are high-level tests. The behavioral PLS generated 36 LVs, as there were six experimental conditions (emotional faces, neutral faces, and fixation, separately for Imitate and Observe, and six social cognitive tests). Overall permutation analysis showed significance in the first two LVs, which accounted for 23% and 13.2% of crossblock covariance respectively. However, the split-half permutation reliability analysis (see methods) demonstrated that the relationship between the design pattern and brain pattern was not reliable within LV 1 and as such it was not considered further. In LV 2, neural activity during imitation of emotional faces was positively correlated with RAD, TASIT1, TASIT2, and TASIT3 (Fig.  , top panel). Neural activity for Fixation and Neutral faces during Imitate, as well as Neutral faces during Observe, was negatively correlated with those same test scores. As such, LV 2 shows a pattern of correlations during the imitation of emotional faces related to performance on TASIT1, TASIT2, TASIT3, and RAD.   
LV 2 of the behavioral PLS results. (  A  ) Design pattern showing the pattern of correlations between brain signal for each during event type and each behavioral score within the voxel pattern. Error bars represent 95% confidence interval based off a bootstrapping analysis of 1000 iterations. (  B  ) Voxel patterns for each lag, displayed as bootstrap ratio on the MNI152 brain. Data is shown for two sagittal views as well as rendered onto the cortex (8 mm search depth) to better visualize cortical activity. Red-yellow shows a correlation pattern matching the design pattern (  A  ), while blue regions show the opposite pattern. Each lag represents a time point (TR) following stimuli onset (which occurred during ‘Lag0’). 
  

The pattern of brain activity in LV 2 (Fig.  , bottom panel) when imitating emotional faces in lag 1 showed a positive relationship with performance on TASIT1 TASIT2, TASIT3, and RAD. Activity was present in right pars opercularis (within inferior frontal gyrus), right and left supramarginal gyrus, right motor cortex, bilateral anterior temporal regions, fusiform gyrus, and parahippocampal cortex. Activity was also noted in right anterior/mid cingulate, right rolandic operculum, right putamen, and the cerebellum. Activity in lags 4 and 5, which positively correlated with social cognitive performance, was notably present in anterior temporal regions as well as in posterior middle and inferior right temporal gyri. Several regions showed negative relationships to the design pattern (thus greater fMRI activity while imitating emotional faces in individuals with poorer social cognitive performance), including the left inferior frontal gyrus (pars operculum and pars triangularis), and bilaterally in the basal ganglia (greatest in left putamen and right globus pallidus). 



## Discussion 
  
The behavioral PLS results of this study showed a robust relationship between neural activity during a process-specific imitate-observe task and both lower-level and higher-level social cognitive performance. While a growing number of studies using complex stimuli have noted co-activation of mirroring and mentalizing regions , co-activity cannot be taken to conclude that mirroring has a strong role in higher level social cognition. The novelty of our study is that we showed complex relationships of neural activity during a simple and process-specific mirroring task with performance on objective out-of-scanner assessments of higher-level social cognitive performance. In addition, the PLS approach allowed us to include several assessments in a single analysis, providing data driven evidence of which assessments best capture these brain-behaviour relationships. These behavioral relationships were specific to imitation of emotional faces, rather than neutral faces. Several regions outside the right fronto-parietal circuit, including left IFG and some mentalizing regions (e.g. TPJ), also showed negative correlations with social cognitive performance, suggesting either compensatory responses or over-activation in participants with poorer social cognition. 

These findings of a relationship between activity in a simple mirroring task and higher level social cognitive processing scores suggest a relationship for the mirror network in higher-order social cognitive processing including complex tasks. Effective mentalizing in humans although likely primarily reliant on classic mentalizing regions may be further subserved by mirroring regions . Given that the relationships elicited were noted in assessments involving interpretation of dynamic interactive video tasks including human actors, it may be that such relationships are only evoked when we consider social cognition as a process involving integrating information from multiple processing levels. The mirroring network may not be solely for understanding the intentions and physical goals of motor acts . Our findings add to the debate regarding the role of this network in social cognition . Several authors have argued that this network is important not only for imitation or action perception, but also for emotional empathy and possibly even in cognitive empathy (sometimes used interchangeably with theory of mind) , consistent with the theory of embodied simulation , despite debate to the contrary . Through the combination of a process-specific in-scanner task, more naturalistic and objective social cognitive tests, and the PLS multivariate framework, we were able to uncover essential brain-behavior relationships for which traditional task contrasts or linear regression analyses may be less sensitive. 

Higher level social cognitive processing involves concepts related to both theory of mind and cognitive empathy, both complex constructs which likely encompass several mental processes. To date, there is only limited evidence of overlap in neural activity between high-level tasks related to the mentalizing network and low-level tasks related to the mirroring network . However, task based analysis is often performed by contrasting conditions, and many mirroring tasks have utilized stimuli with little or no direct social relevance, or tasks designed to evaluate highly specific social cognitive processes which may not be well suited to capturing overlap within these systems . By moving away from an ‘overlapping activity’ perspective into an approach focused on brain-behavior relationships, we were able to demonstrate that activity in the mirroring network is correlated with higher-level social cognitive abilities. This combination of pairing a process-specific task paradigm with dynamic social cognitive measures may be a powerful approach for probing relationships between social cognitive networks and real-life social cognitive abilities. 

The behavioral PLS LV correlating neural activation during imitation of emotional faces with TASIT and RAD scores also included some regions which are often considered part of the mentalizing network. While these regions did not robustly activate during the task PLS, their presence in the behavioural PLS reflects activation during the imitate task that is relevant for social cognitive performance. Positive relationships with social cognition and emotional faces were observed in the temporal pole bilaterally, a region implicated in mentalizing and theory of mind  as well as in processing deception . Activity was also noted in the posterior region of the superior temporal sulcus, which may be of particular interest as this area has been implicated in both the mirroring/imitation network  and the mentalizing network . The superior temporal sulcus may serve as an integrative region, sharing information between these two networks  and/or as serving as a relay point for high level visual information . The superior temporal sulcus has also been implicated in analyzing dynamic facial features , perceiving biological motion , and gaze perception . As such, this region is involved with perceptual processes necessary for both low-level and high-level social cognition. It remains to be seen if this region may serve as an integrative hub between the mentalizing and mirroring networks, though the posterior superior temporal sulcus shares connectivity within both networks  and has been implicated as an important region in social cognitive impairment in autism . 

Studies showing increased connectivity between the right IFG (a critical hub of the mirroring network) and the mentalizing network provide evidence for functional communications between these networks . This connectivity between mirroring and mentalizing regions has been shown to be disrupted in autism , raising the possibility that disrupted social cognition in autism may be driven not only by localized effects within one of these systems but also as a network level disruption in how these systems interact. Likewise, social cognitive deficits are increasingly recognized as a core feature of schizophrenia, strongly related to overall functional outcomes . People with schizophrenia have been noted to show reduced right IFG activity when imitating emotional faces as well as opposite relationships between self-reported empathy and right IFG activity compared to controls . As social cognitive impairment is present at, or potentially preceding the onset of psychosis , it is possible this relatively brief imitate/observe in-scanner task may be useful as a potential early risk marker of the disease. 

We found that increased activity in the left IFG was associated with poorer social cognitive performance, as well as in clusters in the left medial frontal cortex and the TPJ . One study examining resting state network connectivity noted over-connectivity of the left IFG in the mirroring network in participants with autism, consistent with our finding that over activity in the left IFG is associated with poorer social cognitive performance . A number of regions outside the mirroring or mentalizing networks also showed a negative relationship with social cognitive performance, including the basal ganglia, thalamus, occipital cortex and superior colliculus. These regions may be involved in emotional face processing . We propose three possible explanations for the negative correlations between this pattern of neural activity when imitating emotional faces and social cognitive performance: 1) prolonged neural activity related to less efficient processing resulting in a greater magnitude of hemodynamic signal, as may be suggested by increased activity in regions associated with visual and face processing; 2) compensatory activity in which individuals with less efficient processing make greater use of the left IFG to compensate for lack of activity on the right (the compensatory hypothesis); or 3) over activity in the left IFG resulting in competition with right IFG, resulting in interference or an decrease in network coherence and deficits in social cognitive test performance (the dedifferentiation hypothesis). One possible explanation is that participants with poor performance may be attempting to compensate by activating aspects of the mentalizing system during lower-level social cognitive processing. It has been suggested that the anterior cingulate cortex, a region noted in the behavioral PLS, is involved in biasing activity towards either mentalizing or simulation . 

We did not find reliable relationships between the ER40 and RMET with neural activity to emotional faces. The ER40 and RMET rely on static images which fail to capture the full complexity of social cognitive processing, unlike the TASIT which requires interpretation of video scenarios of complex human interactions and the RAD which involves interpreting stories. It may be that more complex and process-general tests are required to more fully elicit relationships between activity in the simulation and mentalizing networks . Supporting this assertion, correlations between TASIT test scores and the observed voxel pattern in the PLS analysis were as high as 0.8, indicating a very strong relationship between mirroring network activity and social cognitive performance measured by TASIT1 (a lower-level task), as well as higher-level tasks TASIT2, and TASIT3. Some recent studies using more naturalistic higher-level social-cognitive paradigms, such as videos, have implicated IFG activity , and a small number of recent studies involving more complex social interaction tasks have noted co-activation in mirroring and mentalizing regions . 

Here we provide evidence that neural activation while imitating emotional faces is related to performance on dynamic and objective ‘real-life’ assessments of even the most complex social cognitive tasks. Given the relatively small sample size, further research expanding into a larger sample would be worthwhile to replicate and extend these findings. However, our findings suggest that patterns of neural activation during basic imitative behaviour may be a surrogate marker for highly complex social function in humans. The paradigm demonstrated here may be particularly useful for early identification studies in neurologic and psychiatric disorders with social cognitive impairment, and in intervention studies using ‘target engagement’ as a marker of early treatment response. 


## Methods 
  
### Participants 
  
Twenty-eight healthy adult participants were initially included in this study. Average age of participants was 34.3 ± 11.7 years, with 18 men and 10 women, 23 right-handed participants, and an average level of education of 15.1 ± 2.22 years. Participants aged 18 to 55 were included in the study. All participants completed the Edinburgh handedness Inventory and were administered the Structured Clinical Interview for DSM-IV disorders (SCID) to rule out possible psychiatric illness. Urine toxicology screening was performed to further ensure that no participant with a current substance use disorder was included in the study. Additionally, exclusion criteria included a first degree relative with a history of psychotic mental disorder, a history of head trauma resulting in unconsciousness, or a history of seizure or other neurological disorders. The protocol was approved by the research ethics board of the Centre for Addiction and Mental Health, University of Toronto, all research was conducted in accordance with the declaration of Helsinki and the tri-council policy statement on Ethic Conduct for Research Involving Humans. All participants gave informed consent, and signed an institutionally approved informed consent form, prior to any research procedures. 


### Social Cognitive Assessments 
  
The Emotion Recognition (ER40) task consists of 40 images of whole faces making emotional expressions, with participants selecting from four possible emotional responses . The Reading the Mind in the Eyes Test (RMET)  consists of 36 trials showing only the eyes of a black and white face, with four possible choices to describe what the person is feeling (e.g. amused, irritated, cautious, contemplative). The RMET is considered a test of empathic abilities as it measures the ability to judge emotional states from looking at the eyes. The Relationships Across Domains (RAD) test  presents 25 written vignettes of 2–4 lines followed by three statements which describe the behaviour of the male-female dyad from each vignette in domains of social life different from that vignette. Participants indicate if the behavior described in each statement is likely or unlikely to occur based on what was learned from the vignettes. The Awareness of Social Inference Test, Revised (TASIT) uses short video vignettes to measure emotional perception and theory of mind . The TASIT is divided into three parts. Part 1 (TASIT1) consists of 24 short videos of actors portraying different emotional states (happy, sad, fear, disgust, surprise, and anger). Part 2 (TASIT2; social inference – minimal) consists of 15 videos showing sincere or sarcastic interactions between two actors, followed by four questions relating to what the actors were thinking, doing, meaning to say, and feeling. TASIT2 is considered a test of theory of mind. TASIT part 3 (TASIT3; social inference – enriched) consists of 15 vignettes in which the speaker is making an assertion which is literally untrue, but can represent either sarcasm or an attempt at deception. Success in TASIT3 requires the ability to detect deception in social encounters. In total, six social cognitive scores were derived from these tests (ER40 reaction time, RMET, RAD TASIT1, TASIT2, and TASIT3). Age was regressed out of all social cognitive test scores. 


### MRI Scanning 
  
MRI scanning was conducted on a Discovery 3 T MR750 machine from General Electric at the Centre for Addiction and Mental Health. The Imitate/Observe task was part of a longer multimodal MRI protocol to which each participant consented. Each block of the task (Imitate and Observe) was collected in counter-balanced order as a separate echo-planar imaging scan, with TRs = 3 sec, TE 30 ms, voxel size 3 mm isotropic, 50 slices, 64 × 64 matrix with FOV = 192 mm, flip angle = 77, and 110 TRs per scan. The first 5 TRs were excluded prior to any preprocessing to allow for magnetic steady-state. 


### Imitate/Observe Task 
  
The participants performed an imitate/observe task as previously described  while being scanned. Participants were shown full-color photographs from an ethnically diverse set of 16 individuals (eight males and eight females) expressing five different facial expressions (fearful, sad, happy, angry, or neutral). During one scanning session, participants were instructed to imitate the expression on the faces (the   Imitate   session), while in the other session participants were instructed to observe the face (the   Observe   session). Each run consisted of 80 faces (16 per facial expression) plus 16 fixation trials presented in a pseudorandomized order determined using Optimize Design 11  to maximize contrast efficiency. Each trial lasted three seconds, with the faces presented for two seconds and a jittered ISI (500 ms to 1500 ms). The order of sessions (Imitate or Observe) was counter-balanced across participants. Participants practiced the task prior to MRI scanning and were instructed to minimize motion during the imitation, only using their facial muscles when matching the expressions. A video recording during the scan confirmed that all participants were following instructions (i.e. imitating during the imitate session but not during observe). 


### fMRI data analysis - Preprocessing 
  
The initial preprocessing stages were slice time corrected and motion corrected in SPM8 (Wellcome Department of Cognitive Neurology, London, UK). Individual sessions were subjected to single-session independent components analysis (ICA, from the MELODIC module in FSL 5.0.6). ICA reports were visually examined, and any ICAs which were clear artifacts were removed based on a set of established criteria. On a case by case basis where some large motions contaminated the ICAs, data ‘scrubbing’ was performed using a spline interpolation. Generally, two TRs were removed for each motion spike, and no more than three TRs were permitted per motion spike and a maximum of three motion spikes were removed from any scan. Of the 56 sessions (Observe and Imitate for the 28 participants) scrubbing was performed in 16 sessions. In nine of these cases (four Observe sessions and five Imitate sessions) scrubbing was not successful. Possible reasons for unsuccessful ‘data scrubbing’ include large movements exceeding three TRs, more than three large movements, or over 90% of ICA components classified as artifact after data scrubbing. These sessions were subsequently excluded from further analysis, leaving neuroimaging data from 20 of the original 28 individuals for final analysis. Data were then de-noised based on the selected noise ICA components using FSL 5.0.6 (reg_filt). Normalization into MNI space was done using SPM8, and images were smoothed with an 8 mm Gaussian kernel. 


### Partial Least Squares Analysis 
  
Patterns of task related activity and relationships between social cognitive test scores and BOLD signal were examined using spatio-temporal PLS , a multivariate approach which allows for detection of spatial patterns and dependant variables across the brain without the need for a-priori selected contrasts across experimental conditions. PLS is designed to handle data with high collinearity while capturing essential non-redundant relationships among the data , overcoming the confounding influence of collinear variables (e.g. cognitive tests) in traditional multiple regression. Additionally, PLS is also well suited to studying the relationships between numerous variables even in the presence of a relatively small sample, which is ideal for our purposes as it allows us to examine a range of social cognitive batteries. PLS produces latent variables (  LVs  ) relating patterns of experiment task activity or behavioral measures with spatial patterns of neural activity across time points (scans, referred to as    lags   , normalized to the scan in which the stimuli was presented, labeled as lag0). As a model free non-parametric approach, PLS is ideal to examine complex relationships amongst the battery of social cognitive scores and neural activity when imitating and observing emotional faces. 

A task-PLS analysis was conducted to replicate the regions of activity in the SPM8 GLM. Brain data from an 18 second window (corresponding to 6 lags) was normalized to the first lag (lag0) to create a data matrix for each condition, stacked across participants. Cross covariance was calculated between the data matrix and a design matrix consisting of vector of experimental conditions (in the task PLS, emotional faces, neutral faces, and fixation crosses, separately for Imitate and Observe). The resulting cross-covariance matrix was then decomposed using singular value decomposition, which created a set of orthogonal latent variables (  LVs  ) which optimally represent spatio-temporal relationships between voxels and experimental conditions. For each LV, a pattern of voxels at each lag value (the ‘brain pattern’) demonstrates the relationship with activity in the voxel at that lag and the ‘design pattern’ (representing the weights of each experimental event). Voxel weight is expressed as salience, which is proportional to the covariance of activity in that voxel and the design pattern expressed by that LV. 

Behavioral PLS was used to examine relationships between social cognition and neural activity. Behavioral PLS examines patterns of covariance between scores and neural activity for each trial type across lags. As such the design pattern is the correlation between the overall pattern of neural activity in each condition and each social cognitive score. For the behavioral PLS, neural activity to emotional faces, neutral faces, and fixation (separately for imitate and observe) was related to the six social cognitive test scores from our battery, deterministically producing 36 LVs. 

Statistical evaluation of each LV was performed using split-half permutation testing. A total of 500 permutations were run, with 100 split-half permutations within each. The overall permutation score determines if the effect represented by the LV is sufficiently strong to be differentiated from random noise, while the split-half analysis provides a measure of the stability of relationships between voxel patterns and design patterns in the data for each latent variable. As the permutations are performed at the level of the entire PLS analysis (rather than on individual LVs), multiple comparisons for the number of LVs is not necessary. In the split-half, the ‘BrainCorr’ value tests the reliability of the voxel pattern for a given design pattern associated with an LV, while ‘DesignCorr’ tests the reliability of a given voxel pattern for the behavioral pattern associated with that LV. Results are expressed as p-values. LV’s were considered significant if the overall permutation and at least one of the BrainCorr or DesignCorr was less than 0.05. A bootstrapping procedure with 1000 iterations was used to test if specific voxels were reliably related to the LV. A bootstrap ratio for each voxel was calculated as the voxel salience divided by its bootstrap standard error. A bootstrap ratio of 2.5 (corresponding to >95% reliability) was used to threshold all voxel pattern maps in PLS. 


 </div>
</div>
</div>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-68' name='judgment-68' value='agree'>
<label for='agree-68'>Agree</label>
<input type='radio' id='disagree-68' name='judgment-68' value='disagree'>
<label for='disagree-68'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-68' name='comment-68' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-69'>
<h2>69. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/21664277/' target='_blank'>21664277</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of allocentric social hierarchy/alliance judgements in healthy adults (22 right-handed male participants, mean age 24.2). It reports group-level, random-effects whole-brain univariate analyses (contrasts with p<0.05 FWE-corrected, tables of Talairach coordinates and SPM maps) for the healthy sample. The task is explicitly social (hierarchy/alliances). No exclusion criteria are met (not ROI-only, not connectivity-only, results reported for healthy adults within 17–65). Therefore it meets all inclusion criteria for whole-brain task-evoked fMRI in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-69' name='judgment-69' value='agree'>
<label for='agree-69'>Agree</label>
<input type='radio' id='disagree-69' name='judgment-69' value='disagree'>
<label for='disagree-69'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-69' name='comment-69' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-70'>
<h2>70. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/19739909/' target='_blank'>19739909</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study of social processing (inhibiting prejudice) in healthy adult participants (young and older adults). The abstract and paper text report group-level task-evoked activation differences (e.g., greater medial prefrontal cortex activity in young adults when viewing stigmatized faces; lateral prefrontal activity in older adults with preserved executive function), indicating whole-brain univariate task contrasts were conducted and reported. At least one healthy adult group falls within the 17–65 range (young adults), and results for healthy groups are reported separately. The study is not ROI-only, not resting-state or connectivity-only, and presents generalizable healthy-group task effects. Therefore it meets all inclusion criteria and no exclusion criteria appear violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.85</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-70' name='judgment-70' value='agree'>
<label for='agree-70'>Agree</label>
<input type='radio' id='disagree-70' name='judgment-70' value='disagree'>
<label for='disagree-70'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-70' name='comment-70' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-71'>
<h2>71. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/24550800/' target='_blank'>24550800</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI task study of affective (social) touch including a healthy adult group (N=22, ages 19–35). The paper reports group-level, whole-brain random-effects GLM analyses for adults (Arm>Rest, Palm>Rest) with cluster-corrected thresholds and tables/figures of activations (including pSTS, insula), satisfying whole-brain evidence. The task probes social/affiliative processing (affective-motivational touch) relevant to the review constructs. No exclusion criteria apply (not ROI-only, not connectivity-only, includes healthy adult subgroup within 17–65). Therefore it meets all inclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-71' name='judgment-71' value='agree'>
<label for='agree-71'>Agree</label>
<input type='radio' id='disagree-71' name='judgment-71' value='disagree'>
<label for='disagree-71'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-71' name='comment-71' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-72'>
<h2>72. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/23251653/' target='_blank'>23251653</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study in a healthy adult sample (N=21, mean age 24) using an action-observation/execution paradigm probing mirror representations—directly relevant to ‘Perception and Understanding of Others’ (a social-processing construct). The paper reports group-level, univariate task-evoked activation and adaptation effects, including a whole-brain analysis (threshold p<0.001 uncorrected) with peak coordinates and SPM figures, in addition to ROI results. Therefore it provides generalizable, healthy-group whole-brain task effects and meets all inclusion criteria; no exclusion criteria (e.g., only ROI results, only connectivity/resting-state, non-healthy sample) are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-72' name='judgment-72' value='agree'>
<label for='agree-72'>Agree</label>
<input type='radio' id='disagree-72' name='judgment-72' value='disagree'>
<label for='disagree-72'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-72' name='comment-72' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-73'>
<h2>73. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/29992485/' target='_blank'>29992485</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study of social cognition (mind perception/gaze-cueing) in healthy adult participants (n=22, mean age 24.4). The authors report whole-brain, voxelwise task-evoked analyses (parametric regressors for mind ratings and gaze-cueing effects) with cluster-based correction and present statistically thresholded activation maps and tables (e.g., vmPFC, TPJ, fusiform). All inclusion criteria are satisfied (social-related fMRI task; healthy adults within 17–65; group-level whole-brain univariate results). No exclusion criteria apply.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-73' name='judgment-73' value='agree'>
<label for='agree-73'>Agree</label>
<input type='radio' id='disagree-73' name='judgment-73' value='disagree'>
<label for='disagree-73'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-73' name='comment-73' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-74'>
<h2>74. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/29366950/' target='_blank'>29366950</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study used task-based fMRI in healthy adult participants (N=19, mean age 25.9) during a social-related auditory perception task (judgement/perception of affective vocalisations—social communication/perception of others). The authors report group-level, whole-brain univariate analyses (mixed-effects FLAME) and present a voxelwise species contrast (human > chimpanzee > macaque) with coordinates, statistical maps/figures and tables (Table 2; whole-brain threshold p < .001). The sample is within the 17–65 range and results for the healthy group are reported separately. The study is empirical and not ROI-only or connectivity-only. Therefore it meets all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-74' name='judgment-74' value='agree'>
<label for='agree-74'>Agree</label>
<input type='radio' id='disagree-74' name='judgment-74' value='disagree'>
<label for='disagree-74'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-74' name='comment-74' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-75'>
<h2>75. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22003388/' target='_blank'>22003388</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> excluded</p>
<p><strong>Fulltext Reasoning:</strong> While the study used fMRI in a social task (ultimatum game) with healthy adult participants and reports whole-brain multivariate classification results (discriminative voxels from SVM weights), it does not provide a group-level, univariate whole-brain task-evoked statistical map (e.g., GLM contrast or main-effect voxelwise activation) for the healthy group. Reported results focus on ROI analyses and multivariate classification-derived discriminative volumes (permutation-based SVM weight maps), which do not fulfill the review's requirement for an univariate, group-level whole-brain activation map generalizable to healthy adults. Therefore it does not meet the ‘whole-brain evidence’ inclusion criterion.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-75' name='judgment-75' value='agree'>
<label for='agree-75'>Agree</label>
<input type='radio' id='disagree-75' name='judgment-75' value='disagree'>
<label for='disagree-75'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-75' name='comment-75' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-76'>
<h2>76. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/23948645/' target='_blank'>23948645</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> excluded</p>
<p><strong>Fulltext Reasoning:</strong> Although the study uses fMRI with social stimuli (face perception) and includes a healthy adult subgroup (ages 18–37), it does not report a group-level, univariate whole-brain task activation map clearly identified as coming from the healthy adult group alone. The paper’s whole-brain voxelwise results are reported as age-regression analyses across a mixed-age sample (children, adolescents, adults). Adult data are reported for ROI/FFA measures and descriptive statistics, but no unmasked whole-brain healthy-adult task map/contrast is presented in the main text. Thus criterion requiring a group-level whole-brain task map for the healthy adult group is not met.</p>
<p><strong>Fulltext Confidence:</strong> 0.88</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-76' name='judgment-76' value='agree'>
<label for='agree-76'>Agree</label>
<input type='radio' id='disagree-76' name='judgment-76' value='disagree'>
<label for='disagree-76'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-76' name='comment-76' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-77'>
<h2>77. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31798816/' target='_blank'>31798816</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study uses task-based fMRI during observation of social (interpersonal) touch, targeting social-affective processing. It includes a healthy neurotypical adult control group (N=21) reported separately. The paper reports group-level univariate whole-brain task effects (social vs. non-social touch) with mean group effects and peak coordinates presented in supplemental materials (Additional file 1: Figure S2 and Table S2), satisfying the whole-brain evidence requirement. The design is task-evoked (not resting-state or connectivity-only), and healthy-group results are clearly described and generalizable to healthy adults. No exclusion criteria (ROI-only, connectivity-only, age outside 17–65, or non-empirical) apply. Therefore the study meets all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-77' name='judgment-77' value='agree'>
<label for='agree-77'>Agree</label>
<input type='radio' id='disagree-77' name='judgment-77' value='disagree'>
<label for='disagree-77'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-77' name='comment-77' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-78'>
<h2>78. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/30834300/' target='_blank'>30834300</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of real-time mutual eye contact—a social communication task—conducted in healthy adult participants (initial N=34; fMRI analyses on N=30; mean age ~21.7, within 17–65). The paper reports group-level, whole-brain univariate GLM results (LIVE > REPLAY), random-effects analyses with cluster-level FWE correction and coordinate information, and figures/tables of voxelwise activation maps generalizable to healthy adults. Although additional connectivity and interbrain synchronization analyses are included, the study provides the required whole-brain task-evoked statistical maps for the healthy control sample. No exclusion criteria apply (not ROI-only, not resting-state only, healthy adult group reported separately). Therefore it meets all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-78' name='judgment-78' value='agree'>
<label for='agree-78'>Agree</label>
<input type='radio' id='disagree-78' name='judgment-78' value='disagree'>
<label for='disagree-78'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-78' name='comment-78' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-79'>
<h2>79. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/24265613/' target='_blank'>24265613</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study in healthy adults (N=27, mean age 34.1, right-handed, no psychiatric/neurological history) that used a social communication task (multimodal emotional communication: facial expression, prosody, speech content). The paper reports group-level, voxelwise GLM whole-brain contrasts (channel-specific contrasts, conjunctions) and displays whole-brain activation maps and coordinates used to define ROIs. Although the reanalysis emphasizes FIR and DCM, whole-brain univariate task-evoked results for the healthy group are clearly reported and generalizable to healthy adults. No exclusion criteria (ROI-only, resting-state-only, clinical-only group) apply. Therefore the study meets all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-79' name='judgment-79' value='agree'>
<label for='agree-79'>Agree</label>
<input type='radio' id='disagree-79' name='judgment-79' value='disagree'>
<label for='disagree-79'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-79' name='comment-79' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-80'>
<h2>80. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/15862225/' target='_blank'>15862225</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical task-based fMRI study in healthy adult participants (N=14; ages 18.3–23.7) that targets social-cognitive processing (impression formation about people vs. objects). The paper reports group-level, voxelwise whole-brain contrasts (e.g., person-impression > others; impression > sequencing) with voxel-based thresholding (P<0.001), regions-of-interest and stereotaxic coordinates in tables and figures. Results are clearly reported for the healthy/control sample and are generalizable within the adult range 17–65. The study does not rely solely on ROIs, connectivity, resting-state, or between-group-only contrasts. Therefore it meets all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.97</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-80' name='judgment-80' value='agree'>
<label for='agree-80'>Agree</label>
<input type='radio' id='disagree-80' name='judgment-80' value='disagree'>
<label for='disagree-80'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-80' name='comment-80' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-81'>
<h2>81. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/21864459/' target='_blank'>21864459</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study (N=20) investigating cross-modal face and voice integration, a form of social perceptual processing (perception/understanding of others). Participants are healthy adults (MeSH includes Young Adult) and analyses report group-level univariate whole-brain contrasts using standard statistical criteria (super-additive, max, mean) that identified loci such as hippocampus, occipital and temporal cortices. The paper also reports psychophysiological interaction (PPI) connectivity but does not rely solely on ROI or connectivity-only results. Thus it meets the fMRI social-related task, healthy adult sample, and whole-brain group-level univariate evidence inclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-81' name='judgment-81' value='agree'>
<label for='agree-81'>Agree</label>
<input type='radio' id='disagree-81' name='judgment-81' value='disagree'>
<label for='disagree-81'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-81' name='comment-81' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-82'>
<h2>82. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/26621704/' target='_blank'>26621704</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social processing in healthy adults (N=20, age 18–27) using a mentalizing task (judging scenarios evoking 60 mental states). It reports task-evoked, group-level whole-brain analyses: univariate voxelwise regressions and corrected searchlight MVPA results, with whole-brain statistical maps and cluster-corrected coordinates (Tables S2–S3, Figs. 2–4, SI). Participants are healthy adults and results for the healthy group are reported separately. The paper is empirical, not ROI-only, and includes whole-brain task activation maps generalizable to healthy adults. No exclusion criteria are met, so the study should be included.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-82' name='judgment-82' value='agree'>
<label for='agree-82'>Agree</label>
<input type='radio' id='disagree-82' name='judgment-82' value='disagree'>
<label for='disagree-82'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-82' name='comment-82' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-83'>
<h2>83. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/18486489/' target='_blank'>18486489</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of reflective social processing in healthy adults (final N=17, mean age 21.5), using social-related tasks (self- and mother-referential processing and a Social Attribution Task/theory-of-mind animation). The paper reports group-level, whole-brain univariate task contrasts and conjunctions (composite t-maps, FDR < .05 and uncorrected contrasts at p<.001), with peak coordinates and tables (Tables 2, 4, 5). Results are reported for the healthy/control sample separately and are generalizable to healthy adults. The study is empirical, not ROI-only, not resting-state or connectivity-only, and participants fall within the 17–65 age range. Therefore it meets all inclusion criteria for whole-brain task-evoked fMRI evidence of social-related processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-83' name='judgment-83' value='agree'>
<label for='agree-83'>Agree</label>
<input type='radio' id='disagree-83' name='judgment-83' value='disagree'>
<label for='disagree-83'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-83' name='comment-83' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-84'>
<h2>84. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22507230/' target='_blank'>22507230</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study of affective speech comprehension (social communication / perception of others) in healthy adults (n=51, ages 18–53). The paper reports group-level, whole-brain univariate task contrasts (EMO vs GRAM) with FWE-corrected maps and coordinate tables, and describes event-related whole-brain analyses and activation maps. Results for the healthy sample are reported directly and are generalizable to healthy adults. The study does not rely solely on ROI, resting-state, or connectivity-only analyses, and does not report only between-group contrasts or clinical samples. All inclusion criteria are satisfied and no exclusion criteria are met.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-84' name='judgment-84' value='agree'>
<label for='agree-84'>Agree</label>
<input type='radio' id='disagree-84' name='judgment-84' value='disagree'>
<label for='disagree-84'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-84' name='comment-84' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-85'>
<h2>85. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/23911672/' target='_blank'>23911672</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study in healthy adult participants (male drivers, ages ~19–30) using task-based fMRI while participants viewed social/traffic campaign videos designed to elicit social-cognitive processes (empathy, mentalizing). The paper reports group-level, univariate whole-brain task contrasts (campaign videos vs neutral videos) for the participant groups, with whole-brain maps/figures and tables of coordinate clusters, satisfying the requirement for whole-brain healthy-group task-evoked results. Results for healthy control/safe-driver group are reported separately and are generalizable to healthy adults. Therefore all inclusion criteria are met.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-85' name='judgment-85' value='agree'>
<label for='agree-85'>Agree</label>
<input type='radio' id='disagree-85' name='judgment-85' value='disagree'>
<label for='disagree-85'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-85' name='comment-85' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-86'>
<h2>86. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/17536964/' target='_blank'>17536964</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social cognition (self-referential processing and perspective taking) in healthy adults using a task that manipulates self vs other judgments and perspective taking. The paper reports group-level task-evoked activations in medial prefrontal cortex subregions (ventral/dorsal anterior MPFC, posterior dorsal MPFC, left dorsal MPFC), indicating whole-brain univariate activation contrasts rather than ROI-only or connectivity-only analyses. Participants are healthy adults (typical adult trait-adjective judgments), and results are reported as group effects generalizable to healthy adults. No exclusion criteria are met (not ROI-only, not resting-state/connectivity-only, not patient-only, and not non-empirical). Therefore it satisfies all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-86' name='judgment-86' value='agree'>
<label for='agree-86'>Agree</label>
<input type='radio' id='disagree-86' name='judgment-86' value='disagree'>
<label for='disagree-86'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-86' name='comment-86' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-87'>
<h2>87. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/27458349/' target='_blank'>27458349</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study in healthy adult participants (pilot N=10, main N=15; all aged ≥18) using social-related tasks (sociality manipulation, Prisoner’s Dilemma, Ultimatum/Welfare games — constructs involving perception/understanding of others, affiliation/social interaction, prosocial behavior). The paper reports group-level, whole-brain univariate task-evoked analyses using FSL (Pilot) and SPM12 (Main), with cluster/FWE-corrected thresholds and coordinates/tables of activations (e.g., BA8/9, BA11, vmPFC, PCC) and descriptions of contrasts (High vs Low sociality, PD vs UG). Thus it provides whole-brain healthy-group task activation maps/results generalizable to healthy adults. It does not fall under exclusion criteria (not ROI-only, not resting-state/only connectivity, healthy adult group reported separately). Therefore include.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-87' name='judgment-87' value='agree'>
<label for='agree-87'>Agree</label>
<input type='radio' id='disagree-87' name='judgment-87' value='disagree'>
<label for='disagree-87'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-87' name='comment-87' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-88'>
<h2>88. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/23850465/' target='_blank'>23850465</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an original, task-based fMRI study of social cognition (impression formation) in healthy adults (N=19, mean age 19.1, within 17–65). The paper reports group-level, voxelwise univariate task contrasts and provides whole-brain results with Talairach coordinates and cluster correction (Tables 1 and 2), not solely ROI or connectivity analyses. The social task directly targets perception/understanding of others and uses an established functional localizer plus main task analyses generalizable to healthy adults. No exclusion criteria (e.g., only ROI, only connectivity, non-healthy sample, or non-empirical) apply. Therefore it meets all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-88' name='judgment-88' value='agree'>
<label for='agree-88'>Agree</label>
<input type='radio' id='disagree-88' name='judgment-88' value='disagree'>
<label for='disagree-88'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-88' name='comment-88' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-89'>
<h2>89. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31729396/' target='_blank'>31729396</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social processing (trust, honesty, reputation, mentalizing) using task-based paradigms (take-advice game and trust game). Sample: healthy adult participants (N=31; mean age ~24), within 17–65 range. The paper reports group-level, whole-brain univariate task-evoked results (voxel-level p<0.001 and cluster-level FWE-corrected p<0.05) for contrasts such as honesty vs dishonesty and outcome-related activations, satisfying the whole-brain evidence criterion. It is empirical task fMRI (not ROI-only, not solely connectivity/resting-state), and results for the healthy group are clearly reported and generalizable. No exclusion criteria are violated. Therefore the study meets all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-89' name='judgment-89' value='agree'>
<label for='agree-89'>Agree</label>
<input type='radio' id='disagree-89' name='judgment-89' value='disagree'>
<label for='disagree-89'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-89' name='comment-89' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-90'>
<h2>90. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/27129794/' target='_blank'>27129794</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study in healthy adults (N=178, mean age 40.9, within 17–65). It uses a task-based social paradigm (EmpaToM) manipulating empathy and Theory of Mind, with participants performing video-based social tasks during fMRI. The paper reports group-level, whole-brain univariate task contrasts (emotional vs neutral videos; ToM vs non-ToM questions/videos) analyzed with random-effects one-sample t-tests and presents activation peaks and MNI coordinates and figures. Although connectivity/DCM and resting-state analyses are also reported, they do not replace the clear whole-brain task-evoked maps required by the inclusion criteria. Therefore all inclusion criteria are met and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-90' name='judgment-90' value='agree'>
<label for='agree-90'>Agree</label>
<input type='radio' id='disagree-90' name='judgment-90' value='disagree'>
<label for='disagree-90'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-90' name='comment-90' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-91'>
<h2>91. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31063817/' target='_blank'>31063817</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of healthy adults (N=78, age 18–40) that includes multiple social-related tasks (false belief/ToM, animacy/intentional triangles, eyes intention, trustworthiness, vocalizations) and reports group-level, voxelwise whole-brain random-effects analyses (RFX) with results thresholded at p<0.05 FWE and extensive statistical maps/tables/figures. Healthy-group results are reported and generalizable to the adult sample. The paper provides univariate task-evoked whole-brain contrasts (both main effects and conjunctions) for social cognition contrasts, satisfying all inclusion criteria and violating none of the exclusions (not ROI-only, not connectivity-only, includes within-range adults). Therefore it should be included.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-91' name='judgment-91' value='agree'>
<label for='agree-91'>Agree</label>
<input type='radio' id='disagree-91' name='judgment-91' value='disagree'>
<label for='disagree-91'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-91' name='comment-91' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-92'>
<h2>92. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/29077925/' target='_blank'>29077925</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Meets all inclusion criteria: (1) Task-based fMRI study of social perception/evaluation (impression-formation of faces varying in race and socioeconomic status) relevant to ‘Perception and Understanding of Others’. (2) Sample comprises healthy adult participants (N=60 male, mean age 23.8), within 17–65 and reported separately. (3) The paper reports group-level, univariate whole-brain task-evoked results (exploratory whole-brain regressions and a reported VMPFC cluster for status effects, and whole-brain contrasts described in text/supplement), not limited to ROI-only analyses. No exclusion criteria apply (not only connectivity/rs-fMRI, not only between-group contrasts, empirical original fMRI data). Therefore the study should be INCLUDED.</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-92' name='judgment-92' value='agree'>
<label for='agree-92'>Agree</label>
<input type='radio' id='disagree-92' name='judgment-92' value='disagree'>
<label for='disagree-92'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-92' name='comment-92' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-93'>
<h2>93. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/20098696/' target='_blank'>20098696</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Common Premotor Regions for the Perception and Production of Prosody and Correlations with Empathy and Prosodic Ability</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2010</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0008759</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/2808341/' target='_blank'>2808341</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social communication (perception and production of emotional and linguistic prosody) in healthy adults (n=19, ages 18–58). The paper reports group-level, univariate whole-brain task contrasts (e.g., “happy–neutral”, “question–neutral”) analyzed with random-effects models and thresholded at p<0.05 FDR (k>5), with results described in the text, figures, and supplementary materials (coordinate tables). It is not ROI-only, not connectivity- or resting-state-only, and the healthy adult sample falls within the 17–65 range. Therefore it meets all inclusion criteria and does not violate any exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
## Background 
  
Prosody, the melody and intonation of speech, involves the rhythm, rate, pitch and voice quality to relay linguistic and emotional information from one individual to another. A significant component of human social communication depends upon interpreting and responding to another person's prosodic tone as well as one's own ability to produce prosodic speech. However there has been little work on whether the perception and production of prosody share common neural processes, and if so, how these might correlate with individual differences in social ability. 


## Methods 
  
The aim of the present study was to determine the degree to which perception and production of prosody rely on shared neural systems. Using fMRI, neural activity during perception and production of a meaningless phrase in different prosodic intonations was measured. Regions of overlap for production and perception of prosody were found in premotor regions, in particular the left inferior frontal gyrus (IFG). Activity in these regions was further found to correlate with how high an individual scored on two different measures of affective empathy as well as a measure on prosodic production ability. 


## Conclusions 
  
These data indicate, for the first time, that areas that are important for prosody production may also be utilized for prosody perception, as well as other aspects of social communication and social understanding, such as aspects of empathy and prosodic ability. 

 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (36433 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Prosody, the melody and intonation of speech, involves the rhythm, rate, pitch and voice quality to relay linguistic and emotional information from one individual to another. A significant component of human social communication depends upon interpreting and responding to another person's prosodic tone as well as one's own ability to produce prosodic speech. However there has been little work on whether the perception and production of prosody share common neural processes, and if so, how these might correlate with individual differences in social ability. 

The   production   of prosody is well known to be a specialization of the premotor cortex, in particular the inferior frontal gyrus (IFG), with emotional prosody more strongly activating the right hemisphere and linguistic prosody more strongly activating the left hemisphere  ,  . Research on the   perception   of prosody has largely focused on the right temporal lobe. However, despite this emphasis, there is some indication that the premotor cortex may also be involved  ,  ,  . Nevertheless, premotor contributions to prosody perception have not been well studied. 

There is limited evidence that there may be common frontal areas active for both the perception and production of prosody; patients with lesions to frontal areas seem to have difficulty with both the perception and production of prosody  . However, these lesions are often very large and it is difficult to discern if the same brain areas are utilized in the two tasks. If the same areas were to be involved, it may indicate that, at least under some circumstances, the acoustic signals from another person's prosodic speech are transformed into articulatory signals in order to understand prosodic meaning. That is, it may imply that in order to understand someone else's prosodic intonation, we may utilize our own motor representations of how we would produce the given intonation. 

Indeed, there is a growing body of data indicating that premotor areas are sensitive to the sounds of actions  – . This activation is somatotopic, such that the sounds of hand actions activate the hand premotor areas and the sounds of mouth actions activate the mouth premotor areas  . The finding that regions in motor-related cortices are active for both the production and perception of a particular action is commonly referred to as “mirror system” activation. This data has also been extended for speech perception, showing that premotor mouth areas involved in producing speech are also involved in perceiving speech  ,  . The latter data indicate that motor areas may be involved in the processing of speech, particularly in noisy environments like the fMRI scanner room  . The current research investigates whether a similar pattern could be found for prosody. It also extends the findings of the auditory mirror system to include processing that is relevant to social and emotional information  . 

Furthermore, there is evidence that activity in premotor areas that respond to the sounds of actions correlates with one's ability to empathize with others  . This finding supports the idea that mapping the perception of other people's actions onto one's own motor representations (simulation) may be an important aspect of empathy. There is also evidence that individuals who score low on measures of empathy (as in psychopathic personality as well as autism) have poor prosodic ability  . Investigating the role of prosodic ability and its neural processes has clinical implications in clarifying the role of affective deficits in psychopathy. For this reason, we are particularly interested in exploring the relationship between prosody, empathy, and the mirror system. 


## Materials and Methods 
  
### Participants 
  
Twenty right-handed, native-English speaking volunteers with no history of neurological or psychiatric conditions participated in the experiment. One subject was eliminated from all analyses due to technical errors, bringing the total to 19 subjects (13 females; 18–58 range, mean 28.1). All subjects had normal or corrected-to-normal vision and normal hearing. All assessments were made by screening questionnaires and all subjects gave informed written consent. Human subjects approval for this study was approved by the Institutional Review Board at the University of Southern California. 


### Stimuli and Task Procedures 
  
The main goal of the study is to determine if there are common regions for the production and perception of prosody. For this reason, the functional imaging component of the experiment consisted of two tasks, one to investigate prosody production and another to investigate prosody perception. Half of the subjects performed the production task runs first, while the other half performed the perception task first. Subjects were trained on the tasks prior to scanning. 

#### Production task 
  
Nonsense syllables were used to reduce/exclude additional linguistic processing (e.g., syntax, semantics)  . Subjects were asked to produce the phrase “da da da da da” in different intonations: happy, sad, question, and neutral. Participants were also instructed to produce no speech on some trials (rest condition). Note that our control condition, “neutral” intonation, will still contain intonation, as a flat pitch profile is still a pitch profile. However, it should nevertheless contain less prosodic information than the other conditions. Subjects were presented with a visual cue at the onset of each trial. A line drawing of a face was used to cue the participant to produce one of five task conditions (happy, sad, question, neutral, rest). As   shows, the mouth of the line drawing varied for each cue (smile, frown, question mark for question, straight line for neutral, and X for rest). The visual cue was presented on the screen for 1 s followed by a gray screen and subjects were asked to produce speech as soon as the gray screen appeared. Subjects were trained prior to scanning to produce speech in a tone of voice that matched the presented visual cue. Each seven and a half minute functional run consisted of ten trials of each condition (including rest) for a total of 50 trials, and each subject performed three functional runs of the production task (30 trials per condition total). Participants' performance during the production task were monitored by an experimenter via headphones and recorded through an fMRI-safe microphone and digital voice recorder. Prior testing of the recording setup indicated that while the quality of the recordings were affected by the MRI background noise and conduction through the tubing, these degradations were minimal and did not affect subsequent analyses of voice data. A further concern when subjects produce speech is the possibility for motion artifacts. Our design minimized movement artifact by training subjects prior to scanning to move their heads minimally while producing speech, by using phrases that require minimal jaw movement (e.g.,“da”), and by using other sophisticated motion correction techniques (e.g., an on-line acquisition correction technique during scanning, and use of motion parameters as regressors in the analyses). 
   Schematic of the prosody production task design.  
A visual cue is presented 1 s, followed by 8 s of blank screen. Acquisition of functional volumes occurred during the last 2 s of the blank screen. The conditions were “happy”, “sad”, “question”, “neutral” (not shown in figure), and “rest”. The presentation order of the conditions was randomized for each subject. 
  

#### Perception task 
  
The perception task had the identical design as the production task except for the stimuli; no visual stimuli were presented. Instead, each trial began with a delay of 1 s followed by an auditory stimulus of duration 2 s. The auditory stimuli consisted of voice recordings (“da-da-da-da-da” recorded by an actress) that depicted the conditions happy, sad, question, and neutral. As in the production task, nonsense syllables were chosen to minimize effects of semantics and syntax. Subjects were instructed to listen to the auditory stimulus and to especially attend to the intonation of the voice. All auditory stimuli were pre-tested prior to the experiment. As in the production task, each seven and a half minute functional run consisted of 10 trials of each condition, plus 10 trials where no auditory stimulus was delivered (rest trials), for a total of 50 trials. Each subject performed three functional runs of the perception task (30 trials per condition total). 



### Image Acquisition 
  
Functional MRI images were acquired with a Siemens MAGNETOM Trio 3T machine. In order to ensure that participants could hear the auditory stimuli during the perception task and that we could take audible voice samples during scanning of the production task, we used a sparse sampling paradigm throughout the experiment  ,  . In this paradigm, we minimized scanner noise by acquiring one volume 6 s after event onset to capture the peak of the hemodynamic response to the stimulus  . In the production task, volumes were acquired 6 s after the offset of the visual cue (which was approximately the onset of the subjects' speech production); in the perception task, functional acquisitions occurred 6 s following stimulus onset. Functional volumes were acquired with a echo planar T2*-weighted gradient echo sequence (TR = 9000 ms; TA = 2000 ms; TE = 30 ms; flip angle = 90°; 192 mm FoV; 64×64 voxel matrix; 29 axial slices (interleaved); 3×3×4.5 mm voxels, no gap). A high-resolution T1-weighted structural scan (MPRAGE; TR = 1950 ms; TE = 2.56 ms; flip angle = 90°; 256 mm FoV; 256×256 voxel matrix; 208 coronal slices; 1×1×1 mm voxels) as well as a T1-weighted structural scan with the same slice prescription as the functional images (coplanar; TR = 702 ms; TE = 17 ms; flip angle = 55°; FoV = 192 mm; 192×192 voxel matrix; 29 axial slices; 1×1×4.5 mm voxels) were also acquired from all subjects. Acquisition of functional volumes employed Siemens' prospective acquisition correction (PACE) technique for motion correction, in which head movements are calculated by comparing successively acquired volumes and are corrected on-line  ,  . 


### Image Processing 
  
Functional images were preprocessed and analyzed with SPM2 software (  www.fil.ion.ucl.ac.uk/spm/  ; Wellcome Department of Imaging Neuroscience, London, UK). Images were corrected for slice timing and then normalized to MNI space (using the EPI.mnc template) to allow across-subject comparisons. Motion parameters were calculated for the functional images. Images were then un-warped using the motion parameters and then spatially smoothed with a 7.5 mm Gaussian filter. In each task (production and perception), each condition (happy, sad, question, neutral, rest) was estimated with a Finite Impulse Response, and motion parameters were added to the design matrix as nuisance variables to minimize the effects of head movements during scanning. Scans were excluded from analysis if translational motion greater than 3 mm was detected; no participant exceeded this amount of translational motion. The finite impulse response model was used because our sparse sampling paradigm made it impossible for us to model the entire length/shape of the hemodynamic response function, and thus we needed to analyze each trial/volume as an impulse function. T-contrasts were computed to observe differences between conditions. Group analyses were performed using random effects models with contrast estimates from individual subjects and were thresholded at p<0.05 (FDR multiple comparisons correction) with a minimum cluster size of 5 contiguous voxels. 

#### Task-related activity for prosody 
  
To observe brain regions involved in the processing of prosody, we performed the contrasts “happy-neutral” and “question-neutral”. These contrasts were performed for the production and the perception task separately. The “happy-neutral” and contrast will reveal brain regions involved in emotional prosody processing, while the “question-neutral” contrast will reveal brain regions involved in linguistic prosody processing. The “sad” condition was not used in this analysis because 1) “happy” and “sad” emotions may be processed differently (e.g., Davidson's Approach-Withdrawal Hypothesis  ); 2) if “sad” were included, then the “emotional” and “linguistic” prosody tasks will not be balanced; 3) acoustical analysis indicated that “sad” is more similar to the neutral prosody condition than the “happy” condition, and different from both “happy” and “question” conditions (see supplementary materials,  ). Thus omitting the “sad” condition from this analysis allows us to maximize the difference between our control condition and question prosody condition. 


#### Common regions for perception and production of prosody 
  
To determine brain regions involved in both the production and the perception of emotional prosody, we observed whether regions associated with emotional prosody production were also active during emotional prosody perception. The same procedure was applied for linguistic prosody production and perception. We first obtained a thresholded map for the production task contrast (“happy-neutral” for emotional prosody; “question-neutral” for linguistic prosody; p<0.05, FDR, k>5). Individual clusters from the thresholded production contrast maps were then used as masks to determine whether prosody perception also activated voxels within those regions. These masks were then used to apply small volume correction (SVC) to the corresponding prosody perception contrasts. 



### Behavioral Measures 
  
We were further interested in how activity in brain areas involved in prosody production/perception may correlate with an individual's ability to produce or perceive prosody. Furthermore, because of the relationship between prosody perception and empathy described in clinical literature  , we were also interested in finding a correlation between brain regions active during prosody perception and an individual's scores on measures of affective empathy. Thus, in addition to the fMRI experiment, we also administered questionnaires to our participants outside of the scanner in order to obtain measures of prosody ability and empathy. These measures were used to correlate prosodic ability to empathy as well as with the functional activations during the fMRI experiment. 

#### Assessment of prosodic ability 
  
To assess prosody   production   ability, two raters subjectively scored the voice recordings taken from participants during the fMRI production task on the level of expression of a subset of the trials. The scoring was performed after the scanning session. A 5-point Likert scale was used to judge prosodic ability, with “1” corresponding with “could not determine intended condition”, to “5” corresponding with “could absolutely determine intended condition; superb expression.” Three randomly selected “happy” and “sad” trials from each scanning run were scored, and average scores for “happy”, “sad”, and “happy&sad” were obtained for each subject. To assess prosody   perception   ability, we administered a separate questionnaire where subjects listened to 28 audio clips depicting the conditions happy, sad, question, and neutral, and were to determine the four conditions each clip belonged to. An accuracy score of the proportion of correctly determined clips was obtained for each subject as a measure of how well a person can distinguish between different prosody conditions. 


#### Assessment of empathy 
  
To obtain a measure of empathy in our subjects, we administered two questionnaires: the Interpersonal Reactivity Index (IRI)   and the Psychopathic Personality Inventory-Revised (PPI-R)  . The IRI, a self-report measure assessing specific dimensions of empathy, consists of 4 subscales, each measuring a unique component of empathy. As our aim was to correlate emotional aspects of empathy with individual ability to perceive emotional prosody, we focused on the component of the IRI thought to reflect an affective component of empathy, Personal Distress (PD; e.g., “When I see someone who badly needs help in an emergency, I go to pieces”  . The other subscales of the IRI are Fantasy Scale (FS), Empathic Concern (EC), and Perspective Taking (PT). EC is another form of affective empathy, while FS and PT are considered to be cognitive forms of empathy. These subscales were not included in the hypotheses. The PPI-R also consists of multiple subscales and factors, each representing some psychopathic personality trait. The affective component of psychopathic personality has generally been thought to be inversely related to empathy; individuals who exhibit psychopathic personality traits and show symptoms of antisocial personality disorder are also likely to show callousness and a lack of empathy  ,  . Specifically, the Coldheartedness scale (C) of the PPI-R reflects a propensity toward callousness, guiltlessness, and lack of sentimentality, and is related to a lack of affective empathy. Thus, the PPI-R Coldheartedness scale was used as an additional measure of affective empathy, and we predicted that it would negatively correlate with prosody perception. 



### Correlations between Prosody Perception and Empathy 
  
#### Behavioral 
  
To determine whether an individual's ability to perceive prosody is related to their empathy, we performed correlations between subjects' scores on the prosody perception questionnaire and empathy scores. Once again we focused on components of empathy and performed correlation analyses using subscales that relate specifically to affective empathy, the Personal Distress scale of the IRI and the Coldheartedness scale of the PPI-R. 


#### fMRI 
  
To determine prosody-related brain regions whose activity correlates with prosody perception and empathy ability, we ran simple regression models at the group level for the contrast “happy&sad-neutral” using individuals' empathy scores as regressors. To observe which brain regions show a linear relationship to empathy, contrast estimates of “happy&sad-neutral” perception were correlated with PD scores from the IRI and C scores from the PPI-R to elucidate correlations between affective empathy and neural activity during emotional prosody perception. These analyses were thresholded at p<0.005 uncorrected with a cluster threshold of k>5 voxels. Both the “happy” and “sad” conditions were included in this analysis as we posited that the neural systems involved in perceive both these intonations was related to empathic ability. 



### Prosody Production Ability Correlated with Emotional Prosody Production 
  
Do individuals who are better at producing prosody show more activity in motor regions involved in prosody production? To investigate this we correlated areas that were active for emotional prosody production with the behavioral measure of prosody production ability. To observe which brain regions show a linear relationship to prosody production ability (i.e., the voice production ratings), we correlated each subject's “happy&sad-neutral” production task contrast estimates with their voice ratings. 



## Results 
  
### Task-Related Activity for Prosody 
  
#### Emotional prosody production 
  
The contrast “happy-neutral” for the production task revealed activations in the left inferior frontal gyrus, bilateral anterior middle temporal gyri, bilateral lingual gyri, left cuneus, right midbrain, right fusiform gyrus, left middle frontal gyrus, right anterior cingulate gyrus, bilateral thalami, left superior frontal gyrus, right middle occipital gyrus, left middle cingulate gyrus, right caudate, right insula, left anterior superior medial gyrus, and bilateral posterior superior medial gyri (p<0.05, FDR, k>5). A complete list of results is available in the supplementary materials ( ). In addition, a whole-brain contrast against rest is shown in   and against control in  . Regions specifically involved in emotional prosody perception as compared to control are shown in  . 


#### Linguistic prosody production 
  
The contrast “question-neutral” for the production task revealed widespread activations across many regions, including portions of the superior, middle, and inferior frontal gyri bilaterally, the supplementary motor area, medial regions of the parietal and occipital cortices, the lingual gyri bilaterally, portions of the left insula, posterior regions of the middle temporal gyri bilaterally, the left superior temporal gyrus, and portions of the anterior cingulate cortex (p<0.05, FDR, k>5. A complete list of results is available in the supplementary materials ( ). In addition, a whole-brain contrast against rest is shown in   and against control in  . Regions specifically involved in linguistic prosody perception as compared to control are shown in  . 



### Shared Networks for Emotional Prosody 
  
In order to determine whether brain regions active while producing emotional prosody were also active when perceiving emotional prosody, we created masks from the thresholded production contrast “happy-neutral”, and observed whether these regions were also active in perception. Masks from the production contrast were used to perform small volume corrections to the perception contrast “happy-neutral”. As predicted, motor related regions in the left inferior frontal gyrus (pars opercularis; BA44) and the left middle frontal gyrus (BA 6; dorsal premotor cortex) were significantly active. The left middle cingulate gyrus, right caudate, and right thalamus also survived SVC (p<0.05, FWE, k>5) ( ). 
   Regions of overlap between prosody production and perception.  
Red = Emotional prosody production regions (p<0.05, FDR; T>3.48) that were also active for perception (p<0.05, FDR (SVC); T>2.38). Green = Linguistic prosody production regions (p<0.05, FDR; T>3.80) that were also active for perception (p<0.05, FDR (SVC); T>2.45). A region in the left inferior frontal gyrus appears to be involved for the production and perception of both emotional and linguistic prosody. 
  

### Shared Networks for Linguistic Prosody 
  
We further predicted that motor-related regions would be commonly active for the perception and production of linguistic prosody. In support of our hypothesis, motor-related regions including the left inferior frontal gyrus (pars opercularis; BA44) and left middle frontal gyrus (BA 6; dorsal premotor cortex) and bilateral superior frontal gyri (BA 6) were active for both tasks. The left anterior cingulate cortex and left insula also survived SVC (p<0.05, FWE, k>5) ( ). 


### Behavioral Results 
  
#### Empathy scales 
  
 IRI  . All 19 subjects completed the IRI. The mean scores (and standard deviations) for each subscale are as follows: FS = 19.21 (5); EC = 18.63 (4.7); PD = 8.58 (5.31); PT = 18.26 (5.94). These values are similar to those originally reported by Davis (1980) and are within two standard deviations of the normed mean.   PPI-R  . One subject did not complete the PPI-R due to experimental difficulties; one participant reported 2 standard deviations above the mean and the remaining 17 participants scored within normal range (+/− 1.5 SD) (mean = 29.16; std = 6.33). As the PPI was originally normed on a college population, our patterns reflect the normal bell curve expected for this measure. 


#### Correlations between prosody perception ability and empathy 
  
As expected, correlations between behavioral measures of prosody and empathy revealed significant results for the PD scale of the IRI and for the C scale of the PPI-R. The PD scale correlated positively with performance on the prosody perception task (r = 0.46; R-sq = 0.21; p(one-tailed) <0.0287). This finding is consistent with our prediction that prosody perception ability will be related with affective empathy. The C scale was found to correlate negatively with performance on the prosody perception task (r = −0.47; R-sq = 0.22; p(one-tailed) <0.0297). Because the C scale is an indicator of deficits in affective empathy, the finding of a negative correlation between C scale scores with prosody perception is expected. It should be noted that in future studies, larger sample sizes would be more optimal in testing these scales, and further allow for more stringent analyses to test the hypotheses. Graphs of performance and production scores are shown in   and scatter plots for these correlations are shown in  . 



### Affective Empathy Scores Correlated with Emotional Prosody Perception: fMRI Results 
  
A correlation analysis between individual differences in the PD score from the IRI and contrast estimates during emotional prosody perception indicates regions in the left inferior frontal gyrus (pars triangularis) and right cerebellum as showing activity that positively correlates with PD scores (p<0.005; uncorrected, k>5) ( ). The R-sq for the left IFG is 0.42 with a 95% confidence interval of 0.12–0.73. 
   Regions involved in emotional prosody perception correlated with empathy.  
 A  ) Correlation between emotional prosody perception brain regions and individual differences in PD (IRI) scores. Orange  =  regions that show positive correlation (p<0.005 uncorrected; Z>2.88).   B  ) Correlation between emotional prosody perception brain regions and individual differences in C (PPI-R) scores. Blue  =  regions that show negative correlation (p<0.005 uncorrected; Z>2.88).   C  ) Correlations between emotional prosody production brain regions and performance on prosody production task (rating scores) (p<0.005 uncorrected; Z>2.88). 
  
For the PPI-R, higher scores in the cold-heartedness scale (C) indicate deficits in empathic ability. Thus here we focused on a negative correlation with the C score and neural activity during emotional prosody perception. A correlation analysis between individual differences in the C score from the PPI-R and contrast estimates during emotional prosody perception indicates regions in the frontal cortex, including bilateral superior, middle, and inferior frontal gyri, bilateral cingulate sulcus, bilateral anterior insula, bilateral transverse temporal gyrus (Heschl's gyrus), bilateral superior temporal gyrus, and right TPJ show activity that negatively correlates with C score (p<0.005; uncorrected, k>5) ( ). The R-sq for a region within the left inferior frontal gyrus (pars opercularis) is 0.54 with a 95% confidence interval of 0.26–0.92. While the results reported here support our hypotheses, it should be noted that larger sample sizes would greatly reinforce this finding, and would better allow for effects to be tested with more stringent tests. 

Further post-hoc analyses in the perception/IRI and perception/PPI-R analyses, indicate that the correlations are driven in part by processing of neutral stimuli. Whereas we report a positive correlation in the left inferior frontal sulcus between PD score (IRI) and the “happy&sad - neutral” contrast, this correlation is influenced by a negative correlation between activity during “neutral” and PD score. Likewise, in the left inferior frontal gyrus (L IFG), we report a strong negative correlation between the Coldheartedness score (C; PPI-R) and the “happy&sad - neutral” contrast. This correlation is also in part influenced by a positive correlation between C score and “neutral” activity. 


### Prosody Production Ability Correlated with Emotional Prosody Production 
  
A linear regression between individual differences in prosody production ability and contrast estimates during emotional prosody production indicates motor-related regions in the right inferior frontal gyrus (pars triangularis), the left superior frontal gyrus, and right middle frontal gyrus to be positively correlated to prosody production ability (p<0.005; uncorrected,  ), although this result did not meet the cluster threshold of k>5 voxels. The R-squared for this result is 0.36 with a 95% confidence interval of 0.04–0.67. 



## Discussion 
  
### Common Brain Regions for the Production and Perception of Prosody 
  
We found areas in the premotor cortex, including the left inferior frontal gyrus and the left dorsal premotor cortex were active for both the perception and production of prosody. This was true for both emotional prosody and linguistic prosody. These results are consistent with previous findings of activity in premotor regions during prosody perception  ,  . The current result indicates a link between perception and production, where brain areas that are commonly thought to be involved with motor planning are also active for perception. While there have been numerous previous reports of perceptual processing in motor areas for action observation  – , for the sounds of actions  ,  , and even for speech  , to our knowledge this is the first report of “mirror” processing for prosody. It may indicate that some components of prosodic perception involve mapping the heard speech to areas that are important for producing that same speech. Such mapping of acoustic signals to articulatory signals is reminiscent of the motor theory of speech perception  . This finding is also in line with the proposed “‘as-if’ body loop” where individuals utilize sensory-motor regions to implicitly simulate perceived or imagined experiences  , as well as other studies that indicate that frontal regions are involved in prosodic perception  ,  ,  ,  . While we do not state that this is the only way that prosodic perceptual processing occurs (and clearly other regions are found to be active when just comparing prosody perception to control), activity in the premotor regions might contribute to the processing more or less strongly in particular circumstances, such as in subtle or more ambiguous instances  . Indeed, the topic of motor contributions to speech processing has been a subject of great debate  ,  , and we take the view that motor contributions to speech processing are one several processing strategies that may be utilized, depending on speech context (e.g., noisy/quiet)   and the task demands. 

The inferior frontal gyrus and premotor cortices are known to have connections to auditory areas, in particular though the arcuate fasciculus  . This “dorsal stream” of speech perception from auditory regions to inferior frontal regions may provide a sensory-motor interface that is important for mapping perceived speech onto articulatory processes  ,  . Thus, inferior frontal areas have the possibility for auditory and motor processing, and in fact are known to respond to the sounds of a variety of hand and mouth actions  . In the case of prosody, we hear our own prosody as we produce it. With time, co-activation of production and perception, through Hebbian learning, could strengthen the activity in multimodal premotor areas to either the afferent or efferent component of the speech, thus producing the areas that we find in this study to be active for both perception and production of prosodic speech. 

Interestingly, our data indicate that common motor areas for production and perception of prosody were found in only the left hemisphere (left IFG and premotor cortices). This was true for both linguistic and emotional prosody. Thus, while emotional prosody perception and also prosody production are known to activate the right hemisphere each  , “mirror” regions for prosody seem to be stronger in the left hemisphere. This is consistent with all previous reports of an auditory mirror system as being lateralized to the left hemisphere  ,  , and may indicate a special role in the left premotor cortex for more multimodal processing (motor, visual, and auditory), while the right equivalent areas instead may be stronger in motor and visual properties rather than auditory properties. 

One possible limitation in this analysis is the possibility that participants implicitly made facial movements during perception trials. Outside the scanner, electromyographic recordings were taken from some subjects to test this possibility, and these results of this analysis, indicating a lack of facial muscle movement during perception trials, are included in the supplementary materials ( ). However it should be noted that any study on perception is limited by the possibility of implicit movement unless measured directly inside the scanning session. 


### Correlations with Affective Empathy 
  
Prosodic ability is known to correlate with deficits associated with affective components of empathic processing. This is best observed in individuals with psychopathy. These individuals, who often score low on emotional aspects of empathy, also tend to score poorly on the ability to perceive prosody  . Our behavioral results further support a positive correlation between ability to perceive prosody and ability to feel emotional aspects of empathy, constructs measured by the PPI-R scale of cold-heartedness (C) and the IRI scale of personal distress (PD). Thus we also looked at individual differences in emotional components of empathy [lower scores on (C) measure on the PPI-R, and personal distress (PD) measure on the IRI], and correlated these with areas that were active for the perception of emotional prosody. We found that individuals who scored higher on these measures of empathy showed more activity during emotional prosody perception in anatomically the same premotor areas that we previously found to be active for the perception and production of prosody, including the bilateral inferior frontal gyrus and premotor cortex. They also were found to show less activity in this region during neutral prosodic intonation, indicating that more empathic individuals utilize premotor regions for emotional prosodic perception, but less for non-emotional stimuli. This data support the notion that components of empathy to emotional stimuli may rely on simulation processes carried out, in part, by motor-related areas  ,  . Thus, in order to understand someone else's prosodic intonation, we may simulate how we would produce the given intonation ourselves, which in turn may be a component of the process involved in creating empathic feeling for that individual. These data indicate that individuals who score higher on scales of affective empathy also show more activity in motor-related areas during prosody perception. Our findings extend previous correlations between the mirror neuron system and individual differences in empathy to include, for the first time, an emotional auditory stimulus: happy or sad prosodic intonation. 

The negative correlation with the C score showed additional areas in the left anterior insula and the superior temporal gyrus. The insula activation might indicate more emotional processing when perceiving emotional stimuli by individuals who are more empathic. Activity in temporal areas may indicate that individuals who are more empathic might also initially process the perceived intonation more than other individuals as well. It is interesting to note that the motor-related activations are bilateral while the temporal activations are observed only in the right hemisphere. The right hemisphere temporal activations are consistent with previous studies of prosody perception; however the motor activities are instead consistent with the bilateral control of the mouth muscles, important for prosody production (see supplementary materials,  ). 


### Correlations with Prosodic Ability 
  
Correlations between behavioral measures of prosody production ability and brain regions that are active during prosody production indicate that individuals who are better at producing prosody activate areas important for motor planning of prosody more than individuals that are poor at prosody production. Because here we focus on affective prosody production alone, we find activity predominately in the right hemisphere, as one would expect. While such a finding has been found for other areas of motor expertise  , this is the first time we find such an effect for aspects of non-verbal aspects of language processing. A similar correlation for prosody perception, while interesting, was not possible due to a ceiling effect on the behavioral measures of perception ability; an abnormal population may be more relevant for such a correlation. 



## Supporting Information 
  
 </div>
</div>
</div>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-93' name='judgment-93' value='agree'>
<label for='agree-93'>Agree</label>
<input type='radio' id='disagree-93' name='judgment-93' value='disagree'>
<label for='disagree-93'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-93' name='comment-93' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-94'>
<h2>94. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22623534/' target='_blank'>22623534</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Study used task-based fMRI in healthy adult participants watching emotional movies (naturalistic social-emotional stimulation) and examines neural synchrony underlying social/emotional processing. The paper reports voxelwise, whole-brain intersubject correlation (ISC) analyses and links moment-to-moment valence/arousal ratings to ISC, with group-level maps/localizations (sensory, corticolimbic, default-mode, attention networks) reported across the brain. This meets inclusion requirements: (1) social-related processing (empathy/emotional contagion/understanding others), (2) healthy adult sample, and (3) group-level whole-brain voxelwise task-evoked results (reported as ISC maps and region lists). No exclusion criteria apply (not ROI-only, not resting-state-only, healthy-group maps are provided). Therefore include.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-94' name='judgment-94' value='agree'>
<label for='agree-94'>Agree</label>
<input type='radio' id='disagree-94' name='judgment-94' value='disagree'>
<label for='disagree-94'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-94' name='comment-94' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-95'>
<h2>95. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/24478377/' target='_blank'>24478377</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study in healthy adults (N=15, ages 20–28) that includes a social-distance task (names/photos of friends vs acquaintances) tapping social perception/understanding. The paper reports whole-brain analyses: a conventional univariate GLM and group-level voxelwise t tests (sooner vs later; closer vs farther; more vs less familiar) conducted across the whole brain; authors explicitly report the univariate results (no voxels survived FDR correction) and describe the group-level searchlight and RSA results. Although univariate effects were null, the study clearly performed and reported group-level, whole-brain task-evoked analyses for the healthy adult sample. It is not ROI-only, not connectivity- or resting-state-only, and participants fall within the eligible age range. Therefore it meets the inclusion criteria for fMRI studies of social-related processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-95' name='judgment-95' value='agree'>
<label for='agree-95'>Agree</label>
<input type='radio' id='disagree-95' name='judgment-95' value='disagree'>
<label for='disagree-95'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-95' name='comment-95' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-96'>
<h2>96. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/24795436/' target='_blank'>24795436</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study of social influence in healthy adults (mean age ~24; right-handed students; N=20 scanned). The task is explicitly social/interactive (pair-based communication of arousal ratings) and addresses social-related processing (social appraisal/conformity). The paper reports group-level, whole-brain univariate analyses (random-effects), with voxelwise results surviving clusterwise FWE correction reported in tables and figures (insula, DLPFC, ventral striatum, amygdala), including parametric modulators and whole-brain contrasts. Results for the healthy/control group are presented and generalizable to healthy adults. No exclusion criteria apply (not ROI-only, not connectivity-only, not between-group-only, participants within 17–65). Therefore it meets all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-96' name='judgment-96' value='agree'>
<label for='agree-96'>Agree</label>
<input type='radio' id='disagree-96' name='judgment-96' value='disagree'>
<label for='disagree-96'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-96' name='comment-96' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-97'>
<h2>97. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31844272/' target='_blank'>31844272</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study in healthy adult participants (N=24; ages 22–39) that investigates social-related processing (collective memory, social knowledge, representation of group/narrative schemas). The task is a task-evoked recall task probing social/collective schema influences on memory (relevant constructs: perception/understanding of others, social knowledge). The paper reports group-level whole-brain analyses: a surface-based searchlight with second-level non-parametric random-effects analysis and TFCE correction (Pcorrected < 0.05) identifying clusters related to collective schema (Extended Data Fig.1), in addition to ROI results. Thus it meets all inclusion criteria (healthy adult sample, social-related fMRI task, and group-level whole-brain task-evoked statistical maps). No exclusion criteria (ROI-only, connectivity-only, non-empirical, out-of-range ages) apply.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-97' name='judgment-97' value='agree'>
<label for='agree-97'>Agree</label>
<input type='radio' id='disagree-97' name='judgment-97' value='disagree'>
<label for='disagree-97'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-97' name='comment-97' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-98'>
<h2>98. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/28643894/' target='_blank'>28643894</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study of social cognition (implicit/explicit theory of mind) in healthy adults (final N=22, mean age 24.4). The paper reports group-level, whole-brain random-effects GLM results from an explicit general-belief localizer (false-belief vs false-photograph) thresholded at q(FDR)<0.05 and provides peak Talairach coordinates and figures. Although ROI analyses were used for the implicit task, the study includes univariate whole-brain task-evoked contrasts from the healthy/control group and reports coordinates, meeting the meta-analysis whole-brain evidence criterion. Age range and participant health criteria are satisfied and this is original empirical fMRI data. Therefore it meets all inclusion criteria and does not violate exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-98' name='judgment-98' value='agree'>
<label for='agree-98'>Agree</label>
<input type='radio' id='disagree-98' name='judgment-98' value='disagree'>
<label for='disagree-98'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-98' name='comment-98' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
<div class='study' id='study-99'>
<h2>99. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/24089495/' target='_blank'>24089495</a></h2>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social processing in healthy adults: 32 healthy participants (ages 18–39) underwent task-based fMRI while performing socially framed collaborative, individual, and competitive effort tasks. The contrasts include whole-brain, group-level univariate SPM results (parametric modulations and contrasts) reported with clusterwise FWE correction and tables/figures of activations (e.g., ventral basal ganglia, TPJ, mPFC). The task probes perception/understanding of others and social motivation (social cognition constructs). No exclusion criteria are met (not ROI-only, not connectivity-only, participants are within 17–65). Therefore the study satisfies all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p>Fulltext not available</p>
</div>
<div class='annotation'>
<h3>Annotation</h3>
<p><strong>Do you agree with the LLM's judgment?</strong></p>
<input type='radio' id='agree-99' name='judgment-99' value='agree'>
<label for='agree-99'>Agree</label>
<input type='radio' id='disagree-99' name='judgment-99' value='disagree'>
<label for='disagree-99'>Disagree</label>
<br><br>
<label for='comment'><strong>Comments:</strong></label>
<textarea id='comment-99' name='comment-99' rows='4' cols='50' placeholder='Add your comments here...'></textarea>
</div>
</div>
</div>

<footer>
    <p>Generated by Qualitative Review Tool for Meta-Analysis Pipeline</p>
</footer>
</body>
</html>
