<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>False Positives at Fulltext Stage</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        .study {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 20px;
            margin-bottom: 20px;
            background-color: #f9f9f9;
        }
        .metadata, .screening, .content {
            margin-bottom: 15px;
            padding: 10px;
            border-left: 3px solid #3498db;
        }
        .metadata {
            border-left-color: #3498db;
        }
        .screening {
            border-left-color: #e74c3c;
        }
        .content {
            border-left-color: #2ecc71;
        }
        strong {
            color: #2c3e50;
        }
        .study-list {
            margin-top: 20px;
        }
        footer {
            margin-top: 40px;
            text-align: center;
            font-size: 0.9em;
            color: #7f8c8d;
        }
        
        /* Accordion styles */
        .accordion {
            background-color: #f1f1f1;
            color: #444;
            cursor: pointer;
            padding: 10px;
            width: 100%;
            border: none;
            text-align: left;
            outline: none;
            font-size: 14px;
            font-weight: bold;
            margin-top: 10px;
            margin-bottom: 10px;
            border-radius: 4px;
        }
        .accordion:hover {
            background-color: #ddd;
        }
        .accordion:after {
            content: ' \25BC'; /* Down arrow */
            font-size: 10px;
            color: #777;
            float: right;
        }
        .accordion.active:after {
            content: ' \25B2'; /* Up arrow */
        }
        .panel {
            padding: 0 18px;
            background-color: white;
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.2s ease-out;
            border: 1px solid #ddd;
            border-top: none;
            border-radius: 0 0 4px 4px;
        }
        .panel-content {
            padding: 15px;
        }
        .fulltext-content {
            white-space: pre-wrap;
            font-family: monospace;
            font-size: 12px;
            line-height: 1.4;
        }
    </style>
</head>
<body>
<script>
    function toggleAccordion(btn) {
        btn.classList.toggle("active");
        var panel = btn.nextElementSibling;
        if (panel.style.maxHeight) {
            panel.style.maxHeight = null;
        } else {
            panel.style.maxHeight = panel.scrollHeight + "px";
        }
    }
</script>
<h1>False Positives Papers at Fulltext Stage</h1>
<p>Total papers: 44</p>
<div class='study-list'>
<div class='study' id='study-1'>
<h2>1. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/28242678/' target='_blank'>28242678</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> A neural model of valuation and information virality</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Proc Natl Acad Sci U S A</p>
<p><strong>Publication Year:</strong> 2017</p>
<p><strong>DOI:</strong> 10.1073/pnas.1615259114</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5358393/' target='_blank'>5358393</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This paper reports two original fMRI experiments in healthy adult participants (study 1 n=41, study 2 n=39; ages 18–24; screened for psychiatric/neurological disorders). Tasks probe social-related processing (sharing decisions, mentalizing-related constructs; a social-processing ROI based on a false-belief localizer) while participants viewed article headlines/abstracts. The authors report both ROI analyses and exploratory whole-brain analyses (cluster- and permutation-corrected whole-brain maps and tables of clusters associated with population-level virality), satisfying the requirement for whole-brain results. This is not a review/meta-analysis and does not involve clinical populations. Therefore all inclusion criteria are met and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>   Significance  
Why do humans share information with others? Large-scale sharing is one of the most prominent social phenomena of the 21st century, with roots in the oldest forms of communication. We argue that expectations of self-related and social consequences of sharing are integrated into a domain-general value signal, representing the value of information sharing, which translates into population-level virality. We analyzed brain responses to   New York Times   articles in two separate groups of people to predict objectively logged sharing of those same articles around the world (virality). Converging evidence from the two studies supports a unifying, parsimonious neurocognitive framework of mechanisms underlying health news virality; these results may help advance theory, improve predictive models, and inform new approaches to effective intervention. 
  
Information sharing is an integral part of human interaction that serves to build social relationships and affects attitudes and behaviors in individuals and large groups. We present a unifying neurocognitive framework of mechanisms underlying information sharing at scale (virality). We argue that expectations regarding self-related and social consequences of sharing (e.g., in the form of potential for self-enhancement or social approval) are integrated into a domain-general value signal that encodes the value of sharing a piece of information. This value signal translates into population-level virality. In two studies (  n   = 41 and 39 participants), we tested these hypotheses using functional neuroimaging. Neural activity in response to 80   New York Times   articles was observed in theory-driven regions of interest associated with value, self, and social cognitions. This activity then was linked to objectively logged population-level data encompassing   n   = 117,611 internet shares of the articles. In both studies, activity in neural regions associated with self-related and social cognition was indirectly related to population-level sharing through increased neural activation in the brain's value system. Neural activity further predicted population-level outcomes over and above the variance explained by article characteristics and commonly used self-report measures of sharing intentions. This parsimonious framework may help advance theory, improve predictive models, and inform new approaches to effective intervention. More broadly, these data shed light on the core functions of sharing—to express ourselves in positive ways and to strengthen our social bonds. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (59578 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
Human social interaction is centered on sharing information with others ( ), and this sharing critically affects the reach and impact of news, ideas, and knowledge over time ( – ). The more than 4 billion Facebook messages ( ), 500 million tweets ( ), and 200 billion e-mails ( ) shared daily highlight this phenomenon. However, not all information is equally likely to be shared ( ,  ). Although a growing body of research describes large-scale patterns of sharing ( – ), the types of data that are used to describe such patterns cannot speak to the underlying psychological and neurocognitive antecedents of sharing. Furthermore, extant empirical research on the psychological mechanisms of sharing ( ,  ) is limited by social desirability bias, memory gaps, and the inaccessibility of unconscious, basic processes inherent in self-report and other commonly used measures ( – ). 

To this end, we assess the neurocognitive processes in individuals that translate into population-level sharing of health news articles (i.e., virality, defined as the mass popularity of a piece of information among those with direct access to that information). Real-time measurement of brain activity offers a mechanistic window into the processes underlying sharing decisions, is less biased by the factors noted above ( ,  ), and hence may offer a new way to understand and predict virality. 

## Value-Based Virality 
  
We tested a parsimonious model of virality centered around the value of sharing. Value-based virality posits that (  i  ) two types of inputs—expectations of self-related outcomes and the social impact of sharing—inform an overall computation of the value of sharing a piece of information with others, and (  ii  ) this domain-general value signal translates into population-level information virality. Operationally, we relied on meta-analyses and large-scale studies in social neuroscience and neuroeconomics to define theory-driven brain regions of interest (ROIs) from which to extract neural activity as a proxy for each of the three psychological processes central to value-based virality ( ). 
  
ROIs in study 1 and study 2 
    

## Information-Sharing Value 
  
Neuroscientists have identified subregions of the ventromedial prefrontal cortex (VMPFC) and ventral striatum (VS) that compute value in various contexts ( ). Importantly, prior work has characterized the domain-general nature of the value signal that is computed in this neural system ( ,  ). That is, if a decision maker is faced with different types of value (e.g., primary and secondary rewards), the brain’s value system enables direct comparisons by transforming them onto a common scale during decision making. Value-based virality argues that this same mechanism enables sharers to compute an overall value of the act of sharing a specific piece of information based on considerations of the self-related and social consequences of sharing. Operationally, the neural valuation system includes VS and VMPFC subclusters which are linked to preference judgments and valuation in decision making across hundreds of studies ( ) and which have been linked to sharing decisions in individuals ( ,  ). 


## Self-Related Outcome Expectations as an Antecedent of Sharing 
  
Value-based virality suggests that expectations of self-related outcomes are one primary antecedent to sharing. In line with work on self-relatedness, this concept assumes thoughts about how sharing information affects “our self-presentation or mental concept” ( ). This broad definition encompasses various specific thought processes, for instance about the effects of sharing on one’s self-presentation or its potential to support self-enhancement, which have been studied separately elsewhere ( ,  ). Value-based virality suggests that neural activity in the brain’s self-related processing system is the greatest common denominator of these broadly self-related processes, allowing us to capture within one measure a set of related cognitions that can vary across people and contexts. Similar to content that enhances such self-related thoughts ( ,  ), information that engages neural activity in regions related to such processes, especially in medial prefrontal cortex (MPFC) ( ,  ), has been linked to self-reported intentions to share information ( ,  ). 

Extant observational evidence further suggests that self-relevant issues are among the most frequent conversation topics ( ,  ), especially in social media ( ), and that disclosing information about the self may be inherently rewarding ( ). Value-based virality suggests that, through this neural mechanism, expectations of positive self-related outcomes of sharing increase the perceived value of information sharing, which in turn increases the likelihood of actual sharing. 

Operationally, we focus on a self-related processing ROI consisting of clusters in the MPFC and precuneus/posterior cingulate cortex (PC/PCC), regions commonly activated by the types of self-related judgments detailed above ( ,  ). 


## Social Outcome Expectations as an Antecedent of Sharing 
  
In parallel, value-based virality suggests that expectations of social outcomes of sharing are another primary antecedent of sharing decisions. Sharing is an inherently social process, and social considerations can strongly impact how content is received and acted upon ( ,  ). In particular, sharers need to consider others’ mental states (e.g., knowledge, opinions, and interests) to predict the potential reactions of their audience and to share successfully ( ,  ). This type of social cognition is called “mentalizing” and involves cognitions or forecasts about the mental states of others ( ), for instance, predicting what others are likely to think and feel about the shared information and about the sharer. Value-based virality suggests that neural activity in the brain’s social cognition system constitutes the greatest common denominator of a range of socially relevant thought processes in sharers, including thoughts about the meaning of the information to receivers and the potential for positive social interactions with others. Neurally, activity in the mentalizing system has been linked to sharing decisions in individuals ( ), and successful persuaders engage brain regions strongly associated with mentalizing ( ) more than unsuccessful persuaders within two-person propagation chains ( ). 

Furthermore, sharing information with others has been found to be rewarding ( ). Value-based virality predicts that, by this mechanism, thoughts about potential positive social outcomes of sharing (e.g., having another person know you better or gaining others’ approval) increase the perceived value of information sharing. This is reflected by positive associations between neural activity in social cognition and value systems. 

We operationalize social cognition as defined above with an ROI consisting of clusters in the middle and dorsal MPFC, bilateral temporoparietal junction, and right superior temporal sulcus, regions which are robustly activated by tasks involving mentalizing ( ) and which specifically overlap with considerations of whether others’ mental states are rational and social ( ). 


## Current Study 
  
We tested the value-based virality framework empirically by combining data from two fMRI experiments with objectively logged population-level data on the sharing of   New York Times   (NYTimes) health news articles that were collected using the NYTimes’ Most Popular application programming interface (API) search tool ( ). We focused on neural activity in theory-driven ROIs associated with key psychological processes (positive valuation, self-related, and social processing) measured while participants in two samples were exposed to headlines and abstracts of NYTimes health news articles. fMRI participants also provided ratings of the likelihood with which they would share each article with their Facebook friends. To create a more realistic sharing context, participants were informed that they would be asked to act on their self-reported intentions after the fMRI scan by sharing articles they rated positively with actual Facebook friends. Furthermore, several article characteristics, such as positivity and perceived usefulness, were available from a prior content-focused investigation of the articles used here ( ). Participants completed similar tasks in the two studies ( ), and parallel analyses were applied to the two datasets to allow the replication of our results linking neural and population-level data. The population-level framework presented here substantially extends orthogonal analyses of individual-level results based on study 1 data showing that decisions about information sharing engage more activity in value, self-related, and social cognition ROIs than do other types of decisions and that this neural activity scales with self-reported, individual-level sharing preferences ( ). 
  
fMRI tasks. (  A  ) Reading trial of the article task (study 1). (  B  ) Abstract trial of the article task (study 2). The trial modeled in main analyses is marked in red. 
  

## Results 
  
Based on the predictions made by value-based virality ( ), path models were specified to link percent signal change of brain activity measured in the three theory-driven ROIs while our participants read headlines and abstracts to the population-level sharing counts of each article. The 80 NYTimes articles were shared a total of 117,611 times (mean ± SD, 1,470.1 ± 2,304.3 times; range, 34–12,743 times) via Facebook, Twitter, and email by the NYTimes online reader population within 30 d of each item's publishing date. 
  
Value-based virality path model. The path diagram shows maximum likelihood estimates (unstandardized coefficients). The table presents indirect effect coefficients and bias-corrected, bootstrapped 95% CIs (1,000 replications). As in prior work predicting population-level message effects from neural data ( ), all variables were rank-ordered.   n   = 80 in study 1 and 76 in study 2; *  P   < 0.05, **  P   < 0.01, ***  P   < 0.001, n.s., not significant. 
  
In both samples, we found robust support for value-based virality (  and  ). First, articles that had high sharing value indicated by stronger neural activity in the valuation ROI in each of our samples were shared more frequently by NYTimes readers. This result is in line with the idea that, in the context of sharing, the brain’s valuation system encodes the value of sharing information with others. Further, there are commonalities across people in the extent to which information engages this neural system. 
  
Correlation matrices underlying the path models in   (variables 1–4) and   (variables 1–5) 
    
In addition, the effects of neural activity in self- and social-cognition systems on population-level virality were fully mediated through value-related activity in both samples. This finding is consistent with the idea that considerations of self-related and social outcomes of sharing impact the overall perceived value of the act of sharing, which in turn directly affects sharing behavior. 

These results were robust when using unranked variables ( ,  , and  ). Further, models specifying value-related neural activity as the mediator of the effects of social and self-related processing on virality showed acceptable model fit and outperformed alternative path models ( ,  ). Finally, following our planned ROI analyses, a whole-brain search for regions associated with population-level virality did not reveal widespread activity outside our ROIs ( ,  , and  ). 
  
Value-based virality path model including unranked variables. The path diagram shows maximum likelihood estimates (unstandardized coefficients). The table presents indirect effect coefficients and bias-corrected, bootstrapped 95% CIs (1,000 replications). Population-level virality was log-transformed because of its positively skewed distribution.   n   = 80 in study 1 and 76 in study 2; *  P   < 0.05, **  P   < 0.01, ***  P   < 0.001, n.s., not significant. 
    
Correlation matrices underlying the path model in   that includes unranked variables 
      
Model fit comparison for alternative path structures 
      
Whole-brain analyses of regions associated with each article's rank of population-level sharing counts in study 1 and study 2. Whole-brain maps were thresholded using (  A  ) a nonparametric permutation analysis corrected at FDR-corrected   P   < 0.05,   K   ≥10 and (  B  ) a cluster-based approach thresholded at   P   < 0.005 uncorrected and   K   ≥320 in study 1 and K ≥296 in study 2, respectively where   K   is the number of vowels per cluster on a 3dClustSim simulation together corresponding to   P   < 0.05 corrected. 
    
Whole-brain tables: Clusters significantly associated with population-level virality ranks of the NYTimes articles shown in each trial during reading screen periods (study 1) or abstract trials (study 2) 
    
We further compared the predictive power of neural activity in regions predicted by value-based virality with variance explained by commonly used self-report measures (intentions to share each article on Facebook) and tested the robustness of the framework when controlling for the effects of article characteristics that have been associated with news virality in prior work ( ,  ). For both the study 1 and study 2 samples, self-reported intentions were significant predictors of population-level sharing (explaining 11.3% and 13.8% of its variance, respectively). Neural activity alone explained 17.5% and 9.6% of the variance in the virality outcome in studies 1 and 2, respectively ( ). When combined, both self-reported intentions and brain activity remained significant predictors, together explaining 19.2 and 19.1% of the variance in studies 1 and 2, respectively (  and  ). In addition, all effects reported in   were robust, even when controlling for any of nine content characteristics available for the article headlines and abstracts ( ). Thus, brain activity measured with fMRI can significantly improve the prediction of large-scale sharing behavior beyond other commonly used metrics. 
  
Effects of self-reported intention. (  A  ) Model using intention ratings to predict population-level virality. (  B  ) Model using both intention ratings and value-based virality to predict virality. All variables are rank-ordered; *  P   < 0.05, **  P   < 0.01, ***  P   < 0.001,   P   = 0.056, n.s., not significant. 
  

## Discussion 
  
Information sharing is an integral part of human nature ( ) that enables and accelerates innovation and development in modern societies ( ,  ). We iteratively combined neuroimaging data with objectively logged population-level data on hundreds of thousands of shares from the NYTimes API search tool to test a parsimonious, neurocognitive framework of the psychological mechanisms underlying sharing decisions that translate into population-level virality. Specifically, we argue that potential sharers consider a broad range of self-related and social consequences of sharing a piece of information with others. The resulting self-related and social-relevance judgments then serve as inputs to the brain’s valuation system, which converts them to a common scale. This overall value of information sharing is directly predictive of large-scale sharing dynamics. 

Consistent with this framework, we found that brain activity in the valuation system (VS and VMPFC) in two groups of participants was associated with virality in the larger population (117,611 total shares of 80 NYTimes articles). That is, articles associated with higher information-sharing value in the brain when individuals first read the headlines and abstracts were shared more frequently by the population of NYTimes readers. Information-sharing value may be a primary psychological motivator and central theoretical concept that guides sharing behavior at scale. Prior work has shown that neural activity in the brain’s valuation system is not only associated robustly with personal preferences ( ) but also with the expectation of positive outcomes ( ,  ). Brain activity in response to persuasive messages in these regions also is associated with message-consistent behaviors at the individual ( ,  ) and population level ( ,  ,  ). Our findings show that the predictive validity of neural valuation activity extends to the realm of information virality and highlights the domain-general nature of this brain signal ( ,  ). In the case of sharing, value-based virality suggests that considerations of self-related and social consequences of sharing are key inputs in the computation of the value of sharing information, even though the specific nature of the self-related and social inputs that inform that value signal may vary depending on qualities of the information sharer, the receiver, or their relationship. 

In line with this argument, we found robust, indirect effects of brain activity in regions associated with self-related processing during article exposure on population-level sharing behavior through value-related activity. Prior evidence has linked a range of self-related judgments to sharing. For example, the promotion of a positive self-image ( ,  ) is an important goal in social interactions, and information that allows potential sharers to appear in a more positive light is more likely to go viral ( ,  ), perhaps because it increases the perceived value of information sharing. Further, self-disclosure increases activity in the brain’s valuation system, suggesting that providing information about or reflecting about the self might be inherently rewarding ( ). Value-based virality brings together prior findings, arguing that self-related neural activity is the greatest common denominator for various self-related thought processes, including reflecting self-concept and self-presentational concerns, and constitutes a primary antecedent of sharing value. 

Further, our results show an indirect effect of activity in neural regions associated with social cognition, and in particular mentalizing, on population-level article virality through value-related activity. Existing work has shown that the expectation of positive social outcomes such as positive interactions with others engages the brain’s valuation system ( ,  ), and our ROI overlaps with brain regions supporting considerations of whether others’ mental states are rational and whether they are social ( ). Social belonging is a basic human need and motivation ( ,  ), and relationship maintenance has been suggested as a motivator of information sharing ( ,  ). A range of basic social motives focused on understanding others’ minds and forecasting their reactions, and expectations about positive social outcomes of sharing information with others may increase the perceived value of information sharing; in turn, the perceived increase in the value of information increases the potential that the information will go viral. Value-based virality brings together prior findings, arguing that neural activity in areas associated with social cognition is the greatest common denominator for various social thought processes and informs sharing value. 

Although we removed voxels within the VMPFC and PCC [regions commonly associated with both self-related and social processing ( ,  ,  )] from our social-processing ROI to ensure statistical validity, self-related and social thoughts are conceptually intertwined. Social psychologists have suggested that one’s sense of self is defined by simple rules that include or exclude an individual from certain social groups and practices, resulting in a “social self” concept ( ,  ). In the context of value-based virality, it follows that content that is expected to have positive social outcomes when shared (e.g., because it is helpful to the receiver or results in a positive social interaction) will likely reinforce the perceived positivity of self-related outcomes of sharing (e.g., by making the sharer look charitable and friendly) and vice versa. Nonetheless, our analyses demonstrate that when operationalizations of both self-related and social processing are included in one model, each concept contributes unique variance to the calculation of overall sharing value. In the future, explorations of the relative importance of each cognition and the patterns of their interaction in the calculation of information-sharing value will be valuable. 

Finally, in line with prior investigations in other contexts ( ,  – ,  ), we show links between brain activity in small groups of individuals and large-scale virality, even though the perception of the sharing value of the same content might vary across people, and the same content might appear valuable to different people for different reasons. Although what is personally relevant to the self and useful to share with others might differ somewhat across individuals, human societies are characterized by a set of basic common values and social norms that drive behavior across individuals ( ,  ). Sharing decisions rely on such basic motives, namely, the pursuit of a positive self-image and social belonging ( ,  ). Consequently, similar types of information are likely to be perceived to have high sharing value across individuals. Furthermore, expectations of self-related and social outcomes, two core concepts within value-based virality, are defined broadly as the greatest common denominators of various self-related and social thought processes, respectively. In other words, population-level prediction of virality from neuroimaging of small groups is likely facilitated by broad societal values, the inclusiveness of our theoretical conceptualizations, and the unique information afforded by neuroimaging. Specifically, neuroimaging is optimally situated to identify such high-level, hard-to-articulate cognitions, allowing us to capture relevant cognitions in a parsimonious way despite the variability in the thought processes that different individuals might associate with the same content. Along with this strength, however, we relied on functionally defined ROIs to take optimal advantage of neuroimaging to operationalize these constructs, which are inherently subject to the limitations of reverse inference ( ). 

The results summarized in this article were robust across several methods of analysis, and the hypothesized model outperformed alternative path structures, although causal inferences are limited by the cross-sectional nature of our data. Additionally, a whole-brain analysis did not provide strong evidence for the involvement of neural regions outside our ROIs in population-level virality. Nevertheless, future work might reveal other basic processes that could complement the theory, for instance as additional inputs to the value signal or its antecedents. Further, our effects were robust, even when controlling for self-reported sharing intentions and various article characteristics. In sum, our data highlight the value of including neural variables in the conceptualization of virality in the context of health news and offer a testable and parsimonious framework that could be extended to virality in other contexts. This mechanistic account of sharing decisions complements insights from previous studies using self-report measures or big data approaches (e.g.,  ,  ). 


## Conclusion 
  
Information that elicits greater brain response in self-, social-, and in turn value-related systems is more likely to be shared. These processes may reflect thoughts about the potential outcomes of sharing to the self and to one’s social relationships. If so, self-related and social processes could serve as targets for content designers aiming to increase the virality potential of their messages. Taken together, our data support a parsimonious neurocognitive model of virality, one of the most prominent social phenomena in the 21st century, and shed light on the core functions of sharing—to express aspects of ourselves and to strengthen our social bonds. 


## Methods 
  
Neural activity was examined while two samples of participants (study 1 and study 2) completed the article task ( ) in which participants were exposed to headlines and abstracts of news items taken from the NYTimes website (  https://www.nytimes.com/  ). We then tested for associations between activity within functionally defined, theory-driven ROIs associated with self-relatedness, social processing, and valuation and the number of article retransmissions performed online by NYTimes readers as a population-level indicator of virality. 

Similar protocols were administered in both studies, and each group of participants was presented with the same news items. Differences in data collection and processing between the two studies are detailed below. All models and results reported here were derived using parallel statistical approaches across studies. All participants provided informed consent, and all procedures were approved by the Institutional Review Board at the University of Pennsylvania. 

### Hypothesis Preregistration. 
  
At the onset of study 1, we preregistered our study design ( ), and upon completion of data collection we explored the relationship between neural data and population-level article retransmission. Based on the results in study 1, hypotheses specifying the effects of self- and social-processing on value-related neural activity and of activity in the value-related ROI on population-level virality were preregistered before the analysis of study 2 data ( ). 


### Sample NYTimes Article. 
  
During the article task, participants in both samples were exposed to the original headline and abstract of 80 articles from the Health section of the NYTimes website (  https://www.nytimes.com/  ). The articles were chosen from a complete census (excluding certain article categories to preserve homogeneity in article format; see ref.   for details) of articles (  n   = 760) published online in the 7.7 mo between 11 July 2012 and 28 February 2013. Population-level data about the number of retransmissions of each article through email, Twitter, and Facebook were collected via the NYTimes API. The 80 articles were chosen to maximize comparability regarding topic (healthy living and physical activity) and length (for the word count of title and abstract, see  ). The 80 articles selected into the final sample were of comparable lengths, i.e., a word count (mean ± SD) of 29.43 ± 3.87 words (range, 21–35 words). To control for reading speed in study 1, we produced audio files in which a female voice read each of the article headlines and abstracts. Depending on word count, each audio file was produced to last 8, 10, or 12 s. 

Coded characteristics of each article’s headline and abstract were available as described by Kim ( ). 


### Population-Level Retransmission. 
  
An article’s population-level retransmission count was measured through the NYTimes’ Most Popular API and defined as the sum of retransmissions via Facebook, Twitter, and email using sharing tools available on the NYTimes website within 30 d of the article’s first appearance on the website (mean ± SD, 1,470.14 ± 2,304.32 retransmissions; range, 34–12,743 retransmissions). Retransmission counts for social media (Twitter and Facebook) and email were highly correlated (  r   = 0.917) and thus are not presented separately, although results remain substantively identical when each type of sharing is considered separately. 


### Study 1 Participants. 
  
From a larger sample of respondents who participated in a project examining the neural correlates of retransmission and social influence by filling out a short online survey, we selected 43 participants. These 43 participants completed an online screening process and an in-person appointment including a 60-min fMRI scan. To be eligible for the fMRI portion, screened participants had to meet standard fMRI eligibility criteria including no metal in the body, no history of psychiatric or neurological disorders, not currently pregnant or breast-feeding, and not currently taking psychiatric or illicit drugs. All participants were right-handed. 

Two participants were excluded from analysis because of data corruption. One participant saw only three of the four conditions during the article task, and one participant showed poor normalization to the template brain. Additionally, for four participants a smaller number of trials was available for analysis because of the loss of data from one run of the article task (  n   = 1), excessive head motion in one run of the task (  n   = 2), and technical difficulties in which 23 articles were shown twice, resulting in only 57 trials that qualified as initial exposures to an article (  n   = 1). The partial data from these participants were included in the analyses. The age of the final sample of 41 participants (29 females) was 20.6 ± 2.1 y (mean ± SD) (range, 18–24 y). 


### Study 2 Participants. 
  
Forty participants were selected from the pool of respondents used to select the study 1 sample using inclusion criteria that paralleled those in study 1. These participants underwent an fMRI session. 

Because of excess head movement during the article task, one participant was removed from all analyses, and one run of the article task was discarded for a second participant. The remaining 39 participants (28 female) were 18–24 y old (mean ± SD, 21.0 ± 2.02 y). 


### Study 1 Article Task. 
  
Inside the fMRI scanner, study 1 participants completed two runs of the article task consisting of 40 trials each ( ). Each trial lasted an average of 14.7 s without fixation. At the beginning of each trial a cue screen indicating the current condition was presented for 1.5 s. Then participants read the article’s title and abstract while considering a condition-specific question. In the four conditions participants were asked to consider (  i  ) whether to read the full text of the article themselves, (  ii  ) whether to share the article via a post on their Facebook wall; (  iii  ) whether to share the article via a private Facebook message to one friend (5-point Likert-type scales from very unlikely to very likely), and (  iv  ) whether age/nutrition/fitness/science/laws/well-being/cancer was the topic of this article (5-point Likert-type scale from certainly not to certainly yes). Conditions were presented in a pseudorandom order based on a Latin-square. To control for reading speed, headlines and abstracts were also presented in auditory format through scanner-compatible headphones while the text was presented on the screen. Article abstracts were categorized in three groups depending on the length of the text. Consequently, the reading screen was presented for 8 (  n =   16), 10 (  n =   40), or 12 (  n =   24) s. Article length was counterbalanced across conditions and task runs. The reading screen was followed by a randomly jittered fixation screen that lasted 1.5 s on average (range, 0.5–4.7 s). Participants then used a button box to indicate their answer to the condition-specific question (3 s). Finally, there was a randomly jittered intertrial interval with an average length of 2 s (range, 1–4.7 s). 

In this analysis, we focused on reading trials in which participants viewed the article headlines and abstracts to decide whether they wanted to read the full text of the article (see   for results in other conditions). Furthermore, we only included reading screens within each trial (i.e., periods in which article headlines and abstracts were visible). This task condition closely mimics natural situations in which readers are initially exposed to articles online. 


### Study 2 Article Task. 
  
Study 2 participants completed two runs (21 trials each) of a modified version of the article task ( ). First, each article’s headline and a description of the article were presented on the reading screen for 10 s, and participants were instructed to read the text on the screen. Articles were not presented in auditory format in study 2. Three types of article descriptions were used: Participants saw the original article headline and abstract that also was seen by study 1 participants (  i  ) or saw the original article headline and a Tweet-length message written by a participant in study 1 to be shared either with one Facebook friend (  ii  ) or on the participants’ Facebook wall (  iii  ). The reading screen was followed by a randomly jittered fixation period (mean, 1.5 s; range, 0.3–4.8 s). Afterward, participants provided two ratings per trial: (  i  ) the likelihood they would share the article on their Facebook wall and (  ii  ) the likelihood (on 5-point Likert-type scales paralleling those used in study 1) that they would share the article via a private Facebook message with one friend. Each rating screen was available for 3 s. Rating screens were separated by a short, jittered fixation period (mean, 1.5 s; range, 0.4–4.3 s). Finally, there was a randomly jittered intertrial interval (mean, 2.9 s; range, 0.5–11.5 s). To parallel study 1 analyses closely, only reading screen periods within each trial (i.e., when article headlines and descriptions were visible) and only abstract trials that presented original NYTimes abstracts were analyzed here. The 80 articles used in study 1 were pseudorandomly assigned to experimental conditions for each participant in study 2; however, because of randomization, only 76 articles were presented in the relevant abstract condition across all study 2 participants. 


### A Priori ROIs. 
  
Three neural masks were constructed as functional ROIs based on extensive prior work in each of the respective subject areas ( ). The self-relatedness ROI was defined based on a prior study ( ) that collected neural data using a well-validated self-localizer task ( ) in which participants judge whether personality traits describe them or not (the self-condition) or whether the adjective shown is positive or negative (the valence condition). Blocks of self-judgments are contrasted with blocks of valence judgments to isolate neural activity associated with self-relatedness. 

The social-processing ROI was defined based on a large-scale study that used the well-validated false-belief localizer during which participants engage in mentalizing ( ). Trials during which participants judged whether beliefs held by others were true or false were contrasted to trials in which they judged whether physical representations were true or false to retrieve the mask used here. To avoid inflated correlations among activity in the three neural systems, we created a reduced version of the social cognition mask, excluding the clusters in VMPFC and PCC that overlap with the self and value ROIs. This mask is used in all analyses presented here. Models using the full social-cognition ROI instead of the reduced social-cognition ROI yielded very similar results and support identical conclusions. 

Finally, the valuation ROI was defined based on a quantitative meta-analysis of 206 studies that reported neural correlates of subjective valuation during decision making. This mask represents the conjunction of several valuation-relevant contrasts, all of which required some form of value-based decision making (figure 9 in ref.  ). 


### MRI Image Acquisition. 
  
Neuroimaging data were collected using a 3-T Siemens Magnetom Tim Trio scanner equipped with a 32-channel head coil was used for 40 participants in study 1 and 33 participants in study 2, and a Siemens Prisma 3T whole-body MRI with a 64-channel head/neck array was used for one participant in study 1 and six participants in study 2. Identical specifications were used on both scanners, except for the number of slices acquired for T2*-weighted images (54 at the Tim Trio and 52 at the Prisma scanner). This difference was accounted for in the slice-time correction step during preprocessing. Standard parameters used to acquire T2*- (two runs of 500 volumes in study 1 and two runs of 311 volumes in study 2), T2-, and T1-weighted anatomical image sequences are described in detail in the  . 


### Imaging Data Preprocessing. 
  
For the analysis of data from both studies, we used SPM8 (Wellcome Department of Cognitive Neurology, Institute of Neurology, the University of London), incorporating tools from AFNI (Analysis of Functional NeuroImages) ( ) and FSL (FMRIB Software Library) ( ) during data preprocessing. The first five volumes of each run were not collected to allow stabilization of the blood oxygenation level-dependent (BOLD) signal. Functional images were despiked using 3dDespike as implemented in AFNI. Slice time correction was performed using Sinc (Stanford University ideal bandlimited) interpolation in FSL. Data then were spatially realigned to the first image and were coregistered in two six-parameter affine stages. First, mean functional images were registered to in-plane T2-weighted images. Next, high-resolution T1 images were registered to the in-plane image. After coregistration, high-resolution structural images were segmented into gray matter, white matter, and cerebral spinal fluid to create a brain mask used to determine the voxels to be included in first- and second-level models. The masked structural images then were normalized to the skull-stripped Montreal Neurological Institute (MNI) template provided by FSL (MNI152_T1_1mm_brain.nii). Finally, functional images were smoothed using a Gaussian kernel (8 mm FWHM). The fMRI data were modeled for each participant using fixed-effects models within the general linear model as implemented in SPM8, using SPM’s canonical difference of gamma hemodynamic response function (HRF). The six rigid-body translation and rotation parameters derived from spatial realignment were also included as nuisance regressors in all first-level models. Data were high-pass filtered with a cutoff of 128 s. Random effects models for the article task were also implemented in SPM8. 


### Analysis of Study 1 Imaging Data. 
  
We took an itemwise approach to modeling the article task using procedures similar to those used elsewhere ( ,  ). Specifically, using a single boxcar function for each trial (i.e., each of the 80 articles) encompassing the 8- to 12-s reading screen, we extracted neural activity in each ROI during each trial compared with the implicit baseline resting state. Activity related to cue and all rating screens was pooled into a separate regressor of no interest each. In addition, the model for one participant who accidentally saw several articles twice included an additional regressor of no interest for each second occurrence of an article. Fixation periods were pooled into the implicit baseline rest. 


### Analysis of Study 2 Imaging Data. 
  
Study 2 data were analyzed using methods parallel to those applied to study 1 data to yield comparable models. Specifically, using a single boxcar function for each of the 42 trials per participant, encompassing the 10-s reading screen, we extracted neural activity observed during each trial compared with the implicit baseline resting state. A regressor of no interest was included for each of the two rating screens. Fixation periods were pooled into the implicit baseline rest. 


### Path Models. 
  
For each a priori ROI, average parameter estimates of activity across all voxels within the region were extracted for each participant and each article using Marsbar ( ). Each set of parameter estimates was divided by the grand mean to derive estimates of the percent signal change. Percent signal change vectors for each participant were reduced to those trials shown in the reading condition for study 1 and in the abstract condition for study 2. For each participant, these reduced vectors were then z-scored and ranked across articles. As in prior work ( ), we then computed the mean ranks of each article across participants and linked these data with the ranked population-level data from the NYTimes API separately. 

Specifically, we conducted path analyses using maximum likelihood estimation in lavaan ( ) to yield the results presented in  . Nonparametric, bias-corrected 95% confidence intervals (CIs) for indirect effects using 1,000 bootstrap samples were further estimated using the mediation package for R ( ) to test for indirect effects of self-related processing and social processing on population-level retransmission through valuation (  for relevant correlation matrices). 


### Robustness Checks. 
  
To check the robustness of our results, we fit (  i  ) models using unranked variables in which population-level retransmission counts were log-transformed because of the positively skewed distribution (  and  ), (  ii  ) models excluding the insignificant direct effects of the exogenous variables shown in   to obtain model fit statistics ( ), and (  iii  ) alternative structural models to those estimated in step   ii   to compare model fit (  and  ). 


### Whole-Brain Analysis. 
  
We conducted exploratory whole-brain searches for regions associated with population-level retransmission ranks in study 1 and study 2 to verify the specificity of our results to our ROIs and to explore whether additional activity outside these ROIs is associated with population-level virality ( ). 


### Models Including Self-Reported Sharing Intentions and Article Characteristics. 
  
We further tested whether the predictions of value-based virality held above and beyond the variance explained by self-reported sharing intentions (  and  ) and article characteristics ( ). 

Study 1 participants provided one rating (intention either to broadcast or narrowcast) for 40 articles. For each article, we computed a mean sharing intention across participants including all available narrowcast and broadcasting ratings. 

Study 2 participants provided both narrowcast and broadcasting ratings for all 42 articles shown to them. For trials shown in the abstract condition, we first calculated a mean sharing intention across the two ratings for each article within participants and then computed a mean sharing intention for each article across participants. 

First, ranked population-level retransmission was regressed onto sharing intentions to estimate the effect of intentions on virality in each sample. Second, we reestimated the models shown in   with self-reported intentions specified as an additional exogenous variable with a direct effect on population-level retransmission. This step was further repeated for each available article characteristic ( ). 



## SI NY Times Article Sample 
  
We selected 80 articles from the full set of 760 articles analyzed in ref.   with the goal of maximizing comparability in topic and length. Specifically, we conducted a keyword search of the full set of 760 articles using the following terms: exercise, fitness, physical activity, running, swimming, skiing, soccer, walking, food (excluding “Food and Drug Administration”), eating, nutrition, nutrient, diet, vitamin, calcium, carbohydrates, gluten, caffeine, cholesterol, obesity, and weight. The search retrieved 143 articles. A closer examination revealed that four articles were irrelevant, and these articles were removed. Of the remaining 139 articles, the 80 that were most similar in length were chosen. 


## SI Scanning Parameters 
  
We captured neural activity during two runs of the article task (500 volumes in each run in study 1 and 311 volumes in each run in study 2) using a T2*-weighted image sequence [repetition time (TR) = 1.5 s, echo time (TE) = 25 ms, flip angle = 70°, −30° tilt relative to the anterior commissure–posterior commissure (AC–PC) line, 54 slices at the Magnetom Tim Trio scanner, 52 slices at the Prisma scanner, field of view (FOV) = 200 mm, slice thickness = 3 mm, multiband acceleration factor = 2, voxel size = 3 × 3 × 3 mm]. High-resolution T1-weighted anatomical images were collected using a magnetization-prepared rapid gradient-echo (MPRAGE) sequence [inversion time (TI) = 1,110 ms, 160 axial slices, voxel size = 0.9 × 0.9 × 1 mm]. Finally, we collected an in-plane, structural, T2-weighted image (slice thickness = 1 mm, 176 axial slices, voxel size = 1 × 1 × 1 mm) to implement a two-stage coregistration procedure between functional and anatomical images. 


## SI Robustness Checks 
  
To test the robustness of our main results reported in  , we estimated models using unranked variables. These analyses produced results similar to those presented in the main text and supported identical conclusions (  and  ). Further, models excluding the insignificant direct effects of the two exogenous variables on virality shown in   were estimated to obtain model fit statistics. Both models revealed satisfactory model fit for the hypothesized structural model, considering its small degrees of freedom (df) and small sample size ( ):   (2) = 2.36,   P   = 0.31, comparative fit index (CFI) = 0.997, residual mean square error of approximation (RMSEA) = 0.05, 90% CI (0.00, 0.23) for study 1;   (2) = 3.26,   P   = 0.20, CFI = 0.986, RMSEA = 0.09, 90% CI (0.00, 0.26) for study 2. Additional analyses revealed the model fit for the hypothesized path structure was superior to that of alternative structural models ( ), providing additional confidence to our proposal that valuation, taking inputs from self and social considerations, serves as a final common pathway. 


## SI Study 1 Whole-Brain Analysis 
  
To test the specificity of our results to our theory-driven ROIs, we conducted exploratory whole-brain analyses. We first created first-level models for each participant that included a separate boxcar function for activity across all trials within a certain condition (content, reading, broadcasting, narrowcasting) for the reading screen and the rating screen of the article task, respectively (eight regressors). An additional regressor represented the boxcar function representing the reading screen during reading trials modified by a mean-centered parametric modulator of population-level virality ranks of each article. Population-level virality ranks were derived by ranking all articles presented within the reading condition by their population-level retransmission counts for each participant (range, 1–20). The model also included a boxcar function for activity across all trials within the cue screen and six nuisance regressors to control for motion. Finally, to ensure that only first exposures were modeled in the main regressor of interest, one regressor of no interest was entered to account for trials in which one participant was accidentally presented with an article for a second time. Second, at the group level, neural activity was pooled for all participants to examine the main contrasts of interest: activity during the reading screen in reading trials modulated by population-level retransmission ranks compared with implicit baseline. 

To balance the risks of false positives and false negatives, we conducted two different kinds of correction for multiple comparisons to derive whole-brain maps and tables of voxels in which neural activity scales with population-level virality (  and  ). The first whole-brain map was thresholded at   P   < 0.005 and   K   ≥320, where   K   is the number of voxels per cluster, to produce a threshold of   P   < 0.05, corrected using 3dClustSim simulation (version AFNI_16.2.02). Although the type 2 error rate can be expected to be lower for this method of analysis, prior work has shown that cluster correction tends to overestimate the number of significant voxels and thus increases the type 1 error rate ( ). Consequently, we also present the results of a more stringent whole-brain correction that controls the number of false positives more efficiently. Specifically, we used nonparametric permutation testing (5,000 iterations) and false-discovery rate (FDR) correction for a voxelwise   P  -threshold of   P   < 0.05 and   K   ≥10 as implemented in the SnPM13 toolbox ( ). (Study 1 results for multiple comparisons correction using nonparametric permutation testing corrected at FDR   P   < 0.05 vary across individual runs of the 5,000 permutations protocol implemented here, because of random elements in this analysis technique. Specifically, although several runs produced maps similar to the map printed in  , these results border on   P   < 0.05. All runs of the permutation protocol for study 1 produced maps that looked very similar to the one printed here at   P   < 0.06 or   P   < 0.07. Study 2 results are highly robust across several runs of the permutation protocol,   P   < 0.05, FDR corrected.) 


## SI Study 2 Whole-Brain Analysis 
  
To conduct a parallel whole-brain analysis for study 2 participants, we first created first-level models for each participant that included a separate boxcar function for activity across all trials within a certain condition (abstract, narrowcasting, broadcasting) for the reading screen (three regressors) of the article task. Separate regressors for rating screens were further derived depending on the condition presented on the reading screen (six regressors in total). Crucially, an additional regressor specified the boxcar function representing the reading screen during abstract trials modified by a mean-centered parametric modulator of population-level virality ranks of each article. As for study 1, virality ranks were derived by ranking articles shown within the abstract condition by their population-level retransmission counts for each participant (range, 1–14). The model also included six nuisance regressors to control for motion. Second, at the group level, neural activity during the main task was pooled for all participants to examine the main contrasts of interest: activity during the reading screen in abstract trials modulated by population-level virality ranks compared with the baseline resting state.  ,  , and   for details and results. 

In parallel to study 1 analyses, whole-brain maps were thresholded via 3dClustSim simulation at   P   < 0.005 and   K   ≥296 (version AFNI_16.2.02) and nonparametric permutation testing (5,000 iterations) and FDR correction for a voxelwise   P  -threshold of   P   < 0.05 and   K   ≥10 as implemented in the SnPM13 toolbox ( ). Results are reported in   and  . 


## SI Analysis of Other Article Task Conditions 
  
In the main text, we focus on neural activity extracted from reading trials in the study 1 article task ( ) because the reading condition most closely represents real-world experiences of NYTimes readers who are unlikely to visit the website to find an article to share with somebody. Instead, readers are more likely to browse abstracts and consider reading various articles until one article motivates them to share it with somebody else. 

Nonetheless, an additional question to consider is the extent to which task instructions affect the relationship between neural activity during article exposure and population-level sharing. Therefore we examined the relationship between value-related neural activity in our value ROI in response to an article’s headline and abstract and population-level article retransmission data, focusing separately on narrowcasting trials in which participants were primed before each trial via a cue screen to consider sharing articles with one Facebook friend and broadcasting trials in which participants were primed to consider sharing the article on their Facebook wall. Note that this analysis is not possible for study 2 data, because the other two conditions, not analyzed in the main text, are not comparable to those in study 1 and did not include the presentation of original article abstracts. 

Results show that value-related neural activity in response to articles shown in a sharing condition is marginally related to population-level virality in the case of narrowcasting trials [  r   = 0.184,   P   = 0.10] and is not significantly related to population-level virality in the case of broadcasting trials [  r   = 0.133,   P   = 0.24]. Individual-level data from study 1 suggest that explicit instructions to share (i.e., the two sharing conditions) increase the overall level of sharing-relevant brain activity compared with instructions to consider reading the full text of an article (i.e., the reading condition analyzed here; ref.  ). However, we also found that these explicit instructions reduce the variance in value-related activity, which is larger for reading trials (s  = 5.10) than for narrowcasting (s  = 4.18) and broadcasting (s  = 3.24) trials. This ordering of conditions according to variance in information-sharing value corresponds to the condition ordering in terms of the strength of the relationship between value-related activity and population-level virality. If this interpretation is correct, one potential implication could be that sharers are likely to share articles based on “gut” decisions, which are better represented by the reading trials, which did not specifically give participants the goal of sharing in each trial, than by longer elaboration, which is better represented by sharing trials. 


## SI Article Characteristics 
  
In a content-focused investigation of 760 NYTimes health news articles that included the 80 articles used here, Kim ( ) characterized the article headlines and abstracts by analyzing human (i.e., the presence of efficacy information or the mention of diseases or bad health conditions) and computerized (expressed positivity: the difference between the number of positive and negative words; expressed evocativeness/arousal: the sum of positive and negative words) content and with the help of lay human raters (perceived usefulness, induced positivity, perceived controversiality, induced evocativeness/arousal, and perceived novelty). Here we explore the relationship between these content characteristics and concepts within our value-based virality framework as well as population-level virality. 


## SI Analysis of Article Characteristics 
  
Prior work has shown that content characteristics can impact virality ( ,  ), and this argument has been made particularly effectively in the case of news articles ( ,  ). Consequently, we explored the role of content characteristics in value-based virality. Specifically, content characteristics might be involved in three different ways. (  i  ) Article characteristics might affect virality directly and independently of variables included in the value-based virality model. If so, it would be of interest whether neural data explain the variance in population-level sharing over and above that explained by article characteristics. (  ii  ) Article characteristics might affect information-sharing value directly or via some other mechanism not currently included in the value-based virality model. (  iii  ) Article characteristics might be antecedents of thoughts regarding the self-related and social outcomes of sharing. 

To explore these possibilities, we first checked whether the predictions made by value-based virality ( ) hold even when controlling for article characteristics. For this purpose, we estimated models identical to the one in   but for the sake of parsimony excluded the insignificant direct effects of self-related and social processing on virality. Each model additionally included a direct effect of one article characteristic on population-level virality. Paralleling other analyses presented in this article, all variables were rank-ordered. In both studies, the effects presented in   were robust when controlling for any of the nine article characteristics considered here. In fact, the only article characteristic that showed a significant effect on population-level virality in these models was the perceived usefulness of an article [  B   (unstandardized estimate of this parameter) = 0.202, SE = 0.101,   P   = 0.04] in study 1, but this effect did not replicate in study 2. 

Second, we examined the relationships between each of the nine content characteristics available to us and average neural activity in regions associated with self-related and social processing in response to each article using   t   tests and Pearson correlation where appropriate. Paralleling other analyses presented in this article, all variables were rank-ordered. 

In study 1, we found a positive relationship between induced positivity in an article and neural activity in the self-related processing ROI [  r   = 0.231;   P   = 0.04]. In addition, articles that mentioned diseases or negative health issues (mean, 9.74) were associated with less self-related processing than articles that did not [mean, 10.70;   T  (78) = 2.24;   P   = 0.03] in study 1. However, these effects did not replicate in study 2. 

Finally, we explored direct effects of article characteristics on information-sharing value (i.e., average neural activity in our value-related processing ROI) using analytical strategies identical to those explained above. Value-related neural activity was positively related to the extent to which articles induced positivity in human raters [  r   = 0.309;   P   = 0.005], and articles that mentioned diseases or bad health conditions (mean, 9.50) engaged less value-related activity than articles that did not [mean, 10.96;   T  (78) = 3.04;   P   = 0.003]. However, these effects did not replicate in study 2. 

In sum, our results hold, even when controlling for the effects of various article characteristics on virality, suggesting that neural activity contributes information over and above what can be learned from variables commonly used in the literature on virality ( ,  ). In contrast to prior work, most article characteristics did not predict population-level sharing. This dissonance with existing studies might be the result of methodological differences among studies. Most notably, previous reports of effects between article characteristics and population-level sharing showed relatively small effect sizes that were identified only in very large samples (e.g.,   n   > 6,000 in ref.   and   n   = 760 in ref.  ). Because of time restrictions in the fMRI scan, we were not able to replicate these article sample sizes. Nonetheless, our ability to predict virality from neural variables even in this small sample of articles speaks to the strength and utility of fMRI. 

In addition, we identified selected relationships between individual article characteristics and the extent to which articles engaged neural activity associated with self-related, social, or value-related cognition in study 1. Although these relationships generally did not replicate in study 2, these findings might suggest that content characteristics could be promising candidates in the search for antecedents of the psychological processes that affect sharing. The lack of robustness of these effects might be due to the small sample size and homogeneity of articles. In addition, it is possible that sharing-relevant cognitions are more sensitive to combinations of article characteristics (e.g., the emotional tone in combination with the topic) than to isolated characteristics. However, the specific combination of article characteristics that enhances expectations of positive social or self-related outcomes of sharing might be highly context dependent. An exploration of the large number of potential interaction terms is beyond the scope of this investigation. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-2'>
<h2>2. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/29915004/' target='_blank'>29915004</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Concrete versus abstract forms of social concept: an fMRI comparison of knowledge about people versus social terms</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Philos Trans R Soc Lond B Biol Sci</p>
<p><strong>Publication Year:</strong> 2018</p>
<p><strong>DOI:</strong> 10.1098/rstb.2017.0136</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6015823/' target='_blank'>6015823</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This paper reports original fMRI data in healthy adult participants (three separate studies, total n=59) performing social-related tasks (person knowledge: faces/names; socially relevant concept words). Imaging used whole-brain acquisition and analyses (whole-brain contrasts social > non-social reported, with cluster thresholds detailed) alongside ROI analyses. Participants are described as healthy control adults and data are not from psychiatric/neurologic patient groups (though a larger study included TLE patients, only control data are used here). The study is not a review/meta-analysis. Although exact participant ages were not listed in the provided excerpt, the sample is described as control adults in typical fMRI experiments; overall, all inclusion criteria are met (functional MRI during social tasks, healthy participants, whole-brain results).</p>
<p><strong>Fulltext Confidence:</strong> 0.85</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
The anterior temporal lobes (ATLs) play a key role in conceptual knowledge representation. The hub-and-spoke theory suggests that the contribution of the ATLs to semantic representation is (a) transmodal, i.e. integrating information from multiple sensorimotor and verbal modalities, and (b) pan-categorical, representing concepts from all categories. Another literature, however, suggests that this region's responses are modality- and category-selective; prominent examples include category selectivity for socially relevant concepts and face recognition. The predictions of each approach have never been directly compared. We used data from three studies to compare category-selective responses within the ATLs. Study 1 compared ATL responses to famous people versus another conceptual category (landmarks) from visual versus auditory inputs. Study 2 compared ATL responses to famous people from pictorial and written word inputs. Study 3 compared ATL responses to a different kind of socially relevant stimuli, namely abstract non-person-related words, in order to ascertain whether ATL subregions are engaged for social concepts more generally or only for person-related knowledge. Across all three studies a dominant bilateral ventral ATL cluster responded to   all   categories in   all   modalities. Anterior to this ‘pan-category’ transmodal region, a second cluster responded more weakly overall yet selectively for people, but did so equally for spoken names and faces (Study 1). A third region in the anterior superior temporal gyrus responded selectively to abstract socially relevant words (Study 3), but did not respond to concrete socially relevant words (i.e. written names; Study 2). These findings can be accommodated by the graded hub-and-spoke model of concept representation. On this view, the ventral ATL is the centre point of a bilateral ATL hub, which contributes to conceptual representation through transmodal distillation of information arising from multiple modality-specific association cortices. Partial specialization occurs across the graded ATL hub as a consequence of gradedly differential connectivity across the region. 

This article is part of the theme issue ‘Varieties of abstract concepts: development, use and representation in the brain’. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (46740 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## . Introduction 
  
The neural organization of conceptual knowledge (or semantic knowledge) has long been a fundamental issue in cognitive neuroscience, with much debate on the degree to which representations are segregated by modality and category. On the one hand, researchers have emphasized cortical specialization for specific modalities and categories of knowledge [ – ]. Other researchers, while not denying these specializations, have argued that true conceptual knowledge additionally requires a transmodal level of representation that integrates across modalities and possibly categories [ – ]. Recent neuroimaging studies using multivariate techniques have also identified brain regions that process transmodal semantic information [ – ]. Here, we investigated the organization of knowledge in the anterior temporal lobes (ATLs), a region that has emerged as a key contributor to conceptual representation [ , – ]. 

Currently, there are different literatures that propose contrastive hypotheses about the ATLs, yet their predictions have never been directly compared. The hub-and-spoke theory holds that the ATLs form a pan-category transmodal ‘hub’ that develops coherent conceptual representations through interaction with distributed information sources [ , , , , ]. This theory stems from studies of semantic dementia (SD) patients who exhibit a selective yet progressive multimodal, pan-category impairment of semantic knowledge, following bilateral ATL atrophy [ – ]. Performance on semantic tasks in SD patients is correlated with the amount of atrophy and hypometabolism in the ventrolateral ATLs [ ]. SD patients exhibit generalized deficits across different conceptual categories, including concrete and abstract words [ – ], living and non-living items [ , ], and people [ ]. Recent fMRI, rTMS and subdural grid-electrode explorations also directly implicate the ATLs as a transmodal, pan-category hub [ , , – ]. 

Conversely, a separate literature proposes that the ATLs are involved in processing socially relevant semantic cognition [ – ]. This account is consistent with long-standing observations that the ATLs are part of a wider network involved in social cognition in humans and primates [ – ]. The question of what constitutes a ‘social concept’ is an important one, and remains relatively ill-defined in the literature. Within the existing literature ‘social cognition’ encompasses topics such as (but not limited to) recognizing conspecifics (people, most commonly from a face) [ – ], processing socially relevant words [ , , ], recognizing emotions [ – ] and understanding the intention of others (theory of mind; [ , , ]). In this paper, we used the term ‘socially relevant concept’ to refer to semantic information which has social connotations/implications. While the definition of socially relevant concepts remains broad and ill-defined, several groups have proposed that all or part of the ATLs selectively code social concepts, including person (face) knowledge and emotional concepts [ , , , , , ]. Indeed deficits in social behaviour are often observed in SD patients, including social awkwardness, person recognition deficits and a loss of empathy [ – ]. These findings could reflect either a dedicated role of ATL regions in social concepts and/or the contribution that a more generalized ATL semantic system might play in activation of all concepts including social items. In a novel extension from the clinical findings to fMRI, Zahn   et al.   [ ] demonstrated that activation associated with socially related words (e.g. polite) versus non-social words (e.g. nutritious) was localized to the right anterior superior temporal gyrus (aSTG) in neurologically intact participants. However, a direct replication of the Zahn   et al.   [ ] task found greater activation for social > non-social words in the left aSTG, rather than in the right aSTG [ ], suggesting that both ATLs may play a role in the task. This finding of differential activation in the aSTG for social concepts was replicated in a recent study which employed more stringent matching of the stimuli [ ]. Indeed the potential role of the left as well as the right ATL in social concepts was underlined by the study of Chan   et al.   [ ], which, in a formal exploration, found social and behavioural deficits in both left > right and right > left SD patients (with a greater proportion of right > left, albeit more severe, SD patients showing social and behavioural deficits). 

Potentially related to the argument that the ATLs show a category effect for socially relevant concepts, a third literature proposes that the ATLs are selectively involved in face processing [ , – ], perhaps in the function of linking familiar faces to stored semantic knowledge [ ]. In support of this, congenital prosopagnosia has been linked to reduced (ventral) ATL volume, and damage to the right ATL can result in greater deficits in face recognition than for other categories [ – ]. Likewise, some fMRI studies have shown that the ATLs bilaterally (though more commonly in the right hemisphere) respond more to faces than non-face objects [ , , ]. This face-related ATL activation has been proposed to be the human homologue to the ‘anterior temporal face patches' recently observed in macaques [ , , – ]. However, the necessarily selective focus on face processing in these studies means that their results are based solely on visual stimuli. Therefore, it is unclear whether the face-related ATL region responds selectively to faces or to transmodal person knowledge [ ]. 

These neuroimaging datasets—general semantics versus social semantics versus face representation—have emerged in parallel and thus a critical question that arises is whether they report activations in the same or different regions within the ATL. Formal analysis of the current literature does allow us to answer this question. Specifically, in  , we report peaks from a number of studies investigating either general semantic knowledge or face representation. The two sets of studies report rather similar (and typically bilateral) peaks, although peaks from the face-related studies are, on average, more anterior/medial along the ventral surface (approx. 1 cm away). Based on these data, it is difficult to distinguish between two interpretations: (1) that faces activate the same ATL regions as other meaningful stimuli but perhaps do so more strongly, or (2) that there are subdivisions within the ATLs which respond differently, with a more anterior/medial area being face-selective.
   
Peak MNI coordinates taken from the general semantics literature and face-selective literature. 
  

This study was designed specifically to draw these three currently separate literatures together in order to understand the role of various ATL subregions in the representation of different kinds of social versus non-social concept. Specifically, we conducted the first comparison of ATL responses to different kinds of socially relevant concepts using three datasets which all used neuroimaging sequences tailored to acquiring signal in the ATL and used appropriate control conditions. First, we compared ATL activation to people versus another conceptual category across different modalities (Study 1). Next, we verified the ATL responses to people-related knowledge using another modality of presentation (famous names presented as written words; Study 2), in order to replicate and extend the findings of Study 1 in a separate dataset. Finally, we compared activation within the ATLs to different classes of socially relevant concepts (e.g. socially relevant words) to assess whether activation to socially relevant concepts is consistent or whether there is selective activation for social knowledge versus other kinds of semantics (Study 3). We also compared activation within the ATL between abstract socially relevant words versus concrete socially relevant words (i.e. famous names from Study 2). 


## Method 
  
We compared data from three studies, each exploring different examples of socially relevant concepts ( ). Two of the three studies explored the perception/representation of person knowledge (Study 1 and Study 2), and one study explored written words depicting (abstract) socially relevant concepts (Study 3). Study 1 was used to compare socially relevant concepts (faces, spoken names) versus a well-established control condition (landmarks) to identify socially relevant activations in the ATLs. Study 2 was used to verify whether the findings of Study 1 could be replicated and extended to another modality of presentation (famous names presented as written words). Study 3 was used to assess whether the findings from famous people generalized to other socially relevant stimuli (i.e. socially relevant concept words).
   
Social and non-social semantic conditions included in Studies 1–3. 
  

### Stimuli and tasks 
  
Data were collected from three separate fMRI studies (  n   = 59). All of the participants in the three studies were unique. Each study consisted of at least one social semantic condition, one non-social semantic condition from the same modality, and a modality-matched non-semantic control task. All three studies used a PC running the E-Prime software (Psychology Software Tools, Pittsburgh, PA) for presentation of stimuli and recording of responses. For behavioural results across all three studies, see electronic supplementary material, table S1. 

#### Study 1: stimuli, tasks and procedure 
  
Study 1 (  n   = 20) consisted of pictures and spoken names of famous people and famous landmarks. Landmarks were chosen as comparison categories for people because landmarks are highly prominent within the visual perception literature as a contrast for faces and, like faces, are also classified as ‘unique entities’ [ ]. Study 1 also contained data from a third non-unique conceptual category (animals); however, these data will not be discussed here. Each conceptual category (people, landmarks) contained 72 stimuli, which were presented twice during scanning, once as a picture and once as a spoken name. Stimuli were presented in two modalities to address a discrepancy in the literature: studies proposing that the ATLs are involved in face processing have exclusively used visual stimuli and do not make explicit predictions about whether this area is visually selective or transmodal [ , ]. This stands in contrast to the general semantic literature which provides evidence that the ATLs respond across multiple modalities for multiple categories [ , , ]. Visual and auditory control conditions were used to account for low-level sensory effects and to provide an attention-demanding baseline condition, which is a crucial factor for observing ATL activations [ , ]. The visual control items were generated by scrambling 72 images from the three conceptual categories; these were created using the Java Runtime Environment ( ) by scrambling each image into 120 pieces and rearranging them in a random order. The auditory control condition consisted of 6 phase-scrambled auditory tones. Stimuli were presented in blocks of the same condition to participants in the scanner and the task was a nationality judgement task (Is the stimulus European or Non-European?). For the control conditions, participants were used to make ‘high/low’ decisions for each stimulus (Is the scrambled image high or low on the screen?’, ‘Is the tone high or low in pitch?). To ensure the semantic and control tasks were matched for eye movements, the visual semantic conditions were also randomly presented above or below the fixation cross. 

Participants completed three functional scans, with a total scan time of 36 min. During scanning, stimuli were presented in a block design. Each functional scan contained alternating blocks of visual or auditory stimuli from one condition; half of the runs started with an auditory block (A – V – A – V) and half the runs started with a visual block (V – A – V – A); this order was counterbalanced across participants. Each block contained 6 trials. Each stimulus was presented sequentially and in isolation for 2500 ms, with an inter-stimulus interval (ISI) of 500 ms. The eight experimental conditions (6 semantic + 2 control conditions) were sampled 12 times in a counterbalanced order, giving a total of 96 blocks. At the start of each block, a written word probe prompted participants as to which task was coming up. Visual stimuli were presented via a mirror mounted on the head coil, angled at a screen at the foot of the scanner bed. Auditory stimuli were presented via noise cancelling headphones (MkII+ headphones, MR confon GmbH;  ) in conjunction with ear plugs, to reduce scanner noise. To ensure that the auditory stimuli were intelligible for each participant, practice trials were run while the scanner was active and the sound level was adjusted as necessary. 


#### Study 2: stimuli, tasks and procedure 
  
Study 2 (  n   = 20) also involved semantic judgements regarding famous people, this time incorporating pictures and written words (names). On each trial participants were presented with a probe item and asked to decide which of the two alternatives shared the same occupation. Each stimulus triad was presented simultaneously. In each triad all stimuli came from the same gender and nationality. Alongside this condition there was a non-social semantic association task, consisting of a variant of the widely used Camel and Cactus test [ ]; here the task was to pick which of the choice items is associated with the probe item. To match the occupation matching task, items were presented either as pictures (CCp) or written words (CCw). Different items were used in the word and picture versions of the Camel and Cactus and occupation matching task to avoid priming effects. Each condition consisted of 33 trials. Again, modality-specific non-semantic control tasks were included in Study 2, namely scrambled versions of the famous faces/names and Camel and Cactus pictures/words. Participants were instructed to choose which of the choice items was identical to the probe. The data reported here form part of a larger study comparing brain activation in control participants to a set of post-surgical temporal lobe epilepsy (TLE) patients. As part of the larger study, control participants saw each of the semantic conditions twice, once at a speed typical for a healthy population (‘standard speed’; 2.5 s/triad) and once at a slower speed (5 s/triad); although importantly the items used in both scans were different to avoid priming effects (i.e. items which were presented as a picture in the ‘standard’ speed scan were shown as written words in the ‘slower’ speed scan). The slower speed was used in relation to the behavioural slowing seen in the patient group and thus to allow direct comparison between the data from the patients to the control group. For the purposes of the current reanalysis only the ‘standard’ blocks were entered into the analysis to match the task demands to the other studies. 

Study 2 consisted of four functional scans, each with a total scan time of 8.45 min. During scanning, stimuli were presented in a block design. Each functional scan contained stimuli from one semantic condition (CCw, CCp, famous names or famous faces) and from the relevant baseline condition (scrambled pictures or scrambled words). This was done to avoid task-switching effects in the scanner. Each block contained three trials from one experimental condition. Each stimulus and the response screen were presented for 5000 ms, with an ISI of 500 ms. The two experimental conditions (semantic and baseline) were sampled 11 times per functional scan in a counterbalanced order, giving a total of 22 blocks per scan. The order of the scans was randomized and counterbalanced across participants. Stimuli were presented visually via a mirror mounted on the head coil, angled at a screen at the foot of the scanner bed. All participants underwent practice trials before beginning the scan to familiarize them with the tasks. 


#### Study 3: stimuli, tasks and procedure 
  
The data from Study 3 (  n   = 19) were taken from a previously published investigation of socially relevant concepts in the ATL [ ]. Briefly, Study 3 presented participants with written synonym judgement decisions. Stimuli were either socially relevant concept words (e.g. bright) or non-social abstract concept words (e.g. edition), matched closely for psycholinguistic properties including frequency, imageability and semantic diversity (see Binney   et al.   [ , ] for full details of stimulus matching). Each condition consisted of 48 triads. In all conditions participants were instructed to choose which of the two choice words was associated with the probe word. The non-semantic control condition was a number judgement task; a triad of numbers was presented on screen and participants were instructed to choose which of the two choice numbers was closer in numerical value to the probe number. 

For Study 3 a block design was used, each block lasting 13.5 s and consisting of three trials from the same experimental condition. Each trial began with a fixation cross presented in the centre of the screen for 500 ms, followed by a stimulus triad (probe and choice words simultaneously). The stimuli remained on the screen for a fixed duration of 4000 ms after which the next trial began. Participants responded by pressing one of two buttons on an MR-compatible response box. Study 3 consisted of two 15 min functional runs separated by a 10 min interval. Each run contained 16 blocks of the number judgement task and 16 blocks of the three semantic judgement conditions. All conditions were presented in a pseudo-random order. 



### Scanning 
  
#### Imaging parameters 
  
Traditionally, imaging the ventral ATLs has been problematic because of a number of technical issues including the nature of the baseline contrast tasks as well as gradient-echo EPI signal dropout and distortion [ , ]. These issues have been tackled through recent methodological developments [ , ]. Across all three studies reported here, the core semantic task was contrasted against an active baseline (see above) using either dual-echo EPI imaging Study 1 + 2 [ ] or spin-echo EPI imaging Study 3 [ ] to improve signal in the ATLs. 

For Study 1 and 2 all scans were acquired on a 3T Phillips Achieva scanner, with a 32-channel head coil with a SENSE factor of 2.5. A dual-echo EPI sequence was used to improve the signal-to-noise ratio (SNR) in the ATLs [ ]. Using this technique, each scan consisted of two images acquired simultaneously with different echo times: a short echo optimized to obtain signal from the ATLs and a long echo optimized for good whole-brain coverage. The sequence included 31 slices covering the whole brain with repetition time (TR) = 2.8 s, echo times (TE) = 12 and 35 ms, flip angle = 85 , FOV = 240 × 240 mm, resolution matrix = 80 × 80, slice thickness = 4 mm and voxel size = 3 × 3×4 mm. All functional scans were acquired using a tilt, up to 45° off the AC–PC line, to reduce ghosting artefacts in the temporal lobes. In Study 1, functional scans were collected in three 12 min runs; each run acquired 255 dynamic scans (including two dummy scans, which were excluded). In Study 2, functional scans were collected in four 4.3 min runs; each run contained stimuli from one of the four semantic conditions (faces, written names, CCp, CCw) and one of the modality-appropriate non-semantic control conditions and acquired 88 dynamic scans (including two dummy scans, which were excluded). To address field inhomogenities, a B0 field-map was acquired using identical parameters to the functional scans except for the following: TR = 599 ms, TEs = 5.19 and 6.65 ms. A high-resolution T1 weighted structural scan was acquired for spatial normalization, including 260 slices covering the whole brain with TR = 8.4 ms, TE = 3.9 ms, flip angle = 8°, FOV = 240 × 191 mm, resolution matrix = 256 × 206, voxel size = 0.9 × 1.7 × 0.9 mm. 

Study 3 used spin-echo data acquisition combined with post-acquisition distortion correction [ ]. This imaging sequence has been used previously to demonstrate robust ATL activation for a variety of semantic tasks [ , , , , ]. All scans for Study 3 were acquired on a 3T Philips Achieva scanner using an 8 element SENSE head coil with a sense factor of 2.5. The spin-echo EPI fMRI sequence included 31 slices covering the whole brain with echo time (TE) = 70 ms, time to repetition (TR) = 3200 ms, flip angle = 90°, 96 × 96 matrix, reconstructed resolution 2.5 × 2.5 mm and slice thickness 4.0 mm. 550 images were acquired in total, collected in two runs of 15 min each. Following the method of Embleton   et al  . [ ] for distortion-corrected spin-echo fMRI, the images were acquired with a single direction k space traversal in the left–right phase encoding direction. In between the two functional runs, a brief ‘pre-scan’ was acquired, consisting of 10 volumes of dual direction k space traversal SE EPI scans. This gave 10 pairs of images matching the functional time series but with opposing direction distortions (10 left–right and 10 right–left). These scans were used in the distortion correction procedure (see below). A high-resolution T2-weighted turbo spin-echo scan with an in-plane resolution of 0.94 mm and slice thickness of 2.1 mm was obtained as a structural reference to provide a qualitative indication of distortion correction accuracy. In addition, a high-resolution T1-weighted 3D turbo field echo inversion recovery image was acquired (TR ≈ 2000 ms, TE = 3.9 ms, Inversion time (TI) = 1150 ms, flip angle 8°, 256 × 205 matrix reconstructed to 256 × 256, reconstructed resolution 0.938 × 0.938 mm and slice thickness of 0.9 mm, SENSE factor = 2.5), with 170 slices covering the whole brain. This image was used for estimating transforms to warp functional images into standard stereotactic space. Full details of the distortion correction technique and preprocessing steps for Study 3 can be found here [ ]. 


#### fMRI data analysis 
  
For all three studies, data were analysed to compare the ‘social’ conditions to the ‘non-social’ conditions in the dataset ( ). For Study 1, the social condition was the faces and spoken names of famous people, and the non-social condition was pictures and spoken names of famous landmarks. For Study 2 the social condition was the faces and written names of famous people, and the non-social condition was the picture and word version of the Camel and Cactus test. For Study 3 the social condition was the socially relevant concept words, and the ‘non-social’ condition was the abstract non-social concept words. 

Data were motion-corrected and co-registered to the anatomical T1. Images were also spatially normalized to the MNI standard space and resampled to 3 × 3 × 3 mm dimensions, and smoothed using an 8 mm Gaussian FWHM kernel. First- and second-level analyses were carried out using SPM8 (Wellcome Department of Imaging Neuroscience, London;  ). At the first level, data for each study were entered into separate general linear model analyses by modelling each condition (social, non-social, non-semantic control) as a separate regressor using a boxcar function convolved with the canonical haemodynamic response function. Contrasts were calculated for each condition (social, non-social) versus the modality-relevant non-semantic control condition. At the second level, the data from each study were entered into separate one-way ANOVA models. The contrasts of interest were social > non-social semantics in each of the three studies ( ). ‘Social > non-semantic baseline’ + ’Non-Social > non-semantic baseline’ contrasts were also calculated at the second level (electronic supplementary material, figure 1). Unless otherwise stated, for Studies 1 and 2 a voxel height threshold of   p   < 0.001, cluster-corrected using an FWE   p   < 0.05 was used. For Study 3 an uncorrected voxel height threshold of   p   < 0.005 was used as per the originally reported results [ ].
   
Whole-brain analysis of Studies 1–3. Regions in blue show stronger activation for social > non-social semantic conditions, regions in red show stronger activation for non-social versus social semantic conditions. 
  

To explore differential activation across a set of ATL regions for different categories of social information, we created four   a priori   ROIs using the Marsbar toolbox [ ]; each ROI was 6 mm in diameter. The first ROI was a region commonly activated in functional imaging studies of semantic cognition [ , , ]. This ventral ATL ROI [MNI: −36 −15 −30; 36 −15 −30] was localized in Binney   et al.   [ ]. The next two regions were chosen because they are often reported in studies investigating the role of the ATL in face processing: (a) the temporal pole (TP), a region slightly anterior and medial to the vATL ROI and (b) the anterior middle temporal gyrus (aMTG), a region on the lateral surface of the ATL. Both the TP (ROI no.2) and aMTG (ROI no.3) were localized from a meta-analysis of 17 studies investigating face recognition in the ATLs (coordinates reported in  ). We used activation likelihood estimation (ALE) analysis [ ], a method that extracts coordinates from a set of neuroimaging studies and estimates the likelihood of activation across each voxel in the brain. The resultant ‘activation likelihood maps' can then be viewed on a standard brain. The ATL peaks from 17 ‘face-selective’ studies (  ) were entered and an overall activation likelihood map was generated to show ATL coverage. This was thresholded using a false discovery rate (FDR) of   p   < 0.05 to correct for multiple comparisons. Four peak MNI regions of activation likelihood were extracted (TP ROI no. 2: −37 4 −29; 31 1 −25, aMTG ROI no. 3: −59 −7 −18; 61 −1 −16). The fourth   a priori   ROI was the aSTG [MNI: −51 16 −27; −51 16 −27]; this subregion of the ATL has been previously associated with social processing [ , , ]. Coordinates were taken from Ross & Olson [ ] using a contrast comparing social versus animal concept words. The coordinates were converted from Talariach to MNI space using the tal2icbm_spm.m function. 




## Results 
  
### Whole-brain analysis: are there regions of the anterior temporal lobe which respond more to socially relevant concepts? 
  
First, we investigated whether there were subregions of the ATLs which responded more to socially relevant concepts compared to other types of semantic information. Regions involved in socially relevant semantic knowledge were identified using the whole-brain contrast social > non-social semantics in each of the three datasets separately. Peak activations for each study are listed in  .   shows a network of regions activated by the socially relevant semantic conditions (blue) across the three datasets. For Study 1 person-related clusters were primarily localized in the right hemisphere, including the ventral aspect of the ATL/TP, precuneus, orbitofrontal cortex, hippocampus, anterior middle temporal gyrus (aMTG) and the temporo-parietal junction ( ). These regions (with the exception of the orbitofrontal cortex and ATL) are in line with the findings from previous studies of conceptual category representation, which showed transmodal responses to person knowledge in the precuneus [ , ], suggesting these regions may play a specific role in processing more socially salient semantic knowledge. No other category differences were localized in the ATLs (i.e. non-social > social). Activation to transmodal landmarks were widespread, and included bilateral parahippocampal gyri, precuneus, lateral occipital cortex and left inferior frontal gyrus ( ).
   
Peak coordinates from the whole-brain analysis across each of the three datasets. 
  

For Study 2, an identical pattern of activation was observed in the midline structure of the orbitofrontal cortex and the precuneus; however, at this threshold there were no significant clusters in the temporo-parietal junction or the ATL. Activation to the CCT was localized to the left posterior temporal cortex, left lateral occipital cortex and left inferior frontal gyrus. Study 3 also showed stronger activation for socially relevant concepts in the left temporo-parietal junction, including the supramarginal gyrus and the posterior MTG, which extended into the posterior insula cortex. There were also two medial occipital clusters, a left hemisphere cluster in the superior aspect of the cuneus and a bilateral cluster peaking at the lingual gyrus. There was also a cluster in the left inferior frontal gyrus. 

Across all three studies there was significant overlap across the ATL and the brain more widely (pink) between the contrasts ‘social > control’ and ‘non-social > control’ (electronic supplementary material, figure S1) when comparing the conditions of interest over the non-semantic baseline, providing support for the hypothesis that both types of semantic information are processed by similar subregions of the ATL. 


### ROI analysis: do anterior temporal lobe subregions respond to transmodal person knowledge or face information? 
  
Next, we investigated whether the ATL subregions identified in the whole-brain analysis responded selectively to   transmodal   person knowledge, based on previous research showing that the ATL is activated by famous names as well as faces [ , ]. To do this, we used   a priori   ROI analysis, using peaks taken from the previous literature. Data from Study 1 and Study 2 were analysed using 2 category (social, non-social) × 2 modality (picture, spoken/written) ANOVAs in each region of interest. 

 shows a gradient of activation across the ATLs in Study 1. This functional gradient progresses from a transmodal, pan-category response in the vATL ( , ROI 1) to a modality-selective (auditory) response in the aSTG ( , ROI 4). The   a priori   vATL ROI (no.1) responded to both social and non-social category information in equal measures, as well as visual and auditory information. In line with this, the category×modality ANOVA showed no significant main effects of category or modality in either hemisphere. This replicates previous findings of transmodal responses in the vATL [ , ]. However, there was a significant category×modality interaction in the left vATL (  F   = 14.90,   p   = 0.001). This interaction may be driven by an intrinsic word length effect for the names of landmarks versus people (16.2 characters versus 12.7 characters;   t   = 5.31,   p   < 0.001); this intrinsic nature of the stimuli could have increased the difficulty of processing for the names of landmarks leading to a greater activation. No significant interaction was found in the right vATL.
   
ROI analysis results for Study 1. Results are shown for four ROIs derived from the literature. Blue bars represent the social conditions and grey bars represent the non-social conditions. All bars show the relative activation for each condition of interest compared to its matched non-semantic control condition. Error bars show standard error. 
  

In contrast to the transmodal, pan-category results in the vATL, the more anterior TP ROI (no. 2), particularly in the right hemisphere, showed selective activation for faces and spoken names of people, as well as the spoken names of landmarks. In the right hemisphere, the category × modality ANOVA showed a significant main effect of category (  F   = 5.13,   p   = 0.04), reflecting overall increased responses to person knowledge compared to landmarks. There was also a significant category×modality interaction in the right hemisphere (  F   = 7.42,   p   = 0.01). In the left hemisphere, there was a main effect of modality (  F   = 14.64,   p   = 0.001), reflecting overall increased responses to auditory stimuli compared to visual stimuli. The peak coordinate reported here (TP peak in Study 1: −45 7 −36; 38 3 −37) aligns well with previously reported coordinates in the face-processing literature ( ; ROI no. 2), indicating that the anterior vATL region responds to transmodal person knowledge, rather than face knowledge specifically [ ]. 

Extending dorsally into the aMTG (ROI no.3), the same pattern of activation for faces and spoken names of people and the spoken names of landmarks remained. This was illustrated in a significant category×modality interaction in the right hemisphere (  F   = 11.69,   p   = 0.0003). This effect trended towards significance in the left hemisphere (  F   = 3.54,   p   = 0.08). In both hemispheres, there was a significant main effect of modality (left:   F   = 16.87,   p   = 0.0001; right:   F   = 48.26,   p   < 0.0001), driven by the stronger response to auditory stimuli compared to visual stimuli. Again, coordinates from this region align with those previously reported in the face-processing literature ( ; ROI no. 3); however, the overall response to auditory stimuli may reflect this region's proximity to auditory processing areas in the superior temporal gyrus. 

By contrast, in the aSTG (ROI no.4) there was no longer a category effect for social > non-social stimuli; instead this region responded selectively to the auditory conditions regardless of category (main effect of modality; left:   F   = 21.53,   p   < 0.0001; right:   F   = 10.10,   p   = 0.005). The main effect of category was not significant in either hemisphere (left:   F   = 1.14,   p   = 0.30; right:   F   = 0.71,   p   = 0.41). 

The main finding from Study 1, therefore, was of two clusters in the vATLs, both transmodal in nature, one dominant area which responded to all conceptual categories, including people ( , ROI no. 1), and another more anterior ‘person-related’ cluster ( , TP ROI no. 2). Across the ATLs a gradation from a transmodal effect to an auditory selective response was shown, peaking in the aSTG (ROI no. 4). 


### Does the pattern of activation shown in Study 1 replicate across different modalities of person knowledge? 
  
 shows the ROI results for Study 2. Here, the vATL ROI showed the same pattern of activation as in Study 1—responding regardless of stimulus category and modality of presentation (picture versus written word). The only significant effect in the category×modality ANOVA was a main effect of modality in the right vATL (  F   = 6.34,   p   = 0.02). This was driven by reduced responses to written words (names and written versions of the Camel and Cactus) in the right hemisphere. This finding aligns with previous reports that written words produce a left lateralized response within the ATLs, whereas pictorial information produces bilateral ATL responses [ ]. The only other region to show a significant effect in Study 2 was in the left aMTG, which showed a significant main effect of category (  F   = 8.49,   p   = 0.009); this was driven by a greater response to social > non-social stimuli. This effect trended towards significance in the right hemisphere (  F   = 3.69,   p   = 0.07). Critically, the aSTG, which in previous studies has shown a category effect for socially relevant (abstract) concept words [ , ], showed no significant interaction for socially relevant concrete words (i.e. famous names) in either the left (  F   = 0.23,   p   = 0.64) or right hemisphere (  F   = 1.80,   p   = 0.20).
   
ROI analysis results for Study 2. Results are shown for four ROIs derived from the literature. Blue bars represent the social conditions and grey bars represent the non-social condition. All bars show the relative activation for each condition of interest compared to its matched non-semantic control condition. Error bars show standard error. 
  


### Do anterior temporal lobe subregions also respond to different kinds of social semantic information? 
  
Finally, we asked the question whether the pattern of results shown for famous people generalize to other kinds of socially relevant semantic knowledge. For this question, data previously published comparing activation for socially relevant words [ ] were plotted in the same ROIs. Paired t tests were used to compare the social versus non-social concepts.   shows the results from Study 3. Again the vATL responded equally to social and non-social concept words (left =   t   = 0.36,   p   = 0.72; right =   t   = 1.65,   p   = 0.12), replicating the pattern of results shown in Study 1 ( ) and Study 2 ( ). The only regions which showed a category effect were the right aMTG (paired   t   test:   t   = 3.17,   p   = 0.005) and the right aSTG (paired t test:   t   = 2.72,   p   = 0.01), as reported in the original paper [ ].
   
ROI analysis results for Study 3. Results are shown for four ROIs derived from the literature. Blue bars represent the social conditions and grey bars represent the non-social condition. All bars show the relative activation for each condition of interest compared to its matched non-semantic control condition. Error bars show standard error. 
  



## Discussion 
  
This study explored the neural organization of conceptual knowledge in the ATLs. One prominent view holds that the ATLs contribute to semantic representation in a pan-category manner [ , , ], while, in parallel, other researchers have proposed the ATLs respond selectively to socially relevant concepts [ , , , ] including faces [ , , ]. For the first time, we directly compared the predictions of these different accounts of ATL function by using neuroimaging protocols that improve signal in the ATLs [ , ]. The principal finding was graded variation in ATL function. One dominant, bilateral vATL cluster responded in a pan-category and transmodal manner, overlapped with peaks reported in previous semantic studies. A second, more anterior, bilateral vATL cluster responded more weakly albeit preferentially to transmodal person knowledge and coincided with peaks reported in the face recognition literature ( ; tables   and  ). Critically, the pan-category region responded more strongly in all conditions (including person knowledge) than the anterior person-related cluster. Thus the organization of vATL function does not seem to reflect a series of mutually exclusive category-selective regions but rather one in which a dominant core vATL is joined in processing people-related knowledge by the more anterior subregion. Finally, a region in the aSTG responded to socially relevant abstract words but not to socially relevant concrete words (e.g. famous names). This region also responded to all auditory inputs in a similar manner. 

These results can be accommodated by a graded version of the hub-and-spoke model of semantic representation [ , , ]. The pan-category, transmodal responses within the core vATL accord closely with previous studies, using clinical and cognitive neuroscience methods, which implicate this area as the centre point of a transmodal representational ‘hub’ for conceptual knowledge [ , – , ]. On this view, the ATL-hub interacts with various distributed regions (coding modality-specific sources of information) to form coherent, generalizable concepts [ , , , ]. Damage to the ATLs in SD not only generates a pan-category, transmodal semantic deficit [ ], but also the degree of vATL hypometabolism correlates with their level of semantic impairment [ ]. Our findings also accord with multivariate neuroimaging studies showing that vATL voxels code not only the conceptual convergence of multiple sensory features e.g. colour/shape; [ ] but also conceptual knowledge for different exemplars, independently of their conceptual properties e.g. how/where an object is used [ ]. An important corollary of this graded hub-and-spoke theory is that the distinct vATL peaks localized here do not represent separate functional modules in the traditional sense. Instead, we believe that they are markers of continuous, graded information coding within the ATLs. 

The transmodal, person-related responses in the (right) anterior vATL subregion (TP; ROI no. 2) can be accounted for by previous proposals that the ATLs are not entirely homogeneous in their function but instead develop graded specializations as a function of differential connectivity to extra-temporal regions [ , , , , , ]. According to this ‘graded’ hub-and-spoke theory, the core vATL is transmodal and pan-category because it is the centre point of multimodal inputs/outputs. Moving away from this core region, functions become increasingly influenced by one or more dominant inputs/outputs reflecting stronger connectivity to a specific neighbouring sensorimotor/verbal region [ , ]. Extending this line of argument, the   anterior   vATLs might play an important role (in addition to the core region) in representing socially relevant concepts (e.g. person knowledge), because of connections to limbic and orbitofrontal cortices via the uncinate fasciculus [ – ]. This is in line with studies indicating that temporo-polar regions contribute to the representation of social and emotional concepts [ , , , ]. The role of such ATL–limbic connectivity in person knowledge remains an intriguing area for future research. Consistent with this hypothesis, other structures implicated in social cognition, including the orbitofrontal cortex and precuneus, also showed transmodal person-related responses ( ). These regions are consistent with studies exploring conceptual category representation across the whole brain [ , ]. Importantly, the graded hub-and-spoke approach does not preclude the presence of other category-preferential responses within the ATLs, based on their particular patterns of connectivity [ , – ]. 

The laterality of ATL responses to conceptual knowledge is currently highly debated [ , – ]. Some studies indicate that patients with right ATL lesions are more likely to be prosopagnosic than those with left ATL damage [ , , ]. Electrophysiological recordings from patients with intractable epilepsy have also revealed face-selective electrophysiological potentials in the right vATL [ ]. Here, we found that activations for person knowledge in the ATLs were highly bilateral. This also follows data that patients with ATL atrophy/resection show a transmodal person deficit [ , – ]. In addition, there were subtle hemispheric variations in the person-selective ATL regions. While the right vATL exhibited equivalent activation for faces and spoken names, the left was more active for the spoken names. This is consistent with studies suggesting that the left ATL is somewhat more important for retrieving knowledge from verbal input including people's names [ , , , – ] as well as being critically involved in generating names of all types from semantic knowledge [ , , , ]. 

This study also helps to resolve another conundrum posed by the literature: the general semantics literature has suggested that the vATL is a transmodal region, whereas the face-processing literature has implicated this region, specifically, in recognition of faces. The use of visual stimuli may have been based on the assumption that the vATLs are a purely visual region because of their anatomical positioning at the apex of the visual ventral stream [ , ]. Indeed, studies have shown connectivity between the vATLs and face-selective regions in the posterior fusiform gyrus [ , , ], and disruption of this anterior–posterior connectivity has been implicated in congenital prosopagnosia [ , ]. The transmodal responses observed here and in other studies using a variety of neuroscience methods [ , , , ] suggest that in addition to the strong visual input to the vATLs, it also receives input from other modalities, consistent with previous findings of transmodal responses to faces and names [ ]. This study bridges, therefore, between the face-processing and semantic processing literatures by showing   transmodal   person-related vATL activation [ , , ]. In keeping with the graded hub-and-spoke model, these findings suggest that the vATLs support the coding of coherent, transmodal semantic representations of people (alongside other categories of concept)—a proposal that accords with models of familiar face processing [ ]. 

The responses to socially relevant abstract words in the aSTG is a highly replicable result, albeit with some debate regarding the laterality of response [ , , , , ]. More recently, the causality of this region in processing social concepts has been confirmed using transcranial magnetic stimulation [ ]. In this study, we were able to show that this region does not respond selectively to other kinds of socially relevant words, in particular the names of famous people (Study 2). This difference between abstract and concrete social concepts might reflect the gradient of concreteness previously shown across the ATLs [ ]. In a functional imaging study the authors showed that abstract words activated aspects of the dorsolateral ATL and inferior frontal cortex relatively more than concrete words; by contrast, concrete words activated aspects of the ventromedial ATL relatively more [ ]. The interpretation of this gradation was that it reflected the underlying properties of the words; concrete words are more associated with visual information, whereas abstract words are associated more with auditory–verbal information and might require greater executive control. In this study, one explanation for the result that famous names activate the vATL more may be that names of people are more intrinsically linked to a mental image of their corresponding face. This visual information may be lacking when associated with abstract words describing social concepts (e.g. polite). 

In conclusion, an emerging literature suggests the vATLs exhibit face-selective responses [ , ]. Our results indicate that this picture is incomplete. An anterior vATL region does respond to images of people but does so equally strongly for their spoken names, indicating a transmodal role in the representation of person knowledge. Slightly posterior to this site, the ‘core’ vATL responds even more strongly and equally for all conceptual categories. This study provides clear evidence in favour of the ATL as a graded transmodal hub which supports coherent conceptual representation across all categories and modalities [ ]. Variation of function in this region reflects graded changes in its connectivity to other brain areas, including ATL–limbic connections, which may be critical for socially relevant concepts including people. Given the inherent broad definition of what constitutes ‘social concepts’, future research should compare and contrast the activation within and across the ATLs with regard to other exemplars of socially relevant concepts. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-3'>
<h2>3. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/25611512/' target='_blank'>25611512</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Learning-Induced Plasticity in Medial Prefrontal Cortex Predicts Preference Malleability</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Neuron</p>
<p><strong>Publication Year:</strong> 2015</p>
<p><strong>DOI:</strong> 10.1016/j.neuron.2014.12.033</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4306543/' target='_blank'>4306543</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study reports an fMRI experiment in healthy adults (mean age 25.6±5.6, within 18–60). The task is explicitly social: subjects learned and made inter-temporal choices for self and for other agents (human confederate and computer), examining social influence on preferences. Imaging analyses include whole-brain random-effects contrasts with cluster-level FWE correction reporting mPFC, pMFC, striatum, and visual cortex effects; results are not limited to ROI-only findings (although some ROI/jackknife follow-ups are used). It is an original empirical fMRI study (not a review) and participants were neurologically and psychiatrically healthy. Therefore it meets all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>   Summary  
Learning induces plasticity in neuronal networks. As neuronal populations contribute to multiple representations, we reasoned plasticity in one representation might influence others. We used human fMRI repetition suppression to show that plasticity induced by learning another individual’s values impacts upon a value representation for oneself in medial prefrontal cortex (mPFC), a plasticity also evident behaviorally in a preference shift. We show this plasticity is driven by a striatal “prediction error,” signaling the discrepancy between the other’s choice and a subject’s own preferences. Thus, our data highlight that mPFC encodes agent-independent representations of subjective value, such that prediction errors simultaneously update multiple agents’ value representations. As the resulting change in representational similarity predicts interindividual differences in the malleability of subjective preferences, our findings shed mechanistic light on complex human processes such as the powerful influence of social interaction on beliefs and preferences. 
   Highlights  
  
Learning the values of another causes plasticity in a mPFC value representation 
  
This plasticity predicts how much subjects’ own preferences change 
  
Plasticity is explained by a striatal surprise signal 
  
Value coding in mPFC occurs independently of the agent for whom a decision is made 
  
  
Garvert et al. demonstrate that learning the preferences of another person increases the similarity between neural value representations for self and other. This plasticity in medial prefrontal cortex predicts how much one’s own preferences shift toward those of the other. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (41627 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Information in the brain is encoded within distributed neuronal populations such that individual neurons typically support more than one representation or computation. Neurons in medial prefrontal cortex (mPFC), for example, perform self-referential as well as social value computations ( ). Whereas it is traditionally suggested that computations for self and other are performed within separate populations of neurons ( ), recent work suggests a functional organization within this region does not neatly conform to such a distinction by agent. Instead, value computations on behalf of any individual can be realized by the same circuitry ( ), and the neural code depends only on the subjective value of an offer. In light of this, we conjectured that multiple value computations might be updated simultaneously if plasticity is introduced into this circuitry. 

The contribution of overlapping neural circuitry to distinct computations has previously been demonstrated during delegated inter-temporal choice ( ). In inter-temporal choice paradigms, subjects reveal their preferences for larger reward delivered later versus smaller reward that arrive sooner. Choice in this context is quantified by a “temporal discount rate” ( ), believed to index forms of behavioral impulsivity ( ) and an ability to imagine future outcomes ( ). When subjects are asked to make such inter-temporal choices on behalf of another individual (“delegated inter-temporal choice”), they rapidly learn the confederate’s discount rate ( ). This adaptability depends on the medial prefrontal cortex, where a neural circuitry used to compute a subject’s own values also computes those of a confederate, enabling rapid switches between the two computations ( ). 

We reasoned that if the same circuitry in the mPFC computes the value of a delayed offer irrespective of agents, plastic changes necessary to learn a new partner’s preferences might have consequences for a subject’s own value computations. The presence of such plasticity would also be expected to induce behavioral change in the subject’s own temporal discount rate, a parameter usually assumed to index a stable personality trait ( ). One can conjecture that such plasticity might underlie social conformity effects, where individuals adjust their beliefs or preferences to align more with those with whom they interact ( ). 

At a neuronal level, a formal test of these predictions requires a fine-grained access to neural populations supporting distinct value computations, as well as a robust measure of learning-induced change in activity of these same populations. Despite its coarse spatial resolution, fMRI can reveal relationships between underlying cellular representations. In particular, fMRI adaptation paradigms can be finessed to measure plastic changes associated with the behavioral pairing of different items ( ). The principle of fMRI adaptation builds on the idea that the repeated engagement of the same neuronal population leads to a diminished response and attenuated BOLD signal, even though the underlying biophysical mechanism remains ambiguous ( ). 

Here we used an fMRI adaptation paradigm to measure the relationship between neuronal value representations for self, a familiar other whose preferences had been learnt prior to scanning and a novel confederate as this latter agent’s preferences were learnt. We deployed a dynamic repetition suppression procedure to provide us with a probe of plastic neural changes associated with learning a new flexible computation. We hypothesized that plasticity associated with this new learning would impact upon the preference representation for self as a consequence of a neuronal representation that maps agent and offer onto an agent-independent measure of subjective value. In essence, this predicts that neuronal value representations between self and a novel other should become more similar with learning, in line with a behavioral shift in preference. An alternative hypothesis posits separate value computations for distinct agents. In such a case, a subject might use their own separate neural representations as a proxy for understanding another’s traits, and an independent neuronal value representation for this other would be constructed through learning-induced plasticity ( ). This alternative scenario predicts that neural value representations for self and other should become less similar with learning. In terms of a mechanism driving such plasticity, we reasoned that the same prediction errors that drive learning about a new partner’s inter-temporal preferences would also induce shifts in the subject’s own discount rate toward that of the partner. 


## Results 
  
### Discount Rates Are Susceptible to Social Influence 
  
To examine whether learning about the preferences of another agent impacts on subjective inter-temporal preferences, we tested 27 subjects on a standard inter-temporal choice task both before, and after, performing the identical task on behalf of a partner ( A and 1B). As in the standard format, subjects deciding for themselves chose between an immediately available smaller reward and a delayed larger reward. The degree to which delay diminishes the value of a reward was then quantified by a discount rate, computed from each subject’s actual choices both before and after the experimental manipulation. The latter involved a context whereby subjects performed the very same task but now chose the option they inferred a confederate would prefer. After each trial they were given feedback about the choice the confederate had actually made, such that they could learn to simulate these choices in future trials. 

Subjects learnt quickly, and accurately, to choose according to a novel partner’s preferences ( C and S1D). Subjects believed that the partner was a human participant playing the game in a neighboring room ( G and S1H). In actual fact, and in part motivated by a need for good experimental control, we delivered feedback of a simulated player with preferences very different from the subjects’ own (see  ). 

Notably, we found that, after learning a partner’s preferences, subjects’ own discount rate shifted in the direction of the partner ( , t  = 3.06, p = 0.006,  C). Their estimate of the novel other’s preferences remained stationary ( , t  = 0.99, p = 0.33) and was not biased toward subjects’ own preferences (t  = 0.49, p = 0.63). This effect is not easily understood as a social norm effect ( ), as we also observed discount rates shifted similarly when subjects were instructed they were deciding on behalf of a computer agent (t  = 3.89, p < 0.001,  F). 

One account of this shift in preference is that it arises out of a simulation of the other’s preferences. In order to test whether such simulation is crucial for this shift or whether the behavior can be explained by simple stimulus- or action-based reinforcement, we designed a category-learning control experiment ( ). This consisted of the same stimuli and actions, but the necessity to simulate another’s discount rate was removed. Subjects were presented with a geometric depiction of a given choice on the screen (x axis: delay of the latter option; y axis: ratio of magnitudes M /M ;  A, right) and instructed to choose according to the location of the dot with respect to an imaginary isoprobability line. Rather than using feedback to update a value simulation, subjects now updated their belief about the orientation of this line. In this scenario, subjects’ discount rates did not shift, indicating that subjects were not merely repeating previous choices they had made on behalf of the other (t  = 0.61, p = 0.55; see  F). This latter finding emphasizes a necessity for preference simulation for another agent in order to modulate a discount rate. 


### Subjective Value Changes Are Induced by Learning 
  
The above account suggests that learning to compute the preferences of another agent induces plastic changes in the neural architecture responsible for personal valuation. This in turn predicts the neural population engaged during the computation of self valuation should change over the course of the experiment. This population should either become closer to that evoked during valuation for the partner if the representational structure of an offer depends solely on its subjective value irrespective of the individual. Alternatively, it should become less close if separate agent-specific representations exist and subjects construct an independent representation for the novel other as a consequence of learning. To test for such change in similarity between neural representations for self and others we interleaved trials from the delegated inter-temporal choice task with “probe” trials in the fMRI scanner. These probe trials enabled us to measure repetition suppression between individuals ( D and 1E). We reasoned that if self and partner valuation mechanisms overlapped more after learning than before, in line with an increase in behavioral similarity, then this predicts greater repetition suppression at the end of the experiment than at the beginning. If, however, subjects constructed a representation of the novel other from their representation of self, then this predicts the very opposite, namely repetition suppression at the beginning of the experiment, which disappears as subjects build a separate representation of the novel partner. 

To be certain that any effects were driven by learning about the partner, as opposed to exercising a choice per se, we introduced a third player (a familiar partner) whose discount rate had been learnt prior to scanning. This controlled for non-specific time-dependent signal changes not associated with learning of new preferences. Thus, our experiment comprised three players: the subject (“self”), a partner whose preferences were learnt prior to scanning (“familiar other”), and a partner whose preferences were learnt during scanning (“novel other”). The familiar and novel others’ choices were simulated based on discount rates placed equally far apart on opposite, and counterbalanced, sides of the subject’s original discount rate. This meant that one partner had a smaller, and the other partner a larger, discount rate than the subject himself. 

We scanned 27 subjects while they performed the two interleaved tasks. In choice trials, as in the behavioral experiment described above, subjects again made inter-temporal choices for themselves and for the two partners. In “probe trials,” subjects performed evaluations serially on behalf of different players, allowing us to measure repetition suppression between the value representations of different individuals ( E). After each choice trial for the novel or the familiar partner, but not after probe trials, subjects were given feedback about the choice the confederate had made. 

In line with our behavioral results, subjects’ discount rates shifted toward the discount rate of the familiar partner during preference learning prior to scanning (t  = 3.17, p = 0.004,  F). During scanning, both subjects’ own discount rate (t  = 3.05, p = 0.006) and subjects’ estimated discount rate of the familiar partner (t  = 2.87, p = 0.008) shifted toward the newly learnt discount rate of the novel partner, with a stronger relative shift evident for subjects’ own discount rate (t  = 2.18, p = 0.04) but comparable absolute shifts (t  = 0.72, p = 0.48). These preference shifts were therefore not simply associated with repeating the partner’s choices but instead are most parsimoniously explained as induced by learning a new individual’s preferences. 


### Plasticity between Neural Representations of Self and Other 
  
To address whether a measured change in subjective preference is linked to plasticity in neural populations computing valuations for self, we focused our analysis on the probe trials. We first established that we could measure repetition suppression by comparing brain activity elicited by simulating values for an agent when preceded by the same agent compared to a situation where an agent was preceded by another agent. Different agents were indicated to the subject by different colors on screen ( D). Unsurprisingly, we observed fMRI adaptation in the visual cortex (p < 0.001, peak t  = 16.93, [30, −61, −8], reported here and in subsequent fMRI analyses as familywise error (FWE) corrected on cluster level,  A) ( ), but also in a network that included mPFC (p = 0.02, peak t  = 5.76, [3, 53, −11]) and left superior temporal sulcus (STS) (p < 0.001, peak t  = 4.95, [−51, −13, −8]). The latter two regions are associated with mentalizing ( ), valuation for self ( ), and valuation for others ( ). While this main effect of repetition suppression does not dissociate visual from agent-specific effects, it confirms that similarity in neural patterns evoked in a valuation network can be indexed by repetition suppression ( ). 

We reasoned that we could use this index of neural similarity to investigate whether the observed shift in subjective preferences was linked to plastic changes in the valuation network. If the neural code depends on the subjective values of a given offer alone, then repetition suppression should emerge between self and novel other over the course of the experiment, given that discount rates for self align with discount rates for the novel other. If, on the other hand, the mPFC encodes value differentially depending on agent, where learning another’s preferences involves the construction of an independent representation of this novel other from a representation of self, then repetition suppression should decrease over the course of the experiment. While a similar change in suppression might also be predicted between novel and familiar others, there should be no such change in suppression between self and familiar other if in fact we are indexing changes induced by new learning. 

We designed a contrast that measured the change in repetition suppression between self and novel other from block 1 to block 3, controlled for by the change in repetition suppression between self and familiar other over the same blocks (see  ). The only brain region to survive whole-brain statistical correction was in mPFC ( B, p = 0.01, peak t  = 3.82, [−12, 53, 1]), although sub-threshold clusters in the left and right STS were also present (p = 0.27, peak t  = 3.77 and p = 0.48, peak t  = 3.38, respectively). This region overlaps with an area involved in self-referential processing and in encoding value on probe trials ( B and S3C). There were no significant effects for the opposite interaction. This change cannot be due to visual effects, as we controlled for these both by inclusion of the familiar agent and separately by the comparison between early and late blocks in the experiment. Consequently, visual regions do not show these condition-specific changes in suppression ( ). Neither can the effect be due to novelty or differences in processing speed, as no differences between main effects of novel and familiar others were seen in this region ( A) or in the response times ( A and S4B). Furthermore, an equivalent contrast measuring the change in suppression between self and novel other, but now controlling for the change in suppression between familiar and novel other, revealed a similar change in activity in an overlapping brain region ( C). Hence, in the mPFC learning the preferences of a novel agent specifically increased repetition suppression between representations of self and this novel partner. 

To further investigate these mPFC suppression effects, we employed a jack-knife procedure across subjects to extract parameter estimates from the cluster of interest. Consistent with the whole-brain analysis, we found a significant change in novel-to-self/self-to-novel suppression ( D, t  = 2.86, p = 0.008), but not in self-to-familiar/familiar-to-self suppression from block 1 to block 3 (t  = 0.64, p = 0.52). The change in novel-to-familiar/familiar-to-novel suppression in the same region of interest (ROI) was in the same direction, but did not reach significance (t  = 1.54, p = 0.14), and was smaller than the change in novel-to-self/self-to-novel suppression (t  = 1.65, p = 0.05). Since overall activity in mPFC for self trials was greater than activity for other trials ( B), sensitivity to repetition suppression may differ depending on the order of the two agents. To explore potential differences, we decomposed the contrasts described above. Changes in repetition suppression between self and novel other were observed in both directions ( E) but were only significant when self trials were the priming and not the test trials ( E; ANOVA: left, F  = 3.39, p = 0.04, right F  = 1.55, p = 0.21). 


### Plasticity in mPFC Predicts Discount Rate Shifts 
  
If the observed behavioral change in preference is related to learning-induced plasticity in value computations, then the increase in representational similarity between self and novel other should predict a subject’s shift in preference. The increase in self-to-novel relative to self-to-familiar suppression over blocks did indeed predict the shift in subjects’ own discount rate toward the novel other (partial correlation, r = 0.54, p = 0.007,  A), but not the same shift in the subjects’ estimate of the familiar other’s discount rate (partial correlation, r = 0.15, p = 0.46,  B), although a direct comparison of these effects in a multiple regression analysis did not reach significance (t  = 0.71, p = 0.24). The shift in subjects’ estimate of the familiar other’s preferences was instead loosely related to an increase in representational similarity between familiar and novel other ( ). The fact that the behavioral estimate for a shift in discount rate was derived from choice trials, whereas the neural plasticity effect was extracted from probe trials, strongly suggests that learning a partner’s choice induces a stable plasticity in regions involved in value computation. 


### Plasticity in mPFC Is Predicted by Surprise Coding in the Striatum 
  
A plausible mechanism for inducing plastic change is surprise or prediction error, which in this context arises when the familiar or the novel partner’s choices diverge from the choice the subjects themselves would have made given the same choice context. Bayes-optimal estimates of this measure (see  ) were reflected in the posterior medial frontal cortex (pMFC) ( A, p = 0.04, peak t  = 4.09, [−9, 29, 58]), a region previously associated with surprise coding in monkeys ( ), as well as in both insula and striatum (caudate nucleus), although these did not survive a stringent multiple comparisons correction (right insula: p = 0.16, peak t  = 8.37, [30, 26, −8]; left insula: p = 0.19, peak t  = 6.25, [−33, 26, −5]; left striatum (p = 0.84, peak t  = 3.44, [3, −25, −8]). pMFC and striatum are strongly implicated in the expression of a prediction error type signal in reinforcement learning ( ), as well as in signaling a discrepancy between an individual’s behavior and the behavior of a group ( ). An alternative measure of prediction error, where surprise was quantified as the discrepancy between the predicted choices of the partner and the partner’s actual choices, did not yield significant activity in any area of the brain. A more lenient cluster-defining threshold of p = 0.05 revealed much smaller clusters in a similar network as the first surprise measure that did not survive multiple comparisons correction (e.g. pMFC, p = 1.0, peak t  = 2.72, [6, 35, 40]). 

A striatal prediction error type signal is known to drive learning through an influence on cortico-striatal plasticity ( ). In line with this notion, the BOLD correlate of the surprise about the novel partner’s choices in the striatum predicted the behavioral shift in subjects’ own discount rate ( B, r = 0.50, p = 0.01) as well as the change in self-to-novel versus change in self-to-familiar neuronal suppression over blocks in mPFC ( C, r = 0.41, p = 0.04). No such relationship was evident for pMFC or insula activity and mPFC plasticity (r = 0.04, p = 0.84 and r = 0.14, p = 0.48, respectively). 

Finally, if prediction errors cause plasticity, and plasticity in turn causes the shift in subjects’ discount rate, then plasticity in mPFC should formally mediate the impact of the striatal surprise signal on the shift in discount rate. We used single-level mediation to test this hypothesis ( ). The path model jointly tests three effects required if indeed mPFC plasticity provides the link between a surprise signal and the shift in discount rate: namely, the relationship between striatal surprise effects and mPFC plasticity (path a), the relationship between mPFC plasticity and shift in discount rate (path b), and a formal mediation effect (path ab) that indicates that each explains a part of the discount rate shift covariance while controlling for effects attributable to the other mediator. All three effects were significant in a mediation analysis (path a = 0.15, SE = 0.07, p = 0.04; path b = 0.30, SE = 0.12, p < 0.001; path ab = 0.05, SE = 0.03, p = 0.01,  ), supporting the idea that prediction errors influence the discount rate by inducing mPFC plasticity, which in turn impacts upon choice behavior. Hence, subjects with the largest striatal surprise signal at outcome of choice trials exhibited both the largest changes in representational similarity on probe trials and the largest changes in preferences, suggesting a role for striatal prediction error signals in inducing cortical plasticity and associated behavioral change. 



## Discussion 
  
The brain’s representational architecture involves population codes wherein individual neurons contribute to a multitude of computations. We set out to investigate whether multiple neuronal representations can be updated simultaneously by learning-induced plasticity targeting one computation alone. The approach we developed exploited repetition suppression ( ) to probe the similarity between distinct neural representations ( ) by interleaving probe valuation trials with decision blocks that induced prediction errors and learning. While the biophysical mechanisms underlying fMRI repetition suppression remain ambiguous ( ), in a careful experimental design this approach allows inferences about population coding with respect to precise features of stimuli ( ) or computations ( ). 

We were interested in changes of value representational similarity over time. By asking subjects to evaluate presented options on behalf of themselves, a novel other whose preferences were acquired during on-line scanning and a familiar other whose preferences had previously been learnt, we could interrogate representational similarity in neuronal populations encoding valuation for these three agents. In line with previous reports that highlight a social influence on the valuation of objects ( ), we found learning about the preferences of a novel agent had clear behavioral consequences evident in a shift in subjects’ own, as well as their estimation of a familiar other’s, discount rate. This behavioral effect coincided with an increase in neural representational similarity in the mPFC. This supports a view that value representations in the mPFC are not aligned to the frame of reference of an individual. Instead, the increase in neuronal overlap tied to a shift in behavioral preferences suggests that the mPFC encodes agent-independent representations of subjective value. 

The presence of a learning-induced representational plasticity for value is likely to depend on generic learning mechanisms. The most influential computational account posits a role for a reward prediction error implemented via phasic activity of dopamine neurons ( ), a putative teaching signal for cortico-striatal learning ( ). Prediction errors align with the dimension relevant for learning in a given situation. They manifest as a sensory prediction error when subjects learn to predict a sensory event ( ), a probability prediction error when subjects learn about reward probability ( ), and a social expectancy prediction error when group preferences diverge from subjects’ own valuations ( ). In the current experiment, a prediction error (expressed in pMFC, insula, and striatum) corresponds to the surprise subjects experience when a partner’s choice is incongruent with their own preference. This accords with previous studies demonstrating an expression of a similar signal representing a discrepancy between one’s own and a group’s opinion ( ). Crucially, our results extend on these reports by showing this error coding is directly related to an expression of plasticity in mPFC, a region widely implicated in tracking preferences for stimuli ( ) as well as inter-temporal preferences ( ). 

The mPFC region displaying the change in repetition suppression is a complex and heterogeneous area with strong connections to regions such as the amygdala, hippocampus, hypothalamus, and insula enabling access to sensory, visceral, and emotional information. It is considered ideally placed for self-referential processing ( ) and for attributing value to stimuli across many reward contexts ( ) and internally generated states ( ). However, a mPFC value computation is also remarkably flexible, and can occur even if direct experience is not available ( ) or if there is a requirement for an abstract model of task structure ( ). This flexibility is vital in social cognition, where a model of the preferences and intentions of another individual needs to be decoupled from the physical and perceptual reality of a subject’s own internal state ( ). Traditionally, it has been suggested that such computations occur in distinct circuitries, where a ventral sector of the mPFC encoding subjective stimulus values ( ) is complemented by a dorsal sector representing the mental states of others ( ). However, this notion is challenged by an observation that a dorsal-ventral axis can be better understood in terms of executed versus modeled choices ( ). The latter observation supports the idea that the very same area encodes subjective value irrespective of the frame of reference, a notion strongly supported by our current observation that a behavioral shift toward the value of a novel agent is mirrored by an increase in neural overlap. 

Irrespective of the exact nature of the observed plasticity, the underlying mechanism would seem to necessitate an overlap in neural populations encoding values for a novel other, self, and a familiar other. How exactly might the brain calculate discounting preferences with neural populations that are prone to the observed shifts in preference? Theoretical studies suggest an agent’s overall preferences might arise out of a summation over a distributed set of discounting units ( ). This is consistent with recordings in rat orbitofrontal cortex demonstrating a distributed encoding of inter-temporal choice parameters across a neuronal population ( ). Similar gradients of discount factors have also been found in the human striatum ( ) and mPFC ( ). This suggests that some neuronal assemblies may represent a preference for fast discounting, favoring smaller-sooner returns, while others favor slow discounting. The discounting preference of each agent would be represented by population codes, implementing sets of weights over these discounting assemblies. The prediction errors a subject perceives when the novel other’s choices differ from what they would have chosen for themselves could in principle change the weights within this pool, resulting in altered populations codes. 

The fact that a common brain region is recruited when computing preferences for self and other might suggest that people initially draw on self-representations to make inferences about another person and only construct a novel representation through learning. Such a mechanism has been observed when constructing a representation for a novel good from a simultaneous activation of familiar components ( ). However, this theory makes opposite neural predictions, as it predicts repetition suppression at the beginning of the experiment as subjects draw on the same representation to choose for self and other. In this scenario a separate representation for a novel other is built over time and would predict disappearance of repetition suppression. Instead, we observe an increase in repetition suppression across time, an effect reminiscent of an increase in similarity between representations observed when subjects repeatedly evoke independent memories ( ). Importantly, we can demonstrate this plasticity is not solely a neuronal phenomenon but also has profound behavioral consequences. 

Our approach uses repetition suppression to provide insight into a similarity in neural representations. Comparable measures of representational content can be obtained by multivariate pattern analysis ( ); however, it is thought the two techniques show a difference in sensitivity to precise features of the neuronal code ( ). Without an explicit measure of MVPA in this study, we are therefore cautious in predicting a comparable increase in similarity between representations for self and a novel other in mPFC when using MVPA. 

Note that subjects grow increasingly familiar with the novel other’s preferences as the task progresses, whereas familiarity remains constant for the familiar other in the sense that there is no new learning in relation to this other. Since psychological constructs such as familiarity, but also similarity and physical proximity, have previously been demonstrated to upregulate mPFC activity ( ), this raises the question whether an increase in familiarity might drive the plasticity effect. Importantly, our data are not consistent with such an account. First, activity for familiar and novel other does not differ in mPFC, not even at the beginning of the experiment, suggesting that the mPFC in our task does not respond to familiarity per se. Second, a mediation analysis suggests that it is a striatal surprise signal, the very opposite of familiarity, that drives the plasticity effect, which in turn drives the behavioral shift. 

Subjects’ own discount rate shifted toward the discount rate of their partner irrespective of whether their partner was human or a computer. This is in line with studies demonstrating that individuals use strategies akin to those used in real social contexts when interacting with a computer agent ( ). Crucially, a control condition with the same stimuli and actions, but without the need to employ a discounting computation, did not evoke a change in subjects’ own preferences. This indicates that the behavioral effect is tied to subjects’ deployment of the very same discounting mechanism to learn on behalf of another agent, be it a human or non-human agent. Thus, it is a learning-induced plasticity in acquiring a novel value representation that impacted on subjects’ own subjective value computation. This also suggests that most subjects do not actively choose to change their preferences but instead do so as the consequence of an mPFC plasticity they are not consciously aware of. Such an implicit mechanism presumably contributes to involuntarily aligning goals with others and might play an important role in spreading values throughout a population ( ). 

In conclusion, our data detail a neuronal mechanism by which personal traits are susceptible to social influence. Such plasticity might be one of the key features underlying learning, because it allows for an integration of past experience with novel information. More broadly, our findings pave the way for further studies of human social interactions at a more mechanistic level. 


## Experimental Procedures 
  
### Subjects 
  
27 volunteers (mean age ± SD: 23.6 ± 3.7, 14 females) participated in the behavioral experiment, and 29 volunteers (mean age ± SD: 25.6 ± 5.6 years, 14 females) participated in the subsequent fMRI experiment. Two subjects were excluded from fMRI analyses, because they had previously participated in the behavioral experiment and because of technical difficulties during the scan. All subjects were neurologically and psychiatrically healthy. The study took place at the Wellcome Trust Centre for Neuroimaging in London, UK. The experimental procedure was approved by the University College London Hospitals Ethics Committee and written informed consent was obtained from all subjects. 


### Task Behavioral Study 
  
For a detailed description of the task and our analyses, see the  . In brief, subjects made a series of choices between a smaller amount paid on the same day and a larger amount paid later ( A). The experiment was divided into three blocks ( B). In the first block, consisting of 100 trials, subjects made decisions for themselves. In block 2, they made decisions on behalf of their partner. They were also provided with trial-by-trial feedback on whether their choice for the partner was correct. Block 2 ended when subjects made 85% correct responses for their partner in a sliding window of 20 trials or after a maximum of 60 trials. In block 3, smaller blocks of ten trials of choosing for self alternated with blocks of ten trials of choosing for the partner. Block 3 ended after a total of 200 trials. Choices were optimized to give us a precise estimate of subjects’ discount rates. 


### Estimation of Discount Rates 
  
We estimated subjects’ discount rates by fitting a hyperbolic model to their choices ( ) separately for each experimental block. Subjects’ shift in discount rates was defined as the change in discount rate from block 1 to block 3 (log k  − log k ) relative to the distance between their estimate of the partner’s discount rate from their own discount rate (log k  − log k ): 

A positive shift represents a movement toward, and a negative shift a movement away from, the partner’s discount rate. Outliers (outside the range mean ± 3⋅SD), as well as subjects who estimated their partner’s discount rate to be less than 0.3 units away from their own discount rate, were excluded from population analyses because of inflated shift estimates (see  E). 


### Simulation of the Other’s Choices 
  
To generate feedback for the confederate’s choices, we simulated a partner with a discount rate that differed from the subject’s own baseline discount rate by 1 (i.e., log k  = log k  ± 1). Choices were correct if they corresponded to the decision that would be preferred by a hyperbolic discounter with this discount rate. Importantly, the simulated partner’s choices were noisy, as the other’s subjective value was translated to a choice probability with a softmax function (temperature parameter β = 1). 


### Task fMRI Study 
  
The fMRI experiment consisted of two trial types: choice trials, as described for the behavioral experiment above, and probe trials, in which subjects evaluated a single option on a scale from 1 to 4 ( D). Subjects learned the preferences of a second partner (“familiar other”) before the scan ( E, top). 

In contrast to the behavioral experiment and the pretraining, subjects learned about the novel other’s discount rate while we assessed their own discount rate. To make sure that we captured a potential shift in discount rate in this scenario, we excluded the first third of all choice trials subjects performed in the scanner when estimating k , k , and k . The relative shift effects reported in  F were then calculated as follows: 

For the estimation of absolute shifts, the denominator z was set to sign(z). Outliers (outside the range mean ± 3 SD) as well as subjects for whom the denominator was smaller than 0.3 (two subjects for shift , three subjects for shift , and two subjects for shift ) were excluded from the analyses. 


### Surprise Measure 
  
We estimated subjects’ own discount rates on a trial-by-trial basis (see  ) and used this measure to compute differences in subjective value for the choices subjects observed their partner make (V  − V ). This difference in subjective value was transformed to a probability using a softmax function applied to a trial-to-trial estimation of subject’s inverse temperature parameter β. This measure gave us an estimate of how likely the subject would have been to make the same choice himself. We subtracted this likelihood from 1 to translate this to a surprise measure. 


### Scan Procedure, fMRI Data Acquisition, and Preprocessing 
  
We used standard procedures for acquiring fMRI data where these were designed to minimize susceptibility related artifacts in the ventral prefrontal cortex ( ). We used SPM8 for image preprocessing and data analysis (Wellcome Trust Centre for Neuroimaging, London). We corrected for signal bias, co-registered functional scans to the first volume in the sequence, and corrected for distortions using the fieldmap. Data were spatially normalized to a standard EPI template and smoothed using an 8 mm full-width at half maximum Gaussian kernel. 


### fMRI Data Analysis 
  
Data were analyzed with an event-related general linear model (GLM). Probe trials were sorted into nine different conditions (self preceded by self [SS], novel preceded by self [SN], familiar preceded by self [SF], self preceded by novel [NS], novel preceded by novel [NN], familiar preceded by novel [NF), self preceded by familiar [FS), novel preceded by familiar [FN], and familiar preceded by familiar [FF]) with 20 trials per condition and block. Each regressor was accompanied by a parametric modulator reflecting subjective value from the respective agent’s perspective. This value was calculated based on a trial-by-trial estimate of the subject’s current belief about their partners’ discount rate k. Furthermore, we defined one choice regressor per agent and block indexing the time at which subjects indicated their decision on choice trials and received feedback. Each was accompanied by a parametric regressor corresponding to the surprise subjects experienced as they observed the partner’s choice. Button presses were included as a regressor of no interest. Because of the sensitivity of the BOLD signal in the OFC region to subject motion and physiological noise, we included six motion regressors obtained during realignment as well as ten regressors for cardiac phase, six for respiratory phase, and one for respiratory volume extracted with an in-house-developed Matlab toolbox as nuisance regressors ( ). Blocks were modeled separately within the GLM. 

To detect areas showing adaptation to repeated agents as depicted in  A, we used the contrast   (i.e.,  ). To test for areas displaying greater increases in suppression between self and the novel other compared to between self and familiar other ( B), we defined the following contrast:  . To test for greater increases in suppression between self and novel other than between novel other and familiar other, we defined a contrast as follows:  . 

The contrast images of all subjects from the first level were analyzed as a second-level random effects analysis. Results are reported at a cluster-defining threshold of p < 0.01 uncorrected combined with a FWE-corrected significance level of p < 0.05. 

We performed a jack-knife procedure from the mPFC ROI ( B) to extract parameter estimates from this region without biasing the selection. To this end, we extracted parameter estimates for each subject from an ROI defined according to all other subjects (threshold at p < 0.01 uncorrected). This signal was used to perform all analyses depicted in   and  A. 

We performed partial correlations to control for correlations between shift  and shift  in our analysis of the relationship of a behavioral shift effect and neural plasticity. This removes the shift of the familiar other toward the novel other from the subjects’ own discount rate shifts and the neural plasticity index [SN − SF]  ( A) and the shift of self toward the novel other from the familiar other’s shift toward the novel other and the neural plasticity index ( B). We also estimated a linear regression model on the same data with shift  and shift  as independent variables and [SN − SF]  as the dependent variable. The relationship between shift  and [SN − SF]  was directly contrasted with the relationship between shift  and [SN − SF] . 

To test for the influence of surprise on mPFC plasticity, we defined a contrast assessing BOLD correlate of the surprise subjects experienced as they got feedback about the novel and the familiar partners’ choices. This contrast revealed activity in ACC, in bilateral insula and dorsal striatum ( A; note that insula and striatal activity did not survive cluster-based FEW thresholding). To identify the surprise experienced when learning about the novel other, parameter estimates were then extracted from these ROIs for the novel other’s choices only. This surprise measure in the striatum was correlated with subjects’ shift in discount rate ( B) and the plasticity measure [SN − SF]  extracted from the mPFC ROI ( C). 

We used the Mediation and Moderation Toolbox ( ) to perform a mediation analysis on this surprise signal, our plasticity measure, and the discount rate shift. 

To test the specificity of adaptation effects, we analyzed repetition suppression effects in visual regions. We defined an ROI from a contrast identifying a main effect to any visual event, averaged across all blocks, and performed the same analyses as for the mPFC ROI (thresholded at p < 0.0001 uncorrected;  ). 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-4'>
<h2>4. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/28939856/' target='_blank'>28939856</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Altered brain activity and the effect of personality traits in excessive smartphone use during facial emotion processing</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Sci Rep</p>
<p><strong>Publication Year:</strong> 2017</p>
<p><strong>DOI:</strong> 10.1038/s41598-017-08824-y</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5610339/' target='_blank'>5610339</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study reports task-based fMRI during a facial emotion discrimination task—an explicit social-related processing task. Participants are healthy adults aged 19–35 screened with the MINI to exclude psychiatric diagnoses (both excessive smartphone use and control groups are non-clinical). The paper presents whole-brain group comparisons with FWE-corrected cluster results (whole-brain analyses reported), not solely ROI analyses (ROIs are supplementary). It is an original empirical fMRI study, not a review, and does not report results from psychiatric or neurological patient samples. Therefore it meets all inclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Excessive smartphone use is a phenomenon related to maladaptive smartphone use, leading to negative consequences. This study set out with the aim of assessing the effects of excessive smartphone use on behavioral and neural responses during facial emotional processing. We examined 25 excessive smartphone users and 27 normal control users using functional MRI during facial emotion processing and investigated Behavioral Inhibition System/Behavioral Activation System (BIS/BAS). The excessive smartphone use group (SP) showed neural deactivation in the dorsolateral prefrontal cortex (DLPFC) and dorsal anterior cingulate cortex (dACC) during the presentation of an angry face and emotional transition compared to that of the normal control group (NC). Additionally, the SP revealed neural deactivation of the superior temporal sulcus and temporo-parietal junction related to social interaction during emotional transition compared to the NC. We found that BAS-Reward Responsiveness level was correlated with behavioral responses during repeated happy faces related to emotional reward in SP compared to NC. It can thus be suggested that excessive smartphone use is likely to fail on cognitive control during emotional processing, and this impairment might be influenced on emotional processing related to social interaction. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (38877 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Over the past decade, smartphones have become a necessity for people’s daily lives with the development of technology. Despite many positive aspects, excessive mobile phone use often leads to potentially harmful or disturbing behaviors such as uncontrolled use leading to a negative impact on various aspects of daily life , and thus, problematic mobile phone use has raised sufficient concerns for being considered a potential public health issue . People who are addicted to smartphone use are unable to maintain concentration on a task or in interpersonal relationships due to the need to constantly check mobile phone notifications . Additionally, the tendency to be emotionally vulnerable  and have low levels of self-esteem  is known to be associated with increased smartphone addiction. In the study using neuroimaging, college students with mobile phone dependence showed altered gray matter volume and white matter integrity . In the previous study using exploratory factor analysis, smartphone addiction symptoms were identified that disregarding of harmful consequences, preoccupation, inability to control craving, productivity loss, and feeling anxious and lost . Particularly, lonely and depressed people preference interacting with other people by texting or social networking applications  and these pattern leads to negative outcomes related to their Internet use . Also, previous study using Internet questionnaire identified that lonely participants preferred making voice calls and anxious participants preferred texting . Therefore, it would be suggested that individual’s emotion influence on excessive smartphone use associated with social interaction. 

Although excessive smartphone use did not define clinical criteria for disorder, excessive smartphone use shares similar sub-dimension with addiction criteria of DSM 5 . In particular, the negative aspects of excessive smartphone use share the same effects as Internet addiction including Internet gaming addiction on interpersonal interaction . In previous studies, Internet addiction and pathological Internet use have been shown to lead to negative outcomes including uncontrolled Internet use, tolerance, withdrawal, social isolation and poor academic or professional achievement . However, the study of smartphone addiction as a potential psychiatric disorder is in its infancy, and the evidence supporting problematic smartphone use as an addictive behavior is still insufficient . 

Problematic smartphone use have related to individual’s social interaction. In previous studies, people using SNS more in terms of time spent usage were found to be less involved in the real life community , and individuals who did not feel comfortable with their peers in real life tend to use social networking service (SNS) more in order to compensate . In some studies, the negative consequences of using SNS use considered as criteria for substance dependence, and these might be considered as valid criteria for behavioral addiction . Addiction influence on the brain’s neuronal circuits necessary for not only reward and motivation, but also social behaviors, and thus allows addicted individuals to make poor choices despite awareness of the negative outcomes . Internet addiction criteria of DSM 5 have included social isolation, and previous studies related to Internet addiction, Internet gaming addiction, and smartphone addiction have considered important role of social interaction or interpersonal relationship on addiction . It is necessary to take account of individual’s personality traits in order to understand characteristic of social interaction in smartphone addiction. In particular, personality traits related to emotional processing are key to understanding social interaction. 

It is known that the behavioral inhibition (BIS) and behavioral activation (BAS) systems are closely related not only to temperament and personality traits but also to a wide range of affective experiences . The BAS are associated with positive emotional and extroversion, whereas BIS are closely related to negative emotional and emotional instability . Furthermore, BAS and BIS are explained on the basis of the independent and distinctive structures in the nervous system and behavioral patterns . According to Gray’s theory, the BIS/BAS systems are theoretical biopsychological systems related to personality traits involving sensitivity toward stimuli associated with negative and positive reinforcement and regulation of motivational behavior . In particular, it is reported that BIS is sensitive to punishment and non-reward cues in terminating behavioral output, and BAS is not only sensitive to reward cues and activating goal directed behavior , but also likely to promote the experience of positive feelings such as exaltation and happiness . Additionally, BAS are considered to be personality factors associated with Internet addiction  and smartphone dependency . In previous studies, BAS activity is associated with substances use such as alcohol . It has been reported that BIS and BAS were associated with the neural activity in the lateral prefrontal cortex  and dorsal anterior cingulate cortex (dACC)  related to cognitive control. Therefore, it can be supposed that individual personality traits in excessive smartphone use have an influence on behavioral and neural response for social reward cue. 

In this study, we have designed a task to explore altered brain activity in excessive smartphone use during cognitive control of an emotional face. In previous studies, a facial emotion discrimination task has been generally used to study social interaction . The perception of changes due to facial movements plays a more central role in social communication . In previous studies, an increased level of general anxiety, including social anxiety, is related to excessive smartphone use , and socially anxious individuals revealed attentional biases toward threatening stimuli, especially angry faces . In previous neuroimaging studies, the dorsolateral prefrontal cortex (DLPFC) and dACC have been shown to be engaged in cognitive control and emotional regulation . Previous studies using animal models of affective learning and imaging studies of either cognitive control or emotional responding in both healthy and psychiatric populations have implicated regions of the prefrontal cortex (PFC) and anterior cingulate cortex (ACC) . The DLPFC may be more involved in maintaining a representation of the context, such as goals, rules and sequence of events, necessary to perform a task accurately . Additionally, the ACC has been shown to be activated by the manipulation of interference and cognitive loading in a previous study related to working memory . Activation of this region is thought to be related to detecting cognitive conflict and signaling the need for greater allocation of attention for the purpose of resolving conflict . 

In this study, we will focus on identifying altered brain activity involved in social interaction in those with excessive smartphone use. Although the relationship between excessive smartphone use and social interaction has been reported , no evidence has been found proving altered neural activity of social emotion in excessive smartphone use. Therefore, we investigated the differences in the behavioral and neural responses between the excessive smartphone use group (SP) and the normal control group (NC) in the cognitive control of facial expressions in order to find neurobiological evidence of excessive smartphone use affecting social interaction. Additionally, this study tends to investigate the influence of personality trait related reward system on the emotional processing due to social context in excessive smartphone use. We examined the correlations between BAS reward response and the behavioral and neural responses related to facial emotion processing in the SP compared with NC. 

This study investigated the effect of excessive smartphone use on neural activity during facial emotion discrimination through the following hypothesis. First, we hypothesized that the SP would show a cognitive deficit during the emotional transition of faces requiring fast emotional regulation. Second, we expected that there is altered neural activity in the SP compared to that in the NC in the prefrontal and cingulate cortex related to emotional regulation and cognitive control. Lastly, we hypothesized that BAS-Reward Responsiveness (BAS-RR) is correlated with the responses of happy faces related to the emotional reward in the SP. 


## Results 
  
### Demographics and clinical data 
  
Table   summarizes the demographic and clinical characteristics of the two groups. The two groups did not differ in age, K-WAIS, and the main usage of smartphones, whereas the time of smartphone use per week,   t  (50) = 4.67,   p   < 0.001, the time of major smartphone use per week,   t  (50) = 3.47,   p   < 0.005, and Smartphone Addiction Proneness Scale (SAPS) scores,   t  (50) = 4.55,   p   < 0.001 were significantly different. The SP showed higher score on the BIS,   t  (50) = 3.6,   p   < 0.001 and BAS,   t  (50) = 5.38,   p   < 0.001, and particularly the SP revealed higher score on the BAS-RR,   t  (50) = 2.32,   p   < 0.005 and BAS-Fun Seeking (BAS-FS),   t  (50) = 5.08,   p   < 0.001 compared to NC. Additionally, there was a significant difference in the education duration,   t  (51) = 2.16,   p   < 0.05, but the difference was around a year. According to gender distribution, there was no significant difference across groups.   
Demographic characteristics of the PSU and NC. 
  
Abbreviations: SP, Excessive smartphone use group; NC, Normal control group; SAPS, Smartphone Addiction Proneness Scale; BIS, Behavioral inhibition system; BAS, Behavioral activation system. 

*  p   < 0.05, **  p   < 0.005, ***  p   < 0.001. 
  


### Behavioral performance 
  
As shown in Table   and Fig.  , we conducted a repeated-measures ANOVA on the error rate with emotional valence of face (happy and angry), emotional status (repetition vs. transition), and group (SP and NC). For error rate, there was a 3-way interaction between the emotional valence, emotional status, and groups,   F  (1,50) = 11.52,   η   = 0.91,   p   < 0.001. The ANOVA revealed significant interaction between the emotional valence and emotional status of the face,   F  (1,50) = 14.19,   η   = 0.96,   p   < 0.001.   
Behavioral responses. 
  
Abbreviations: SP, Excessive smartphone use group; NC, Normal control group; HH, Happy face followed by happy face; AH, Angry face followed by happy face; AA, Angry face followed by angry face; HA, Happy face followed by angry face. 
    
Behavioral responses of each group. In the SP, the error rate for AH was higher than that for the HH, and the error rate for the AA was higher than that for the HA (  a  ); however, there were no significant differences between conditions in the NC (  b  ). The SP showed a higher error rate than the NC in the AH. The SP exhibited slower responses in the AH than in the HH, and they also showed slower responses in the AA than the HA (  c  ). The NC showed delayed responses in the AH trials compared to that in the HH trials, however, there were no significant differences between the AA and the HA in the NC (  d  ). 
  

In the SP, the error rate for the AH was higher than that for the HH,   t  (24) = 4.67,   p   < 0.001, and the error rate for the AA was higher than that for the HA,   t  (24) = 2.50,   p   < 0.05; however, there were no significant differences between conditions in the NC. In the group comparison, the SP showed a higher error rate than the NC in AH,   t  (50) = 2.04,   p   < 0.005. 

For the reaction time, there were main effects for the emotional valence of the face,   F  (1,50) = 20.05,   η   = 0.99,   p   < 0.001, and emotional status,   F  (1,50) = 33.32,   η   = 1.00,   p   < 0.001. There were a 3-way interaction among the two conditions and the groups,   F  (1,50) = 13.03,   η   = 0.94,   p   < 0.005. There was a significant interaction in the reaction time between the emotional valence of the face and the groups,   F  (1,50) = 5.14,   η   = 0.60,   p   < 0.05. There was a significant interaction between the emotional valence and emotional transition of the face,   F  (1,50) = 81.46,   η   = 1.00,   p   < 0.001. 

The SP exhibited slower responses in the AH than in the HH,   t  (24) = 8.45,   p   < 0.001, and they also showed slower responses in the AA than the HA,   t  (24) = 2.77,   p   < 0.05. The NC showed delayed responses in the AH trials compared to that in the HH trials,   t  (26) = 5.96,   p   < 0.001, however, there were no significant differences between the AA and HA in the NC. 

Regarding to correlation between the behavior response and effect of personality trait, BAS-RR score revealed a significant negative correlation with the error rate during the HH,   r   = −0.42,   p   < 0.05, in SP, however there was no significant correlation in NC (Fig.  ). The results were converted to equally probable z-scores, comparing Fisher’s z-transformed correlation values across groups (z = 1.65,   p   = 0.049).   
Correlations among neural activity of the ROIs, the error rate, and the BAS-RR scores. In the SP, the activation of the right DLPFC did not showed correlation with behavioral error (  a  ), and the dACC exhibited negative correlation with the error rate under HH,   r   = −0.53,   p   < 0.05 in SP (  b  ). In the SP compared to NC, the error rate revealed a significant negative correlation with BAS-RR score during the HH,   r   = −0.42,   p   < 0.05 (  c  ). 
  


### Functional MRI results 
  
#### Group differences in emotional valence 
  
The results from the emotional valence of the face condition analysis are presented in Table  . In the happy face condition, the SP showed less activity in the left precentral gyrus (PG), left lingual gyrus (LG), right inferior temporal gyrus, left middle frontal gyrus (MFG), and left middle temporal gyrus than the NC. In the angry face condition, the SP exhibited less activity in the bilateral precentral gyri, left LG, bilateral middle temporal gyri, right superior parietal gyrus (SPG), left middle occipital gyrus, right dACC, left DLPFC, right supplementary motor area (SMA), right cuneus, right thalamus, left cerebellum, left superior occipital gyrus (SOG), and left MFG than the NC. However, the SP did not exhibit significantly more activity than the NC in either the happy or angry face condition.   
Group differences of brain regions showing significant activation in each emotional valence. 
  
Clusters with peak-level and FWE-corrected p < 0.001 and more than 100 voxels are reported. 

Abbreviations: L., Left; R., Right; B., Bilateral; ACC, Anterior cingulate cortex; DLPFC, Dorsolateral prefrontal cortex; SMA, Supplementary motor area; FWE, family wise error. 
  


#### Group differences in emotional status 
  
The results from the analysis of the emotional status are presented in Table  . The SP showed less activity in the right inferior temporal gyrus, left LG, and left PG than the NC with emotional repetition. The SP exhibited less activity in the bilateral precentral gyri, left LG, left STS, left SPG, left DLPFC, right interior temporal gyrus, left SMA, left inferior frontal gyrus, left supramarginal gyrus, left dorsal ACC, right TPJ, left inferior parietal gyrus, left SOG, right cuneus, and right superior frontal gyrus (SFG) with emotional transition. However, the SP did not exhibit significantly more activity than the NC with either emotional repetition or transition.   
Group differences of brain regions showing significant activation in emotional status. 
  
Clusters with peak-level and FWE-corrected p < 0.001 and more than 100 voxels are reported. 

Abbreviations: L., Left; R., Right; B., Bilateral; STS, Superior temporal sulcus; ACC, Anterior cingulate cortex; DLPFC, Dorsolateral prefrontal cortex; SMA, Supplementary motor area; TPJ, Tempro-parietal junction; FWE, family wise error. 
  


#### Regional differences between conditions within groups 
  
The results from the analysis of the reginal differences between conditions for each group are presented in Table  . The SP showed stronger activation in the right SFG, right LG, left middle occipital gyrus, right dorsal ACC, right MFG, right thalamus, right postcentral gyrus, right superior temporal gyrus, and left inferior parietal gyrus during AH than during HH. Additionally, they revealed more activation of the right SFG, right DLPFC, left SPG, right inferior parietal gyrus, and right angular gyrus during AA than during HA. There were no significant differences in activity dependent on the condition in the SP. In contrast, the NC showed stronger activation in the left SPG, left SMA, left LG, and right SOG during AH than during HH. There were no significant differences dependent on other conditions in the NC.   
Brain regions of each group showing significant activation in conditions. 
  
Clusters with peak-level and FWE-corrected p < 0.05 and more than 100 voxels are reported. 

Abbreviations: L., Left; R., Right; B., Bilateral; ACC, Anterior cingulate cortex; DLPFC, Dorsolateral prefrontal cortex; SMA, Supplementary motor area; FWE, family wise error; *Region of Interest. 
  


#### ROIs analysis 
  
In the region of interest (ROI) analysis for exploring the activation differences of the DLPFC (Fig.  ), the main effect of the emotional status of the face was significant,   F  (1,50) = 4.75,   η   = 0.57,   p   < 0.05, and the activation of DLPFC during emotional repetition was higher than that during emotional transition. The interaction between the emotional status and group was significant,   F  (1,50) = 8.90,   η   = 0.83,   p   < 0.005. Also, the interaction between the emotional valence of the face and the emotional status was significant,   F  (1,50) = 48.35,   η   = 1.00,   p   < 0.001.   
Neural activity in the DLPFC and dACC of each group. The right DLPFC extracted from the contrast between HH and AH in SP (  a  ), and the right DLPFC in the SP showed stronger activity with emotional repetition than emotional transition, while the difference was not significant in the NC. Additionally, the NC showed greater activity in AH than in HH, while the difference was not significant in the SP (  b  ). The right dACC extracted from the contrast between AA and HA in SP (  c  ). In the right dACC, the SP showed greater activity in the happy than the angry faces, but the NC did not show a significant difference. Additionally, the SP revealed deactivation of the dACC in the HH, AA, and HA trials compared to observed in the NC (  d  ). 
  

In the multiple comparison, the right DLPFC in the SP showed stronger activity with emotional repetition than emotional transition,   t  (24) = 3.22,   p   < 0.05, while the difference was not significant in the NC. In the AH, the NC showed greater activity in the right DLPFC than in HH,   t  (26) = 3.90,   p   < 0.005, but the SP did not show a significant difference in activity between the AH and HH. 

In terms of the activity in the right dACC (Fig.  ), the main effects of emotional valence of the face,   F  (1,50) = 8.37,   η   = 0.81,   p   < 0.005, and emotional status,   F  (1,50) = 16.58,   η   = 0.98,   p   < 0.001, were significant. The activation of dACC during happy face trials was higher than that during angry face trials, and the activation of dACC during emotional transition was higher than that during emotional repetition. The 3-way interaction among the emotional valence, emotional status, and the groups was significant,   F  (1,50) = 6.43,   η   = 0.70,   p   < 0.05. The interaction between the emotional valence of the face and the group was significant,   F  (1,50) = 6.15,   η   = 0.11,   p   < 0.05. Additionally, the interaction between the emotional valence and emotional status of the face was significant,   F  (1,50) = 23.51,   η   = 1.00,   p   < 0.001. In the right dACC, the SP showed greater activity in the happy than the angry faces,   t  (24) = 3.23,   p   < 0.001, but the NC did not show a significant difference. 

In the SP, multiple comparisons revealed that the activation of the right dACC exhibited negative correlation with the error rate under HH,   r   = −0.53,   p   < 0.05 (Fig.  ), however, right DLPFC did not show a significant correlation between the BAS score and regional activations. 




## Discussion 
  
The aim of this study was to identify the behavioral differences between the SP and NC, and the altered brain activation of the prefrontal and cingulate cortex associated with cognitive control in SP compared to that of NC during facial emotion processing. Additionally, we identified the correlations between the BAS-RR activity, behavioral, and neural response during facial emotion processing related to emotional reward. We hypothesized that, based on the vulnerability of the excessive smartphone user in social interaction, SP would reveal deficit of cognitive control in behavioral and neural responses during facial emotional processing. In addition, we predicted that reward sensitivity in the SP would influence on cognitive processing of social reward cue. 

In this study, the SP showed higher error rate induced by failure of cognitive control during presentations of angry face in the previous trial, whereas the NC did not show such a difference. These results indicated that the SP suffered difficulty on cognitive control caused by emotional evaluation when they are exposed to negative emotional expression. In particular, the SP showed a higher error rate under the emotional transition preceded by a negative emotional face, compared to the NC. These behavioral findings would indicate that the previous exposure to a negative emotion influenced the cognitive control on the current emotional transition trial in the SP. 

In the neural response, the SP showed decreased activation in the dACC and DLPFC related to cognitive control of facial emotion compared to NC under angry face and emotional transition. These results associated with previous studies which reported dysfunction of frontolimbic region related to cognitive control in Internet gaming disorder . The previous studies have reported that cognitive reappraisal of negative emotion activates the dACC and PFC systems that support the selection and application of reappraisal strategies and modulate activity in appraisal systems suitable for the goal of reappraisal . In the results of meta-analysis, it has been reported that emotional interference during cognitive conflict induced neural activities in the DLPFC and dACC . Therefore, decreased activity of both the dACC and DLPFC in the SP suggests that the cognitive control of negative emotion and emotional transition has been altered compared to that in the NC. Consistent with neural activities, the SP reported higher error in emotional transition after angry face comparted to NC. Therefore, excessive smartphone user has a harmful effect on cognitive control during emotional face processing, and this impairment might be influenced on emotional processing related to social interaction. Additionally, the SP revealed neural deactivation of the STS and TPJ compared to the NC. According to a previous study related to facial information, the activation of the STS is associated with processing and reacting to the emotional state of another person . Additionally, it has been known that the right TPJ is selectively recruited for the attribution of mental states when receiving socially relevant stimuli  and is more responsive to mentalizing than physical judgments . Therefore, this evidence suggests that activation of the STS and TPJ during emotional transition reflects the social cognitive effort to make a rapid emotional judgment, and the SP showed a lower neural response towards emotional information involved in social context than the NC. 

In the ROIs comparison, we found that NC showed higher activation of DLPFC during presentations of angry face in previous trial than during presentations of happy face in the previous trial, while the SP did not show significant difference of neural activation between the previous emotional valences under current happy face. Cognitive reappraisal has been known to enhance the signal in the DLPFC regions in cognitive regulation of negative emotion . In a previous study on emotional distracters, normal control participants were able to recruit the DLPFC; however, depressed individuals showed an exaggerated amygdala response to such distracters and a failure to recruit the DLPFC . In this study, the activation of DLPFC during emotional repetition was higher than that during emotional transition. The effect of repeated emotion revealed only in the angry face, not in the happy face. In particular, SP showed strong activation in DLPFC during repeated angry face compared to non-repeated angry face. In the previous study related to emotional processing, the repeated negative stimuli induced significant activation in the DLPFC, and functional connectivity between the DLPFC and other regions . The activation of DLPFC can be regarded as a cognitive effort in other to process repeated angry faces. In previous studies, the right lateral prefrontal regions have been shown to be activated under interference conditions , and the activation of right DLPFC region negatively correlated with sensitivity of interference . Despite the higher DLPFC activation, the SP showed more behavioral errors during the repeated angry face than non-repeated angry face. Therefore, it would imply that the neural activity related emotional regulation fails to control the behavioral performance in excessive smartphone user. 

The SP also showed less activation of the dACC, which is related to conflict monitoring, during presentations of angry faces than the NC and compared to happy faces within the SP. The dACC has been known to be associated with detecting cognitive conflict  and signaling the need for greater allocation of attention for the purpose of resolving conflict . In the previous study related to altered brain structure of mobile phone dependence (MPD), MPD individuals had decreased gray matter volume relative to controls, and they showed decreased white matter integrity of bilateral hippocampal cingulum bundle fibers . Therefore, it can be inferred that the SP have a deficit in cognitive monitoring during the presence of negative emotional faces compared to NC and, as this result, the SP revealed higher error rate under angry face followed by happy face compared to NC. Additionally, the SP showed a higher error with less neural activity in the dACC related to cognitive monitoring during repeated happy face, while there was no significant correlation between error rate and activity in the DLPFC related to cognitive conflict resolution. In other words, it imply that the SP showed individual differences according to cognitive monitoring during repeated happy face related to emotional reward. 

In this study, correlations between the BAS-RR level, behavioral and neural response of facial emotion were shown to depend on the group. In the correlation results, high BAS-RR individuals in the SP exhibited low error rate during repeated happy face. In particular, the correlation between the BAS-RR and error rate in repeated happy face showed a significant difference between the SP and NC. These results indicate that sensitivity of reward more influence behavioral performance during repeated positive facial expression in the SP compared to NC. Therefore, it can be supposed that high BAS-RR individuals in the SP are sensitive to emotional reward such as happy face, and they might use social network service in order to gain positive responses. This is related to a previous finding that people who have a negative social identity tend to use SNSs more in order to compensate for this . 

Finally, a number of important limitations need to be considered. First, the participants did not evaluate the emotional valence and arousal of each face in this study. Second, the main usages of smartphone were heterogeneous among the participants. A future study with more focus on problematic social network service use through smartphones is therefore suggested. Third, the gender differences in excessive smartphone use group were not considered. In subsequent study, it is necessary to identify differences in facial emotional discrimination according to gender differences in the SP using the same gender distribution. Additionally, we suggest that the functional connectivity of fronto-cingulate regions in SP are investigated in social cognitive contexts in future studies. 

In summary, we showed that the SP exhibited different behavioral responses and functional alterations compared to the NC during emotional processing of faces. The SP revealed a cognitive deficit during the emotional transition preceded by a negative emotional face, compared to NC. In the neural activity, the SP showed a neural deactivation of prefrontal and cingulate cortex related to conflict detection and cognitive control compared to that of the NC during exposure to angry faces and emotional transition. The behavioral performance in the SP correlated with the activity of dACC related to cognitive monitoring during repeated happy face associated with emotional reward. Lastly, we found BAS-RR level was correlated with behavioral responses during repeated happy faces related to emotional reward in SP compared to NC. These findings may help us to understand altered neural responses associated with cognitive control during facial emotional processing, and could provide important implications for the effect of personality traits related to emotional reward in excessive smartphone use. 


## Methods 
  
### Participants 
  
This study was conducted for adult men and women aged 19–35 through online recruiting. A total of 728 adults participated in the online survey on smartphone usage. Twenty-six adults with SP (14 male and 12 female) and 30 NC (18 male and 12 female) were recruited for the fMRI study, and all participants underwent the Mini-International Neuropsychiatric Interview by a clinician to screen out participants with a current psychiatric diagnosis. One participant was excluded because of depressive disorder, and the data from three participants were excluded because of severe head motion during the analysis; thus, the data from twenty-five adults with problematic smartphone use (13 male and 12 female, 27.76 ± 5.97 years) and twenty-seven NC (18 male and 9 female, 28.93 ± 6.39 years) were considered in this study (Table  ). Exclusion criteria included past or current major medical disorders (e.g., diabetes mellitus), neurological disorders (e.g., seizure disorders, head injury) or psychiatric disorders (e.g., major depressive disorder, anxiety disorders). All participants had normal or corrected-to-normal vision and were right-handed assessed by the Edinburgh handedness inventory . The purpose and procedure of this study were explained to the participants. Each participant provided written informed consent, and this study was approved by the Institutional Review Board of Seoul St. Mary’s Hospital. All experiments were performed in accordance with relevant guidelines and regulations. 


### Questionnaires 
  
#### SAPS 
  
Excessive smartphone use was estimated using SAPS developed by the Korean National Information Society Agency in 2011 and the reliability test of the scale yielded a Cronbach’s alpha of 0.814 . The SAPS is a self-report scale and includes fifteen items, and the responses are scored on a four-point Likert scale (1: Not at all to 4: Always). The SAPS has four subscales: disturbance of adaptive functions, virtual life orientation, withdrawal, and tolerance, and participants were classified as SP if their total score exceeded 44, or if their subscales scores exceeded 15, 13, and 13 for disturbance of adaptive function, withdrawal, and tolerance, respectively. 


#### BIS/BAS 
  
BIS and BAS are general motivation systems that underlie behavior and affect . The BIS responds to cues associated with punishment; the BAS responds to those associated with reward. The BIS and BAS questionnaire scales assess BIS (7 items) and three subdomains of BAS-D (4 items), BAS-FS(4 items), and BAS-RR (5 items) . Responses used a 4-point scale (1: strongly disagree, 4: strongly agree). Items on the BIS scale assess sensitivity to the mechanism controlling aversive motivation. Items in the BAS-RR subscale assess positive responses to anticipated rewards. Items in the BAS-D subscale assess persistent pursuit of desired appetitive goals. Items in the BAS-FS subscale assess desire for new rewards and willingness to spontaneously approach potentially rewarding events . 



### Facial emotion discrimination task 
  
Participants performed a facial emotion discrimination task using Korean emotional faces, which were selected from the Korean Facial Expressions of Emotion . To maintain the participants’ attention, the stimulus material for each trial consisted of a positive or negative emotional face on the left or right side and a fixation cross at the center of the gray background. Half of the participants were asked to press a button with their left or right index finger in response to a positive or negative feeling produced by the picture, respectively, regardless of the picture’s location. The other half of the participants were assigned to respond in the opposite manner as a counterbalance. The trials consisted of four different stimuli according to emotional valence (happy vs. angry) and emotional status (repetition vs. transition) of face. The task sequence was separated into two sessions and was composed of a rapid event-related design in which the duration of each trial was 1,500 ms and the inter-trial intervals were varied from 500 to 4,500 ms. Each session started with a 12-s dummy scan with six practice trials and included 160 events consisting of 40 repeated happy face trials, 40 non-repeated happy face trials, 40 repeated angry face trials, and 40 non-repeated angry face trials, and thus took a total duration of 7 min 32 s. 


### Image acquisition 
  
Functional and structural MRI data were acquired using a 3T MRI system (Siemens, MAGNETOM Verio, Erlangen, Germany) equipped with a 16-channel head coil. Participants’ heads were cushioned with attached earmuffs. The functional images were obtained using a T2*-weighted gradient echo-planar imaging sequence (31 slices of 3.5-mm thickness and no gaps, repetition time [TR] = 2,000 ms, echo time [TE] = 30 ms, flip angle = 90°, image matrix = 124 × 124, field of view = 220 mm) with an in-plane resolution of 1.719 mm × 1.719 mm. Structural images with a resolution of 0.859 mm × 0.859 mm × 1.2 mm were acquired using a 3D T1-weighted gradient echo sequence (170 slices, TR = 9.692 ms, TE = 4.59 ms, image matrix = 224 × 224). 


### Data analysis 
  
#### Behavioral data 
  
The behavioral data were analyzed according to the emotional valence of the face, the stimuli exposure, and the group. The three variables of interest were the emotional valence of the face (happy vs. angry), emotional status (repetition vs. transition), and group (SP vs. NC). The task performances, measured by accuracy and reaction time, were analyzed by a repeated measures analysis of variance (ANOVA) to assess the main effects of the three factors and their interactions using IBM SPSS Statistics for Windows, Version 20.0 (IBM SPSS Inc., Armonk, NY). Subsequent paired t-tests for post hoc analyses were performed to test the significance between the different conditions and groups. 


#### Image data 
  
Image preprocessing and statistical analysis were performed with Statistical Parametric Mapping software (SPM8; Wellcome Department of Cognitive Neurology, London, UK). After discarding the first six images from the dummy scan at each session, the remaining 220 images were used for further preprocessing. Differences in the slice acquisition time of the interleaved sequence were corrected, and realignment was performed to correct the artifact created by head motion. The corrected images were coregistered on the T1-weighted image of the same participant. The T1-weighted images were normalized to the standard T1 template, and the resulting transformation matrices were applied to the coregistered functional images. Functional data were smoothed with a Gaussian kernel of 8-mm full-width at half-maximum. 

Preprocessed data were analyzed using a general linear model. Experimental trials were modeled separately using a canonical hemodynamic response function for individual data. Multiple linear regression, as implemented in SPM8 using a least-squares approach, was used to obtain the parameter estimates . These estimates were then analyzed by testing specific contrasts using the participant as a random factor. According to the emotional valence and emotional status of the face, all trials were classified as HH, AH, AA, and HA trials. Images of the parameter estimates for each condition were created in the primary analysis, during which individual realignment parameters were entered as regressors to control for movement-related variance. 

For the secondary analysis, the parameters for the four conditions, which were estimated in the primary analysis, and group condition were entered into the flexible factorial model, in which contrast maps were compared for group differences. The results were measured with group differences in relation to the emotional valence (happy and angry) and emotional status (repetition vs. transition) of the face. Significant results were determined by family-wise error (FEW) corrected p values of less than 0.001 and more than 100 voxels preferentially. 

Post hoc tests for interactions and correlation analysis were performed on the a priori regions of interest (ROIs), which were defined as significant clusters within fronto-cingulate regions including the dACC [6, 10, 38] and DLPFC [48, 16, 32] related to cognitive control for emotional faces in group. The % BOLD signal changes in the ROIs were extracted in each condition using MarsBaR version 0.41 (  http://marsbar.sourceforge.net  ), and the differences for the ROIs were analyzed using repeated measures ANOVA. The correlations between ROIs and behavioral error rate were calculated using Pearson correlation analyses in each condition and groups, and the p-values were adjusted by Benjamin–Hochberg FDR for multiple comparisons. Also, the statistical difference in regional correlation results between groups was computed after application of Fisher’s r-to-z transform. 



 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-5'>
<h2>5. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22403154/' target='_blank'>22403154</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Neuroimaging self-esteem: a fMRI study of individual differences in women</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Soc Cogn Affect Neurosci</p>
<p><strong>Publication Year:</strong> 2012</p>
<p><strong>DOI:</strong> 10.1093/scan/nss032</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3682439/' target='_blank'>3682439</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study reports fMRI data collected while participants performed a social-related task (Visual–Verbal Self-Other Referential Processing Task), involving self- vs other-referential processing—clearly social cognition. Participants were healthy adults aged 18–52 (within 18–60). Imaging used whole-brain acquisition and whole-brain analyses (SPM8 GLM), with cluster-wise whole-brain contrasts and tables of whole-brain results reported; although some ROI small-volume corrections are used, the primary results are whole-brain rather than ROI-only. This is an original empirical fMRI study (not a review/meta-analysis) and excludes psychiatric/neurological disorders. Therefore all inclusion criteria are met and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Although neuroimaging studies strongly implicate the medial prefrontal cortex (ventral and dorsal), cingulate gyrus (anterior and posterior), precuneus and temporoparietal cortex in mediating self-referential processing (SRP), little is known about the neural bases mediating individual differences in valenced SRP, that is, processes intrinsic to self-esteem. This study investigated the neural correlates of experimentally engendered valenced SRP via the Visual–Verbal Self-Other Referential Processing Task in 20 women with fMRI. Participants viewed pictures of themselves or unknown other women during separate trials while covertly rehearsing ‘I am’ or ‘She is’, followed by reading valenced trait adjectives, thus variably associating the self/other with positivity/negativity. Response within dorsal and ventral medial prefrontal cortex, cingulate cortex and left temporoparietal cortex varied with individual differences in both pre-task rated self-descriptiveness of the words, as well as task-induced affective responses. Results are discussed as they relate to a social cognitive and affective neuroscience view of self-esteem. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (36040 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## INTRODUCTION 
  
Trait self-esteem, or the tendency to evaluate oneself positively rather than negatively, is a robust predictor of mental health and well-being ( ). Neuroimaging studies strongly implicate the medial prefrontal cortex (ventral and dorsal), cingulate gyrus (anterior and posterior), precuneus and temporoparietal cortex (reviews by  ;  ;  ) in mediating our ability to consciously reflect about ourselves, that is, self-referential processing (SRP;  ). However, little is known about the neural bases mediating individual differences in valenced SRP, that is, why most people tend to think about themselves positively, whereas others regard themselves negatively, cognitive and affective processes that are intrinsic to self-esteem. 

Previous studies investigating valenced SRP measured neural response while healthy participants explicitly judged the self-descriptiveness of trait adjectives (e.g. ‘liked’   vs   ‘disliked’, ‘success’   vs   ‘failure’) ( ;  ;  ) or self-relevance of valenced pictures ( ;  ), tasks not unlike completing a self-esteem questionnaire within the scanner. However, healthy individuals typically endorse positive stimuli (e.g. the words ‘liked’, ‘success’) as more self-descriptive than negative stimuli (e.g. ‘disliked’, ‘failure’) ( ), confounding valence with self-descriptiveness, and rendering these designs less sensitive to detecting neural processes mediating negatively valenced SRP. Limitations inherent to the use of direct survey-based measures of SRP also include susceptibility to self-presentational biases and the likelihood that not all valenced self-representations are fully accessible to conscious reflection (e.g.  ). To circumvent these concerns, priming methodologies are increasingly used in experimental social psychology as indirect measures of associations between valence and self-representation (reviews by  ;  ). However, no previous studies have utilized these methods in order to assess the neural processes mediating valenced SRP (for a study examining implicit SRP of stimuli that were not overtly valenced, however, see  ). 

The present study addressed the above limits of past literature by directly comparing the neural correlates of valenced SRP with valenced ‘other-referential processing’ (ORP) using a priming methodology. Specifically, to obviate the effect of the self-positivity bias, we previously designed a ‘Visual–Verbal Self-Other Referential Processing Task’ (VV-SORP-T; see  ) that directly engenders valenced SRP and ORP ( ). The VV-SORP-T requires participants to covertly rehearse the words ‘  I am  ’ or ‘  He/She is  ’ when presented with either their own or another person’s picture and then read positive or negative words, thereby experimentally engendering an association between the self/other and positivity/negativity on different trials (e.g. ‘I am’ … ‘disliked’). The encoded representation (e.g. ‘I am’ … ‘disliked’) may or may not match individuals’ internal self-representations (e.g. ‘I am’ … ‘liked’) as determined by individual differences in trait self-esteem. Participants monitor and report their affective response to the task, the outcome of which we further interpret as partly reflecting the match between the task-induced encoded representation and internal representations. Specifically, matching negative self-representations (e.g. ‘I am’ … ‘disliked’) are more likely to engender negative affect and matching positive self-representations (e.g. ‘I am’ … ‘liked’) are more likely to engender positive affect. The impact of the task on cognitive processing is also measured indirectly via response time (RT) providing a conjoint passive button-pressing requirement. We previously demonstrated in young adults that the VV-SORP-T is sensitive to individual differences in valenced SRP such that individuals with lower explicit self-esteem (as indexed by the Rosenberg Self-Esteem Scale;  ) are more likely to experience negative affect during negative SRP, less likely to experience positive affect during positive SRP, and evidence slower RT particularly during negative SRP ( ).
   
Illustration of one block of the VV-SORP-T. The individual shown in the photograph is the second author. Participants posed for their own photographs in neutral expression as for a passport application. Photographs of strangers (‘other’-condition) were taken from the NimStim set ( ) and matched to the participant as closely as possible for the following attributes: ethnicity, hair colour and hair length. Participants viewed the photographs and silently rehearsed ‘I am’ (for the self) or ‘She is’ (for the other), and then silently read the words, thus associating the self/other with positivity/negativity on different trials. 
  

In the present fMRI study we investigated the neural correlates of cognitive and affective processes relating to individual differences in self-esteem by examining variability in the BOLD response to the VV-SORP-T in 20 women. Consistent with previous research, we expected relatively few differences between valenced SRP and valenced ORP at the group level ( ). However, we hypothesized that individual differences in valenced adjective endorsement, and affective responses to the VV-SORP-T, would predict between-person variation in the BOLD response within regions of interest including within the medial prefrontal cortex, cingulate gyrus, temporoparietal cortex and amygdala. 


## METHODS 
  
### Participants 
  
Twenty women varying from young to middle adulthood (18–52 years, M age = 27.80, s.d. = 8.33) recruited by advertisement from the general community took part in this study. Participants’ ethnic status was distributed as follows: European–Caucasian (  n   = 12, 60%), East Indian (  n   = 3, 15%), Asian (  n   = 2, 10%), African (  n   = 2, 10%) and Middle Eastern (  n   = 1, 5%). As a group, participants reported normative levels of trait self-esteem [Rosenberg Self-Esteem Scale ( ): M = 22.61, s.d. = 6.01, Range 13–30] and self-critical thinking [Cognitive Distortion Scale–Self-Criticism subscale ( ); M = 14.22, s.d. = 6.25, Range 8  –  33]. Current or past psychiatric history, head injury with loss of consciousness and left-handedness were study exclusion criteria as assessed by structured clinical interviews. 

#### VV-SORP-T 
  
The VV-SORP-T involved three components: (i) completion of a paper-and-pencil survey asking about the descriptiveness of negative and positive traits for the self   vs   others (completed outside scanning), (ii) completion of an experimental task while undergoing fMRI and (iii) a post-task rating questionnaire asking about affective responses (completed outside scanning). The instructions given for the VV-SORP-T are reported verbatim in supplementary data to our prior report ( ). 

Approximately 2 weeks prior to scanning, within a battery of related questionnaires, participants rated for each of 10 positive and 10 negative words ‘how much each word describes (i) how you think about yourself, and describes (ii) how you think about other people, in general’ on 11-point (0–10) scales anchored by ‘Not at all’ (0), ‘Moderately’ (5) and ‘Completely’ (10). The adjective list was the same as that used in  , originally based on that used in  , and covered social (e.g. loved, rejected) and achievement-related (e.g. successful, incompetent) themes. We conceptualize such scores as indicative of trait self-esteem and consistent with that assumption adjective endorsement scores correlated   r   = 0.73 with Rosenberg Self-Esteem Scale scores in our prior study ( ). We did not purposely match the negative and positive word sets we used for frequency of general use as this would have violated natural usage within the English language ( ), nor did we seek to equate the word sets for salience as this would also be contrary to norms (e.g.  ). Nevertheless,   post hoc   comparisons revealed the word sets to be statistically comparable in terms of length in letters, frequency of use within the English language relative Hyperspace Analogue of Language (HAL) norms ( ), as well as normed mean reaction time in lexical decision and naming, all as investigated and compiled within the English Lexicon Project ( ; number of letters,   P   = 0.24; normed frequency of use,   P   = 0.42; log-frequency of use,   P   = 0.69; RT in lexical decision,   P   = 0.23; RT in naming,   P   = 0.27). Furthermore, no differences were observed in arousal ratings relative to the Affective Norms for English Words ( ) for the subset of the words we used that are contained therein (  n   = 12 of 20;   P   = 0.27). 

 illustrates how the experimental component of the VV-SORP-T was conducted. Participants’ photographs were taken in neutral expression (instructions were to pose ‘as if for a passport photograph’) using a standard-use electronic camera (4.1 megapixels) against an off-white office wall. Photographs were then standardized in order to match in essential respects those used in the development of the NimStim set of facial expressions ( ). The latter were used as pictures for a comparison ‘other’ (i.e. a female was selected from the NimStim set for each study participant, matched as closely as possible for ethnicity, hair colour and hair length). Before beginning the VV-SORP-T participants were habituated to the photographs for 6–10 s (as desired) in order to reduce their novelty, with the ‘other’ instructed to be regarded as ‘a typical person they might meet in their day-to-day life but presently do not know personally’. This manipulation was intended to limit error associated with responding to specific persons as has been used in previous fMRI studies (e.g. individual differences in how one regards former American President George Bush;  ). 

Instructions underscored that completing the VV-SORP-T would require participants ‘to do three things: 1) internally rehearse statements and read words, 2) press response buttons on a keypad, and 3) all the while pay close attention to how you are feeling throughout the different parts of the task’. Participants were instructed to view a fixation cross (presented for 12 s in between task-blocks) until they were presented with the word ‘SELF’ or ‘OTHER’ (for 3 s) signalling which of the respective pictures they were about to see. Upon seeing their own or the other person’s photograph (also presented for 3 s), they silently rehearsed to themselves ‘I am’ or ‘She is’, respectively, and then pressed a keypad button with either their index or middle finger (counter-balanced). Participants were then presented with a single positive or negative word for 3 s, asked to silently read the word and then pressed another keypad button with their other finger. Four additional pictures and words were then presented following the same ‘picture-then-word’ rotation, with the identical picture displayed in all cases, and the words being of common valence. Therefore the stimulus presentations were blocked in terms of the conditions Reference (Self   vs   Other, i.e. photographs) and Valence (words), creating four trial types: self-negative (S-N), self-positive (S-P), other-negative (O-N) and other-positive (O-P). Participants were not instructed that they ‘should try to press the buttons as fast as possible’ as is often done in social cognition experiments. In contrast, participants were instructed only to press the buttons ‘so that we can assess afterwards whether you are paying attention to and completing the task’. This passive orientation was intended to focus attention towards introspection and interoception with participants reminded repeatedly of the importance of ‘paying close attention to how you are feeling throughout the different parts of the task’. 

While undergoing FMRI, participants were presented with eight-blocks in each of three 6-min runs in which the self and other photographs were presented in combination with two negative and two positive word lists. The order of the eight blocks within runs was fully randomized within and across participants. A full 6-min practice run was also completed outside of the scanner in an office setting ∼30 min before scanning in order to normalize participants to the task. 

Immediately after completing the experimental task component and exiting the scanner, participants were asked open-ended and percentage rating-scale questions about their response to the four experimental conditions (S-N, S-P, O-N, O-P). The percentage rating-scale asked participants to rate from 0 (‘Not at all’) to 100% (‘Strongly’), with 50% indicating ‘Moderately’, ‘ … how much you felt certain specific feelings in response to each picture and word type combination’. Ratings were provided for the following five negative affective states: ‘Anger’, ‘Sad’, ‘Anxiety-Fear’, ‘Disgust’, ‘Bad About Self’, and for two positive affective states: ‘Happy’ and ‘Good about Self’. As previously noted we conceptualize affective responses to the task as providing an additional measure of relevance to individual differences in self-esteem-related processes. Specifically, our prior study observed that individuals with lower trait self-esteem reported experiencing greater negative affect during S-N trials, and lesser positive affect during S-P trials ( ). Results for quantitative ratings collected from the present sample are presented herein and open-ended comments are included as   Supplementary Table S1  . 



### Procedure 
  
All procedures were approved by the health sciences research ethics board of Western University in London, Ontario, Canada. As noted previously, participants were assessed for study inclusion criteria and completed a short questionnaire battery including the adjective rating component of the VV-SORP-T ∼2 weeks prior to scanning. Participants completed a single-block practice version of the experimental component of the VV-SORP-T in an office setting ∼30 min prior to fMRI scanning, and three blocks of the experimental component of the VV-SORP-T while undergoing fMRI. Participants then rated their affective response to the VV-SORP-T immediately post-scan. The entire experiment took ∼75 min to complete. 

Imaging took place at the Robarts Research Institute in London, Ontario, Canada. All imaging data were collected using a 3.0 Tesla whole-body MRI scanner (Magnetom Tim Trio, Siemens Medical Solutions, Erlangen, Germany) with the manufacturer’s 32-channel phased array head coil. Orthogonal scout images were collected and used to prescribe a tri-dimensional T1-weighted anatomical image of the whole head with 1 mm isotropic resolution (MP-RAGE, TR/TE/TI = 2300/2.98/900 ms, flip angle = 9°, FOV (  x  ,   y  ,   z  ) = 256 × 240 × 192 mm, acc. factor = 4, total acq. time = 3 min 12 s). The anatomical volume was used to determine the angle of the transverse plane passing through both the anterior and posterior commeasures mid-sagittaly and as the source image for inter-individual spatial normalization. A set of 64 contiguous, 2 mm thick imaging planes for BOLD fMRI were prescribed parallel to the AC  –  PC plane and positioned to ensure coverage of the top of the brain. BOLD fMRI images were acquired with the manufacturer’s standard gradient echo EPI pulse sequence (single-shot blipped EPI) using an interleaved slice acquisition order and tri-dimensional prospective acquisition correction (3D-PACE). EPI volumes were acquired with 2 mm isotropic resolution and the following parameters: FOV = 192 × 192 mm, 94 × 94 matrix, TR/TE = 3000/20 ms, flip angle = 90°, 64 slices, 178 measurements. Before completing the VV-SORP-T while undergoing fMRI a ‘resting-state’ functional scan of each participant’s brain was also acquired, to be described elsewhere. 


### Data preparation and statistical analysis 
  
Across blocks and runs for each of the four experimental conditions (S-N, S-P, O-N, O-P), VV-SORP-T survey scores were summed, and button-press RT and affect ratings were averaged. The effect of experimental condition on each of these variables was examined by ANOVA with results reported in  .
   
Descriptive statistics and paired comparisons between conditions of the VV-SORP-T 
    

Analyses of the BOLD signal were conducted via SPM8 (Welcome Department of Imaging Neuroscience, University College, London, UK). Standard preprocessing was conducted within SPM8, with volumes realigned to the first functional image acquired (unidirectional movements were <4 mm from origin in all cases), normalized to a common EPI template [rendering 2 mm  voxels in accordance with the coordinate system of the Montreal Neurological Institute (MNI)], and data smoothed across 8 mm (FWHM). A canonical haemodynamic response function was modelled as a response to each stimulus in individual participants (first-level), with group-averaged results evaluated as random effects (second-level). The BOLD response observed during each of the four task trials relative to between-block fixation was examined via the general linear model. Planned contrasts also compared response occurring during S-N relative to S-P trials, S-N relative to O-N trials, and S-P relative to O-P trials, thus examining the effects of Valence within Reference, and Reference within Valence. Group-averaged results for these contrasts are reported in   and  . We also report the results of main effect contrasts for Reference and Valence in   Supplementary Table S2   and   Supplementary Figures F1 and F2  .
   
BOLD response during the four conditions of the VV-SORP-T   vs   baseline fixation. Response during S-N trials is shown in red, during S-P trials in green, during O-N trials in magenta, during O-P trials in yellow. Voxel-wise   P   < 0.005 with a cluster threshold   k   ≥ 67 voxels. 
    
Group-level differences between VV-SORP-T trial types 
    

Of primary interest to this study, however, was a multiple regression analysis associating individual differences in survey and affective response scores with between-participant variability in the BOLD contrast between S-N trials and both fixation and O-N trials, and S-P trials and both fixation and O-P trials. Note that we preferred to evaluate BOLD correlations with adjective endorsement rather than Rosenberg Self-Esteem scores in this study, which allowed direct examination of associations between response to a common stimulus set (words) evaluated in differing contexts (i.e. paper-and-pencil survey rating of self and other descriptiveness   vs   performance of the experimental component of the VV-SORP-T). Results concerning individual differences are reported in   and  , and   and  .
   
BOLD response during S-N trials   vs   baseline fixation (BL) and O-N trials. Within the legend, positive correlations are denoted with a plus symbol; there were no significant negative correlations. Positive correlation between survey endorsement of negative traits and response during S-N trials (>BL) is shown in red. Positive correlation between survey endorsement of negative traits and response during S-N trials (>O-N trials) is shown in magenta. Positive correlation between experienced negative affect and response during S-N trials (>O-N trials) is shown in blue. Voxel-wise   P   < 0.005 with a cluster threshold   k   ≥ 67 voxels. 
    
BOLD response during S-P trials   vs   baseline fixation (BL) and O-P trials. Within the legend, positive correlations are denoted with a plus symbol, and negative correlations are denoted with a minus symbol. Regarding survey endorsement of positive traits and response during S-P trials (>BL), positive correlations are shown in green and negative correlations are shown in red. Positive correlation between experienced positive affect and response during S-P trials (>BL) is shown in yellow. Negative correlation between survey endorsement of positive traits and response during S-P trials (>O-P trials) is shown in magenta. Positive correlation between experienced positive affect and response during S-P trials (>O-P trials) is shown in cyan. Voxel-wise   P   < 0.005 with a cluster threshold   k   ≥ 67 voxels. 
    
Individual differences in response to S-N trials of VV-SORP-T 
      
Individual differences in response to S-P trials of the VV-SORP-T 
    

We report within Tables clusters of size   k   ≥ 67 voxels (approximating the volume of the smoothing kernel) with uncorrected voxel-wise   P   < 0.005 as a criterion selected so as to balance risk against type-I and type-II errors ( ). To examine the location of BOLD responses we observed in relation to previous studies, we also report the number of voxels that fell within an 8-mm radius (equally the smoothing kernel) of coordinates reported in recent meta-analyses of SRP ( ;  ;  ) and key study results ( ;  ;  ,  ;  ); an ROI for the left and right temporoparietal junction (TPJ) was also prescribed from   meta-analysis of neuroimaging studies of social cognition (as calculated in  ). Voxels in ROI analyses include those exhibiting   P   < 0.05 after correction for multiple comparisons (family-wise error rate) within the indicated centred spherical search volume, denoted   k   for Small-Volume Corrected. Cluster loci are labelled by the voxel exhibiting maximal effect size within MNI space. 



## RESULTS 
  
### Self-report, experiential and behavioural response 
  
 reports the descriptive and inferential statistics describing self-report and behavioural response to the VV-SORP-T. Replicating previous results ( ), survey endorsements were higher for S-P as compared with O-P (  d  ′ = 1.04), consistent with the self-positivity bias. Positive affect was also higher during S-P than O-P trials (  d  ′ = 1.21), although negative affect was not significantly higher during S-N than O-N trials (  d  ′ = 0.02). Finally, RT was marginally slower during S-N than O-N trials (  d  ′ = 0.35), and during S-P than O-P trials (  d  ′ = 0.15). 

Further replicating previous results ( ), participants who described themselves more positively (S-P survey endorsement) experienced less negative affect during S-N trials (  r   = −0.77,   P   < 0.001), less negative affect during S-P trials (  r   = −0.57,   P   = 0.006) and greater positive affect during S-P trials (  r   = 0.52,   P   = 0.011). In comparison, associations between S-N survey endorsement and affective responses were non-significant. 


### fMRI-BOLD response 
  
#### Group-level differences between trial types 
  
 and   report significant responses observed as specific to each of the four distinct trial types at the group level in comparison with between-block fixation (in  , S-N = red, S-P = green, O-N = magenta, O-P = yellow). S-N trials activated three clusters: the posterior mid-cingulate (at ROI 0, −13, 31,  ;   k   = 66), right superior parietal cortex and dorsal ACC-MPFC (at ROI −3, 19, 38,  ;   k   = 32). S-P trials activated two clusters: ventral MPFC and left middle frontal cortex. O-P trials activated two clusters: right DLPFC and right temporal pole. Finally, response during O-N trials was more distributed, with the maximal effect size observed within the right posterior insula, and additional activations observed within the left posterior insula, right middle frontal gyrus (at ROI 50, 24, 10,  ;   k   = 28), left middle frontal gyrus (at ROI −56, 15, 10,  ;   k   = 132), left precentral gyrus, left posterior mid-cingulate and left cuneus. 

Planned contrasts examining the effects of Valence within SRP and Reference within Valence are also reported in  . S-N trials were associated with greater response than S-P trials within two regions: the posterior mid-cingulate and right superior parietal cortex. In contrast, S-P trials were not associated with greater response in comparison with S-N trials in any brain region, and contrasts of Reference within Valence were non-significant. 


#### Individual differences in response to S-N trials 
  
 and   report correlations between self-report and affective responses, on the one hand, and response during S-N trials, relative to both between-block fixation and O-N trials, on the other. Concerning the contrast S-N > fixation, a positive correlation was observed between how negatively participants regarded themselves and response within the ventral MPFC-ACC (including within ROI 0, 22, −9,  ;   k   = 26). In addition, women who rated themselves more negatively demonstrated increased response within left VMPFC (including within ROI −6, 42, −12,  ;   k   = 7). In comparison, there were no significant correlations with variability in negative affective response. 

Concerning the contrast S-N > O-N, participants who regarded themselves more negatively demonstrated less response within the supplementary motor area (including within ROI −3, 14, 49,  ;   k   = 61) and retrosplenial cortex. In comparison, participants who experienced greater negative affect exhibited greater response within the parahippocampal gyrus and right amygdala. 


#### Individual differences in response to S-P trials 
  
 and   report correlations across the whole-brain between self-report and affective responses, on the one hand, and BOLD response during S-P trials, relative to both between-block fixation and O-P trials, on the other. Concerning the contrast S-P > fixation, a negative correlation was observed between how positively participants regarded themselves and response within the right parahippocampal gyrus/amygdala and right temporal pole. A positive correlation was observed between positive affect experienced during S-P trials and response within the DMPFC (within ROI 2, 55, 17,  ;   k   = 87), left TPJ (within ROI −52, −56, 22,  ;   k   = 48) and right temporal pole. 

Concerning the contrast S-P > O-P, a negative correlation was observed between how positively participants regarded themselves and response within VMPFC (at ROI −3, 36, −18,  ;   k   = 48), right DMPFC (at ROI 6, 27, 42,  ;   k   = 18), left TPJ (two clusters within ROI −52, −56, 22,  ;   k   = 22 and 36), right temporal pole and bilateral inferior frontal gyri. In comparison, the more positive affect participants experienced during S-P trials, the greater was their response within many of the same regions, specifically VMPFC (at ROI −3, 36, −18,  ;   k   = 20), DMPFC (at ROI 6, 27, 42,  ;   k   = 35), left TPJ (within ROI −52, −56, 22,  ;   k   = 31), left inferior frontal gyrus, as well as within the precuneus. 




## DISCUSSION 
  
How people represent themselves in comparison with others, and the role played by affective processing in such representations, are matters of significant interest to a social cognitive and affective neuroscience of core personality constructs including trait self-esteem. We investigated the neural correlates of self-esteem-related processes in response to the VV-SORP-T using an individual differences design. 

Although recent meta-analyses confirm greater response within MPFC, perigenual ACC and PCC during SRP than during ORP ( ;  ;  ), individual studies using relatively neutral adjectives rarely observe this effect (e.g.  ; cf  ;  ).  , using valenced adjectives, similarly observed few differences between SRP and ORP. Within the present study, the spatial maps obtained relative to fixation differed between valenced SRP and ORP ( ), while null effects were observed when conditions were directly compared, as conducted by  . We speculate that the neural correlates of SRP and ORP will differ principally in so far as SRP is regarded as more affectively salient (e.g.  ). In other words, we expect that trait endorsement must not only differentiate the self from others, but this result must sufficiently matter to participants to evoke corresponding differences in the BOLD signal. The use of valenced adjectives as in   study and the present one cannot assure this because, as was clearly the case in the present study, most participants will endorse robustly positive views of both themselves and others, leading trials requiring negative SRP and ORP to be regarded as relatively neutral and irrelevant ( ). 

In contrast to the modal self-positivity bias, however, a certain number of participants with lower self-esteem will endorse relatively negative views of themselves and a corresponding range of affective responses when such representations are primed such as via the VV-SORP-T. Consistent with expectations, in the present study these individual differences dovetailed considerably with between-subject variability in the BOLD response within ROIs including MPFC, PCC, left temporoparietal cortex and right amygdala. These potentials for heterogeneity across subjects in experiential response to a common stimulus pattern make them well suited to the study of the neural correlates of personality and individual differences ( ;  ). Further knowledge about the neural underpinnings of negative SRP may also enlighten our understanding of psychiatric disorders associated with maladaptive SRP including depression ( ;  ;  ) and post-traumatic stress disorder ( ). 

The present findings are consistent with and further inform current theorizing about the neural correlates of the ‘emotional self’ ( ). In particular, it has been posited that ventral MPFC (inclusive of ventral ACC;  ;  ) may be particularly associated with SRP that is affectively (and perhaps uniquely negatively) salient, whereas dorsal MPFC may be particularly involved in conscious, reflective processes that are either neutral or positive in nature ( ;  ). Consistent with previous observations, relative to fixation, we observed ventral MPFC/ACC response during negative SRP particularly in women who regarded themselves more negatively (see  ,   x   = 0,   z   = −10, red blobs), but dorsal MPFC response particularly in women who experienced greater positive affect during positive SRP (see  ,   x   = 0,   z   = +10 and +20, yellow blobs). However, when contrasting response occurring during positive SRP with positive ORP, ventral MPFC regions were particularly involved such that, interestingly, response was increased as a function of increasing positive affect but decreasing self-regard (see  ,   x   = 0,   z   = −20, cyan and magenta blobs, respectively). This dissociation suggests the merit of   distinction between the significance of referential   vs   affective ratings and may inform interpretations regarding the ‘validity’ of direct (e.g. self-report survey)   vs   indirect (e.g. task-induced affective response) assessments of self-esteem-related processes ( ;  ). Our findings that decreasing self-regard predicted positive SRP response (  magenta) agree with the hypothesis of VMPFC involvement in negative SRP. However, the dissociation with positive affective experience within a brain region strongly associated with reward requires interpretation. One interpretation is that VMPFC response is particularly increased in mediating positive affect in individuals for which positive affect is otherwise not easily activated, such as in individuals disposed towards alexithymia ( ) and anhedonia ( ;  ). However, that the same dissociation was observed concerning response within the left TPJ, which is widely implicated in social cognition and mentalizing (e.g.  ), suggests individual differences during ORP likely complicate interpretation. Consistent with this, self-reports obtained from the present participants as well as those collected from participants in a previous study suggest that response during ORP within the VV-SORP-T represents anything but simply a neutral comparator condition ( ). Investigation of individual differences in affective response during ORP as a predictor of the BOLD response could clarify this concern, but were considered beyond the scope of the present project given its focus on valenced SRP as it relates to self-esteem. It should also be noted that Lemogne and colleagues observed increasing response during SRP within dorsal MPFC in both depressed individuals ( ) and individuals high in trait negative affect ( ), which challenges a model emphasizing only the ventral MPFC in the affective aspects of SRP. 

Besides response within higher cortical areas, Yoshimura and colleagues recently revealed a dissociation between left   vs   right amygdala response and negative   vs   positive SRP, respectively ( ). The right amygdala has also been associated with   social   emotional processing ( ;  ;  ) as is inherent to the VV-SORP-T (see  , for descriptions of socio-emotional responses during ORP including guilt, shame and envy). In our study, however, not only those women who experienced greater negative affect during negative SRP, but also those women who regarded themselves less positively before positive SRP, exhibited an increased right amygdala response. If right amygdala response is to be interpreted as signifying a negative self-appraisal within the context of SRP ( ), our individual difference effects extend the significance of right amygdala response to positively valenced SRP. However, our results may qualify the finding in suggesting that the amygdala response may signify the outcome of the appraisal, that is, the experienced negativity of a stimulus or task, rather than the negativity inherent to the stimulus or task,   per se  . In other words, even objectively positive stimuli may be responded to   as if   they are negative (e.g.  ,  ;  ,  ), with the right amygdala response during SRP perhaps revealing the valence or salience of the result of that appraisal. 

The loci of activations observed within the present study overlapped most closely with those observed by  ,   and  , the only other studies, to our knowledge, directly addressing between-subject variability in SRP using a correlational design. MPFC response within the present study was more inferior to loci summarized by recent meta-analyses (wherein   z  -values are typically > 5;  ;  ;  ), but consistent with that observed with the methodology of Phan   et al.   ( ; also used by  ). Provided current models emphasize VMPFC in the affective aspects of SRP ( ;  ), this confluence of findings for the VV-SORP-T and Phan   et al.   methodology are interesting provided that both methods likely encourage affective processing more greatly than do most other standard judgments tasks (the Phan   et al.   method through the use of arousing pictures and the VV-SORP-T by engendering an association between self and valence and encouraging attention to that association). Overlapping responses observed herein with those observed by Moran   et al.   occurred in regions that differentiated reaction time in Moran   et al.  ’s study, implicating these regions in online SRP. Future neuroimaging studies might compare different SRP tasks to provide a more nuanced assessment of the specific subprocesses involved in SRP. 

Limitations of the present study should be addressed in future work. We recruited only female participants for the present study due to widely known gender differences in trait self-esteem and associated risk for depression ( ); future studies may wish to directly investigate the neural basis for these gender differences. Clarity of interpretation could have been enhanced had we also administered neutral words and assessed affective response to the task not only subjectively but also via peripheral physiological measures of arousal. It should further be noted that contrasts of both SRP and ORP with passive fixation may be underpowered due to similarity between the neural processes involved in SRP, ORP and the passive resting state ( ); inclusion of active control tasks other than passive fixation would be useful in future studies, which might utilize a rest-stimulus interaction paradigm to examine valenced SRP and ORP ( ). Finally, the external ‘real-world’ validity of the VV-SORP-T for predicting socio-emotional behaviour remains to be established. 


## SUPPLEMENTARY DATA 
  
 Supplementary data   are available at   SCAN   online. 


## Conflict of Interest 
  
None declared. 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-6'>
<h2>6. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/32059228/' target='_blank'>32059228</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Hyperfunctioning of the right posterior superior temporal sulcus in response to neutral facial expressions presents an endophenotype of schizophrenia</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Neuropsychopharmacology</p>
<p><strong>Publication Year:</strong> 2020</p>
<p><strong>DOI:</strong> 10.1038/s41386-020-0637-8</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/7297989/' target='_blank'>7297989</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study used task-based fMRI during social-cognitive processing (neutral face processing, emotion recognition, affective ToM) in a sample of healthy adult participants (no history of mental/neurological disorders). Whole-brain analyses were conducted and reported (FWE-corrected threshold reported), along with ROI analyses; however, whole-brain results are present (not ROI-only). It is an original empirical fMRI study (not a review) and does not include clinical/psychiatric samples. Although exact participant ages are not explicitly listed in the excerpt, the sample comprises healthy undergraduates/adults, consistent with the 18–60 criterion. Therefore it meets the review inclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.85</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Deficits in social cognition have been proposed as a marker of schizophrenia. Growing evidence suggests especially hyperfunctioning of the right posterior superior temporal sulcus (pSTS) in response to neutral social stimuli reflecting the neural correlates of social-cognitive impairments in schizophrenia. We characterized healthy participants according to schizotypy (  n   = 74) and the single-nucleotide polymorphism   rs1344706   in ZNF804A (  n   = 73), as they represent risk variants for schizophrenia from the perspectives of personality traits and genetics, respectively. A social-cognitive fMRI task was applied to investigate the association of right pSTS hyperfunctioning in response to neutral face stimuli with schizotypy and   rs1344706  . Higher right pSTS activation in response to neutral facial expressions was found in individuals with increased positive (trend) and disorganization symptoms, as well as in carriers of the risk allele of   rs1344706  . In addition, a positive association between right–left pSTS connectivity and disorganization symptoms during neutral face processing was revealed. Although these findings warrant replication, we suggest that right pSTS hyperfunctioning in response to neutral facial expressions presents an endophenotype of schizophrenia. We assume that right pSTS hyperfunctioning is a vulnerability to perceive neutral social stimuli as emotionally or intentionally salient, probably contributing to the emergence of symptoms of schizophrenia. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (28623 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Social-cognitive impairments have been proposed to present a marker of schizophrenia [ – ]. The impairments occur in different domains of social cognition, ranging from deficits in neutral face processing [ ,  ], emotion recognition [ ], up to complex social-cognitive processes [ ], like inferring others’ mental states, known as theory of mind (ToM) [ ], and are highly important for social functioning [ ]. The association of these deficits to enhanced activity and connectivity of the right posterior superior temporal sulcus (pSTS [ ,  ]) makes aberrant pSTS functioning during social cognition a highly promising endophenotype candidate for schizophrenia. 

Several regions of the brain are central to social-cognitive processing, including amygdala, medial and inferior frontal cortex, insula, fusiform gyrus, as well as pSTS [ ,  ]. Most of these regions have been both found to be affected structurally [ ], as well as functionally [ ,  ] in schizophrenia. For investigating the neural correlates of social-cognitive impairments in schizophrenia, we [ ] developed a social-cognitive task that assesses several aspects of social cognition (namely neutral face processing (NFP), emotion recognition (ER), and affective ToM (aToM)) using facial expressions as stimuli. Applying this task, we found activation in key regions of social-cognitive processing in healthy participants [ ]. In addition, hyperactivity in the right pSTS during NFP, but not during aToM, was revealed in two independent samples of patients with schizophrenia [ ,  ]. Furthermore, we found hypoconnectivity between the right and left pSTS for aToM, and a relative hyperconnectivity between the right and left pSTS for NFP [ ]. Other authors also [ ,  ] showed hyperconnectivity of the pSTS in emotionally and intentionally neutral conditions of social-cognitive paradigms. Since the pSTS is a core area of social cognition and prominently involved in inferring other’s intentions [ ] (also Schmidt et al., unpublished data), increased pSTS activation during NFP might be interpreted as a vulnerability for false-positive perceptions of intentions, also called hypermentalizing [ ]. 

Imaging genetics studies with healthy participants and with relatives of patients with schizophrenia provided further evidence for aberrant pSTS functioning during social cognition as an endophenotype of schizophrenia. ZNF804A, a zinc-finger protein, presents an odds ratio of 1.08 (0.92–1.26 95% CI) for schizophrenia samples [ ]. One of its single-nucleotide polymorphisms (SNPs,   rs1344706  ) [ ,  ] was identified in whole-genome association studies as the first common genetic variant associated with schizophrenia [ ,  ].   Rs1344706   is involved in regulating gene expression [ ], and has been linked to executive functioning [ ] and social cognition [ ]. Imaging genetics findings from two healthy samples suggest that activity and connectivity of the STS and adjacent temporoparietal junction are associated with variation in   rs1344706   in a mentalizing task with sketches [ ,  ]. Further, healthy relatives of patients with schizophrenia showed aberrant activation in this task. Family members had reduced activation in the medial prefrontal cortex during mentalizing, but increased activation in the posterior cingulate cortex and right middle temporal gyrus. Interestingly, activation in right middle temporal gyrus during mentalizing correlated positively with self-reported paranoid ideation [ ]. These findings are exemplary of the approach to identify endophenotypes by investigating variations of traits of a disease in healthy participants. 

Schizotypy as part of the schizophrenia spectrum is a valuable construct that refers to personality structures spreading dimensionally throughout the population [ ,  ], but can also present as a personality disorder [ ]. Schizotypy can be characterized by a three-factor model of sub-threshold psychotic symptoms, including positive (e.g., ideas of reference), negative (e.g., no close friends), and disorganization symptoms (e.g., eccentric behavior). Several studies have consistently revealed an association between schizotypy and the development of a psychotic disorder (for a review please see ref. [ ]). A longitudinal study reported that 9% of an at-risk sample had a transition to schizophrenia within 12 months, and suggested self-reported schizotypy presenting the most reliable scale-based predictor [ ]. In addition, accumulating evidence points to schizotypy and schizophrenia having common genetic [ ], neuroanatomical [ ], and neurocognitive [ ] abnormalities, which again highlights the strong associations between schizotypy and schizophrenia. Importantly, as in schizophrenia, schizotypy has been associated with different kinds of social-cognitive deficits [ ,  ]. 

To date, only two fMRI studies have investigated the association between neural correlates of mentalizing and schizotypy in healthy participants. Both studies found right pSTS activity for mentalizing varying with schizotypy [ ,  ]. However, whereas one [ ] revealed negative symptoms to be positively related to right pSTS activation during mentalizing, the other [ ] showed a positive association with positive symptoms. In these studies, different tasks and accordingly different stimulus materials were used to investigate ToM, possibly explaining the divergent results. An even more general and crucial aspect when comparing social-cognitive studies, however, is not only the selection of stimulus material but also of the control condition (ranging from emotionally neutral analogs of the experimental condition to completely nonsocial conditions), which is usually subtracted from the higher-order social-cognitive process. Therefore, divergent findings in prior studies might be explained by differences in brain activation in the control condition between participants with and without schizophrenia risk. 

To summarize, deficits in social cognition are proposed to present a marker for schizophrenia [ ], and aberrant pSTS functioning during social cognition is a promising endophenotype of schizophrenia [ ,  ]. In this imaging genetics study, we applied a social-cognitive fMRI task [ ,  ] that assesses different social-cognitive processes, and has consistently revealed right pSTS hyperactivation during NFP, but not during mentalizing, in patients with schizophrenia [ ,  ]. We aimed at investigating whether we find in healthy participants a comparable activation and connectivity pattern as in schizophrenia, depending on the   ZNF804A rs1344706   risk allele, and schizotypy. This allowed us to assess possible pSTS hyperfunctioning unconfounded of medication status, or chronicity of disease. For both   ZNF804A rs1344706   risk allele and schizotypy, previous studies found a relationship to aberrant pSTS activation during mentalizing [ ,  ,  ,  ], but the response to neutral facial expressions was not investigated. We hypothesized that activation and connectivity of the right pSTS in response to neutral facial expressions in healthy participants is positively associated with (1) the risk allele of the   rs1344706   genotype and (2) higher self-reported schizotypy. 


## Materials and methods 
  
### Participants 
  
Of 81 healthy participants, seven were excluded for the present analyses: five due to low fMRI data quality, one due to a BDI-II [ ] score >18, and one due to schizotypy scores >3 SD above the group mean. For the genetics analyses, one additional participant was excluded because genotyping for rs1344706 was not possible. Therefore, we included 74 participants (40 females, see Table  ) in the behavioral and imaging analyses and 73 participants (39 females) for the imaging genetic analyses. Participants were grouped for the imaging genetics analysis for the existence of the risk allele of schizophrenia [ ]; ZNF804A genotype groups: 62 AA/CA (risk-allele carriers and 11 CC non-risk-allele carriers). All participants were of German ancestry, had higher school certificate, were right-handed, had normal or corrected-to-normal vision and no self-reported background of mental or neurological disorders, or drug abuse. In addition, participants reported having no relatives with psychotic disorders.   
Characteristics of the sample. 
  
 SPQ   schizotypal personality questionnaire,   AA/CA   indicates the risk-allele carriers,   CC   indicates the non-risk-allele carriers. 
  

Prior to the study, participants were informed about study procedure and purpose and gave their written informed consent. The study was approved by the local ethics board of the Medical Faculty Mannheim, University of Heidelberg. The data reported here are part of a larger study on the human mirror neuron system that involved a measurement containing simultaneous EEG-fMRI with three tasks (including an imitation task, an empathy task, and the social-cognitive task presented here), blood-taking and a series of questionnaires, including the Schizotypal Personality Questionnaire (SPQ [ ], details are presented in the Supplementary Text  ), and a second measurement with transcranial magnetic stimulation prior to fMRI. The results reported in this paper are based on the fMRI data of the first appointment. 


### Experimental paradigm 
  
We applied a modified version of the social-cognitive task that was used in earlier studies with patients with schizophrenia [ ,  ]. The paradigm was extended to four conditions, including three levels of social cognition [lower-level social cognition (NFP), ER, and higher-level social cognition (aToM)], and a nonsocial control condition. In each trial of the social-cognitive conditions, a statement preceded a facial expression. These statements described the facial expressions referring to physical features (gender or age) for NFP, the emotional state (fear or anger) for ER, or the possible intention (running away or blustering) for aToM. For NFP, only neutral facial stimuli were shown, for ER and aToM only emotional facial expressions. The facial stimuli were taken from the Karolinska Directed Emotional Faces set [ ]. Half of the stimulus persons were male, and the same persons were used for each of the social-cognitive conditions. For the control condition, prior to a geometric figure (a triangle or a circle) a statement describing the figure (e.g., “This is a circle”) was displayed. Task duration was around 8 min (details of timing and presentation can be found in Fig.   and Supplementary Text  ).   
The social cognition fMRI task. 
  


### Genotyping 
  
Genotypes for   ZNF804A SNP rs1344706   were extracted from whole-genome genotype data obtained using Illumina Global Screening array and following stringent quality control (see Supplementary Text  ). 


### Imaging data acquisition and analyses 
  
The study was conducted with a 3-Tesla Siemens Tim TRIO whole-body magnetic resonance tomography (Siemens Medical Systems, Erlangen, Germany; acquisition protocol can be found in Supplementary Text  ). Brain activity and connectivity analyses were conducted with SPM8 (Wellcome Department of Imaging Neuroscience, Institute of Neurology, London, UK). Data preprocessing contained slice-time correction, realignment, co-registration to the structural image, spatial normalization (MNI template) with resampling to a 3 × 3 × 3 mm voxel size, and spatially smoothing with an 8 mm full-width half-maximum kernel. The first-level analyses were achieved by a general linear model with four regressors (aToM, ER, NFP, and control), and six motion parameters, derived from the realignment procedure, as covariates. The hemodynamic response function was modeled to the onset times of the pictures. The time series was high-pass filtered using a 128 Hz function. From the model, linear combinations of the regressors built the contrasts of interest, including effects of each higher against the lower social-cognitive condition (aToM > ER, ER > NFP), and each condition against control (aToM >control, ER > control, NFP > control). Connectivity analyses were applied using generalized psychophysiological interactions (gPPI [ ]), as implemented in the gPPI toolbox (  http://www.nitrc.org/projects/gppi  ) with a functional mask of right STS as seed region, produced from our previous comparison between aToM and ER in 40 undergraduate students [ ] (details of the gPPI analysis are reported in Supplementary Text  ). 

For second-level analyses, significance threshold for exploratory whole-brain analyses was   p   < 0.05 FWE-corrected,   k   = 10. We conducted one sample   t   tests to analyze the effect of each social-cognitive condition, and a within-subject one-way analysis of variance (ANOVA) to identify the neural correlates of increased social-cognitive processing (contrast: [aToM > control] > [ER > control] > [NFP > control]). Regression analyses were conducted to explore the associations between the factors related to schizophrenia (schizotypy and the rs1344706 risk allele) and right pSTS activation, and connectivity for the different social-cognitive conditions. Region of interests were right and left pSTS, as derived from an earlier study [ ]. These masks were also applied in our studies on patients with schizophrenia [ ,  ]. The significance threshold for the ROI analyses was set to   p   < 0.05 small volume corrected (svc),   k   = 10. Behavioral data were analyzed with SPSS version 23. Differences between the social-cognitive conditions in reaction times (RTs) or accuracy were analyzed with repeated measures ANOVA, post hoc tests were conducted with paired-samples   t   tests. Pearson correlation was applied to investigate possible associations among task conditions, and to test the associations between schizotypy and task performance. We conducted independent sample   t   tests to test genotype effects on task performance, as well as to investigate differences in self-reported schizotypy, depending on genotype. 



## Results 
  
### Behavior 
  
Similar to our previous studies [ ,  ,  ], RTs and accuracy differed significantly between conditions, with the control condition being the easiest and aToM being the most difficult task condition. Neither genotype nor schizotypy significantly affected task performance (detailed behavioral results are reported in Supplementary Text   and Supplementary Fig.  ). In addition, no significant differences in self-reported schizotypy were revealed, depending on the risk allele (see Table  ). 


### Imaging 
  
Replicating the results from our previous studies [ ,  ], activation increased linearly from NFP over ER to aToM in regions of the “social brain”, including bilateral superior temporal gyrus covering pSTS, bilateral inferior frontal gyrus covering BA44 (Fig.  ; detailed results of task effects are presented in Supplementary Table  ). Whole-brain analyses of right pSTS connectivity differences between conditions were not significant across participants. ROI analyses revealed greater pSTS connectivity between hemispheres for aToM compared with ER at the trend level (peak voxel: −57, −49, 7;   t   = 3.37,   p   = 0.069 svc,   k   = 10).    Neural correlates of distinct social-cognitive processes.  
 a)   neural correlates of increasing social-cognitive demands [with the contrast: (affective theory of mind > control) > (emotion recognition > control) > (neutral face processing > control)];   b)   affective theory of mind (> emotion recognition);   c)   emotion recognition (> neutral face processing);   d)   neutral face processing (> control condition). Significance threshold is   p   < 0.05, FWE-corrected,   k   = 10. 
  

#### rs1344706 
  
ROI analyses revealed that risk-allele carriers compared with non-risk-allele carriers had increased right pSTS activation during NFP (> control; peak voxel: 63, −58, 13;   t   = 3.19,   p   = 0.042 svc,   k   = 10, Fig.  ). No significant differences in pSTS activation were found for ER and aToM, and also right–left pSTS connectivity during all task conditions did not differ between risk-allele carriers and non-risk-allele carriers. In addition, whole-brain analyses with the given significance threshold revealed no significant group differences, neither in the activation nor in the connectivity analyses.    Associations between functioning of right posterior superior temporal sulcus for neutral face processing and schizotypy as well as rs1344706 genotype.  
The first two scatter plots show positive correlations between activation in the right posterior superior temporal sulcus (pSTS) for neutral face processing (> control) and   a)   disorganization, as well as   b)   positive symptoms;   c)   positive association of disorganization with right-to-left pSTS connectivity for neutral face processing (> control);   d)   genotype effect of increased activation in the right pSTS for neutral face processing (> control). Significance threshold for display purposes is   p   < 0.005 uncorrected,   k   = 10. Note: rpSTS stands for right posterior superior temporal sulcus, lpSTS stands for left posterior superior temporal sulcus. 
  


#### Schizotypy 
  
There was a trend for a positive association between right pSTS activation for NFP (> control) and schizotypy sum score (peak voxel: 63, −55, 10;   t   = 3.01,   p   = 0.065 svc,   k   = 10). There was also a significant positive association between activation in right pSTS and disorganization symptoms (peak voxel: 57, −55, 7;   t   = 3.54,   p   = 0.018 svc,   k   = 10, Fig.  ), and at the trend level with positive symptoms (peak voxel: 63, −55, 10;   t   = 3.94,   p   = 0.077 svc,   k   = 10, Fig.  ). ROI analysis also revealed a significant positive correlation between disorganization symptoms and right–left pSTS connectivity during NFP (> control; peak voxel: −45, −70, 22;   t   = 3.60,   p   = 0.038 svc,   k   = 10, see Fig.  ). Neither for ER nor for aToM were significant associations between schizotypy and pSTS activation, or connectivity found. In addition, whole-brain analyses with the given significance threshold did not reveal any significant associations of schizotypy with task-related brain activation and connectivity. 




## Discussion 
  
This study aimed at investigating whether pSTS functioning during social-cognitive processing is an endophenotype for schizophrenia. Confirming our hypothesis, we found a positive association of right pSTS activation for neutral face processing with schizotypy (in particular disorganization, and positive symptoms on a trend level), and also with a risk allele for schizophrenia. Furthermore, connectivity between the right and left pSTS during neutral face processing was positively associated with disorganization symptoms. 

The pSTS is consistently found to be involved in inferring goals and intentions [ ,  ,  ,  ]. Across participants, we replicated our previous findings showing decreased performance and increased activation in pSTS and BA44 with increasing social-cognitive demands. With this, our results again highlighted the role of pSTS functioning for inferring others’ intentions [ ]. Importantly, increased right pSTS functioning in our participants with schizophrenia risk allele and subclinical symptoms of schizophrenia was present only for neutral face processing, but not for higher-order social-cognitive conditions. This supports our previous findings and conclusions that impairments in higher-order social cognition in schizophrenia might originate in impaired basic social-cognitive processes [ ,  ]. Our results are also consistent with further previous findings with patients with schizophrenia. A recent study reported not only increased pSTS activation in response to the emotionally and intentionally neutral control condition in their social-cognitive task but also increased pSTS connectivity [ ]. These results add to the idea that pSTS dysfunction for neutral social stimuli might be regarded as neural basis for hypermentalizing, which may constitute a vulnerability to the emergence of delusion [ ]. 

But how could this pSTS hyperfunctioning in response to neutral facial expressions cause symptoms of schizophrenia? Kapur [ ,  ] proposed that psychosis, particularly delusions, result from aberrant attribution of novelty and salience to objects and associations, and that faulty attributions of salience arise due to chaotic, context-inappropriate firing of dopamine neurons. Delusions have been suggested to represent a deficit in encoding the precision of predictions and prediction errors [ ], indicating a bottom-up inappropriate perceptual input; i.e., aberrant salience. Supporting this idea, our results revealed a positive association between self-reported symptoms of schizotypy, as well as between the presence of a risk allele for schizophrenia, and activation in the right pSTS for neutral faces, and unveiled a positive association between disorganization and right-to-left pSTS connectivity. This might indicate that people with higher positive symptoms and a genetic risk for schizophrenia might be prone to perceive neutral faces as emotionally or intentionally salient. Whether these inappropriate perceptual inputs lead to delusions in turn could depend on how individuals interpret these false perceptions, pointing to the importance of a top-down cognitive explanation to delusions [ ,  ], and the impact of disorganization. When the cognitive explanation is interfered or interrupted due to executive dysfunction, the accumulating experiences of aberrant salience might gradually increase confusion and result in delusional ideas that are based on overinterpretation of emotions and intentions to neutral social stimuli. 

Together, our findings add to the perspective that delusions probably derive from dynamic interactions between bottom-up erroneous perception and top-down cognitive deficits, caused by increased responsiveness to emotionally and intentionally neutral social stimuli [ ]. Since all of our participants were without a history of mental disorders, we found alterations only on the level of neural functioning. Further studies with large patient samples that allow the analysis of subgroups are needed to investigate the validity of the proposed mechanisms in schizophrenia. 

Importantly, aberrantly high pSTS functioning in response to neutral social stimuli seems to be not “only” a marker of schizophrenia, but an endophenotype of schizophrenia according to the criteria characterizing an endophenotype proposed by Gottesman and Gould [ ]: (1) the endophenotype is associated with illness in the population: aberrant right pSTS functioning is consistently observed in patients with schizophrenia in response to stimuli and situations without emotional, or intentional meaning [ ,  ,  ,  ,  ,  ]. Our current results show a comparable neural pattern in healthy participants with increased proneness to schizophrenia, illustrating an association of right pSTS dysfunction with schizophrenia symptoms also in healthy participants. (2) The endophenotype is heritable: in line with previous studies showing aberrant pSTS functioning in schizophrenia risk-allele carriers [ ,  ], we found increased right pSTS activity in response to the neutral condition in   rs1344706   risk-allele carriers, possibly reflecting one aspect of the heredity of the right pSTS dysfunction. (3) The endophenotype should be state-independent: we found the neural pattern first in schizophrenia out-patients who were remitted from positive pathology [ ], then in in-patients with schizophrenia [ ], now even in healthy participants carrying the psychosis allele, suggesting that right pSTS dysfunction might represent a state-independent neural pattern for schizophrenia. (4) Within families, endophenotype and illness co-segregate: increased engagement of right pSTS varied with positive symptoms in patients with schizophrenia’ relatives [ ], suggesting that right pSTS dysfunction and schizophrenia symptoms co-segregate within families. However, studies systematically investigating differences in pSTS functioning between relatives of patients with schizophrenia are pending. (5) The endophenotype in affected family members is found at a higher rate in non-affected family members than in healthy participants: While hyperfunctioning was observed in relatives of patients with schizophrenia who reported positive symptoms, it is also found in non-affected family members at a higher rate than in healthy participants without familial risk for schizophrenia [ ]. In addition to the criteria initially proposed by Gottesman and Gould, a further criterion has been put forward [ ]: (6) the endophenotype should be a trait that can be measured reliably, and ideally is more strongly related with the disease of interest than with other psychiatric conditions: aberrant activation in the right pSTS was consistently revealed by our social-cognitive task in patients with schizophrenia [ ,  ] and also in the current study in healthy participants with increased schizophrenic proneness, but not in patients with borderline personality disorder [ ]. In addition, especially in patients with schizophrenia with paranoid symptoms, pSTS activity during a neutral condition was higher than in patients with autism [ ,  ], highlighting that dysfunction in right pSTS is not only a reliably assessable trait but might be specific to schizophrenia. Thus, there is extensive evidence supporting the idea that hyperfunctioning of pSTS to neutral social stimuli represents an endophenotype for schizophrenia. 

Despite the reported studies consistently finding genotype effects on brain activation and connectivity [ ,  ], they, like this study, tested only one risk SNP’s effect. In addition, since genetic penetrance is higher for endophenotypes than phenotypes [ ]; i.e., significant association between the risk allele and right pSTS functioning, but no significant association between the risk allele and schizotypy, several approaches would be of interest for future studies to validate our findings and to investigate the proposed mechanisms: (a) investigating the load of risk SNPs to reveal biological subcategories of schizophrenia [ ], (b) due to unequal distribution of risk-allele presence (only 11 participants homozygous for the non-risk allele), replication of the finding with pre-selection of participants depending on their genotype, (c) replicating the marginally significant association of positive symptoms and right pSTS activation with different approaches to assess schizotypy, such as the Oxford-Liverpool Inventory of Feelings and Experiences [ ], (d) targeting not only right pSTS activation and connectivity, but also of further regions that are central for social-cognitive processing (e.g., amygdala, MPFC). Besides, some previous studies only reported hypo-functioning in the pSTS with regard to schizophrenia in response to higher-level social cognition (such as ToM) [ ,  ]. Whether these studies would also reveal pSTS hyperfunctioning if the neutral condition was investigated remains an open question. However, investigating pSTS hyperactivation in participants with schizophrenia risk can be challenging, because no significant pSTS activation in response to the neutral conditions is found across all participants, pointing to small effect sizes that warrant moderate to large sample sizes to reveal the effects. Moreover, some studies suggest aberrations in left pSTS instead of the right pSTS presenting an intermediate phenotype for schizophrenia [ ,  ]. Perner et al. [ ] proposed that the left pSTS is linked to perspective differences for mental and nonmental objects, while the right pSTS is associated with mental states. Future studies should approach the question of laterality with a systematic variation of social-cognitive processing to clarify the functioning of this region in schizophrenia. 

Taken together, our findings point to right pSTS hyperfunctioning in response to neutral faces as an endophenotype of schizophrenia. We assume that right pSTS hyperfunctioning presents a vulnerability to perceive neutral social stimuli as emotionally or intentionally salient and suggest that bottom-up and top-down aberrations interact to cause delusions via deficient social perception. 


## Funding and disclosure 
  
This work was supported by the Heidelberg Academy of Science and Humanities. Zhimin Yan is supported by the Chinese Scholarship Council. The authors declare no conflict of interest. Open access funding provided by Projekt DEAL. 


## Supplementary information 
  




 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-7'>
<h2>7. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/19826471/' target='_blank'>19826471</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Understanding Others' Regret: A fMRI Study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2009</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0007402</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/2756584/' target='_blank'>2756584</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study investigating understanding others' regret (social cognition/empathy). Healthy adult participants (Study 1: 24 adults, ages ~22–31; Study 2: 24 adults, ages 19–30) are within the 18–60 range. The task involves social-related processing (observing another player’s gambles and judging their emotional state), and data were acquired with whole-brain EPI sequences and analyzed using SPM5 with whole-brain parametric and conjunction analyses (thresholded p<0.001 uncorrected; cluster reports). No ROI-only results, no patient or disordered samples, and this is not a review/meta-analysis. Therefore all inclusion criteria are met and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Previous studies showed that the understanding of others' basic emotional experiences is based on a “resonant” mechanism, i.e., on the reactivation, in the observer's brain, of the cerebral areas associated with those experiences. The present study aimed to investigate whether the same neural mechanism is activated both when experiencing and attending complex, cognitively-generated, emotions. A gambling task and functional-Magnetic-Resonance-Imaging (  f  MRI) were used to test this hypothesis using   regret  , the negative cognitively-based emotion resulting from an unfavorable counterfactual comparison between the outcomes of chosen and discarded options. Do the same brain structures that mediate the experience of regret become active in the observation of situations eliciting regret in another individual? Here we show that observing the regretful outcomes of someone else's choices activates the same regions that are activated during a first-person experience of regret, i.e. the ventromedial prefrontal cortex, anterior cingulate cortex and hippocampus. These results extend the possible role of a mirror-like mechanism beyond basic emotions. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (44749 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
From the early stages of cognitive development, humans are able to represent and understand others' mental and emotional states  . It has been suggested that the neural bases of this ability may rely on the mirror mechanism  ,  . The mirror mechanism has been investigated in two major domains, i.e. sensorimotor and emotional, involving two main circuits. One is located on the lateral convexity of the cortex, and includes the inferior parietal lobule (IPL) and the ventral premotor cortex plus the caudal part of the inferior frontal gyrus (IFG). This circuit mediates the understanding of gestures and meaningful actions  ,  . The second circuit, which includes the insula and anterior cingulate cortex (ACC), is involved in the experiential understanding of others' emotional states shaping interpersonal relations at a basic level  – . 

Although there may be several ways in which others' emotions can be understood, recent studies indicate that one such mechanism is based on the reactivation of the cerebral areas associated with the observer's direct emotional experience  . Yet, neural mirror-responses have been assessed only in conditions involving basic-level emotional stimuli, such as visual expressions of disgust   or cues signaling pain  . As far as complex emotions are concerned, to date there is only behavioral evidence to suggest the involvement of a mirror-like mechanism in the automatic understanding of others' emotional states  ,  . 

To further advance our understanding of complex emotional processes, the present study investigates whether the understanding of others' negative emotions involves the activation of the same neural mechanism as in the first-person experience. Specifically, we investigated whether a neural resonance system is also engaged in situations involving complex emotions that emerge at the interface with high-level cognitive processing. To this purpose we used   regret  , a cognitively-based emotion that occurs when one's outcome is worse than the outcome one would have obtained had one made a different choice. Unlike basic emotions, regret stems from the counterfactual comparison between alternative outcomes, as when the chosen option in a gamble results in a negative outcome   compared with   that of the unselected alternative  . The possibility to quantify and evaluate the values associated with unselected alternatives, resulting in better outcomes than the one obtained, is crucial for regret to occur. Additionally, the emotion of regret is elicited when the individual feels a personal responsibility upon the outcome of her/his deliberate choice. Without these prerequisites, regret would be replaced by the basic emotion of disappointment. 

Evidence that regret and disappointment are mediated by neural structures only partially overlapping comes from clinical   and brain imaging studies  , that employed gambling to assess the neural underpinnings of these emotions. These studies showed that the experience of regret specifically involves the activation of the medial orbito frontal cortex (mOFC)  ,  , ACC and hippocampus  . 

In the present work, we extended the studies on regret by investigating whether the same cortical areas involved in the first person experience of regret become active also when the individual is faced with emotional experiences of regret in others. Two   f  MRI studies testing mirror-like responses to regret were carried out. In both studies, participants chose one of two gambles resulting in real wins or losses, like in previous investigations  ,  . Unlike previous works, though, in the present studies the participants also observed the same sequence of events (gambles evaluation, decision, outcome evaluation), this time experienced by another individual (see  ). 
   Experimental conditions, Studies 1 and 2.  
From left to right, schematic depiction of the sequence of events in the conditions IP (“I play”, top) and OP (“Other plays”, bottom). Within each condition there are 5 phases: instruction, evaluation of the wheels, choice of the gamble, outcome evaluation and judgment of the outcome. In the depicted example, the participant chose the loosing wheel. The length in seconds of each sub-event in the two studies is shown, in the inferior-most part of the figure. 
  
As noted above, regret results from a sense of responsibility. Therefore, to address specifically regret, as opposed to disappointment, in two control conditions a computer program randomly chose one of the gambles for the participant or for the other player. In these instances, the computer choices still resulted in real monetary gains or losses for the players but, given the participants' lack of responsibility upon the gamble selection, the game outcome did not result in the feeling of regret  . 

The main difference between the two studies lies in the nature of the participants' task when presented with the outcomes obtained. In the first study, we ensured that the participants' emotional reaction to the results of the gambles was consistent with the actual counterfactual comparison between the obtained and unobtained outcomes (i.e., satisfied or unsatisfied with the outcome). In this way, we could also assess the participants' understanding of the other players' emotional state at outcome evaluation during “Other Plays” condition. More precisely, the participants were asked to indicate, after each trial, whether they were satisfied with their own decision (“I Play” condition) or whether, in their opinion, the other player was satisfied with her/his decision (“Other Plays” condition). Although this response was necessary to unfold the participants' emotional coherence with the actual outcomes in both IP and OP tasks, this type of judgment, by its nature, is likely to prompt an emotional response in the beholder. Since one requirement for a mirror response is its automaticity, to make sure that the observed activations were not affected by the explicit emotional appraisal of the gamble results, in the second study participants were required to give a non-emotional evaluation of the outcomes indicating whether results represented a win or loss. 

Finally, to shed light on the question of whether the engagement of a resonance mechanism when attending someone else's experience of regret is affected by the individuals' empathic aptitude, we compared brain activations of females and males, under the assumption that females are more empathic than males  . 


## Results 
  
### Study 1 
  
The reported activations are based on the contrasts between the conditions where the players (the participant or the actor) made the decision   versus   the control conditions (IP   minus   IF; OP   minus   OF). These contrasts aimed at controlling for activations merely related to the carrying out of the tasks (e.g. visual, motor, etc.) and to highlight those underlying regret, i.e. outcome evaluation when one was responsible for her/his own choices. Behavioral measures confirmed that participants paid attention to the outcomes of all experimental conditions (see   for details). 

In line with previous works on the neural correlates of regret processing  , a   parametric   analysis was carried out to highlight the regions showing a positive linear relationship between regional signal change and the objective amount of regret in the condition “IP   minus   IF” or “OP   minus   OF”. Additionally, to investigate the possible involvement of a resonance-mapping system for regret, we focused on the   common   parametric effects across tasks, that is on the cerebral regions activated both when experiencing regret (IP   minus   IF) and when being aware of regret experienced by someone else (OP   minus   OF) (see  –  and   for the description of the activated foci in the IP and OP tasks separately, as well as in the formal direct comparisons between them). 

The conjunction analysis between IP and OP statistical maps (relative to IF and OF, respectively; p<0.001 uncorrected) revealed significant common parametric activations in the left ventromedial prefrontal cortex (vmPFC), left amygdala and bilaterally in the hippocampus ( ,  ). Common parametric activations were also observed in the dorsal anterior cingulate cortex (ACC), and in a cluster extending from the supplementary motor area (SMA) to the middle cingulate cortex, as well as in the right middle temporal gyrus. 
   Common parametric effects of   regret   in Studies 1 and 2.  
Activations linearly and positively related to the objective amount of regret (measured as the difference between the outcomes of the chosen and unchosen gambles) in   both   the IP (  minus   IF) and OP (  minus   OF) conditions in Studies 1 and 2 (Conjunction analysis; p<0.001 uncorrected). a) Study 1: representative sections from the MNI305 template brain. From left to right: sagittal section showing activations in supplementary motor area (SMA), middle cingulate cortex and anterior cingulate cortex (ACC); horizontal section showing activations in ventromedial prefrontal cortex (vmPFC) and hippocampus (HIP); horizontal section showing left amygdala and right middle temporal gyrus activations. b) Study 1: from left to right, percent BOLD signal change (4 mm-radius sphere centered on the local maxima) in the Anterior Cingulate Cortex (ACC), ventromedial prefrontal cortex (vmPFC) and Hippocampus (HIP) is shown for both “I Play” (IP, yellow) and “Other Plays” (OP, blue) conditions. c) Study 2: representative sections from the MNI305 template brain. From left to right: sagittal section showing activations in middle cingulate cortex and ACC; horizontal section showing activations in vmPFC and HIP; coronal section showing right HIP activation. d) Study 2: from left to right, percent BOLD signal change in the same areas as in b). 
     Study 1, parametric analysis of   regret  : conjunction IP and OP conditions.        
To make sure that these results did not only reflect an emotional response to a negative outcome   per se  , in a separate analysis we investigated the regions where activity was related to   disappointment   (i.e., win or loss in the chosen gamble, independent of the outcome of the unselected one). Common parametric activations to IP and OP tasks were observed in a number of areas including the left postcentral gyrus, the parahippocampal gyrus bilaterally, thalamus and brainstem periaqueductal grey matter ( ,  ) but, crucially, in neither vmPFC nor ACC. 
   Common parametric effects of disappointment in Study 1.  
Shared effect of the parametric amount of disappointment (measured as the difference between the actual and unobtained outcome of the chosen gamble) across IP (  minus   IF) and OP (  minus   OF) conditions in Study 1, as shown by the results of a conjunction-analysis (p<0.001). 
     Study 1, parametric analysis of   disappointment  : conjunction IP and OP conditions.        

### Study 2 
  
Like in study 1, here we carried out a conjunction analysis of the parametric effects observed between IP (  minus   IF) and OP (  minus   OF) conditions. This analysis confirmed the results of study 1, in that mirror-like effects were found in the left ventromedial PFC and dorsal anterior cingulate cortex ( ,  ). As far as hippocampal activation is concerned, in study 2 we found a stronger activation in the right hemisphere, as opposed to an enhanced activation observed in the left hemisphere in study 1. However, these results are not in conflict since, as it can be observed from  , a parametric effect of regret was observed in the right hippocampus in both IP and OP conditions also in study 1, though the respective foci did not overlap. Finally, a few differences were observed with respect to study 1, the most notable being a lack of activation of the left amygdala. 
   Study 2, parametric analysis of   regret  : conjunction IP and OP conditions.        

### Individual Empathy-Scores and Gender Effects 
  
During a post-scanning session, participants had to complete an Italian translation   of the Balanced-Emotional-Empathy-Scale (BEES;  ), a test assessing emotional empathy. 

Behavioral data from the BEES showed that the mean scores for our participants in study 1 were 34.83 (s.d. = 16.75) for females and 19.33 (s.d. = 18.39) for males. These data were representative of the normal Italian population (female mean = 37, s.d. = 18; male mean = 21, s.d. = 18;  ) and revealed a significant gender difference, females being more empathic than males (Kolmogorov-Smirnov test for normality:   d   = 0.091,   p  >0.2; two-sample t-test, N = 24,   t  (22) = 2.15,   p   = 0.042). 

Consistent with these results, direct gender comparisons carried out in the parametric statistical maps of the third-person task (OP   minus   OF) revealed stronger activations for females than males in the ventromedial PFC, in ACC and in portions of the parietal cortex bilaterally, including the somatosensory cortex and the inferior parietal lobule ( ,  ). 
   Differential parametric effects of gender on attended regret in the “Other Plays” (OP) condition.  
The different linear parametric effect of regret for female   vs  . male participants in Studies 1 (a) and 2 (b) (thresholded at p<0.001 uncorrected) in the OP (  minus   OF) condition are shown on 3D-renderings and representative slices of the MNI305 template brain. 
     Study 1, parametric analysis of   regret  : direct gender-comparisons in OP condition.        
These findings were confirmed in OP condition (  minus   OF) of study 2, where enhanced activations for females with respect to males were observed in the ventromedial PFC and somatosensory cortex bilaterally ( ,  ). However, unlike study 1, an enhanced activation for females was also observed in the anterior insula bilaterally ( ). This result can be interpreted in relation to the behavioral scores obtained on the BEES in study 2, that not only showed a higher mean difference between females and males than that observed in study 1, but also higher scores for females with respect to those obtained by their peers from study 1 (females' mean = 53.83, s.d. = 11.37; males' mean = 23.08, s.d. = 27.11; Kolmogorov-Smirnov test for normality:   d   = 0.19, p>0.2; two-sample t-test, N = 24,   t  (22) = 3.62,   p   = 0.007). 
   Study 2, parametric analysis of   regret  : direct gender-comparisons in OP condition.        


## Discussion 
  
The aim of the present study was to investigate whether the understanding of complex emotions, like regret, in others involves the reactivation of the cerebral areas associated with the observer's direct emotional experience. Regret is a negative emotion arising from a counterfactual comparison between the outcome of chosen and discarded options, whereby the discarded option would have produced higher benefits to the individual  . Regret thus requires two conditions to occur: namely, the feeling of responsibility for the decision made and a post-decisional evaluation of possible unselected alternatives associated with better outcomes than the one obtained. These two conditions define the emotional and cognitive differences underpinning regret with respect to other negative emotions like disappointment for a loss  . 

In this study we controlled for the effect of regret on cerebral activity by means of methodological and statistical measures. Methodologically, we dealt with the players' feeling of responsibility by comparing the conditions in which the participants actively made a deliberate choice (IP, OP) with control conditions in which choices were randomly made by the computer (IF, OF). Statistically, we used a parametric analysis to investigate only those areas whose activity showed a positive relation with increasing levels of regret. Specifically, we modeled the difference between the outcome of the chosen and unchosen gambles, so that also positive outcomes could result in regret if compared to an even more positive unselected outcome. Violation to these assumptions (feeling of the responsibility and counterfactual evaluation) lead to another emotional state, namely disappointment, even when faced with the same amount of loss. 

The neural correlates of regret processing have been previously investigated using   f  MRI. These studies, carried out on healthy volunteers playing a gambling task similar to that employed in the present experiments, showed that the experience of regret is associated with the activation of OFC alongside structures involved in cognitively-induced responses to aversive and painful stimuli (ACC), and in declarative memory (hippocampal regions)   (see also   below). 

What distinguishes the present study from the previous ones is a specific focus to the understanding of the experience of regret when observing someone else experiencing it, i.e. a resonance mirror effect that, to date, has been investigated only with basic-level emotional stimuli. Among the studies addressing mirroring in the emotional system, of particular interest is the   f  MRI study by Singer   et al.  , where volunteers either experienced a painful stimulus or observed a cue indicating that their loved one, present in the same room, was receiving a similar stimulation. The areas that were activated both when the volunteers were experiencing pain and when they knew that the other individual was experiencing it, were the anterior insula bilaterally and the ACC. Similar results were reported also for disgust. As for pain, feeling disgust or observing someone expressing it activates the anterior insula and the ACC  . 

In line with these studies  ,   (see also  ,   and   for a review), we focused on the common effects observed in the cerebral regions that were activated both when experiencing regret (IP   minus   IF) and when observing the regretful outcome of another player (OP   minus   OF). 

Our data on the parametric effects common to IP and OP tasks (relative to baseline) in both studies 1 and 2 revealed several activation foci including the ventromedial prefrontal cortex, the dorsal anterior cingulate cortex (ACC) and hippocampus (  and  ,  ). These results confirm previous findings  ,   and, crucially, show that the activation of these regions also occurs when participants observe the other player's regretful outcomes. It is worth noting that the results from study 1 revealed a modulation of activity also in the amygdala that was not confirmed in our second study. In this respect, it is likely that, in study 1, amygdala activation was enhanced by the emotional nature of the judgment provided by the participants, and lack of activation in study 2 shows that modulation of its activity is not specific for regret. This lack of emotion-specificity is in contrast with vmPFC activation that, on the other hand, is core to the expression of regret. 

Largely on the basis of evidence coming from animal studies, the   medial   portion of ventral prefrontal cortex is thought to be associated with positive reward processing, as opposed to its   lateral   part that instead is supposed to be involved in the processing of negative stimulus valence  . However, several studies have highlighted a more complex picture, according to which the medial portion of ventral prefrontal cortex is engaged in the processing of both positive and negative emotional events  . What the present and previous works strongly suggest, however, is that not all types of emotion are associated with vmPFC activation; rather there seems to be a specific involvement of this area in the processing of complex emotions. A convincing evidence in this respect comes from clinical studies, showing that patients with medial PFC lesions that performed a gambling task similar to that employed in this study could not process the emotion of regret elicited by the counterfactual comparison between the selected outcome and those of unselected alternatives  . Notably, however, those patients could exhibit emotional arousal to a loss when the observation of post-decisional outcome did not induce any counterfactual reasoning, i.e. disappointment. 

These results confirm the view that vmPFC defines the emotional value of the error given by the difference between the obtained outcome and the unselected alternatives that, if chosen, would have produced better results. This error, which emotionally results in the negative feeling of regret, is a necessary drive for behavioral reorganization. Anterior cingulate cortex uses information about the emotional valence of unsuccessful behavior to re-organize future choices accordingly  . In other words, the negative emotion associated with regret is the basis of the motivation to workout alternative solutions in response to the reoccurrence of future similar situations. This motivation lacks in disappointment, where the individual has no feeling of responsibility upon the outcome and is powerless with respect to her/his loss. 

Core of this study are the common effects observed between the conditions IP and OP (after baseline subtraction), which indicate that vmPFC-ACC and hippocampal activations mediate the processing of regret not only when directly experienced, but also when knowing that someone else is facing a counterfactual negative outcome. More specifically, this finding shows that the understanding of others' regret is mediated by the reactivation of the same core cerebral regions that induce the feeling of regret in the beholder during a first person experience, hence supporting the involvement of a resonance, mirror-like, mechanism in the comprehension of the high-order emotion of regret when experienced by others. Through this mechanism, others' emotional states are mapped onto the same areas that underlie ones' own direct experiences, therefore allowing an automatic understanding of the cognitive/emotional states intrinsic to the complex emotion of regret in others. 

So far, there was only behavioral evidence to suggest that the mere observation of a negative situation occurring to another individual evokes in the observer the same mental processes as those of the acting individual. These investigations assessed counterfactual reasoning in social contexts by comparing reported mental simulation  s   of actors, readers and observers of different situations all resolving negatively  ,  . These studies showed that actors (who made a decision and obtained a negative outcome) and readers (who read a story describing the actor's choice and outcome) produce different counterfactuals by focusing attention on different aspects of the situation  . However, when comparing actors' and observers' counterfactuals, these studies show that observers (who directly observed the actors' negative resolving situations) tend to mentally simulate alternative post-decisional solutions to those situations as actors themselves do  . These results suggest that, when faced with the negative outcome of another person's choices, individuals tend to react as they were personally involved in that situation. 

Attending another's negative emotion, however, is a complex phenomenon that can elicit different and conflicting reactions in the beholder, as shown by two recent studies that have highlighted some of the several facets related to the understanding of others' emotions. These studies have addressed individuals' emotional responses arising from direct   social comparisons  ,  . In Takahashi   et al.  , experimental contexts were defined a priori so as to elicit in the participants either the emotion of envy or gloating (  schadenfreude  ).   f  MRI technique allowed to associate these emotions to the activation of dorsal ACC (envy) and of ventral striatum plus medial OFC (gloating), supporting the view that OFC activation is not specific for the processing of negative emotions. Bault   et al.  ,  , on the other hand, assessed the effects of one's own and others' previous outcomes on choice behavior in a gambling task. The authors observed that, when individuals played simultaneously on the same trials, the emotional (as assessed trough skin conductance response and heart-rate recording) and behavioral effects of envy and gloating (when the players made different choices) are stronger than the effects of regret and relief (when they made the same choices). In other words, these data show that, in a direct social confrontation, individuals' choice behavior is more strongly affected by the feelings of envy and gloating than by the emotions of regret or relief. 

At a first glance, based on data from both these investigations, one might argue that the neural activations observed in the present study during “Other Plays” condition could relate to the emotion of gloating for the other player's misfortunes, rather than to regret. However, several considerations speak against this interpretation. Firstly, those studies were constructed so to elicit direct social comparisons between individuals by either manipulating participants' specific information or by having individuals playing on same trials. In the present study, the effect of possible social comparisons on the reported results was minimized. In fact, participants played on different trials and, particularly in study 1, the OP trials occurred immediately after the IP ones (direct social comparison) statistically only in 1 out of 32 trials. Additionally, outcomes producing the feelings of regret and relief were counterbalanced, thus further reducing the effect of gloating also when OP trials directly followed IP ones. Moreover, evidence that our results are not spoilt by the effects of gloating is represented by a lack of activation of the ventral striatum in OP task, which Takahashi   et al.   indicate as its neural signature. Nonetheless, we do not reject the idea of possible different emotions, than regret, ultimately arising from the individual's awareness of someone else's regret. Still, our data clearly show that, in given contextual frames, e.g. when direct social comparison is minimized, and when individuals are aware of the process that leads to regret in others, observers neurally respond as they were directly involved in that situation. This neural process allows one to cognitively and emotionally reproduce the feeling experienced by a third person, thus leading to its automatic understanding. 

A critical factor in the level of an individual's   shared   experience is her/his empathic aptitude. In this study, the behavioral results obtained on the BEES showed higher scores for females than males, particularly in study 2, suggesting that higher emphatic aptitude is associated with enhanced activation observed for females in vmPFC (see also  ) and, only in study 2, in anterior insula (see   and  ,  ). Enhanced vmPFC activation for females during OP condition suggests that the engagement of the “resonant” mechanism in the regret network is particularly strong in emphatic individuals; insular activation, on the other hand, appears to be not related to regret   per se  , rather it can be more generally associated with the processing of emotional empathic responses, as also shown in previous studies  ,  ,  . 

On the whole, our data suggest that the emotional understanding of regret in others is specifically reflected by the activation of a subset of the regions involved in its direct, first-person, experience. Among these regions, vmPFC appears to be at the core of a counterfactual evaluation of the outcomes, updating the emotional valence of the obtained outcome with respect to that unobtained  . This evaluation results in the appropriate behavioral response associated with activity in ACC even when attending another's negative results. The finding of a resonance mapping system for the high-order experience of regret entails an important notion. In real social decisional contexts, one's own decisions and behaviors may be strongly influenced by interactive learning, i.e., learning from what other individuals experience as a result of their choices  . One might then wonder how such learning occurs, i.e. how the negative, regretful, outcomes of other individuals are coded in the decision-maker's brain. Does such a process involve the mere cold encoding of numerical quantities? The results of the present study show that this is not entirely the case. Rather, knowing the regretful outcomes of others' choices do lead to similar counterfactual comparisons and, via the reactivation of the same underlying cerebral regions, to the comprehension of the related emotional reactions, as experienced in a first-person perspective. This resonant emotion may represent a drive for behavioral reorganization even when attended in somebody else's experiences. 


## Materials and Methods 
  
### Study 1 
  
#### Participants 
  
Twenty-four healthy right-handed   monolingual native speakers of Italian (12 females [mean age = 25.75, s.d. = 2.18, range = 23.5–31.8] and 12 males [mean age = 25.34, s.d. = 2.90, range = 22–29.7]) participated in study 1. All participants had normal or corrected-to-normal visual acuity. None reported a history of psychiatric or neurological disorders, or current use of any psychoactive medications. They gave their written informed consent to the experimental procedure, which was approved by the Ethics Committee of San Raffaele Scientific Institute. 


#### Task 
  
The participants performed a classical gambling task  . In every trial, they were required to choose one of two gambles depicted as “wheels of fortune”, in which different probabilities of financial gain or loss are represented by the relative size of colored sectors of a circle. The gambles were then played and the results shown. Participants could thus evaluate not only the financial consequences of their decision, but also the outcome they might have obtained had they selected the alternative gamble. These evaluations gave them a sense of responsibility for their choices and determined a counterfactual reasoning, i.e., the main hallmarks of regret, when decisions produce relatively-negative outcome. 

In the present investigation, there were two basic experimental conditions (see  ). In the “  I play  ” (IP) condition, participants were asked to choose one of two gambles, leading to a financial gain or loss for themselves. The gambles were shown for 5 s, during which they could evaluate them and make a decision. Next, the appearance of an asterisk in the centre of the screen prompted the participants to choose, by pressing one of two buttons on a keyboard with their right index or middle finger. The participants had 2 s to choose the gamble. In case they did not answer within this temporal window, they received an “out of time” message, and a new trial started. Once selected, the chosen gamble was highlighted by a white contour, and 3 s after the appearance of the asterisk the outcome of both gambles was shown for 3 s. In the “  Other plays  ” (OP) condition, the participants were shown the same sequence of events (evaluation, decision and outcome, with the same timings) of the gamble played by an actor in a nearby room. In the OP condition, a small white square was shown along with the asterisk, either on its left or right side. The asterisk position indicated which gamble had just been chosen by the actor, and participants were asked to press the corresponding button. In order to focus their attention on the gamble-results in both IP and OP conditions, and to assess the participants' understanding of the other players' emotional state at outcome evaluation, after outcome presentation the participants had to indicate whether they were satisfied with their own result (IP) or whether the actor was satisfied with her result (OP), by pressing one of two buttons (left: yes, right: no; 3 s). 

As an explicit-baseline, two further conditions were used: in the “  I follow  ” (IF) and “  Other follows  ” (OF) conditions, participants were informed that the computer would randomly choose one of the gambles, for themselves or for the other player, respectively. In these conditions, the decision-period lasted 2 s. Like in the OP condition, the decision made by the computer was signaled by a small white square appearing along with the asterisk, and participants were simply asked to press the corresponding left/right button. These trials still resulted in financial gains or losses for the participants or the actor, yet enabled us to control for the feeling of responsibility for the gamble choice, which is a crucial determinant of the emotion of regret. 

Each trial started with a specific instruction indicating the condition type (1 s), which remained at the bottom of the screen throughout the trial length. All instructions were presented in Italian. 


#### Gambles structure 
  
The participants underwent a total of 256 trials (64 for each experimental condition). The complete list of trials was predetermined and identical for all the participants. In each gamble, the 4 possible outcomes resulted from paired combinations of 200, 50, −50 and −200 (arbitrary units), associated with 8 different levels of probability (30-70, 35-65, 40-60, 45-55, 55-45, 60-40, 65-35, 70-30). Thus, the possible combinations of wins and losses gave four potential levels of regret (−100, −150, −250 and −400) and relief (100, 150, 250 and 400). The possible combinations of payoffs and levels of probability were equally balanced across all experimental conditions. In each trial, payoffs and probabilities were associated so that a) one of the gambles was riskier than the other, and b) the difference between the gambles was minimized with regard to the expected-value (i.e., the sum of the probability of the two possible gamble outcomes, each multiplied by the corresponding outcome value). In order to compare the effects of different experienced   vs  . attended amounts of regret, it was crucial to outbalance the number of events of interest across the different experimental conditions. Therefore, unbeknownst to the participants, the list of stimuli was arranged so that in OP, IF and OF conditions every single trial resulted in a pre-determined pair of outcomes (and thus in a pre-specified amount of either regret or relief in the OP condition). In order to make sure that the number of regret and relief events balanced out in the IP task (where we had no control on the participant's choice), every trial was pre-determined to necessarily result in a variable amount of either regret or relief by means of a feedback-routine. For every task, the obtained “regret” and “relief” trials were then assigned to the different functional runs so to obtain a variable proportion of events of regret and relief. Crucially, to preserve a most realistic probabilistic scenario, in all conditions we ensured that, across trials, the least probable gamble outcomes would occur in a proportion equal or inferior to 50% (OP = 47%; IF and OF = 50%; IP = 42%). In fact, as confirmed by the post-scanning debriefing, all participants were unaware of the experimental control on the probabilistic occurrence of wins and losses. 


#### Instructions and procedure 
  
The participants underwent a training session and were introduced to the same unknown female actor before the beginning of the study. Moreover, they were informed that both their and the actor's performance in IP/IF and OP/OF tasks, respectively, would have resulted in a financial gain or loss with respect to an initial endowment. Importantly, to constrain a competitive attitude towards the actor's performance, participants were explicitly informed that their potential gains/losses were completely independent of those of the other player. Additionally, when introducing the actor to the participants, the actor's personal profile was purposely kept very low. The participants were informed about their cumulative earnings only outside the scanner, after the functional acquisition. 

The study was composed of 8 functional runs. Every run comprised 32 trials (8 for each experimental condition). These were randomly assigned to 8 blocks, each of which contained 4 consecutive trials of the same condition. The order of the functional runs, of the blocks within each run and of the trials within each block were randomized across participants. Null events were also included in every run, to allow estimation of low-level baseline brain activity. In order to desynchronize the timings of event-types with respect to the acquisition of single slices within functional volumes, interstimulus intervals (ISI) between successive trials were presented in different (“jittered”) durations across trials (1350, 1950, and 2550 s, in proportion of 4∶2∶1;  ). 

Visual stimuli were viewed via a back-projection screen located in front of the scanner and a mirror placed on the head-coil. The software Presentation 11.0 (Neurobehavioral systems, Albany, CA,   http://www.neurobs.com  ) was used both for stimulus presentation and participants' answers recording. 

After the scanning, participants were asked to report their personal impressions about the task. Then, they completed an Italian version   of the Balanced Emotional Empathy Scale (BEES;  ), a 30-item questionnaire on emphatic abilities designed to measure individual tendency to empathize with others' emotional experiences (i.e., emotional empathy). 



### Study 2: Differences with respect to study 1 
  
#### Participants 
  
Twenty-four healthy right-handed   monolingual native speakers of Italian (12 females [mean age = 20.28, s.d. = 1.16, range = 19–23] and 12 males [mean age = 22.86, s.d. = 3.26, range = 19–30]) participated in study 2. 


#### Task 
  
Three main differences distinguished study 2 from study 1 with regard to the task. Firstly, the emotional component of post-outcome judgment was replaced by a “cold” appraisal of the obtained outcome. Namely, instead of providing a satisfaction-judgment, the participants were required to indicate whether the gamble outcome was a win or a loss. Second, in study 2 participants' response was required in all four conditions (IP, OP, IF, OF) and only on 10% of the trials. Finally, the length of the evaluation phase (gambles presentation) was identical in all four conditions (4.5 s). 


#### Gambles structure 
  
Different from study 1, in each gamble the 4 possible outcomes resulted from paired combinations of 200, 50, −50 and −200 (arbitrary units), associated with only 3 different levels of probability (25-75, 50-50, 75-25). However, the possible combinations of wins and losses still gave four potential levels of regret (−100, −150, −250 and −400) and relief (100, 150, 250 and 400). 


#### Instructions and procedure 
  
All participants underwent a training session, and were introduced to an unknown actor. In study 2, half of them (50% females and 50% males) were presented to a female actor and the other half to a male actor. 


#### fMRI data acquisition and statistical analysis 
  
Anatomical T1-weighted and functional T2*-weighted MR images were acquired with a 3 Tesla Philips Achieva scanner (Philips Medical Systems, Best, NL), using an 8-channels Sense head coil (sense reduction factor = 2). Functional images were acquired using a T2*-weighted gradient-echo, echo-planar (EPI) pulse sequence (38 interleaved coronal slices covering the whole brain, TR = 2200 ms, TE = 30 ms, flip-angle = 85 degrees, FOV = 240 mm×240 mm, inter-slice gap = 0.5 mm, slice thickness = 4 mm, in-plane resolution 2.5 mm×2.5 mm). Each scanning sequence comprised 215 sequential volumes. Immediately after the functional scanning a high-resolution T1-weighted anatomical scan (150 slices, TR = 600 ms, TE = 20 ms, slice thickness = 1 mm, in-plane resolution 1 mm×1 mm) was acquired for each participants. 

Image pre-processing and statistical analysis were performed using SPM5 (Wellcome Department of Cognitive Neurology,   http://www.fil.ion.ucl.ac.uk/spm  ), implemented in Matlab v7.4 (Mathworks, Inc., Sherborn, MA)  . The first 5 volumes of each participant were discarded to allow for T1 equilibration effects. All volumes were then spatially realigned   to the first volume of the first session to correct for between-scan motion and unwarped  , and a mean-image from the realigned volumes was created. This image was spatially normalized to the Montreal Neurological Institute 305 (MNI305) brain template using a 12-parameter affine normalization and 16 nonlinear iterations with 7×9×7 basis functions  . The derived spatial transformations were then applied to the realigned-and-unwarped T2*-weighted volumes, that were resampled in 2×2×2-mm voxels after normalization. All functional volumes were then spatially smoothed with an 8-mm full-width half-maximum (FWHM) isotropic Gaussian kernel to compensate for residual between-subject variability after spatial normalization, and globally scaled to 100. The resulting time series across each voxel were then high-pass filtered to 1/128 Hz, and serial autocorrelations were modeled as an Auto-Regressive AR(1) process. 

Statistical maps were generated using a random-effect model, implemented in a 2-levels procedure  . 

At the first level, two sets of analyses were performed. Firstly, outcome trials were partitioned according to the 4 conditions (IP, IF, OP, OF) which were separately modeled as mini-epoch lasting 3 s. For each of the 4 conditions, one additional regressor modeled a linear parametric modulation of the outcome-related activity by the degree of objective amount of   regret/relief   (computed as the difference between the actual and unobtained outcomes). In line with Coricelli   et al.  's   procedure , in a second analysis we modeled a linear parametric modulation by the degree of   satisfaction/disappointment  , i.e., the amount of discrepancy between the obtained and unobtained outcomes in the   chosen   gamble only. All the within-trials events other than the outcomes, as well as those trials in which a wrong response or no response was given, were modeled in a single regressor of no interest. Regressors modeling events were convolved with a canonical Haemodynamic Response Function (HRF), and parameter estimates for all regressors were obtained at each voxel by maximum-likelihood estimation. Contrasts of parameter estimates were then calculated to produce “contrast images” for each contrast of interest (“IP   minus   IF” and “OP   minus   OF” for both regret- and disappointment-related parametric regressors). 

At the second (group) level, these two types of contrast-image were used to perform separate parametric (i.e., dependent on the degree of either regret or disappointment) analyses. Furthermore, since we aimed at investigating also potential gender effects on “mirror-like” cerebral activity, the 1 -level contrast images for “IP   minus   IF” and “OP   minus   OF” for male and female participants were entered into a 2×2 [perspective (“IP   vs  . OP”) by gender (female   vs  . male)] factorial design with sphericity-correction for repeated measures  . Based on a-priori hypotheses from a previous study  , the resulting statistical maps were thresholded at p<0.001 uncorrected for multiple comparisons, and only clusters larger than 5 voxels were reported. 

In order to assess common effects across IP and OP tasks, we carried out a conjunction analysis on the IP (  minus   IF) and OP (  minus   OF) statistical maps for both the disappointment- and the regret-related parametric effects. This analysis was done using an inclusive masking procedure, in which the statistical maps for OP conditions were inclusively masked by those for the IP condition. Finally, direct comparisons were performed to assess perspective- and gender-effects on condition-related cerebral activity in both analyses. The resulting statistical maps were thresholded at p<0.001 uncorrected for multiple comparisons and, in order to ensure that the observed activations did not result from relative deactivations, they were inclusively masked at p<0.05 uncorrected by those associated with the conditions of interest   minus   the baseline task. 

The location of the activation foci in terms of Brodmann Areas (BAs) was determined in the stereotaxic space of Talairach and Tournoux   after correcting for differences between the latter and the MNI coordinate systems by means of a nonlinear transformation (see   http://www.mrc-cbu.cam.ac.uk/Imaging/Common/mnispace.shtml  ). Those cerebral regions for which maps are provided were also localized with reference to cytoarchitectonical probabilistic maps of the human brain, using the SPM-Anatomy toolbox  . 




## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-8'>
<h2>8. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31157395/' target='_blank'>31157395</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Investigation of functional brain network reconfiguration during vocal emotional processing using graph-theoretical analysis</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Soc Cogn Affect Neurosci</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1093/scan/nsz025</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6545541/' target='_blank'>6545541</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This fMRI study tested vocal emotional (prosody) processing — a form of social/emotion-related processing — in healthy adults (N=36; ages 20–35). Data were acquired with whole-brain BOLD fMRI and analyzed at the whole-brain level (Power-264 parcellation, whole-brain functional connectivity and graph-theoretical measures); results reported global, nodal, and interregional whole-brain findings. No clinical or neurological populations were included and this is not a review/meta-analysis. Analyses are not limited to ROI-only results. Thus all inclusion criteria are met (social-related fMRI task, healthy participants age 18–60, whole-brain results) and no exclusion criteria are violated. Minor caveat: “social-related” is interpreted to include vocal emotional perception; confidence remains high.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Vocal expression is essential for conveying the emotion during social interaction. Although vocal emotion has been explored in previous studies, little is known about how perception of different vocal emotional expressions modulates the functional brain network topology. In this study, we aimed to investigate the functional brain networks under different attributes of vocal emotion by graph-theoretical network analysis. Functional magnetic resonance imaging (fMRI) experiments were performed on 36 healthy participants. We utilized the Power-264 functional brain atlas to calculate the interregional functional connectivity (FC) from fMRI data under resting state and vocal stimuli at different arousal and valence levels. The orthogonal minimal spanning trees method was used for topological filtering. The paired-sample   t  -test with Bonferroni correction across all regions and arousal–valence levels were used for statistical comparisons. Our results show that brain network exhibits significantly altered network attributes at FC, nodal and global levels, especially under high-arousal or negative-valence vocal emotional stimuli. The alterations within/between well-known large-scale functional networks were also investigated. Through the present study, we have gained more insights into how comprehending emotional speech modulates brain networks. These findings may shed light on how the human brain processes emotional speech and how it distinguishes different emotional conditions. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (37745 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Emotion is one of the crucial cognitive factors that affect our daily life and social interaction. Various facial and vocal expressions convey the emotion during social interaction. Thus, comprehending these emotional expressions and their underlying neural mechanism is essential to modern society and to build new communication technologies. Several prior neuroimaging studies have aimed to elucidate the neural mechanism foremotional processing; however, most of them have studied emotion based on facial expressions and visual stimuli ( ;  ). Of late, several neuroimaging studies have focused on vocal emotion. Functional magnetic resonance imaging (fMRI) studies have shown that emotional prosody (especially emotions such as anger) consistently activates amygdala as well as numerous brain regions in the lateral temporal lobe and frontal lobe ( ;  ;  ;  ). Additionally, electrophysiological [electroencephalography (EEG) and magnetoencephalography (MEG)] studies using event-related potentials have strived to delineate the neural dynamics related to the effects of vocal emotions. For example,   suggested that valence information is decoded during early processing, while arousal effects occur at a later stage of processing. 

In addition to changes in regional brain activity, emotional perception may also alter the interregional functional connectivity (FC) as well as the brain network topology. At the connectivity level, studies have employed FC analysis and investigated reorganized FC induced by emotional processing ( ;  ;  ;  ;  ). At the network level, the recent advancement in computational approaches, especially graph-theoretical analysis, has provided the means to characterize the brain network topology ( ). Several studies have used graph-theoretical analysis to investigate the alteration of brain networks when interpreting facial emotional expressions that have shown significant changes of global efficiency and clustering coefficient (CC) compared with the resting state ( ;  ). Compared with regional functional activation, connectivity-based and network-based studies may help us gain more insights into the neural mechanism of emotion and learn how emotion may modulate the cognition states. Currently, a growing body of evidence supports the affective workspace hypothesis, suggesting that either positive or negative affective state is not necessarily associated with activating a specific set of regions ( ;  ). Alternatively, it can emerge as ‘brain state’ at the population level. Therefore, to strengthen the validity of this hypothesis, it is essential to understand how emotion-related cortical regions interact during processing of emotional information. 

Several studies have explored the alteration of network topology due to facial emotional expressions, but not much is known about the effects of vocal emotional stimuli on brain networks at connectivity and network topological levels. Therefore, to explore the vocal emotion and its underlying neural mechanism, this study has the following three objectives. First, we sought to examine the feasibility of graph-theoretical analysis on fMRI data with vocal emotional stimuli. Second, we sought to explore whether vocal emotional stimuli induce any alteration of brain networks—at both network topological and connectivity levels. We also investigated the differences within/between well-known large-scale functional networks. Third, we sought to investigate whether there is any difference in network topology between the resting state and the ones induced by vocal emotional stimuli. 


## Materials and methods 
  
### Participants 
  
A total of 36 healthy volunteers (27 male and 9 female) participated in our study. Furthermore, to reduce the risk of possible confounding factors, the participants were recruited based on several criteria: being free of any brain disease or major brain injury, age ranging between 20 and 35 years and a college or higher-level education to understand the vocal emotion stimuli pronounced in English. Furthermore, we only recruited right-handed subjects to exclude any potential variability due to handedness. The Institutional Review Board at National Health Research Institutes approved this study, and all volunteers provided informed consent. 


### Experimental stimuli 
  
The vocal emotion stimuli were generated from part of the USC IEMOCAP database ( ). The audio data from IEMOCAP database consist of recordings of scripted or spontaneous speech during dyadic interaction between a pair of voice actors. Naive raters rated each recording with attributes including valence, arousal and dominance with the continuous rank from 1 to 5. For our study, we used the scripted dialogs by a chosen male voice actor whose recordings yielded the highest variability in the speech attributes among all voice actors. From 639 segments spoken by the selected voice actor, we selected 251 voice segments as the stimuli for our experiments. 

We categorized the stimuli into two types of emotional attributes, namely, arousal and valence, and designed three conditions for each feature. Each experiment comprised six 5 min vocal emotion stimuli and a 1 min break between any two stimuli. For the arousal attribute, the conditions were categorized into low (value ≤ 2.5), medium (2.5 < value < 3.5) and high (3.5 ≤ value) levels. For the valence attribute, the conditions were negative (value ≤ 2.5), neutral (2.5 < value < 3.5) and positive (3.5 ≤ value) levels. For each condition, the speech segments with the given attribute and level were shuffled to remove any contextual information and were then concatenated to form a 5 min continuous vocal emotional stimulus. The participants were asked to pay attention to the speech-based stimuli without being informed of the purpose or the details of the experiment. 


### Image acquisition 
  
MR experiments were performed on a 3T MRI scanner (Prisma, Siemens, Erlangen, Germany) at National Taiwan University. Each scanning session included T1-weighted imaging (T1WI), resting-state fMRI (rs-fMRI) and task-evoked fMRI (t-fMRI) of all vocal emotional stimuli. The T1WI protocol was employed using a magnetization-prepared rapid gradient-echo sequence with repetition time (TR) of 2000 ms, echo time (TE) of 2.3 ms, inversion time (TI) of 900 ms, flip angle (α) of 8°, voxel size of 1 × 1 × 1 mm , matrix size of 256 × 256 and 192 slices. Each fMRI scan with blood oxygen level-dependent (BOLD) contrast was acquired using gradient-echo echo-planar imaging sequence with TR/TE of 3000/32 ms, α of 90°, voxel size of 2.5 × 2.5 × 3 mm , matrix size of 96 × 96, 40 slices and 100 repetitions. 


### Data pre-processing 
  
Before network analyses, all rs-fMRI and t-fMRI data sets were pre-processed using DPARSF toolbox ( ). The pre-processing procedures included the removal of the first 10 volumes, slice-timing correction, co-registration to T1WI, covariate regression of head motion, white matter signals and cerebrospinal fluid signals, nonlinear spatial normalization using T1WI, linear detrending and band-pass filtering (0.01–0.1 Hz). To estimate the FC over the whole brain, brain regions were parcellated using the Power-264 functional atlas ( ), which comprises 264 putative functional regions-of-interest (ROIs) associated to 13 large-scale functional networks and a group of unlabeled regions ( ). We also provide the region definitions used in Automated Anatomical Labeling (AAL) atlas ( ) and reported the corresponding anatomical locations of functional ROIs using the definitions by the AAL atlas. The averaged time series of each putative functional ROI defined in Power-264 functional atlas was derived by averaging the pre-processed rs-fMRI signals within the ROI. The pairwise between ROI FC was derived by quantifying the temporal dependency between two extracted averaged time series. We computed two types of FC measures—Pearson’s correlation (PC) and covariance (COV). It should be noted that the negative FCs were excluded in the following analysis, i.e. only positive FCs were used. Subsequently, we employed the orthogonal minimal spanning trees (OMSTs) method on constructed FC matrices to filter out spurious connections ( ;  ). Briefly, the OMSTs iteratively extract the minimal spanning trees from a given graph, and the filtered graph is the aggregate of OMSTs that maximizes the global efficiency subtracted by the wiring cost of the brain network. Compared with the conventional sparsity thresholding method based on either a given FC value or a network sparsity, the OMSTs method is parameter-free and more reproducible in group-wise or even individual-level brain network ( ;  ). 
  
Abbreviations of the large-scale functional networks defined in Power-264 functional atlas 
  

### Graph-theoretical analysis 
  
After applying OMSTs, the graph-theoretical analysis was employed to derive both nodal and global graph-theoretical network measures from the filtered FC matrices. The nodal network measures used in this study are degree centrality (DC), CC ( ), local efficiency (E ) ( ) and PageRank centrality (PR) ( ). In addition to investigating the network attributes at nodal scale, we also examined the network attributes at the global scale—the whole brain—using a set of global graph-theoretical network measures. The global network measures in our study includes characteristic path length ( ), global efficiency ( ), mean local efficiency ( ), mean clustering coefficient ( ), transitivity ( ) ( ), modularity ( ) and assortativity coefficient ( ) ( ), in addition to the network wiring cost ( ). We provided the detailed definitions of network measures in the  . One can also refer to a previous review article for more details ( ). We also performed an analysis of complementarity among different network measures and provided the discussion in the  . 


### Statistical analysis 
  
In this study, we sought to explore the topological reconfiguration of t-fMRI networks with vocal emotional stimuli and rs-fMRI networks. By categorizing these vocal emotional stimuli into multiple arousal and valence levels, we further investigated the relationship within and between these levels, as well as their differences with the resting-state condition. The comparisons were performed at nodal network, global network and FC levels. As for each well-known large-scale functional network, we calculated the averaged nodal measures across its member ROIs, the averaged intra-network FC and inter-network FC connecting to other functional networks. Except the above analyses, we also performed the analysis of common connections across all subjects for each specific arousal, valence or resting-state condition and discussed in the  . All statistical analyses of the FC and graph-theoretical network measures were performed using the paired-sample   t  -test. All significant levels were subsequently adjusted for multiple comparisons jointly across 264 ROIs and 6 pairs of conditions (either resting-state and 3 arousal levels or resting-state and 3 valence levels) using Bonferroni correction. 



## Results 
  
### Investigation on nodal network measures 
  
 shows the statistical comparisons of the nodal network measures among different t-fMRI and resting-state conditions. Note that we denoted the type of FC in superscripts for a given network metric in the following sections. For example,   denotes the DC calculated using PC as definition of FC. For t-fMRI with arousal stimuli, significantly reduced   of low-arousal condition was found in an ROI (in STG.R) within the auditory network by comparing with resting-state condition. However, no significant differences among those arousal and resting-state conditions were found by using all nodal network measures derived from COV. For t-fMRI with valence stimuli, significant differences of nodal network measures were only found between neutral- and negative-valence conditions. Compared to neutral-valence condition, our results show decreased   in one ROI (located between MOG.L and IOG.L) within the visual network,   in one ROI (between DCG and SMA.L) within the hand sensory/somatomotor network and   in three ROIs (one in IOG.R, one between ITG.R and IOG.R and one between CUN.R an PCUN.R) in visual network of negative-valence condition. 
  
The statistical comparisons of nodal network measures among different task-evoked, (a) arousal stimuli and (b) valence stimuli and resting-state conditions. All   P  -values were corrected for multiple comparison across the arousal–valence levels by Bonferroni correction (  P   < 0.01;   P   < 0.001). For each ROI, both of the corresponding network in Power-264 atlas and the corresponding regions in Automated Anatomical Labeling atlas were shown. Please see   for abbreviations of AAL region 
    
The statistical comparisons of global network measures among different task-evoked, (a) arousal stimuli and (b) valence stimuli and resting-state conditions. All   P  -values were corrected for multiple comparison across the arousal–valence levels by Bonferroni correction (  P   < 0.01;   P   < 0.001) 
  

### Investigation on global network measures 
  
 shows the statistical comparisons of the global network measures among different t-fMRI and resting-state conditions. For t-fMRI with arousal stimuli, the high-arousal condition showed increased  ,  ,   and   compared to mid-arousal condition. The decreased   was also found in high-arousal condition compared to mid-arousal condition. Compared to low-arousal condition, increased   was found in high-arousal condition. However, no significant between-condition difference of global network measures was found by utilizing  as definition of FC. For t-fMRI with valence stimuli, significant between-group differences of global network measures were found mainly in negative-valence condition compared to other valence or resting-state conditions. For utilizing COV as FC definition, the altered global network measures includes increased   and decreased   (compared to all other conditions), decreased  ,   and   (compared to resting-state and neutral-valence conditions). For utilizing PC as FC definition, decreased  ,  ,   and increased   (compared to neutral-valence condition) were found. No significant between-condition difference of  ,   nor   was found among all comparisons. 


### Investigation on interregional FC 
  
In addition to network metrics—either nodal or global—we also performed the between-condition comparisons of interregional FC (PC based and COV based). For arousal stimuli, significant between-condition differences were found by using PC-based FC, while no significant between-condition differences were found by using COV-based FC. Compared with resting-state condition, significantly reduced PC-based FC were found in either low- or high-arousal condition for Aud, SM.M, SM.H, DA, VA and Vis networks, as shown in  . For valence stimuli, significant between-condition differences were found by using both PC-based and COV-based FC. By comparing the resting-state and positive-valence conditions, the significantly different connection with PC-based FC was found between DA and DMN. Most of the significant between-condition differences were found to associated with reduced FC in negative-valence condition, including Vis-FP (resting-state > negative-valence; neutral-valence > negative-valence), Vis-DMN (resting-state > negative-valence), SM.H-Vis (neutral-valence > negative-valence), SM.M-CO (neutral-valence > negative-valence) and DA-Vis (neutral-valence > negative-valence). Two significantly different connections with increased FC in negative-valence condition were found in intra-DMN (resting-state < negative-valence) and SM.H-CO (positive-valence < negative-valence). For COV-based FC, a significantly different connection was found between DMN and Vis (negative-valence < neutral valence;  ). 
  
Significant changes of FC associated with arousal stimuli and resting state. Blue and red lines signify decrease and increase of connectivity in the latter condition compared with the former condition, respectively. For having a better visualization, the ROIs are reordered and colored according to their correspondence to the large-scale functional networks. Please see   for the abbreviations of the functional networks. Note that we excluded CB in the illustration. All FCs are corrected for multiple comparisons across arousal levels using Bonferroni correction. 
    
Significant changes of FC associated with valence stimuli and resting state. Blue and red lines signify decrease and increase of connectivity in the latter condition compared with the former condition, respectively. For having a better visualization, the ROIs are reordered and colored according to their correspondence to the large-scale functional networks. Please see   for the abbreviations of the functional networks. Note that we excluded CB in the illustration. All FCs are corrected for multiple comparisons across valence levels using Bonferroni correction. 
  

### Investigation on large-scale functional networks 
  
 shows the statistical comparisons of averaged nodal network measures within well-known large-scale functional networks among different conditions. No significant difference was found in the arousal condition. In contrast, significant differences of averaged nodal network measures were found to be mostly associated with negative-valence condition. Compared with the neutral-valence condition, decreased averaged nodal network measures were found in negative-valence condition, including   and   in SM.H,   in DMN and  ,   and   in Vis for both FC definitions. Additionally, increased   in MR and decreased   in Vis were found in negative-valence condition by comparing with the neutral-valence and resting-state conditions, respectively.   shows the inter-network and intra-network comparisons of FCs. The alterations of FCs were only found in t-fMRI with valence stimuli, and most of them were associated with the negative-valence condition. A total of five inter-network alternations of PC-based FC were found, including VA-Sub (resting-state < positive-valence), CO-DA (positive-valence < negative-valence), Sub-FP (positive-valence < negative-valence), Aud-SM.M (neutral-valence > negative-valence) and Vis-DA (neutral-valence > negative-valence). In contrast, the only intra-network alteration was found in Vis (neutral-valence > negative-valence) by using COV-based FC. 
  
The statistical comparisons of averaged nodal network measures within large-scale functional networks among different task-evoked and resting-state conditions. All   P  -values were corrected for multiple comparison across the arousal–valence levels by Bonferroni correction (  P   < 0.01;   P   < 0.001). 
    
Significant changes of averaged intra-network or inter-network FCs with respect to the 12 large-scale functional networks (without CB and unlabeled) associated with the valence stimuli and resting state. Both PC- and COV-based FCs were investigated. Blue and red lines signify decrease and increase of connectivity in the latter condition compared with the former condition, respectively. For having a better visualization, the ROIs are reordered and colored according to their correspondence to the large-scale functional networks. Please see   for the abbreviations of the functional networks. All FCs are corrected for multiple comparisons across valence levels using Bonferroni correction. 
  


## Discussion 
  
Our study demonstrates that perception of emotional speech could modulate brain network topology in several cortical regions associated with emotion processing. We also found the altered global network topology among different task-based and resting-state conditions. Beyond regional level, we further investigated the alterations of network metrics and FCs within/between large-scale functional networks and reported our findings. To our knowledge, this is the first study that investigates the effects of vocal emotional stimuli on brain network topology using graph-theoretical analysis of fMRI data. These findings may shed light on how the human brain processes emotional speech and how it distinguishes different emotions. In the following sections, the results from our analysis and their interpretations are elaborated. Also, the limitations of the experimental design and data interpretation are discussed. 

### Task-related alterations in nodal network measures 
  
Results for valence stimuli revealed a tendency that the network topology was significantly altered under the negative-valence condition compared with that of neutral valence or resting state, suggesting that the negative-valence stimuli may modulate or reorganize the brain network. In addition, we should note that alterations of averaged network measures in the large-scale functional networks are highly consistent with that by investigating individual ROIs, further supporting our findings. One interesting finding from the experiments with valence stimuli was that the reductions of functional segregation (  and  ) were observed in the visual network. These alterations were observed in several individual ROIs in visual network and from investigating the averaged measures in visual network. A meta-analytic review by   has reported that a group of visual sub-regions would be activated under visual emotional stimuli. Furthermore, we hypothesized that these visual sub-regions could be stimulated by not only visual stimuli but also other modalities. A similar hypothesis has been introduced in an fMRI study by   in which activation in CUN was observed under attended anger prosody compared with neutral or unattended anger prosody. Therefore, we speculated that the alteration of network topology may be resulted from the complex cross-modal interactions during emotional processing. One possible explanation about cross-modal interactions in our case is the visual mental imagery triggered by the speech stimuli. A previous fMRI study showed that the mental imagery evokes greater emotional response than verbal representation ( ). Another fMRI study by   also revealed that the visual imagery is crucial for sentence comprehension. Essentially, the theory of multimodal mental imagery has been supported by a growing body of evidence. For instance, an fMRI study by   showed that using silent visual speech stimulus (facial videos during speech overlaid with written pronunciation) could activate primary auditory cortex. Other than visual mental imagery, a few studies have also reported different kinds of cross-modal interactions during emotional processing.  ,   have reported that visual attention could be modulated by anger prosody. Another EEG study by   also showed that the cross-modal prediction of emotion exists in the multimodal processing of audiovisual emotion. Based on these previous studies, we could suggest that a similar cross-modal interaction mechanism to alter the network topology might also be revealed in visual sub-regions. However, a more sophisticated experimental design in further study would be needed to verify our speculation. 

We also observed significantly reduced nodal functional segregation (  and  ) in the sensorimotor network by comparing negative-valence and neutral-valence conditions. These alterations were found in one ROI in the hand sensorimotor network and by investigating the averaged network measure of the mouth sensorimotor network. Consistently, previous studies have also reported the association of sensorimotor network with speech, language and emotional processing ( ;  ;  ). A study using transcranial magnetic stimulation suggested the role of supplementary motor area in movement control triggered by emotional stimuli ( ). An fMRI study showed that the vocal emotion was associated with the BOLD responses in emotion, attention and sensorimotor circuits, in addition to the inter-subject synchronization within somatosensory and supplementary motor cortices ( ). Intense emotion can trigger corresponding physiological and bodily response through sensorimotor and visceral nervous systems ( ;  ;  ). Therefore, it is reasonable to speculate that the alterations in sensorimotor network were likely due to the increased demand for physiological and bodily emotion response. 


### Task-related alterations in global network measures 
  
Our results showed that vocal emotional stimuli altered not only nodal network measures but also global network measures. For arousal stimuli, significant increases of functional integration (increased   and decreased  ) and segregation (increased  ,  , and  ) were found in high-arousal condition compared with low- and mid-arousal conditions. For valence stimuli, significantly reduced functional integration and segregation were found in negative-valence condition compared with all the other conditions (neutral valence, positive valence and resting state). We hypothesized that the brain network for processing emotional speech with high-arousal condition might intrinsically exhibit distinct level of functional integration and segregation as compared with other conditions or resting state. In this case, the brain network under high-arousal condition may show higher degree of integration and segregation, while the task-negative resting-state network is being suppressed. However, the brain network under low- or mid-arousal condition may be presented as a mixed pattern of task-positive and resting-state networks. Having different combinations of task-positive and resting-state networks may contribute to our speculation about the altered global network topology between high-arousal and the other two arousal levels. 

Similarly, the brain network to process the negative-valence vocal emotion stimuli may be characterized by reduction in network integration and segregation. Our results generally showed reduced network integration and segregation in negative-valence conditions compared with the resting state. Previous studies have attempted to understand the underlying mechanism and investigate the relationship between task-specific and resting-state networks further.   compared the global network measures of a task-general and meta-analytic coactivation network to a group-averaged resting-state network and reported reduced clustering, reduced modularity and increased efficiency. Recently,   used binarized PC matrix for studying the change of brain network topology under seven different kinds of functional tasks, which showed significant increases in global efficiency in all functional tasks compared with resting state. Another specific study by   investigated the network topology during the semantic matching task and resting state using binarized correlation matrices. Their results showed reduced global efficiency, reduced normalized global efficiency, increased E  and increased nodal centrality.   used alphabet recognition tasks and discovered reduced normalized CC compared with that of resting state. Although the experimental designs and targeted network measures of these previous studies do not converge in details, a general tendency that we could summarize from these studies is that most task-related networks would exhibit increased efficiency—in contrast to our findings. This controversy may arise from experimental designs, pre-processing of graph theoretical analysis, computation of network measures and statistical comparison approaches. A further study is needed to clarify these effects of data processing. 


### Task-related alterations in FC 
  
Our results also showed altered interregional FC in several connections. For arousal stimuli, reduced FC was mostly found in those connections associated with the auditory network, mostly involving superior temporal gyrus (STG). This finding may suggest that the reduced FC centered to these regions could be a result of configuration switching between resting-state and task-positive networks. Several sub-regions within STG, e.g. primary auditory cortex and Wernicke’s area, are known to be responsible for processing auditory and language information. Functionally, STG is responsible for language processing, which may also contribute to the altered FC under task-related conditions ( ;  ). In our current results, the altered FC related to STG may reflect that the patterns of network topology are different between vocal emotion modulation and resting state. However, our results cannot fully explain the association between STG and vocal emotional processing. Other than STG, we also observed that the   and   in TPOmid.R under high-arousal condition were significantly lower than those under mid-arousal condition. Interestingly, previous studies have suggested the temporal pole was associated with the social and emotional processing, including face recognition and theory of mind ( ;  ). Although the association between the temporal pole and vocal emotional processing is not clear yet, we could speculate that the arousal levels of vocal emotion stimuli may alter the network topology and result in altered nodal network characteristics in temporal pole. For valence stimuli, significantly reduced COV-based interregional FC and mean intra-network FC was found in several connections within the visual network by comparing negative-valence to neutral-valence conditions—consistent with our findings in the nodal network topology, further supporting our hypothesis of cross-modal mental imagery altering the network topology in visual-associated regions. We should note that the alterations of averaged network measures in the well-known large-scale functional networks and mean inter-network/intra-network FCs were highly consistent with those observed by investigating individual ROIs, especially in the visual and sensorimotor networks. The observations among large-scale functional networks further solidified our findings in FCs, nodal and global network metrics. 


### Investigation on complementarity of network measures 
  
Since we incorporated a series of nodal and global network metrics that may be used to quantify similar network topological characteristics in theory, it was of great interest to explore the complementarity between these network metrics. How they complement each other to form a more concrete delineation of the overall brain network topology would be beneficial for our current study. Thus, we also analyzed the similarity between different nodal network metrics using correlation analysis and also compared these between-metric similarities from two different pre-processing procedures, i.e. OMSTs and sparsity thresholding (see   for details). Our results generally showed that the network metrics used to characterize the same topological attribute could be highly correlated even if they have different theoretical definitions. For example, E  was calculated based on the shortest path length and CC was based on triangles; however, these two metrics were highly correlated in our case. Although these metrics were highly correlated, E  revealed more between-condition differences than other metrics that also measured the functional segregation in this study. We could summarize that, in our study, the network metrics for characterizing the same topological attribute could still provide complementary information, e.g. sensitivity to differentiate subtle alterations between conditions, even if they were highly similar in their quantities. It would be beneficial if all metrics were calculated and included in providing more insights into the complex brain network architectures. 


### A comparison between PC- and COV-based FC 
  
We also investigated the influence of two kinds of FCs—PC and COV—on brain network topology. Interestingly, it was revealed that the analyses using these two FCs could provide non-redundant information for depicting the brain networks under different task-related and resting-state conditions. For nodal network measures, PC and COV reflected the influences of arousal and valence stimuli on brain network topology, respectively. For global network measures, the influences of both arousal and valence stimuli were only revealed by COV. For FC, PC revealed most of the alterations induced by arousal stimuli, whereas COV revealed most of the alterations induced by valence stimuli. By definition, assuming two independent variables X and Y, PC(X,Y) is equivalent to COV(X,Y) divided by the products of the variances of those two variables ( ). In other words, the calculation of COV considers both the signal amplitudes and variations, while PC is a dimensionless measure that decouples the effect of the signal variations. Therefore, PC and COV could reflect different aspects of functional dependency in principle and then result in non-redundant observations. 

Here, we give two scenarios where the observations of PC and COV may not converge. In some cases where the alteration of signal variances is irrelevant to the stimulation, COV may show a lower significance level than PC due to the inclusion of signal variances. In other cases where the alteration of signal variances is highly relevant to the stimulation, COV may show a higher significance level than PC. Considering the nature of definitions, we speculate that the network modulation under arousal stimuli is less relevant to the alteration of signal variations, while network modulation under valence stimuli is mostly contributed by the alteration of the amplitude of signal fluctuations. To date, choosing optimal FC measures for graph-theoretical analysis remains challenging. Our study demonstrates that the use of multiple FC measures may be a better approach to address the complex network and could provide complementary perspectives on the task-related reconfiguration of a network. 


### Limitations 
  
In this investigative study, we have shown that the different levels of emotional speech stimuli may alter or modulate the brain networks on either a nodal or global scale. Although we suggest that brain network analysis could have the potential to resolve the vocal-emotion-induced topological changes, several limitations must be carefully discussed. The first limitation may come from the cultural difference between the volunteers who rated the emotional scales in the IEMOCAP data set and the participants involved in this study. The cultural difference arising from native languages and environmental factors may play a major role in comprehending the emotional speech, which might be the major confounding factor in this exploratory study. The second limitation is the design of vocal emotional stimuli, in which we tried to mimic the real-world scenarios. However, this experimental design might be too complicated to rule out some other mental confounding factors. Considering both limitations, one should use the speech database with the same native language as that of the participants involved in the experiments to investigate better the effects of vocal emotional stimuli on brain network topology. Furthermore, the scenarios of the functional stimuli should be divided into several simplified sections so one could investigate each phenomenon separately. Additionally, it is also worth noting that the method used in this study assumes a static topology under a given type of stimuli. However, it is highly likely that such an assumption does not hold—for brains are dynamic systems. Notably, several studies have also investigated how functional networks change and evolve with time using dynamic FC ( ;  ).   also performed whole-brain dynamic connectivity analysis for studying the effects of emotional speech on dynamic changes of brain networks. It is highly likely that considering the dynamic nature of the brain network would provide a more valid analysis and allow for studying dynamic changes in brain states. However, some careful analysis design is required to apply high-level network analysis to a dynamic network. Furthermore, the emotional stimuli used in our study were attributed to a simple two-dimensional model (i.e. arousal and valence). However, it is also possible to extract emotion-related features directly from the stimuli ( ). In fact, it has been shown that emotion recognition using EEG signals can be facilitated by incorporating features extracted from the stimuli ( ;  ;  ). Therefore, we postulated that by incorporating sound features extracted from the speech stimuli, we could achieve a more comprehensive analysis of various aspects of emotions during the speech. 



## Conclusions 
  
In this study, we investigated the modulation of brain networks under emotional speech perception using high-level graph-theoretical network measures. With the use of OMSTs approach and Power-264 functional atlas, we discovered that brain network exhibits significantly altered network attributes at global, nodal and connectivity levels, especially under emotional speech with high arousal or negative valence. We also investigated the alterations of network metrics and FCs within/between large-scale functional networks and found that most of alterations were associated with negative valence. To the best of our knowledge, this is the first study employing a graph-theoretical analysis of emotional speech perception. Although this is predominantly an investigative study, we have gained crucial insights into how comprehending emotional speech modulates brain networks. Additionally, this study provides directions for high-level network analysis on emotional speech comprehension or possibly other types of brain functions. 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-9'>
<h2>9. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/18958158/' target='_blank'>18958158</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Neural Correlates of Enhanced Visual Short-Term Memory for Angry Faces: An fMRI Study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2008</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0003536</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/2568825/' target='_blank'>2568825</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study in healthy adults (N=35, mean age 29) using a social-related task: encoding and short-term memory for faces with emotional expressions (angry/happy/neutral), which is social cognition. The imaging analysis used whole-brain, random-effects ANCOVA with FDR correction and reports whole-brain clusters and Talairach coordinates (not ROI-only results). Participants were healthy, within the 18–60 age range, and no patient groups were involved. The paper is an original fMRI experiment (not a review/meta-analysis). Although ROI beta extractions were performed for some follow-ups, primary inference and reported results derive from whole-brain analyses. Therefore all inclusion criteria are met and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
## Background 
  
Fluid and effective social communication requires that both face identity and emotional expression information are encoded and maintained in visual short-term memory (VSTM) to enable a coherent, ongoing picture of the world and its players. This appears to be of particular evolutionary importance when confronted with potentially threatening displays of emotion - previous research has shown better VSTM for angry versus happy or neutral face identities. 


## Methodology/Principal Findings 
  
Using functional magnetic resonance imaging, here we investigated the neural correlates of this angry face benefit in VSTM. Participants were shown between one and four to-be-remembered angry, happy, or neutral faces, and after a short retention delay they stated whether a single probe face had been present or not in the previous display. All faces in any one display expressed the same emotion, and the task required memory for face identity. We find enhanced VSTM for angry face identities and describe the right hemisphere brain network underpinning this effect, which involves the globus pallidus, superior temporal sulcus, and frontal lobe. Increased activity in the globus pallidus was significantly correlated with the angry benefit in VSTM. Areas modulated by emotion were distinct from those modulated by memory load. 


## Conclusions/Significance 
  
Our results provide evidence for a key role of the basal ganglia as an interface between emotion and cognition, supported by a frontal, temporal, and occipital network. 

 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (35900 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Visual short-term memory (VSTM) is an active system that temporarily stores and updates information over a period of a few seconds. It is particularly useful for maintaining a constant and coherent percept of the world in the face of eye, head, and object motion. In contrast, long-term memory (LTM) is a system dedicated to storing information over hours, days, and even decades; it is essential for learning and developing knowledge and skills. 

Although it is well established that LTM is enhanced for images with an emotional, particularly negative, content  – , an effect thought to be driven by neural communication between LTM and limbic systems  , the question of whether information to be retained in VSTM is influenced by its emotional content, and which brain mechanisms might be involved, has received little attention and results are varied. One study found no effect of valence on STM for fearful versus neutral faces, nor for taboo versus neutral words  . Two studies using emotive images from the International Affective Picture System (IAPS) found an influence of valence on STM. In one, participants judged the relative emotional intensity (“higher” or “lower”) of two successively presented images that were matched for valence (positive or negative) and were separated by a 3 second retention interval  . Young participants were more likely to make accurate relativity judgments for negative compared to positive images (accuracy was based on whether judgments matched previously established ratings obtained from an independent group of young participants). The authors interpreted this to reflect enhanced STM for negative images, and report the opposite effect with older participants. However, their task was not a direct test of the effect of valence on STM for visual content per se. In a functional magnetic resonance imaging (fMRI) study, participants were required to state whether a positive, negative, or neutral image seen 11.5 seconds earlier was present or not in an array of nine valence-matched images  . Increased activity in dorsolateral prefrontal cortex (DLPFC) and decreased orbitofrontal cortex (OFC) activity was found for positive versus negative images, but these data are difficult to interpret because task accuracy during scanning did not show a difference in STM for positive (65%) versus negative (65%) images. The above studies, while interesting in measuring responses to emotional stimuli, provide little clear insight into whether visual information with an emotional content can influence VSTM and, if so, what brain mechanisms might be involved. [Note that because our aim is to measure the neural correlates of information retained in VSTM with an emotional versus neutral content, we do not review here studies of the effect of emotional distraction or induced mood state on VSTM for neutral stimuli.] 

Previous behavioural research of ours   has shown that VSTM for face identities is significantly enhanced when faces display an angry compared to a happy or neutral expression. We replicated this result a number of times and were able to eliminate several possible accounts of the effect. We showed that that the anger benefit for faces in VSTM was not due to low-level feature recognition: inverting the faces abolished the effect; a perceptual discrimination task in which participants stated whether two faces matched identity or not showed no difference in accuracy or reaction time between angry, happy, or neutral face conditions. We also showed that heightened physiological arousal is unlikely to underpin the effect: the presence of calming or energizing background music during the task did not differentially influence VSTM nor interact with emotional expression conditions, suggesting that enhanced VSTM for angry faces is valence-driven. Perceptual encoding limitations were excluded as an account because the angry benefit remained present when the original study time of 2000 ms was doubled. Finally, the effect was replicated using a different set of faces from another database that were also equated for expression intensity, providing evidence that enhanced VSTM for angry faces is not specific to the faces used, nor due to the potential for angry faces to be more intense in expression than happy or neutral faces. 

In the current study, we again used angry, happy, and neutral faces to investigate the neural correlates of VSTM for information with an emotional versus neutral content. Faces are well suited for this purpose because not only are they ecologically valid, they also allow the presentation of differently valenced emotional information in the same individual exemplars. This reduces variability of low-level featural information among different emotion conditions, a factor that may have confounded results of previous studies using IAPS pictures  . Another person's emotional facial expression can convey critical information about his/her internal mood state and, in turn, affect one's own behavioral decisions, e.g., whether to approach or avoid, or what manner of speech to adopt. Successful and appropriate face-to-face interactions depend not only on recognition of emotional expression, but often also require accurate face identification. Critically, our ability to select an appropriate social response in a timely and effective manner depends on our ability to identify who is expressing what emotion, and this information must be retained in memory for a period sufficient to develop an action plan. Thus, storage of face identity information in VSTM forms a crucial bridge between immediate encoding of emotionally charged information and execution of appropriate behavior. 

Here, during fMRI participants were required to memorize between one and four angry, happy, or neutral faces for 2,000 ms (the number of faces to be remembered is termed   face load  ), and one second later they were asked to report whether a single face probe matched in identity to one of the previous to-be-remembered faces or not ( ). All faces (at both encoding and retrieval) in any one trial displayed the same emotion, thus emotional expression of the to-be-remembered faces was task-irrelevant. Our aim was to specifically examine the neural correlates of the angry benefit for faces in VSTM and determine how emotion and memory systems in the brain might interact to produce this effect. By manipulating face load, we were also able to examine any interactions between load and expression conditions. We predicted that the angry face benefit in VSTM is likely to recruit an interplay of brain regions involved in emotion processing, such as the amygdala, basal ganglia, and insula  – , short-term memory, such as the prefrontal cortex  , and face processing, such as the fusiform gyrus   and superior temporal sulcus  . 
   Here is an example trial procedure (load 3 shown as illustration).  
Between one and four faces (all expressing either angry, happy, or neutral emotion) were shown for encoding for 2000 ms, followed by a 1000 ms blank retention/maintenance phase, and a 2000 ms retrieval phase in which participants stated whether a single probe face had been present or not in the previous display. All faces in any one trial (i.e., at encoding and retrieval) displayed the same emotion. A jittered inter-trial interval (ITI) of between 4000 ms and 6500 ms separated each trial. 
  

## Methods 
  
### Participants 
  
Thirty five right-handed healthy volunteers (mean age 29 years; 15females) from the student and community panels in Bangor participated in return for £20. Subjects reported no history of neurological or psychiatric disorder, had normal or corrected to normal vision, and provided informed written consent prior to participation. The study was approved by the School's ethics committee in Bangor. 


### Stimuli 
  
Greyscale face images of six adult males each expressing three emotions (angry, happy, and neutral) were used  . Each image subtended approximately 1.43°×1.36°. Scrambled greyscale face images, selected at random from a set of eight different scrambled images, were used to fill memory display locations on trials in which fewer than four faces were presented. 


### Experimental Procedure 
  
Participants were oriented to the centre of the computer screen by a small fixation cross presented for 1,000 ms and instructed to maintain fixation throughout each session in order to minimize eye movement artefacts in the functional data. To signal the start of a trial, the fixation cross increased in size for 1,000 ms, after which it returned to its original size for another 1,000 ms. On each trial, between one and four faces, each expressing the same emotion (angry, happy, or neutral) were presented for 2,000 ms in a 2×2 memory matrix with fixation at the centre. The centre of each image within the matrix was positioned at a visual angle of approximately 1.27° from fixation to ensure that the faces display was foveal, and thus minimize eye movements. Previous research has established that 2,000 ms is sufficient time to encode four faces  ,  . On trials in which fewer than four faces were presented, all other matrix locations were occupied by a scrambled face. Face locations were randomised within the matrix. After a 1,000 ms blank retention interval during which only the fixation cross was present, a single face probe (expressing the same emotion as the preceding matrix) was displayed in the centre of the screen for 2,000 ms. Participants were required to state, within the 2,000 ms single probe presentation duration, whether the probe person had been present or not in the immediately preceding display (50% probe present). The task involved an identity decision, thus emotional expression was irrelevant to the task. Participants used their right hand to respond “yes” or “no” using a simple button press. Feedback was not provided. A jittered fixation inter-trial interval (ITI) of between 4,000 and 6,500 ms separated each trial ( ). 

Sixteen experimental trials were presented for each load (1,2,3,4) in each emotion condition (angry, happy, neutral) in a pseudo-random order, resulting in 192 trials in total (event-related design). In order to minimize subject fatigue, the experiment was separated into four separate scanning blocks of 48 trials each, within a single scanning session. Each block lasted approximately 11 minutes. Before the main experiment began, participants were given a short practice session outside the scanner. 


### Data Acquisition 
  
Behavioural data were acquired with a 14-inch Dell Latitude D610 laptop (32-bit true colour; resolution 1280×1024 pixels). The tasks were generated by E-Prime software  . fMRI data were acquired with a Philips 1.5T MRI scanner with a SENSE parallel head coil. We used a gradient echo echoplanar sequence sensitive to the blood oxygen dependent (BOLD) signal (TR = 2,000 ms; TE = 40 ms; matrix size = 96×96; FOV = 256×256 mm ; voxel size = 3×3×3 mm ; 90° flip angle; 20 axial slices). Two dummy volumes were acquired before each scan block to reduce possible T1 saturation effects. During the VSTM faces task, the fMRI sequence was synchronized with the fixation cross at the start of each trial (see  ). Anatomical data was acquired with a high resolution T1-weighted three-dimensional (3D) volume (1×1×1 mm ), and used for coregistration of functional data. 


### Data Analysis 
  
#### Behavioural Data Analysis 
  
False alarm rates in all emotional expression conditions varied significantly as a function of face load, so we converted hits and false alarms into dprime (d') scores in order to provide a more sensitive measure of signal detection. d' is the z-normalised hit rate (probability of ‘yes’ responses when the probe was present) minus the z-normalised false alarm rate (probability of ‘yes’ responses when the probe was absent) [d' =  Hit Rate –  False Alarm Rate]. 


#### FMRI Data Analysis 
  
Functional data were preprocessed and analysed using the BrainVoyager 1.79 software. We applied slice scan time correction using sinc interpolation and ascending slice scanning order, 3D motion correction using trilinear interpolation, spatial smoothing (8 mm Gaussian kernel), and a temporal high pass filter (3 cycles per time course). Three-D anatomical scans were transformed into Talairach space  , the parameters of which were applied to the coregistered functional data. 

All but one subject completed all four VSTM task runs (one subject completed only three runs due to technical scanning problems), and runs that were unsuitable for analysis were excluded from analysis (two runs in each of two subjects revealed head movements greater than 5 mm). In total, 135 z-normalised volume time courses were entered into a whole brain, random effects analysis of covariance (ANCOVA). Motion-corrected covariates were included in the model in order to optimize the elimination of task-correlated motion artifacts and maximize sensitivity to true activations  , and to reduce inter- and intra-subject variability  . Functional data from all phases of the VSTM task (excluding the ITI) were entered into the analysis model: no distinctions were made between encoding, maintenance, or retrieval phases. In all analyses, regions of activation were determined using the False Discovery Rate (FDR) significance threshold of <.05. To examine emotional expression effects, we computed a repeated-measures ANCOVA (three within-factor levels: angry, happy, neutral) to assess the main effect of emotion, and we also computed specific emotion contrasts (angry - neutral, angry - happy, happy - neutral). In each identified emotion cluster, we conducted random effects GLM region of interest (ROI) analyses to extract beta values that were subsequently applied to statistical comparisons between emotional expression conditions, and correlated with VSTM task performance values. VSTM load effects were examined by contrasting loads 4, 3, and 2 with load 1. A repeated-measures ANCOVA with emotion and load as within factors assessed whether an emotion by load interaction was present at the whole brain level. 


#### Correlation with behavioural data 
  
To examine whether there were any correlations between the magnitude of the angry face effect and brain activity levels, we used the mean behavioural dprime score across all face loads for each emotional expression condition to calculate difference scores for angry minus happy and angry minus neutral face contrasts (based on the angry face advantage observed in the behavioural results). These performance difference scores were correlated with related beta difference scores extracted from emotion-sensitive brain areas. To examine whether there were any correlations between STM capacity and brain activity levels, we calculated Cowan's K capacity estimates at each load [load*(hits – false alarms)]  , averaged across emotion conditions, with related beta values extracted from load-sensitive brain areas. K and beta values were concatenated across all loads for this statistical comparison. Pearson's correlation coefficient (r ) was used in all cases. 




## Results 
  
### Behavioural Results 
  
We conducted an emotion (angry, happy, neutral) by load (1, 2, 3, 4) repeated-measures ANOVA on the behavioural data, expressed in d' values. Consistent with our previous findings  , we found that VSTM performance was significantly modulated by emotional expression,   F  (2, 68) = 3.17,   p   = .048, and that angry faces were significantly better remembered than happy faces (  p  <.05) ( ). It is clear from   that the effect of emotional expression appears most pronounced at face loads 2 and 3, likely due to the fact that we can only store about two face identities in VSTM at any one time  . When only face loads 2 and 3 are analysed, the main effect of emotion becomes more significant (  F  (2, 16) = 4.01,   p   = .02) and the difference between angry and neutral faces also reaches significance (  p  <.05). A significant main effect of face load was observed,   F  (3,102) = 120.38,   p  <.001, but its interaction with emotional expression was not significant,   F  (6, 204)<1.0. 
   Behavioural performance on angry, happy, and neutral trials for all four face loads are displayed as d' (dprime) values.  
A maximum d' value of 4.66 indicates 100% performance, while a d' value of zero indicates performance at chance (50%). Participants performed significantly better on the VSTM task when the identities of angry faces were to be remembered, compared to happy or neutral faces. VSTM performance declined as face load increased for all emotional expression conditions. Bars represent±1 standard error. 
  

### Functional Imaging Results 
  
#### Emotion Effects 
  
Using whole-brain analysis of variance (ANOVA), and an FDR significance threshold of   p  <.05, we found a significant main effect of emotion in three areas of the right hemisphere: superior temporal sulcus (STS), prefrontal cortex (PFC) along the anterior inferior frontal sulcus (IFS), and globus pallidus internus (GPi) ( ). Talairach coordinates are provided in  . There was no main effect of emotion in the left hemisphere. ROI analyses revealed that the main effect of emotion in the STS, PFC, and GPi was driven by significantly enhanced blood oxygen level dependent (BOLD) responses to angry faces (in all regions: angry vs. happy,   p  <.001; angry vs. neutral,   p  <.001) ( ). There were no significant differences between happy and neutral face activations in any of these regions (  p  >.54 in all cases). 
  
(A) Three coronal brain slices show modulation of brain activity by emotional expression of faces in the VSTM task in the superior temporal sulcus (STS), prefrontal cortex (PFC) along the inferior frontal sulcus (IFS), and globus pallidus internus (GPi), all in the right hemisphere. (B) Beta values for each emotion and face load condition are plotted for the STS, PFC, and GPi. Activity is greater for angry vs. happy and neutral face expression conditions in all three brain regions. Bars represent±1 standard error. 
     Talairach coordinates and voxel cluster size values for the main effect of emotion (FDR<.05).      
The angry minus neutral functional contrast showed the same pattern of activation as the main effect of emotion (higher activity for angry than neutral faces in rSTS, rPFC, and rGPi), but in addition this contrast revealed significantly greater angry vs. neutral activity in bilateral fusiform gyrus (  p  <.001 in both cases) ( ). In the right fusiform, analysis of extracted beta values also revealed significantly greater activation for angry vs. happy faces,   p   = .02. There were no load effects in these regions. At whole-brain level, the angry minus happy functional contrast similarly revealed rSTS activity (higher for angry) but did not show any additional regions of activation. No regions showed greater activation for happy vs. neutral faces. Talairach coordinates for the specific emotion contrasts are provided in  . 
   Coronal view shows bilateral fusiform activity obtained from the angry minus neutral contrast (regions outlined by black squares).  
Activity is greater for angry compared to neutral faces. Bars represent±1 standard error. 
     Talairach coordinates and voxel cluster size values for specific emotion contrasts (FDR<.05).        

#### Correlation Between Behavioral and Functional data for Emotion Effects 
  
To test whether higher activation for angry faces reflected a generalized increase in response to angry faces or associated arousal levels, or whether it might represent the very brain mechanism that brings about the angry face benefit in VSTM, we investigated the relationship between brain activity and behavioral data. We correlated the behavioral scores (difference in d') for the angry minus happy and angry minus neutral differences with the corresponding beta value differences in each emotion-sensitive region. In GPi, behavioural difference scores significantly correlated with related beta difference scores in the angry-happy contrast,   r   = .44,   p   = .01 ( ), and marginally correlated with related beta difference scores in the angry-neutral contrast,   r   = .32,   p   = .06 ( ). Superior VSTM for angry faces was thus correlated with enhanced activity in the GPi, suggesting a key role for this region in the angry face benefit. There were no significant correlations between behavioural scores and beta values in STS, PFC, or fusiform regions. Because the behavioural angry vs. neutral benefit was driven by the differences at loads 2 and 3, we re-ran these correlations using just loads 2 and 3. We replicated the angry-neutral contrast marginal correlation between behavioural and brain data in the GPi (  r   = .33,   p   = .06), and additionally found a marginally significant angry-neutral contrast correlation in the right FFA (  r   = .29,   p   = .09) suggesting perhaps some role of this face processing region in the angry vs. neutral benefit. Correlations in all other emotion-sensitive regions yielded a   p  -value greater than .10. We also correlated these behavioural data with related activity in load-sensitive areas and found no significant results. 
   Better performance on the VSTM task for angry versus happy faces (A), and for angry versus neutral faces (B), was correlated with greater activity in the GPi.    

#### Load Effects 
  
We examined load effects by contrasting loads 4, 3, and 2 with load 1, with the view that higher activity at loads greater than 1 indicates a greater draw on resources used to encode and retain multiple face identities in VSTM. Several areas in bilateral dorsolateral, ventrolateral, and medial prefrontal cortex (DLPFC, VLPFC, MPFC), frontal eye field (FEF), inferior parietal sulcus (IPS), fusiform gyrus, and occipital cortex showed significantly higher activation when multiple faces were to be remembered compared to one face in both the right and left hemispheres ( ). These results conform to previous studies of face load in STM  . Interestingly, we replicated the dissociation of load effects between parietal and prefrontal areas described previously  , with activity in parietal areas peaking at load 3 and prefrontal activity rising further towards load 4 in a monotonic fashion ( ). This dissociation was supported by a significant load by region interaction between beta values in right parietal cortex and right PFC,   F  (3, 102) = 16.05,   p  <.001. Talairach coordinates for the load contrasts are provided in  . 
  
(A) Face loads 4 (blue), 3 (green), and 2 (red) were contrasted with face load 1. Several regions of the PFC, the frontal eye fields (FEF), inferior parietal sulcus (IPS), fusiform gyrus, and occipital cortex, in both left and right hemispheres, showed greater activity when multiple faces were to be remembered compared to just one face. Brain regions modulated by emotion in the right hemisphere (pink = emotion main effect; white = angry minus neutral contrast; brown = angry minus happy contrast) are overlain to illustrate the anatomical distinction between emotional expression and face load effects. Some anatomical landmarks are provided to aid navigation: superior frontal sulcus (SFS); inferior frontal sulcus (IFS); silvian fissure (SF); inferior parietal sulcus (IPS); occipito-temporal sulcus (OTS). (B) Beta values from each load condition (averaged across emotions) illustrate the contrast between a monotonic increase of activity with load in right PFC (x = 41, y = 29, z = 26) and peaked activation at load 3 in right parietal cortex (x = 18, y = −69, z = 43). Bars represent±1 standard error. 
     Talairach coordinates and voxel cluster size values for face loads 4 minus 1, 3 minus 1, and 2 minus 1 contrasts (FDR<.05).      
The spatial dissociation of emotion and face load effects on brain activation is particularly striking. Although both emotion and load effects were observed in parts of the right PFC, these areas did not anatomically overlap ( ). Similarly, the load effect in bilateral fusiform gyrus was anatomically different to fusiform activity modulated by the angry minus neutral contrast (the emotion region lies more anterior to the load region). Furthermore, a whole brain statistical analysis did not reveal any areas that showed an interaction between emotion and load. 


#### Correlation Between Behavioral and Functional data for Load Effects 
  
We also examined correlations between STM capacity estimates, as indexed by Cowan's K, and brain activation levels in load-sensitive areas. K capacity estimates (collapsed across emotion conditions) were: load 1 = 0.93 (  SE   = .02  )  ; load 2 = 1.48 (  SE   = .07); load 3 = 1.70 (  SE   = .11); load 4 = 1.71 (  SE   = .13). Significant or marginally significant positive correlations were found in all regions except left VLPFC and right fusiform ( ): as the number of faces stored in STM (K) increased, activity also increased. We correlated these K data with load activity in emotion-sensitive areas and found no significant results, confirming the spatial dissociation between emotion and load effects. 
   Correlation between STM capacity estimates (K) and related beta values in load-sensitive regions. r  values are provided with   p   values in brackets.      



## Discussion 
  
Our behavioral results show that VSTM is significantly enhanced for face identities when faces display an angry compared to a happy or neutral expression, replicating previous findings  . It has been suggested that effects of emotion on memory require time to emerge, allowing effective consolidation of such memories  . Yet here, as in our previous study, we show that the effects of emotion on memory can be more immediate – emotional expression can influence visual short-term memory for faces. 

In the present study, a network of emotion-sensitive areas comprised STS, PFC, and GPi, all in the right hemisphere, in keeping with the view that the right hemisphere is more involved in the processing and generation of emotions and affect than the left  ,  . The specific areas all fit into current models of emotion processing. The STS has been identified as a key area for the extraction of emotional information from faces  ,  ,   and more generally for the evaluation of others' intentions  . The STS has also been specifically implicated in processing various forms of anger  . Regions of the PFC have been implicated in experience   and observation   of negative mood, and higher activity in response to negative than positive images has been evidenced in regions of the right ventrolateral PFC specifically  . Integration of emotional state and STM processes in regions of bilateral PFC has also been reported  . The GPi, a subcortical structure, is a major part of the basal ganglia which, beyond their function in the extrapyramidal motor circuit, are involved in a variety of cognitive functions including emotion processing  . 

What is striking about the present findings is that the right STS, PFC, and GPi were specifically recruited in the service of VSTM for angry faces. The GPi seems to be the main region responsible for enhanced VSTM for angry faces, and this finding concurs with a recent study that showed a positive correlation between increased globus pallidus activity and increased STM capacity for simple objects  . This study also outlined the role of the globus pallidus as an attentional filter that allows only relevant information access to VSTM. It is possible in our study that enhanced GPi activity to angry faces in VSTM might reflect heightened attention to angry faces, driven by the saliency of potential threat. Threat (anger and fear) expressions have frequently been reported as especially good at capturing attention  – , even when task-irrelevant  . However, these studies involve the capture of attention of a single angry face in a display of differently valenced faces, while in our study all faces in any one VSTM trial displayed the same emotion, thus removing any such competition for attention between different expressions. Furthermore, there is also evidence of rapid attentional orienting to happy faces   and more generally to stimuli with high emotional relevance  . Perhaps attention was heightened in general during angry face trials, in order to facilitate encoding and maintenance of person identity information in VSTM in the context of potential threat. 

The prominent role of the GPi, which was the key area where neural activity was significantly correlated with behavioural performance, is in keeping with recent findings on the role of dopamine in recognition of angry expression. Selective impairment of angry face perception has been linked to: lack of dopamine in Parkinson's disease, which affects the information processing capacity of the GP  ,  ; treatment with antidopaminergic drugs  ; and deep brain stimulation of the subthalamic nucleus  , which is directly connected with the limbic part of the GP  . The present study shows that the GPi, one of the main relay stations of the basal ganglia, is not only responsive to emotional stimuli but aids their processing in a way that allows the effective handling of evolutionarily salient information. 

A specific angry vs. neutral contrast also revealed a role for the fusiform gyrus - a face-selective area   - in the angry benefit, wherein BOLD activity was higher for angry than neutral faces bilaterally and for angry than happy faces in the right hemisphere. Modulation of activity in the fusiform region by facial expression has been reported previously during passive viewing, identity matching, and emotion recognition tasks. For example, there is evidence that fearful  – , happy  ,  , and angry faces   elicit greater fusiform activity than neutral faces. However, our study is the first to report modulation of the fusiform gyrus by facial expression during a VSTM task. 

Traditionally, the amygdala has been implicated in the processing of emotional stimuli and in the long-term retention of emotional events or images wherein activity is often suggested to reflect heightened physiological arousal, which is thought to mediate emotional learning via direct and indirect neural pathways subserving short and long-term memory  . In our study, however, we did not find significant influence of the amygdala on the enhancement of VSTM for angry faces. There are a couple of explanations for this. First, the amygdala does not respond selectively to negative emotion: studies have shown activation in response to images of happy and neutral faces  . Thus, it is possible that the emotion contrasts computed here did not reveal modulation of the amygdala if all three emotions recruited this region to the same degree. Second, the angry face effect in VSTM is likely driven by image valence (i.e., negativity) rather than physiological arousal (i.e., excitability). In our previous behavioural study   we showed that music-induced arousal states did not modulate VSTM performance in general nor interact with expression conditions. We also found that arousal ratings, as measured by the Self-Assessment Manikin (SAM) rating scale  , did not differ between angry and happy faces. Our behavioural data thus make a general arousal account of enhanced VSTM for angry versus happy faces less likely. 

With regard to load modulated brain regions, higher activity in the fusiform gyrus can be explained by the larger number of faces in the memory encoding display, and may also reflect the involvement of this area in VSTM processes  . The activation increase in parietal and prefrontal areas reflects their role in supporting the attentional, encoding, and storage requirements of higher memory loads  ,  . Importantly, the bilateral fusiform regions that displayed load effects (e.g., load 4 – load 1; LH: x = −36, y = −66, z = −19; RH: x = 36, y = −66, z = −19) were anatomically distinct from the more anterior fusiform regions that displayed an angry face benefit (LH: x = −32, y = −42, z = −12; RH: x = 43, y = −43, z = −16). Face processing regions in the occipito-temporal cortex have been segregated previously into two distinct regions, the fusiform face area (FFA) and the occipital face area (OFA), the former located more anterior to the latter  . Our Talairach coordinates for the emotion- and load-affected fusiform regions correspond nicely with reported right hemisphere FFA and OFA coordinates respectively (FFA: x = 39, y = −44, z = −18; OFA: x = 39, y = −64, z = −20). None of the other load-related areas showed an additional modulation of their activity by emotional expression. This suggests that the enhancement of VSTM capacity by the angry expression operates mainly through the recruitment of emotion and face processing networks rather than through recruitment of additional neurons in the classical fronto-parietal STM network. The positive correlation between capacity estimates (K) and brain activation levels in most load-sensitive regions in the occipital, temporal, parietal, and frontal cortices, reflecting increased activity as the number of stored faces increased, suggests that activity in both low-level perceptual and higher-level cognitive areas is modulated by the amount of facial information stored in STM. 

We propose a new neural mechanism that supports the angry face benefit in VSTM by facilitating processing and extending memory capabilities. Studies have reported several areas of the fronto-parietal STM network that pose a bottleneck for memory storage at high loads because they cannot respond by further increasing their levels of activity  ,  ,  . Our study suggests that VSTM for faces is not only supported by the recruitment of areas that are modulated by load, but also by areas that respond categorically and automatically to the presence of a certain type of stimulus content, in this case, emotion. In the present study, enhanced VSTM capacity for angry faces would thus have been supported by communication between emotion-sensitive areas (STS, IFS, GPi, and FFA) and face identification and VSTM areas (PFC, IPS, OFA). 

Our findings also provide further perspective to the debate on whether or not there is independence between face identification and emotional expression decoding processes. While some studies have indicated dissociable neural representations for identity processing in the fusiform gyrus and facial expression processing in the anterior STS  ,  , others suggest that neural circuits underpinning identity and expression processes overlap  ,  . We show that, in VSTM at least, the impact of (angry) emotional expression on face identification tends not to be achieved by multi-functionality of one region but by communication between different process-specific regions responsive to face expression or load. The dissociation between anger and load effects in anterior (FFA) and posterior (OFA) regions of the fusiform gyrus respectively is a novel finding, and perhaps suggests a more complex, fine-grained functional organisation of this region in supporting both expression and face identification processes. 

Finally, our discovery of the pivotal role of the GPi at the interface between emotion and cognition may have profound implications for clinical neuropsychiatry. Deficits of social cognition, such as extraction of meaning from facial expressions, may be core elements of the psychopathology of schizophrenia and mood disorders. Whether these are linked to changes in the basal ganglia will have to be explored in future research. The basal ganglia also are the main target of deep brain stimulation for movement disorders and increasingly also for behavioural disorders, and a better understanding of their non-motor functions would be of great clinical importance. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-10'>
<h2>10. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22062191/' target='_blank'>22062191</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Autism spectrum traits predict the neural response to eye gaze in typical individuals</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Neuroimage</p>
<p><strong>Publication Year:</strong> 2012</p>
<p><strong>DOI:</strong> 10.1016/j.neuroimage.2011.10.075</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3315678/' target='_blank'>3315678</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study in healthy adult participants (N=18; ages 18–30) performing a social-related task (gaze perception/mentalizing). The authors report whole-brain second-level analyses (AQ regressor) with whole-brain FDR-corrected results (p<0.05) identifying clusters in pSTS, TPJ, amygdala, IPS, etc. Participants with neurological/psychiatric disorders were excluded. The paper is an original empirical fMRI study (not a review/meta-analysis). Although supplementary ROI analyses are reported, the primary inferential statistics reported are whole-brain analyses, so the study meets all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.98</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Autism Spectrum Disorders (ASD) are neurodevelopmental disorders characterised by impaired social interaction and communication, restricted interests and repetitive behaviours. The severity of these characteristics are posited to lie on a continuum extending into the typical population, and typical adults' performance on behavioural tasks that are impaired in ASD is correlated with the extent to which they display autistic traits (as measured by Autism Spectrum Quotient, AQ). Individuals with ASD also show structural and functional differences in brain regions involved in social perception. Here we show that variation in AQ in typically developing individuals is associated with altered brain activity in the neural circuit for social attention perception while viewing others' eye gaze. In an fMRI experiment, participants viewed faces looking at variable or constant directions. In control conditions, only the eye region was presented or the heads were shown with eyes closed but oriented at variable or constant directions. The response to faces with variable vs. constant eye gaze direction was associated with AQ scores in a number of regions (posterior superior temporal sulcus, intraparietal sulcus, temporoparietal junction, amygdala, and MT/V5) of the brain network for social attention perception. No such effect was observed for heads with eyes closed or when only the eyes were presented. The results demonstrate a relationship between neurophysiology and autism spectrum traits in the typical (non-ASD) population and suggest that changes in the functioning of the neural circuit for social attention perception is associated with an extended autism spectrum in the typical population. 
   Highlights  
► Autistic spectrum might extend to typically developing (TD) individuals. ► We studied TD individuals with varying Autism Spectrum Quotient (AQ). ► AQ correlated with BOLD response to viewing variable vs. constant eye gaze. ► AQ did not correlate with response to directional control stimuli. ► Neurophysiology and autism spectrum traits are associated in non-AS individuals. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (30795 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Autism spectrum disorders (ASD) are characterized by abnormal social interaction and communication, severely restricted interests and repetitive behaviour. ASD have a range of clinical phenotypes from mild to severe, however an even wider continuum of social-communicative ability has been proposed extending into the general or typical population ( ). Initial support comes from studies demonstrating that the degree of autistic traits measured by Autism Spectrum Quotient (AQ;  ), in both ASD and typical populations, is related to performance on behavioural tasks that show impairments in ASD, including self-focussed attention ( ), the ability to draw mentalistic inferences from the eyes ( ), and attentional cueing from eye gaze ( ). However, stronger evidence for a continuum extending into the typical population would involve a demonstration that the neural response to these sorts of social tasks or stimuli is related to typical participants' scores on the AQ. 

Neuroimaging has shown structural and functional impairments in ASD in ‘social’ brain regions involved in processing goal-directed actions and biological motion (superior temporal sulcus, STS), theory of mind (medial prefrontal cortex; mPFC and temporo-parietal junction; TPJ), and emotion (amygdala) (see reviews in  ). A number of these areas, together with components of the attention system, are recruited during gaze perception ( ), and we will refer to them as the ‘social attention’ network. Since individuals with ASD also show an abnormal neural response to gaze cues ( ), gaze perception provides a well-grounded model for studying neurophysiological correlates of the autistic spectrum in the general population. Our recent work in typical participants showing that individual differences in AQ predict changes in the structure and function of the posterior STS (pSTS), a central component of the social attention network, provides further reason to predict that a relationship between AQ and the social attention network might be found ( ). Specifically, this study found a reduction in white matter in pSTS of individuals with higher AQ scores. This was accompanied by an increased task-independent deactivation in high-AQ subjects, akin to ‘resting state’ activity, in the same area of pSTS. Here we investigate whether the BOLD response in the pSTS region, and wider components of the social attention network with which it is connected ( ), show a significant relationship with AQ in response to viewing gaze stimuli. This would provide the first direct evidence that individual variation in autism spectrum traits in typical participants impact on the neural correlates of social processing. We addressed this in the context of a functional magnetic resonance imaging (fMRI) study. 

Participants viewed epochs of faces gazing in ‘variable’ directions (i.e., left, direct, and right) or a constant direction (e.g., all left), implying rapid changes in their focus of attention or interest, or no change, respectively ( ). A second, control condition comprised ‘variable’ and ‘constant’ epochs of oriented heads with eyes closed, thus physical direction was again variable or constant but without concomitant changes in the faces' focus of attention and interest. ASD is known to impact primarily on the ability to draw mental inferences from social attention cues (e.g., that a person is   interested   in something to their left) rather than discrimination of their perceived physical direction ( ). Consequently, an effect of AQ on the social attention network was predicted to be most apparent for a comparison of the variable versus constant gaze conditions because mental inferences regarding the faces' should be greater for the rapidly changing foci of interest conveyed by the variable gaze condition relative to the constant gaze condition in which the focus of interest remained fixed. In contrast, we predicted that an effect of AQ should be absent for a comparison of the variable versus constant head conditions because heads with eyes closed convey directional information only. 

Our study also included a third ‘Eyes only’ condition in which gaze was again variable or constant but only the eyes were visible. For this condition we predicted a reduced or absent relationship with AQ for a comparison of the variable and constant conditions since previous research has shown that perception of gaze direction, or gaze following, is heavily influenced by the orientation of the head. For example, significant gaze cueing to the left (or right) has been reported using gaze cues in which the heads are rotated to the left (or right) and the gaze directed towards the observer ( ). Moreover, these effects were significantly larger than those observed using leftward (or rightward) oriented heads with their gaze oriented in the same direction as the heads. This suggests that the cueing effect is not dependent on the direction of the gaze alone, but is contingent on directional cues conveyed by the head   and   eyes. 


## Materials and methods 
  
### Participants 
  
Eighteen right-handed typical, healthy volunteers (4 males; aged 18 to 30 years; mean age = 24 years) with normal or corrected to normal vision participated in the study in return for payment. Individuals with a history of neurological or psychiatric disease or currently taking medication affecting the central nervous system were excluded. All provided written informed consent as a part of a protocol approved by the Suffolk Research Ethics Committee. Participants completed the AQ before scanning. This questionnaire contains 50 questions measuring the extent of autism spectrum characteristics, and has good test–retest reliability and internal consistency ( ). 


### Design and procedure 
  
Stimuli and design are summarized in  . The stimuli were prepared from 10 computer-generated faces (5 males and 5 females). Participants were shown three types of facial stimuli. A ‘Gaze’ condition comprised full-face views of faces with eyes oriented 25° left (L), 0° (direct), or 25° right (R). In a second ‘Heads’ condition, heads with eyes closed were oriented 25°L, 0°, or 25°R. In a third, ‘Eyes only’ condition, the gaze was again oriented 25°L, 0°, or 25°R, however, the majority of the head was masked leaving only the eyes visible. The facial stimuli were presented in 15 s epochs containing six presentations of one of the three facial stimulus types. The epochs were divided into two further conditions — ‘variable’ and ‘constant’. For example, in the ‘constant’ condition for the Gaze stimuli, all faces displayed the same gaze direction (i.e. all 25°L, all 0° or all 25°R), whereas the variable condition comprised continually changing gaze directions (i.e. 25°L, 0° and 25°R in random order). Similarly, the variable and constant conditions for the Heads and Eyes-only stimuli showed different or repeated head and gaze orientations. 

Each facial stimulus was presented for 2 s, followed by a 500 ms blank screen to prevent apparent motion. Consecutive faces never showed the same identity. The task was to categorize the gender of each face. Seven epochs of each category were presented. The order of epochs was fixed for each participant (e.g. gaze, heads, eyes-only, gaze …) counterbalanced across participants. The face epochs were interleaved with 10 s epochs of house images. This helped to reduce activation in the gaze network between face conditions and acted as a baseline condition. Note that houses were used in preference to a fixation (rest) condition because activation at rest varies between individuals with Autism and typical controls in brain areas associated with social processing, and is correlated with AQ in typical participants ( ). To reduce task switching, participants were also asked to categorize the gender (‘masculine’ vs. ‘feminine’) of the house stimuli. Pilot testing showed that participants were readily able to categorise houses with these labels. The total task duration was 33 min and 50 s. The stimuli were presented via an angled mirror above the participants' eyes. The mirror reflected images back-projected onto a translucent screen in the bore of the magnet behind the participants' head. All participants practised the task outside the scanner prior to the experiment. 


### Image acquisition and preprocessing 
  
MR imaging was performed with a 3-Tesla Tim Trio Magnetic Resonance Imaging scanner (Siemens, Germany) with a head coil gradient set at the MRC Cognition and Brain Sciences Unit. Whole-brain data were acquired with an echo-planar T2*-weighted (EPI) imaging sequence, sensitive to the blood–oxygen-level-dependent (BOLD) signal contrast (40 oblique slices, 3 mm slice thickness; TR = 2424 ms; TE = 30 ms; flip angle = 78°; FOV 192 mm; voxel size = 3 × 3 × 3 mm). The first 3 volumes were discarded to allow for equilibration effects. T1-weighted structural images were acquired at a resolution of 1 × 1 × 1 mm. Data were preprocessed and analyzed using SPM5 software (  www.fil.ion.ucl.ac.uk/spm/  ). The EPI images were sinc interpolated in time to correct for slice time differences and realigned to the first scan by rigid body transformations to correct for head movements. EPI and structural images were coregistered and normalized to the T1 standard template in MNI space (Montreal Neurological Institute (MNI) — International Consortium for Brain mapping) using linear and non-linear transformations, and smoothed with a Gaussian kernel of FWHM 8-mm. 


### Analysis of regional effects 
  
A random effects model was implemented using a two-stage process, of within (first level) and between (second level) subjects modelling, in turn. This random-effects analysis assessed effects on the basis of inter-subject variance and thus allowed inferences about the population that the participants were drawn from. For each participant we used a GLM to assess regionally specific effects of task parameters on BOLD indices of activation. The model included two experimental factors — stimulus type (Gaze, Heads, and Eyes-only) and presentation format (variable vs. constant); effects of no interest (realignment parameters) were also included to account for motion-related variance. Low-frequency signal drift was removed using a high-pass filter (cutoff 128 s) and AR(1) modelling of temporal autocorrelations was applied. 

The individual contrast images were generated using the following contrasts: i) variable versus constant gaze, ii) variable vs. constant heads, and iii) variable vs. constant eyes-only. The second level analyses used these contrast images in new GLMs with AQ as a regressor (plus a constant term), from which we generated statistical images, i.e. SPM-t maps, of voxels showing positive or negative relationships with AQ. With balanced designs at the first level (i.e. similar events for each subject, in similar numbers) this second level analysis closely approximates a true mixed effects design, with both within and between subject variance. A recent meta-analysis identified that perception of others' gaze engages a network of regions comprising the pSTS/TPJ, fronto-parietal attention system, amygdala, and dorsal medial prefrontal cortex ( ). The relationship between AQ and activation in this network was assessed with a threshold of p < 0.05 whole-brain FDR correction and minimum cluster size of 20 voxels. 



## Results 
  
### Behavioural data 
  
The distribution of the AQ scores was as follows: range = 7–33,   M   = 16.80,   SD   = 7.60. The mean accuracy for gender classification of faces was high (86%) and exceeded chance level (50%) for all task conditions,   p  s < 0.05. However, accuracy varied slightly across task conditions,   F  (2,34) = 5.50,   p   < 0.01, η  = 0.24 (  M   = 91%,   M   = 81%,   M   = 88%). As would be expected, accuracy for eyes-only condition was lower than that for the gaze (  p   < 0.01) or head (  p   < 0.01) conditions, for which the full face was visible; the gaze and head conditions did not significantly differ (  p   > 0.05). Median latencies for correct responses were also influenced by condition,   F  (2,34) = 34.48,   p   < 0.001, η  = 0.67 (  M   = 612 ms,   M   = 774 ms,   M   = 613 ms). Latency for eyes-only condition was longer than that for the gaze (  p   < 0.01) or head (  p   < 0.01) conditions, with no differences between the latter two conditions (  p   > 0.05). Neither the accuracy nor the response latency correlated with the AQ scores,   r  s < 0.3,   p  s > 0.4. Accuracy and RTs were not analyzed for the house trials because responses could not be categorised as correct and incorrect. 


### fMRI data 
  
The second-level contrasts for variable vs. constant gaze, variable vs. constant heads and variable vs. constant eyes-only (or vice versa) did not yield any significant effects. Consistent with our hypothesis, however, the variable vs. constant gaze comparison yielded significant positive correlations with the AQ ( ) in a number of regions of the gaze perception network, including right pSTS (50, − 50, 18,   T   = 4.38), intraparietal sulcus (IPS) (34, − 48, 60,   T   = 4.43), bilateral amygdala (left: − 26, − 8, − 12,   T   = 4.37; right: 26, − 4, − 14,   T   = 3.81) and right TPJ (52, − 58, 8,   T   = 4.38). Additional cortical clusters were observed in the vicinity of the MT/V5 (− 42, − 66, 2,   T   = 7.87) and inferior parietal lobule (IPL) and supramarginal gyrus (SMG) (− 42, − 30, 36,   T   = 4.35). Other regions that survived our a priori threshold are summarised in  . 

Following the request of one of the reviewers, a secondary ROI analysis (see Supplementary  ) using independently defined ROIs confirmed that AQ correlated significantly with BOLD response to gaze specifically in regions that prior studies have linked with gaze and face perception (OFA, FFA, pSTS, IPS and amygdala) as well as mentalizing (TPJ),   p   < 0.05 FWE small-volume corrected. In contrast to the gaze condition, AQ scores did not significantly correlate with activation to the variable vs. constant heads and variable vs. constant eyes-only conditions in any brain region, even at reduced threshold (  p   < 0.05, uncorrected). 

As the AQ can be split up into five subscales measuring different domains (social skills, attention switching, attention to detail, communication and imagination), we tested whether the scores for these domains would also show correlations with the variable versus constant gaze/heads/eyes only contrasts. The overall pattern was similar to that observed with the composite AQ score. Once again, the scales only correlated with the response to variable versus constant gaze, and not with variable versus constant heads or eyes-only. The correlations were also smaller in magnitude on average than those for the composite score. This may be because the range of the subscale scores is truncated in comparison with the composite AQ score. Subscales for attention to detail, imagination and social skills showed the largest correlations with the variable versus constant gaze contrast, while attention switching and communication showed the smallest correlations (see Supplementary  ). 

Finally, it is possible that the correlation between AQ scores and activation to variable versus constant gaze was due to an increased response to variable gaze, a decreased response to constant gaze, or both. To explore this further, we examined the correlation between AQ and i) responses to variable gaze vs. house stimuli and ii) constant gaze vs. house stimuli. This demonstrated that for the same regions as shown in  , AQ correlated   positively   with variable gaze versus houses and   negatively   with constant gaze versus houses ( ). 



## Discussion 
  
Our study shows that in typical individuals, the neural response to eye gaze across the social attention network (pSTS, TPJ, amygdala, IPS, SPL, and SMG) is closely related to the number of autism spectrum characteristics they display. The overlap between these AQ-dependent responses and the network for social attention identified by recent meta-analysis ( ) is illustrated in  . Although functional imaging studies have not revealed a specific neural marker of ASD, they have consistently shown abnormal functioning of a number of the same regions that showed AQ-dependent changes in BOLD response in the present study, namely the TPJ, STS and amygdala (see reviews in  ).   showed that relative to typical controls, individuals with ASD show less activation to eye gaze cues in areas such as the pSTS. At first sight then, it is surprising that we found a positive association between AQ and the hemodynamic response to variable versus constant gaze. However, our results accord with recent research showing that AQ scores in neurotypical individuals were   positively   related to the change in BOLD response in pSTS produced by a measure of task-independent deactivation ( ). The same study also showed that AQ was   negatively   correlated with white matter (WM) volume in a very similar region of pSTS (52, − 42 12) which also falls reasonably close to the region where the AQ-dependent pSTS responses were found in the present study (68, − 42, 24; Euclidian distance between the peaks = 20 mm). 

 suggested that the enhanced BOLD signal in high AQ participants might reflect a compensatory response for their reduced pSTS WM volume. A similar inverse relationship between WM integrity and increased BOLD response has been seen in the early stages of multiple sclerosis (MS), which is characterised by damage to WM tracts ( ). Notably, however, after a critical point of white matter deterioration   reduced   BOLD response is found in the later stages of this disease. We do not wish to draw parallels between ASD and degenerative disorders, but rather simply to highlight that the relationship between BOLD response and brain structure is not necessarily positive. It is therefore possible that white matter integrity is negatively correlated with autistic traits throughout the whole AQ range from typical individuals to those with ASD ( ), whereas the BOLD response to social stimuli might show an inverted u-shaped relationship with AQ scores. Hence, increased BOLD response in neurotypical individuals with higher AQ scores could reflect compensatory mechanisms as these individuals may require more cognitive resources to process gaze and other social cues than people with lower AQ scores. However, after some critical point in the AQ distribution (e.g. close to the clinical cut-off) this compensatory processing might fail, at which point, increasing AQ scores begin to show a   negative   association with BOLD responses, resulting in an inverted U-shaped association between AQ and BOLD when the full range of AQ scores are considered. Such an association could reconcile our findings with clinical studies showing decreased BOLD responses to social cues in ASD ( ). In line with this prediction, an inverted-u-shape relationship has already been observed between self-referential cognition and AQ, reflecting a positive association in controls and a negative association in people with ASD ( ). Future research involving both typical and ASD populations should therefore address whether the association between AQ and both the BOLD response and anatomical structure of pSTS across the entire AQ range. 

The above explanation is by no means the only possible factor that could underlie the positive relationship between AQ and BOLD response to eye gaze. As far as we are aware, the only previous study showing an abnormal BOLD response to a comparison of two gaze cues in people with ASD used a very different task in which a face directed its gaze towards or away from the position of an object in the display ( ), depending on the location of the object (i.e., the gaze was the same for both conditions). While Pelphrey and colleagues found reduced pSTS activation in individuals with ASD relative to controls, we cannot discount that people with autism might show increased activation in response to the variable versus constant Gaze conditions used in the current study. In this respect, the important result is that AQ scores were correlated with the activity of a network of regions implicated in gaze processing, rather than the direction of the correlation. 

Our study also suggests that the direction of the relationship between BOLD and AQ may be influenced by the nature of the stimuli. Relative to the house baseline, variable gaze showed a positive relationship with AQ, whereas constant gaze showed a negative relationship; indicating that the overall positive correlation was composed of positive and negative associations between AQ and activation to variable and constant gaze conditions, respectively. This may be explained by the relative extent to which processing variable and constant gaze engages the social attention network in low and high AQ participants. 

### Autism spectrum traits modulate the activity of the social attention network 
  
Hemodynamic response and AQ scores showed a positive correlation with a number of regions in the social attention network. Next, we deal the potential role of each. The pSTS region has been implicated widely in perception of social stimuli (as reviewed by  ), and its involvement in eye gaze perception is well documented ( ). However, recent studies point to its involvement in analyzing behavioural outcomes and intentionality of human actions ( ). Understanding intentions of others from social cues such as gaze is often impaired in autism ( ), and recent imaging studies have found that when compared to controls, individuals with ASD show an abnormal pSTS response to the perceived intentionality of gaze shifts ( ) or abstract shapes moving interactively with implied intentionality (such as chasing or teasing,  ). The present data from typical individuals accord with these results, as we observed the AQ-correlated pSTS response only for the gaze condition, in which the eyes convey a clear intention of looking at, or being interested in, various locations. All in all, these findings fit well with the proposal that functional changes in the pSTS region may underlie some of the social perception dysfunctions in ASD ( ). Interestingly, ROI analysis also confirmed that AQ modulated BOLD responses to gaze in the FFA (see supplementary  ). This accords with findings showing that FFA is involved in processing eye gaze ( ), and is in line with the proposal that the ventral face perception route may also significantly contribute to the processing of changeable facial cues (see reviews in  ) 

By contrast, AQ did not correlate with the change in BOLD response in the head condition in which the eyes were closed, thus conveying no intention of attending anywhere. Given that cueing effects from averted gaze are maximal when they are presented in the context of a full-face view of the head ( ), it is interesting that the correlation was also absent for the eyes-only condition where head direction information was not available. It is therefore possible that the present results reflect the activity of cells coding both head and gaze direction information, and their interactions with other components of the social attention network ( ). Alternatively, the eye region alone may constitute a less natural, ‘less social’ stimulus than gaze shown in the context of a fully visible head. 

It is also interesting to note that pSTS activation was not observed for the group-level analyses of variable vs. constant gaze or variable vs. constant eyes-only contrasts. Although many studies report pSTS activation in gaze perception tasks ( ), some don't ( ). Furthermore, even when effects are observed they tend to be small, suggesting variable evidence exists across subjects. On the basis of the present results showing AQ-dependent pSTS responses to gaze, AQ score might be a factor in determining whether or not the eye gaze perception systems respond to gaze stimuli. In other words, it is possible that the variability in AQ scores in the typical population may account for discrepant findings in the gaze perception literature. For example, relative increases and decreases in pSTS activation in participants scoring high and low on the AQ questionnaire respectively, as shown here, may result in no overall mean change in BOLD response in this region. In this respect, it is worth emphasising that the main effect of an experimental manipulation and its correlations with proxy variables, such as personality scores, measure different things and are statistically distinct. Main effects can occur in the absence of correlations, and vice versa (see review in  ). 

Although TPJ is not typically associated with gaze perception, it has been consistently linked with mentalizing or theory of mind processing ( ), and with directing attention to behaviourally salient events ( ). In the context of the present study, it seems plausible that the association between AQ scores and TPJ activation might reflect individual differences in the spontaneous tendency to draw mentalistic inferences from eyes, given that spatial reorienting (as indexed by the Posner cueing task) is typically intact in autism ( ). AQ was also correlated with activation in the vicinity of the motion-sensitive MT/V5 complex which has been proposed to constitute an initial stage in processing dynamic facial characteristics, including gaze shifts ( ). A magnetoencephalographic study has also shown that MT/V5 may extract social information conveyed by the eyes within 160 ms post-stimulus, as it shows stronger responses to faces that establish gaze contact rather than gaze aversion ( ). The AQ-dependent MT/V5 activation shows that autistic traits could influence even the very early, dynamic face processing stages. This raises the possibility that facial processing deficits observed in ASD (see  ) could be partially accounted for by deficits in extracting motion cues from faces, although this would need to be verified with studies of individuals with ASD. 

Several studies suggest that the amygdala's role in gaze perception relates to drawing mentalistic inferences from eyes ( ) and detecting or monitoring gaze contact ( ), but its exact contribution is currently unclear. ASD does not typically impair discrimination of others' gaze direction, but hampers the ability to infer others' mental states (e.g., intentions) from their gaze ( ). Taking this dissociation into account, the AQ-dependent amygdala activation found in the current study seems likely to reflect the amygdala's role in attaching social or affective salience to perceived gaze direction, rather than gaze direction encoding per se. The amygdala correlation with AQ is also consistent with Baron-Cohen's proposal that amygdala dysfunction could be one of the potential precursors to ASD ( ). 

Previous research has shown that circuits involved in visual attention are also engaged by viewing changes in gaze direction. The IPS forms part of the dorsal attention system which is thought to underlie attentional target selection ( ).   proposed that the IPS could also subserve attention orienting from seen gaze direction. In line with this proposal, single-unit recordings in macaques ( ) have indeed established that some neurons in the lateral intraparietal area (LIP; the lateral wall of the monkey IPS) increase their firing rate, while others reduce their firing rate, when the monkey views an image of a conspecific gazing towards the cell's response field. Similar effects are also observed when the monkey overtly looks at the corresponding locations, suggesting this regions' involvement in mirroring others' gaze. A number of behavioural studies in humans have found that viewing averted gaze triggers an involuntary shift of covert or overt attention towards the gazed-at location (for a review see  ). Although attention orienting was not measured behaviourally in our study, it is plausible that the AQ-dependent response in the IPS reflects the relationship between AQ and the tendency to imitate others' gaze behaviour ( ). In addition to the IPS, AQ-dependent activation of the IPL and SMG was also observed. The role of these regions in governing goal-directed shifts of attention is well established ( ), and a recent meta-analysis of fMRI studies on autism ( ) showed that individuals with ASD show reduced IPL and SMG activations in non-social attentional tasks. 

Finally, it must be noted that although there was a considerable overlap between the social attention network ( ) and AQ-modulated BOLD responses to gaze in the present study ( ), some of the activation foci clearly fall outside the social attention network. It is therefore possible that AQ also influences certain ‘gaze-independent’ neural mechanisms. However, this seems unlikely, given that AQ was not correlated with responses to variable versus constant heads and eyes-only conditions. Perhaps a more likely explanation is that AQ modulated responses in brain regions that are not part of the ‘core’ network for social attention perception, but are nevertheless recruited during certain gaze perception tasks such as the one used in the present study. 



## Conclusions 
  
We have shown that individual differences in autism spectrum traits in typical individuals are correlated with brain responses to observed shifts in gaze direction in key components of the brain circuit for eye gaze perception ( ), as well as those involved in inferring others' mental states ( ). Dysfunction in these same regions is also systematically observed in individuals with ASD. Our results therefore provide support for the existence of a broader autistic spectrum that extends into the typical population ( ). The data also demonstrate that neural processing of eye gaze is not fully homogenous across typical participants, as individual differences in social-cognitive processing styles indexed by AQ have a profound influence on the neural processing of eye gaze. Thus, in addition to furthering our understanding of the neurobiological basis of the extended autism phenotype, our results demonstrate that studies of eye gaze perception in typical individuals should take into account that a significant proportion of between-subject variance has a meaningful psychological basis. The identification of a cortical network influenced by AQ may be important in furthering our understanding of the neurobiological basis of deficits in the processing of social cues. Future studies on the development and functional connectivity of this network across the entire autism spectrum range could contribute to our understanding of neural markers of the development of ASD. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-11'>
<h2>11. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/26048954/' target='_blank'>26048954</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Functional Organization of Social Perception and Cognition in the Superior Temporal Sulcus</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Cereb Cortex</p>
<p><strong>Publication Year:</strong> 2015</p>
<p><strong>DOI:</strong> 10.1093/cercor/bhv111</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4816802/' target='_blank'>4816802</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an original fMRI study scanning healthy adult participants (N=20, ages 19–31) performing multiple social-cognitive tasks (theory of mind, face perception, biological motion, voice perception, auditory stories). Tasks are social-related and imaging was whole-brain (GLM performed across the brain; analyses focused on STS using an anatomically defined mask but are not limited to ROI-only approaches). Participants are healthy and within the 18–60 age range. The paper is not a review or meta-analysis and does not report patient samples. Thus it meets all inclusion criteria (social fMRI in healthy adults, appropriate age range, whole-brain analyses) and none of the exclusion criteria (not ROI-only, not a review, not clinical).</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
The superior temporal sulcus (STS) is considered a hub for social perception and cognition, including the perception of faces and human motion, as well as understanding others' actions, mental states, and language. However, the functional organization of the STS remains debated: Is this broad region composed of multiple functionally distinct modules, each specialized for a different process, or are STS subregions multifunctional, contributing to multiple processes? Is the STS spatially organized, and if so, what are the dominant features of this organization? We address these questions by measuring STS responses to a range of social and linguistic stimuli in the same set of human participants, using fMRI. We find a number of STS subregions that respond selectively to certain types of social input, organized along a posterior-to-anterior axis. We also identify regions of overlapping response to multiple contrasts, including regions responsive to both language and theory of mind, faces and voices, and faces and biological motion. Thus, the human STS contains both relatively domain-specific areas, and regions that respond to multiple types of social information. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (61675 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Humans are profoundly social beings, and accordingly devote considerable cortical territory to social cognition, including lower tier regions specialized for perceiving the shapes of faces and bodies ( ), and high-level regions specialized for understanding the meaning of sentences ( ;  ) and the contents of other people's thoughts ( ;  ). Yet between these 2 extremes lies a rich space of intermediate social processes, including the ability to discern the goal of an action, the significance of a fleeting facial expression, the meaning of a tone of voice, and the nature of the relationships and interactions in a social group. How do we so quickly and effortlessly extract this multifaceted social information from “thin slices” of social stimuli ( )? Here we investigate the functional organization of our computational machinery for social cognition by using fMRI to target a brain region that has long been implicated as a nexus of these processes: the superior temporal sulcus (STS). 

The STS is one of the longest sulci in the brain, extending from the inferior parietal lobe anteriorly along the full length of the temporal lobe. Subregions of the STS have been implicated in diverse aspects of social perception and cognition, including the perception of faces ( ;  ;  ), voices ( ), and biological motion ( ;  ;  ;  ;  ;  ), and understanding of others' actions ( ;  ;  ;  ), and mental states ( ;  ;  ;  ;  ). Regions of the STS have also been implicated in linguistic processing ( ;  ;  ), as well as basic perceptual and attentional functions, such as audiovisual integration ( ;  ;  ), and the control of visual attention ( ). But because most prior studies have investigated only a small subset of these mental processes, the relationship between the regions involved in each process remains unknown. 

One possibility is that the STS is composed of a number of distinct, functionally specialized subregions, each playing a role in one of these domains of processing and not others. This would point to a modular organization, and would further point to separate streams of processing for the domains listed above—processing faces, voices, mental states, etc. Another possibility is that responses to these broad contrasts overlap. Overlap could either point to 1) STS subregions involved in multiple processes, indicating a nonmodular organization; or 2) a response driven by an underlying process shared across multiple tasks, such as integration of information from multiple modalities or domains. 

) performed a meta-analysis assessing locations of peak coordinates of STS responses from biological motion perception, face perception, voice perception, theory of mind (ToM), and audiovisual integration tasks. They found that peak coordinates from different tasks did not fall into discrete spatial clusters, and thus argued 1) that the STS consists of multifunctional cortex, whose functional role at a given moment depends on coactivation patterns with regions outside of the STS; and 2) that there is little spatial organization to the STS response to different tasks. 

However, meta-analyses cannot provide strong evidence for overlap between functional regions. Because the anatomical location of each functional region varies across individual subjects, combining data across subjects in a standard stereotactic space can lead to findings of spurious overlap ( ;  ;  ). These issues are compounded in meta-analyses, which combine data across studies using different normalization algorithms and stereotactic coordinate systems. Furthermore, to investigate overlap between regions responding to distinct tasks, we would ideally want to study the full spatial extent of these regions, rather than simply peak coordinates. 

The present study addresses these limitations by scanning the same set of subjects while they engage in face perception, biological motion perception, mental state understanding (termed ToM), linguistic processing, and voice perception. Within individual subjects, we compare STS responses across different tasks. We show that distinct input domains evoke distinct patterns of activation along the STS, pointing to different processes engaged by each type of input. In particular, we find that a dominant feature of this spatial organization consists of differences in response profile along the anterior–posterior axis of the STS. Investigating focal regions that respond maximally to each contrast within individual subjects, we are able to find strongly selective regions for most processes assessed, including biological motion perception, voice perception, ToM, and language. These selective regions are also characterized by distinct patterns of whole-brain functional connectivity, and similarity in functional connectivity profiles across regions is predictive of similarity in task responses. In addition to these selective regions, we identify a number of regions that respond reliably to multiple contrasts, including language and ToM, faces and voices, and faces and biological motion. Thus, the STS appears to contain both subregions specialized for particular domains of social processing, as well as areas responsive to information from multiple domains, potentially playing integrative roles. 


## Materials and Methods 
  
### Participants 
  
Twenty adult subjects (age 19–31 years, 11 females, all right-handed) participated in the study. Participants had no history of neurological or psychiatric impairment, had normal or corrected vision, and were native English speakers. All participants provided written, informed consent. 


### Paradigm 
  
Each participant performed 5 tasks over the course of 1–3 scan sessions. These included a ToM task, biological motion perception task, face perception task, voice perception task, and an auditory story task that yielded multiple contrasts of interest. The paradigms were designed such that roughly 5 min of data was collected for each condition within each experiment. 

In the ToM task, participants read brief stories describing either false beliefs (ToM condition) or false physical representations (control condition), and then answered true/false questions about these stories. Stories were chosen based on a prior study that identified false belief stories that elicited the largest response in the right temporo-parietal junction (TPJ) ( ). Stories were presented for 10 s, followed by a 4-s question phase, and 12-s fixation period, with an additional 12 s fixation at the start of the run. Twenty stories (10 per condition) were presented over 2 runs, each lasting 4:32 min. Conditions were presented in a palindromic order (e.g., 1, 2, 2, 1), counterbalanced across runs and subjects. The stimuli and experimental scripts are available on our laboratory's website ( , Last accessed 16/05/2015). 

In the biological motion task, participants watched brief point-light-display (PLD) animations that either depicted various human movements (walking, jumping, waving, etc.) or rotating rigid 3D objects with point-lights at vertices ( ). Animations consisted of white dots moving on a black background. Individual animations lasted 2 s, and were presented in blocks of 9, with a 0.25-s gap between animations. Participants performed a one-back task on individual animations, pressing a button for repeated stimuli, which occurred once per block. Additionally, 4 other conditions were included which are not reported here; these included spatially scrambled versions of human and object PLDs, linearly moving dots, and static dots. In each of 6 runs, 2 blocks per condition were presented in palindromic order, with condition order counterbalanced across runs and subjects. Runs consisted of 12 20.25-s blocks as well as 18-s fixation blocks at the start, middle, and end, for a total run time of 4:57 min. Due to timing constraints, one subject did not complete the biological motion task. 

In the face perception task, participants passively viewed 3-s movie clips of faces or of moving objects, using stimuli that have been previously described ( ). We chose to use dynamic as opposed to static face stimuli as dynamic stimuli have been shown to yield a substantially stronger response in the face area of posterior STS (pSTS) ( ), facilitating the ability to identify face-responsive regions of the STS in individual subjects. Stimuli were presented in blocks of 6 clips with no interval between clips. Additionally, a third condition presenting movies of bodies was included, but not assessed in this report. In each of 3 runs, 4 blocks per condition were presented in palindromic order, with condition order counterbalanced across runs and subjects. Runs consisted of 12 18-s stimulus blocks as well as 18-s rest blocks at the start, middle, and end, for a total run time of 4:30 min. 

In the voice perception task, participants passively listened to audio clips consisting either of human vocal sounds (e.g., coughing, laughing, humming, sighing, speech sounds), or nonvocal environmental sounds (e.g., sirens, doorbells, ocean sounds, instrumental music). Stimuli were taken from a previous experiment that identified a voice-responsive region of STS ( ) ( , Last accessed 16/05/2015). Clips were presented in 16-s blocks that alternated between the 2 conditions, with a 12-s fixation period between blocks and 8 s of fixation at the start of the experiment. Condition order was counterbalanced across subjects. A single run was given, with 10 blocks per condition, lasting 9:28. Due to timing constraints, 4 subjects did not receive the voice perception task. 

During the auditory story task, participants listened to either stories or music. Four conditions were included: ToM stories, physical stories, jabberwocky, and music. This task provides a language contrast (physical stories vs. jabberwocky), a second ToM contrast (ToM vs. physical stories), and a second voice contrast (jabberwocky vs. music). Two additional conditions, stories depicting physical and biological movements, were included for separate purposes, and are not analyzed in the present report. ToM stories consisted of stories describing the false belief of a human character, with no explicit descriptions of human motion. Physical stories described physical events involving no object motion (e.g., streetlights turning on at night) and no human characters. All stories consisted of 3 sentences, and stories were matched across conditions on number of words, mean syllables per word, Flesch reading ease, number of noun phrases, number of modifiers, number of higher level constituents, number of words before the first verb, number of negations, and mean semantic frequency (log Celex frequency). Jabberwocky stimuli consisted of English sentences with content words replaced by pronounceable nonsense words, and with words temporally reordered. This condition has minimal semantic and syntactic content, but preserves prosody, phonology, and vocal content. Music stimuli consisted of clips from instrumental classical and jazz pieces, with no linguistic content. Each auditory stimulus lasted 9 s. After a 1-s delay, participants performed a delayed-match-to-sample task, judging whether a word (or music clip) came from the prior stimulus. Each run consisted of 4 trials per condition, for a total of 24 trials. Four runs of 8:08 min were given. Stimuli were presented in a jittered, slow event-related design, with stimulus timing determined using Freesurfer's optseq2 to optimize power in comparing conditions. 

Additionally, resting-state data were acquired to investigate functional connectivity of STS subregions. For these scans, participants were asked to keep their eyes open, avoid falling asleep, and stay as still as possible. These scans lasted 10 min. 


### Data Acquisition 
  
Data were acquired using a Siemens 3T MAGNETOM Tim Trio scanner (Siemens AG, Healthcare, Erlangen, Germany). High-resolution   T  -weighted anatomical images were collected using a multi-echo MPRAGE pulse sequence (repetition time [TR] = 2.53 s; echo time [TE] = 1.64, 3.5, 5.36, 7.22 ms, flip angle   α   = 7°, field of view [FOV] = 256 mm, matrix = 256 × 256, slice thickness = 1 mm, 176 near-axial slices, acceleration factor = 3, 32 reference lines). Task-based functional data were collected using a   T  *-weighted echo planar imaging (EPI) pulse sequence sensitive to blood oxygen level–dependent (BOLD) contrast (TR = 2 s, TE = 30 ms,   α   = 90°, FOV = 192 mm, matrix = 64 × 64, slice thickness = 3 mm, slice gap = 0.6 mm, 32 near-axial slices). Resting-state functional data were also collected using a   T  *-weighted EPI sequence (TR = 6 s, TE = 30 ms,   α   = 90°, FOV = 256 mm, matrix = 128 × 128, slice thickness = 2 mm, 67 near-axial slices). Resting data were acquired at higher resolution (2 mm isotropic) to reduce the relative influence of physiological noise ( ,  ). 


### Data Preprocessing and Modeling 
  
Data were processed using the FMRIB Software Library (FSL), version 4.1.8, supplemented by custom MATLAB scripts. Anatomical and functional images were skull-stripped using FSL's brain extraction tool. Functional data were motion corrected using rigid-body transformations to the middle image of each run, corrected for interleaved slice acquisition using sinc interpolation, spatially smoothed using an isotropic Gaussian kernel (5-mm FWHM unless otherwise specified), and high-pass filtered (Gaussian-weighted least-squares fit straight line subtraction, with   σ   = 50 s ( )). Functional images were registered to anatomical images using a rigid-body transformation determined by Freesurfer's bbregister ( ). Anatomical images were in turn normalized to the Montreal Neurological Instititute-152 template brain (MNI space), using FMRIB's nonlinear registration tool (FNIRT). Further details on the preprocessing and modeling of resting-state data are provided below (see Resting-state functional connectivity analysis). 

Whole-brain general linear model-based analyses were performed for each subject, run, and task. Regressors were defined as boxcar functions convolved with a canonical double-gamma hemodynamic response function. For the ToM task, the story and response periods for each trial were modeled as a single event, lasting 14 s. For the auditory story task, 9-s-long stories were modeled as single events; these did not include the response period, as the response was unrelated to the processes of interest for this task. For the face, biological motion, and voice perception tasks, the regressor for a given condition included each block from that condition. Temporal derivatives of each regressor were included in all models, and all regressors were temporally high-pass filtered. FMRIB's improved linear model was used to correct for residual autocorrelation, to provide valid statistics at the individual-subject level ( ). 

Subsequently, data were combined across runs for each subject using second-level fixed-effects analyses, after transforming beta maps to MNI space. For split-half analyses (further described below), data were combined across even and odd runs separately. For the voice localizer, which only had a single run, the data were temporally split into first and second halves, each with 5 blocks per condition, and these were analyzed as if they were separate runs. 

The contrasts analyzed were as follows: from the ToM task, false belief versus false physical representation stories (termed ToM 1); from the face perception task, faces versus objects (Faces); from the biological motion task, biological motion versus rigid object motion (Biological Motion); from the voice perception task, vocal versus nonvocal sounds (Voice 1); and from the auditory story task, false belief versus physical stories (ToM 2), physical stories versus jabberwocky (Language), and jabberwocky versus music (Voice 2). Note that the ToM 2 and Language contrasts are nonorthogonal and thus statistically dependent, as are the Language and Voice 2 contrasts. As a result, these pairs of contrasts are biased toward finding nonoverlapping sets of voxels: for instance, voxels with high responses in the physical condition are less likely have significant effects of ToM 2, and more likely to have significant effects of Language. However, in both of these cases we have contrasts from separate datasets (ToM 1 and Voice 1 contrasts) to validate the results. 

Because we were specifically interested in responses within the STS, second-level analyses were restricted to voxels within a bilateral STS mask, defined by drawing STS gray matter on the MNI template brain. Posteriorly, the STS splits into 2 sulci surrounding the angular gyrus. Our mask included both of these sulci as well as gray matter in the angular gyrus, because responses to ToM contrasts have previously been observed on the angular gyrus. Statistical maps were thresholded using a false discovery rate of   q   < 0.01, which controls the proportion of positive results that are expected to be false positives, to correct for multiple comparisons; supplementary analyses also used different thresholds to determine the effect on overlap estimates. 


### Anterior–Posterior Organization 
  
We first investigated the large-scale spatial organization of STS responses to different contrasts, by assessing how responses to each contrast vary as a function of position along the length of the sulcus. We sought to define a series of regions of interest (ROIs) that carved the STS into slices along its length. Prior studies have analyzed responses in coronal slices of the STS, assessing how responses vary as a function of the   y  -coordinate in MNI space ( ;  ;  ;  ). However, the STS has an oblique orientation in the   y  –  z   plane of MNI space, and we wished to define ROIs that extended perpendicularly to the local direction of the STS in the   y  –  z   plane. 

To this end, we used our STS mask to estimate the local orientation of the sulcus at different   y  -coordinates. Mask coordinates were averaged across the   x  - and   z  -dimensions, to obtain a function specifying the mean   z  -coordinate of the STS for a given   y  -coordinate. Next, for each   y  -coordinate, the local slope of the STS was determined by fitting a linear regression to   z  -coordinates in a 1-cm window along the   y  -dimension. This slope was used to define “slice” ROIs along the length of the STS, by constructing an anisotropic Gaussian ROI and intersecting this with the STS mask (sample ROIs are shown in Fig.  ). Note that, for the posterior segment of the STS, where it splits into 2 sulci, our approach does not treat these sulci separately, instead computing the local slope of a mask including both sulci and the angular gyrus. For each ROI, hemisphere, subject, and contrast, percent signal change values were extracted, and plotted as a function of   y  -coordinate. 

Additionally, we asked whether these patterns differed across the upper and lower banks of the STS. The upper and lower banks of the STS were drawn on individual subjects' cortical surface representations, and intersected with the slice ROIs defined above. Percent signal change values were extracted from the resulting “upper and lower slice” ROIs. For this analysis, we only considered portions of the STS that were anterior to the point at which the STS splits into 2 sulci posteriorly, and data were only smoothed at 3-mm FWHM to minimize bleeding across upper and lower banks. 

These analyses revealed that the positions of regions with the strongest response to each contrast were ordered as follows, from posterior to anterior: ToM, biological motion, faces, voices, language. We next aimed to statistically assess these differences in spatial position. Although some contrasts elicited responses in multiple regions along the STS, we aimed to compare responses specifically within the region of maximal response to each task, and thus assessed active regions in individual subjects within spatially constrained group-level search spaces. Search spaces for each contrast were defined from group-level activation maps, computed using a mixed-effects analysis ( ), as the set of active voxels within a 15-mm sphere around a peak coordinate (shown in   Supplementary Fig. 1  ). For each spatially adjacent pair of search spaces (e.g., ToM and biological motion, biological motion and faces, etc.), we combined the 2 search spaces, and identified regions of activation in individual subjects to each of the 2 contrasts within this combined search space. We then computed the center of mass of these regions, and compared their   y  -coordinates across the 2 contrasts using a paired, two-sample, two-tailed   t  -test. 


### Responses in Maximally Sensitive Regions 
  
We next asked whether the STS contains selective regions, responding to one contrast and not others. We focused on small regions that were maximally responsive to each contrast in a given subject, to increase the likelihood of finding selective responses, and extracted responses in these regions across all conditions. ROIs were defined using data from odd runs of each task. For the face localizer, which had 3 runs, runs 1 and 3 were used to define ROIs. The group-level search spaces defined above (Anterior–Posterior Organization section) were used to spatially constrain ROI definition. For each contrast, hemisphere, and subject, we identified the coordinate with the global maximum response across a given search space, placed a 5-mm-radius sphere around this coordinate, and intersected this sphere with the individual subject's activation map for that contrast. 

Responses to each condition in each task were then extracted from these ROIs. For the task used to define the ROI, data were extracted from even runs while, for other tasks, the full dataset was used, such that the extracted responses were always independent from data used to define the ROI. Percent signal change was extracted by averaging beta values across each ROI and dividing by mean BOLD signal in the ROI.   t  -Tests were used to test for an effect of each of the seven contrasts of interest in each ROI, with a threshold of   P   < 0.01 (one-tailed). Participants who lacked a certain ROI were not included in the statistical analysis for that ROI. 


### Resting-State Functional Connectivity Analysis 
  
We next probed another aspect of spatial organization in the STS: do subregions of the STS have different patterns of functional connectivity, and do these patterns relate to the task response profile of that region? Specifically, we assessed resting-state functional connectivity of functionally defined STS subregions. 

For resting-state data, several additional preprocessing steps were performed to diminish the influence of physiological and motion-related noise. Time series of 6 motion parameter estimates, computed during motion correction, were removed from the data via linear regression. Additionally, time series from white matter and cerebrospinal fluid (CSF) were removed using the CompCorr algorithm ( ;  ). White matter and CSF ROIs were defined using FSL's Automated Segmentation Tool and eroded by one voxel. The mean and first 4 principal components of time series from these masks were computed and removed from the data via linear regression. 

We again focused on regions with maximum responses to a given contrast, to isolate spatially distinct subregions of the STS. ROIs were defined in the same way as above (see Responses in maximally sensitive regions): as the set of active voxels within a 5-mm-radius sphere around the peak coordinate of response from a given task and participant. Although these ROIs were defined using the same procedure as described above, they were defined using the full dataset from each task, rather than half of the data, and thus differed slightly from the ROIs used above. Time series were extracted from each ROI, and correlations were computed with time series from every voxel in a Freesurfer-derived gray matter mask (excluding within-hemisphere STS voxels), to derive a whole-brain functional connectivity map for each region. We then computed correlations between whole-brain functional connectivity maps from different regions, to determine the degree of similarity of functional connectivity maps from different STS subregions (functional connectivity similarity). We also computed task responses of these ROIs across the 12 conditions assessed in this study, and computed correlations between these task response vectors across ROIs, to assess similarity of response profiles (response similarity). 

Lastly, we assessed the relationship between functional connectivity similarity and response similarity, after accounting for effects of spatial proximity of ROIs. Within each hemisphere, a linear mixed model was performed with functional connectivity similarity values (Fisher-transformed) across ROI pairs and subjects as the dependent variable. To avoid pairs of ROIs with trivially similar response profiles due to similarity in physical location, we excluded ROIs from the ToM 2 and Voice 2 contrasts, as well as any pair of ROIs whose centers were closer than 1 cm, which prevents any overlap between pairs of ROIs. Response similarity (Fisher-transformed) was used as the explanatory variable of interest. Additionally, physical distance between ROIs, as well as the square and cube roots thereof, were included as nuisance regressors to account for effects of spatial proximity on similarity of functional connectivity maps. These specific nonlinear functions of physical distance were found to accurately model the relation between physical distance and functional connectivity similarity values. A mixed model with random-effect terms for the intercept and the effect of response similarity was used. Parameters were estimated using an approximate maximum likelihood method ( ), implemented using MATLAB's nlmefit function. A Wald test was used to assess the relationship between response similarity and functional connectivity similarity in each hemisphere; the use of a normal approximation is justified by the large number of data points in each model (  N   = 291, right hemisphere;   N   = 233, left hemisphere). 


### Overlap Analysis 
  
Having probed the response profile of focal, maximally responsive ROIs for each contrast, we next investigated the full spatial extent of responses to each contrast. Specifically, we assessed the amount of overlap between significantly active STS voxels in each hemisphere across contrasts. To illustrate our method for quantifying overlap, suppose we have 2 regions, called A and B, defined by 2 different contrasts, and let AB denote the region of overlap between A and B. We compute 2 quantities to assess the overlap between A and B: the size of AB divided by the size of A, and the size of AB divided by the size of B. In addition to the amount of overlap, these measures provide some insight into the type of overlap occurring. For instance, if region A encompasses and extends beyond region B, then size(AB)/size(B) = 1, while size(AB)/size(A) <1. In contrast, if the regions are of equal size, then size(AB)/size(B) = size(AB)/size(A). Furthermore, these quantities have an intuitive and straightforward interpretation, as the proportion of one region (A or B) that overlaps with the other. Overlap values were averaged across subjects. For each pair of contrasts and each hemisphere, subjects who lacked any STS response to one or both contrast were excluded from this average. 

fMRI overlap values depend on both the extent of spatial smoothing applied, as well as the statistical threshold used to define the extent of active regions. For this reason, we additionally computed overlap values at a range of different thresholds (  q   < 0.05,   q   < 0.01, and   q   < 0.005) as well as smoothing kernels (5-, 3-, and 0-mm FWHM) to ask whether overlap could be consistently observed across these different parameters. 

Lastly, we investigated the response profiles of overlapping regions, focusing on pairs of contrasts for which substantial overlap was observed. Specifically, we focused on regions responsive to language and ToM, faces and voices, and faces and biological motion. We used a split-half analysis approach. Regions were defined in the first half of the dataset as the set of all voxels that responded to 2 given contrasts. Responses were then extracted in the second half of the data for the 2 tasks used to define the region, or the full dataset for other tasks, such that responses were always extracted from data that was independent of those used to define the ROI. Unsmoothed data were used to extract responses, such that overlapping responses could not be introduced by spatial smoothing.   t  -Tests were used to test for an effect of each of the 7 contrasts of interest in each ROI, with a threshold of   P   < 0.01 (one-tailed). 



## Results 
  
### Individual Subject Activations 
  
Individual subject activations are shown in Figure  , and mean peak coordinates of response (within search spaces for each contrast) are given in Table  . For the ToM contrasts, the most commonly observed response bilaterally was in the angular gyrus or one of the 2 branching sulci of the STS, a region previously termed the TPJ ( ). Additionally, responses in middle and anterior STS region were often observed. In some subjects, these responses were relatively focal (e.g., Subject 2 in Fig.  ), while in others this response encompassed a large portion of middle to anterior STS (e.g., Subject 1 in Fig.  ).
   
Peak coordinates (in MNI space) of response to each task 
      
Individual-subject activations to 7 different contrasts in 2 representative example subjects. Analyses were restricted to the bilateral STS mask shown in yellow at the bottom, and were thresholded at a false discovery rate of   q   < 0.01. The slices displayed are at MNI   x  -coordinate ± 52 . 
  

Responses to the language contrast were generally stronger in the left than right hemisphere. In the left hemisphere, most subjects had several distinct regions of activation along the STS, with variable positions across subjects, ranging from angular gyrus to middle and anterior STS. In the right hemisphere, the most commonly observed response was a single region of far-anterior STS, as seen in both subjects in Figure  . 

For the voice contrast, activations were generally centered in the middle STS, and were typically stronger in the upper than lower bank of the STS. These responses varied substantially in extent across subjects, with some being relatively focal (e.g., Subject 2 in Fig.  ), and some extending along nearly the full length of the STS anterior to the angular gyrus (e.g., Subject 1 in Fig.  ). 

Face responses were most commonly observed in a region at and/or just anterior to the point at which the STS breaks into 2 sulci, previously termed the pSTS ( ;  ). Additionally, many subjects had several other discrete face-sensitive regions both anterior and posterior to this pSTS region, with locations varying across individuals. 

Biological motion responses were typically observed in a similar region of pSTS. This region was typically overlapping with the face-responsive pSTS region, but was centered slightly posteriorly in most subjects (e.g., Subject 2 in Fig.  ; also see Anterior–Posterior Organization section). 


### Anterior–Posterior Organization 
  
To summarize the large-scale organization of responses to each contrast, we next analyzed the strength of BOLD responses to each contrast as a function of position along the length of the STS. 

Results from this analysis are shown in Figure   (ToM 2 and Voice 2 contrasts are omitted for visualization purposes); results separated across the upper and lower banks are shown in   Supplementary Figure 2  . These results are consistent with the qualitative descriptions of individual-subject activation patterns described above, and provide a visualization of these effects at the group level. ToM responses are strongest in the posterior-most part of the STS (in the angular gyrus and surrounding sulci), and were also observed in middle-to-anterior STS. Biological motion responses peaked in a pSTS region just anterior to the angular gyrus ToM response. Face responses peaked in a further-anterior pSTS region, with weaker responses also observed in middle-to-anterior STS. The voice response was very broad, encompassing much of the STS, and centered on middle STS. Lastly, language responses in the left hemisphere were observed along the extent of the STS, with peaks in posterior and anterior STS regions. In the right STS, only an anterior region of language activation was observed. Voice responses were substantially stronger in the upper bank than the lower bank of the STS, while responses to ToM, biological motion, faces, and language were largely symmetric across the 2 banks (with a slightly stronger right anterior ToM response in the lower bank).
   
Responses to each task as a function of position along the length of the STS. The upper figure shows the ROIs that were used to extract responses at each position. The lower 2 graphs show left and right STS responses (percent signal change) for each task, as a function of   y  -coordinate in MNI space. 
  

To determine the reliability of these anterior–posterior spatial relations across individual subjects, we statistically assessed differences in center of mass along the   y  -axis of spatially adjacent regions. This difference was significant for all pairs of regions, including ToM 1 and biological motion regions (LH:   t   = 2.34,   P   < 0.05, RH:   t   = 5.65,   P   < 10 ), biological motion and face regions (LH:   t   = 7.30,   P   < 10 , RH:   t   = 3.17,   P   < 0.01), face and Voice 1 regions (LH:   t   = 2.54,   P   < 0.05, RH:   t   = 6.10,   P   < 10 ), and Voice 1 and language regions (LH:   t   = 7.46,   P   < 10 , RH:   t   = 6.91,   P   < 10 ). This result demonstrates a reliable, bilateral anterior-to-posterior ordering of responses: the TPJ response to ToM, pSTS response to biological motion, pSTS response to faces, middle STS response to voices, and anterior STS response to language. 


### Responses in Maximally Sensitive Regions 
  
Do STS subregions of maximal sensitivity to a given contrast also exhibit selectivity—a response to one contrast but not others? We tested this by extracting responses across all conditions from small ROIs surrounding peak coordinates for the response to each contrast (Fig.  ), using data independent of those used to define the ROI. Responses in regions defined by ToM 2 and Voice 2 contrasts are omitted for brevity, as the locations of these regions and their response profiles were highly similar to the ToM 1 and Voice 1 ROIs.
   
Responses (in percent signal change) of maximally sensitive regions for each contrast, across all conditions. Responses were measured in data independent of those used to define the ROIs. 
  

Among regions defined by the ToM (ToM 1) contrast, the left hemisphere region responded strongly to the ToM 1 (  t   = 7.13,   P   < 10 ) and ToM 2 (  t   = 7.45,   P   < 10 ) contrasts, but also responded significantly to the language contrast (  t   = 4.88,   P   < 10 ). The right hemisphere region, in contrast, exhibited a selective response, with significant effects only for the ToM 1 (  t   = 6.84,   P   < 10 ) and ToM 2 (  t   = 4.00,   P   < 10 ) contrasts. 

Language regions were defined in a relatively small number of subjects (4 for the right hemisphere and 8 for the left, in split-half data). This likely reflects the fact that this contrast was generally somewhat weaker than the others, as well as more spatially variable, leading to a substantial portion of subjects with no significant response in the anterior STS language search space when only odd runs were analyzed. Nevertheless, significant effects of the language contrast were observed in both the left (  t   = 6.03,   P   < 0.001) and right (  t   = 5.74,   P   < 0.01) hemispheres. An effect of the Voice 2 contrast was observed in the left hemisphere (  t   = 3.65,   P   < 0.01). Note that the jabberwocky condition used to define this contrast involves phonemic and prosodic information; this difference could thus still reflect linguistic processing. However, an effect of the ToM 2 contrast was also observed in the left hemisphere (  t   = 3.73,   P   < 0.01), in addition to a marginal effect of ToM 2 in the right hemisphere (  t   = 2.16,   P   < 0.05) and marginal effects of ToM 1 in the left (  t   = 2.63,   P   < 0.05) and right (  t   = 3.73,   P   < 0.05) hemispheres. These effects reflected moderately sized differences in percent signal change (0.2–0.4%), but were nevertheless statistically marginal due to the small number of subjects with a defined region. Thus, although this region appears largely language selective—with a stronger response to language conditions relative to a range of nonlinguistic visual and auditory conditions—it appears to also be modulated by mental state content. 

Voice-sensitive regions in middle STS showed a clearly selective profile of responses bilaterally. These regions responded to the Voice 1 (left:   t   = 6.78,   P   < 10 ; right:   t   = 11.12,   P   < 10 ) and Voice 2 (left:   t   = 7.02,   P   < 10 ; right:   t   = 6.95,   P   < 10 ) contrasts, and did not respond significantly to any other contrast. 

Strikingly, the face-sensitive region of posterior STS responded strongly to both face and voice contrasts, bilaterally. The expected response to faces was found in the left (  t   = 6.51,   P   < 0.001) and right (  t   = 7.50,   P   < 10 ) hemispheres. Additionally, there was a bilateral effect of the Voice 1 (left:   t   = 7.42,   P   < 0.001; right:   t   = 5.13,   P   < 10 ) and Voice 2 (left:   t   = 4.13,   P   < 0.01; right:   t   = 3.86,   P   < 0.01) contrasts. Weaker effects of the ToM 2 contrast (  t   = 2.80,   P   < 0.01) and the biological motion contrast (  t   = 2.90,   P   < 0.01) were also observed in the right hemisphere. 

Lastly, the posterior STS regions defined by the biological motion contrast responded to biological motion bilaterally (left:   t   = 15.20,   P   < 10 ; right:   t   = 13.76,   P   < 10 ). There was also an effect of the Voice 1 contrast in the right hemisphere (  t   = 2.78,   P   < 0.01) and marginally in the left hemisphere (  t   = 2.43,   P   < 0.02), although neither region showed an effect of the Voice 2 contrast. This indicates the presence of an STS subregion that is quite selective for processing biological motion. 

Could differences in effect sizes across regions in this analysis reflect differences in signal quality from different subregions of the STS? To address this, we computed temporal signal-to-noise ratios (tSNR) for the ROIs assessed here (  Supplementary Fig. 3  ). These results indicate that tSNR values are largely similar across ROIs, with a slight (∼25%) decrease in values for voice ROIs. This suggests against the possibility that these functional dissociations result from signal quality differences. 


### Resting-State Functional Connectivity Analysis 
  
We next asked about another dimension of spatial organization: do functionally and anatomically distinct subregions of the STS have differing patterns of functional connectivity with the rest of the brain? We identified regions of maximum response to each task within individual subjects, and assessed similarity between their functional connectivity maps, as well as their task response profiles. 

Matrices of functional connectivity and response similarity are shown in Figure   (additionally, whole-brain functional connectivity maps for each seed region are shown in   Supplementary Fig. 4  ). Generally, positive correlations were observed between functional connectivity patterns. Excluding correlations between regions defined by similar contrasts (ToM 1/ToM 2, Voice 1/Voice 2), these correlations ranged from 0.05 to 0.58 (LH), and 0.11 to 0.60 (RH). The broad range in these correlation values indicates that some pairs of STS subregions share similar functional connectivity patterns, while others diverge.
   
Matrices of functional connectivity similarity (correlations between whole-brain resting-state functional connectivity maps of seed ROIs defined by each contrast) and response similarity (correlations between vectors of task responses from each seed ROI). ROIs are defined to consist of a focal region of maximal activation to a given contrast. 
  

Does this variability in functional connectivity similarity relate to variability in the response similarity of pairs of regions? A linear mixed model showed a significant relationship both in the left hemisphere (  z   = 2.52,   P   < 0.05) and the right hemisphere (  z   = 3.29,   P   < 0.001), after accounting for effects of spatial proximity. These findings indicate that there are multiple functional connectivity patterns and response profiles associated with STS subregions, and that pairwise similarity along these 2 measures is related: regions with more similar response profiles also have more similar patterns of functional connectivity. 


### Overlap Analysis 
  
Having investigated the response profiles of maximally responsive focal regions in individual subjects, we next asked whether the full STS response to each contrast is spatially distinct or overlapping across contrasts. To answer this question, we computed the proportion of the STS activation to one contrast that overlapped with activations to each other contrast. 

Results from the overlap analysis are shown in Figure  . As expected, the strongest overlap values (47–75%) were found for the ToM 1 and ToM 2 contrasts, as well as the Voice 1 and Voice 2 contrasts, intended to elicit activity in similar regions. Overlap values for other pairs of contrasts ranged from 4 to 59%. Particularly strong overlap was observed between face and voice responses (19–59%, mean = 36%), face and biological motion responses (15–39%, mean = 30%), and ToM and language responses (11–50%, mean = 29%). Relatively high values were also observed for overlap between ToM and face responses (16–39%, mean = 24%), and ToM and voice responses (9–35%, mean = 20%). This indicates in addition to focal regions with selective response profiles, the STS contains parts of cortex that respond significantly to social information from multiple domains.
   
Overlap matrices for regions of activation defined by each task contrast. Each cell in a given overlap matrix is equal to the size of the overlapping region for the tasks on the corresponding row and column, divided by the size of the region of activation for the task on that row, as shown in the graphic on the left-hand side. 
  

We next assessed how overlap values vary as a function of amount of smoothing and the statistical threshold used to define regions.   Supplementary Figures 5   and   6   show overlap matrices at smoothing kernels of 5-, 3-, and 0-mm FWHM, and thresholds of   q   < 0.05,   q   < 0.01, and   q   < 0.005. As expected, using stricter thresholds and less spatial smoothing lead to numerically smaller overlap values, with spatial smoothing appearing to have a greater influence in the range of parameters tested. For example, face/voice overlap had a mean value of 42% at   q   < 0.05 and 5-mm FWHM, and a mean value of 28% at   q   < 0.005 and no smoothing. Nevertheless, a similar pattern of overlap values across pairs of contrasts was observed across thresholds and smoothing kernels. In particular, relatively strong overlap between responses to language and ToM, faces and voices, and faces and biological motion were consistently observed. In contrast, overlap between responses to ToM and faces, as well as ToM and voices, decreased substantially as less smoothing was used. This may indicate that this overlap was introduced by spatial blurring of distinct regions; alternatively, it is possible that the increased signal-to-noise ratio afforded by smoothing is necessary to detect this overlap. 

Lastly, we investigated response profiles of overlapping regions, by defining overlapping ROIs in one half of the dataset, and extracting responses from left-out, unsmoothed data (Fig.  ). We focused on pairs of contrasts for which substantial overlap was consistently observed.
   
Responses (in percent signal change) of overlapping regions responsive to multiple contrasts, across all conditions. Responses were measured in data independent of those used to define the ROIs. 
  

The language and ToM region responded substantially above baseline for all language conditions, with a near-zero response to all other conditions, and was additionally modulated by the presence of mental state content. Significant effects of the language contrast were observed in both hemispheres (RH:   t   = 6.31,   P   < 10 ; LH:   t   = 4.56,   P   < 10 ). Effects of the ToM 2 contrast were also significant bilaterally (RH:   t   = 4.59,   P   < 10 ; LH:   t   = 2.74,   P   < 0.01), while effects of ToM 1 were significant in the right hemisphere (  t   = 3.08,   P   < 0.01) and marginal in the left (  t   = 1.86,   P   < 0.05). 

The face and voice region had a roughly similar response profile to the pSTS region defined by a face contrast, with a moderately sized response to both dynamic faces and vocal sounds. The effect of the Voice 1 contrast was significant bilaterally (RH:   t   = 9.00,   P   < 10 ; LH:   t   = 5.38,   P   < 10 ), as was the effect of the Voice 2 contrast (RH:   t   = 4.50,   P   < 10 ; LH:   t   = 2.93,   P   < 0.01). There was also a significant effect of faces over objects bilaterally (RH:   t   = 5.12,   P   < 10 ; LH:   t   = 4.68,   P   < 10 ). This region also had a weak but reliable response to the ToM contrasts: ToM 2 bilaterally (RH:   t   = 3.50,   P   < 0.01; LH:   t   = 4.45,   P   < 10 ) and ToM 1 in the right hemisphere (  t   = 3.75,   P   < 0.01), and marginally in the left hemisphere (  t   = 2.05,   P   < 0.05). This response appeared to be driven by overlap with the mid-STS ToM response. 

The face and biological motion region had a moderate response to faces, a relatively weak response to biological motion, and a response to vocal sounds of variable effect size. This region responded significantly to faces over objects bilaterally (RH:   t   = 10.15,   P   < 10 ; LH:   t   = 6.64,   P   < 10 ). There was also a significant effect of biological motion in the left hemisphere (  t   = 3.33,   P   < 0.01), but not in the right. The lack of an effect in the right hemisphere, however, appeared to be driven by a single outlier with a strongly negative effect of biological motion; there was a significant effect after removing this participant (  t   = 3.82,   P   < 0.01). Additionally, there was a significant effect of the Voice 1 contrast bilaterally (RH:   t   = 5.01,   P   < 10 ; LH:   t   = 4.61,   P   < 10 ), and the Voice 2 contrast in the left hemisphere (  t   = 3.15,   P   < 0.01) and marginally in the right hemisphere (  t   = 1.83,   P   < 0.05). Lastly, there was a weak but significant effect of the ToM 1 contrast in the left hemisphere (  t   = 2.84,   P   < 0.01). These results indicate that, while there is a pSTS region responsive to both dynamic faces and biological motion, it only responds weakly to biological motion, with a much stronger response observed in the more selective biological motion area. Furthermore, this region appears to also have a substantial response to vocal sounds, of magnitude similar to or stronger than the response to biological motion. 



## Discussion 
  
We investigated STS responses to a number of social cognitive and linguistic contrasts, and found that patterns of response along the length of the STS differed substantially across each contrast. Furthermore, we found largely selective subregions of the STS for ToM, biological motion, voice perception, and linguistic processing, as well as a region that specifically responds to dynamic faces and voices. Contrary to claims that there is little systematic spatial organization to the STS response to different tasks and inputs ( ), these findings argue for a rich spatial structure within the STS. In addition to these selective areas, regions responsive to multiple contrasts were observed, most clearly for responses to language and ToM, faces and voices, and faces and biological motion. These results indicate that the STS contains both domain-specific regions that selectively process a specific type of social information, as well as multifunctional regions involved in processing information from multiple domains. 

Our analysis of resting-state functional connectivity of STS subregions supports the argument for systematic spatial organization in the STS. Our results point to distinct patterns of functional connectivity within the STS, suggesting the presence of fine-grained distinctions within the 2–3 patterns observed in prior studies ( ;  ;  ). Furthermore, we show that these connectivity differences are linked to differences in response profiles, consistent with the broad claim that areas of common functional connectivity also share common function ( ). Contrary to the claim that STS subregions are recruited for different functions based on their spontaneous coactivation with other brain regions ( ), these results paint a picture in which STS subregions have stable, distinct response profiles and correspondingly distinct patterns of coactivation with the rest of the brain. 

The STS regions found to respond to each contrast in the current study are broadly consistent with regions reported in prior studies. Prior studies using ToM tasks have most consistently reported the posterior-most TPJ region ( ;  ;  ;  ;  ;  ;  ;  ;  ), but some have also reported middle and anterior STS regions like those observed in the present study ( ;  ;  ). At least 2 prior studies have investigated responses to both ToM and biological motion, and both found that the response to biological motion was anterior to the TPJ region elicited by ToM tasks, as observed in the present results ( ;  ). Consistent with prior arguments, the right TPJ region observed in the current study was strongly selective for mental state reasoning, among the tasks used here. 

Studies of face and biological motion perception have found responses in a similar region of pSTS ( ;  ;  ;  ;  ). In the present study, we observe overlapping responses to faces and biological motion in the pSTS, consistent with a recent study on responses to biological motion and faces in a large set of participants ( ). However, we find that the pSTS region responding to faces is slightly but reliably anterior to the region responding to biological motion, and that it is possible to define a maximally biological motion-sensitive region of pSTS that has no response to faces over objects. Thus, pSTS responses to faces and biological motion, while overlapping, also differ reliably. The finding of a consistent difference in position of face and biological motion responses diverges from the results of  ; this difference could result from the use of dynamic face stimuli in our study. While studies using static faces have typically observed a single face-responsive region of posterior STS, the current results and prior evidence ( ) indicate that dynamic faces engage several regions along the length of the STS, and may engage a posterior STS region with slightly different spatial properties. 

The most striking case of overlap observed in the current study was that between responses to dynamic faces and vocal sounds. This result manifested as a strong voice response in a region defined to be maximally responsive to faces, and substantial overlap between the set of voxels responding significantly to each contrast. This is consistent with prior work finding a region of posterior STS that responds to faces and voices ( ;  ;  ), as well as individual neurons in macaque STS that respond to faces and voices ( ;  ;  ). The strikingly high voice response of a region defined by a face contrast was nevertheless unexpected, and indicates that this region should not be characterized as a “face region,” but rather a fundamentally audiovisual area. This case of overlap seems most plausibly interpreted as suggesting a common underlying process elicited by the 2 broad contrasts used in this study. One possibility is that this region is involved in human identification using both facial and vocal cues. However, this hypothesis cannot easily explain the strong preference for dynamic over static faces in this region ( ). Another possibility is that this region is involved in audiovisual processing of speech and/or other human vocalizations. Alternatively, this region might be more generally involved in processing communicative stimuli of different modalities. Further research will be necessary to tease apart these possibilities. 

In addition to a region of overlapping response to faces and voices, a further-anterior region responded highly selectively to vocal stimuli. This region was centered on the upper bank of the middle STS, consistent with prior reports ( ). 

Language responses have been observed along the entire length of the left STS ( ;  ), consistent with our results. In our data, language responses were strongest bilaterally in a far-anterior region of STS, a pattern that prior studies have not noted. Unlike most prior studies, the sentences used in our language contrast involved no human characters whatsoever (nor any living things at all), to dissociate language from social reasoning. This difference might account for the slight divergence between our results and those of prior studies. 

Another case of particularly strong overlap occurred between responses to language and ToM. The left TPJ region defined by a ToM contrast was modulated by linguistic content, and the bilateral anterior language regions were both modulated by mental state content. We also observed substantial overlap between language and ToM responses across the STS: roughly half of voxels with a language response also had an effect of ToM content. While not observed previously, this observation is consistent with prior reports that regions elicited by ToM and semantic contrasts both bear a rough, large-scale resemblance to default mode areas ( ;  ). While relationships between language and ToM in development have been extensively documented ( ), lesion evidence indicates that these functions can be selectively impaired in adults ( ,  ). Nevertheless, the finding of strong overlap between language and ToM responses is intriguing and should be explored further. One potential account of the effect of ToM in language regions is that the presence of agents is an organizing principle of semantic representations in these regions. 

Based on fMRI overlap results, we have argued that, at the spatial resolution of the present study, STS responses to certain types of social information overlap, in some cases substantially. However, a number of caveats must be made regarding the interpretation of fMRI overlap data. For a number of reasons, it is impossible to directly infer the presence of overlap in underlying neural responses from overlap in fMRI responses, which measure a hemodynamic signal at relatively low resolution. For one, fMRI measures signal from blood vessels, and stronger signal is obtained from larger vessels that pool blood from larger regions of cortex ( ). Next, fMRI is a relatively low-resolution measure (typically ∼3 mm), pooling responses over hundreds of thousands of individual neurons, and further structure likely exists within the resolution of a single voxel. Lastly, fMRI data are both intrinsically spatially smoothed by the use of   k  -space sampling for data acquisition, and typically smoothed further in preprocessing, to increase signal-to-noise ratio. In the present study, we mitigate this concern by measuring overlap at different smoothing kernels, and assessing response profiles of overlapping regions using spatially unsmoothed data. 

The above points establish that fMRI can miss spatial structure at a fine scale. Thus, in principle, functionally specific STS subregions within the overlapping regions observed here could exist at finer spatial scales. Nevertheless, the present results argue for substantial overlap at the typical resolution of fMRI studies, which is not merely induced by spatial smoothing during preprocessing, and is robust to differences in the statistical threshold used to define regions. 

We have argued that the STS contains subregions with distinct profiles of fMRI responses, resulting from distinct underlying neuronal selectivity profiles. Could the differences observed here instead relate to other influences on contrast-to-noise ratio, such as differences in signal reliability across regions, or differences in the efficacy of different stimulus sets in driving neural responses? It is unlikely that signal reliability contributes substantially to regional differences, given that these regions are roughly matched on tSNR (and despite slightly lower tSNR in voice regions, these areas had among the strongest category-selective responses observed). The paradigms we used were designed to be similar in basic ways (e.g., mostly blocked designs, with ∼5 min of stimulation per condition), but could nevertheless differ in their ability to drive strong responses. For instance, they might differ in variability along stimulus dimensions encoded in a given region, which is impossible to judge without knowing these dimensions. We consider it unlikely that this accounts for the substantial differences across regions observed here, given that 1) each task drove strong responses in at least some STS subregion; and 2) for tasks that evoked the most spatially extensive responses (ToM and voices), we found similar responses across 2 tasks, suggesting that these were somewhat robust to stimulus details. Nevertheless, it is important to note that differences in the efficacy of different tasks could have influenced the response magnitudes reported here. 

Another general limitation of this study is that while we would like to identify regions of the STS that are involved in specific cognitive and perceptual processes, we instead use the proxy of identifying regions of the STS that respond in a given task contrast, as in any fMRI study. There is presumably no simple one-to-one mapping between processes or representations and broad pairwise contrasts. Given that we have little knowledge of the specific processes underlying social perception and cognition, it is difficult to determine the appropriate mapping. For instance, our face stimuli presumably elicit processes related to the perceptual processing of faces (which itself is a high-level description that likely comprises multiple computations), but they also contain specific types of biological motion (eye and mouth motion), which might be processed via separate mechanisms. These stimuli could also trigger the analysis of intentions or emotional states of the characters in the clips. Likewise, our ToM contrasts are intended to target mental state reasoning, but the ToM condition in both contrasts is more focused on human characters, and thus some of the responses we observe may relate to general conceptual processing of humans or imagery of human characters (although note that prior studies have found TPJ responses using tighter contrasts ( ;  )). Generally, it is important to emphasize that the activation maps we describe presumably comprise responses evoked by a number of distinct processes, which future research will hopefully tease apart. 

In sum, the present study converges with prior research to indicate that the STS is a key hub of social and linguistic processing. Our method of testing each subject on multiple contrasts enables us to rule out prior claims that the STS represents a largely homogenous and multifunctional region ( ), instead revealing rich spatial structure and functional heterogeneity throughout the STS. Specifically, the STS appears to contain both subregions that are highly selective for processing specific types of social stimuli, as well as regions that respond to social information from multiple domains. These findings paint a picture in which the extraordinary human capacity for social cognition relies in part on a broad region that computes multiple dimensions of social information over a complex, structured functional landscape. This work opens up myriad questions for future research, including which specific computations are performed within each subregion of the STS, how the functional landscape of the STS differs in disorders that selectively disrupt or selectively preserve social cognition (e.g., autism and Williams' syndrome respectively), and whether the spatial overlap observed here is functionally relevant, or whether it reflects distinct but spatially interleaved neural populations. 


## Supplementary Material 
  
 Supplementary material can be found at: http://www.cercor.oxfordjournals.org/  


## Funding 
  
This study was supported by grants from the Packard Foundation (to R.S.), and NSF (graduate research fellowship to B.D., CCF-1231216 to N.K. and R.S.). Funding to pay the Open Access publication charges for this article was provided by The Ellison Medical Foundation. 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-12'>
<h2>12. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22003388/' target='_blank'>22003388</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Predicting Decisions in Human Social Interactions Using Real-Time fMRI and Pattern Classification</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2011</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0025304</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3189203/' target='_blank'>3189203</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Study used fMRI while healthy adult humans (male, 23–28 years) completed a social task (ultimatum game). Imaging included whole-brain acquisition and analyses: the paper reports offline whole-brain classification, leave-one-subject-out cross-subject models, and lists discriminating volumes (voxelwise weight maps) from SVM analyses. Participants were healthy (no psychiatric/neurological disorders) and within the 18–60 age range. Although the online analysis used predefined ROIs, the presence of whole-brain results and reported discriminating brain volumes meets the whole-brain criterion. This is an empirical fMRI study (not a review/meta-analysis). Therefore it satisfies all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Negotiation and trade typically require a mutual interaction while simultaneously resting in uncertainty which decision the partner ultimately will make at the end of the process. Assessing already during the negotiation in which direction one's counterpart tends would provide a tremendous advantage. Recently, neuroimaging techniques combined with multivariate pattern classification of the acquired data have made it possible to discriminate subjective states of mind on the basis of their neuronal activation signature. However, to enable an online-assessment of the participant's mind state both approaches need to be extended to a real-time technique. By combining real-time functional magnetic resonance imaging (fMRI) and online pattern classification techniques, we show that it is possible to predict human behavior during social interaction   before   the interacting partner communicates a specific decision. Average accuracy reached approximately 70% when we predicted online the decisions of volunteers playing the ultimatum game, a well-known paradigm in economic game theory. Our results demonstrate the successful online analysis of complex emotional and cognitive states using real-time fMRI, which will enable a major breakthrough for social fMRI by providing information about mental states of partners already during the mutual interaction. Interestingly, an additional whole brain classification across subjects confirmed the online results: anterior insula, ventral striatum, and lateral orbitofrontal cortex, known to act in emotional self-regulation and reward processing for adjustment of behavior, appeared to be strong determinants of later overt behavior in the ultimatum game. Using whole brain classification we were also able to discriminate between brain processes related to subjective emotional and motivational states and brain processes related to the evaluation of objective financial incentives. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (44181 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Neuroscientific studies of the brain mechanisms of social decision-making offer new insight which helps to incorporate human behavior into economic models. In the framework of neuroeconomics, cognitive and neural constraints of the complex processes of social decision-making are explored  – . Experimental paradigms from game theory are well suited to the investigation of neural correlates of decision-making, because profound empirical insight into human behavior is provided  ,  . 

Using a real-time noninvasive technique based on fMRI, we investigated the neural correlates of social decision-making and tried to already infer the decisions made by participants involved in social interaction from brain activation during scanning. We employed a well-established economic game called the ultimatum game (UG), in which two players split a given amount of money. One player acts as the proposer, retaining one share of the money and offering the remaining share to the other player (the responder). The responder can either accept or reject the proposer's offer. If the offer is accepted, the money is split as proposed. If the offer is rejected, neither player receives anything. According to the notion of profit maximization, the proposer is expected to offer the smallest possible sum of money and the responder to accept this offer, because even the smallest profit is preferable to no monetary reward  . Contrary to this assumption, it has been repeatedly shown that the results of negotiation in this game do not conform to the expected game-theoretic equilibrium outcomes. Instead, low (unfair) offers of 10–20% of the total sum of money are rejected in more than 50% of cases  ,  , suggesting that emotions, attitudes, and expectations influence players' decisions. 

Social interaction as in the ultimatum game may lead to conflicts between players' goals and internal attitudes and social norms, which elicit emotions. These conflicts require considerable cognitive effort to be resolved  ,  ,  . Consequently, previous fMRI studies on decision-making report the involvement of cortical and subcortical brain regions related to cognitive control, such as prefrontal cortex, anterior cingulate cortex, and regions connected to emotional response such as amygdala and insular cortex (for a review see  ). Decision-making processes in social interaction scenarios have already been examined using functional magnetic resonance imaging (fMRI)  ,  ,  ,  . For example, Sanfey et al. reported activation of anterior cingulate cortex, anterior insula, and dorsolateral prefrontal cortex when presenting unfair offers vs. fair offers in a single-shot version of the UG  . In the single-shot UG, the responder plays just one trial against a single proposer, whereas in the repeated UG, a responder interacts repeatedly with the same proposer. Generally, the behavior in the repeated version of the game is influenced by strategic reasoning and the interaction of the players is more competitive than in the single shot version  . 

However, the statistical analysis used in these studies relies on the comparison of mean blood oxygen level dependent (BOLD) signals calculated from many trials, leaving the question open whether these effects are strong enough to be reliably detected in   single   decisions   before   the decision is revealed by the subject, and without prior knowledge of the actual offer in the trial  . Multivariate classification is well suited to such a “brain-reading” task. Brain states have been decoded from the temporal and spatial patterns in fMRI data  – . The application of pattern classification to fMRI data was done in the fields of fear perception  , visual perception  , goal-related intentions  , or lie detection  . However, in conventional fMRI decoding, these methods are applied offline in the post-experimental analyses. We aimed to predict the decisions before volunteers communicated them and therefore combined the multivariate classification of brain states with real-time fMRI (rtfMRI). This technique allows for online analysis of BOLD activity, for example in the framework of brain computer interfaces  – . To date, real-time multivariate analysis of fMRI data has been conducted in very few studies  – . La Conte et al. and Sitaram et al. combined whole-brain classification and rtfMRI to implement neurofeedback experiments. Posse et al. combined a classifier with neuroanatomically constrained boosting to analyze rtfMRI data recorded during visual stimulation, finger tapping, auditory attention, and mental calculation. In none of these studies were the online data used to continuously retrain the classifiers during the experiment to improve classification performance. 

Here our goal was to discriminate complex brain states occurring in social interactions on the basis of the BOLD signal in a small number of distinct brain regions in real time. Including only few relevant brain areas allowed us to adapt the model parameters of a Relevance Vector Machine (RVM) classifier   during the ongoing experiment to improve online classification performance. In a second offline analysis step, we trained a multivariate pattern classifier on the whole brain across subjects and tested the transfer of the brain activation over subjects. This latter step allowed us to   a posteriori   evaluate if the pre-selected brain areas used in the online approach were adequate. We were also able to investigate hypotheses about the role of brain processes related to subjective emotional and motivational states during decision-making and to distinguish them from brain processes related to the evaluation of an objective financial incentive. 


## Materials and Methods 
  
### Subjects and paradigm 
  
Ten healthy male subjects (23–28 years, mean: 24.7±1.6 years) with normal or corrected to normal vision were examined after providing written informed consent. The experiments were approved by the local ethics committee of the Medical Faculty of the University of Magdeburg. One subject was excluded from the study after reporting doubts about whether he was playing with human partners. Data from two subjects served for the initial training of the classifier that was subsequently used to examine seven subjects. To avoid cross-gender effects, only male volunteers participated in the study  . 

At the beginning of a session, participants met two male individuals, who were introduced to them as the proposers in the UG. Participants were told that the actual proposer would be chosen randomly from these two individuals for each single trial and that proposers do not interact with each other during the experiment. This procedure was chosen because personal contact between responder and proposer is considered to be an essential prerequisite to establishing a social bond between players  ,  ,  . During scanning, the actual offers were made by a computer in a predefined order. This ensured a controllable set of offers. 

Brain activity was measured and analyzed using rtfMRI and real-time pattern classification while each volunteer completed 60 trials of 22 s length each. In each trial the amount to be split was shown for 2 s. Subsequently, the offer was shown to the volunteer for 12s. The BOLD signal of the first 10 s after showing the offer was used to predict the upcoming decision. During the following response phase of 4 s length, participants pressed one of the two buttons to convey their decision. Finally, the payoff in the current trial was presented for 4 s and the next trial started immediately (see   for the trial design). The amount of money to share was 3 euros in every trial and five types of offers were presented at the following rates (percentage of 3 euros share for proposer: responder): 6×50∶50, 8×65∶35, 12×70∶30, 21×80∶20, 13×90∶10. These offers were presented in a random order. As usual in economic bargaining games, reimbursement for the volunteers was determined solely by their earnings in the ultimatum game. During the experiment no cumulative earnings were presented. After the experiment, every participant completed a questionnaire to assess whether he had any doubts about having played with a human partner at any time during the experiment. Also the questionnaire assessed the emotional states during the experiment and the perceived decision behavior concerning timing and fairness. 
   Single trial design in the ultimatum game with cumulative event times.  
 (a)   Each trial started by displaying the amount to be split (3 euros) for 2 s.   (b)   Subsequently, the offer was shown to the volunteer, who then had 12 s to make up his mind. This time was required for BOLD activity to build up and to subsequently use it to predict the upcoming decision. The classification result was indicated to the experimenter 1–2 s   before   the response screen   (c)   was shown to the participant. During the response phase (4 s), participants pressed one of the buttons to convey their decision. After the response, the payoff (split sum as proposed when the offer was accepted or no money for both players when offer was rejected) in the current trial was presented for 4 s   (d)  . The outcome of a rejected offer is shown. 
  
Stimuli were backprojected with an LCD beamer onto a transparent screen. Subjects had to press buttons with their left or right index finger to convey their decisions on the given offers. The mapping between buttons and responses (for either accepting or rejecting) was switched randomly for each trial and displayed at the beginning of each response phase. This prevented the classifiers from using brain activity related to preparation of motor responses  ,  . 


### Imaging protocol and real-time prediction 
  
The blood oxygen level dependent (BOLD) response was measured in a 3 Tesla whole-body MRI scanner equipped with Avanto gradient system (Siemens Medical Systems, Erlangen, Germany). The imaging protocol consisted of a gradient echo EPI sequence for BOLD imaging with repetition time (TR) of 2 s, time to echo (TE) of 29 ms, and a flip angle of 90°. Thirty-one slices with axial slice orientation covering the whole brain were acquired. The matrix size was 64×64 and spatial resolution was 3.4×3.4×4 mm . 

The vendor's EPI BOLD sequence (system version VA25A) and the corresponding image reconstruction programs were modified to export each EPI volume immediately after acquisition and internal motion correction to the host computer of the MR scanner (see   for a scheme of the hardware and the dataflow). All further preprocessing steps, statistical data analysis and classification were performed on an external computer (“External PC” in  , Pentium IV, 3.0 GHz, 2 GB Random Access Memory, Windows XP) which received the preprocessed EPI volumes via a 100 MBit/s network connection. 
   Schema of information flow in the experimental setup.  
The components highlighted in gray depict the vendor-specific measurement system (Siemens Trio with SYNGO Version VA25A). Initially, the original MR data are fourier-transformed and motion-corrected by the vendor image processing unit (Image PC). The reconstructed data are then transferred to the host computer (External PC). There the data are processed using custom software (rtExplorer). This software performs pre-processing, statistics, online classification, and documentation of the classification results. The participants' responses are processed in the stimulus PC and transferred to the external PC for evaluation of the classification and for retraining the classifier during the ongoing session. 
  
The locations of the regions of interest (ROIs) used in the online procedures were pre-specified on the basis of functional MRI data from preliminary experiments including two participants (120 trials) using the same experimental paradigm. The results of a whole-brain offline trained Support Vector Machine (SVM) classifier indicated signal changes predictive of the volunteers' decisions in anterior insula, lateral prefrontal cortex, and occipital cortex (see also  ). The informative brain areas revealed in the pilot study were in concordance with those reported in the literature on social interaction where in particular anterior insula and lateral prefrontal cortex were found to be involved in decision making in the ultimatum game  ,  . Therefore, we selected prefrontal cortex, anterior insula and visual cortex as ROIs for the online classification.   lists the MNI coordinates of the centre points and volumes of these ROIs (also shown in  ). 
   The regions of interest (ROIs) used for online classification projected onto anatomical data of one participant.  
Three distinct brain regions were used for classifying the volunteers' decisions: anterior insula (AI), lateral prefrontal cortex (LPFC) and occipital cortex (OC). See   for MNI coordinates and volumes of the ROIs. 
     Regions of interest used in the real-time classification.        
These preliminary data sets were also used to obtain an initial solution for the model parameters of the real-time classifier used in the online experiment. This allowed us to start prediction without first acquiring an exhaustive set of individual data. Importantly, using only a small set of ROIs reduced the feature space sufficiently allowing us to continuously adapt the classifier in real time by retraining with newly arriving individual data. 

In the online experiments, custom rtfMRI analysis software was used to process the incoming image data as soon as they were acquired  . During online processing, data sets were normalized to 3×3×3 mm  MNI space (Montreal Neurological Institute  ) and detrended to remove linear signal drifts. The BOLD signal of homologous left and right brain areas were pooled. Then the mean BOLD signal in the ROIs during the baseline period (1  and 2  scan immediately following the offer) were compared to the mean BOLD signal during the active period (3  to 5  scan) by calculating one t-value per ROI. Note that we only used data acquired during ten seconds immediately following the presentation of the offer to predict the subject's intended decision in single trials. Thus all data for prediction was acquired before the mapping for the manual decision was revealed. Specifically, we calculated t-values comparing the BOLD response in the first four seconds (scans 1&2) and seconds 6–10 (scans 3&4&5) which were fed into the real-time classification. Because the BOLD response requires approximately five seconds to develop  ,   we can use the data acquired in the first four seconds after the offer was presented as a baseline. The BOLD response to the offer can be expected to be fully developed 6–10 seconds after the offer and the difference between BOLD following the offer and baseline is the trial specific effect of the offer. 

The three t-values per trial served as input for the online classifier, a nonlinear Relevance Vector Machine Classifier   (Software available at   www.miketipping.com/index.php?page=rvm  ), was used to decide on each trial   i   whether an offer would be accepted or rejected. The training set   X   of the classification problem is defined as: 

We refer to   y   as decision vector. Its elements   y   take a value of 1 for an accepted offer and 0 for a rejected offer. 

During the experiment, the initial training set (  X  ) was continuously expanded by including the t-values and decision from the   n  -1th trial into the training data (  X  ) of the   n  th trial: 

The classifier was continuously retrained in each trial using the expanded training set. As such, the system adapted the model parameters based on subject-specific activation states in real time and included these in the forecast of volunteers' future decisions to improve classification accuracy. 

The RVM applied in online prediction makes use of Bayesian inference to obtain sparse solutions for classification. By computing a posterior distribution, it provides probabilistic classification and has the same functional form as the well-known Support Vector Machines:  

Here   w   depicts a weight vector and   is a kernel function that can be used to express a non-linear relationship between   x   and   y  . The goal is to compute the posterior probability of class membership   given the input   x   and target class   y  . This is solved by computing the weight posterior  , where α denotes a hyperparameter. More details are described in  . 


### Offline estimation of the guessing level of the real-time classifier 
  
To test the reliability of the online prediction, we determined individual empirical guessing levels to ensure that the online discrimination rates were not obtained by pure guessing but exploit information inherent to the data. The theoretical guessing level of a two-class experiment (e.g. accept or reject an offer) is 50% (perfect coin toss). However, other factors, such as the relative frequencies of the two classes in the training set, may influence the classifiers' strategy and bias the guessing level to much higher values than expected  . 

We estimated individual empirical guessing levels by permuting the decision vectors in each subject's data set. Permutation destroys the coherence between the observed BOLD data and volunteers' decisions but retains other information such as class size ratio. The classifier was then retrained, and all trials were classified according to the new training set. These steps were repeated 500 times to estimate the mean guessing level and the 95% confidence interval. Empirical guessing levels were calculated as the geometric mean of the guessing levels for the classes accept and reject  . Only if the correct prediction rate of the classifiers in the actual experiment exceeded the 95% confidence interval of the empirical guessing level estimates did we assume that the classifier learned from the inherent structure of the data  . 


### Offline whole brain classification 
  
Additional offline classification was performed to assess classification performance achievable using BOLD data from the whole brain and to further investigate the neural correlates of the decision process. Preprocessing included motion-correction, spatial smoothing with a 9 mm Gaussian kernel, and linear detrending. Furthermore, low-frequency signal fluctuations were removed using a high-pass filter with a cut-off frequency of 0.01 Hz, and BOLD volumes were normalized to 3×3×3 mm  MNI space. Non-brain voxels were excluded by applying a MNI brain template. Before combining the BOLD-data over subjects we first z-scored every subject's data individually. This normalization was done voxel-wise and as a result the BOLD-time series of each voxel had a mean of 0 and a standard deviation of 1. The volumes of the 2 , 3 , and 4  scan after the presentation of the offer were averaged for every subject. This resulted in 420 average functional brain volumes serving as single samples for whole brain classification. Our learning algorithm thus provides a cross-subject model based on single trial data. We then used this to classify the single trial data of the single subject excluded from the classifier training. 

The 2 , 3 , and 4  volumes after offer presentation were chosen because the participants reported in the post-scanning questionnaire that they made their internal decisions quickly (i.e. always in less than 5 seconds) after an offer was revealed and always before the accept/reject screen was shown. We thereby also avoided including information about the actual motor response, because in the interval included the participants did not know the mapping of the two buttons for accepting or rejecting the offer. 

We used feature selection, a very common approach in pattern classification, to reduce the number of features (voxels) in the input space. This was done on a training set by correlating signal changes with the volunteers' two different decisions. Voxels with correlation values between −0.15 to 0.15 were excluded. Since we wanted to analyze which voxels the trained classifier judged as informative we chose this relatively liberal value to somewhat reduce the number of voxels used for classification without being overly restrictive. Approximately 10  voxels were retained for subsequent classification using this criterion. 

For offline classification, we used a publicly available implementation of a SVM  . We used a linear classifier because it allows direct analysis of informative features learned during training  . Generalization performance was tested in a leave-one-average-volume-out cross-validation (LOOCV) which also included feature selection. In LOOCV, one trial is excluded from feature selection and training. The trained classifier is then used to predict the class label of the excluded trial. These steps are repeated for all trials, and the result (the percentage of correct classified decisions) represents a measure of the generalization power of the classifier. The correct prediction rate is finally calculated as: 


### Guessing level of the whole brain classification and discriminating volume 
  
Theoretical and empirical guessing levels were determined analogous to the approach in real-time prediction, in a permutation test with 500 repetitions. 

We extracted the spatial patterns used by the classifier to discriminate between different brain states from the weight vector   w   (Eq. 3). Therefore,   w   was transformed from feature space into the original voxel space and scaled to the length of one. The absolute weight value of each voxel reflects its importance for the discrimination of brain states. To obtain a probability distribution of the weight for each voxel, we permuted the class labels 1000 times. This provides a probability distribution under the null hypothesis of no relationship between class labels and the intrinsic structure of the data  . Based on these distributions, we computed the p-values for each voxel to determine which voxels were significantly predictive for the class label. The threshold for the reported discriminating volumes was set to p<0.05 (uncorrected). 



## Results 
  
### Behavioral analysis and real-time prediction 
  
The percentages of acceptance for the five types of offers are depicted in  . The acceptance/rejection ratios are in accordance with previous studies employing the repeated UG  – . A dramatic drop in the acceptance rate for offers around 20% or less of the amount to be split indicates that these offers were judged as unfair by our participants. 
   Overall percentage of acceptance rates of the offers in the ultimatum game.  
Values are calculated as rate of accepted offers over seven volunteers. Labels on the x-axis show the split rate: (proposer: responder). 
  
As depicted in  , the average online prediction accuracy reached 69.7%±2.4%. The average empirical guessing level derived from permutation tests was 52.3%±2.8% (average 2.5% and 97.5% quantiles were 47.2% and 55.3%, respectively). The real-time prediction accuracy was significantly above guessing level (p<0.0038, binomial distribution). The significant prediction results show that the classifier captured information about rejection or acceptance of an offer which was available in brain activity before the participant revealed his decision. With our approach, we were able to predict the participants' decisions 1–2 s before their response ( ). The online processing algorithm (pre-processing, real-time classification) was executed in less than 0.5 s (time required for retraining of the classifier was 0.4 s on average). 
   Real-time prediction accuracy of the RVM classifier in the ultimatum game.  
The arrows mark the empirical guessing levels. 
  
To assess the gain in correct predictions achieved by continuously retraining the classifier, we simulated the online procedure both with and without retraining. The overall prediction accuracy increased by 10.7% when novel data were used to retrain the classifier showing a clear benefit of retraining with individual data ( ). 
   Improvement of online prediction due to continuous retraining.  
The number of additional correct predictions using individual data acquired during the experiment in a sliding window of six trials are shown. Each window includes 42 single predictions (6 trials times 7 subjects). 
  
In addition to binary classification accuracy, RVM classification provides a continuous posterior probability estimate for each classified decision. The mean probability estimates for the five types of offers are depicted in  . Acceptance of an offer is indicated by a probability exceeding 0.5. 
   Mean posterior probabilities for accepting an offer assigned by the RVM to single offers in the UG.  
Means and standard deviations plotted were calculated over the seven volunteers tested in online analysis. The labels on the x-axis depict the split rate: (proposer: responder). 
  
The analysis of the activation of the signal variation immediately following an offer showed a clear difference between frontal and posterior ROIs. Higher BOLD signal in AI and LPFC predicted rejection, whereas a higher BOLD signal in OC predicted acceptance of an offer ( ). This finding suggests different functional roles during the evaluation of the offer for frontal and posterior sensory areas. 
   Mean fMRI signal differences in the ROIs used in the online UG to predict acceptance vs. rejection for the five types of offers.  
Differences were calculated between 1  to 2  and 3  to 5  scan after the offer and averaged over the seven participants. Bold signal in AI (slope linear fit 0.062, p<0.05) and LPFC (slope linear fit 0.11, p<0.05). In contrast, signal decreases in OC when the likelihood of acceptance decreases (slope linear fit −0.16, p<0.05). 
  

### Offline whole brain classification 
  
In an additional offline analysis, we pooled the single trial fMRI data from all but one subject (leave on subject out) to train classifiers and test generalization among subjects. This improved the correct classification rate greatly to an average of 81.2%. The average guessing level of the offline classification determined in permutation tests was 51.1%±2.3% SD (average 2.5% and 97.5% quantiles were 47.3% and 55.1%, respectively). Again, the correct classification rate clearly exceeds the 95% confidence interval for guessing. This results clearly shows that there is information about rejection or acceptance of a decision in the BOLD data that is similar among participants. Moreover, this analysis allowed us to derive brain areas informative about a participant's decision from a larger set of subjects and to validate the choice of the ROIs in the online experiment.   lists the discriminating volumes extracted from the trained linear SVM (see also  ). Importantly, the brain areas revealed by this analysis include the predefined ROIs used for real-time classification. Both, bilateral LPFC and OC were revealed as informative by the classifier. The only discrepancy was that bilateral AI was used in the online experiment but the offline classifier revealed only right AI as an informative ROI. In addition, offline classification found informative differences consistent over subjects in medial frontal gyrus (MFG), ventromedial prefrontal cortex (vmPFC), ventral striatum (VS), CRUS I in cerebellum, right orbitofrontal cortex (OFC), and posterior superior temporal sulcus (pSTS). 
   Volumes discriminative for decisions in the offline classification.        
The decision process we investigated so far includes at least two sub-processes: one related to the evaluation of the offer (e.g. low or high earning) and another related to the choice of the response (reject or accept an offer). We analyzed our data according to choices in the previous offline analysis. However, since choice and offer value are correlated over the full scale of offers it is possible that BOLD activity related to evaluation of offer value is more predictive about the subjects' UG responses than choice related BOLD activity, at least on the full scale of offers. To investigate this hypothesis each trial received two labels: one for the offer (low or high) and one for the choice (accepted or rejected) and we trained two classifiers with trials of the same dataset sorted in the two different ways (choice or value). The datasets used for classifier training have to be balanced with respect to each of the four possible label combinations (low/accept, high/accept, low/reject, and high/reject) to avoid unwanted classifier bias. In order to maximize the number of trials available in the four label combinations we distinguish high from low offers around the categorical decision border between 80∶20 and 70∶30 split rates where acceptance rate sharply drops. We labeled 50∶50, 65∶35, and 70∶30 trials as high offers and 80∶20 and 90∶10 trials as low offers. The combination reject/high offer contained the lowest number of samples (n = 19), restricting the number of trials used in the other three combinations in the training of the classifier. In order to avoid selection bias, we evaluated classifier performance on 200 balanced subsets of 76 samples each of which included the 19 rejected/high offers and 19 samples randomly drawn from each of the other three label combinations. The average LOOCV classification accuracy revealed that it was possible to discriminate high from low offers on the basis of the single trial BOLD activity (65.9% correct ±6.2% SD) with some success. On the contrary, discrimination according to choice (accept/reject) was around chance level (56.4% correct ±5.9% SD). This result indicates that brain processes related to the evaluation of offer value rather than the choice related activation allows the prediction of the subject's response on the wide range of offer values used in the offline prediction. 

Although no systematic brain activation difference related to choice (reject/accept) may exist over a wide range of offer values, this does not rule out, that a strong link between choice and brain activity exists that may manifest in a predictable and restricted regions along the offer scale where a large change in choices (accept/reject) is found. In the following analysis we aim to demonstrate such an isomorphism between brain activity and behavior for choice related activity. The reasoning behind this analysis follows previous work from us and other groups  ,   and is outlined below. We assume that brain activation related to choice should easily discriminate between two adjacent offers if these differ greatly in their acceptance rate and little if they differ little in their acceptance rate. Behaviorally, trials with split rates 50∶50, 65∶35, and 70∶30 trials were mostly accepted and trials with 80∶20 and 90∶10 trials were mostly rejected. Discrimination between trials with different offers within the same category (accepted or rejected) should be low because choice related brain activity should be very similar in trials from the same category. Importantly, choice related brain activity should reproduce the categorical border between acceptance and rejection of offers observed between 70∶30 and 80∶20 split ratios. Consequently, a classifier trained to discriminate between trials either of these two split ratios should produce particularly high discrimination rates because these offers cross the category border between acceptance and rejection. In addition, classifiers trained on adjacent pairs of offers from within a category should be less discriminable. 

We tested this prediction by training an SVM in an LOOCV to discriminate between adjacent offers. Therefore, we repeatedly (200 times) selected 42 examples from each split rate. The number of trials used per repetition was limited by the class with the lowest number of examples, in this case the number of trials in the 50∶50 split rate. In concordance with our hypothesis we found the highest discrimination rate between trials from 70∶30 and 80∶20 splits (71.4%±5.53% SD). The single trial discrimination rate was at guessing level for the comparisons among trials between split rates 80∶20 vs. 90∶10 (53.4%±5.3% SD), and 65∶35 vs. 70∶30 (54.6%±4.7% SD), and moderate for the discrimination between split rates 50∶50 vs. 65∶35 (65.9%±5.2% SD). It is important to note that this pattern of results cannot be explained by value differences between offers. The 70∶20 offer differs by 10% (or 0.3 Eurocent) from the 80∶20 offer, the same amount the 80∶20 differs from the 90∶10 and even less than the 65∶35 differs from the 70∶30, and the 50∶50 from the 60∶35 offer ( ). This result indicates that there exists informative brain activity that reflects choice rather than evaluation of the offer value. The discriminative brain areas found at the choice category border 70∶30 vs. 80∶20 are listed in   together with those areas discriminative for offers 50∶50 vs. 65∶35 (see also  ). 
   Discriminating volumes found in the offline classification of offers.        


## Discussion 
  
### Real-time analysis of decision processes 
  
In this study, we show that it is possible to predict the behavior of social agents acting as responders in the UG in real time using BOLD measurements of brain activity to detect complex emotional and cognitive states. Offline analyses confirmed the ROIs selected for online prediction on two pilot subjects and the rejection rates. More detailed analyses of the information about split rate and decision outcome available in the BOLD-data strongly supports the notion that brain activity related to expected subjective value of an offer rather than choice predict the subjects behavior over a large range of offer values. the mere decision process. Importantly, we find that information about choice in the BOLD activity predicts the behaviorally observed categorical change from offer acceptance to rejection. 


### BOLD modulation related to emotional and regulatory processes predicts imminent behavior in the UG 
  
We found that AI and LPFC are both predictive of the rejection of an offer on a trial-by-trial basis, in the online as well as in the offline analysis. Both brain areas are involved in emotion regulation and adjustment during social interaction  ,  –  as well as in the evaluation of negative emotions such as disgust  ,  . Increasing activation in AI and LPFC may reflect the experienced level of unfairness which in turn leads to the rejection of the offer in a given trial. In accordance with this interpretation, AI was found to be informative about split level when comparing 70∶30 splits to 80∶20 splits ( ) but not when comparing 50∶50 splits to 65∶35 splits. Moreover, this finding is in concordance with Sanfey et al.  , who also found that higher BOLD activation in AI indicated the rejection of an offer. A competing hypothesis is that activation in AI is not directly connected to the evaluation of negative emotional content but rather refers to attentional processes as reaction to salient environmental stimuli. As part of the ventral attention system the AI is thought to support the reorientation of the attention focus to external stimuli  . In this context it was suggested that activation of the ventral attention system may be connected to switching “internally directed” activities to behaviorally salient external stimuli, also in social cognition  . 

As opposed to AI and LPFC, activation in early visual cortex decreased with unfavorable split rates. It has been shown that attention strongly influences the responses of cortical neurons  ,  . Different levels of attention elicited by offers with different split rates, i.e. a fair offer may induce stronger attention because it reflects fair behavior and higher monetary outcome, may result in different activation in early visual cortex. However, one could also argue that the behavioral relevance is comparable for high and low offers in the UG and thus should lead to comparable attentional effects. The role of attention-related activation in encoding of decision behavior in the presented social context is not fully explored and may be subject to further investigation. 

In sum, the results from the online experiment suggest that activation in brain areas reflecting the subject's emotional and motivational state and self-regulatory processes can be used to discriminate accepted from rejected offers. 


### Reward-related brain areas predictive of altruistic punishment and financial incentive 
  
When playing against a computer that is creating offers in a random order, it makes no sense to reject an offer from an economic perspective. Thus, the participants' best strategy to optimize monetary gain would have been to accept any offer. However, responders in our study rejected unfair offers (20% of 3 euros and less) significantly more often than fair offers. This is the behavior expected in the repeated version of the UG ( ) with two humans playing, and corroborates the participants' reports that they thought they were playing with a human. In such a social setting of reciprocal cooperation, altruistic punishment, sacrificing potential monetary gain, can serve to optimize gains in the long run. 

Thus, in the ultimatum game the acceptance of an offer is correlated with the expectation of a financial incentive but, in addition, hedonic states following costly punishment of an unfair offer may also contribute to adjustment of behavior  ,  . We hypothesized that processing of the financial incentive and altruistic punishment is likely to involve different brain circuits although the same behavioral result, the acceptance or rejection of an offer, is observed  ,  . We probed this hypothesis by comparing the discrimination power of brain activity according to financial incentive vs. discrimination power tracking a categorical change from acceptance to rejection signifying altruistic punishment. We found that BOLD activation in VS signified the categorical border and discriminated between offers with a 70∶30 split rate vs. 80∶20 split rate but not between 50∶50 and 65∶35 offers (  and  ). The first pair differs with respect to the number of accepted offers, whereas the number of accepted offers is approximately equal and the difference in financial incentive is even higher in the second pair. This implies that, in our social setting, activation in VS, an important component of the reward network, is linked to hedonic states following punishment of unfair offers rather than financial incentive. OFC, another informative brain area of the reward circuit, provides similar information. Interestingly, OFC has previously been linked to the evaluation of threatening and/or punishing stimuli that may lead to the adjustment of behavior  ,  . In contrast, ventral medial prefrontal cortices discriminate accepted from rejected offers when all split rates are included ( ) but they do not discriminate 70∶30 from 80∶20 split rate trials ( ) where the categorical transition between accepted and rejected offers occurred. This suggests that, in contrast to VS and OFC, activation in ventral medial prefrontal cortices is related to the evaluation of monetary gain rather than hedonic states following punishment of unfair offers. This is in agreement with results from previous studies linking ventral medial prefrontal cortices to evaluation of primary as well as secondary rewards like monetary gain  . Thus, the result of the offline analysis adds further support to the conclusions that activation in brain areas reflecting the subject's emotional and motivational state and the self-regulatory processes thereof can be used to discriminate accepted from rejected offers in the social UG. 


### Cross subject ROI based probabilistic classification 
  
Unlike other offline “mind reading” approaches (compare e.g.  ,  ), we used a cross-subject approach in the online analysis. Nevertheless, the high prediction rate of 69.7% in the cross-subject procedure confirms the good generalization of the classifier between subjects. This indicates the identification of neural mechanisms that are common between our volunteers. The advantage of this approach is that it allows training of the RVM classifier prior to measurement, simplifying the setup by providing an initial solution of the classification problem without acquisition of additional training trials. Our approach made it possible to predict the subject's choice from the first experimental trial on, although this was with reduced accuracy. Importantly, continuous retraining during the course of the experiment increased classification performance by approximately 11% on average. 

Moreover, RVM provides posterior probabilities for single trial class membership, which can be useful in classification-based neurofeedback (compare  ,  ). Subject-specific offline classification resulted in 81.2% average accuracy and was, as expected, superior to cross-subject online prediction performance. This increase might be partly due to including subject-specific anatomical information but also to the high dimensional feature space we used in offline training. Thus, we would expect improvements in online classification using a more elaborate training scheme that combines non-subject-specific ROI-based classifiers with subject-specific whole-brain classifiers. During an experiment, the classification result would be calculated as a weighted average of the two classification approaches with weights adjusted by the quantity of information available for online classifier retraining. Fast implementations of procedures for preprocessing and training of whole-brain fMRI data are necessary for this approach. 


### Implications of single trial online prediction of social decision-making 
  
Whether a responder in the UG finally decides to reject or accept a specific offer depends on a multitude of internal factors. Among these factors are emotions such as the feeling of being treated fairly as well as rational considerations of reward maximization. The extraction of this information about the way a social agent is tending with a decision in real time   before   the decision was actually revealed can have extensive consequences for negotiations and other social interactions. However, the framework presented here for online decision prediction can also be used to study the link between neuronal and behavioral aspects of human decision-making In future studies, this framework could be used to investigate how decision-making processes are influenced by additional information about the emotional or cognitive state of a communication partner in an “augmented communication” scenario which feeds back information about current hidden brain states of the partner. Our approach could significantly extend previous work on effects of overt social cues in social interaction  ,  , or emotional facial expressions of social agents in bargaining games  . 


### Conclusion 
  
In sum, our results show that, in single trials, it is possible to reliably predict acceptance or rejection of an offer from BOLD measurements of brain activity before the subject reveals the decision with an overt response. However, more detailed analyses indicated that prediction of the decision was based on brain processes related to the perception and evaluation of the offer rather than processes related to the decision itself. Importantly, AI, VS, and LOFC, brain areas related to emotional self-regulation and reward processing for adjustment of behavior, appeared to be strong determinants of overt behavior in the ultimatum game. The decisions derived from the activation in these brain areas paralleled the behaviorally observed categorical transition from high likelihood of acceptance to high likelihood of rejection of an offer when the split rate fell below 70∶30. The framework presented here can be used in future studies to augment information available in social interaction with information about current brain states that remain hidden in traditional approaches. 



## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-13'>
<h2>13. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/23155450/' target='_blank'>23155450</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Effect of Intentional Bias on Agency Attribution of Animated Motion: An Event-Related fMRI Study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2012</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0049053</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3498331/' target='_blank'>3498331</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study reports an event-related whole-brain fMRI experiment in healthy adult participants (n=12, mean age 25.2) performing a social-related task (agency/intentionality attribution to animated agents). Imaging used whole-brain acquisition and SPM2 random-effects analyses with reported whole-brain activation maps (no ROI-only analysis). Participants were screened for neurological/psychiatric disorders (healthy sample). The study is an original empirical fMRI report (not a review/meta-analysis). Therefore it satisfies all inclusion criteria (fMRI during a social task, healthy adults 18–60, whole-brain results) and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Animated movements of simple geometric shapes can readily be interpreted as depicting social events in which animate agents are engaged in intentional activity. However, the brain regions associated with such intention have not been clearly elucidated. In this study, intentional bias was manipulated using shape and pattern animations while measuring associated brain activity using event-related functional magnetic resonance imaging (fMRI). Twenty-five higher-intention involved and twenty-five lower-intention involved animations were presented to participants. Behavioral results showed that the degree of agency attribution of the mental state increased as intentional involvement increased. fMRI results revealed that the posterior superior temporal sulcus (STS), inferior temporal gyrus (ITG), inferior frontal gyrus (IFG), premotor, temporal pole, supramarginal gyrus, and superior parietal lobule (SPL) were activated while participants viewed the high-intention animations. In contrast, occipital, lingual, and middle frontal gyri were activated while the participants viewed the low-intention animations. These findings suggest that as agent attribution increases, the visual brain changes its functional role to the intentional brain and becomes a flexible network for processing information about social interaction. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (29268 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Recent evidence from cognitive social neuroscience has accelerated our understanding of intricate social brain functions, including processes involving the perception of others and their apparent behavior. However, relatively little research has been conducted to evaluate agency and its role in intentional bias. Moreover, there is limited evidence regarding how the intentional brain can be differentiated from the visual brain. For example, some configural cues such as contingent movement of geometrical patterns trigger an agency or animacy detectors in the brain that can partially explain intentional agents such as other people's minds. 

We hypothesize that the specific intentional brain function of estimating others' mental states based on agency attribution is an extended version of the visual brain. This extension involves recruiting higher brain regions found in the temporo-parietal cortices like the superior temporal sulcus (STS)  . The social braininvolves consciousness of one's own and others' mental states, intentions, attitudes, beliefs and motives and, therefore, is closely related to the theory of mind (ToM) and intentional agents. The ToM requires the ability to estimate the intentional states of others. Estimating another's state of mind involves modeling the other person's intention, possibly by agency attribution and one's own past experience. 

Current social neuroscience studies suggest that the superior temporal sulcus (STS) and medial prefrontal cortex (MPFC) are likely essential components of the social brain region involved in intentional tasks. In order to examine this issue, we developed simple animations that manipulated intentional bias (higher- and lower-intention involved animations) by representing geometrical shapes as opposed to complex verbal or visual tasks. 

In their seminal research, Heider and Simmel (1944)   and Michotte (1963)   used simple moving geometrical patterns as intention-involving agents in a local environment (i.e., a house having walls and a door). In Heider and Simmel's classic experiment, observers were asked to interpret a moving-picture film in which three geometrical figures (i.e., a large triangle (“T”), a small triangle (“t”) and a circle (“c”)) moved in various directions. A rectangle (“house”) with a wall section that opened and closed as a door was also shown. In their original film sequence, the animation was as follows. When the door opened, “t” and “c” moved into the “house.” Then, “T” moved into the “house” and shut the door. Next, “T” and “t” fought and “T” won. Finally, “t” and “c” broke through the door and ran away from the house. This work suggests that moving shapes can simulate the actions of living beings and, therefore, can represent agents performing actions. Accordingly the moving shapes are perceived to have goals and to possess qualities of an intentional mind. Therefore, the moving shapes are likely observed as if they represent the intentional states of others. 

In his theory of interpersonal relations, Heider proposed that individuals perceive and create explanations for the behavior of other's, a process he called “attribution”  . Researchers have documented that higher-order cognition involving concepts such as causality and agency can be elicited by observing interactions, but not by observing the independent random movements of simple geometrical objects. If animations could possibly evoke mental state attributions based on intention, we propose that attributions of a mental state can be applied to animated objects. If this supposition is true, it would suggest that the neural substrate associated with understanding intentional events would include the same substrate (i.e., the STS) that becomes active when watching an interactive animated object in cooperation with other regions  . To date, however, there have been few empirical studies to investigate why and how these attributions are affected by animations containing objects with lower- or higher-intentional involvement. 

In mentalization studies in which the ability to estimate another's mind is required, the observer must infer and model the intentions of another person. In this type of paradigm, the observer models the behavior of the other person prospectively by using attributions that are represented as animated dots or cartoons. For example, Baron-Cohen et al. (1994)   found a rCB (regional cerebral blood flow) increase in the orbitofrontal cortex of the right hemisphere during the TOM task. Abel, Happe, and Frith, using two triangles moving around the screen in one of three ways (ToM-like, in a goal-directed way, or randomly), compared the attribution of the mental state in autistic children having less TOM than that of normal children, finding that the former used mentalizing (ToM-like) descriptions less often than the latter did  . 

In another study, Schultz et al. presented short animations to participants in which two moving disks appeared to be either interacting or moving independently from each other  . Using fMRI, they found that activation in the STS increased in proportion to the degree of correlation between the motion of two disks, and that an increase in correlation increased the amount of interactivity and animacy the observers attributed to the two disks. 

Perception of animacy also influences interactive behavior  . Recent fMRI studies using non-Heider & Simmel patterns showed that the STS is also activated by simple moving objects whose interactions appear causal or intentional   and that the STS is involved in the representation of observed intentional actions  . Saxe et al. presented a real movie of a human walking into a room with or without occlusion (e.g., bookcase), finding that the walking figure activated the right posterior STS, which appears to be sensitive to the relationship between the observed motion and local environment  . They further hypothesized that the right posterior STS is involved in the representation of observed intentional actions. 

In a study using PET, Castelli, Happe and Frith presented participants with a silent, computer-generated animation involving two simple geometric shapes (e.g., triangles) that resembled Heider and Simmel patterns  . They found that the STS, MPFC, and temporal regions, including the fusiform gyrus, temporal pole, and occipital gyrus, were activated. The investigators argued that these animations strongly evoked mental state attributions based on intentions and hypothesized that the ability to make inferences about another's mental state evolved from the ability to make inferences about another's apparent behavior. Their findings suggest that controlling the degree of intention from high to low evoked by animations that vary in attribution appears to be critical in this type of research. They had six adult participants observe an animation that involved two moving triangles that manipulated the degree of intention from high to low in three ways: 1) ToM-like, corresponding to high intention; 2) goal-directed, corresponding to intermediate intention; and 3) randomly, corresponding to low-intention intention. These stimuli could therefore be graded from random movements to goal-directed actions, and finally to complex intentional states. 

The primary goal of the current work was to evaluate the degree to which intentional bias could result in greater STS activation and less MPFC activation. Similar animations were used such that objects always stayed within the same local region. However, animations differed in terms of their movements. Specifically, some animations were designed to give a graded impression of either intentional-oriented interactions or mechanical-oriented movements  . In other words, a primary aim of our study was to describe how the social brain is influenced by animations that evoke high intention relative to less or no intention. We sought to replicate and extend the findings of Castelli et al.   using a larger sample and event-related technology, and by grading stimuli based upon random movements, goal-directed actions, and complex intentional states. 


## Methods 
  
### Participants 
  
Twelve healthy, right-handed participants (4 males and 8 females; mean age = 25.2) and fifteen separate participants (11 males and 4 females, mean age = 25.8) were recruited for the fMRI experiment and preliminary rating study, respectively. All had normal or corrected-to-normal vision, and were screened for the presence of current or past neurological and psychiatric disorder. 


### Ethics Statement 
  
The experiment was conducted in accordance with the guidelines of the ethical committees of the Brain Activity Imaging Center (ATR, Kyoto, Japan) and of Kyoto University. All individuals voluntarily participated in the study and provided their written, informed consent prior to study participation. 


### Procedure 
  
The animations used in the study was modeled on that of Heider and Simmel  .   depicts examples of the five-second animations (moving from left to right) used. Two or three triangles of different colors (blue, pink, and green) moved around on a black background. These triangles corresponded to the “t,” “c,” and “T” stimuli used in the Heider and Simmel animation. Additionally, the animation had a “house” with a gap on its side wall. 
   Typical animation strips from high- and low-intention groups, each 5 seconds in length from left to right.  
Three geometrical objects of different colors (blue, red, and green triangle) move around a black background containing a “house,” which has a gap on its side wall. Preceding the experiment, 2 sets of 25 animation movies each were developed that involve high- and low-intentionality groups. The movies varied in terms of the ratio of degree of attribution of mental states to animated pattern. For example, when the door opened, blue and red move into the “house”. Then, green moves into the “house” and shuts the door. Green and blue fights and green wins. Blue and red broke the door and they ran away from the “house” under the highest intentionality condition (rated 5.77), while figures move in parallel under the lowest intentionality condition (rated 1.79). 
  
The upper panel of   shows a high-intention-involved animation (rated 5.77 and corresponding to condition i = 1 in  ; see movies for details). In our preliminary study (see below), one participant reported a ToM-like story corresponding to the high-intention-involved animation as follows: “When the door of the ‘house’ opened, the blue and pink triangles moved in. Then, a green triangle moved in. Green and pink fought and green won. Blue and pink broke out of the ‘house’ and ran away. Based on this script, the two triangles were chased and persecuted by the green triangle and each triangl moved in an interactive way. 
   Samples of matched animation sequence from left to right with a 1 s interval between sequences.  
The upper panel depicts matched pairs (i = 9, r = 9; three triangles) and the lower panel depicts other matched pairs (i = 19, r = 19; two triangles). I = intention; R = random. 
  
The lower panel of   depicts a low-intention-involved animation (rated 1.79 and corresponding to condition r = 1 in  ; see movie file in detail). In our preliminary study (see below), a typical response to a story corresponding to one of the low-intention-involved animations as follows: “Triangles moved merely randomly or drifting without interaction”. By varying the motion path of the triangles, 25 different pairs consisting of one high- and one low-intentionality animation were designed for a total of 50 animations. Interactive motion (two triangles chased and persecuted by the third triangle) was varied by the experimente. In order to test the effect of the number of objects, we used three triangles in all but six pair in which the green triangle did not appear. The animations were created and encoded using Adobe Flash CS3 (30 flames per second, 320×320 pixel). 


### Preliminary study 
  
In the preliminary behavioral study, 15 participants rated each animation based on an intentionality score. The intentional score was rated using a Likert-type scale of 1 to 7 (1: not at all intentional; 7: highly intentional). Next we selected 25 “high” and 25 “low” intentionality animations. Observers were asked to rate intentionality between the blue object and the other objects based on their mutual actions. 

Pairs of high- and low-intention animations were created. Their paths of motion are shown in  . The highest-intention animation was created in a manner similar to the Heider and Simmel   pattern (  upper panel, which corresponds to i = 1 motion path in  ). The lowest intention (i.e., random) animation was made by simple drifting (  lower panel, which corresponds to r = 1 motion path in  ). We also made a series of different intermediate animation pairs for a total of 25 pairs ranging from (i = 1, r = 1) to (i = 25, r = 25), where i and r indicates intention and random, respectively. Thus, we matched animation to have a similar motion path length and time for all triangles within a pair. Based upon this design, it was expected that participants would judge the triangles in a pair (for example, i = 19, r = 19 shown in  ) to be somehow different from each other in terms of intentionality, while triangles in another pair (for example, i = 1(highest), r = 1(lowest) shown in   and  ) would be much different from each other Thus, we created a total of 25 graded steps of stimulus pairs. Of the 25 animations, the mean intentionality score was 5.77 in the “high” group and 1.79 in the “low” group. 

A two-way repeated-measures ANOVA (intention×animation number) revealed a significant main effect for intentionality [F(1,14) = 768.9,   p  <.001] and stimulus number [F(24,336) = 4.82,   p  <.001]. We also found significant interaction between intentionality and stimulus number [F(24,336) = 6.35,   p  <.001]. Multiple comparisons using Turkey's HSD revealed significant differences between high- and low-rated scores. Thus, we confirmed that the higher-rated group was significantly more sensitive to intention than the lower-rated group. T-tests comparisons between the number of objects (2 to 3 objects) found no differences in terms of intentionality. Based on these preliminary findings, we adopted all the stimulus objects tested for later experiments. 


### fMRI session 
  
No participants who participated in the preliminary study participated in the fMRI study. In an fMRI session, an animation was presented one second after a beep tone and an evaluation screen appeared which asked the participant to rate the level of intentionality from one (high) to four (low). Participants made ratings by choosing from two sets of four buttons (one set for each hand). One trial took 17 s, resulting in a total of length of 14 min 30 s for each session. For the first session, fifty moving patterns were presented in random order to participants in a counter-balanced manner. Twenty-five patterns were presented to the high group and to the low group, respectively. In the second session, up-down reversed patterns from the first session were presented. The presentation of normal and up-down reversed patterns was counter-balanced for each participant. In the preliminary study, we confirmed that participants could easily decide a response after reading the agent's intention 3 s after presentation. Therefore, the fMRI scan began 3 s after the animation presentation. 

Animations were back-projected onto a screen viewed through an angled mirror. The size of each animation was 11.5°×11.5°. In one session, participants observed 50 animations presented in random order. The length of each trial was 17 seconds. 


### fMRI data acquisition 
  
Whole brain images were acquired on a 1.5-T whole-body magnetic resonance imaging scanner (Shimadzu-Marconi Magnex Eclipse, Kyoto, Japan). Head motion was minimized with a forehead strap. Functional MRI was performed with a gradient echo-planer imaging (TR = 3000 ms, TE = 49 ms, flip angle = 90°, 5 mm slice thickness, FOV = 192 mm×192 mm, and pixel matrix 64×64). After the collection of functional images, T1-weighted images (154 slices with no gap) using a conventional spin echo pulse sequence (TR = 12 ms, TE = 5 ms, flip angle = 8°, FOV = 220 mm×220 mm, and pixel matrix 256×256) were collected for anatomical co-registration with the functional images. 

After image reconstruction, functional images were analyzed using SPM2 (Wellcome Department of Imaging Neuroscience, London, UK). Six initial images were discarded from the analysis to eliminate the non-equilibrium effects of magnetization. All functional images were corrected for between-slice timing differences in image acquisition and realigned to correct for head movement, which was less than 1 mm within runs. The functional images were normalized and spatially smoothed with an isotropic Gaussian filter (6 mm full-width at half-maximum). Low-frequency noise was removed by high-pass filtering (time constant = 128 s). We conducted the analysis using an event-related design. An onset of an event according to the data analysis occurred three seconds after an animation started based on the results of the preliminary study. 

Data were modeled by convolving the vector of expected neural activity with the canonical hemodynamic response function (HRF) included in SPM2 and modulated by ratings of intentionality (4-point scales: high for 4 and low for 1). Single-participant   t  -contrast images were then entered into second-level analysis using a random effects model for all participants. The levels of statistical significance for these analyses were set to   p  <0.001 (uncorrected). 



## Results 
  
Two contrasts were specified per single-participant analysis: 1) Low versus High and 2) High versus Low. Low-intention involves activations under participant's button press 1 (highest) and 2 (higher) and high-intention involves that of button press 3 (lowest) and 4 (lower). As shown in   and  , fMRI revealed activation of three main areas when participants observed 25 low-intention-involved animations (low>high): the left middle occipital areas including the calcarine sulcus/cuneus (BA17,18), the right lingual gyrus (BA18), and the right prefrontal gyrus in the middle prefrontal cortex (BA9). However, when participants observed 25 high-intention-involved animations and intentional bias was increased (high>low), the activated areas extended to include the bilateral posterior STS sulcus (BA22/37/39), the right temporal pole (BA38), the bilateral inferior frontal gyrus (BA47:IFG), the premotor (BA6), the inferior temporal gyrus (ITG), the left supramarginal gyrus, and the left superior parietal lobule (SPL). We did not find any activation in the MPFC ( ). 
   Brain activation regions for high→low-intention corresponding to the social brain (i.e., yellow area) and areas for low→high-intention corresponding to the perceptual brain (i.e., blue area).  
Event-related fMRI results showed that main activation areas occurred in three regions while participants observed low-intention animations: extrastriate cortices including calcarine sulcus and lingual gyrus (BA 17,18), and right middle frontal gyrus (BA9). During high-intention animations, activation of more widespread regions was observed, including: bilateral inferior frontal gyrus (BA47:IFG), premotor (BA6:PM), superior temporal sulcus (BA22/37/39: STS), inferior temporal gyrus(ITG), left supramarginal gyrus (SMG), left superior parietal lobule (BA 7: SPL), and right temporal pole (BA38:TP). 
     Brain region of activation for each contrast.        

## Discussion 
  
In this study, we sought to investigate the differential contributions of the areas involved in visual and intentional cognitive processes. Participants conducted tasks that required them to make social interpretations by looking at moving objects that were presented as low- or high-intentionally biased animations. By varying the stimuli, we varied the extent to which intentional cognitive processing was required, which facilitated the analysis of intentional and perceptual influences on various brain regions. 

Based upon event-related fMRI data, our results revealed activation of several visual areas including the calcarine sulcus/cuneus and the lingual gyrus (BA17, 18), which is near the fusiform gyru when the visual brain operated in a mechanical low-intention-involved context. The middle frontal gyrus is thought to maintain visual attention to groups of moving objects  . In contrast, the fusiform gyrus is believed to play a general role in the representation of visual stimuli that signify intent, independent of the visual form  . Our finding of activation in the lingual gyrus, which is near the fusiform gyrus corroborates with a previous study  . 

As shown in  , when the brain processes high-intention-involved interactive animations, activation in the posterior STS involving part of the supramarginal area increased. It has been demonstrated that the STS becomes activated while viewing animated geometrical figures portraying social interactions  ,  ,   and when evaluating the intentions of others. Using fMRI, Gobbini et al.   reported that social animations activated an extensive portion of the STS including areas in the posterior STS as well as the inferior parietal lobule. 

In an earlier PET study, Castelli et al.   presented animations that featured two characters (a large red triangle and a small blue triangle) moving on a framed white background similar to Heider and Simmel's pattern  . The investigators presented each participant with three types of animation: 1) ToM (two triangles bluffing one another); 2) goal-directed (two triangles dancing together); and 3) random (two triangles merely drifting). These animations were displayed for approximately 40 s over the course of 12 scans and divided into two consecutive counterbalanced blocks consisting of cued and uncued animations. These animations were designed to evoke mentalizing and elicited activity in the STS relative to a random motion condition. The design of the current study improved that done by Castelli et al. in two ways. First, intentional biases were manipulated continuously from highest to lowest by 25 matched pairs selected from 50 animations using ratings from the participants in a preliminary study. Second, an event-related design was introduced to avoid prior knowledge by using a shorter presentation duration (5 s). Based on our results, it is likely that intentional bias may be controlled more by the STS than by the MPFC, particularly when brain responses to high-intention-involved animations are compared with responses to low-intention-involved animations. 

The STS has been hypothesized to be closely connected to the perception of biological motion. Studies using transcranial magnetic stimulation   and magnetoencephalography   have shown that the simulation of human walking induced by moving dots selectively activates a brain area on the ventral bank in the occipital extent of the STS and the right temporo-parietal junction. Furthermore, such animations may be similar to the Heider and Simmel   paradigm. We show here that tasks tapping mentalization and agency attribution activated the same brain regions in the STS and temporo-parietal cortices including the supramarginal gyrus, inferior temporal gyrus, the temporal pole, and the SPL. One explanation for why we did not find activation in the MPFC is that we used an event-related design to avoid expectancy with a much shorter presentation time than the 30 s previously reported  . Expectancy cueing and longer presentation time could also yield possible contingent activations in the MPFC in addition to controlling intentional bias in the STS. It is highly possible, therefore, that higher-intention-involved animations, such as the fight between the blue and green triangle used in the current study, was perceived by the observer as though he/she was participating in the action against an antagonis. Indeed, humans may possibly detect intentions in shapes, even when those shapes change their motion to face another object  . 

Overall, we assumed that activation in the premotor cortex invoked a mirror system when a human acts and when the person observes the same action performed by anothe  . This system may be important for understanding the actions of other people, and that of the geometrical shapes in our animations. Some researchers also speculate that mirror systems may simulate observed actions, thus contributing to ToM skills  ,  . In the premotor area, a functional mirror system estimating others' intentions may contribute to activation of the IFG  . In the current study, significant increases of activation in the IFG were observed only when the animations were actively viewed with intention. Therefore, it is possible that the IFG monitors intentional thoughts in the STS. In contrast, activity in visual areas, including the lingual gyrus, which is near the fusiform gyrus, was only found in conditions requiring less intentional involvement and passive viewing. 

With close interconnections to the STS, the IFG and the temporal pole provide internally-represented self and other's mental states. Rather than the MPFC per se, it is the ventral side of the IFG, close to the orbitofrontal PFC and temporal pole, along with temporo-parietal-junction areas including the posterior STS and supramarginal gyrus  ) that are possible critical components for the representation of another's mental state. Saxe et al.   examined whether activation of the posterior STS, similar to the perception of intentionality, depends particularly on the contingency between an agent's motion and the environment by introducing short and long occlusions of a walking person's animation strip. They showed that right posterior STS activation occurred following the long occlusion (i.e., when a person remained hidden for a few seconds before re-emerging). In the current study, we found activation in the same region; namely, the bilateral posterior STS, using simple geometric animations depicting high-intention-involved action. The present study suggests that the posterior STS is involved in constructing an abstract visual description of another agent's intentional actions, without engagement of the MPFC. Based on the present results, it is possible that incoming animated information is decoded perceptually and integrated with contextual interpretation; the constituent product of these two processes can be understood either in terms of perceptual- or intention-involved behaviors. 

In their examination of the neural correlates of mentalization, Vogeley et al. (2001)   used fMRI to investigate common and differential neural mechanisms underlying ToM and the self during the presentation of a verbal story, finding that a ToM task led to increased neural activity in the temporal pole, whereas the self-task led to increased neural activity in the right temporo-parietal junction involving the STS. Interestingly, our data corroborate theirs regarding the neural correlates of ToM despite the large differences in the methods employed. The ability to model another intentional mind using an animated patter could be an evolutionary innovation in the human social brain that developed from the perceptual brain. Further investigations are necessary in order to clarify this issue. 


## Conclusion 
  
To summarize, we investigated how the visual brain transitions to the social brain using event-related fMRI in the present study. Animations consisted of moving patterns evoking various mental states of attribution based on intentions. Among 25 pairs of animations, each participant rated the higher- and lower-intention animation according to their attribution of agency (i.e., internal or external). Results showed that activations of the posterior STS, ITG, IFG, premotor, temporal pole, supramarginal gyrus, and SPL occurred under high-intention–involved animations, whereas occipital, lingual, and middle frontal gyri were activated under lower-intention-involved animations. 

Findings of the present study suggest that as intentional stance increased, the portion of the social brain involving the representation of an agent's intentional actions became more activated. Thus, developing the capacity to model another's mind could be an evolutionary innovation in the human social brain that developed from the perceptual brain. Previous studies have implicated regions activated by higher intention in self-monitoring in the perception of biological motion and in the attribution of mental states, and regions activated by lower-intention in simple perceptual processing. In the present study, we report how the visual brain shifts to the social brain in an agency attribution experiment. We suggest that as agent attribution increases, the visual brain changes to the intention-assuming social brain and therefore possesses a flexible network for processing information about social interactions based on agency attribution. 


## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-14'>
<h2>14. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/30834300/' target='_blank'>30834300</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> What Makes Eye Contact Special? Neural Substrates of On-Line Mutual Eye-Gaze: A Hyperscanning fMRI Study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> eNeuro</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1523/ENEURO.0284-18.2019</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6397949/' target='_blank'>6397949</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI hyperscanning study of real-time mutual eye contact (a social interaction task) in healthy adult participants (mean age ~21.8; no neurologic/psychiatric history). Whole-brain EPI volumes covering cortex and cerebellum were acquired and whole-brain analyses were conducted (voxelwise GLM with cluster-level FWE correction, interbrain voxel-to-voxel synchronization, and seed-to-voxel gPPI evaluated across the whole brain). Results are not limited to ROI-only analyses, the sample is healthy adults within 18–60, and the manuscript is an original empirical fMRI study rather than a review. Therefore all inclusion criteria are met and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.98</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>   Visual Abstract  
  
  
Automatic mimicry is a critical element of social interaction. A salient type of automatic mimicry is eye contact characterized by sharing of affective and mental states among individuals. We conducted a hyperscanning functional magnetic resonance imaging study involving on-line (LIVE) and delayed off-line (REPLAY) conditions to test our hypothesis that recurrent interaction through eye contact activates the limbic mirror system, including the anterior cingulate cortex (ACC) and anterior insular cortex (AIC), both of which are critical for self-awareness. Sixteen pairs of human adults participated in the experiment. Given that an eye-blink represents an individual’s attentional window toward the partner, we analyzed pairwise time-series data for eye-blinks. We used multivariate autoregression analysis to calculate the noise contribution ratio (NCR) as an index of how a participant’s directional attention was influenced by that of their partner. NCR was greater in the LIVE than in the REPLAY condition, indicating mutual perceptual–motor interaction during real-time eye contact. Relative to the REPLAY condition, the LIVE condition was associated with greater activation in the left cerebellar hemisphere, vermis, and ACC, accompanied by enhanced functional connectivity between ACC and right AIC. Given the roles of the cerebellum in sensorimotor prediction and ACC in movement initiation, ACC–cerebellar activation may represent their involvement in modulating visual input related to the partner’s movement, which may, in turn, involve the limbic mirror system. Our findings indicate that mutual interaction during eye contact is mediated by the cerebellum and limbic mirror system. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (52963 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Significance Statement 
  
Eye contact is a key element that connects humans during social communication. We focused on a previously unaddressed characteristic of eye contact: real-time mutual interaction as a form of automatic mimicry. Our results indicate that real-time interaction during eye contact is mediated by the cerebellum and limbic mirror system. These findings underscore the importance of the mirror system and cerebellum in real-time unconscious social interaction. 


## Introduction 
  
Automatic mimicry refers to unconscious or automatic imitation of movement ( ). It is a critical part of human social interaction because it is closely tied to the formation of relationships and feeling of empathy ( ). Automatic mimicry occurs when two or more individuals engage in the same behavior within a short window of time (e.g., facial expressions, body postures, laughter, yawning;  ). Automatic mimicry induces synchronous behavior through recurrent interaction ( ), thereby enabling spontaneous synchronization (e.g., clapping) and goal-directed cooperation ( ). 

Eye contact is one of the most salient types of automatic mimicry, as two people must be able to synchronize their eye movements to make eye contact ( ). Eye gaze provides a communicative signal that transfers information regarding emotional and mental states ( ). Eye contact, or mutual gaze, conveys the message, “I am attending to you,” thereby promoting effective communication and enhancing social interaction ( ;  ). 

Recent functional magnetic resonance imaging (fMRI) studies have revealed that eye contact activates the social brain, including the fusiform gyrus ( ;  ;  ), anterior superior temporal gyri ( ;  ), posterior superior temporal gyri ( ;  ;  ), medial prefrontal cortex ( ;  ;  ;  ), orbitofrontal cortex ( ;  ), and amygdala ( ;  ;  ; for review, see  ). The above-mentioned studies were conducted using single-participant fMRI data, contrasting the neural activation elicited by an eye-contact event with that elicited by an eye-aversion event. However, neural substrates underlying recurrent interaction during eye contact that result in the development of shared, pair-specific psychological states (e.g., attention and emotion) remain unknown. 

The mirror neuron system plays a role during mutual interaction through joint attention ( ;  ). The existence of two main networks with mirror properties has been demonstrated, with one residing in the parietal lobe and premotor cortex plus caudal part of the inferior frontal gyrus (parietofrontal mirror system), and the other formed by the insula and anterior medial frontal cortex (limbic mirror system;  ). The parietofrontal mirror system is involved in recognizing voluntary behavior, while the limbic mirror system is devoted to recognizing affective behavior ( ). We hypothesized that mutual interaction involving eye contact activates the limbic mirror system. 

This study aimed to elucidate the behavioral and neural representations of mutual interaction during eye contact using hyperscanning fMRI ( ). The neural activity associated with real-time eye contact was compared with that of non-real-time eye contact using a double-video system ( ). Eye contact is characterized by a two-way, behavioral stimulus-to-brain coupling, such that the behavior of a partner is coupled to the activation in the brain of the other ( ). Thus, face-to-face interaction through eye contact can be regarded as a mirrored reactive–predictive controller system consisting of two controllers ( ). We used eye-blink as a behavioral index of mutual exchange of communicative cues between two participants during eye contact. As the blinks of others can be easily recognized due to their relatively long duration (200–400 ms;  ), eye-blinks can provide social communication cues ( ). Further, blink rates change with internal states such as arousal, emotion, and cognitive load ( ;  ;  ). Finally, the timing of eye-blinks is associated with implicit ( ) and explicit ( ) attentional pauses in task content.   observed that eye-blinks of a listener and speaker were synchronized during face-to-face conversations, and concluded that eye-blinks define the attentional temporal window and that its synchronization reflects smooth communication between interactants through sharing of attention in the temporal domain. In this study, we used hyperscanning fMRI to analyze brain activation related to eye-blinks using the following different measures: activation, modulation of functional connectivity, and interbrain synchronization. 


## Materials and Methods 
  
### Participants 
  
Thirty-four volunteers participated in the experiment (20 men, 14 women; mean age ± SD, 21.8 ± 2.12 years). Participant pairs were determined before the experiment and consisted of participants of the same sex. None of the participants had met each other before the experiment. All participants except one were right handed, as evidenced by the Edinburgh Handedness Inventory ( ). None of the participants had a history of neurologic or psychiatric illness. The protocol was approved by the ethics committee of the National Institute for Physiological Sciences. The study was conducted in compliance with the national legislation and the Code of Ethical Principles for Medical Research Involving Human Subjects of the World Medical Association (Declaration of Helsinki). All participants provided written informed consent before the experiment. 


### Design and Procedure 
  
#### Experimental setup 
  
To measure neural activation during the on-line exchange of eye signals between pairs of participants, we used a hyperscanning paradigm with two MRI scanners (Magnetom Verio 3T, Siemens) installed side-by-side in parallel, sharing one control room and a triggering system ( ;  ). The top component of the standard 32-channel coil was replaced by a small four-channel flex coil (Siemens) attached with a special holding fixture (Takashima Seisakusho;  ;  ) to fully visualize the eye region. On-line grayscale video cameras were used during scanning to identify reciprocal face-to-face interaction (NAC Image Technology). The cameras captured images of each participant’s face, including the eyes and eyebrows. The captured images were in turn projected using a liquid crystal display projector (CP-SX12000J, Hitachi) onto a half-transparent screen that stood behind the scanner bed. The captured images were also entered into the picture delay system (VM-800, Sugioka System), which could output video delayed by an arbitrary amount of time. For analysis, video pictures used in the experiment were transferred to a video recording system (Panasonic). We recorded facial movement in AVI (audio video interleave) format (640 × 480 pixels, 30 frames/s). While the exact values varied depending on the participant’s head size, the screen stood ∼190 cm from the participants’ eyes, and the stimuli were presented at a visual angle of 13.06° × 10.45°. The delay between the capture and projection of the participants’ face was controlled using a hardware device (VM-800, Ito Co., Ltd.) connected between the video camera and projector. The delay was set at 20 s for the REPLAY condition and 0 s for the LIVE condition. The intrinsic delay of the on-line video system in this experimental setup was ∼100 ms. 


#### Experimental conditions 
  
We adopted a conventional blocked design for this study. Each run included three conditions: LIVE, REPLAY, and REST. During the LIVE condition, participants were presented with a live video of their partner’s face in real time ( ), allowing for the on-line exchange of information between the two participants. We instructed participants to gaze into the right or left eye of their partners and think about their partner as follows: what he/she is thinking about, what is his/her personality, how he/she is feeling. The participants were instructed not to exhibit explicit facial expressions such as laughing or grimacing. We also informed them that we will stop MRI scanning if they were not gazing into the partner’s eyes for an extended period of time. The REPLAY condition was identical to the LIVE condition, except that the participant watched a video picture of their partner’s face presented at a delay of 20 s. Therefore, there was no real-time interaction between the participants ( ). During the REPLAY condition, the participant was informed that all the videos they were watching represented their partner’s face in real time. During the REST condition (baseline), participants were required to gaze at the blank screen ( ). Although we monitored the participants to ensure that they do not fall asleep, two participants fell asleep during the experiment, and we had to restart the experiment after a short break. 
  
Experimental setup.    A   , LIVE condition: the face of Participant 1 is projected on the screen of Participant 2 in real time and vice versa, allowing a mutual exchange of information.    B   , REPLAY condition: the picture is projected on the screen with a 20 s delay; therefore, there is no mutual interaction between participants in real time.    C   , REST condition (baseline): no image is presented on the black screen.    D   , Sequence of presentation of the experimental conditions. 
  
Before starting the run, a live video of the partner was presented on the screen to confirm that an interactive partner was in the other scanner. Following confirmation, the video was turned off. The first run began with the REST condition for 30 s, followed by the LIVE, REPLAY, and REST conditions for 20 s each. After each 20 s presentation of the partner’s face, the screen was turned off for 1 s, and the condition was switched (e.g., from LIVE to REPLAY, REPLAY to REST;  ). The 1 s interval was designed to prevent participants from becoming aware of the difference between the LIVE and REPLAY conditions. The order of presenting the conditions was pseudorandomized. The conditions were switched manually during the fMRI run according to a predefined experimental design. Each run consisted of eight LIVE and eight REPLAY conditions. The total length of each run was 8 min and 30 s, and the entire scan consisted of four runs. Throughout the experiment, none of the participants exhibited any sudden display of emotions such as laughter. 

An interview following the experiment revealed that only one female pair realized that a delayed facial picture was presented in one of the conditions during the experiment; thus, the requirements of the experiment were not fulfilled in the pair. Data were analyzed from the remaining 32 participants (20 men, 12 women; mean ± SD age, 21.8 ± 2.03 years). 


#### MRI data acquisition 
  
Brain activation data were acquired using interleaved T2*-weighted, gradient echo, echoplanar imaging (EPI) sequences. Volumes consisted of 60 axial slices, each 2.0 mm thick with a 0.5 mm gap, covering the entire cerebral cortex and cerebellum. The time interval between two successive acquisitions of the same image [repetition time (TR)] was 1000 ms, with a flip angle of 80° and echo time (TE) of 30 ms. The field of view (FOV) was 192 mm, and the in-plane matrix size was 64 × 64 pixels. We used the multiband accelerated sequence developed at the University of Minnesota ( ), with the multiband factor set to 6. Thus, 510 volumes (8 min and 30 s) were collected for each run. For anatomic reference, T1-weighted high-resolution images were obtained using a three-dimensional magnetization-prepared rapid acquisition gradient echo (MPRAGE) sequence (TR = 1800 ms; TE = 2.97 ms; FA = 9°; FOV = 256 mm; voxel dimensions = 1 × 1 × 1 mm ) and a full 32-channel phased array coil. 



### Data analysis 
  
#### Behavioral data analysis 
  
##### Extraction of eye-blink time series 
  
Eye-blink was chosen as a behavioral index of interaction during mutual gaze ( ). We calculated the “motion energy” using the AVI video of the participant’s face during the task ( ) to evaluate the time series of eye-blinks. Due to technical difficulties with the video recording system, data from two pairs were unavailable. In total, video data of faces from 14 pairs (18 men, 10 women; mean ± SD age, 21.8 ± 2.17 years) were subjected to the analysis described below. 

 illustrates the procedure used to calculate the motion energy time series representing eye-blinks. First, the spatial window (400 × 100 pixels) of the AVI video was manually set to cover the eye area of each participant. Second, using the pixel intensity of the defined eye area, we obtained the motion energy index, which can detect the occurrence of motion only from a series of pictures ( ). The first-order difference in picture intensity was calculated frame by frame in each pixel, and the average of the absolute value of differences in each frame was calculated. This process was used to obtain motion energy values at specific time points. The calculation was repeated to obtain the motion energy time series reflecting eye-blinks during each run. Third, we divided the time series in each run into shorter subsections corresponding to the LIVE, REPLAY, and REST conditions. Although each condition lasted 20 s ( ), we analyzed only the final 15 s of each condition to minimize the effect of brightness instability (largely due to the procedure for switching conditions). We obtained eight time series for each condition of a single run. As each participant underwent four runs, 32 time series were obtained for each condition per participant. Finally, the effect of the linear trend in the data was removed using the “detrend” function implemented in MATLAB. The whole procedure was performed using a MATLAB script (MATLAB 14, MathWorks) developed in-house. 
  
Evaluation of the motion energy time series representing eye-blinks. The red dots indicate the timing of the detected eye-blink. 
  

##### Number of eye-blinks 
  
To determine whether the number of eye-blinks itself was influenced by differences in the type of task, we calculated the number of eye-blinks in the LIVE, REPLAY, and REST conditions using the extracted time series of motion energy. We first adapted the peak-detection function implemented in MATLAB, which automatically detected and marked the time point at which the eye-blink appeared to occur ( ). Next, we visually examined whether the detected time point was acceptable. Finally, we calculated the average number of eye-blinks in 1 block (  15   s) for each participant. All calculations were performed using a MATLAB script (MATLAB 2014) developed in-house. 


##### Causality analysis between eye-blink time series 
  
Several hyperscanning studies have used synchronization or correlation as an index of interaction ( ), neither of which can evaluate the directional effect. In this study, we used an Akaike causality model ( ;  ), which can delineate the causal direction and quantify its effect. The Akaike causality model uses a multivariate autoregressive (MVAR) model under the steady-state assumption and can quantify the proportion of the power-spectral density of an observed variable from the independent noise of another variable. The quantified causality, that is, the noise contribution ratio (NCR) index, is regarded as a measure of how one variable is influenced by another. In this study, we assumed that the eye-blink time series satisfies a steady-state assumption at least in one block. The NCR values were calculated as follows. 

First, an MVAR model was applied to a pair of time-series data,   x  (  t  ) and   y  (  t  ), using the linear sum of the history of the two time series, as follows: where the time series   and   correspond to the time series of the participant’s eye-blinks and that of the partner, respectively. In these equations,  ,  ,  , and   indicate AR coefficients, while   and   indicate the residual noise in the eye-blinks of the participant and partner, respectively. The AR order   N   defines the duration of the history. For each pair of time-series data, the AR order   N   was estimated to minimize the Akaike information criterion in the range from 1 to 10. Next, we estimated the power spectrum of the two time series based on the sum of the contributions of the   x  -specific noise (i.e.,  ) and   y  -specific noise (i.e.,  ). Here,   and   are frequency response functions, derived from Fourier transformation via an impulse response function, using a set of AR coefficients, while   and   indicate the variance of residual noise   and  , respectively. The  , an index reflecting how the participant’s eye-blinks   are influenced by the partner’s eye-blinks  , was calculated from the ratio of part of the spectral density of   contributed by   to the total spectral density of   at frequency   f  . Therefore,   can be expressed as follows: 

To assess how   is influenced by   across the whole frequency range, we mathematically integrated   NCR   values via trapezoidal numerical integration as follows: where   f   is the sampling frequency of the time series   and  . In this study,   f   was 30 Hz, based on the frame rate of the video data. We collected 32 time series for each condition. Therefore, our calculations yielded 32 ΣNCR values for each condition per participant. These 32 ΣNCR values were averaged to calculate one summarized ΣNCR value for each participant in each condition. Using the summarized ΣNCR, we applied statistical analyses to determine whether the influence of the partner differed between conditions. The entire procedure was performed using a MATLAB script (MATLAB 2014) written in-house. 

In this study, we calculated four ΣNCR values to assess how a participant’s eye-blink was influenced by that of the partner. Firstly, in the REST condition, participants could see nothing on the screen. Therefore, the ΣNCR value in the REST condition (i.e.  ) was regarded as a baseline of causal relationship. In the LIVE condition, the face of one participant was immediately projected on the screen, and the partner was able to see the face in real time. In this condition, we calculated ΣNCR between two participants’ time series (i.e.,  ).　The ΣNCR value represents how participants influence their partners when they mutually interact with each other in real time. Next, in the REPLAY condition, two types of causality were calculated as follows: first, the ΣNCR value between actual eye-blinks, like in the LIVE condition (i.e.,  ); and second, the ΣNCR value in the REPLAY condition representing how the eye-blinks projected on the screen has an influence on the actual eye-blink time series,  . While it is possible that a participant’s face receives influence from the delayed picture on the screen ( ), influence from an actual eye-blink to the screen (reverse influence) is theoretically absent. We also calculated the ΣNCR value (i.e.,  ). It represents how participants are influenced by a video picture, while there could be only unidirectional influence from the screen to actual eye-blinks. 


##### Estimation of statistical inferences and data visualization 
  
All statistical inference estimation for the behavioral data analysis was performed using R (RRID:  SCR_001905  ). We analyzed three types of behavioral measures. (1) The number of eye-blinks is highly influenced by the degree of attention ( ;  ;  ;  ;  ) and could reflect the differences across conditions. We tested the number of eye-blinks in three conditions using repeated-measures analysis of variance (ANOVA). (2) ΣNCR values: we have four ΣNCR values for each participant,   in the REST condition,   and   in the REPLAY condition, and   in the LIVE condition. The differences between them were assessed using repeated-measures ANOVA. (3) Enhanced ΣNCR values: in the REST condition, participants know there is no interaction with a partner as nothing is projected on the screen. Therefore, theoretically speaking, the REST condition could be regarded as a baseline condition. We calculated the increase in ΣNCR values (enhancement) by subtracting the   value from each of the ΣNCR values. Thus, we have three enhanced ΣNCR values for each participant:   and  . Repeated-measures ANOVA was used to test the differences between these values. In all ANOVA procedures, the effect size was measured using the generalized η  value ( ). In the   post hoc   pairwise analysis, estimated   p   values were adjusted using a Bonferroni correction. The confidence levels for   post hoc   pairwise analyses were calculated via the pairwise confidence intervals of  . The details of the statistical methods used in this behavioral data analysis are listed in  . All the graphs were prepared using the RainCloudPlots R-script ( ;   https://github.com/RainCloudPlots/RainCloudPlots  ), which could provide a combination of box, violin, and dataset plots. In the dataset plot, each dot represents a data point, respectively. Outliers were defined by 2 SDs and are represented in   by red diamonds. In the boxplot, the line dividing the box represents the median of the data, while the ends of the box represent the upper and lower quartiles. The extreme lines show the highest and lowest values excluding outliers defined by 2.0 SDs. 
  
Statistical analysis 
  


#### Neuroimaging analysis 
  
##### Image preprocessing 
  
The first 10 volumes (10 s) of each fMRI run were discarded to allow for stabilization of the magnetization, and the remaining 500 volumes/run (total of 2000 volumes/participant) were used for the analysis. The data were analyzed using statistical parametric mapping (SPM12, Wellcome Trust Center for Neuroimaging, London, UK; RRID:  SCR_007037  ) implemented in MATLAB 2014 (RRID:  SCR_001622  ). All volumes were realigned for motion correction. The whole-head T1-weighted high-resolution MPRAGE volume was coregistered with the mean EPI volume. The T1-weighted image was normalized to the Montreal Neurologic Institute (MNI) template brain using a nonlinear basis function in SPM12. The same normalization parameters were applied to all EPI volumes. All normalized EPI images were spatially smoothed in three dimensions using a Gaussian kernel (full-width at half-maximum = 8 mm). 


##### Estimation of task-related activation using univariate generalized linear modeling 
  
Because of technical difficulties, we could not acquire fMRI data from one pair. Therefore, we analyzed whole fMRI data acquired from 30 participants (18 men, 12 women; mean ± SD age, 21.7 ± 2.10 years). Statistical analysis was conducted at two levels. First, individual task-related activation was evaluated. Second, summary data for each participant were incorporated into a second-level analysis using a random-effects model ( ) to make inferences at a population level. 

In the individual-level analysis, the blood oxygenation level-dependent (BOLD) time series representing the brain activation of each participant was first modeled using a boxcar function convolved with a hemodynamic response function and filtered using a high-pass filter (128 s), while controlling for the effect of runs. Serial autocorrelation assuming a first-order autoregressive model was estimated from the pooled active voxels using the restricted maximum likelihood procedure and used to whiten the data ( ). No global scaling was applied. The model parameters were estimated using the least-squares algorithm on the high pass-filtered and whitened data and design matrix. Estimates for each of the model parameters were compared with the linear contrasts to test hypotheses regarding region-specific condition effects. Next, the weighted contrasts of the parameter estimate (i.e., LIVE > REST and REPLAY > REST) in the individual analyses were incorporated into the group analysis. Contrast images obtained via individual analyses represented the normalized task-related increment of the MR signal relative to the control condition (i.e., the REST condition) for each participant. 

In the group-level analysis, we investigated differences in brain activation between the LIVE and REPLAY conditions using these contrast images and the random-effects model implemented in SPM12. We analyzed these data using the paired   t   test. The resulting set of voxel values for each contrast constituted a statistical parametric map of the   t   statistic (SPM {t}).   T  he threshold for significance of the SPM {t} was set at   p   < 0.05 with familywise error (FWE) correction at the cluster level for the entire brain ( ). To control FWE rates using random field theory ( ), the height threshold was set at an uncorrected   p   value <0.001, which is conservative enough to depict cluster-level inference with the parametric procedure ( ). To validate the statistical inference with a parametric method, we also tested the statistical significance of activation using a nonparametric permutation test implemented in the SnPM13 toolbox (RRID:  SCR_002092  ;  ). We used the nonparametric paired   t   test with no variance smoothing; the number of permutations was set at 10,000. The SnPM toolbox did not yield statistical significance at all the voxels reported in SPM; thus, the   p   values for some voxels have not been listed in the tables. 


##### Generalized psychophysiologic interaction analysis 
  
Next, we performed generalized psycho-physiologic interaction (gPPI) analysis ( ;  ) using the CONN toolbox ( ; RRID:  SCR_009550  ) to reveal how effective connectivity from the LIVE- or REPLAY-specific regions (toward other brain regions) was altered between the LIVE and REPLAY conditions. For this purpose, we selected three clusters based on the LIVE > REPLAY contrast defined by the results of univariate generalized linear modeling (GLM) analysis ( ,  ) as seed regions for the gPPI analysis. We used conventional seed-to-voxel gPPI analysis in which the whole brain is the search area. The components associated with a linear trend, CSF, white matter (WM), and experimental tasks (i.e., LIVE and REPLAY effects) were removed from the BOLD time series as confounding signals. Using the residual time series, gPPI analysis was performed to evaluate whether the effective connectivity from the seed region was modulated by the task condition (i.e., the LIVE or REPLAY condition) at the individual level. This individual-level analysis produced contrast images representing the modulation of effective connectivity from the seed region. Up to this point, all procedures were conducted using the CONN toolbox. Finally, we used these contrast images and the random-effect model implemented in SPM12 to test whether any regions exhibited significant differences in effective connectivity between the LIVE and REPLAY conditions. Analyses were assessed at   p   < 0.05 with FWE correction at the cluster level. The height threshold to form each cluster was set at an uncorrected   p   value of 0.001. This relatively high cluster-forming threshold is enough to prevent the failure of a multiple-comparison problem in cluster-level statistical inference ( ;  ). We also listed statistical values estimated by the SnPM toolbox with a nonparametric permutation test. 
  
Behavioral analysis.    A   , The number of eye-blinks per block. We omitted the first 5 s of each block because of instability of the recorded video induced by task switching; the number of eye-blinks was therefore calculated based on the succeeding 15 s. Each dot represents a data point. In the boxplot, the line dividing the box represents the median of the data, the ends represent the upper/lower quartiles, and the extreme lines represent the highest and lowest values excluding outliers.    B   , ΣNCR values. The integral of the NCR of each condition across the whole frequency range was calculated.   is the ΣNCR from the time series of the participant’s facial movement to that of the partner during the LIVE condition.   is the ΣNCR from the time series of the participant’s facial movement to that of the partner during the REPLAY condition.   is the ΣNCR from the time series of the participant’s facial movement to that of the partner during the REST condition.   is the ΣNCR from the time series from the participant’s delayed facial movement on the screen to the partner’s time series during the REPLAY condition.    C   , Enhanced ΣNCR values from the REST condition. 
    
Regions exhibiting greater activation in the LIVE condition than in the REPLAY condition 
    

##### Interbrain synchronization analysis 
  
We tested for differences in the interbrain synchronization of the LIVE and REPLAY conditions using conventional voxel-to-voxel method used by previous hyperscanning fMRI studies that can identify interbrain synchronization of activation without any prior assumptions ( ;  ). We focused on the spontaneous fluctuation of BOLD signal that is unrelated to the task-related activation or deactivation ( ). First, the task-related activation/deactivation was removed from the BOLD time series using the GLM model implemented in the SPM12. This yielded 3D-Nifti files representing residual time series that are independent of task-related activation/deactivation compared with baseline (i.e., the REST condition). Second, we divided the original time series into three sub-time series based on the experimental design: LIVE, REPLAY, and REST conditions. Third, we concatenated sub-time series into one long time series. The length of the LIVE- and REPLAY-related residual time series was 640 volumes. Next, we calculated the interbrain synchronization between the voxels representing the same MNI coordinates (  x  ,   y  ,   z  ) in the two participants using the Pearson’s correlation coefficient. This computation was performed using a MATLAB script developed in-house. The correlation coefficient   r   was transformed to the standardized   z   score using Fisher’s   r  -to-  z   transformation. Finally, we obtained two 3D-Nifti images representing interbrain synchronization in the LIVE and REPLAY conditions per pair. 

We conducted the random-effects model analysis in SPM12 at the group level. The normalized interbrain synchronization images were used in the group-level analysis. Here, the paired   t   test was used to test the differences in interbrain synchronization between the LIVE and REPLAY conditions. The resulting set of voxel values for each contrast constituted a statistical parametric map of the   t   statistic (SPM {t}). The threshold for significance of the SPM {t} was set at   p   < 0.05 with FWE correction at the cluster level for the entire brain ( ); the height threshold was set at an uncorrected   p   value of 0.001. This cluster threshold is conservative enough to prevent failure in cluster-level inference ( ;  ). The statistical inference was also estimated by a nonparametric permutation test using the SnPM toolbox, like the GLM and gPPI analyses. Anatomic labeling was based on Automated Anatomic Labeling ( ) and the Anatomy toolbox version 1.8 ( ). Final images have been displayed on a standard template brain image (  http://www.bic.mni.mcgill.ca/ServicesAtlases/Colin27  ) using MRIcron (  https://www.nitrc.org/projects/mricron  ;  ). 





## Results 
  
### Behavioral index 
  
 shows the average number of eye-blinks per block. Repeated-measures ANOVA revealed a significant effect of condition ( , a;   F   = 13.1814,   p   < 0.0001, η  = 0.0354). A   post hoc   comparison with Bonferroni correction revealed that there were no significant differences in the number of eye-blinks between the LIVE and REPLAY conditions ( , d;   t   =2.3522,   p   = 0.0786, Bonferroni correction), while the number of eye-blinks was greater in the REST condition than in the LIVE ( , b;   t   =3.9464,   p   = 0.0015, Bonferroni correction) and REPLAY ( , c;   t   = 3.8499,   p   = 0.0021, Bonferroni correction) conditions. 

 N  ext, we compared the ΣNCR values using repeated-measures ANOVA ( ) and found a significant effect of condition was significant (  F   = 3.9830,   p   = 0.0295, η  = 0.03236;  , e). A   post hoc   comparison with Bonferroni correction revealed that there were significant differences between the   (  t   = 3.406,   p   = 0.0126;  , f),   (  t   =3.2934,   p   = 0.0168;  , h). Differences in the other pairs did not meet the threshold for statistical significance ( , g, i, j, k). To confirm that the outliers did not skew the parametric statistics, we recomputed the statistical values after removing outliers defined by two SDs rather than 1.5. Four subjects to whom the outlier data could be attributed in at least one of the four conditions were excluded from the analysis; the repeated-measures ANOVA therefore included a sample of 24. Even after removing the outliers, the repeated-measures ANOVA could replicate the significant effect of condition (  F   = 4.3334,   p   = 0.0074, η  = = 0.0785;  , l), as well as the significant differences between the   (  t   =3.0965,   p   = 0.0306;  , m), and between   (  t   = 3.0779,   p   = 0.0318;  , o). Differences in the other pairs did not meet the threshold for statistical significance ( , n, p, q, r). 

We also tested differences across enhanced ΣNCR values using repeated-measures ANOVA ( ) and found that the effect of condition was significant (  F   = 10.3784,   p   = 0.0002, η  = 0.03236;  , s). A   post hoc   comparison with Bonferroni correction revealed that there were significant differences between   and   (  t   = 3.4061,   p   = 0.0063;  , t), as well as between   and   (  t   = 3.2934,   p   = 0.0084;  , u). Differences in the other pair did not meet the threshold for statistical significance ( , v). We recalculated statistical inferences as raw NCR values without outliers to ensure that the outliers had no effect on the inferences. The stricter criteria for outliers remained 2 SDs, resulting in the removal of seven subjects from the analysis. Even after outliers were excluded from the analysis, we obtained qualitatively identical results: significant effect of condition (  F   = 7.9233,   p   = 0.0013, η  = 0.1330;  , w), and significant differences between   and   (  t   = 2.8343,   p   = 0.0306;  , x) and between   and   (  t   = 2.9034,   p   = 0.0265;  , y). Differences in other pairs did not meet the threshold for statistical significance ( , z). 

To test whether or not these enhancements of entrainment of eye-blinking is influenced by the number of blocks, we calculated the Akaike causality index for separate blocks of the experiment and applied the repeated-measures ANOVA (4 blocks × 4 conditions) to the ΣNCR data. We found a significant effect of conditions (  F  =3.9830,   p   = 0.0106, η  = 0.0132;  , aa). However, the effects of sessions (  F  =1.0351,   p   = 0.3816, η  = 0.0139;  , bb) and interaction (session × conditions;   F   = 1.8235,   p   = 0.0647, η  = 0.0128;  , cc) were nonsignificant. Therefore, in the following analysis of neuroimaging data, we combined data from the four blocks. 


### Brain activation in the LIVE and REPLAY conditions 
  
We used GLM analysis ( , dd, ee) to elucidate brain activation in the LIVE and REPLAY conditions. For the LIVE versus REPLAY contrast, we observed greater activation in the left cerebellar hemisphere (lobules VI, VII, and VIIIa), bilateral paravermis area (lobule XI;  ), and the pre-supplementary motor area (SMA) extending to the dorsal tier of the anterior cingulate cortex (ACC;  ). No significant differences in activation were observed in the REPLAY versus LIVE contrast. Detailed information regarding each cluster is outlined in  . 
  
Brain regions exhibiting significantly greater activation in the LIVE condition than in the REPLAY condition.    A   , Cerebellar activation is overlaid on the coronal planes of the SUIT template ( ;  ).    B   , The activation in the ACC is superimposed on the T1-weighted high-resolution anatomic MRI normalized to the MNI template space in the sagittal (left), coronal (middle), and transaxial (right) planes that crossed at (6, 12, 40) in the MNI coordinate system (in mm). SUIT, Spatially unbiased infratentorial template. 
  

### Results of the gPPI analysis 
  
The gPPI analysis ( , ff, gg) revealed that the effective connectivity from the ACC region toward the dorsal anterior insular cortex (dAIC;  ) was greater during the LIVE condition than during the REPLAY condition ( ,  ). No regions exhibited greater effective connectivity involving the pre-SMA-ACC regions in the REPLAY condition than in the LIVE condition. There was no modulation of effective connectivity involving cerebellar seed regions.
 
  
Regions exhibiting greater effective connectivity from the ACC in the LIVE condition than in the REPLAY condition. The area outlined in white is the dAIC ( ). X indicates the MNI coordinates (in mm). 
    
Regions exhibiting enhanced effective connectivity from the ACC in the LIVE condition 
    

### Interbrain synchronization 
  
 illustrates interbrain synchronization that is specific to the LIVE condition ( , hh, ii). It was found on the bilateral middle occipital gyrus (MOG). Detailed information about these clusters is described in  . No regions showed significant interbrain synchronization in the REPLAY condition compared with the LIVE condition. 
  
Regions exhibiting greater interbrain synchronization during the LIVE condition than the REPLAY condition. These areas are superimposed on a surface-rendered high-resolution anatomic MRI normalized to the MNI template viewed from the left and right. 
    
The regions exhibiting enhanced interbrain synchronization in the LIVE condition compared with REPLAY condition 
    


## Discussion 
  
This study aimed to elucidate the behavioral and neural representations of mutual interaction during eye contact by comparing the neural activity associated with real-time eye contact with that associated with non-real-time eye contact. Our findings suggest that mutual interaction/shared attention during eye contact is mediated by the cerebellum and the limbic mirror system. 

### Behavioral index 
  
In this study, causal analysis using an MVAR model ( ;  ) was performed to assess how an individual’s temporal attentional window is influenced by that of the partner ( ;  ;  ). Our results show that participants were more sensitive to the eye-blinks of a partner in the LIVE condition than in the REPLAY condition because none of the participants perceived the difference between the LIVE and REPLAY conditions. Thus, the experimental setup for our LIVE condition enabled a reciprocal feedback system through the visual modality. Our findings suggest that perceptual–motor interaction occurs during eye contact without conscious awareness. Previous researchers have argued that an essential component of real-time social interactions involves reciprocal coupling via perceptual–motor linkages between interacting individuals ( ;  ;  ;  ;  ). Our results extend this notion to the attention mediated by the minimal motion of blinking, which represents the temporal window of attention toward one’s partner. Interestingly, the influence from a partner was significantly greater when the information flow between two individuals was reciprocal ( ) than when it was unidirectional ( ). As the mutual interaction in real time evinced a significant effect on the partner’s eye-blink, this finding indicated that the mutual on-line interaction is critical to the influence of the other’s eye-blink. Feedback through the on-line mutual interaction may induce a nonlinear response, causing the subtle effect to be amplified ( ). 

This experiment can be regarded as a simplified version of the social contingency detection task originally reported by  . Social contingency is defined as the cause–effect relationship between one’s behavior and consequent social events ( ;  ) and is highly associated with a sense of self or one’s own body in infancy, developing a sense of reciprocity, and participation with others ( ), all of which are critical for typical development ( ;  ;  ;  ;  ). Several previous studies have investigated differences in mother–infant interactions between real-time bidirectional interaction and off-line unidirectional interaction ( ;  ;  ;  ). Even in adults, turn-taking behavior accompanying social contingency is likely to serve as experience sharing, which represents the basis of all social behaviors ( ;  ). Our results indicate that even a minimal task condition, such as mutual gaze, constitutes a reciprocal feedback system that can provide a basis for the detection of social contingency, promoting sharing of attention between partners ( ;  ). 


### Neural substrates of eye contact in real time 
  
Using a conventional GLM approach, we observed LIVE-specific activation in the cerebellum and ACC. The cerebellum plays a key role in error detection and processing of temporal contingency ( ;  ;  ), the latter of which is critical for real-time social communication ( ). The cerebellum is also critically involved in sensorimotor prediction ( ), especially in building predictions about the actual sensory consequences of an executed motor command. One previous fMRI study reported that the prediction error caused by sensory feedback is essential for acquiring internal forward models of movement control ( ). This prediction (forward model) is mainly used in the early stages of movement execution to maintain accurate performance in the presence of sensory feedback delays ( ), as well as in social interaction ( ). Considering that real-time social interaction can be regarded as a cross-individual sensorimotor loop ( ;  ), the cerebellum may receive visual afferents of the partner’s blink as sensory feedback for the prediction of one’s blink movement, to evaluate temporal contingency between the partners’ blinks. 

In humans, the ACC is located in the medial wall of the cerebral hemisphere, adjacent to the pre-SMA ( ). The ventral (limbic) tier occupies the surface of the cingulate gyrus, corresponding to Brodmann’s areas 24a and 24b, and subcallosal area 25. The dorsal (paralimbic) tier is buried in the cingulate sulcus, corresponding to Brodmann’s areas 24c and 32 (for review, see  ). The dorsal tier is involved in volitional motor control ( ;  ;  ). 

The ACC and cerebellum constitute a tightly connected corticocerebellar network. Recent functional connectivity analysis studies have demonstrated that distinct cerebellar seed regions in the anterior portion of the crus I exhibit functional connectivity with the dorsolateral prefrontal cortex, the rostral portion of the inferior parietal lobule, and a frontal midline region bordering the pre-SMA and ACC in healthy adults ( ;  ). Conversely, the ACC exhibits a negative correlation with the cerebellum ( ), possibly reflecting its hypothesized role in the inhibition of prepotent stereotyped responses ( ;  ). In terms of anatomic connectivity,   used diffusion MRI to demonstrate disruption of WM connectivity between the cerebellum and the cingulate cortex in individuals with Friedreich ataxia, an autosomal recessive disease involving degeneration of the spinal cord and cerebellum, thereby supporting the notion of reverse cerebellar diaschisis ( ). 

The corticocerebellar–thalamocortical circuit involving the cerebellum and ACC plays a role in attention. The cerebellum is involved in attention, including anticipation/prediction of the internal conditions for a particular operation, as well as the setting of specific conditions in preparation for that operation ( ;  ).   reported that patients with schizophrenia exhibited an attenuated response of the ACC and cerebellum to degradation of the target during a continuous performance task, paralleling their limited visual attentional resources. They also observed disruption in the pattern of task-related connectivity of the ACC to the prefrontal regions.   concluded that attentional impairments associated with schizophrenia could be attributed to the corticocerebellar–thalamocortical circuit, which includes the ACC and cerebellum. Considering the role of the ACC and cerebellum in sensorimotor and attentional control, the ACC–cerebellar network may constitute a reactive–predictive controller system ( ) by which one’s own attention-contingent motor output (that is, eye-blink) is modulated by the visual input of the partner’s movement. Under the mirror configuration during the LIVE condition, the reactive–predictive controllers in two individuals work to coordinate their own behavior with the partner’s. Thus, it closes the sensorimotor circuits across the individuals. 


### Enhanced connectivity between the ACC and AIC 
  
We observed enhanced effective connectivity from the ACC to the right dAIC in the LIVE condition than in the REPLAY condition. In the present study, no emotional processes were included in the task, suggesting that the enhancements in connectivity were related to recurrent interaction via eye contact. The ACC has a strong connection to the AIC ( ;  ), most prominently in the dAIC ( ), a central hub in which several different cognitive networks converge ( ;  ). The ACC–AIC network represents the portion of the limbic mirror system related to the recognition of affective behavior ( ;  ;  ). 

 proposed that the AIC and ACC represent the basis of self-awareness by constituting the input (AIC) and output (ACC) components of a system. In such a system, the integrated awareness of cognitive, affective, and physical states first generated by the integrative functions of the AIC are then re-represented in the ACC as a basis for the selection of and preparation for responses to inner or outer events.   regarded the AIC as the probable site for awareness, based on its afferent representation of “feelings” from the body, and the ACC as the probable site for the initiation of behaviors.   proposed a “like-me” framework for the understanding of others. He suggested that imitation enables the understanding of another mind based on an understanding of actions and their underlying mental states.   observed that pain empathy relies on neural structures that are also involved in the direct experience of that emotion [i.e., the limbic mirror system (ACC, AIC)]. This finding is consistent with the Simulation Theory, which proposes that “we understand other people’s minds by using our mental states to simulate how we might feel or what we might think in a given situation” ( ).   concluded that perceiving the states of another activates neural representations encoding each state when it is experienced personally. In the eye-contact state, participants are aware that they are attending to their partner during eye contact. Therefore, given that the ACC–AIC network represents self-awareness, its activation during real-time eye contact may represent a shared mental state (i.e., awareness involving the participant and partner) such as shared attention. This interpretation is consistent with a study by  , which demonstrated that autonomic arousal is enhanced by eye contact with a live human, but not with static images of faces. The authors argued that this might be due to the enhancement of self-awareness by the presence of another person. The results of our study suggest that the self-awareness is enhanced by the social contingency generated with live humans through the interaction of each other’s attentional windows via eye-blinks and that the regulation of self-awareness by interaction might be caused by the cerebellar–cerebral networks that tap into the limbic mirror system. 


### Interbrain synchronization 
  
By comparing the degree of interbrain synchronization between the LIVE and REPLAY conditions, we found an enhancement in the MOG region related to the LIVE condition. This region is in the lateral occipitotemproral cortex (LOTC) and is almost identical to the region that shows interbrain synchronization specific to the eye-contact state ( ). Previous studies suggest that the LOTC receives both sensory inputs of a partner’s behavior ( ) and efference copies of one’s own behavior ( ;  ). Therefore, the roles of the LOTC in supporting action perception and overt action performance are closely related. The LOTC may play a role in the human action observation network ( ) that is typically attributed to the frontoparietal mirror system ( ). Thus, the MOG region may conceivably receive information about self and other’s eye-blinks. 

Based on the electroencephalography (EEG) hyperscanning experiment of the mutual gaze between mothers and infants,   found interpersonal neural synchronization. They argued that the phase of cortical oscillations reflects the excitability of underlying neuronal populations to incoming sensory stimulation ( ), a possible mechanism for temporal sampling of the environment ( ). Interpersonal neural synchronization could increase within a dyad during the course of social interaction because each partner is continuously producing salient social signals (e.g., gaze) that act as synchronization triggers to reset the phase of his or her partner’s ongoing oscillations ( ). The present study showed neural synchronization in the LOTC, which receives both visual input of others’ actions and efference copies of one’s own actions. The salient social signals were sent to the partner through gaze or blink (defining the temporal attentional window), and the motor command corresponding to which is likely delivered to the LOTC as an efference copy. The eye-blink may, thus, act as a synchronization trigger. Therefore, the cross-individual neural synchronization of the MOG represents the alignment of the temporal pattern of attention, which may optimize communicative efficiency ( ). 


### Limitations and future directions 
  
The present study is subject to several limitations. First, concerning the hyperscanning fMRI experimental design, the very long mutual gaze condition was not ecological and may be quite different from conceptions of “mutual gaze” or “eye contact” informed by daily life. This is due to our use of a blocked design, the most effective way to detect brain activation. Also, the product of our experimental design, estimations of the temporal dynamics of eye-blink entrainment, brain activation, and interbrain synchronization, could not be performed. While we could not find a significant effect of session on the eye-blink entrainment in real-time eye contact, it is possible that the eye-blinking entrainments only occur in the very first phase of mutual gaze condition in one block. By refining the experimental and analytical design, we may further gain insight into the dynamics of interindividual interaction through eye-contact and interbrain synchronization. To explore the temporal dynamics of interbrain synchronization, we are currently conducting a hyperscanning simultaneous EEG-fMRI recording that could integrate the merits of the two neuroimaging methods ( ). As the present study demonstrated the efficacy of using Akaike causality analysis to evaluate dynamic mutual interaction, future studies applying this method to EEG data in ecological settings of normal and diseased populations are warranted. 

The present study is also limited by its capacity to find interbrain synchronization only between homologous regions, but not between nonhomologous regions (i.e., frontoparietal synchronization;  ). In our setting, two participants play identical roles in eye-to-eye communication; therefore, the resonance through interbrain closed loop might occur in the homologous regions. However, the interbrain effect may also occur between nonhomologous regions. To explore this possibility, an ROI analysis based on the precise parcellation of human cerebral cortex in a human connectome project may be the most suitable ( ). Future studies adapting this method could reveal the mechanism underlying the means by which two brains are wired through eye-to-eye communication without any conscious awareness. 


### Summary 
  
In the present hyperscanning fMRI study, we focused on real-time mutual interaction during eye contact. The open-and-close timing of the attentional window, defined by eye-blinks, was entrained to that of the counterpart during real-time mutual interaction. Our findings indicate that the social interaction is nonlinear, and the influence from the partner might be amplified by the nonlinearity during the real-time interaction. Corresponding with the nonlinearly amplified behavioral coordination, real-time interaction during eye contact was found to be mediated by the amplified activation of the cerebellum and the cingulate motor cortex. This was accompanied by enhanced connectivity within the limbic mirror system. These findings underscore the notion that real-time eye contact generates an emergent property of shared attention, which is mediated by a cerebellocerebral network inclusive of the limbic mirror system. 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-15'>
<h2>15. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/24789353/' target='_blank'>24789353</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> The Neural Basis of Event Simulation: An fMRI Study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2014</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0096534</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4008581/' target='_blank'>4008581</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Study reports whole-brain fMRI (SPM8, random-effects, cluster correction) in healthy adult participants (n=20, mean age 20.65) performing tasks that explicitly require situational inference and future-prediction. Although the paradigm is framed as event simulation, 41/96 stimulus sets depicted social situations and the explicit ES contrasts engage regions known for social cognition; the authors also performed separate social vs. non-social analyses. This meets the review objective of fMRI studies of social-related processing in healthy adults. No exclusion criteria apply: results are whole-brain (not ROI-only), participants are healthy, and the paper is an original empirical fMRI study (not a review).</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Event simulation (ES) is the situational inference process in which perceived event features such as objects, agents, and actions are associated in the brain to represent the whole situation. ES provides a common basis for various cognitive processes, such as perceptual prediction, situational understanding/prediction, and social cognition (such as mentalizing/trait inference). Here, functional magnetic resonance imaging was used to elucidate the neural substrates underlying important subdivisions within ES. First, the study investigated whether ES depends on different neural substrates when it is conducted explicitly and implicitly. Second, the existence of neural substrates specific to the future-prediction component of ES was assessed. Subjects were shown contextually related object pictures implying a situation and performed several picture–word-matching tasks. By varying task goals, subjects were made to infer the implied situation implicitly/explicitly or predict the future consequence of that situation. The results indicate that, whereas implicit ES activated the lateral prefrontal cortex and medial/lateral parietal cortex, explicit ES activated the medial prefrontal cortex, posterior cingulate cortex, and medial/lateral temporal cortex. Additionally, the left temporoparietal junction plays an important role in the future-prediction component of ES. These findings enrich our understanding of the neural substrates of the implicit/explicit/predictive aspects of ES-related cognitive processes. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (45347 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
To cope with dynamically changing physical and social environments, both current situations and future transitions must be inferred from fractionally perceived environmental information. Recently, such situational inferences have been proposed to be accomplished when partially perceived event features are associated in the brain to represent the whole situation  – . Those event features include information concerning objects, agents, actions, mental states, and places that constitute a situation. By matching those event features with the event knowledge constructed through the accumulation of experience, the most likely situation is inferred. At the same time, other event features likely to appear in that situation but not perceived at that moment are also inferred based on the event knowledge. Via such completion inference, the whole situation is represented in the brain as a simulation. The situational inference process explained above is called event simulation (ES). ES is thought to provide a common basis for various cognitive processes. Those include simple perceptual prediction, situational understanding/prediction previously termed “event schema/script”, or complex social cognition such as “theory of mind” or trait inference  ,  . Thus, clarifying the detailed neural basis of ES would contribute to our understanding of these cognitive processes. 

Although previous studies have assessed the neural basis underlying ES-related cognitive processes, such as language-based situational understanding  –  and social cognition (e.g., theory of mind (TOM) and trait inference)  – , no study has clarified the ES core, the process in which event features are integrated into a coherent representation of a situation. A few recent studies assessed this ES core more directly  – . In these studies, event features (e.g., objects, agents, and backgrounds) that constitute a situation were presented in words or pictures, and the brain regions that respond to successful integration of these event features were examined. These studies demonstrated that the ES core process recruits the medial prefrontal cortex (MPFC), retrosplenial cortex (RSC), inferior parietal cortex (IPL), dorso-lateral prefrontal cortex (DLPFC), ventro-lateral prefrontal cortex (VLPFC), parahippocampal cortex (PHC), middle temporal gyrus (MTG), and temporal pole (TP). 

Although previous studies have assessed the neural basis of ES as a whole, critical ES subdivisions and the neural basis of those subdivisions have not yet been clarified. For example, whether ES recruits similar or different neural substrates when occurring explicitly versus implicitly remains unclear. ES is sometimes conducted without an explicit intention to do so; this implicit aspect of ES has great significance. For example, in daily life, an individual will usually spontaneously notice his or her own situation. In this case, ES occurs implicitly. On the other hand, although this is often the case in a laboratory experiment, it is rare that an individual will need to explicitly understand a situation in daily life. When “implicit”, the aforementioned process is not assumed to be unconscious. Instead, it is characterized by its spontaneous activation via bottom-up input from the environment, regardless of explicit intentions to do so. Another example of the importance of the implicit aspect of ES is the fact that social phenomena such as stereotypes or prejudices are problematic due to their implicit nature  – . Because these phenomena depend on ES-based trait inference, clarifying the neural mechanisms underlying the implicit aspects of ES would contribute to understanding these social phenomena. In fact, implicit aspects of various cognitive processes and their neural substrates have attracted immense attention in recent years  ,  – . However, previous studies have not differentiated the neural basis of implicit ES from that of explicit ES. Of the above-mentioned studies that directly assessed the ES core, that by Bar et al. employed only an implicit task  . Other studies employed only explicit tasks  – . So, there is an urgent need to differentiate the neural basis of implicit and explicit ES by conducting a comparison in a unified experimental framework. In the present study, we differentiated between the neural substrates of implicit and explicit ES by assuming that two cognitive processes underpin implicit and explicit ES. The first process is recruited by implicit ES (implicit ES process) and is also recruited when ES is conducted explicitly, thus providing a common ground for implicit and explicit ES. The second process is recruited together with the implicit ES process in the explicit ES (explicit ES process). We differentiated brain regions specific to those processes using the following paradigm. In one condition, subjects were shown a picture set of contextually irrelevant objects and performed an object-name-matching task. Unknown to the subjects, contextually related objects, indicating a situation, were occasionally inserted to induce implicit ES. Brain regions that increased their activity in response to this insertion were assumed to be the neural basis of the implicit ES process. In the second condition, subjects were explicitly instructed to infer the situation indicated by objects to demonstrate explicit ES. Brain activation induced in the explicit condition was compared with that induced in the implicit condition to clarify the neural basis of the explicit ES process. Based on previous findings noted above, it was expected that ES as a whole would recruit the MPFC, RSC, IPL, DLPFC/VLPFC, PHC, MTG, and TP. More importantly, it was expected that implicit and explicit ES processes would recruit different subsets of these brain regions. 

Another important aspect of ES is the future-prediction component, but the neural basis underlying this component is not yet known. To cope with dynamically changing environments, not only must the current situation be inferred but the possible future situation must also be predicted. This predictive component plays an essential role in ES. Previous studies that assessed the neural basis of future prediction emphasized that common brain networks are recruited as in episodic memory recall, including the hippocampus, PHC, MPFC, VLPFC, RSC, precuneus, posterior cingulate cortex (PCC), and the temporo-parietal junction (TPJ)  – . Based on these findings, it has been suggested that future prediction and episodic memory recall both depend on a common ‘scene construction’ process  ,  . This process is similar to the completion inference process in ES, as it integrates event features into a coherent situational representation. In addition to this completion inference process, however, future prediction additionally demands representing unexperienced future situations as hypothetical ones. Previous studies have not dissociated this key component of future prediction from completion inference itself. Consequently, the specific neural substrate of this component is still unknown. As for the candidate neural substrates of this component, we expected that the TPJ plays a primary role among the regions previously indicated to be involved in future prediction. This is because the TPJ has been consistently indicated to be involved in representing hypothetical perspective or perspective differences in previous studies on TOM, perspective taking, and self-transcendence  – . In the present study, to extract brain regions specific to representing a hypothetical situation in future prediction, the following paradigm was used. In addition to the above-explained explicit task condition in which subjects were asked to infer a situation indicated by objects, we also used a future-prediction condition in which subjects were asked to predict future situations likely to happen after those indicated by the objects had already occurred. By comparing the brain activity induced under these two task conditions, this study aimed to clarify the neural basis of the future-prediction component of ES. 


## Materials and Methods 
  
### Subjects 
  
Twenty-three healthy volunteers with no psychiatric or neurological history participated in the present study. All were right-handed as assessed using Edinburgh Handedness Inventory  . Written informed consent was obtained from all subjects prior to their participation. Data from one subject were excluded due to head motion and from two subjects because they fell asleep in the scanner. Thus, data of 20 subjects (nine female and 11 male) with an average age of 20.65 years (SD = 2.13) were analyzed. The current study was approved by the ethics committee of the Tohoku University Graduate School of Medicine. 


### Cognitive task detail 
  
Subjects participated in the following three types of matching tasks in the scanner ( ). The first task was the Object task (starts with the cue “Same?”). Following the cue, a picture set comprising three object pictures was presented. After a 4.5-sec delay period, an object name (target) was presented. Subjects were instructed to judge the congruency of the picture set and target object name. If the object name matched one of the three objects the subjects observed in the picture set, they had to respond “yes” by pushing a button with their right index finger. Otherwise, they were told to answer “no” by pushing another button with their right middle finger. Unknown to subjects, this task included two conditions. In half of the trials, the three objects in the picture set were contextually unrelated (control, Con), whereas in the remaining half of the trials, these object pictures were contextually related and indicated a situation (e.g., milk a cow;  ) to trigger an implicit ES (implicit, Imp). The second task was the Situation task (starts with the cue “Situation?”) in which subjects observed an object picture set similar to the Imp of the Object task and a target word depicting a situation. Subjects were asked to explicitly understand the situation indicated by the pictures and to answer whether this situation matched the target word (explicit, Exp). The third task was the Future-prediction task (starts with the cue “After this?”). Again, an object picture set similar to those used in the Imp and Exp conditions was presented to subjects. This time, the subject was instructed to understand the current situation indicated by the pictures (e.g., making a birthday cake) and then infer the possible future situation (e.g., starting birthday party) likely to occur afterword (future prediction, Ftr). The subject responded “yes” if the target word correctly depicted a possible future situation. In all the above conditions, the time course of trials was identical. A 1.5-s cue was followed by a 0.5-s fixation delay and then the object picture set was presented for 4-s followed by a 4.5-s delay period. Subsequently, a target word was presented for 2.5-s followed by a 3.5-s inter-trial rest period. 
   Schematic depiction of a trial for each task and condition.  
In the Object task (cue “Same?”), the subject answered whether one of the three objects presented was congruent with the subsequently presented target word (i.e., object name). Three objects presented in the Con condition were contextually unrelated, and those in the Imp condition were contextually related and indicated a situation. In the Situation task (cue “Situation?”), the subject answered whether the target word was properly depicting the situation indicated by the object pictures. In the Future-prediction task (cue “After this?”), the subject answered whether the target word was properly depicting possible future events of the indicated situation. 
  
To extract the activation associated with the ES process itself (i.e., the activation induced during the picture presentation and subsequent delay) and the activation associated with the target response (i.e., the activation induced after target presentation) separately, “incomplete” trials, which were interrupted after the 4.5-s delay period by showing an “X” sign instead of a target word, were introduced. Subjects were instructed that if they observed the “X” sign, they did not need to respond to any question and were instructed to wait for the next trial. Half of the trials in each condition (Con, Imp, Exp, and Ftr) were randomly presented as incomplete so that subjects could not predict the interruption. The purpose of including these incomplete trials was to increase the orthogonality of the hemodynamic response models between the ES and target response phases. Without incomplete trials, those two models would have considerable degrees of correlation because the ES and response phases occur in a fixed order with a small time separation relative to the time constant of the hemodynamic response function. By including incomplete trials, we were able to observe what happened when the target response phase did not follow the ES phase in half the trials, which allowed us to separate the neural response patterns of these two phases in the analysis. Because only the ES phase was included in the contrast for purposes of statistical testing, the current results are free from the effects related to the target response phase (e.g., recognition of target, matching decisions, semantic priming) that might occur in target processing. 

Each subject underwent two task sessions with 48 trials each (12 trials for the conditions Con, Imp, Exp, and Ftr). Thus, 96 trials (Con: 24 trials; Imp: 24 trials; Exp: 24 trials; Ftr: 24 trials) were presented to each subject. Each condition (Con, Imp, Exp, and Ftr) appeared in a pseudo-randomized order. At the beginning of the experiment, all subjects underwent a practice session outside of the scanner and were assured that they could solve all tasks easily. In this practice session, 12 trials were presented for each of the Con, Exp, and Ftr conditions. In each condition, picture sets different from those used in the functional magnetic resonance imaging (fMRI) session were presented. 


### Post-scanning questions 
  
Following the scanning session, we assessed whether subjects noticed that object pictures were associated with a situation in the Imp condition to ensure that stimuli presented in the Imp condition elicited implicit ES even in the absence of an explicit task requirement. First, subjects were asked the following question: “Did you notice something when you were doing Object task?” Then, they were asked more directly, “Did you notice that sometimes object pictures were associated with a situation in the Object task?” They answered “yes” or “no”. 

Additionally, we determined the extent to which subjects were familiar with the situations they saw in the Imp, Exp, and Ftr conditions. Subjects were asked to rate familiarity using a four-point scale [1 (“Not at all familiar”) to 4 (“Very familiar”)] to ensure that the results were not confounded by differences in familiarity across conditions. 


### Stimulus preparation 
  
We prepared the stimulus sets for the fMRI task paradigm described above in accordance with the following principles. First, stimulus sets were prepared so that all experimental conditions (Con, Imp, Exp, Ftr) involved the same object picture stimuli when averaged across subjects. Thus, observed differences in neural activity across conditions could not be attributed to differences in stimuli-related factors such as low-level visual processing, the object recognition process, or contextual information inherent in the objects themselves. Second, stimulus sets were prepared so that each experimental condition involved different object picture sets at the individual level. This was essential to avoid any noise caused by repetition of the stimulus in different conditions. To meet these criteria, 96 object picture sets in which objects were contextually related to a situation were prepared. The 96 picture sets were divided into four subsets (A, B, C, and D). Thus, each subgroup comprised 24 picture sets. Thereafter, scrambled versions of each subset (Ascr, Bscr, Cscr, and Dscr) were created by shuffling objects within each subset and making them contextually unrelated. Such contextually unrelated scrambled subsets were allocated to the Con condition so as to prevent recognition of the situation in this condition. The other three original subsets were allocated to the Imp, Exp, and Ftr conditions, respectively (e.g., Ascr-Con, B-Imp, C-Exp, D-Ftr). Allocation of those subsets was counterbalanced across subjects. 

Specifically, the following two-stage preliminary experiments were conducted to create the stimulus set described above. Subjects were recruited from the same subject pool (i.e., students from the same university) used for the fMRI experiment. In all, 14 (5 female and 9 male) and 12 subjects (6 female and 6 male) who did not participate in the fMRI experiment participated in the first and second experiments, respectively. Information about the age of one subject in each experiment was missing due to registration failure, and data on the age of the remaining subjects in each experiment are provided below. The average ages for the first and second experiment were 20.92 years (SD = 1.44) and 19.36 years (SD = 0.92), respectively. In the first experiment, object picture sets from which both the current and future situations could easily be imagined were selected, yielding a total of 200 object picture sets. Object pictures were taken by digital camera or obtained from publicly available Internet sources. These objects were limited to non-human objects, such as commodities, vehicles, and animals. No human images (e.g., faces) were included except for ones that appeared as part of another object (e.g., magazine cover). Subjects viewed these 200 picture sets and answered the following two questions for each: 1) Q-scn: “Can you imagine a situation from this picture set?” and 2) Q-Ftr: “Can you imagine the future situation likely to occur after the situation indicated by this picture set?” Subjects answered these questions using a four-point scale [1 (“No, I can't imagine one at all”) to 4 (“Yes, I can imagine one easily”)]. To select picture sets that ranked highly on both questions, mean ratings for each question type were obtained for each picture set, picture sets were ranked according to the lower of the two rankings, and the 96 highest-scoring picture sets were chosen. The average subjects' Q-scn and Q-Ftr ratings for these selected picture sets were 3.94±0.08 [mean ± standard deviation (SD)] and 3.83±0.10, respectively. Subsequently, the 96 picture sets were divided into four subsets (A, B, C, and D) while balancing Q-scn and Q-Ftr scores between them. 

Next, scrambled versions of the object picture sets created above (Ascr, Bscr, Cscr, and Dscr) were generated, and we determined whether these scrambled versions would prevent recognition of the situation. In the second experiment, subjects viewed both the original and scrambled picture sets and rated the likelihood of imagining a situation from those picture sets using the same four-point scale described above. The average ratings of the original and scrambled picture sets were 3.85±0.09 and 1.16±0.15, respectively. A paired   t  -test indicated that scrambled picture sets scored significantly lower than the originals (  p   = 5.22×10 ). 

Among the final 96 picture sets, 41 (42.7%) depicted a social situation. Here, a social situation is defined as a situation in which human interaction or communication is evident   (e.g., wedding dress + tuxedo + wedding cake  =  wedding ceremony). As we noted above, stimulus sets were prepared so that all experimental conditions (Imp, Exp, and Ftr) involved the same stimuli sets when averaged across subjects. Thus, the proportion of social and non-social situations was totally balanced across these conditions. 


### fMRI measurement and image preprocessing 
  
Thirty-three gradient-echo images (echo time  = 25 ms, flip angle  = 78°, slice thickness  = 3 mm, slice gap  = 1 mm, field of view  = 200 mm, matrix size  = 64×64) covering the whole brain were acquired at a repetition time of 2000 ms using an echo planar sequence and a 3-T magnetic resonance scanner (Achieva Quasar Dual, Philips Medical Systems; Best, The Netherlands). 

For each subject, data were acquired in two scanning sessions. Excluding the first two “dummy” volumes for stabilization of the T1-saturation effect, 404 volumes were acquired in each fMRI session. The following preprocessing procedures were performed using Statistical Parametric Mapping (SPM8) software (Wellcome Department of Imaging Neuroscience; London, UK) implemented in MATLAB R2009b (MathWorks; Natick, MA, USA) for whole brain analysis: correction for head motion, adjustment of acquisition timing across slices, spatial normalization using the MNI template, and smoothing using a Gaussian kernel with a full width at a half-maximum of 5 mm. 


### fMRI data analysis 
  
The following series of subtraction analyses were conducted to differentiate the brain regions specific to the implicit and explicit ES processes and to clarify the neural bases specific to future prediction. First, brain regions specific to the implicit ES process were evaluated using the contrast (Imp–Con). In the Object task, subjects were engaged in the same task in both the Con and Imp conditions. However, in the Imp condition, object pictures were contextually indicating a situation, thereby inducing implicit ES. Hence, it was assumed that differential brain activation between these conditions reflected the implicit ES process. Second, brain regions specific to the explicit ES process were evaluated using the contrast (Exp–Imp). As the same object picture sets were shown to subjects in both the Exp and Imp conditions, these conditions commonly induced the implicit ES process. Conversely, only in the Exp condition was the explicit ES process additionally induced because subjects were required to conduct explicit ES in this condition. Hence, it was assumed that the differential brain activation between the Exp and Imp conditions reflects the explicit ES process. Finally, brain regions specific to future prediction were evaluated using the contrast (Ftr–Exp). The same object picture sets were shown to subjects in both the Ftr and Exp conditions. Similarly, both conditions required subjects to explicitly understand the situations indicated by those stimulus sets. Conversely, only in the Ftr condition were subjects additionally required to infer a future situation that is likely to occur after the current situation indicated by the stimulus. Thus, it was assumed that the differential brain activation between the Ftr and Exp conditions reflects a future-prediction component of ES. 

To conduct the series of subtraction analyses depicted above, a conventional two-level approach was adopted using SPM8. A set of regressors was generated by convolving a canonical hemodynamic response function provided by SPM8 with a series of epochs. For each condition (Con, Imp, Exp, and Ftr), the period from the time of picture set presentation to the end of the subsequent 4.5-s delay was modeled as the regressor of interest. Additionally, the target (or “X” mark) and inter-trial rest period were modeled individually as regressors of no interest. These regressors of no interest were not included in contrasts for statistical inference. A voxel-by-voxel multiple regression analysis of these regressors was applied to the preprocessed images for each subject. Statistical inference on contrasts of parameter estimates was then performed at the second-level between-subjects (random effects) model using a one-sample   t  -test. The statistical threshold was set to   p  <0.001 for height and corrected to   p  <0.05 for multiple comparisons using cluster size assuming the whole brain as the search volume  . Additionally, results surviving a threshold of   p  <0.001 without multiple comparisons in two regions are reported here; namely, the PHC and the TPJ. This is because their contribution to ES was expected based on previous findings (see the  ). 

To reject the possibility that the brain activation detected in the main subtraction analysis was due to the difference in task difficulty between conditions, an additional parametric modulation analysis using response times (RTs) as an explanatory variable was conducted. It was reasoned that if the brain activation detected in the main subtraction analysis reflected the difference in task difficulty or general cognitive load commonly recruited in the two conditions included in a contrast, then the activation of these regions should be correlated with RTs in the relative control condition of that contrast. The direction of the correlation should be positive if RTs in the target condition were longer than those in the relative control condition and vice versa. This possibility was evaluated as follows. A parametric modulation analysis was conducted that sought brain regions in which activity was correlated positively or negatively with RTs in each condition. This was performed by expanding the original model used in the main analysis by adding RTs for each condition as parametric modulators. Next, if RTs differed between the two conditions included in a contrast in the main analysis, we determined whether each peak voxel detected in that contrast also appeared as RT-correlated areas in the relative control condition at the statistical threshold of uncorrected   p  <0.05 in the second analysis. 

As the explicit ES process-specific brain regions revealed by the contrast (Exp – Imp) were well known social cognition-related regions (see  :  )  ,  , we examined whether this result was affected by the social factor of task stimuli (i.e., whether the object picture set indicated a social or non-social situation). To clarify this issue, we conducted another additional analysis in which the effects of (Exp – Imp) in social events and that in non-social events were tested separately. First, trials in Imp and Exp conditions were split into ones that indicated social and non-social situations (i.e., Imp_social, Imp_nonsocial, Exp_social, and Exp_nonsocial), and modeled as separate regressors, respectively. Then, the two contrasts (Exp_social – Imp_social) and (Exp_nonsocial – Imp_nonsocial) were tested. If the original (Exp – Imp) comparison was not affected by social factors and rather reflected general situational inference load, then both new social and non-social contrasts would replicate the activation pattern seen in the original comparison. Considering that sample trial number in each condition was reduced in this analysis, the statistical threshold was set to p<0.005 without multiple comparisons. 
   Activation areas specific to the implicit and explicit event simulation (ES) processes.  
All voxels except for the regions described below are significant at a statistical threshold of   p  <0.001, corrected to   p  <0.05 for multiple comparisons using the cluster size, assuming the whole brain as the search volume. The result of the left parahippocampal cortex in the explicit ES process is thresholded at   p  <0.001 (uncorrected). Error bars indicate standard deviations (SDs). IPL: inferior parietal lobule. PCC: posterior cingulate cortex. RSC: retrosplenial cortex. R: right. L: left. The coordinates in the Montreal Neurological Institute (MNI) standard space are indicated. 
  
The fMRI and behavioral data used in the above analysis are available to all interested researchers upon request (contact the corresponding author). 



## Results 
  
### Behavioral data 
  
The accuracies of the conditions Con, Imp, Exp, and Ftr were 96.25±6.33%, 95.00±6.28%, 97.50±3.92%, and 89.58±9.32%, respectively. A one-way analysis of variance (ANOVA) indicated a significant effect of condition;   F  (3,76) = 5.8678 (  p  <0.01).   Post hoc   Bonferroni's multiple comparison tests revealed that this difference was due to the lower accuracy in the Ftr condition than in the Con (  p  <0.05) and Exp (  p  <0.05) conditions. 

Second, the RTs for the Con, Imp, Exp, and Ftr conditions were 1059.62±214.51 ms, 998.61±197.03 ms, 1007.82±197.13 ms, and 1246.55±204.59 ms, respectively. A one-way ANOVA indicated a significant effect of condition;   F  (3,76)  = 39.418 (  p  <0.01).   Post hoc   Bonferroni's multiple comparison tests revealed that the RTs in the Ftr condition were significantly longer than were those in the Con (  p  <0.01), Imp (  p  <0.01), and Exp (  p  <0.01) conditions. Additionally, the RTs in the Con condition were longer than were those in the Imp condition (  p  <0.05). No statistically significant RT difference was found between the Imp and Exp or the Con and Exp conditions. 

Post-scanning questions revealed that subjects noticed that object pictures were associated with a particular situation in Imp condition. In response to the first question, 16 of 20 subjects (80%) mentioned that they saw some object picture sets that indicated a situation in the Object task. This proportion increased to 100% when subjects were more directly asked, in the second question. This clearly indicates that implicit ES was elicited in the Imp condition even in the absence of an explicit task requirement. 

Subjects' familiarity with situations presented in the Imp, Exp, and Ftr conditions were 2.73±0.72, 2.80±0.66, and 2.70±0.52, respectively. A one-way ANOVA revealed no statistically significant difference. Thus, the current results are not confounded by differences in familiarity. 


### fMRI data 
  
#### Implicit ES process-specific areas 
  
Implicit ES process-specific regions were evaluated using the contrast (Imp–Con). A statistically significant activation was found in the bilateral IPL, left middle temporal gyrus (MTG), bilateral anterior VLPFC, right DLPFC, and bilateral precuneus ( ;  ). In the right DLFPC region, the activation peak was located at the lower end of the middle frontal gyrus (MFG) whereas the cluster itself spread over both the MFG and inferior frontal gyrus. Because the 1  cluster right IPL reflected task difficulty between conditions rather than implicit ES processes (see below), the activation profile of the 2  cluster/1  peak (left IPL) is shown in  . 
   Clusters of activation.        

#### Explicit ES process-specific areas 
  
Explicit ES process-specific regions were evaluated using the contrast (Exp–Imp). A statistically significant activation was found in the dorsal/ventral MPFC and adjacent ACC, bilateral TP, left PCC and adjacent RSC, and left TPJ (  and  ). Additionally, a significant activation was found in the left PHC at a threshold of   p  <0.001 (uncorrected). Although this region did not survive the multiple comparisons analysis, it is reported due to the hypothesis describing PHC involvement in ES, which was based on previous findings (see the  ). The activation profile of the 1  cluster/1  peak (left PCC/RS) is shown in  . 


#### Future-prediction-specific areas 
  
Future-prediction-specific regions were evaluated using the contrast (Ftr–Exp). A statistically significant activation was found in the left TPJ at a threshold of an uncorrected   p  <0.001 ( ;  ). Although this region did not survive the multiple comparisons analysis, it is reported for two reasons: first, due to the hypothesis concerning TPJ involvement in future prediction (see the  ); second, the   p   value of this region after correction was close to significance (  p   = 0.06). The activation profile of the 1  cluster/1  peak (left TPJ) is shown in  . 
   Activation areas specific to future prediction.  
The result is thresholded at   p  <0.001, corrected to   p  <0.06 (  k   = 133) for multiple comparisons. Error bars indicate SD. TPJ: temporoparietal junction. R: right. L: left. The coordinates in the MNI standard space are indicated. 
  

#### Additional parametric modulation analysis 
  
Behavioral data showed that RTs differed between conditions in the contrast (Ftr – Exp). RTs in the Ftr condition were longer than those in the Exp condition. If the brain activation revealed by the contrast (Ftr – Exp) was caused by increased ‘general’ task difficulty or cognitive load reflected in longer RTs, then the activity of these regions should have been greater when trial RTs were longer even within the Exp condition. In other words, the activity in these regions should have been positively correlated with trial RTs in the Exp condition. We looked into this possibility by conducting an additional parametric modulation analysis which sought the brain regions in which activity was positively correlated with trial RTs in the Exp condition (thresholded at uncorrected p<0.05) and assessed whether the left TPJ peak revealed by the (Ftr – Exp) contrast fell within these regions; this was not the case. Thus, the left TPJ activity reflected a qualitative difference in cognitive processes between the Ftr and Exp conditions (i.e., future prediction) rather than an increase in general task difficulty or cognitive load. 

Similarly, RTs differed between conditions in the contrast (Imp - Con). This time, RT in the Imp condition was shorter than that in the Con condition. Thus, following similar logic as above, if brain activations revealed by the contrast (Imp – Con) just reflected a decrease in general task difficulty or cognitive load in the Imp condition, the activity in these regions should have been negatively correlated with RTs in the Con condition. We examined this possibility by conducting an additional parametric modulation analysis which sought the brain regions in which activity was negatively correlated with RTs in the Con condition (thresholded at uncorrected p<0.05) and assessed whether activation peaks found in the contrast (Imp – Con) fell within these regions. The right IPL, left MTG, and right anterior VLPFC met that criterion ( ; right-most column), indicating that these regions' activity could have reflected differences in general task difficulty or cognitive load between the Imp and Con conditions. In contrast, other regions revealed by the contrast (Imp – Con) reflected a qualitative difference in cognitive processes between these conditions (i.e., implicit ES process). 


#### Additional analysis to assess the effect specific to social situations 
  
Brain regions specific to the explicit ES process in social events and those specific to non-social events were separately evaluated by testing the contrasts (Exp_social – Imp_social) and (Exp_nonsocial – Imp_nonsocial), respectively. Both tests replicated similar activation patterns observed in the original (Exp – Imp) comparison (see  ). Thus, we suggest that the explicit ES process-specific regions we showed above ( ) reflect general situational inference processes rather than any social situation-specific factors. 




## Discussion 
  
In the present study, the neural basis of ES, or the process by which partially perceived event features are associated in the brain to represent the whole situation, was clarified. Two major findings were revealed by this study. First, implicit and explicit ES processes depend on different neural substrates. Second, the future-prediction component of ES increases the activity of the left TPJ among those ES networks. These issues are discussed in detail in the following sections. 

### Implicit versus explicit ES 
  
The present results suggest that implicit and explicit ES processes depend on different neural substrates. The implicit ES process, which provides the common ground for implicit and explicit ES, recruits the left anterior VLPFC, right DLPFC, bilateral precuneus, and left IPL. Conversely, the explicit ES process, which characterizes the explicit ES, recruits the dorsal and ventral part of the MPFC and its adjacent ACC, left PHC, bilateral TP, left PCC/RSC regions, and left TPJ. In addition to the regions stated above, the right IPL, left MTG, and right anterior VLPFC were also associated with the implicit ES network. However, those regions reflected the difference in task difficulty between conditions in that contrast rather than the ES itself. Thus, those regions are not discussed. 

The neural basis of implicit and explicit ES processes has not been distinguished thus far. The current findings provide the first evidence of such a dissociation and contribute to an understanding of the neural mechanisms underlying ES. Because ES provides the common basis for various cognitive processes from situational understanding to social cognition, clarifying its neural basis in terms of both implicit and explicit aspects is of great significance. For example, an understanding of the neural mechanisms underlying the implicit and explicit aspects of various social cognitive processes would be enriched. The difference between explicit and implicit processes in social cognition has been of great importance for many years, and clarification of the neural bases of these processes will have important ramifications  ,  ,  . The C-system/X-system model proposed by Lieberman   et al  . is well-known  ,  . This model comprises a list of brain regions recruited in implicit and explicit processes and was constructed by reviewing the literature on social cognition and related cognitive processes. In this model, the orbitofrontal cortex, basal ganglia, amygdala, lateral temporal cortex, and dorsal ACC regions are classified as the implicit/X-system. Conversely, the lateral prefrontal cortex, medial temporal lobe (MTL), rostral ACC/MPFC, and lateral/medial posterior parietal cortex (PPC) comprise the explicit/C-system. The current results provide additional information regarding this distinction of implicit/explicit systems from the viewpoint of ES. These findings confirm, in part, the present C-system/X-system model by showing that the explicit process recruits the MPFC, MTL, and PPC. Furthermore, within these regions, the lateral PPC was recruited not only by the explicit process but by the implicit process as well. The explicit and implicit processes activated different subregions within the lateral PPC. Similarly, it was found that different subregions in the medial PPC were recruited by the explicit and implicit processes, respectively. These findings will help to elaborate the current C-system/X-system model and might enrich our understanding of the neural substrates of social cognitive processes, particularly those such as stereotyping or prejudice, in which implicit aspects play a substantial role. 

The regional distinction of the implicit/explicit network revealed here is supported by previous studies investigating ES-related cognitive processes. For example, the present study revealed that the left anterior VLPFC is engaged in the implicit process, and lesions in the VLPFC are known to reduce implicit stereotypical attitudes  . Because stereotyping is one type of trait inference based on ES, this finding is consistent with the current findings. Similarly, a previous study demonstrated that the MPFC is engaged in the explicit theory-of-mind process, whereas the DLPFC is engaged in implicit theory-of-mind  . This distinction is also consistent with the current results. Further evidence has shown that the MPFC is involved in the explicit aspects of theory of mind. This region was activated more when subjects believed they were playing games with a human opponent compared with a computer program  ,  . Similarly, this region is known to be activated more in children than in adults when understanding others' minds, reflecting a greater explicit process in children  . 

Finally, the left PHC is engaged in the explicit ES process. This seemingly contradicts Bar   et al  .'s findings that the PHC is recruited during contextual processing of situation-related objects in the implicit task  . However, in the same study, the posterior part of the PHC processed place-related contextual information (e.g., a farm), whereas the anterior part processed more complex contextual information (e.g., a birthday), which is similar to the current findings. This anterior part was activated only when subjects were explicitly instructed to process such contextual information  . Actually, this anterior part was comparable to the region identified in this study; hence, the findings of Bar   et al  . are consistent with the present results overall. In short, the implicit/explicit ES network suggested in this study is well supported by previous reports and will enable generation of an overview of this phenomenon. 


### The left TPJ and future prediction 
  
The present results suggest that the left TPJ plays an important role in representing hypothetical situations, which characterizes future prediction. Because predicting future situations from fractionally perceived environmental information is essential to cope with a dynamically changing environment, clarifying the neural basis of such a process has great significance. Our suggestion is supported by the fact that the left TPJ was consistently involved in representing hypothetical perspective or perspective differences in previous studies on TOM, perspective taking, and self-transcendence  – . Interestingly, in the present study, left TPJ activation was also detected as an explicit ES process-related region, along with other regions such as the MPFC, TP, and PCC. We are not certain if this explicit ES process-related left TPJ is exactly the same region as the left TPJ we found to be future prediction-specific. If the explicit ES-process and future prediction recruit the same left TPJ region, it could be that the left TPJ basically engages in explicit ES, and when future prediction requires an additional load to represent a hypothetical situation, the left TPJ boosts its activity for perspective processing. In the present study, we observed future prediction-specific activity in the left but not right TPJ. This kind of left dominance has been reported in relation to the linguistic nature of the task in previous studies on perspective processing  ,  . In the present study, targets of the matching task were presented in words, so it is possible that after the subject inferred a future situation from object pictures they sought the proper word (i.e., name) for that situation. This linguistic load of the task could account for the TPJ's left dominancy in the present study. 

Given that subjects were less accurate and had a longer RT in the Ftr condition than in the Exp condition, one might think that the left TPJ activity identified with the contrast (Ftr – Exp) simply reflects the effect of general task difficulty or cognitive load which was relatively greater in the Ftr condition. However, we think this is unlikely because of the following reasons. First, we directly showed that activity in the left TPJ was not correlated with RTs, which reflect general cognitive load common to both the Ftr and Exp conditions, by conducting an additional parametric modulation analysis. Furthermore, previous studies showed that TPJ activity reflecting general cognitive load, such as attention or control demand, is right dominant  – . So, if the left TPJ activity in our study reflected an increase in general cognitive load in the Ftr condition, it would be unlikely for us to not to also observe this activity in the right TPJ. 

As subjects were required to match the future situation they inferred from object pictures to target in the Ftr condition task, one might think that the left TPJ activity observed in this condition would reflect subjects' intention to infer a future situation that the experimenter had in mind. However, we think that this is unlikely due to the following reasons. First, our task did not require subjects to hit the correct answer in the first place, and did not provide any feedback on hits or misses. Thus, subjects' motivation to infer the correct answer that the experimenter had in mind should have been very low. Second, if some of the subjects were inclined to infer how the experimenter labeled stimulus situations, then this should also be true in the Exp condition. Thus, it is unlikely that such a process is reflected in the activation derived from the comparison (Ftr – Exp). 



## Conclusions 
  
In conclusion, these findings show that implicit and explicit ES processes have different neural substrates and that the left TPJ plays an important role in the future-prediction process of ES. It is assumed that the implicit, explicit, and future-prediction sub-processes and their underlying neural substrates collaborate to support ES. Because ES is thought to provide a common basis for various cognitive processes ranging from simple perceptual prediction to complex social cognition, such as theory of mind, these findings enrich the understanding of the neural substrates of the implicit/explicit/predictive aspects of those cognitive processes. Moreover, it is proposed that these results provide a good reference point for future studies that aim to elucidate a unified explanation for these cognitive processes from the viewpoint of neuroscience. 


## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-16'>
<h2>16. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31269199/' target='_blank'>31269199</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Social evaluations under conflict: negative judgments of conflicting information are easier than positive judgments</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Soc Cogn Affect Neurosci</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1093/scan/nsz045</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6778826/' target='_blank'>6778826</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study meets all inclusion criteria: it reports an fMRI experiment in which healthy adult participants (N=20; ages 18–29) performed a social task (forced-choice social evaluations of target persons across situations). Whole-brain analyses are reported (multilevel whole-brain MLM with voxelwise results and cluster thresholds), with ROI follow-ups but not limited to ROI-only reporting. Participants are healthy and within the 18–60 age range. The paper is an original empirical fMRI study (not a review or meta-analysis) and does not report data from clinical populations. Therefore it should be included in the meta-analysis of fMRI studies of social-related processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
In the current study, we used functional magnetic resonance imaging to investigate how the brain facilitates social judgments despite evaluatively conflicting information. Participants learned consistent (positive or negative) and ambivalent (positive and negative) person information and were then asked to provide binary judgments of these targets in situations that either resolved conflict by prioritizing a subset of information or not. Self-report, decision time and brain data confirm that integrating contextual information into our evaluations of objects or people allows for nuanced (social) evaluations. The same mixed trait information elicited or failed to elicit evaluative conflict dependent on the situation. Crucially, we provide data suggesting that negative judgments are easier and may be considered the ‘default’ action when experiencing evaluative conflict: weaker activation in dorsolateral prefrontal cortex during trials of evaluative conflict was related to a greater likelihood of unfavorable judgments, and greater activation was related to more favorable judgments. Since negative outcome consequences are arguably more detrimental and salient, this finding supports the idea that additional regulation and a more active selection process are necessary to override an initial negative response to evaluatively conflicting information. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (40891 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
Every day we evaluate and interact with others across a range of situations. Because human behavior is complex, it is not uncommon that information we gather about others is marked by ambivalence, for example, when we perceive a person as cold but competent. Often, we are forced to resolve such evaluative conflict toward a favorable (e.g. collaborate with this person) or unfavorable judgment (e.g. do not collaborate). In the current article, we extend existing literature by investigating how the brain facilitates these social decisions by weighing evaluative information in line with affordances of the situation. Importantly, we provide data suggesting that negative judgments can be considered the easier, ‘default’ response when experiencing evaluative conflict. 

Social evaluations are influenced by aspects of the task or situation that provide goals in relation to which a person or object is evaluated. Thereby, situational affordances facilitate flexible, nuanced evaluations ( ;  ). In a recent study, we suggested that situational affordances can resolve evaluative conflict by prioritizing specific information; that is, we may judge someone positively in a specific situation despite knowing that the person also has negative features ( ). For example, we may judge a colleague who is charming and lazy positively when deciding whether to invite him or her to a social event because we prioritize the positive trait (charming) over the more negative one (lazy). Accordingly, affordances of the situation can also fail to resolve conflict if features of opposite valence remain relevant for the current judgment. For example, choosing whether to organize a social event with a friend who is charming and lazy makes both positively (i.e. charming) and negatively evaluated traits (i.e. lazy) important and evaluative conflict remains ( ). These situations of evaluative conflict and specifically how judgments are facilitated despite evaluative conflict are the focus of the current study. 
  
Proposed processing of evaluative information in line with situational affordances. 
  
Cognitive conflict is traditionally studied in paradigms where a more salient, default response interferes with an objectively correct response (e.g. Stroop task and Eriksen Flanker task). Interestingly, there is no objectively correct response when conflict occurs between subjective evaluations, and the default response in these evaluative conflicts is unclear. We suggest that in such cases, negative judgments are the easier, default response based on two theoretical approaches. First, psychologists and neuroscientists have theorized that conflicts generate negative value (Botvinick, 2007; Braem et al., 2017; Dreisbach & Fischer, 2012; Inzlicht et al., 2015; Schouppe et al., 2015). For example, in a facial electromyographic study using a variant of the current impression formation paradigm, participants expressed less positive affect when ambivalent person information remained conflicted in the evaluation situation compared to when ambivalence was resolved (Nohlen et al., 2016). The negative value of conflict has also been suggested to extend to evaluations. Direct evidence comes from a study by Fritz &\Dreisbach (2013), who showed that presenting conflict (incongruent Stroop) primes increases the number of negative judgments of neutral targets (words or Chinese pictographs) that followed these primes. 

Second, some have argued for a greater impact of negative information on evaluations because it arguably outweighs positive information in terms of salience and outcome consequences ( ;  ;  ). For example, animals that are conflicted between approaching and avoiding a predator-infested water source tend to show avoidance behavior ( ). This bias may be due to the fact that ignoring negative information can instill higher costs (e.g. being eaten) than ignoring positive information (e.g. drinking water;  ). Similarly, negative judgments that insinuate avoidance in social situation (e.g. do not collaborate) could represent the ‘safer choice’ by maintaining the status quo when feeling torn between positive and negative evaluations (cf.  ). 

A tendency toward negative social judgments on the basis of conflicting person information can thus be expected because they may be easier due to the negative value of conflict which influences evaluations (e.g. Botvinick, 2007; Fritz & Dreisbach, 2013), and because negative information arguably outweighs positive information in terms of salience and outcome consequences (Gray & McNaughton, 2000; Rozin & Royzman, 2001). 

If negative judgments are the easier response in evaluative conflicts, positive judgments should be more effortful and take more time. Supporting this argument, research has shown that even though ambiguous (i.e. surprised) facial expressions are primarily judged as negative, positive judgments become more likely when participants take more time to evaluate the stimulus ( ;  ;  ). This suggests that overriding an initial negative response to interpret an ambiguous stimulus positively requires additional regulatory processes; we need to invest effort and actively attend to positive information ( ,  ;  ). 

Many models of control and executive functioning focus on the interaction of the anterior cingulate cortex (ACC) and dorsolateral prefrontal cortex (DLPFC) to resolve such complex decision situations ( ;  ;  ). These domain-general regions are also more active in impression formation task when evaluations are updated with information that is inconsistent with prior information ( ;  ). Because of their engagement during many tasks, it has proven difficult to pinpoint the specific role of these regions. Interpretations of dorsal ACC’s (dACC’s) function thus vary from conflict monitoring ( ) and detection (e.g.  ) to violation of expectancies ( ), negative affect and pain ( ) or comparisons of value outcomes, to name a few ( ;  ;  ;  ). Even though there is thus some debate on the specifics of dACC functioning (e.g.  ;  ), it is widely agreed that dACC is engaged when tasks are more difficult and effortful as is, for example, the case when we have to form an integrative judgment from conflicting information ( ). Recently, the Expected Value of Control theory ( ) suggested that dACC has the role of a ‘controller’ that detects and signals an increased need for control through a cost–benefit analysis for optimal control allocation ( ;  ). Important in the current paradigm, these control-eliciting situations are often those in which one behavior, generally referred to as the default response, is suppressed in favor of another behavior that serves current goals better ( ;  ). 

According to this idea, difficult choice situations signaled by the ACC are relayed to the DLPFC, which is critically involved in the implementation of control ( ). Specifically, DLPFC has been associated with biasing processing in line with salient goals, meaning that it is involved in attending to task-relevant information and selecting context-appropriate responses ( ;  ). Supporting this, Hughes   et al.   ( ) found both dACC and DLPFC to play a role in an intergroup social judgments task. A failure to engage these regions was associated with increased ingroup bias in that participants did not adjust their impression of ingroup members to incorporate negative information and stuck to their default (biased) response. Based on the idea that negative judgments are the default response in situations of evaluative conflict, positive judgments should represent a move away from the default response and thus be mediated by greater DLPFC and dACC activation. 

## Present research and hypotheses 
  
The goal of our study was to investigate how the human brain facilitates social judgments when information is conflicting. Two aspects were central. First, we were interested in replicating our previous work showing the flexibility of ambivalent person evaluations with the idea that the same positive and negative person information elicits evaluative conflict in some but not in other situations ( ). Second, we examined the role of dACC and DLPFC in biasing evaluations toward positive or negative judgments when evaluative conflict remains. As far as we know, this is the first study investigating whether blood oxygen level-dependent (BOLD) signal can be related to the valence of social evaluations. 

We used a novel forced-choice task in which participants judged target persons described by consistent (positive or negative) or ambivalent (positive and negative) traits in different situations that either allowed for prioritizing some traits over others (conflict is resolved) or not (conflict remains unresolved; cf.  ). If negative judgments of conflicting information are the default, we should find an interaction effect of the valence of social judgment (positive, negative) and the presence of evaluative conflict on BOLD signal. More specifically, dACC and DLPFC response should be stronger if participants experience evaluative conflict and override the default negative judgment and judge the person positively. Accordingly, weaker dACC and DLPFC activation should be related to negative judgments under evaluative conflict. If conflict does not have a negative value that influences evaluations, brain response to the valence of social judgments should be independent from conflict. 


## Methods 
  
### Participants 
  
Participants were 20 adults (11 male, 9 female) in the age range of 18 to 29 years (  M   = 22.7; s.d., 2.60). Participants provided informed consent, had normal or corrected-to-normal vision, and had no history of neurological problems. Nineteen of 20 participants were right handed. All procedures were approved by the local ethical committee. 


### Design and procedure 
  
#### Target persons 
  
Two to 5 days before scanning, participants received descriptions of four male target persons that consisted of a list of traits and a short text to make the traits more memorable. One target was described by positive traits (friendly, charming, enthusiastic, intelligent), one by negative (dominant, jealous, lazy, dumb), and two by the combination of the two positive and two negative traits each (dominant, jealous, enthusiastic, intelligent; friendly, charming, lazy, dumb). The combinations of names and traits were counterbalanced across participants, and we used a pretest (  N   = 34; Supplementary Material S1) to ensure that the trait combinations were evaluated as positive, negative or ambivalent. Participants memorized the combinations of names and traits before coming to the laboratory and were verbally tested on recall during take-in. If participants were not able to recall the traits and names of the targets, they were given additional time to learn them. Because we did not want differences in knowledge of the name–trait combinations to introduce noise in the data, exposure to the pairs may have varied between participants. Post-relearning, all participants were able to quickly recall the combinations when prompted. 


#### Evaluation situations 
  
The four target persons were evaluated in 21 different situations (cf.  ). All situations were combined with each of the four target persons (84 trials). Based on a pretest (S1), situations were selected that varied in the degree to which they resolved conflict between ambivalent trait information by prioritizing a subset of either positive or negative traits. In the pretest, we used a one-item adaptation of  ) subjective ambivalence scale, which assesses experienced conflict by asking participants to evaluate the degree to which they experienced ‘mixed feelings and/or thoughts’ toward each target person (described by their specific traits) in each of the different evaluation situations on a scale ranging from 0 (not at all) to 100 (very much). Results were used to categorize the combinations of ambivalent target persons and evaluation situations as representing either situationally resolved ambivalent (2 target persons × 10 situations = 20 trials), or unresolved ambivalent judgments (2 target persons × 11 situations = 22 trials), resulting in three critical trial types based on the combination of person traits and evaluation situation ( ). Note that the situation did not have to resolve conflict when targets were described by positive or negative (i.e. consistent) traits; they elicited unconflicted judgments across all situations (2 target persons × 21 situations = 42 trials). Whether situations resolved conflict between ambivalent target information was dependent on the specific target; the same situation could thus be categorized as situationally resolved ambivalent for one target and unresolved for another (Supplementary Material S2 for all stimuli).  Additionally, a manipulation check was added to this study to test whether this categorization was successful (see  ). 
  
(A) Timing sequence of an experimental trial. (B) Example trial of each trial type. 
  


### Social Judgment task 
  
#### Functional magnetic resonance imaging social judgment task 
  
In the scanner, participants indicated their judgment (‘yes,’ ‘no’) to each combination of target person and evaluation situation by pressing one of two buttons with their right index and middle finger. Choice labels were counterbalanced between participants. Participants completed one functional run of 84 randomly presented trials with a 5 s break after every 21 trials. Trials started with a fixation cross (500 ms), and stimuli were presented until participants responded. After the response, participants saw a white dot on a black screen with varying presentation times (min, 4000 ms; max, 6600 ms) before the next trial ( ). Responses were recoded so that yes responses represent positive judgments and no responses represent negative judgments of the person in that situation. 


#### Manipulation checks 
  
##### Before scanning: assessing ambivalence toward target persons 
  
To confirm that information about the target persons was indeed perceived as consistent or conflicted, we assessed experienced ambivalence toward the four target persons with the subjective ambivalence scale ( ). This scale assesses psychological conflict with three items anchored with ‘Toward this person I… have completely one-sided feelings/feel no conflict/feel no indecision’ (0) and ‘have mixed feelings/feel maximum conflict/maximum indecision’ (100). Participants responded on a slider without numeric labels (α = 0.71). Ambivalence was calculated by taking the mean of these questions. 


##### After scanning: assessing ambivalence toward each target person in each situation 
  
To verify that we correctly categorized the combinations of person information and evaluation situation as conflicting or conflict resolved on the basis of pretest data, participants indicated their ambivalence toward each target person in each situation using the same scale ( ; e.g. ‘I have mixed feelings/feel conflict/feel indecision about collaborating with X’). Responses were given on a slider (0–100) without numeric labels (α = 0.93). 




### Magnetic resonance imaging data acquisition 
  
Imaging was conducted with a 3.0-T Philips Achieva scanner at the Spinoza Centre for Neuroimaging in Amsterdam. Head motion was limited by placing foam inserts around the head inside the head coil. Stimuli were presented using E-Prime and projected onto a screen in the magnet bore, which participants could see through a mirror attached to the head coil. Functional data were obtained using T2*-weighted echo-planar imaging in one event-related run (84 trials). The first two dummy scans were removed to allow for equilibration of T1 saturation effects [time repetition (TR), 2 s; time echo (TE), 28 ms; voxel size, 3 × 3 × 3 mm; field of view (FOV), 240^2]. A high-resolution T1-weighted sagittal scan was collected as anatomical reference (TR, 9.56 s; TE, 4.6 s; voxel size, 1.2 × 1.2 × 1.2; FOV, 224^2). 


### Functional magnetic resonance imaging preprocessing 
  
Data were preprocessed using FEAT (FMRI Expert Analysis Tool) Version 6.00, part of FMRIB’s Software Library (FSL,   www.fmrib.ox.ac.uk/fsl  ). Data were corrected for motion using FMRIB’s Linear Image Registration Tool (MCFLIRT; (FSL’s Motion Correction using FMRIB’s Linear Image Registration Tool;  ); the brain was extracted using FSL’s Brain Extraction Tool (BET;  ) and spatially smoothed using a Gaussian kernel (full width at half maximum [FWHM] = 5 mm). The four-dimensional data set was grand-mean intensity normalized by a single multiplicative factor. We applied a high-pass temporal filter (Gaussian-weighted least-squares straight line fitting, with σ = 50 s). Registration to standard space images was carried out using FLIRT ( ;  ). 



## Results 
  
### Behavior analysis 
  
#### Manipulation checks 
  
##### Before scanning: assessing ambivalence toward target persons. 
  
Results on the subjective ambivalence scale confirmed that the combination of traits successfully created unconflicted (consistent) or conflicted evaluations of the target persons independent of evaluation situation. Participants experienced less conflict regarding persons described by positive or negative traits (  M   = 11.03, SE  = 2.24) than toward those described by positive and negative traits [  M   = 40.67, SE  = 3.13;   t  (19) = −8.610,   P   < 0.001,   r   = 0.89]. 


##### During scanning: response behavior 
  
In line with the categorization, target persons described by positive traits were evaluated positively in 416 of 420 trials (99%) independent of evaluation situation, and negatively described targets were evaluated negatively in 399 of 420 trials (95%). Correspondingly, judgments were mixed when target persons were described by positive and negative traits; positive judgments were given in 433 of 840 trials (51.5%) and negative judgments in the remaining 407 trials (48.5%). Splitting ambivalent trials according to situational resolution of conflict showed that negative judgments were given in 181 of the 400 conflict-resolved ambivalent trials (45.3%) and in 226 of the 440 unresolved ambivalent trials (51.4%). This difference was significant in that participants judged ambivalent target persons negatively more often when conflict remained unresolved (51.4%) compared to when it was situationally resolved [45.3%;   F  (1,19) = 8.09  , P   = 0.01,   η   = 0.30]. 


##### After scanning: assessing ambivalence toward each target person in each situation 
  
We assessed experienced conflict toward target persons in each evaluation situation to verify the pretest-based categorization between situations that resolved conflict and those that did not. Results confirmed the expected main effect of trial type [consistent, situationally resolved ambivalent, situationally unresolved ambivalent;   F  (1.27,24.14) = 33.13,   P   < 0.001,   η   = 0.64 (Greenhouse–Geisser corrected)]. Experienced ambivalence toward unconflicted trials (  M   = 7.96, SE  = 2.5) was lower than toward conflict-resolved ambivalent trials (  M   = 23.16, SE  = 3.00;   P   < 0.001), which was lower than ambivalence toward conflict-unresolved ambivalent trials (  M   = 31.15, SE  = 3.74,   P   < 0.001). The pattern of results provides confidence in the categorization into three trial types by combining trait information with evaluation situations. 



#### Decision times 
  
The time it takes to make a judgment provides an indication of judgment difficulty. To confirm that judgments were more difficult when conflict was not situationally resolved and to verify that negative judgments are easier when experiencing conflict, we conducted a repeated-measures analysis of variance (ANOVA) comparing decision times between trial type (consistent, resolved ambivalent, unresolved ambivalent) and the judgment participants provided (positive, negative). Expectedly, trial type influenced decision times [  F  (2,38) = 37.89,   P   < 0.001,   η   = 0.66]; participants were quickest to evaluate persons with consistent traits (  M   = 2.73 s, SE  = 0.13 s) and somewhat slower when traits were conflicted but resolved by situational affordances (  M   = 3.84 s, SE  = 0.28 s;   P   < 0.001). Judgments took longest when traits were conflicted and remained conflicted in the evaluation situation (  M   = 4.20 s, SE  = 0.31 s;   P   = 0.02), suggesting that these were experienced as most difficult. As expected, there was no main effect of response behavior, and participants were equally quick in providing negative and positive judgments [  F  (1,19) = 1.53,   P   = 0.23]. 

Critically, we found the expected interaction of response behavior and trial type [  F  (2,38) = 6.54,   P   = 0.004,   η   = 0.26]. Confirming that negative judgments of conflicting stimuli are the easier response, decision times were quicker when participants judged situationally conflicting targets negatively (  M   = 3.95 s, SE  = 0.30 s) than positively (  M   = 4.45 s, SE  = 0.34 s;   P   = 0.03). In line with hypotheses, no difference in decision times between positive and negative judgments was found for ambivalent stimuli when situational affordances resolved conflict (  P   = 0.24). Regarding consistent stimuli, positive judgments were made faster (  M   = 2.59 s, SE  = 0.12 s) than negative judgments (  M   = 2.88 s, SE  = 0.16 s),   P   = 0.03. 
  
Interaction effect of trial type and response behavior in the whole-brain MLM analysis (Montreal Neurological Institute [MNI] coordinates:   x   = 12,   y   = −6,   z   = 18). Activation thresholded at   P   = 0.005 (red) and   P   = 0.001 (yellow). The left side of the brain is shown on the right side and vice versa. 
  


### Image analysis 
  
#### Whole brain: multilevel model 
  
Because we differentiated trials on the basis of subjects' judgments, we dealt with an unequal number of observations in each cell of the study design. To estimate the effect of trial type and subjects' judgment simultaneously, we thus constructed a multilevel model (MLM) that can deal with such unbalanced designs. Using AFNI’s 3dDeconvolve function, we obtained β estimates for BOLD response magnitude for each voxel and trial by modeling functional magnetic resonance imaging (fMRI) time series with individual trial regressors based on onset times for stimulus presentation (  https://afni.nimh.nih.gov/;-stim_times_IM  ; see  ;  ;   for similar approaches). Decision times were included as duration modulation. Trial type and response behavior were coded as categorical variables. Using R ( ), we then modeled fMRI BOLD from the three trial types (consistent, resolved ambivalent, unresolved ambivalent), the judgments participants made (response behavior: positive   vs   negative judgment) and their interaction, with random intercepts on the subject level at each voxel to account for the repeated measures design (lme4-package;  ). Categorical variables were automatically dummy coded in the analysis, and in order to examine the effects of the two degrees of freedom simultaneously, we used the ANOVA function in the car library (car-package;  ). 

We observed a significant interaction between the effect of trial type and response behavior on brain activation in several regions, including bilateral DLPFC and dACC as hypothesized ( ). For our analyses, we used an a priori threshold of   P   < 0.005 with a cluster size of 25 ( ) to balance Type I and Type II errors. However, all effects of interest were significant at a more stringent threshold and are more accessibly presented using a threshold of   P   < 0.001 with a cluster size of 25 ( ). For the ease of presentation, we use this more stringent threshold in the main paper for presentational purposes and place the full list of activations at the original threshold in the Supplementary Material S3. 
  
Regions that showed a significant interaction effect of trial type and response behavior in the whole-brain MLM (  P   < 0.001, uncorrected) 
  
 Notes  . Only clusters that exceed a minimum size of 25 voxels are shown. Voxel coordinates of the maximally activated voxels are given. 

IFG, inferior frontal gyrus PFC, prefrontal cortex; SFG, superior frontal gyrus. 
    
Activation in right DLPFC (A) and dACC (B) by trial type and response behavior. 
  


### ROI analysis 
  
#### Simple effects 
  
 Post hoc   tests were conducted in SPSS on the DLPFC and dACC regions from the MLM analysis to decompose the interaction effect of trial type and response behavior. For each cluster, we extracted the β estimates for each trial and participant that were used to run the whole-brain MLM analysis. We averaged estimates across voxels for each trial and participant within each cluster. Note that the following analysis is applied to interpret the significant interaction effect by testing simple effects, not to run the same analysis on a subset of the data ( ). 

##### DLPFC 
  
In line with expectations, we observed greater DLPFC activation for positive than negative judgments only when target persons were described by ambivalent traits and evaluative conflict remained unresolved by the situation in which the evaluation took place (right DLPFC, left DLPFC:   P   < 0.001;  ). When target traits were ambivalent but affordances resolved conflict, results showed no difference in DLPFC activation for positive and negative judgments (right DLPFC:   P   = 0.67; left DLPFC:   P   = 0.82). Activation in DLPFC was weaker when participants made positive compared to negative judgments when target traits were consistent (right DLPFC:   P   = 0.009; left DLPFC:   P   = 0.02). 


##### dACC 
  
The pattern of activation in the dACC mirrored DLPFC activation. When trials elicited (unresolvable) evaluative conflict, dACC activation was stronger when participants judged the person positively than negatively (  P   < 0.001;  ). We found no difference for judgment valence in dACC response to ambivalent target persons when affordances resolved conflict (  P   = 0.79). Finally, judging consistently described target persons negatively was associated with greater dACC activation than judging them positively (  P   = 0.05). 

In a follow-up analysis, we verified that these effects cannot be ascribed to differences in decision times. Including decision times did not eliminate the critical interaction between trial type and response behavior on DLPFC activation [right: χ (2) = 22.63,   P   = 1.22e−05; left: χ (2) = 21.95,   P   = 1.71e−05; Type III Wald] and on dACC activation [χ (2) = 14.65,   P   = 0.0007; see Supplementary Material S5 for details]. 



#### Explaining response behavior from variation in BOLD within trial type 
  
A more stringent test of the hypothesis that dACC and DLPFC signal under evaluative conflict is related to going with or against the default evaluation is to test the relationship between judgment behavior and BOLD variability within different trial types while controlling for differences between participants and trial type. If we find that greater (weaker) DLPFC (dACC) activation is related to a greater likelihood of positive (negative) judgments—only within situationally unresolved ambivalent trials—we solidify the claim that positive judgments of conflicting information are more effortful. Compared to the previous analysis in which we found that positive judgments are in general related to greater DLPFC (dACC) response in situationally unresolved ambivalent trials across participants, this analysis looks for the relationship within participants and trial types. To test this, DLPFC (dACC) activation and decision times were centered within participant and trial type. Using R, trial type (consistent, resolved ambivalent, unresolved ambivalent), centered BOLD response and centered decision time effects, as well as their interaction with trial type, were modeled in a multilevel-model nested within subject. Trial type was coded as a categorical variable. Testing the interaction between centered BOLD response and trial type while controlling for decision times thus allows us to test whether response behavior can be explained by variation in BOLD signal in each type of trial. For readability, the discussion of the results focuses on the predicted interaction between BOLD response and trial type. Other effects are reported in the notes. 

##### DLPFC 
  
Most critically, we found that variation in DLPFC activation predicted response behavior dependent on trial type [χ (2) = 22.16,   P   = 1.54e−05; left DLPFC: χ (2) = 21.73,   P   = 1.91e−05]. As can be seen in  , DLPFC activation had little effect on the valence of judgments when target persons' traits were consistent or the situation resolved ambivalence. When target traits were ambivalent and situational affordances did not resolve conflict, however, comparatively lower DLPFC activation was related to a greater likelihood of negative judgments and positive judgments were more likely under greater DLPFC activation. This supports our suggestion that negative judgments are easier when judging ambivalent targets, whereas greater DLPFC activation is necessary to bias toward more favorable judgments. 
  
Likelihood of positive and negative social judgments within each trial type on the basis of centered brain activation in right DLPFC (A), left DLPFC (B) and dACC (C). Shaded areas represent 95% confidence intervals. 
  

##### dACC 
  
The analysis was repeated for the dACC, again examining the interaction between centered dACC signal and trial type while controlling for decision times. The results mirrored the effect of DLPFC activation. Most importantly, variation in dACC activation within trial type condition predicted response behavior differently for different trial types [χ (2) = 14.92,   P   = 0.0006;  ). However, the pattern was less clear than in DLPFC. 





## Discussion 
  
In the current study, we investigated how the brain facilitates social judgments when person information is conflicting. We made two claims. First, we put forward that social evaluations are dynamic and have situational dependency ( ;  ). Second, we hypothesized that people have a tendency toward negative evaluations under evaluative conflict. To investigate this, our paradigm compared social judgments of people described by consistent or ambivalent trait information across different situations. Our findings confirm that social judgments of the same person vary across situations. Dependent on the situation in which the person was evaluated, ambivalent trait information elicited or failed to elicit evaluative conflict as represented in self-report, decision times and brain activation. Importantly, decision time and brain data converged in support of the hypothesis that negative evaluations are easier when experiencing evaluative conflict; participants were faster to make negative than positive judgments. Crucially, positive judgments were associated with greater DLPFC and dACC activation than negative judgments even when controlling for decision time, suggesting that differences in response magnitude are not simply an effect of processing time. Moreover, the variability of participants' DLPFC and dACC activation predicted the likelihood of positive and negative judgments only within evaluative conflict trials. The study thus provides converging evidence suggesting that saying no is easier than saying yes when experiencing evaluative conflict. 

Our findings complement and extend prior work in a number of ways. Related work has focused on the negative value of response conflict, for example, showing that the negative value of conflict primes translates to negative judgments of following neutral targets ( ). The current study extends this line of research showing that negative value of conflict translates to faster negative evaluations of the conflict stimulus itself. Additionally, whereas previous studies focused primarily on the negative value of response conflicts, we focused on evaluative conflict in the traditional sense, which requires the presence of conflict between positive and negative valence (i.e. ambivalence). Thereby, it provides a stringent test of the idea that negative evaluations of conflict-eliciting stimuli can be considered the default response, whereas positive evaluations require more control. 

Important to note is that, even though we observed more negative judgments when participants experienced evaluative conflict compared to when they did not (on the basis of the same ambivalent person information), there was an equal number of positive and negative judgments within high conflict trials. In line with others ( ), we suggest that overriding negative interpretations of ambiguous or conflicting information in favor of a positive interpretation requires regulatory processes. That is, even though negative judgments were easier, participants regularly seem to exert effort in favor of positive judgments. However, it is as yet unclear what motivates people to exert this effort and bias their judgment. 

To our knowledge, this is also the first study that related the likelihood of positive or negative judgments of conflicting information to dACC and DLPFC activity. Negative judgments were made quicker, and weaker dACC and DLPFC response in trials eliciting evaluative conflict was linked to a greater likelihood of negative judgments, whereas stronger dACC and DLPFC response predicted a greater likelihood of positive judgments. Greater activation in dACC on trials eliciting evaluative conflict could be a prerequisite for implementing control and processing changes in DLPFC toward a more favorable judgment. However, the similar activation pattern observed here makes claims regarding their individual contribution challenging. Our interpretation is based on prior work suggesting that both regions play important roles in behavioral flexibility with dACC signaling the need for behavior adjustment, which is critically implemented by the DLPFC (e.g.  ). In social evaluation tasks, regions in the lateral prefrontal cortex have been linked to updating initial impressions with incongruent information ( ). For example, Bhanji and Beer (2013) demonstrated that modifying impressions toward a more favorable (i.e. positive) judgment is linked to parametrically increasing engagement of a region within lateral prefrontal cortex. Similar to our suggestion, they interpret this increased engagement as a reflection of cognitive effort. We argue that the engagement of DLPFC when changing one’s social judgment is not linked to the valence (i.e. positivity) of the evaluation   per se   but dependent on whether the evaluation moves away from the default response. For example,  ) showed that engagement of DLPFC was related to incorporating negative information about positively evaluated ingroup members. Since it is not the valence of the evaluation but the movement away from the default response that engages DLPFC, and since positive evaluations of ingroup members are the default response, integrating negative information into the evaluation of an ingroup member requires more effort similar to moving toward a positive evaluation when experiencing evaluative conflict in our task. This may also suggest some interesting boundary conditions worthy of future investigation. Whereas we suggest that it is easier to evaluate individuals negatively based on conflicting information, there are likely situations under which this effect may be diminished or even reversed due to motives of the evaluator. Situational factors such as group membership, one’s need to belong or stressful social situations (e.g. ostracism) may influence our interpretation and value judgment of certain traits as well as our global evaluation of another person. For example, when we feel socially rejected or lonely, we may be more inclined to evaluate another person positively despite conflicting trait information, thus shifting the default response to evaluatively conflicting information from negative to positive. Additionally, when evaluating ingroup and outgroup members on the basis of the same conflicting trait information, it may be relatively easier to judge an ingroup member positively because group membership carries positive value and we may process negative information about ingroup members in a biased manner (cf.  ). 

Usually, research into cognitive conflicts and the role of dACC and DLPFC in executive functioning is tested with non-social tasks in which perceptual or response conflict is correctly resolved by actively attending to and regulating behavior. Our study shows that the role of dACC and DLPFC in guiding behavior flexibly in more low-level cognitive control tasks also maps onto more complex tasks in which people have to search memory and weigh information in line with situational affordances. However, an important aspect of our study design was that participants were forced to provide a positive or negative judgment. By forcing a single-factor solution from evaluatively contradicting information, we created an evaluation situation in which neither response option fits participants' evaluation of the stimulus. Even though this approach mirrors many real-life situations, it prevents us from pulling apart possibly separate fMRI responses to evaluative conflicts and response conflicts. The distinction is less relevant for the current study since we were interested in the interaction between the presence of conflict and the judgment provided. However, independent of judgment valence, it may be that dACC response was partly driven either by the difficulty to choose between two unfitting response options or by the evaluative conflict that the stimulus elicits independently of choice. Future studies may investigate this further by comparing forced-choice situations with situations in which participants can indicate mixed evaluation toward an evaluatively conflicted stimulus. 


## Conclusions 
  
The current study shows that social evaluations are dynamic and form in a particular situation, with a particular goal in mind. Complex and conflicted stimulus representations can be resolved by situational prioritization of information. Extending the work on conflicts as negative signals, the findings indicate that when prioritization fails to resolve conflict, negative judgments of conflicting stimuli are easier than positive judgments as indicated by decision times and engagement of dACC and DLPFC. 


## Notes. 
  
  
Given the traits and situations included in the study, a majority of the judgments related to the competence of the target person in a given situation (Supplementary Material S2). 
  
Participants additionally rated how positively (negatively) they evaluated each target persons' most positive (negative) traits on a scale ranging from not at all (0) to very (100). Ratings were combined in line with Thompson Zanna, and Griffin (1995): Ambivalence = (Pos + Neg)/2 −|Pos − Neg|. This measure has been moved to the notes due to word constraints and because we expected the same pattern of results as on the subjective ambivalence scale. Results on this measure indeed confirmed the other self-report results that targets described by mixed traits elicited more ambivalence (  M   = 48.05, SE = 5.14) than did targets described by consistent traits [  M   = −30.21, SE = 4.61;   t  (19) = −9.405,   P   < 0.001,   r   = 0.91]. 
  
For exploratory reasons, participants also responded to the same questions presented in the scanner on a continuous scale ranging from definitely not (0) to definitely yes (100). This measure was not analyzed for this study. 
  
We verified the results of the MLM by running an ANOVA. Note that because of the unbalanced design, ANOVA is inferior to MLM in this case. This analysis resulted in similar findings; the details can be found in the Supplementary Material S4. 
  
Activation in right DLPFC explained response behavior [χ (1) = 4.47,   P   = 0.03; left DLPFC: χ (1) = 6.50,   P   = 0.01] next to decision times [χ (1) = 10.75,   P   = 0.001; left DLPFC: χ (1) = 9.48,   P   = 0.002]. Whereas there was no main effect of trial type on the valence of the judgments participants made, we observed that the effect of decision time on the direction of judgments depended on trial type [χ (2) = 16.69,   P   = 0.0002; left DLPFC: χ (2) = 14.89,   P   = 0.0006]. 
  
We observed that the direction of response behavior could be explained by (participant- and valence-centered) activation in dACC [χ (1) = 3.70,   P   = 0.05] next to (participant- and valence-centered) decision times [χ (1) = 9.35,   P   = 0.002]. Variation in decision times also predicted the valence of judgments dependent on trial type [χ (2) = 15.21,   P   = 0.0005]. 
  


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-17'>
<h2>17. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/20520767/' target='_blank'>20520767</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> The Brain Functional Networks Associated to Human and Animal Suffering Differ among Omnivores, Vegetarians and Vegans</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2010</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0010847</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/2877098/' target='_blank'>2877098</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study reports whole-brain fMRI in healthy adult participants (N=60, ages 18–60) performing a social-related task (viewing human and animal suffering; empathy/social cognition). Analyses used SPM2 whole-brain random-effects models with results reported at whole-brain FWE-corrected thresholds and MNI coordinates. Participants were healthy with no neurological/psychiatric disorders, and the paper is an original empirical fMRI study (not a review) reporting whole-brain results rather than ROI-only analyses. Therefore it meets all inclusion criteria (social task, healthy adults 18–60, whole-brain results) and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Empathy and affective appraisals for conspecifics are among the hallmarks of social interaction. Using functional MRI, we hypothesized that vegetarians and vegans, who made their feeding choice for ethical reasons, might show brain responses to conditions of suffering involving humans or animals different from omnivores. We recruited 20 omnivore subjects, 19 vegetarians, and 21 vegans. The groups were matched for sex and age. Brain activation was investigated using fMRI and an event-related design during observation of negative affective pictures of human beings and animals (showing mutilations, murdered people, human/animal threat, tortures, wounds, etc.). Participants saw negative-valence scenes related to humans and animals, alternating with natural landscapes. During human negative valence scenes, compared with omnivores, vegetarians and vegans had an increased recruitment of the anterior cingulate cortex (ACC) and inferior frontal gyrus (IFG). More critically, during animal negative valence scenes, they had decreased amygdala activation and increased activation of the lingual gyri, the left cuneus, the posterior cingulate cortex and several areas mainly located in the frontal lobes, including the ACC, the IFG and the middle frontal gyrus. Nonetheless, also substantial differences between vegetarians and vegans have been found responding to negative scenes. Vegetarians showed a selective recruitment of the right inferior parietal lobule during human negative scenes, and a prevailing activation of the ACC during animal negative scenes. Conversely, during animal negative scenes an increased activation of the inferior prefrontal cortex was observed in vegans. These results suggest that empathy toward non conspecifics has different neural representation among individuals with different feeding habits, perhaps reflecting different motivational factors and beliefs. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (31724 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Social cognition includes mental processes necessary to understand and store information about the self and other persons, as well as interpersonal norms and procedures to navigate efficiently in the social world  . Basic abilities underlying social cognition include the perception and evaluation of social stimuli, the integration of perceptions with contextual knowledge, and finally the representation of possible responses to the situation. One of the hallmarks of social cognition in humans is the ability to understand conspecifics as beings like oneself, with intentional and mental lives like one's own  . Accordingly, human beings tend to identify with conspecifics and attribute mental states to them. Such abilities rely on the activity of several brain regions, including the frontal lobes (orbitofrontal cortex, medial prefrontal cortex, and cingulate cortex), the temporal lobes (including the amygdala), the fusiform gyrus, and the somatosensory cortices  ,  ,  . The majority of these regions is also critically involved in the processing of emotions  . This suggests that the merging between emotions and feelings experienced by oneself and those perceived in other individuals may be a key ingredient of social understanding, and it may play a major role in promoting empathy, prosocial behaviours, and moral norms  ,  . Moreover, empathic responses can be modulated by the subjective attitude held toward suffering individuals  , as well as by personal experience  . Several functional magnetic resonance imaging (fMRI) studies showed that observing the emotional state of another individual activates a neuronal network involved in processing the same state in oneself, whether it is pain, disgust, or touch ,  ,  . Empathy toward another person, which can be defined as the ability to share the other person's feeling in an embodied manner, has been related to recruitment of a network mostly including the somatosensory and insular cortices, limbic regions and the anterior cingulate cortex (ACC). Whereas cognitively inferring about the state of other person (known as theory of mind) has been associated with recruitment of medial prefrontal regions, the superior temporal sulcus and the temporo-parietal junction . 

A few investigations have also assessed whether affective links between people modulate their brain empathic responses to others, such as when these are loved ones or strangers , or when they are believed to be fair or unfair persons  ,  . The majority of previous studies attempting to characterize empathy-related responses did not separate empathy towards humans from that towards animals. Furthermore, in some studies, scenes showing animals were treated as a neutral condition. However, a recent study   that compared stimuli depicting human and non human animal targets demonstrated higher subjective empathy as the stimuli became closer in phylogenetic relatedness to humans (mammalian   vs  . bird stimuli), thus indicating that empathic response towards humans may generalize to other species. 

In this study, we postulated that the neural representation of conditions of abuse and suffering might be different among subjects who made different feeding choice due to ethical reasons, and thus result in the engagement of different components of the brain networks associated with empathy and social cognition. In details, we tested the hypothesis that the neural processes underlying empathy in vegetarians and vegans may not only operate for representations about humans but also animals, and thus vary between them and omnivore subjects. Vegetarians and vegans, who decided to avoid the use of animal products for ethical reasons, have a moral philosophy of life based on a set of basic values and attitudes toward life, nature, and society, that extends well beyond food choice. The earliest records of vegetarianism as a concept and practice among a significant number of people was closely connected with the idea of nonviolence towards animals and was promoted by religious groups and philosophers. The term veganism, which was coined from vegetarianism, acknowledges the intrinsic legitimacy of all sentient life and rejects any hierarchy of acceptable suffering among creatures. Veganism is a lifestyle that seeks to exclude the use of animals for food, clothing, or any other purpose  . The central ethical question related to veganism is whether it is right for humans to use and kill animals. Due to these differences of believes and behaviours, we also hypothesized that, in addition to a common shared pattern of cortical processing of human and animal suffering, vegetarians and vegans might also have functional architecture differences reflecting their different motivational factors and believes. 


## Results 
  
### Empathy assessment 
  
The Empathy quotient (EQ) score was significantly different between groups (p = 0.002). At post-hoc analysis, the EQ score was significantly higher in vegetarians in comparison with omnivore subjects (mean EQ score = 49.5, SD = 8.9 in vegetarians   vs  . 38.8, SD = 8.1 in omnivore; p = 0.001), and in vegans (mean EQ score = 44.6, SD = 9.8) in comparison with omnivore subjects (p = 0.04) ( ). The difference between vegans and vegetarians was not statistically significant. 
   Graph showing error bars of means and standard deviations of empathy quotient (EQ) score in the three groups of subjects.  
See text for further details. 
  

### Within-group fMRI results 
  
The observation of both human and animal negative valence scenes resulted in the recruitment of several brain areas involved in emotion and empathy in the three groups of subjects, including the anterior insula, basal ganglia, thalami, and several other cortical areas located in the occipital lobes, prefrontal and parietal cortices.   shows the brain patterns of activations in the three groups of subjects during the different experimental conditions.   summarizes the main results of within-group comparisons of the two experimental conditions. 
   Within-group analysis of activations.  
Cortical activations on a rendered brain from omnivore (A–H), vegetarian (I–R) and vegan (S–W) subjects during observation of pictures showing negative valence scenes of humans (A–D, I–N, S–V) or animals (E–H, O–R, Z–W) (within-group analysis, one-sample t tests, t = 3 for display purpose). Images are in neurological convention. 
     Within-group comparisons of human   vs  . animal negative valence picture view and vice versa in omnivore subjects, vegetarians and vegans (paired t test in each group, p<0.05 FWE-corrected).        

### Between-group fMRI results 
  
The patterns of activations during the neutral condition did not differ between groups. 


### Common regions of activations between vegetarians and vegans 
  
During human negative valence picture view, omnivore subjects had a more significant activation (p<0.05, FWE) of the bilateral middle temporal gyrus (MTG) (MNI space coordinates: 38, −58, 8, t value = 5.65; and −36, −76, 8, t value = 5.56) when compared to vegetarians and vegans. Compared to omnivore subjects, the entire sample of vegetarians and vegans had more significant activations (p<0.05, FWE) of the ACC (MNI space coordinates: 10, 22, 40; 10, 36, 28, and −4, 30, 36; t values = 5.65, 5.43, and 5.30), and the left inferior frontal gyrus (IFG) (MNI space coordinates: −48, 20, 0, t value = 5.56) ( ). 
   Results of the between-group comparisons of emotional (human and animal) negative valence picture views.  
Results are superimposed on a high resolution T1-weighted image in the standard MNI space, at a threshold of p<0.05 corrected for multiple comparisons. Areas activated during human picture view in vegetarians and vegans   vs.   omnivores are shown in yellow. Activations specific for vegetarians are shown in blue. Activations specific for vegans are shown in red. A: human picture view; B: animal picture view. Images are in neurological convention. 
  
During animal negative valence picture view, omnivore subjects had more significant activations (p<0.05, FWE) of the bilateral MTG (MNI space coordinates: −46, −62, 0, t value = 6.03; and 34, −74, 4, t value = 5.94), when compared to vegetarians and vegans. Compared to omnivore subjects, the entire sample of vegetarians and vegans had more significant activations (p<0.05, FWE) of the bilateral IFG (MNI space coordinates: −50, 14, −2, t value = 6.84; and 52, 14, −4, t value = 6.34), bilateral lingual gyrus (MNI space coordinates: 8, −80, −14, t value = 6.83; and −10, −78, −14, t value = 6.58), ACC (MNI space coordinates: 0, 24, 28; −2, 52, 8; t values = 5.76 and 5.51), posterior cingulate cortex (PCC) (MNI space coordinates: 0, −42, 26, t value = 5.87), left cuneus (MNI space coordinates: −2, −78, 24, t value = 5.83), and left middle frontal gyrus (MFG) (MNI space: −44, 46, 8, t value = 5.50) ( ). This analysis also showed that, compared to omnivores, vegetarians and vegans had a lower activation of the right amygdala (MNI space coordinates: 30, 2, −20, t value = 5.38). To better define amygdala behavior in the three groups of subjects, we analyzed its activations and deactivations during the two experimental conditions in each group (  and  ). This analysis revealed no significant activation neither deactivation (even when lowering the threshold for the statistical significance at a p<0.001, uncorrected) during animal picture view in this region in vegetarians and vegans. 
   Cluster maxima coordinates of activations/deactivations, at the within-group one sample t test analysis of the areas which showed a significant interaction between groups and conditions (p<0.001, uncorrected).        

### Different regions of activations between vegetarians and vegans 
  
We also directly compared the neural responses in empathy and emotion-related networks between omnivores, vegetarians, and vegans, using a masking procedure (See  ), to identify regions of specific activations of each group contrasted to the others. 

#### a) Vegetarians vs. omnivores and vegans 
  
Observation of human negative valence scenes resulted in a selective recruitment of the right IPL (BA40) (MNI space coordinates: 52, −50, 40, t value = 4.44) in vegetarians ( ). For animal pictures, activations specific to vegetarians were found in the ACC (MNI space coordinates: −2, 52, 10, t value = 5.02) and the right lingual gyrus (MNI space coordinates: 8, −84, −10, t value = 5.00) (p<0.05, FWE). 


#### b) Vegans vs. omnivores and vegetarians 
  
During human negative valence picture view, no cortical activation “specific” to vegans was found. During animal negative valence picture view, vegans activated the IFG bilaterally (MNI space coordinates: 54, 16, −6, and −46, 18, −2, t values = 4.88 and 4.67), and the left MFG (BA10) (MNI space coordinates: −46, 48, 4, t value = 4.29) ( ) (p<0.05, FWE). 



### Analysis of interaction 
  
To further explore the specificity of stimulus processing within the three groups of subjects, we performed an analysis of interaction between picture types (animal/human) and groups (omnivore/vegetarian/vegan). Results showed an interaction in the right amygdala (MNI space coordinates: 24, −10, −22) (greater increases to animal negative valence view in omnivores and to human negative valence view in vegans) ( ), the left amygdala (−22, −8, −28) (greater increases to human negative valence view in vegans) ( ), the ACC (MNI space coordinates: −2, 52, 10) (preferential increases to human negative valence view in omnivores, and to animal negative valence view in vegetarians) ( ); and the right IFG (MNI space coordinates: 52, 20, −8) (selective responses to animal negative valence view in vegans) ( ). 
   Interactions between stimuli (animal/human) and groups (omnivore/vegetarian/vegan).  
An interaction was found in the right amygdala (A), indicating greater increase to animal negative valence picture view in omnivores and to human negative valence picture view in vegans. An interaction between “human pictures” and “vegan group” was also found in the left amygdala (A). An interaction was found in ACC (B) between the “omnivore group” and “human pictures”, as well as between “vegetarian group” and “animal pictures”; and in the right IFG between “animal pictures” and “vegan group” (C). Foci of activations are shown on a high-resolution T1-weighted image in the standard MNI space. Plots indicate activation changes detected in the three groups during the two experimental conditions in each of these regions. Images are in neurological convention. 
  
 summarizes the behavior, in terms of activations/deactivations, at the within-group one sample t test analysis of the three main areas which showed a significant interaction between groups and conditions (i.e., amygdala, IFG, and ACC). 


### Analysis of correlations 
  
During human negative valence picture view, no correlation was found between EQ score and fMRI activity in the three groups of subjects of the study. 

During animal negative picture view, significant correlations (p<0.001) were found between EQ score and: 
  
activation of the left MTG (r = 0.87), ACC (r = −0.76) and the bilateral IFG (right IFG: r = −0.71, left IFG: r = −0.89) in omnivores; 
  
activation of the left IFG (r = 0.92), the left MFG (r = 0.68), and the right MTG (r = −0.75) in vegetarians; 
  
activation of the bilateral lingual gyrus (right lingual gyrus: r = 0.69, left lingual gyrus: r = 0.75) and the left IFG (r = 0.78) in vegans. 
  


## Discussion 
  
The first main finding of this study was the demonstration of a common functional architecture of emotional processing in vegetarians and vegans. In particular, while omnivores are characterized by a greater activation of the bilateral posterior MTG during both human and animal negative valence scenes, vegetarians and vegans have constantly an higher engagement of empathy related areas while observing negative scenes, independently of the species of the individuals involved, which is characterized by an increased recruitment of the ACC and the IFG. Increased activation in the ACC and left IFG in vegetarians and vegans during human and animal suffering view is likely to reflect a stronger empathic response in the first two groups. 

Remarkably, vegetarians and vegans have an higher engagement of empathy related areas while observing negative scenes regarding animals rather than humans, with the additional recruitment of the mPFC, PCC, and some visual areas. ACC has been associated with alert states, self awareness and pain processing  , whereas mPFC and PCC activations are frequently observed in conditions involving representation of the self and self values  . The PCC is also thought to be involved in memory and visuospatial processing  , particularly in relation to emotions and social behavior  . PCC is consistently activated when subjects have to judge the valence of emotionally salient words or episodic memories, with the strongest responses seen when unpleasant stimuli are presented  . 

The notion that empathic response might differ among vegetarians, vegans and omnivores, and that such a response might vary during viewing of human and animal sufferance is at least partially supported by the results of EQ assessment in the three groups of subjects and by the analysis of correlation between EQ scores and fMRI findings, which showed a direct relationship between the EQ score and left IFG recruitment during animal suffering view in vegetarians and vegans, whereas in omnivores such a relationship was inverse. 

The pattern of increased recruitment of empathy-related areas in vegetarians and vegans during animal suffering view was also associated with a reduced activation of the right amygdala in comparison to omnivores. The amygdala responds to various kinds of aversive stimuli, most strongly fearful and threatening scenes   and, to a lesser extent, to those associated with disgust  . Remarkably, the within-group analysis during animal picture view, showed the absence of signal changes (in terms of activations and deactivations) within the amygdala in vegetarians and vegans, suggesting a down-regulation of amygdala response from areas located in the frontal lobes, in an attempt to regulate emotion through cortical processes in these subjects. 

The second main finding of this study is the demonstration of strong functional architecture differences between the vegetarians and vegans during observation of negative scenes. During human suffering viewing, activations specific to vegetarians were located along the IPL. The IPL is involved in bodily representations that distinguish the self from the other  , and was found to be more activated when pictures of mutilations were presented than when contamination or neutral pictures were shown , which suggests a stronger effect on the somatosensory system in observers exposed to the former than the latter conditions. 

More critically, for animal pictures, activations specific to vegetarians were found in the ACC and the lingual gyrus, whereas activations specific to vegans were found in the bilateral IFG and the left MFG. Our data, therefore, point to differential ACC responses to animal suffering for vegetarians, a region highly interconnected with limbic and prefrontal structures that is thought to play a key role in normal and dysfunctional emotional self-control as well as social behaviour  . ACC activation has been related to awareness of emotional material, attention to emotional stimuli  , and rating of affect intensity. In a meta-analysis study, Phan et al.   found that emotional tasks with explicit cognitive components (e.g., recognition or evaluation of emotional stimuli and biographic material) engaged specifically the ACC as compared to passive emotional conditions. The ACC has also been associated with alertness and attention, notably in terms of response control and during painful stimulation  . The recruitment of this region in vegetarians might therefore correspond to their distinctive behavioral response to pictures of animal suffering, e.g., enhanced attention and empathic pain  , or increased self control and monitoring  . On the other hand, the activation of the inferior prefrontal cortex (IFG) seen in vegans during animal suffering, which is consistent with a role of such a region in different emotional tasks  , may be related to aspects of cognitive control during emotion processing. Notably, right IFG is critically involved in inhibitory processes during both cognitive   and emotional   conditions. In addition, even if the existence of the mirror-neuron system (MNS) in humans is still controversial, the IFG is also considered to be part of such a system, since these regions are often activated during action observation, motor learning and imitation of action  . Activation of MNS areas has been shown to increase during social interaction, as well as during observation and imitation of emotional faces  . The role of the MNS in social cognition is also supported by studies in patients with autism, who show a reduced recruitment of the MNS, and in particular of the IFG, during observation and imitation of facial expressions  . Our findings therefore suggest a distinctive pattern of empathic response and emotional control in vegans, mediated through the IFG and MFG. 

Between-group differences in stimuli processing were also confirmed by an analysis of interaction, which showed greater increases to animal negative valence view in omnivores and to human negative valence view in vegans in the amygdala, a preferential increase to human negative valence view in omnivores, and to animal negative valence view in vegetarians in the ACC, and selective responses to animal negative valence view in vegans in the right IFG. Intriguingly, an inverse correlation between amygdala response and activation in the right PFC and ACC has previously been shown during emotional tasks  . In humans, this system is thought to control and direct emotional responses through appraisal and evaluation of their experiences. Such an inverse correlation (i.e., decreased activation of the amygdala together with increased activations of the ACC and PFC) has also been demonstrated during “reappraisal”, which implies altering the meaning of a potentially emotion-eliciting situations in order to reduce their emotional impact  , suggesting that cortical networks of prefrontal regions can exert a cognitive modulation on emotion processing in the amygdala, particularly during intense emotional responses. An alternative hypothesis that has been considered is that limbic structures, such as the amygdala, might respond preferentially to emotive stimuli at a sensory level, and less likely to be engaged in the cognitive processing of emotional material  . 

Collectively, our results reveal that distinct brain responses are evoked by emotionally significant pictures of humans and animals in people with vegetarian and vegan feeding habits, as well as between vegetarians and vegans, suggesting that different motivational factors might underlie their preferences and moral attitudes. Vegetarians showed distinctive responses to negative valence scenes of animals in the ACC, but also to negative valence scenes of humans in the IPL, which might be consistent with greater empathic pain responses and/or enhanced attention in this group for these two conditions. On the other hand, the selective response of vegans to animals in the ACC (with reduced amygdala responses) might reflect a greater attribution of self-relevance   and a greater recruitment of emotional regulation mechanisms  ,   when viewing negative states of non-human beings, together with an enhanced activation of the motor MNS and inhibitory control processes mediated through the MFG and the IFG, respectively. By contrast, omnivores, showed greater responses to human negative valence scenes in the ACC (together with reduced amygdala activation), suggesting that self-relevance and emotion control mechanisms were more specifically engaged by viewing suffering conspecifics than suffering animal beings. 

Our study is the first to assess the neural correlates of empathy towards non conspecifics in people with different social norms, as reflected by their feeding habits. Our results converge with theories that consider empathy as accommodating a shared representation of emotions and sensations between individuals, allowing us to understand others  . They also led us to speculate that the neuronal bases of empathy involve several distinct components including mirroring mechanisms  , as well as emotion contagion and representations of connectedness with the self  . In addition, brain areas similar to those showing different emotional responses between groups in our study (such as the IFG and the mPFC) have also been found to be modulated by religiosity  , further supporting a key role of affect and empathy in moral reasoning and social values. 

This study is not without limitations. First, the use of neutral scenes as a “baseline” condition does not allow defining the neural response to suffering per se, since the response might be influenced by seeing humans or animals. Second, even if a questionnaire related to feeding habits and the EQ were obtained from all the study subjects, affective and cognitive responses during fMRI acquisition were not recorded. Clearly, further studies are warranted to confirm our results. 


## Materials and Methods 
  
The study was approved by the Ethics Committee of Scientific Institute and University Ospedale San Raffaele, Milan, Italy and a written informed consent was obtained from all subjects prior to study entry, according to the Declaration of Helsinki. 

### a) Subjects 
  
We studied 60 right-handed   healthy subjects (34 women, and 26 men, mean age = 37.7 years, range = 18–60 years), with different dietary habits. All subjects had normal or corrected-to-normal vision. We recruited 20 omnivore subjects (11 women and 9 men; mean age = 36.9 years, range = 22–60 years), 19 vegetarians (11 women and 8 men; mean age = 40.3 years, range = 23–60 years), and 21 vegans (12 women and 9 men; mean age = 36.3 years, range = 18–53 years). The groups did not statistically differ for sex and age. A questionnaire was filled in by all the subjects before fMRI acquisition to investigate feeding habits, reasons/motivations of the feeding choices, and the time elapsed from such a choice. All vegetarians and vegans reported to have made their feeding choice for ethical reasons. They had stable feeding habit since 3.8 years (SD = 8.7 years), and were recruited among vegetarian associations. Omnivore subjects were recruited by advertisement and none of them had been vegetarian or vegan before the study. Eight vegans had been vegetarians before becoming vegans. All the subjects were naïve about the goal of the study. None of the subjects had any history of neurological, major medical, or psychiatric disorders (including depression), and either alcohol or drug abuse. In addition, none of the subjects was taking any medical treatment at the time of fMRI assessment and all of them had a normal neurological examination. 


### b) Empathy assessment 
  
On the day of fMRI acquisition, subjects were evaluated with the EQ questionnaire  , a self-report questionnaire which has been developed to measure the cognitive and affective aspects of empathy. This questionnaire is widely used in clinical research  ,  , as well as in neuroscience studies  . The EQ comprises 60 questions: 40 questions tapping empathy, and 20 filler/control items. The 20 filler/control items have been included to distract the participant from a relentless focus on empathy. On each empathy item, a person can score 2, 1, or 0, so that the EQ has a maximum score of 80 and a minimum score of 0. To avoid response bias, approximately half of the employed items are worded to produce a “disagree” response and half to produce an “agree” response  . The EQ has a forced choice format, can be self-administered, and is straightforward to score because it does not depend on any interpretation. 


### c) Experimental design 
  
During fMRI, an event-related design was used. A program implemented with the Presentation software (  www.neuro-bs.com  , Version 9.70) presented in a random order a series of 150 pictures: 40 showed negative valence scenes related to humans, 40 negative valence scenes related to animals, and the remaining 70 showed “neutral” natural landscapes. Pictures were pseudo-randomized so that no more than two pictures of the same category were presented consecutively. Negative-valence scenes were taken from the International Affective Picture System  , newspapers, books, or magazines (all images were of high-quality resolution and taken in an electronic format). Scenes had to show the entire figure and not only the face of the subject/animal. Human and animal pictures were comparable in terms of valence and arousal rating. Non-IAPS pictures were validated in a group of 50 healthy subjects that did not participate in the fMRI experiment. To assess the three dimensions of pleasure, arousal, and dominance, the rating procedure by Lang was used  . 

Each trial began with a fixation cross presented in the centre of the screen for 3 sec, followed by the pictures, in a random order, presented for 2 sec followed by black screen. A variable interstimuls interval was used. Subjects were instructed to look at the scenes, without providing any specific response during fMRI acquisition. 


### d) fMRI acquisition 
  
Brain MRI scans were obtained using a 3.0 Tesla scanner (Intera Philips Medical Systems, Best, The Netherlands) with a gradient strength of 40 mT/m. Functional MR images were acquired using a T2*-weighted single-shot echo-planar imaging (EPI) sequence (echo time [TE] = 30 ms, flip angle = 85°, matrix size = 128×128, field of view [FOV] = 240 mm , repetition time [TR] = 3.0 seconds). During each functional scanning run, 151 sets of 40 axial slices, parallel to the AC-PC plane, with a thickness of 3 mm, covering the whole brain were acquired. Shimming was performed for the entire brain using an auto-shim routine, which yielded satisfactory magnetic field homogeneity. Head movements were minimized using foam paddings. 

On the same occasion, a brain dual-echo turbo spin echo sequence (TR = 3500 ms, TE = 24/120 ms; echo train length = 5; flip angle = 150°, 44 contiguous, 3-mm-thick, axial slices with a matrix size = 256×256 and a FOV = 240×240 mm ) was also acquired. 


### f) FMRI analysis 
  
FMRI data were analyzed using the statistical parametric mapping (SPM2) software. Prior to statistical analysis, all images were realigned to the first one to correct for subject motion, spatially normalized into the Montreal Neurological Institute (MNI) space, and smoothed with a 10-mm, 3D-Gaussian FWHM filter. 


### g) Statistical analysis 
  
Event-related paradigms for each condition were modelled on a voxel-by-voxel basis, using the general linear model and the theory of random Gaussian fields  . In each subject, a first-level design matrix was built, where motion parameters were used as regressors of no interest. Then, specific effects were tested by applying appropriate linear contrasts. For each subject, the following contrasts were defined: human negative valence images > neutral, and animal negative valence images > neutral. To test whether between-group differences in processing the neutral conditions might have influenced our results, the contrast assessing activations of neutral images was also defined. Significant hemodynamic changes for each contrast were assessed using t statistical parametric maps (SPMt). Then, a second level random effect analysis was performed to assess the main effects of the stimuli, differences between groups, and interactions between groups and conditions  , using an ANOVA model where groups and conditions were entered as separate factors (2×3 factorial design). To assess between-group similarities and differences in the brain patterns of activations, the following sets of linear comparisons were performed: 1) vegetarians and vegans, separately,   vs.   omnivores; 2) vegetarians and vegans, combined,   vs.   omnivores; 3) vegetarians   vs.   vegans, and vice versa. Common patterns of activations between vegetarians and vegans during a given contrast were identified by a conjunction analysis  . Regions of specific activations of each group contrasted to the other were identified by inclusively masking (uncorrected mask p value = 0.05) the relevant contrast from comparison 1 (e.g., vegetarians   vs.   omnivores) with the appropriate contrast from comparison 3 (e.g., vegetarians   vs.   vegans). 

Intra-group activations were evaluated using a one-sample t test and a paired t test, as appropriate. At this stage, task-related activations and deactivations were estimated. We report activations below a threshold of p<0.05 corrected for multiple comparisons (FWE). Within each region of statistical significance, local maxima of signal increase were determined and their locations expressed in terms of   x  ,   y  , and   z   coordinates into the MNI space. A 3D anatomical atlas was also used to increase confidence in the identification of the anatomical locations of the activated areas  . Using a linear regression analysis, the correlation of fMRI changes during task performance with EQ score was assessed (p<0.001, uncorrected). 

Demographic and behavioral data were compared using the SPSS software and an ANOVA model (version 13.0). 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-18'>
<h2>18. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/23251653/' target='_blank'>23251653</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> fMRI Evidence of ‘Mirror’ Responses to Geometric Shapes</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2012</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0051934</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3522615/' target='_blank'>3522615</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study used fMRI in healthy adult participants (N=21, mean age 24) during tasks involving action observation and execution designed to probe mirror-system responses—processes widely considered part of social cognition (action understanding/mirroring). Participants completed active tasks in the scanner (shape observation, action observation, action execution). Whole-brain analyses are reported (p<0.001 uncorrected) in addition to ROI analyses, so results are not ROI-only. Participants were healthy and within the 18–60 age range. The paper is an original empirical fMRI study (not a review) and does not involve clinical populations. Therefore it meets the inclusion criteria for fMRI studies of social-related processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Mirror neurons may be a genetic adaptation for social interaction  . Alternatively, the associative hypothesis  ,   proposes that the development of mirror neurons is driven by sensorimotor learning, and that, given suitable experience, mirror neurons will respond to any stimulus. This hypothesis was tested using fMRI adaptation to index populations of cells with mirror properties. After sensorimotor training, where geometric shapes were paired with hand actions, BOLD response was measured while human participants experienced runs of events in which shape observation alternated with action execution or observation. Adaptation from shapes to action execution, and critically, observation, occurred in ventral premotor cortex (PMv) and inferior parietal lobule (IPL). Adaptation from shapes to execution indicates that neuronal populations responding to the shapes had motor properties, while adaptation to observation demonstrates that these populations had mirror properties. These results indicate that sensorimotor training induced populations of cells with mirror properties in PMv and IPL to respond to the observation of arbitrary shapes. They suggest that the mirror system has not been shaped by evolution to respond in a mirror fashion to biological actions; instead, its development is mediated by stimulus-general processes of learning within a system adapted for visuomotor control. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (42515 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Mirror neurons discharge when a monkey executes an action and when it passively observes a similar action. They have been found in ventral premotor cortex (PMv), area F5  ,   and rostral inferior parietal lobule (IPL), area PF  ,  . Since their initial discovery, mirror neurons responsive, not only to object-directed, but also to pantomimed or intransitive actions, have been discovered in F5  . Mirror neurons have also been reported in F5 that appear tuned to the sight of actions executed with tools (e.g. grasping with pliers  ) and to the sounds associated with actions (e.g. plastic crumpling)  . 

Evidence consistent with the claim that humans also have populations of neurons with mirror properties (supporting mirror ‘representations’ of action) can be obtained from studies using functional magnetic resonance imaging (fMRI). These show that areas of the human cortex, homologous to those where mirror neurons have been found in monkeys, are active when we observe and execute similar actions  , and show characteristic patterns of adaptation. Specifically, these cortical areas are less active where an action event (‘A’; either the observation or execution of an action) is preceded by a similar action event (AA) than when preceded by a dissimilar action event (BA). Importantly, this adaptation is observed both when the two events are experienced within-modality (A −A  or A −A ) or across modalities (A −A , or A −A ). For example, in a study where participants either observed or executed a precision grip or ring pulling action in successive trials, there was less PMv activation when ring pulling observation was preceded by ring pulling execution than when it was preceded by precision grip execution   (references to PMv include BA44, a posterior portion of the inferior frontal gyrus, because it is thought to be the human homologue of monkey premotor region F5). This crossmodal (execution-observation and observation-execution) adaptation effect has been replicated in PMv   and also reported in IPL  . It provides evidence that common neural populations are active during the observation and execution of the same actions, suggestive of mirror representations of action: Whereas repeated activation of a common ‘mirror’ population will result in a decline in its responsivity, successive activation of independent sensory and motor populations will not  . 

According to the associative hypothesis  ,  , mirror neurons acquire their characteristic matching properties through sensorimotor learning. At birth, sensory neurons in the superior temporal sulcus and elsewhere in the cortex are weakly and unsystematically connected to motor neurons; for example in PMv. During infancy, individuals watch their own actions and are imitated by others  ,  . Both self-observation and being imitated cause correlated (i.e. contiguous and contingent) activation of sensory neurons and motor neurons that code similar actions. This correlated activation selectively strengthens connections between those sensory and motor neurons encoding similar actions (associative learning), giving the motor neurons ‘mirror’ properties, i.e. they discharge, not only when an action is executed, but also, by virtue of their connections with sensory neurons, when similar actions are observed. This account assumes that mirror neuron development is relatively unconstrained, as it is mediated by domain general processes of learning. Given the appropriate sensorimotor experience mirror neurons can emerge that respond to different actions in the observe and execute conditions (so-called ‘logically related’ mirror neurons  ) or to arbitrary sensory stimuli (e.g. the sight of actions executed with tools or action sounds  ,  ). This contrasts with the dominant view in the literature, which suggests that mirror neurons are a genetic adaptation for social interaction  ; that mirror neurons have been ‘programmed’ by evolution to promote action understanding, or other social cognitive functions. 

If the associative account is correct, it should be possible for mirror neurons in classic mirror areas (e.g. PMv and IPL) to become connected through sensorimotor learning, not only to visual neurons that code actions, but also to visual neurons that code non-action stimuli, such as geometric shapes. Connections of this kind would yield mirror neurons that are selectively responsive to the execution and observation of a particular action and to the observation of a shape that has been associated with performance of that action. In order to test this hypothesis, participants were given sensorimotor training in which they were required to perform distinct hand actions in response to different geometric shapes (see  ). It is difficult to measure the activity of single neurons in humans, and so in the current study fMRI adaptation was used to measure the activity of populations of neurons with mirror properties. After training, in the first fMRI session participants experienced runs of events in which shape observation alternated with action execution. We compared the blood-oxygen-level-dependent (BOLD) signal in ‘trained trials’, where the event was immediately preceded by an event with which it had been paired during training, and ‘untrained trials’, when it was preceded by an event with which it had not been paired (see  ). If sensorimotor training induces populations of neurons in mirror areas encoding motor properties of actions to respond to geometric shapes (see  ), one would expect a lower BOLD signal in trained than in untrained trials (due to BOLD adaptation). 
   Schematic illustration of the experimental design.  
a) An example set of trained shape-response mappings. The relationship between shape and action type was held constant for a given participant throughout training, but was varied between participants. b) Illustration of a sequence of trials in Session 1. Observation of shapes alternated with execution of actions. A trial was ‘trained’ if preceded by an event type with which it had been paired during training, and ‘untrained’ if preceded by a different event type. c) Illustration of a sequence of trials in Session 2. In this session, observation of shapes alternated with observation of actions, and ‘trained’ trials were those in which, if training induced   mirror   representations to respond to arbitrary shapes, both the preceding and current events should activate the same motor representation. See also  . 
     Schematic representation of the fMRI adaptation logic.  
Note that although reference is made to mirror   neurons  , fMRI data is driven by populations of neurons. Purple ovals denote populations of sensory neurons encoding visual properties of stimuli; blue ovals denote populations of motor neurons responsible for action execution. a) Before training, motor neurons are activated by observation of actions (top) but not by observation of shapes (bottom). These cells are therefore mirror neurons b) Training where participants respond to each arbitrary geometric shape with a distinctive action establishes novel excitatory links (broken arrow) between neurons encoding sensory properties of each shapes and motor neurons encoding the trained action. c) Session 1. Adaptation from shape observation to action execution (signified by paler flash on right), and vice versa, shows that, as a result of training, the shapes activate neuronal populations with motor properties. d) Session 2. Adaptation from shape observation to action observation, and vice versa, shows that shape and action observation activates common neuronal populations; i.e. cells with   mirror   properties. Session 2 adaptation would not have occurred if experimental training had linked visual neurons with i) purely motor neurons, ii) canonical neurons, or iii) logically related mirror neurons. The training must have linked neurons encoding the sensory properties of the geometric shapes with neurons that were already encoding both sensory and motor properties of action, i.e. congruent mirror neurons. 
     An example of 16 trials in a block, categorised according to their Transition Type and Trial Type with respect to the previous trial.        
To determine whether sensorimotor learning changed the responses, not merely of populations of motor or canonical neurons, but of populations of neurons coding the matching sensory and motor properties of action (i.e. mirror representations), participants completed a second fMRI session in which shapes alternated with action observation (see  ). It should be noted that participants could not observe their actions during training. Therefore, in this session, ‘trained’ trials were those in which both the preceding and current event could activate a common neuronal population encoding the same motor representation. Since in this session both events comprise only observation (of shapes or of actions), they could only activate the same motor representation if the training had induced responses to arbitrary shapes not only in populations of   motor   neurons but in populations of neurons with   mirror   properties. BOLD adaptation between shapes and observation of actions in mirror areas would indicate that sensorimotor training induced mirror representations – populations of neurons that were already coding both observation and execution of similar actions - to respond to arbitrary geometric shapes. For example, for a participant trained to associate ‘observe hexagon’ with ‘execute splay fingers’, both the observation of a hexagon and the observation of splayed fingers should activate neural populations coding for the execution of splay fingers, as long as this population has mirror properties; i.e. it responds to both observation and execution of splay fingers. 

Session 2 is crucial for the interpretation of any learning effects observed. If training altered the properties, not of populations of cells with mirror properties, but of other populations of neuron in the regions of interest (e.g. canonical neurons, motor neurons, or ‘logically-related’ mirror neurons), adaptation should not be observed in Session 2. That is, if sensorimotor training induced purely motor neurons to respond to geometric shapes, one would not expect shape and action observation to activate the same neural population during Session 2. In this case, although shape observation would activate the motor representation, observation of actions would not. Similarly, if training induces populations of canonical neurons to respond to observation of the shapes, adaptation would not be observed during Session 2, as one would again expect shape observation, but not action observation, to activate these populations. If training induced populations of ‘logically-related’ mirror neurons to respond to observed shapes, adaptation would not be expected during Session 2. Observation of the shapes could activate logically-related neurons coding for execution of action A, but, by definition, observation of action A would not. One would only expect adaptation in Session 2 if training induced populations of neurons coding for observation and execution of the   same   action (i.e. by definition, congruent mirror representations) to respond to the observation of the trained shape. 


## Materials and Methods 
  
### Participants 
  
Twenty-one paid healthy participants took part in this study (8 male, mean age 24.0 years, standard deviation 4.4 years). All were right handed, assessed using the Edinburgh Handedness Inventory (EHI)  . One participant had an EHI score of 55 which is in the 1  right-handed decile, all other participants had scores of 70 or greater. Participants had normal or corrected-to-normal vision, were naïve with respect to the purpose of the experiment, and all gave written informed consent. The experiment was performed with the approval of the Birkbeck Psychology Research Ethics Committee and performed in accordance with the ethical standards laid down in the 1964 Declaration of Helsinki. 


### Stimuli 
  
The action stimuli were generated by video recording each of four models (two male and two female) performing four different gestures with the right hand. The gestures were filmed from a first-person perspective and all started from a relaxed position with the hand supine on a featureless background. From this starting position the four gestures were: 1) point finger - curling the thumb, middle, ring and little fingers under the palm and extending the index finger so that it pointed; 2) splay fingers - extending all of the fingers and the thumb as far as possible away from the palm; 3) extend thumb - curling all fingers under the palm and extending the thumb to the side, and 4) make fist - curling the thumb and all fingers under the palm to make a fist. These gestures were used because they had previously been shown to produce robust adaptation when executed  . The shape stimuli consisted of a green circle, yellow hexagon, red square and blue triangle. Execution trials were cued by the words, ‘point’, ‘stretch’, ‘thumb’, and ‘fist’ presented uppercase, in white Helvetica font on a black background. 


### Procedure 
  
#### Training 
  
During training participants were initially instructed in the correct execution of each of the four gestures. When the participant was consistently executing the correct gestures, they were asked to put their hand behind a screen so that it was invisible to the participant but visible to the experimenter. Participants were seated in front of a computer monitor where the shape stimuli were to be displayed. They were instructed that they would be asked to perform the appropriate gesture in response to a shape and that each of the four shapes cued one of the four gestures. They were also told that they would have to discover for themselves which gesture was appropriate for each shape. Thus, participants were not explicitly instructed about the shape-gesture mappings (e.g. they were not told to respond to green circles by pointing), or to make a particular gesture in any given trial. In the first eight training trials each of the shapes was presented twice. Subsequently, the order of shape presentation was randomized within each block. In each trial a shape was presented and the participant made a response. If the gesture was correct, the next trial was presented. If the participant executed the wrong gesture, a warning tone sounded and the word ‘Wrong!’ appeared on the screen. The same stimulus was then presented in successive trials until the participant made the correct response. Accuracy was monitored by the experimenter, who could see both the stimulus presented to the participant and the participant’s response. Eleven of the participants were trained with the following stimulus-response mappings: circle −point finger ; square −extend thumb ; hexagon −splay fingers ; triangle −make fist  (see  ). The remaining ten participants were trained: circle −splay fingers ; square −make fist ; hexagon −point finger ; triangle −extend thumb . Using different arbitrary pairings for different participants ensured that it could not have been pre-existing associations between the actions and shapes, rather than the training, which produced the observed effects. The initial period of training was completed a day before the scanning session and consisted of eight blocks of 150 trials each (lasting approximately one hour in total). A refresher period of training was completed immediately before the scanning session and consisted of four blocks of 150 trials. 


#### Scanning procedure 
  
All participants completed two sessions. During Session 1, shape observation alternated with gesture execution (see  ). Execution events were cued by the words, ‘point’, ‘stretch’, ‘thumb’, and ‘fist’. Participants were required to perform the gesture that corresponded to the word cue. Whether the first event involved shape observation or action execution was counterbalanced across participants. During Session 2, shape observation alternated with action observation ( ). Session 2 was structurally identical to Session 1; the only difference between them was that participants were required to execute actions in Session 1 and to observe actions in Session 2. Each stimulus (shape, word, or action video) was presented for 800 ms. 

Each session was split into eight mini-blocks of 33 events (264 events in total). Each event was characterized as a trained or untrained trial with respect to the preceding event (i.e. using the methodology employed by Hamilton and Grafton  ; see   and  . The first event in each mini-block was therefore discarded, resulting in an effective design of eight mini-blocks of 32 trials each (256 trials in total). Each mini-block comprised a factorial design with factors of Trial Type (trained or untrained), ISI (short or long), and Transition Type (observation - execution, or execution - observation). Adaptation was assessed over both short and long trial-to-trial and session timescales: ISI between stimuli was fixed at 250 ms (‘short’), or was randomly jittered between 2 and 4 seconds (mean 3 seconds, ‘long’). In addition, mini-blocks 5–8 were an exact replication of mini-blocks 1–4, enabling adaptation to be assessed during a short session (mini-blocks 1–4), and across a longer session (comparison with mini-blocks 5–8). Four repetitions of each combination of the ISI, Trial Type, and Transition Type factors made up each mini-block. The trial order within mini-blocks was randomly determined. Each mini-block contained only two examples of the four shape-gesture pairings (e.g. in a particular mini-block participants may have only observed circle and square stimuli and only executed point finger and extend thumb). This ensured that the number of specific combinations of shape and gestures presented in a mini-block did not differ between trained and untrained trials, and therefore that the opportunity to learn new associations did not differ between trained and untrained trials during the fMRI sessions. The two examples were chosen randomly in each of mini-blocks 1–4, and replicated in mini-blocks 5–8. 

Participants were filmed throughout Session 1 so that the experimenter could ensure online, and subsequently offline, that they were executing 1) the actions they were instructed to perform, and 2) during execution periods only. Participants made very few errors. They omitted a cued response in 0.69% of trials, made an incorrect response in 0.39% of trials, and made an uncued response in 0.49% of trials. Given the low rate of errors, the behavioral data were not analysed further. 



### Data Acquisition and Analysis 
  
We acquired T2*-weighted echo-planar images (EPI) with BOLD contrast on a 1.5T whole-body MRI scanner (Siemens AG, Erlangen, Germany) in two sessions (TR = 2.556s, TA = 2.556s, 30 axial slices, 4 mm×4 mm×4 mm in-plane resolution) operated with a 32-channel head coil. A total of 252 volumes were collected for each of the two sessions, including 6 dummy volumes at the start of each session to allow for T1 equilibration. High-resolution T1-weighted structural scans were collected for all but one participant and were co-registered to their mean EPI images. For the participant where it was not possible to collect a T1 scan, we co-registered functional scans to the Montreal Neurological Institute (MNI) EPI template. 

Data pre-processing of the EPI functional scans, including spatial realignment, unwarping, normalization to the standard MNI template, and smoothing with a 4 mm (full-width half-maximum, FWHM) Gaussian kernel, was completed using SPM8 (  www.fil.ion.ucl.ac.uk/spm  ). The event-related fMRI data were then analysed using a linear convolution model. We included 32 regressors of interest, which were regressed against the EPI data and high-pass filtered at 128 seconds to remove low-frequency drift. These regressors were derived by convolving a canonical hemodynamic response function and its temporal derivative with delta functions representing stimulus onset of each unique combination of the levels of the factors. The factors were Trial Type (trained, untrained), Transition Type (observation - execution, execution - observation), ISI (short, long) and Session Half (miniblocks 1–4, miniblocks 5–8) factors). The resulting beta images for each condition were combined to form magnitude images as described in Steffener et al.  . These subject (first) level magnitude images were used to generate contrast images, which were smoothed with a 4 mm FWHM Gaussian kernel, and entered into a random effects (second-level) analysis to investigate group-level responses. All co-ordinates are reported in MNI space. 

Two analyses were performed. The first was performed within regions of interest (ROIs) that corresponded to 10 mm spheres around the peak voxels within PMv and parietal cortex where previous studies have found crossmodal (observation – execution or execution – observation) action adaptation effects. These voxels were taken from the studies of Chong et al.  , Lingnau et al.  , Kilner et al.  , and Press et al.  . We generated two ROIs; one for cross-modal effects within PMv and IFG, consisting of spheres around [−50,−2,12]  , [−56,2,20] and  ,  ,  , and another for effects within parietal cortex; consisting of spheres around [58,−56,34] (IPL  ), [−46,−37,27] (intraparietal sulcus  ), and [−28,−59,46] (superior parietal lobule  ). Significance levels within this analysis were family-wise error corrected for the ROI volume at a voxel-level of   p  <0.05 and a cluster extent threshold of four voxels. The second analysis investigated responses across the whole brain at a threshold of   p  <0.001 uncorrected, with a cluster extent of four voxels. 



## Results 
  
fMRI adaptation was calculated by contrasting trained and untrained trials (untrained - trained). In Session 1, ‘trained’ trials were those in which the preceding event had been paired with the current event during training ( ). Thus, for a participant trained to associate ‘observe circle’ with ‘execute point’, a trained trial would consist of either observation of a circle preceded by execution of a point action, or execution of a point action preceded by observation of a circle. In ‘untrained’ trials the previous and current events had not been paired (e.g. observation of a circle following execution of a ‘fist’ action). Adaptation from shape observation to action execution, or vice versa, would indicate that as a result of training, neuronal populations responsive to action execution are also responsive to shape observation. An adaptation effect surviving family-wise error correction (FWE) was found within the PMv ROI, with a peak at  ,  ,  ,   t   = 4.5,   p  <0.05 FWE (see  ). In Session 1 there were no voxels surviving FWE correction within the Parietal ROI, but there was a cluster at   p  <0.001 uncorrected, with a peak at [54,−28,22]. Peak voxels demonstrating a main effect of adaptation are reported in  . 
   Statistical parametric maps (SPM) of the main effects of adaptation in Session 1.  
The SPM is thresholded for display at   p  <0.001 uncorrected with a cluster extent of 4 voxels. Results are rendered upon the smoothed average brain provided in SPM8. 
     All peak coordinates for the main effect of adaptation in Session 1, at   p  <0.001 uncorrected, with a cluster extent of four voxels.        
In Session 2, shape observation alternated with action observation. Thus ‘trained’ trials ( ) were those in which, if training induced   mirror   representations to respond to arbitrary shapes, both the preceding and current events should activate a neuronal population coding the same motor representation. ‘Untrained’ trials were those in which the preceding and current events were not predicted to share a motor representation. Adaptation from shape observation to action observation, or vice versa, would therefore indicate that as a result of training, shape observation activates a neural population responsive to observation and execution of the same action: that is, a population of neurons with mirror properties. Adaptation effects were observed both within the PMv (peak at  ,  ,  ,   t   = 4.4,   p  <0.05 FWE) and Parietal (peak at [−54,−36,30],   t   = 4.2,   p  <0.05 FWE) ROIs (see  ). Additionally, there was a right parietal adaptation effect at   p  <0.001 uncorrected, with a peak at [54,−44,38]. Peak voxels demonstrating a main effect of adaptation in Session 2 are reported in  . 
   Statistical parametric maps (SPM) of the main effects of adaptation in Session 2.  
The SPM is thresholded for display at   p  <0.001 uncorrected with a cluster extent of 4 voxels. Results are rendered upon the smoothed average brain provided in SPM8. 
     All peak coordinates for the main effect of adaptation in Session 2, at   p  <0.001 uncorrected, with a cluster extent of four voxels.        
We also investigated whether adaptation interacted with any of the other variables (Inter Stimulus Interval (ISI), Session Half, or Transition Type). In Session 1, we found an area where adaptation was modulated by ISI within the PMv ROI, at two peak coordinates ([−58,8,26],   t   = 4.4,   p  <0.05 FWE; [−62,4,22],   t   = 4.1,   p  <0.05 FWE). At these coordinates, the adaptation effect was greater at short ISIs. Previous studies have also found greater adaptation effects at shorter ISIs  ,  , suggesting that adaptation effects within certain regions, including left PMv, may be short-lived. There were no areas within the Parietal ROI in Session 1, or in either ROI in Session 2, where adaptation was modulated by ISI, Transition Type or Session Half. 


## Discussion 
  
The present experiment set out to test a specific prediction of the associative account of the development of mirror neurons: If mirror neurons acquire their properties through domain general processes of sensorimotor learning, it should be possible for human mirror neurons to respond to arbitrary non-action stimuli following exposure to appropriate sensorimotor contingencies. While a test of this hypothesis would ideally involve single-cell recording in humans, due to the difficulties in obtaining these data the present study utilised fMRI adaptation in order to record the BOLD signal from populations of neurons with properties consistent with mirror neurons. To test the associative hypothesis, participants were trained to execute different responses (point, splay fingers, make fist, extend thumb) to the onset of different geometric shapes (green circle, red square, yellow hexagon, blue triangle). After training participants completed two scanning sessions where the observation of either shapes or actions alternated with action execution (Session 1) or where observation of shapes alternated with observation of actions (Session 2). This procedure, particularly the inclusion of Session 2, allowed us to use the fMRI adaptation technique to provide evidence of the activation of populations of neurons with mirror properties. 

The results confirmed the prediction of the associative account. When shape observation alternated with action execution (Session 1), adaptation was observed in PMv: for both shapes and actions, the BOLD signal associated with an event was lower when that event was preceded by an event with which it had been paired during training than when it followed an untrained event. PMv is an area in which mirror neurons have been found in the macaque  ,  , and where adaptation effects indicative of populations of neurons with mirror properties have been found when humans observe and execute similar actions  ,  . Therefore, consistent with the associative account of the development of mirror neurons  ,  , the findings from Session 1 suggest that the sensorimotor training at the beginning of the experiment strengthened connections between visual neurons coding the colour and/or shape of geometric stimuli and neurons in a classical mirror area encoding the motor properties of action. 

The above interpretation of the results of Session 1 is supported and strengthened by the findings from Session 2: When observation of shapes alternated with observation of actions, we found an adaptation effect in PMv and in another classical mirror area, IPL  ,  . For both shapes and actions, the BOLD signal associated with observing an event was lower when that event was preceded by observation of an event with which it shared a motor representation, through training, than when it was preceded by observation of an event with which it did not share a motor representation. Even without data from Session 1, these results provide evidence that training induced populations of neurons with mirror properties, rather than any other population, to respond to geometric shapes. The adaptation effects seen in Session 2 show that common neural populations were coding the visual properties of the actions used during training and also the shapes. These populations could not have acquired the capacity to map visual properties of the shapes onto visual properties of the actions during training, because participants were not allowed to see their own actions at any stage in the experiment. Therefore, the adaptation effect in Session 2 implies that the sensorimotor training at the beginning of the experiment induced mirror representations – populations of neurons in the PMv and IPL that were already coding both observation and execution of similar actions – to respond to arbitrary geometric shapes. 

These results are consistent with research showing that activation in mirror areas varies with expertise   and training  ,  , and with previous reports that sensorimotor learning can induce  ,  , enhance  , abolish  ,  ,  ,  ,   and even reverse  ,  ,   ‘mirror effects’, i.e. effects of action observation on overt behaviour, motor evoked potentials (MEPs), and BOLD responses in mirror areas. For example, Catmur et al.   showed that sensorimotor training can reverse a ‘Fadiga effect’   in which transcranial magnetic stimulation (TMS)-induced MEPs are larger in the index finger muscle when observing index finger than little finger actions, and larger in the little finger when observing little finger than index finger actions. After incompatible sensorimotor training, in which participants executed little finger actions when observing index finger actions, and vice versa, observation of index finger actions induced greater MEPs in little finger muscles, and observation of little finger actions induced greater MEPs in index finger muscles. Indeed, in a closely-related study Petroni et al.   found that, following training where an arbitrary shape cue was paired with an action, passive observation of the shape cue activated motor representations of action, presumably via mirror areas. Evidence of plasticity observed in previous studies of expertise and sensorimotor training, and in the present study, accords with the predictions of the associative hypothesis  ,  . Moreover, the present findings contribute to growing evidence that the effects of sensorimotor training modulate mirror effects by modifying mirror representations in classical mirror areas  ,  . 

Contrary to the view that mirror neurons were specifically designed   or ‘canalised’   by genetic evolution to mirror observed actions, the associative account implies that there is nothing intrinsically ‘mirror’ about mirror neurons. The associative account predicts that sensorimotor learning can readily cause populations of motor neurons, responsible for the performance of both transitive and intransitive actions  , to become associated with the observation of similar actions (strictly and broadly congruent mirror neurons  ), dissimilar observed actions (logically related mirror neurons  ), actions performed with tools (tool-use mirror neurons  ), characteristic action sounds (audiovisual mirror neurons  ), and action-appropriate objects (canonical neurons  ). For example, audiovisual mirror neurons respond to action sounds such as plastic crumpling and metal striking metal  . Under the associative account, these cells acquire their properties through experience of performing actions while hearing these sounds, but are harder to accord with evolutionary hypotheses  . The present study confirms that geometric shapes - a class of arbitrary non-action stimuli that have neither the morphological or dynamic properties characteristic of body movements - should be included in the list of sensory stimuli that can elicit excitation of populations of cells with mirror properties following contingent sensorimotor experience. The present findings suggest that differences in response patterns among these different neurons (broadly and strictly congruent mirror neurons, logically-related mirror neurons, tool-use mirror neurons, audiovisual mirror neurons, canonical neurons, geometric-shape mirror neurons) may not reflect different cell types, but rather the fact that motor neurons may become associated with different eliciting stimuli. Consequently, the particular ‘class’ of observed stimuli that causes the cell to fire may not be a normative, intrinsic property of the cell itself, but may instead be a consequence of the individual’s learning history  ,  . 

An alternative interpretation of the present data could be advanced whereby the matching property of mirror representations has been designed by evolution to promote action understanding or social interaction, but these representations will additionally encode arbitrary stimuli following appropriate learning. There are at least two versions of this hypothesis. First, mirror representations are present at birth  , but these representations are not buffered against becoming responsive to other stimuli through learning. Second, the development of mirror representations may be incompletely canalised, such that these representations are acquired more readily in this population of cells, but not to the exclusion of other response properties. These hybrid models, along with a wide range of additional recent hybrids, represent interesting potential advances on the two accounts contrasted historically and in the present study, but there is currently no independent data to support them. 

fMRI adaptation effects provide evidence that common neural populations code both events  ,  . However, the neural mechanism underlying BOLD adaptation at the single-cell level is a topic of debate. While it may reflect reduced firing rate of single cells, it may also reflect firing of fewer cells, or faster, more efficient, processing of the stimulus and its ‘downstream’ effects (the ‘facilitation model’,  ,  ). Here, we have used BOLD adaptation solely as an index of neural specialisation, i.e. to identify the presence of a common neural population encoding actions and events with which they have been paired in training, rather than to investigate the mechanism by which that reduction occurs (see also  ). Therefore, the interpretation of our BOLD adaptation results is appropriate irrespective of whether individual mirror neurons show reduced firing rates with repeated stimulus presentation. 

### Alternative Accounts 
  
We have argued that the sensorimotor training completed before the scanning session induced associations between sensory populations of neurons encoding geometric shapes, and populations of neurons with mirror properties which were already responsive to the observation and execution of actions. In this section, we will consider a number of alternative accounts, and explain why we believe these to be unlikely explanations of our findings. 

First, rather than reflect novel   sensorimotor   associations, it could be argued that the observed adaptation effects could be caused by associations between the sensory descriptions of shapes and actions. Such   sensory-sensory   associations might allow shape observation to activate motor representations (Session 1) indirectly, via sensory representations of action, and sensory descriptions of action (Session 2) directly. However, this account is unlikely. Crucially, participants’ hands were occluded from view throughout both training and scanning phases. Consequently the sensory descriptions of the shapes and actions were never paired (i.e. temporally contiguous and contingent), thus the necessary conditions for sensory-sensory associative learning were not met. A related alternative account might hold that if participants imagined the sensory consequences of their actions during training   this may have yielded enough pairings to produce weak sensory-sensory associations. However, for either of these alternative accounts to be true, it would have to be the case that execution of the action caused the sensory description of that action to be activated. Thus, the sensory description of the shape would activate populations of neurons coding for both action execution and the sensory description of that action i.e. populations of neurons coding for mirror representations. 

Second, classical mirror areas do not only contain mirror representations of action; they also contain substantial populations of canonical neurons  ,  , thought to mediate object affordances. Could the adaptation effects observed be the product of canonical populations acquired long before the experiment? While geometric shapes lack the three-dimensional properties of the objects on which transitive actions are typically performed, it is possible that geometric shapes prime object properties – for example, a circle may activate neurons sensitive to the properties of spheres. However, this account is also implausible. Our training regime paired actions with shapes in a way that was both arbitrary with respect to any priming of this sort, and different between participants. For example, the observation of a circle (or sphere) no more ‘affords’ pointing than the observation of a square (or block), and does not do so more for the participants trained with this pair compared to those trained with the circle-splay finger pairing. The reliable motor activations during shape observation, seen in both sessions, are therefore unlikely to be the product of canonical neurons shaped before the experiment. Moreover, populations of canonical neurons could not produce the adaptation seen in Session 2 to the alternating observation of shapes and actions, as canonical neurons, by definition, are not responsive to the sight of actions. 

Third, it has been well-established using behavioural   and neurophysiological methods  ,   that both human and non-human animals show associative learning when they experience a contiguous and contingent relationship between an arbitrary stimulus and a motor response. It could be argued that the adaptation effects seen in Session 1 are the product of novel stimulus-response associations between the sensory representations of the geometric shapes and purely motor (i.e. non-mirror) representations. However, the results of Session 2 cannot be explained by this type of learning. Crucially, in Session 2, common motor populations were excited by both shape and action observation. This finding demonstrates that shapes were associated with motor populations that were already responsive to the sight of the same actions; i.e. mirror representations of action. Interestingly, previous research has found effects of associative learning in dorsal premotor cortex (PMd)  ,  , whereas mirror neurons have been found in the monkey PMv. However, the results of the present study, together with the results of Cisek and Kalaska   who found neurons with mirror properties in PMd, indicate that the loci of mirror representations and of training effects are not, in fact, dissociable (see also  ). 

Fourth, could the adaptation effects observed be due to adaptation of neurons coding for verbal or semantic representations of action, rather than populations of neurons with mirror representations? Such representations are thought to depend on regions of IFG  ,  . Under this interpretation, shapes become associated not with mirror representations but with verbal or semantic representations of the trained actions. Thereafter, neural populations encoding semantic or verbal descriptions of action may be excited both during observation and performance, via pre-experimental learning, and also during the observation of shapes, through associations acquired during training. However, if a population of neurons fires during the execution and observation of the same action - as is required in order to explain the adaptation in Session 2 - then that population meets the functional definition of a mirror representation, irrespective of whether that population also responds to verbal descriptions/semantic representations of actions. A ‘semantic account’ is therefore an extension of, and perfectly compatible with, the idea that the properties of mirror representations have been changed by training. Elucidating the nature of the information encoded by populations of neurons firing during observation and execution of action in different regions is a research aim common to all those researching the functions and origins of the human mirror system (e.g.  ). However, the observation that regions containing mirror neurons are considered to be the same as those involved in language processing is precisely what has prompted some authors to speculate that mirroring and language processes are closely related  . 

In conclusion, the results of the present study is consistent with the idea that mirror neurons are not ‘specialists’; i.e. they have not been shaped by evolution   or ‘canalised’   to respond in a mirror fashion to biological actions. One would expect the development of an adaptation to be buffered against such short-lived variations in the environment  ,  ,  . In contrast, evidence that populations of cells with mirror properties can become responsive to static, non-biological stimuli after a relatively short training period supports the associative account of the origin of mirror neurons. This account proposes that the development of mirror neurons is mediated by stimulus-general processes of learning within a system that is adapted for basic visuomotor control. Under this account, mirror neurons may contribute to social interaction, but they are not specialised for this role. 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-19'>
<h2>19. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/30225341/' target='_blank'>30225341</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Motivation Modulates Brain Networks in Response to Faces Varying in Race and Status: A Multivariate Approach</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> eNeuro</p>
<p><strong>Publication Year:</strong> 2018</p>
<p><strong>DOI:</strong> 10.1523/ENEURO.0039-18.2018</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6140103/' target='_blank'>6140103</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study in healthy adult participants (final N=60 male participants, mean age 23.8, within 18–60) who performed an explicit social task (impression formation of faces varying in race and socioeconomic status) while being scanned. The paper reports whole-brain analyses (behavioral and task PLS across the whole brain with voxelwise bootstrap ratios and cluster reporting) rather than ROI-only results. It is an original empirical fMRI study (not a review/meta-analysis) and does not report data from psychiatric or neurological patient groups. All inclusion criteria are met (task-based fMRI, healthy adults 18–60, whole-brain results); no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Previous behavioral and neuroimaging work indicates that individuals who are externally motivated to respond without racial prejudice tend not to spontaneously regulate their prejudice and prefer to focus on nonracial attributes when evaluating others. This fMRI multivariate analysis used partial least squares analysis to examine the distributed neural processing of race and a relevant but ostensibly nonracial attribute (i.e., socioeconomic status) as a function of the perceiver’s external motivation. Sixty-one white male participants (  Homo sapiens  ) privately formed impressions of black and white male faces ascribed with high or low status. Across all conditions, greater external motivation was associated with reduced coactivation of brain regions believed to support emotion regulation (rostral anterior cingulate cortex), introspection (middle cingulate), and social cognition (temporal pole, medial prefrontal cortex). The reduced involvement of this network irrespective of target race and status suggests that external motivation is related to the participant’s overall approach to impression formation in an interracial context. The findings highlight the importance of examining network coactivation in understanding the role of external motivation in impression formation, among other interracial social processes. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (50096 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Significance Statement 
  
This multivariate fMRI analysis examined distributed neural processing as participants formed impressions of faces varying in race and status. Across all conditions, participants reporting greater external motivation to respond without racial prejudice showed reduced coactivation in brain regions believed to support emotion regulation, introspection, and social cognition. These results suggest that external motivation may calibrate how perceivers form impressions in an interracial context, irrespective of target race. The results from this analysis raise new questions that may not have readily emerged in studies relying on traditional behavioral and univariate fMRI analyses. 


## Introduction 
  
Race remains a contentious topic in the United States and around the world. Evaluations of others based on race and other features may depend on motivations to respond without prejudice ( ;  ). In contrast to individuals who intentionally cultivate a racially egalitarian self-concept (i.e., internally motivated), individuals who are motivated to avoid the social sanctions of expressing racial prejudice (i.e., externally motivated) can be especially uncomfortable when race is salient ( ;  ). These motivations are frequently assessed using the internal motivation scale (IMS) and the external motivation scale (EMS;  ). Potentially due to race-related discomfort ( ;  ), whites with high EMS scores typically engage in more effortful (albeit less efficient) self-regulation during intergroup interactions ( ;  ;  ;  ;  ;  ). High-EMS individuals also tend to avoid explicit mentions of race, focusing instead on nonracial categories or topics ( ;  ). In a recent fMRI study ( ), we examined neural responses to perceived race and socioeconomic status (SES) during impression formation as a function of white perceivers’ EMS scores. Findings from this original univariate analysis indicated that EMS modulated the processing of SES (but not race) in brain regions involved in person evaluation. To gain greater insight into this intriguing set of findings, we used a multivariate approach known as behavioral partial least squares (PLS) analysis ( ) to identify how brain networks may be modulated as a function of individual differences in perceiver motivation. 

In our original univariate analyses ( ), we found that EMS modulated responses to SES in the bilateral nucleus accumbens (NAcc) and ventromedial prefrontal cortex (VMPFC), consistent with the literature on status-based evaluations ( ,  ). Notably, high-EMS participants showed neural response patterns to SES that were difficult to reconcile with the largely positive evaluations of high SES (when considered independently of other dimensions) observed in the behavioral ( ;  ) and neuroimaging ( ,  ) literature. 

In the present analysis, we used behavioral PLS analysis to examine distributed neural responses to perceived race and SES as a function of white perceivers’ EMS scores. Behavioral PLS analysis is a data-driven method that allows for the identification of one or more latent variables (LVs) that reliably account for covariance between individual differences (e.g., EMS) and distributed patterns of neural responses to conditions of interest (e.g., targets varying in race and status;  ;  ;  ). Because this is a data-driven approach to brain–behavior correlations, behavioral PLS analysis allows for the identification of several potentially compatible LVs. One possibility is that brain–behavior correlations may differ qualitatively across conditions ( ). Based on our original analysis showing EMS-related modulation of neural responses to SES ( ), for example, EMS could correlate with increasing coactivation across a distributed network of brain regions when forming impressions of high-SES targets and with decreasing (or null) coactivation in a different network when forming impressions of low-SES targets. The converse is also possible. Although our original univariate analysis did not show a reliable relationship between EMS and localized neural responses to race (or the race-by-status interaction), it is nonetheless possible that EMS may predict distinct patterns of neural coactivation as a function of race in a multivariate analysis. For example, one study using multivoxel pattern analysis examined the neural representation of race in key regions of interest (ROIs) as white participants were assigned to one of two mixed-race groups and subsequently categorized members from both groups while in the scanner ( ). Although no effects of race were reported in the behavioral or univariate analyses, the authors did find that race was reliably decoded above chance in the visual cortex and the fusiform gyri but not in control regions (for a similar study using gender instead of race, see  ). This is particularly interesting because recent work has suggested that distributed neural responses to race are decoded more reliably in the fusiform gyri when race processing is incidental to the task (i.e., as in the present study) compared with when race processing is integral to the task ( ). A final possibility is that brain–behavior correlations are similar across all conditions ( ). In other words, EMS could increase or decrease the overall coactivation between brain regions irrespective of face race or SES, implying that EMS influences how participants approach the task overall. Although the data-driven nature of PLS analysis obviates the need to formalize a priori ROIs, we anticipated that any latent variables would likely implicate regions involved in person evaluation (VMPFC;  ;  ;  ;  ,  ) and the regulation of prejudice (e.g., cingulate cortex, lateral prefrontal cortex;  ;  ;  ). 


## Materials and Methods 
  
### Participants 
  
Eighty-two Chicago-area men passed the initial screening. Of the 82 eligible participants, 61 completed the study. The 21 eligible participants who did not complete the study either failed to complete the on-line battery of questionnaires or were unable to schedule a suitable time for the scanning session before achieving our intended quota for this study (  N   = 60). One participant was excluded from analyses as an outlier for IMS (a control variable), exceeding 3.5 SDs from the sample mean (see Results). The final sample comprised 60 male participants (mean age, 23.8 years; SD = 4.59 years). 


### Protocol 
  
#### On-line surveys 
  
Eligible participants completed a battery of questionnaires on-line before the day of their scan. Most of these measures were assessed for a large-scale resting-state fMRI investigation or an unrelated experiment completed immediately before the impression-formation task used for the present analysis. Although we provide an overview of pertinent measures for this report (see Experimental design and statistical analysis), full details are available in the open-access report from our previous analysis of the presented data ( ). 


#### Scanning session 
  
On the day of scanning, participants were instructed to arrive without having consumed drugs, including caffeine and alcohol. After signing consent and imaging center paperwork, the participant was photographed and completed brief surveys. Participants were then trained on the two tasks they would complete while in the scanner. The primary experimental task involved forming impressions of faces varying in race and ascribed status. An additional task, which served as a control task for the purpose of an analysis performed for the current study, involved explicitly rating (1) the attractiveness of a series of faces depicting white actors and models and (2) the likeability of a separate set of white actor faces based on their body of work. The faces of black actors and models were not used for this control task. 

Participants were first trained on the control task. They completed a practice block outside of the scanner in which they learned how they would be rating the actors and models while in the scanner. The practice block was a shortened version of the main experiment (one run with three blocks of 10 trials each), using actors and models that would not be presented in the scanner. After completing the full practice block for the control task, participants then learned about the main impression-formation task. The experimenter informed participants that the study investigated how people think of others varying in SES. SES was defined as follows: “Those who have the highest social status tend to have the most money, the most education, and the most respected jobs. Those who have the lowest social status tend to have the least money, the least education, and the least respected jobs or no job.” Following this definition, participants learned to associate colors with low- and high-status Americans (e.g., blue = low; orange = high). Status–color associations were counterbalanced across participants. 

To thoroughly learn status–color associations, participants completed simple association training blocks ( ;  ;  ). In an initial block of 10 trials, participants viewed a darkened silhouette over a colored background (i.e., orange or blue: five per status level), indicating by key press whether the silhouette was low status or high status based on the background color. Participants were informed of their cumulative accuracy on each trial (mean, 98.5%). Next, participants completed a block of 10 trials (5 per status level) in which they were asked what color represents low (or high) status. Participants were again informed of their cumulative accuracy on each trial (mean, 93.4%). 

Having learned the two status–color associations, participants briefly practiced the impression-formation task that they would complete while in the scanner (see Experimental design and statistical analysis). The experimenter first verbally confirmed that the participant learned the status–color associations and then explained that participants would no longer be categorizing targets as low or high in status for the impression-formation task. Instead, they would be forming quick overall impressions of male faces, taking into account all visually available information ( ). This was repeated for participants in the written instructions for the practice block of the impression-formation task. The procedure for the practice trial block was the same as the procedure reported for the experimental block. 

Once situated in the scanner, participants first completed two fMRI runs of the control task ( ). After this task, participants completed a brief task reminding them of the learned status–color associations and how to use the button box. All participants correctly recalled the status–color associations. After this reminder, participants completed two runs of the impression-formation task (each ∼4 min), followed by resting-state and anatomic scans, time permitting (total scan time, ∼1 h). On exiting the scanner, participants completed explicit stimuli ratings and judgments ( ). After this block of surveys, participants were compensated and debriefed. 


#### fMRI acquisition 
  
We used a Phillips dStream Achieva 3 T system and 32-channel head coil to acquire BOLD, T2* contrast-weighted echoplanar images (EPIs). With a 2000 ms repetition time and a 25 ms echo time, we acquired 34 oblique slices using an interleaved   z  -shim acquisition protocol ( ). Slices were 4 mm thick with a 0.5 mm gap, a 3 mm  in-plane resolution, 77° flip angle, and a 192 × 134 × 192 mm field of view. Slices were aligned to the anterior commissure–posterior commissure axis of each participant ( ). 



### Experimental design and statistical analysis 
  
#### Design and key measures 
  
The present analysis focuses on BOLD responses as participants formed impressions of targets varying in race and SES. We describe the impression-formation fMRI task design first, followed by the primary individual difference measures of EMS and IMS. 

##### Impression-formation task 
  
After a brief training session completed outside the scanner (see Protocol), participants learned to associate two colors with different status levels ( ). For example, blue conveyed high status, and orange conveyed low status. Status–color associations were counterbalanced across participants. 

The impression-formation task that participants completed during functional scanning adhered to a rapid event-related design ( ). Trials began with a black or white male face surrounded by a blue- or orange-colored frame over a black background. After 1500 ms, the face was replaced by a white fixation of a jittered duration (i.e., intertrial interval of 500, 2500, 4500, or 6500 ms). Participants formed a quick impression of each individual by the time the face disappeared or shortly thereafter. To signal they formed an impression, participants simultaneously pressed two keys, one per index finger. Participants were informed that their responses were not meant to indicate the content of their impressions, but merely to indicate that they had formed an impression. In each run of the impression-formation task, participants viewed 60 male faces divided evenly across conditions (for details on stimulus equating, see  ). Two reminder trials after the first and second thirds of the sequence required participants to identify the status level of a silhouette framed by either blue or orange. 

Faces from all four combinations of race (black, white) and status (low, high) were interspersed in a fixed pseudorandom sequence. To optimize fMRI design efficiency ( ), three fixed trial sequences were generated using optseq2 ( ). For further details on trial sequence design and optimization, see the study by  ). 


##### Control task 
  
The control task consisted of an event-related design with two functional runs. Full details on stimulus equating and counterbalancing have been reported (T.P.D., B.D.M., J.T.K., and J.C., unpublished observations). Images of actor faces and model faces were presented over two functional scans, with 30 unique white actors and 15 unique white models per functional scan. In each scan, participants rated half of the actors on attractiveness and the other half on the body of work. The models were rated only on their attractiveness. 

Before each block of the control task, participants viewed a prompt indicating the evaluative judgment and target group (e.g., How attractive are these models?). All trials began with a 1500 ms presentation of a face over a black background, followed by a 500 ms fixation. After 500 ms of fixation, the fixation cross changed from white to green, prompting participants to indicate their evaluation of the actor or model. Participants responded on a scale of 1 (very attractive/likable) to 4 (very unattractive/unlikable), with key mapping counterbalanced across participants. After 1000 ms, the green fixation changed back to white and remained for an additional 1000 ms. Jittering was implemented after each trial using 0, 2000, 4000, or 6000 ms fixations. 


##### Motivation to respond without racial prejudice 
  
This 10-item measure ( ) was administered on-line before the participant’s scheduled scan date. The EMS (Cronbach’s α = 0.874) included five items (e.g., “I try to act nonprejudiced toward black people because of pressure from others”). The IMS (Cronbach’s α = 0.764) also contained five items (e.g., “Being nonprejudiced toward black people is important to my self-concept”). Both motivations were measured on a 9 point scale from 1 = strongly disagree to 9 = strongly agree. EMS and IMS were uncorrelated in the final sample (  r   = 0.052,   p   = 0.694). Full details on the distributions of EMS and IMS are reported by  ). 


##### Postscan stimulus ratings 
  
Participants completed a measure of explicit likeability for each of the 60 male face stimuli viewed in the scanner during the impression-formation task. Faces were presented with the same status-associated colored backgrounds used in the scanner. Participants rated each face on a scale from 1 = extremely unlikeable to 9 = extremely likeable. 



#### Analyses of behavioral data 
  
For the sake of completeness, we report briefly on participants’ reaction times (RTs) during the impression-formation task, simultaneously testing whether reaction times show any relationship with EMS. Using a similar approach, we also explore whether EMS predicts postscan stimulus ratings of likeability. 

##### Reaction time analysis 
  
Because of device malfunctions, RTs were not recorded from four participants. Therefore, the RT analysis included only 56 participants. Any RTs <250 ms (<0.1% of all trials) and any trials where no response was provided (1.5% of all trials) were immediately excluded from analysis. We then subsequently trimmed any remaining RTs exceeding 3 SDs from the participant’s mean RT (0.4% of all trials). RTs were then log-transformed before analysis to reduce the natural skew of RT data. To test for effects in the speed of responses during the impression-formation task, we used a linear mixed-effects model in which log-transformed reaction times were predicted by target race, target status, and the participant’s EMS score. The model included a random intercept, all possible random slopes by participant, and all possible correlation parameters. 


##### Postscan likeability ratings and EMS 
  
Using a similar linear mixed-effects model, we analyzed postscan ratings of stimulus likeability as a function of target race, target status, and the participant’s EMS score. As in the analysis of RTs, the model included a random intercept, all possible random slopes by participant, and all possible correlation parameters. 



#### Analyses of fMRI data 
  
For the fMRI data, we first summarize the preprocessing parameters and GLM parameters as reported in the original univariate analysis of these data ( ). We then provide a detailed overview of the multivariate behavioral PLS analyses used in the present report. Additional supplemental analyses are also described. 

##### Preprocessing 
  
EPIs from each participant’s four runs (two per task) were preprocessed and analyzed at the first level using SPM8 (  www.fil.ion.ucl.ac.uk/spm  ), facilitated by a custom suite of scripts for fMRI analysis (  https://github.com/ddwagner/SPM8w  ). We first implemented slice-time correction ( ), using the 17th slice acquisition as the reference. Subsequently, we integrated the four repeated   z  -shim slices ( ). The resulting images from each participant were then unwarped and realigned to the participant’s mean EPI to correct for motion and motion-by-distortion interactions ( ). Images were subsequently normalized to the MNI template and smoothed with an 8 mm FWHM kernel ( ). 


##### GLM 
  
To estimate the BOLD responses for each condition, each trial was considered as an event, and the stimulus time series was convolved with the canonical hemodynamic response function. A GLM modeled scan sequences concatenated by task as a single session with regressors for each condition. For the race-status impression-formation task, we modeled four conditions (ordered as follows: high-status black, high-status white, low-status black, and low-status white). For the control task, we modeled three conditions (ordered as follows: attractiveness ratings for actors, body-of-work ratings for actors, and attractiveness ratings for models). For both task GLMs, regressors for the key conditions of interest were followed by regressors controlling for variance associated with: (1) reminder trials; (2) low-frequency drift (i.e., a linear trend); (3) session means (1 for scan 1, 0 for scan 2); (4) six movement parameters; (5) a constant across all scans; and (6) slow fluctuation of the signal (i.e., a standard set of harmonic regressors effectively serving as a 1/128 Hz high-pass filter). Contrast images reflecting the first-level effect of each condition versus baseline were used for PLS analyses ( ). 


##### Behavioral PLS analysis 
  
Behavioral PLS analysis is a data-driven method that allows for the identification of LVs that reliably account for covariance between individual differences on a behavioral measure (e.g., EMS) and one or more distributed patterns of neural responses to conditions of interest ( ). In other words, the goal of behavioral PLS analysis is to find weighted patterns (i.e., the LVs) characterized by maximal covariance between the behavioral and neural datasets. A description of this method given in considerable detail can be found in previous work ( ;  ;  ;  ). In this section, we first provide some detail on how the analysis is implemented followed by an overview of the benefits and limitations of behavioral PLS analysis. 


##### Analysis parameters 
  
In the present report, we use the same analysis procedure reported by   to examine the degree to which EMS predicts distributed neural responses to all conditions of interest in both the impression-formation and control tasks. To test the overall significance of each LV, a set of 2000 permuted samples was created by randomly reordering participants and condition labels (without replacement) in the voxelwise fMRI dataset, but conserving the original behavioral dataset (i.e., EMS scores). The same model used to generate the LV was subsequently applied to each permuted dataset, resulting in 2000 new covariance matrices. These covariance matrices embody the null hypothesis that there is no relationship between brain activity and behavioral data. Each covariance matrix was then subjected to singular value decomposition (SVD), resulting in a null distribution of singular values. The significance of the SVD of the original LV was ultimately assessed with respect to this null distribution. The   p   value was calculated as the proportion of the permuted singular values that exceeded the original singular value. For each significant LV, the reliability of brain–behavior correlations specific to each condition was tested using 95% confidence intervals ( ). These confidence intervals were generated using a 2000-sample bootstrapping test. Because the top and bottom bounds of the confidence intervals are derived from a bootstrap distribution, it is common for these bounds to be asymmetric relative to their corresponding estimates ( ). Indeed, when the underlying distribution is sufficiently skewed, it is possible for the correlation estimate to fall outside of its bootstrapped confidence interval. We report confidence intervals derived from the standard estimation procedure built into the PLS analysis toolbox (see   http://web.mit.edu/seven/src/PLS/Plscmd/pls_analysis.m  ). 
  
  A   , External motivation to respond without prejudice (EMS) emerged as a significant LV in behavioral PLS analysis. Brain–behavior correlations were similar across conditions.    B   , Patterns of whole-brain activity covarying with EMS are presented on lateral–anterior (left) and medial (right) views of the right hemisphere. All voxels with BSR ≥2.5 are displayed, irrespective of their respective cluster sizes. Note that the directionality of brain activity needs to be interpreted in conjunction with the plotted brain–behavior correlations in    A   . Increasingly positive BSRs in    B    indicate greater reliability of the negative brain–behavior correlations depicted in    A   . 
  
The reliability with which each voxel contributes to the LV (i.e., the “salience” of the voxel) was also determined with bootstrapping. A set of 2000 bootstrap samples was created by resampling participants (with replacement) within each condition. Each new covariance matrix was subjected to SVD as before, and the singular vector weights from the resampled data were used to build a sampling distribution of the voxel saliences from the original dataset. The purpose of a constructed bootstrapped sampling distribution is to determine the reliability of each salience; saliences that are highly dependent on which participants are included in the analysis will have wide distributions. A single index of reliability termed “bootstrap ratio” (BSR) is calculated by taking the ratio of the salience to its bootstrap estimated SE ( ). A BSR for a given voxel is large when the voxel makes a strong contribution to the LV and the bootstrap-estimated SE is stable across many resamplings. 

In the present study, voxel-specific BSR values were thresholded at the 95% confidence interval, corresponding to absolute BSR values exceeding 2.5. We used xjview (  http://www.alivelearn.net/xjview  ) to identify and report the clusters of ≥20 contiguous voxels showing BSRs at or above this threshold ( ,  ).
 
  
Results of behavioral PLS analysis using external motivation to respond without prejudice (EMS) 
      
Behavioral PLS analysis results from the supplemental analysis of the control task 
    

##### Benefits and limitations of PLS analysis 
  
Although other methods exist for examining changes in functional connectivity as a function of individual differences (e.g., psychophysical interaction, dynamic causal modeling), one of the primary advantages of behavioral PLS analysis relative to these methods is that behavioral PLS analysis maximizes coactivation at the whole-brain level without constraining analysis to correlations with a particular seed voxel or region ( ). Behavioral PLS analysis can result in differences in brain–behavior correlations across conditions ( ), albeit in a less subject-specific fashion than for more traditional analyses. This is because estimates for brain–behavior correlations are determined through a bootstrapping approach that collapses across participants. Therefore, behavioral PLS analysis can illustrate intercondition differences in at least two ways. First, confidence intervals for brain–behavior correlations in one or more conditions may contain zero. In this case, one can have little confidence that the condition containing zero in the confidence interval reliably contributes to the latent variable, unlike for the other conditions that do not contain zero in their confidence intervals. Second, confidence intervals across conditions may lie on opposite sides of zero. In this case, one can more strongly articulate a difference between conditions. Namely, conditions with positive (vs negative) brain–behavior correlations would be associated with opposite changes in coactivation in brain regions with large BSR values of the same sign (e.g., positive) as a function of the behavioral variable (e.g., EMS). 

Because behavioral PLS analysis is a data-driven approach, distributed neural responses that maximally covary with the behavioral data need not be condition specific as in the preceding examples. In fact, a significant LV could reflect neural responses that correlate with the behavioral data to a similar degree for all conditions ( ). In this case, supplemental analysis of a control task can provide additional information regarding the relative context specificity of brain–behavior correlations. For the present report, the control task served to determine whether the relationship between EMS and distributed neural coactivation in the impression-formation task, which systematically varies target race, would generalize to a different face evaluation task for which race is not a factor. Such generalization would suggest that findings from our analysis of interest (i.e., how EMS shapes neural coactivation when forming impressions of faces varying in race and status) are not task specific but rather are revealing of broader differences in the neural responses of individuals varying in EMS. 


##### Supplemental PLS analyses 
  
Because the EMS is thought to have different consequences depending on the perceiver’s IMS score ( ), we conducted a follow-up analysis that controlled for IMS by partialing out variance in the EMS accounted for by the IMS and using the residuals in behavioral PLS analysis. Because the mean IMS score was 7.64 (on a scale from 1 to 9), the original analyses of EMS assume a high-IMS participant sample. For all analyses, the pattern of findings was similar even after controlling for IMS. As noted here and in our previous work ( ), the limited range in IMS precludes the possibility of generalizing effects to individuals who are low in IMS (all participants scored above the midpoint of the scale). 

Finally, we also conducted a task PLS analysis of the fMRI data from the impression-formation task. Task PLS analysis differs in important ways from behavioral PLS analysis for which each LV represents (1) a correlation between an individual difference (e.g., EMS) and distributed neural activity across participants and (2) the spatial pattern of voxel activations that supports that profile. In task PLS analysis, each LV represents (1) differences between experimental conditions for each participant (interpreted as a contrast) and (2) the spatial pattern of voxel activity that supports that contrast. In other words, because task PLS analysis results in brain scores at the participant level, it allows for more formal tests of differences between conditions, albeit in the absence of any individual difference variables such as EMS. In the present analyses, we used task PLS analysis to test for latent variables accounting for the relationship between the 2 (race: black, white) × 2 (status: low, high) factorial design and distributed patterns of neural responses. The same permutation and bootstrapping parameters for behavioral PLS analyses were applied to the task PLS analysis. Because results failed to return any significant LV (all   p   > 0.11), we do not further report on the task PLS analysis. 




### Code accessibility 
  
Analyses of RT and postscan ratings were conducted in R ( ) using the lme4 ( ) and lmerTest ( ) packages. The code used to run preprocessing and GLM steps of the analysis was facilitated by SPM8 (  www.fil.ion.ucl.ac.uk/spm  ) and a custom suite of scripts for fMRI analysis (spm8w version r5236;   https://github.com/ddwagner/SPM8w  ). PLS analyses were conducted using a set of scripts based on an existing MATLAB-based PLS analysis toolbox (PLS Applications version 6.1311050:   http://pls.rotman-baycrest.on.ca/UserGuide.htm  ). All code used for analysis is available from the authors on request. Analyses were performed on a linux-based server (OS, Redhat Release 7) using Matlab 2012a. 



## Results 
  
### Reaction time data 
  
RTs were on average just under 1 s (mean RT = 977 ms; SD = 306 ms). Analyses revealed similar RTs irrespective of target race, target status, and EMS score. A marginal main effect of target status (  b   = 0.00673, SE = 0.00350, 95 CI% = [−0.000138, 0.0136],   t   = 1.920,   p   = 0.060) suggested a nonsignificant trend for faster responses when forming impressions of low-status (vs high-status) targets. All other effects were also nonsignificant (  p   > 0.24). 


### Postscan likeability ratings 
  
Postscan ratings of likeability revealed significant main effects of target race (  b   = 0.793, SE = 0.124, 95% CI = [0.550, 1.04],   t   = 6.385,   p   < 0.001) and target status (  b   = 0.413, SE = 0.106, 95% CI = [0.205, 0.621],   t   = 3.896,   p   < 0.001). These effects indicated greater likeability ratings for black (vs white) targets and high-status (vs low-status) targets, respectively. Consistent with the behavioral PLS analysis reported below, we observed a significant main effect of EMS (  b   = −0.175, SE = 0.0790, 95% CI = [−0.330, −0.020],   t   = −2.215,   p   = 0.031), with greater EMS scores associated with lower likeability ratings, irrespective of the race or status of the target. All other effects were nonsignificant (  p   > 0.19). 


### PLS analysis of the impression formation task 
  
Results revealed a significant effect of EMS as the first LV (  p   = 0.028), which explained 61.4% of the crossblock covariance. Across all conditions ( ), larger EMS scores were associated with reduced coactivation in regions that form part of the emotion regulation [rostral anterior cingulate cortex (rACC)], introspection [middle cingulate cortex (MCC)], and social cognition [dorsomedial frontal pole, dorsomedial prefrontal cortex (DMPFC), and temporal pole] networks ( ,  ). This relationship was not substantially impacted when controlling for IMS (first LV:   p   = 0.028, explaining 57.9% of crossblock covariance). Due to the similarity between these two analyses and the limited IMS variance in our high-IMS sample, all reported results are without controlling for IMS. Nonetheless, any differences that emerged between these two analyses are indicated in  . 


### PLS analysis of the control task 
  
Results revealed a significant effect of EMS as the first LV (  p   = 0.025), which explained 56.7% of the crossblock covariance. Notably, only the attractiveness conditions reliably contributed to the LV: model brain–behavior correlation = 0.4235, 95% CI = [0.4568, 0.7570]; actor brain–behavior correlation = 0.1466, 95% CI = [0.0740, 0.6331]. The confidence interval for ratings of actor likeability based on body of work contained zero: brain–behavior correlation = 0.0878, 95% CI = [−0.0025, 0.4718]. In the attractiveness conditions, larger EMS scores were associated with increased coactivation in a distributed network of regions largely localized to the visual cortex, cerebellum, and sensorimotor and lateral prefrontal areas ( ). Note that the directionality of this effect (i.e., EMS was associated with increased coactivation between brain regions) runs in the opposite direction to that observed in the impression-formation task (i.e., EMS was associated with decreased coactivation). 



## Discussion 
  
The present findings provided the first demonstration using PLS analysis that motivation can shape the recruitment of brain networks when forming impressions of others. Specifically, increasing EMS predicted reduced coactivation of regions involved in affect regulation (e.g., rACC), introspection (MCC), and social cognition (frontal pole, DMPFC, and temporal pole) when forming impressions of faces varying in race and social status. The components of the network emerging from the impression-formation task analysis are noteworthy in several respects. We discuss each set of regions separately in the following section. 

Notably, the supplemental analysis of the control task (i.e., explicit evaluations of white actors and models) provides some evidence that the negative relationship between EMS and coactivation in the aforementioned network of regions may be specific to social evaluations when race is a factor (i.e., as in the main impression-formation task). Although the supplemental analysis of the control task showed a positive relationship between EMS and coactivation of a network of regions that was distinct from the main task analysis, we nonetheless caution the reader that this difference may also reflect task differences other than the salience of race. For example, the main task involved privately forming impressions, whereas the control task required relatively more explicit and public ratings. 

Beyond providing insight into the potential neural underpinnings of EMS, the present findings are also noteworthy in that the network observed in the present analysis emerged in a relatively private context. Although previous work often indicates that high-EMS individuals are typically sensitive to experimental contexts in which they believe their responses are being monitored or will be made public ( ;  ;  ), the effects of the EMS are still observed even in a private context. For example, previous studies using both EEG ( ) and behavioral methods ( ) have also identified the effects of EMS on the endorsement/inhibition of stereotypes in private contexts. One possibility is that participants’ awareness that their brains were being scanned while forming impressions of black and white targets may have triggered externally motivated regulation (e.g., pipeline effects, see  ). Unfortunately, these present data do not allow us to directly test the extent to which external motivation was triggered by (erroneous) beliefs about scanners reading minds. It would be interesting in a future study to examine this possibility by scanning participants who have been deceived with information that individual preferences and tendencies can be inferred from brain data versus those who have been informed about the limitations of fMRI research. Informing participants during scanning that their responses will be private (vs made public) should have a similar effect. In summary, although the mechanism requires further study, our findings add to the existing behavioral and EEG literatures, suggesting that EMS may be associated with distinct neural underpinnings even when the central threat pertaining to EMS (i.e., the potential to be exposed as harboring racist tendencies) is minimized by the private nature of the impression-formation task. 

### rACC 
  
Although the present data do not directly speak to the relationship between rACC and affect regulation, the emergence of this region in the present analysis is interesting in light of earlier work that has more directly implicated the rACC (among other regions) in the regulation of negative affect ( ,  ) and prejudice ( ;  ;  ). The rACC and adjacent areas of the orbitofrontal cortex/VMPFC are thought to serve as a conduit for inhibitory signals from dorsomedial and lateral prefrontal regions en route to the amygdala ( ;  ;  ). Even in simple cognitive tasks, rACC is associated with enhanced processing of emotion-related stimuli ( ) and attempts to increase emotional responses to errors under low cognitive load ( ). In the context of race, the rACC has been implicated in the experience of guilt after learning about one’s own implicit prejudice. More specifically, in a high-IMS score sample, rACC activity to prejudice-indicative feedback increased as self-reported guilt decreased ( ), suggesting that the rACC may have been recruited spontaneously to downregulate the negative experience of guilt in the absence of an opportunity to effectively reduce their prejudice ( ). Such an interpretation is consistent with the recent suggestion that the rACC may play a special role in implicit emotion regulation—that is, regulation arising without conscious monitoring, immediate insight, or awareness ( ). 

As in previous work reporting multivariate analyses of race ( ;  ) and gender ( ) perception, response patterns differed from those we observed in our behavioral and univariate analyses ( ). Nonetheless, we note that the rACC region detected in the present PLS analysis overlaps partially with the medial prefrontal region detected in the whole-brain analysis of the same dataset ( ). This univariate analysis indicated that the overall larger response to high-status (vs low-status) targets reversed in high-EMS score individuals, specifically in a region involved in social evaluation (VMPFC, extending to rACC; compare with ROI analyses of VMPFC, NAcc, and amygdala). The brain–behavior correlations in   are consistent with this picture (i.e., indicating numerically larger decreases in coactivation in the rACC for high-status than for low-status targets. Together, these findings suggest that EMS score may be associated with changes in both the participant’s overall approach to the task (i.e., poorer coordination between key networks previously implicated in affect regulation, introspection, and social cognition) and the participant’s sensitivity to target attributes within the task (i.e., status level). Based on the partial anatomic overlap between the findings from these two complementary studies, it will be important to more closely examine the degree to which rACC may play a unique role in supporting both task-general and target-specific effects of motivation. We believe that a multianalysis approach such as the one used for the present dataset should guide such future investigations. 


### MCC 
  
In addition to the rACC, the MCC was also part of the overall network that decreased in coactivation as a function of EMS. Although the MCC is perhaps less frequently implicated in studies on motivation or affect regulation, several studies have tied activity in this region to introspection about one’s own internal states ( ;  ;  ) or unpleasant emotions ( ). In the present study, we observed decreased coordination between this region and areas previously implicated in affect regulation and social cognition as a function of increased EMS. On the basis of this finding, we speculate that increasing awareness of one’s own negative internal states (vis-à-vis neural substrates in the MCC) may play an important role in circumventing the regulatory difficulties experienced by high-EMS score individuals in an interracial context (see  ). In any case, the present finding highlights the MCC as an important ROI in future work on external motivation to respond without racial prejudice. 


### DMPFC and frontal/temporal poles 
  
Beyond the cingulate cortex, EMS was associated with diminished coactivation in regions previously implicated in social cognition, such as the medial prefrontal cortex (frontal pole and DMPFC) and temporal pole. In general, these regions often emerge in studies of impression formation and mentalizing ( ). The frontal pole in particular is thought to support recently evolved aspects of social cognition including the planning and monitoring of goal-directed actions ( ;  ). Recent work illustrates that the frontal pole can be divided into cytoarchitectonically and functionally distinct subregions. Meta-analyses have linked the dorsomedial subregion of the frontal pole (corresponding to the frontopolar region observed in the present study) to affective and social cognitive tasks ( ;  ). For example, this region appears to be sensitive to reputational outcomes for the self and close others ( ). In addition, analyses of functional connectivity have revealed that the dorsomedial frontal pole is functionally connected with a number of other key regions observed in this PLS analysis, including lateral temporal cortex, rACC, and middle/posterior cingulate cortex ( ;  ). 

In addition to the cingulate cortex and frontal pole, we also observed EMS-related decreases in coactivation between the DMPFC and temporal pole. Previous work has implicated these regions in general impression formation ( ;  ;  , ;  ) and the representation of evaluative and/or stereotypic person knowledge ( ;  ;  ), respectively. The EMS-related coactivation between DMPFC and the temporal pole (in addition to the rACC) overlaps considerably with the results observed in a recent study on race-based impression formation in the presence of evaluation-relevant person knowledge ( ). In that study, diminished activity was observed in the DMPFC, temporal pole, and rACC as high-IMS (vs low-IMS) participants formed impressions of black and white targets paired with evaluatively incongruent traits (i.e., positive and negative traits, respectively). This finding suggests that high-IMS (vs. low-IMS) individuals may be less sensitive to evaluative incongruence, resulting in diminished recruitment of regions involved in (affect-related) conflict regulation and impression formation. Notably, the present analysis indicates that these same regions (DMPFC, temporal pole, and rACC, among others) nonetheless exhibit sustained coactivation as high-IMS individuals form impressions of targets varying in race and other attributes (i.e., status). However, this coactivation between regions involved in emotion regulation and social cognition is diminished in individuals with higher levels of EMS. Together, the relationship between EMS and diminished coactivation in this social-cognitive network (in addition to regions involved in affect regulation and introspection) raises the possibility that high-EMS individuals may have been less engaged with the impression-formation task overall, despite also reporting high IMS. Future work is needed to more directly examine the relationships among coactivation in this network, task engagement, and potential mediators, such as negative affect arising from external concerns about implicit evaluative bias. 


### Relevance to the neuroscience of prejudice 
  
Previous neuroimaging work has implicated the frontal control network (including the ACC) in the regulation of prejudice in paradigms ranging from race-irrelevant spatial location tasks ( ;  ) to race-related fear learning ( ) and measures of implicit bias ( ;  ). In recent reviews, the ACC [i.e., dorsal ACC (dACC)] is typically considered to reflect monitoring for conflicts between internal desires to be egalitarian and an undesirable propensity for stereotypic or prejudiced responses ( ;  ;  ;  ). It bears mentioning that cingulate activity in the present analysis was localized to the rACC and the MCC. Although previous work on the neural substrates of prejudice regulation has focused primarily on the dACC, some have suggested on the basis of evidence from event-related potentials (ERPs) that rACC may be recruited to monitor for conflicts with external cues such as egalitarian norms ( ;  ). This possibility is consistent with the present finding that EMS (i.e., an external motivation) affected coactivation in a relatively rostral aspect of the ACC. 

Although this is one of the first fMRI studies to examine the effects of EMS on impression formation (but see  ;  ), previous work relying primarily on ERPs has long suggested that the ACC may be sensitive to perceiver motivations to respond without prejudice. Specifically, high-IMS individuals are thought to exhibit amplified conflict monitoring when race is salient ( ,  ), even when not explicitly instructed to control their racial bias ( ). Even at high levels of IMS, increasing EMS has been observed to diminish control-related ERPs, ultimately resulting in poorer regulation of racial prejudice ( ). This is consistent with the present observation (also in a high-IMS sample) that EMS reduced overall coactivation between a collection of regions previously implicated in both affect regulation (rACC) and social cognition (frontal pole, DMPFC, and temporal pole). 

Finally, it is imperative to note that the present study did not involve any revelations of prejudice; nor did it directly assess the regulation of negative affect. For this reason, it is difficult to determine what mechanism is mediating the effects of EMS on neural coactivation. Exploratory analyses of postscan stimulus ratings indicated a significant negative relationship between EMS and ratings of target likeability irrespective of target race or status, providing indirect support for the notion that high-EMS participants may be less predisposed to like others in the context of this interracial impression-formation task. The reason for this decline in likeability ratings as a function of EMS is unclear. It is possible that forming impressions of any individual in an interracial context is particularly uncomfortable for individuals with high EMS scores ( ;  ;  ;  ), resulting in lower overall likeability ratings. In summary, it will be important for future work to examine additional behavioral correlates of EMS to triangulate more precisely what psychological mechanism underlies the relationship between individual differences in EMS and the pattern of neural coactivation observed in the present study. Consistent with existing evidence that high EMS affects neural control mechanisms in participants concerned about appearing prejudiced ( ;  ), one possibility is that externally motivated concerns (e.g., about the scanner detecting one’s prejudice) may have diminished effective regulation of negative affect arising from conflicts between racial/class bias and intentions to form unbiased impressions ( ;  ). Alternatively, EMS may be associated with a diminished awareness of and/or propensity to regulate negative affect in the first instance. Further research is needed to differentiate between these and other possibilities. 


### Conclusion 
  
Using PLS analysis, we found that EMS diminished coactivation between brain networks previously implicated in affect regulation, introspection, and social cognition as high-IMS white perceivers formed impressions of targets varying in race and status. Notably, this EMS score-related decrease in coactivation was observed in all conditions, suggesting that EMS was associated with the way participants approached the impression-formation task as a whole rather than their responses to attributes of the targets, such as status (but compare with  ). The emergence of the rACC in the present analysis is noteworthy in light of previous work that has more directly examined the role of this region in prejudice regulation ( ;  ;  ). Moreover, together with the previous univariate analysis of the same dataset ( ), the present analysis suggests that the rACC may uniquely contribute to both task-specific and target-specific effects of motivation to respond without racial prejudice. Finally, the current findings also raise new questions regarding the relationship between self-reported levels of EMS and the psychological and neural mechanisms of prejudice regulation. 

In conclusion, the present PLS analysis provides insight above and beyond what was previously obtained using univariate analysis ( ), suggesting that EMS leads to decreases in coactivation in regions previously implicated in emotion regulation, introspection, and social cognition. Although the precise mechanism underlying this EMS-related decrease in coactivation across this network requires further study, we believe that this network and multivariate approach will be a fruitful starting point for research into the neural substrates of previously established relationships among EMS, race-related discomfort ( ;  ;  ;  ), and prejudice regulation ( ;  ;  ;  ;  ;  ;  ). 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-20'>
<h2>20. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31680152/' target='_blank'>31680152</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> The neural basis of shared preference learning</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Soc Cogn Affect Neurosci</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1093/scan/nsz076</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6970152/' target='_blank'>6970152</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study in healthy adults (n=25, mean age 25.1) where participants performed a social task in the scanner (learning others’ preference similarity). Analyses report whole-brain, cluster-corrected results (conjunctions and contrasts across the brain) rather than ROI-only findings. Participants were screened for neurological disorders and no clinical population was studied. The study is empirical (not a review/meta-analysis) and presents task-based functional MRI results relevant to social processing, meeting all inclusion criteria and violating none of the exclusions.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
During our daily lives, we often learn about the similarity of the traits and preferences of others to our own and use that information during our social interactions. However, it is unclear how the brain represents similarity between the self and others. One possible mechanism is to track similarity to oneself regardless of the identity of the other (Similarity account); an alternative is to track each other person in terms of consistency of their choice similarity with respect to the choices they have made before (consistency account). Our study combined functional Magnetic Resonance Imaging (fMRI) and computational modelling of reinforcement learning (RL) to investigate the neural processes that underlie learning about preference similarity. Participants chose which of two pieces of artwork they preferred and saw the choices of one agent who usually shared their preference and another agent who usually did not. We modelled neural activation with RL models based on the similarity and consistency accounts. Our results showed that activity in brain areas linked to reward and social cognition followed the consistency account. Our findings suggest that impressions of other people can be calculated in a person-specific manner, which assumes that each individual behaves consistently with their past choices. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (39403 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
The ability to rapidly form and update our impressions about other people is a vital skill in navigating our complex social world. During our daily lives, we frequently learn about the traits and preferences of other people and use that information to inform our social interactions. However, the neural mechanisms that govern our learning of the relationship between our preferences and those of others are currently unclear. The current study investigated these mechanisms by combining fMRI and computational modelling. 

Researchers investigating impression formation have sought to determine which brain areas respond when we learn about other people and when our expectations of others are violated. Most have done this by providing participants with some information about a novel person and then presenting either consistent information that confirms the previous impression or inconsistent one, which requires participants to update their impressions. These studies have shown increased activity in regions like the precuneus/posterior cingulate cortex (PCC), the temporal-parietal junction (TPJ) and the dorsomedial prefrontal cortex (dmPFC) when receiving inconsistent   vs   consistent information about another person’s moral behaviour ( ;  ;  ), competence ( ;  ), traits ( ;  ;  ) and political beliefs ( ). These regions are key nodes in the ‘mentalising’ network, which is activated when thinking about the beliefs, preferences and intentions of others ( ;  ;  ;  ). 

The increased activation to inconsistent information seen in the mentalising network is reminiscent of the prediction error (PE) signal seen in reinforcement learning (RL) models. These signals compute the expectation of a future outcome (or reward) as being a function of the current expectation plus the product of the learning rate and the PE, i.e. the difference between the last expected and actual outcome ( ;  ). RL models have been shown to be biologically plausible both at the neurochemical level, where the pattern of midbrain dopamine neuron response matches that of reward PEs ( ), and at the level of whole brain anatomy ( ). This biological plausibility along with the findings outlined above have led researchers to suggest that regions in the mentalising network may be involved in calculating social PEs ( ;  ;  ). 

Several studies have investigated this possibility directly, using computational modelling to parametrically track PE from trial to trial and have found evidence of social PE tracking in the dmPFC, the anterior cingulate cortex (ACC), the TJP, the superior temporal sulcus (STS), the medial temporal gyrus (MTG), ventrolateral PFC (vlPFC) and the precuneus ( ;  ;  ;  ). A recent study by   examined the related phenomenon of self-other mergence, in which knowledge about another person’s performance reciprocally influences judgements of one’s own performance. They found a division between PEs for self-performance, represented in the anterior cingulate cortex, and PEs for other performance, represented in the dmPFC. Interestingly, individual variance in the strength of dmPFC activation also predicted how far participants’ self PEs were affected by the performance of the others. Such findings have led some researchers (e.g.  ;  ) to argue that predictive processing plays a key role in social cognition. 

To date, most studies examining social PEs have considered cases where participants learn about other individuals, but do not examine the relationship between those individuals and the self (although see   for an interesting exception). A distinct literature has examined the role of self-similarity in impression formation ( ;  ) and shown that self-similarity can lead to liking and affiliation. Numerous studies have shown that those we perceive as similar to us in terms of traits ( ), attitudes ( ) and preferences ( ) tend to be evaluated more favourably than those perceived as different. There is evidence for a ventral–dorsal gradient in the mPFC when processing the similarity of others with similar others being processed in the ventromedial prefrontal cortex (vmPFC) and dissimilar others in the dmPFC ( ;  ). 

The current study aims to test how the brain tracks and learns about other people from the self-similarity of their choices. In particular, we distinguish two possible ways in which the brain could track others: the similarity approach and the consistency approach. The similarity approach assumes that, on each trial, we consider ‘is this person like me on this trial?’ and assign high PEs to any trial where an agent makes a different choice to me. The consistency approach assumes that we model each person we encounter as an individual with a level of overall similarity to me. On each trial, we then consider ‘is this person’s choice consistent with their overall similarity to me?’ and assign high PEs to any trial where the agent behaves in a way that is inconsistent with that agent’s track record. 

To do this, we adapted RL models to investigate how the brain tracks the choices of two different agents in terms of how similar they are to the participant’s own choices. It is important to note that we are not claiming that the tracking of similarity is necessarily linked to reward-based reinforcement in a direct manner. Rather, we use RL models because they can track the accumulation of information and evidence over time. This allows us to look at how the brain represents confirming and disconfirming information about other’s similarity to ourselves. For a related approach applied to the learning of others’ traits, see  . 

Our task created a context in which participants chose which painting they prefer (an arbitrary aesthetic choice) and then learn the preferences of two agents for the same paintings (see  ). Using fMRI and computational modelling, we can identify which brain areas track agents’ preferences relative to self-preferences in a trial-by-trial manner. In each trial, our participants saw two paintings and indicated which they preferred. They then saw the preferences of two agents, a similar agent (ASim) who chose the same painting 75% of the time and a different agent (ADiff) who chose the same painting 25% of the time. Using RL models, we are able to calculate the prior probability of the agents’ choice and the PE of their actual choice separately for each trial and each agent, allowing us to localise brain regions where BOLD signal tracks the model parameters. 
  
Outline of experimental trial structure and number of trials per condition. A trial phases and timings. Each trial has four phases (self, similar, different, feedback). On every screen, three icons at the top represent the participant (blue outline in the centre) and the two agents (two photos), with one icon enlarged in a green square to show who is the ‘active player’ in this phase. In the self-phase, participants chose which of two pictures they prefer. In the ASim phase and ADiff phase, the two agents ASim and ADiff chose pictures and the participant sees the outcome. The order of these two phases was counterbalanced. Finally, in the Feedback phase, the participant sees a reminder of his/her own choice.   B. Detail of one phase  . This shows an expanded view of the two different screens within the ASim phase; the same structure was used for the Self phase and ADiff phase. Participant’s first see a ‘decision screen’ with the two pictures used on this trial. During the decision screen participants either chose their own preferred painting (Self phase) or waited to see the choice of the agent (similar and different phases). Then they see an ‘outcome screen’ which shows either the painting they chose (Self phase) or the painting the agent chose (ASim and ADiff phases). The durations of each screen are given at the bottom of the figure, and multiple times separated by a dash represent the jittering in order to effective temporal sampling resolution much finer than one TR  . C. Number of trials of each type.   This table shows the breakdown of the four possible combinations of choices made by the two agents, ASim and ADiff. Each agent could agree with the participant’s choice (Ag) or disagree (Dis). The columns show the percentage of trials, number of trials by block and total number of trials which had a particular pattern of choices. 
  
We then used RL to create signed PE models of both the similarity and consistency approaches to tracking the agent’s choices (see  ). In the similarity model, agents are tracked only in relation to the participant’s own preferences, on a single dimension of ‘distance from me’. This means that the model will tend to have positive PEs for ASim and negative PEs for ADiff (see  ). In the RL model, each signed PE then contributes to an accumulated similarity (AS) parameter, which will tend to be high for ASim (who is often similar) and low for ADiff (who is often different). To make this model clear, we term the two parameters the ‘similarity PE’ (PE_Sim) and the AS. 
  
Two possible ways that the choices of the two agents, ASim and ADiff, may be tracked in the brain  . A. Similarity approach.   The yellow/green boxes in the top row show how trials are classified as Similar or Different according to whether the agent choose the same picture as the participant or not, and the same classification is used for both agents. Green indicates that a choice is given a positive value and yellow that it has a negative value. This is reflected in the sample sequence of 20 trials, where the ‘choice similarity’ tends to be high for ASim and low for ADiff. Based on the choice similarity, the Sim_PE and AS parameters are calculated as in equations   and  .   B. Consistency approach.   Trials are classified as Consistent or Inconsistent according to whether the agent conforms to type. Both agents show high choice consistency most of the time in the sample of 20 trials shown below. Based on the choice consistency the PE_Con and AC parameters are calculated as in equations   and  . 
  
The alternative is the consistency model, which assumes that participants track agents and choices in terms of whether the agent’s choice is consistent with their past level of preference similarity to the participant. Thus, we label each agent’s choices as ‘consistent’ or ‘inconsistent’ with that agent’s past behaviour: agreeing with the participant is   consistent   for ASim but   inconsistent   for ADiff. In this model, a trial will have negative consistency PE when ASim chooses a different picture to the participant, because this is unlike ASim’s typical preference. In the same way a trial will have negative PE when ADiff chooses the same picture as the participant (unlike ADiff’s typical preference) (see  ). These PEs feed into the accumulated consistency (AC) of each agent, which will be high when that agent conforms to type (i.e. high for both ASim and ADiff most of the time) but will fall if the agent makes atypical choices. To make this model clear, we term the two parameters the ‘consistency PE’ (PE_Con) and the AC. 

Importantly, these two models predict a different pattern of brain activity in our experimental design, as ASim and ADiff’s trial-by-trial preferences can have the same sign (both consistent, according to the consistency approach) or opposite sign (as they chose different images, according to the similarity approach, see  ). It is important to note that while our study can test how well each of these models fit activation in different brain areas, we are not claiming that they are mutually exclusive competing accounts. Indeed, it is entirely plausible that some brain areas track similarity of choices directly while others track the consistency of choices. Our design allows for us to investigate the neural signature of both models, in two separate GLMs, and thus identify which brain areas (if any) are involved in each of these two ways of processing similarity relationships. 


## Methods 
  
### Design 
  
In our study, participants tracked the choices of two agents on multiple trials, in relation to their own choices. On each trial, the participant and two agents, ASim and ADiff, indicated which of two paintings they preferred. ASim chose the same painting as the participant in 75% of all trials, while ADiff only chose the same painting in 25% of trials. 


### Participants 
  
Twenty-five participants (mean age ± SD: 25.1 ± 5.7, 11 male) took part in this study, which was approved by the University College London, Institute of Cognitive Neuroscience Research Department’s Ethics Committee. All participants gave their informed consent to participate and were paid for their participation. All participants were right handed and were screened for neurological disorders. Due to technical issues, pre- and post-ratings data were lost for seven participants. Therefore, our final sample size for the ratings analysis was   n   = 18. As we did not use this ratings data for model fitting, and data on all 25 participant’s choices during the task were collected, this issue did not impact on the fMRI analysis so the full sample   n   = 25 was used for fMRI analysis. 



## Procedure 
  
### Experimental task 
  
The main task in this study was an aesthetic choice task. Participants were told that in each trial, they would see a pair of paintings (see  ) and would have to choose which painting they preferred. They were informed that other participants had previously indicated which of the paintings they preferred and that they would see the choices of two previous participants during the study. Names and faces were assigned to these ‘previous participants’, but in fact they were computer agents whose choices were determined based on the participant’s own choices. Prior to entering the scanner, participants completed a training block of the task (see  ). After the training, participants learnt the names of the agents with whom they would do the experimental task. They also rated their faces for similarity, likeability and attractiveness, using a 10-point scale in order to provide us with a manipulation check as to how well the participants learnt the similarity of the agent to themselves. Other than being asked to rate their similarity to the agent, participants were not given any information to suggest the relationship between their choices and those of the agents were important to the task. 

Each trial was divided into four phases (see  ). The first three phases were each split into two screens, a   decision screen   and an   outcome screen   (see  ). In the self-phase, participants were shown a pair of paintings on the   decision   screen and had 2.75 s to choose which they preferred using the left and right buttons on a response box. They then saw an   outcome   screen displaying their preferred painting for a jittered interval (1–3 s). In the similar phase, participants first saw a 1-s   decision   screen, which displayed the pair of paintings along with an indicator that ASim was choosing. This was followed by an   outcome   screen, which displayed the agent’s preferred painting for a jittered interval (2.75–4.75 s). In the different phase, participants again saw a   decision   screen with an indicator that ADiff was choosing, followed by a jittered   outcome   screen displaying that agent’s preferred painting. The order of the similar and different phases was pseudorandomised across trials. Finally, each trial contained a   feedback   phase in which participants again saw their own choice for an interval of 2 s. 

Participants completed four sessions of 20 trials (see   for a breakdown of trial types by block); at the end of each block, they rated the similarity, likeability and attractiveness of each agent using a 10-point scale. Using fast event-related design, i.e. varying the intervals of the outcome screen in the three choice phases and using many trials, an effective temporal sampling resolution much finer than one TR for each of these periods was achieved. The lengths of the intervals were uniformly distributed for each period, ensuring that evoked haemodynamic responses time locked to the events were sampled evenly across the time period following each choice period. 


### Model-based fMRI analysis 
  
For full details of image acquisition and fMRI data analysis, please see  . To examine whether the relationship between the participant preferences and those of the agents was coded in terms of similarity or consistency, two general linear models (GLM) were created, which include different trial types and the parameters of the two RL models. Both GLMs modelled BOLD activation during   outcome   screen for ASim and ADiff separately. Regressors of no interest modelled activity during the   self-choice outcome   screen, the   feedback   phase, the ratings periods and trials where participants failed to make a choice and the residual effects of head motion. In addition, parametric modulators linked to the   outcome   screen regressors allowed us to model the values of our RL parameters on a trial-by-trial basis. Note that we also conducted a more traditional GLM without RL parameters, the details of which can be found in  . 

In the similarity GLM, we modelled the signed similarity PE (PE_Sim) and accumulated similarity (AS) between the agent choice and the participant choice for each agent (  n  ), using the following algorithms: where 

As we did not fit the model to any response, we set the learning rate (λ) with a fixed value of 0.5 and initial AS was set to 0. The learning rate of 0.5 was chosen a priori and fixed for all participants, to indicate the carry-on effect of previous trials to the current trials. This value was chosen because it is in the middle of the LR range (0–1) and indicates a decaying memory window of about four trials. We chose this conservative approach and did not explore learning rates further to avoid double dipping the data or   post hoc   analysis. AS was set at 0 as this represented no a priori expectation of a similarity relationship between the participant and the agents. In total, there were six regressors-of-interest in our similarity GLM: outcome screens, AS values, and PE_Sim values for both ASim and ADiff. 

In the consistency GLM, we modelled the signed consistency PE (PE_Con) and AC between the agent choice and the participant choice for the two agents (  n   = ASim or ADiff), using the following algorithm. where 

Again, the learning rate (λ) was set to 0.5 and initial AC was set to 0 (see   for examples of how AS and PE varied across 20 trials). In total, there were six regressors of interest in our consistency GLM: outcome screens; AC values and PE_Con values for both ASim and ADiff. 



## Results 
  
### Behavioural results 
  
To examine whether learning about the preferences of the agents changed participants’ feelings of affiliation towards them, we collected ratings of similarity, likeability and trustworthiness at the start of the study and after every 20 trials. This meant that each participant contributed five ratings of each of the three attributes across the study. These ratings were then z-scored within participant to remove baseline differences between participants, before the next analysis. Three separate 2 (agent: similar/different) × 5 (session number: pre/S1/S2/S3/S4) repeated measures ANOVAs were carried out on the z-scored ratings of similarity, liking and trust (see  ). Due to problems with data recording, the ratings from seven participants were incomplete and were excluded from the behavioural analysis leaving a remaining sample of 18 participants. 
  
Z-scored ratings of liking similarity and trustworthiness for the similar and different agents across rating sessions. 
  
The ANOVA on similarity ratings found a significant main effect of agent,   F  (1.17) = 23.52,   P   < 0.001, η  = 0.58. Overall participants rated ASim as being more similar (  M   = 0.33,   MSE   = 0.15) to them than ADiff (  M   = −0.68,   MSE   = 0.12). There was also a significant interaction between agent and session   F  (1.17) = 5.65,   P   = 0.001, η  = 0.25. To examine this interaction further, ratings for ADiff were subtracted from the ratings of ASim for each session to create a difference score. Pairwise comparisons (Bonferroni corrected) showed that the difference score for the pre-session (  M   = −0.16,   MSE   = 0.36) significantly differed from the scores after sessions S1 (  M   = 1.49,   MSE   = 0.35),   P   < 0.05, S3 (  M   = 1.26,   MSE   = 0.29),   P   < 0.05, and S4 (  M   = 1.43,   MSE   = 0.25),   P   < 0.01. No other pairwise comparisons were significant. 

The ANOVA on liking ratings found a significant main effect of agent,   F  (1.17) = 23.8,   P   < 0.001, η  = 0.58. Overall participants rated ASim as being more likeable (  M   = 0.55,   MSE   = 0.07) than ADiff (  M   = −0.2,   MSE   = 0.12). There was no significant effect of session and no interaction between session and agent. The ANOVA on trust ratings found a significant main effect of agent,   F  (1.17) = 7.67,   P   < 0.05, η  = 0.31. Overall participants rated ASim as being more trustworthy (  M   = 0.23,   MSE   = 0.11 than ADiff (  M   = −0.24,   MSE   = 0.01). There was no significant main effect of session and no interaction between session and agent. 


### fMRI results 
  
#### Main effect of agent preference similarity 
  
Two contrasts investigated the main effect of agent identity (ASim/ADiff) on BOLD response. The regressors, which contribute to these contrasts, were identical in the similarity GLM and the consistency GLM, so the results here are the same for both. The ADiff > ASim contrast revealed that observing the choice of ADiff compared to ASim led to a greater activation in the right inferior frontal sulcus (rIFS) and in a cluster centred on the right fusiform gyrus (rFG) (  and  ). No significant activations were found in the ASim > ADiff contrast. 
  
Peak voxel coordinates in MNI space,   z  -values and cluster sizes for analyses of the outcome screen showing significant effects after cluster correction for main effect of similarity. Same shading indicates local maxima in distinct anatomical regions within the same cluster, BA indicates Brodmann area and   k   indicates the cluster size threshold for whole brain significance of   P   < 0.05 
    
A. Brain areas showing significant cluster corrected results in the ADiff > ASim contrast for the Outcome screen. B. Brain areas tracking the PE_Sim parameter (similarity PE) for the outcome screen across both agents, cluster corrected. Parameter estimates in the lower panel are averaged across the whole cluster. Error bars represent SEM. Graph border colours indicate matching circled area. Red/yellow represents positive activations and blue/green represents negative activations. 
  

#### Parametric analysis of the similarity GLM 
  
To identify brain regions, which tracked accumulated similarity (AS) across both agents, we calculated a conjunction of the RL parameters for each of the agents, that is AS  ∩ AS . This did not reveal any significant clusters in either a positive or negative direction, suggesting that no brain areas directly tracked preference similarity between agents and participant. Similarly, there were no significant clusters that tracked the positive conjunction of similarity PE for both agents, that is, PE_Sim  ∩ PE_Sim . This means that no areas showed increased activation when both agents preferences were unexpectedly similar to that of the participant. However, the negative PE_Sim conjunction analysis revealed that unexpected dissimilarity between either agent choice and participant choice correlated with activation in a number of clusters within the occipital cortex including the bilateral lateral occipital cortex (LOC) and the lingual gurus (  and  ). 
  
Peak voxel coordinates in MNI space,   z  -values and cluster sizes for analyses of the outcome screen in the similarity GLM showing significant effects after cluster correction for conjunction analyses of the AS and PE parametric modulators. Same shading indicates local maxima in distinct anatomical regions within the same cluster, BA indicates Brodmann area and   k   indicates the cluster size threshold for whole brain significance of   P   < 0.05 
  


### Parametric analysis of the consistency GLM 
  
To identify brain regions tracking the consistency of agents’ choices across both agents, we first examined the conjunction of areas tracking AC, that is AC  ∩ AC . The positive conjunction showed a significant activation in a cluster-corrected region centred on the superior medial frontal gyrus (smFG) (  and  ). This region showed greater activation as evidence for the consistency of the agents’ choice similarity to the self-increased, and lower activation during inconsistence periods. No significant activations were found in the conjunction analysis testing for areas negatively correlated with AC. 
  
Peak voxel coordinates in MNI space,   z  -values and cluster sizes for analyses of the outcome screen in the consistency GLM showing significant effects after cluster correction for conjunction analyses of the AS and PE parametric modulators. Same shading indicates local maxima in distinct anatomical regions within the same cluster, BA indicates Brodmann area and   k   indicates the cluster size threshold for whole brain significance of   P   < 0.05 
    
Brain areas showing significant cluster corrected tracking of AC and PE_Con for the Outcome screen. A. Areas significantly tracking AC in the positive ASim ∩ ADiff conjunction. B. Areas significantly tracking PE_Con in the positive ASim ∩ ADiff conjunction. C. Areas significantly tracking PE_Con in the negative ASim ∩ ADiff conjunction. Parameter estimates averaged across whole cluster. Error bars represent SEM. Graph border colours indicate matching circled area. Red/yellow represents positive activations and blue/green represents negative activations. sMFG = superior medial frontal gyrus, rCN = right caudate nucleus, rAG = right AG, rSFS = right superior frontal sulcus. 
  
The conjunction analysis testing for areas tracking PE in consistency (PE_Con  ∩ PE_Con ) identified significant cluster-corrected activations bilaterally in a dorsal region of the caudate nucleus as well as in a more ventral midbrain region of the left hemisphere (  and  ). These areas showed increased BOLD response when the agents’ choices were unexpectedly consistent with their overall preference, and decreased activation when agents’ choices were unexpectedly inconsistent. Note that while the peak activation in the more dorsal left hemisphere cluster is in fact found in the neighbouring corpus callosum, both dorsal clusters showed considerable overlap with the caudate nucleus. The conjunction analysis testing for areas tracking PE_Con in a negative direction identified significant clusters in several right hemisphere regions, namely the angular gyrus (rAG), the superior frontal sulcus (rSFS), the rSTS, the rMTG and the precuneus (  and  ). These areas showed increased BOLD response when the agents’ choices were unexpectedly inconsistent with their overall preference, and reduced activity when the agents’ choices were highly predictable. 



## Discussion 
  
Our study examined the neural basis of learning about preference similarity between self and others and its role in promoting affiliation. We created a context where participants could express a preference for a painting and learn about the preferences of two agents for the same paintings. Our behavioural data show that similar preferences lead to higher ratings of liking, trustworthiness and similarity, indicating that participants tracked the agents’ preferences in relation to their own preferences. 

Our introduction outlined two possible, non-mutually exclusive, ways in which preference similarity might be tracked in the brain: either by a general mechanism, which tracks an agent’s choice in relation to one’s own, i.e. how similar or dissimilar they are from the self, or via a model of consistency, which tracks agent’s choices in terms of their consistency to that agent’s previous choice, i.e. how   consistently   similar or dissimilar they are from the self. To examine the evidence for each of these two mechanisms, we created two RL models, which tracked the agents’ choices based on similarity and consistency, respectively. Our results from the similarity model indicated that regions of the visual cortex negatively tracked similarity PE (PE_Sim). Results from the consistency model showed a number of brain areas tracking different variables associated with the consistency model; the dorsomedial pre-frontal cortex (dmPFC) tracking AC, and the caudate nucleus, AG and precuneus tracked consistency PE (PE_Con). The caudate is involved in value updating ( ;  ), while the AG and precuneus are associated with social cognition ( ;  ). Below, we elaborate on the results of the AC conjunction before moving on to discuss the findings on PE_Con and PE_Sim. 

### dmPFC tracks AC 
  
The AC parameter represents a trial-by-trial estimate of the probability that a person makes choices in line with his previous choices, this is, that the similar agent (ASim) should choose the same painting as the participant while the different agent (ADiff) should choose differently. The only area we found tracking AC was a cluster in the bilateral superior medial frontal gyrus (smFG) corresponding to the anterior region of the dmPFC. The dmPFC is known to be a key area for the processing of information about both self and other ( ;  ;  ). See   for a more detailed survey of previous results. 

The dmPFC’s involvement in coding prior knowledge of other people is supported by previous research suggesting that the dmPFC encodes reputational priors of one’s partners during economic games ( ;  ). Our results build on these findings by suggesting that dmPFC PEs track the   consistency   of the agent’s similarity to the self rather than simply tracking preference similarity. 


### Consistency PEs are tracked by regions involved in reward and social cognition 
  
PE_Con reflects the difference between the agent’s choice and the participant’s expectation of what choice the agent will make. For example, the model assigns a positive update signal when ADiff picked the painting not chosen by the participant, and a negative signal when ADiff picked the same painting (see  ). Areas that tracked PE_Con revealed two distinct patterns of activation. Clusters in the bilateral caudate nucleus ( ) showed increased activity when the agents chose consistently with their type. Meanwhile, clusters in regions associated with social cognition including the superior temporal sulcus (STS), the AG, precuneus and superior frontal sulcus (SFS;  ) showed increased activations when the agent’s choice was inconsistent with their type. Overall, this pattern shows that PE tracking in these regions is not a ‘generic’ signal of how similar a person is to me, but rather reflects how much each person’s choice conforms to their typical pattern of similarity to me. 

The caudate nucleus, along with other parts of the striatum, has been heavily implicated in the generation of PEs during RL of rewards for self ( ;  ;  ) and others ( ;  ;  ). Previous studies have shown that the caudate nucleus is also involved in signalling PEs when learning the characteristics of others.   found that the caudate nucleus activity tracked PEs regarding the trustworthiness of other during an economic game. Subsequent studies have found similar results for trustworthiness ( ;  ;  ), generosity ( ), reliability in advice giving ( ) and general behavioural traits ( ). Our findings add to this literature by showing that caudate nucleus activity also tracks PE when learning about the similarity of others’ preferences to one’s own. 

The regions showing greater activations when PE_Con was negative, i.e. when the agents’ choice was inconsistent with their typical choices, are key nodes of the mentalising network involved in processing information about self and others ( ;  ;  ;  ). These areas have been implicated in the formation of impressions about other peoples’ traits ( ;  ;  ;  ;  ), beliefs ( ) and abilities ( ;  ). Of particular note are two studies which directly modelled PEs for learning about the traits of other.   found that the precuneus and STS tracked PEs for other generosity during an economic game, while   found that only the precuneus showed greater tracking of PEs in a social verses non-social setting. The current study shows that these regions also track PEs regarding the similarity relationship between self and others, underlining the role of PEs in social learning ( ). 

It is also notable that while previous studies on social impression formation have tended to show bilateral activations of the mentalising network, in the current studies, activity was limited to the right hemisphere. This is consistent with previous research demonstrating right lateralisation for tasks involving self and other differentiation ( ;  ;  ;  ). 


### Similarity-related responses in regions involved in visual attention 
  
In addition to modelling the RL parameters, we also directly contrasted the outcome screen where participants see the choices of ASim with the outcome screen for ADiff. This contrast shows greater activation for ADiff in two clusters: one centred on the rIFS and the other on the rFG. The IFS has been implicated in attentional processing and in particular in the control of attentional shifts by both internal goals and by salient external stimuli ( ,  ;  ;  ;  ), while the FG is known to play a key role in the visual perception of faces ( ;  ;  ). Interestingly, a previous study found greater FG activation when participant observed faces of individuals judged to have different traits to themselves ( ). These findings were also consistent with our conjunction analysis of regions that showed a negative relationship to the value of PE_Sim. This analysis revealed that when an agent made an unexpectedly dissimilar choice to that of the participant, it led to increased activation across a series of visual areas including regions in the bilateral LOC and in the left FG. 

The activation of these areas suggests that participants may have found the choices of ADiff to be more attention-grabbing than those of ASim in a comparable way to studies that have demonstrated an attentional bias towards untrustworthy as opposed to trustworthy agents ( ;  ;  ). 


### Comparison with non-RL GLM 
  
In addition to running our main RL analysis, we also conducted a more traditional GLM, which divided our trails using a 2 × 2 design with confederate/agent identity (similar   vs   different) as one factor and choice decision (agree   vs   disagree) as the other factor, the interaction between them (i.e. similar agree and different disagree   vs   similar disagree and different agree) was equivalent to our consistency model. This allowed us to compare the results of our RL model to more traditional non-parametric approaches (see   for full details and results). When comparing the results of the RL models and the conventional GLM the activations for the choice main effects and the consistency (interaction effects) were largely similar with the disagree > agree contrast showing activations equivalent to the clusters shown for areas that negatively tracked similarity PEs, the consistent > inconsistent contrast showing activations for two of the three clusters we identified that positively tracked consistency PE and the results for the inconsistent > consistent contrast showing results largely consistent with areas negatively tracking consistency PE. 

Despite these similarities, our model has two advantages over the non-RL GLM. First, it is more sensitive to the temporal order of observations, as it takes history into account. For example, it treats differently two consecutive inconsistencies as the first one is more surprising than the second one, while the standard GLM treats them in the same way. This makes our approach more sensitive, more powerful (statistically) and more relevant to our research question. The second advantage is that we can estimate the hidden variables of AC/similarity which the standard GLM cannot. This allowed our model to identify the dMPFC area, which is involved in the tracking of AC. 


### Limitations 
  
One key limitation of the current study is that our task did not allow us to collect trial-by-trial behavioural data showing what participants had learnt about the agents. This is because we wanted participants to learn implicitly, rather than making explicit predictions of the agent’s choice on each trial. Because of this, we approximated a learning rate (0.5) and used it in our RL models to track changes in preference tracking according to the actual choices made by the agents. This raises the possibility that there may only be a weak fit between the learning rate used in our model and the actual learning rate of our participants. However, our main predictions related to the direction of the tracked PEs and accumulated preferences, and not with the specific magnitude of these variables, are less likely to be affected by our approximation. This is in line with a recent theoretical paper ( ) that demonstrated that model-based fMRI results are, under some conditions, insensitive to changes in individual learning rates. While it is possible that our approximation may lead to lower power at detecting brain responses to PEs, we feel that the main hypothesis concerning the direction of the effects (similarity approach   vs   consistency approach) is supported by our analysis. 



## Conclusions 
  
In this study, we combined computational modelling and fMRI to investigate the neural processes that underlie learning about the similarity of other people’s preferences to one’s own. We found that more regions of the brain encode information about the similarity of others’ choices in a consistency driven manner than encode that information purely based on each particular preference’s similarity to one’s own. This was particularly the case for the accumulated information about the other’s similarity with no areas showing sensitivity to purely accumulated similarity while a region of the dmPFC showed significant tracking of AC. 

These findings suggest that higher level neural representations of similarity to the self are coded in a person-specific manner, which reflects how consistent are that person’s preference related to the self, i.e. do we usually agree or disagree in our preferences. As such our study highlights the role of context-dependent predictive processing in the learning of preference similarity between self and others and, by extension, in the formation of social impressions more generally. Further research in this area could build on our results by examining whether the neural correlates of similarity learning are modulated by having pre-existing cues about how similar that person is to oneself. In addition, it is possible that this consistency approach also applies to learning about other domains including people’s traits, attitudes and competence. 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-21'>
<h2>21. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31729396/' target='_blank'>31729396</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Neural representations of honesty predict future trust behavior</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Nat Commun</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1038/s41467-019-13261-8</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6858375/' target='_blank'>6858375</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social processing in healthy adults (n=31; mean age 24.3, range within 18–60) that implements social-interaction tasks (take-advice game and trust game) during scanning to probe trust/honesty and social evaluation. Whole-brain analyses are reported throughout (whole-brain searchlight MVPA, univariate whole-brain contrasts with voxel-level p<0.001 and cluster FWE correction, PPI connectivity across the brain). Although a post-hoc OFC ROI is used for an additional analysis, primary results are whole-brain and not ROI-only. The sample is healthy and not clinical, and the article is an original empirical fMRI study (not a review/meta-analysis). Thus the study meets all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Theoretical accounts propose honesty as a central determinant of trustworthiness impressions and trusting behavior. However, behavioral and neural evidence on the relationships between honesty and trust is missing. Here, combining a novel paradigm that successfully induces trustworthiness impressions with functional MRI and multivariate analyses, we demonstrate that honesty-based trustworthiness is represented in the posterior cingulate cortex, dorsolateral prefrontal cortex and intraparietal sulcus. Crucially, brain signals in these regions predict individual trust in a subsequent social interaction with the same partner. Honesty recruited the ventromedial prefrontal cortex (VMPFC), and stronger functional connectivity between the VMPFC and temporoparietal junction during honesty encoding was associated with higher trust in the subsequent interaction. These results suggest that honesty signals in the VMPFC are integrated into trustworthiness beliefs to inform present and future social behaviors. These findings improve our understanding of the neural representations of an individual’s social character that guide behaviors during interpersonal interactions. 
  
We tend to be more trusting of people who we know to be honest. Here, the authors show using fMRI that honesty-based trustworthiness is represented in the posterior cingulate cortex, dorsolateral prefrontal cortex and intraparietal sulcus, and predicts subsequent trust decisions. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (64720 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Trust is the essential component of social life enabling successful cooperation and fostering individuals’ well-being. The factors that induce trust in others remain, however, still largely unexplored. To date, at least two accounts have been proposed to explain an individual’s trust. 

One account proposes that interacting agents focus on maximizing their personal payoffs during social exchanges . This account assumes that optimally rational agents trust another as long as they will be better off with trusting than distrusting . Empirical investigations implementing economic games such as the trust game (TG) confirm that people are willing to trust as long as trusting leads to monetary rewards . However, trust levels drop significantly when external incentives lack or when trust leads to monetary losses . 

An alternative account argues that individuals take into account the social character and attitudes of the interacting partner when trusting. In this regard, individuals seek to form beliefs about the other’s social character by focusing on whether the other’s behavior fosters fairness, equality, and cooperation . Honesty, that is, the quality of being reliable and the tendency to share truthful information, has been proposed as a central determinant of trustworthiness impressions promoting prosocial behaviors . For instance, altruistic behavior, unconditional kindness, and reciprocity have been observed in response to others’ honesty . However, whether honesty also encourages others to trust is yet unexplored. 

These two accounts make different predictions on the neural mechanisms underlying trust. When individuals focus on the trade-off between advantageous and disadvantageous consequences following a trust decision, brain regions signaling actual, or hypothetical decision outcomes (such as the ventral striatum and dorsal anterior insula) should be recruited in trusting interactions . On the contrary, if trust draws on the social character of the other, brain regions associated with social evaluations (such as the ventromedial prefrontal cortex, VMPFC, and dorsolateral prefrontal cortex, DLPFC), and inferences on the other’s intentions (e.g., the posterior temporoparietal junction, pTPJ) should be engaged during trusting behaviors . However, to date, evidence on the brain regions representing the honest character of another is still missing. 

In this study, we investigated for the first time whether information about the other’s honest character evokes trustworthiness impressions that predict future trust in the other. Importantly, a reputation as a trustworthy person has been suggested to impact information processing during social learning. In particular, although individuals prefer to interact with, and learn from, trustworthy partners , beliefs about the other’s trustworthiness bias how information from the trustworthy other is processed and learnt . An explanatory hypothesis for such bias posits that beliefs about the other’s trustworthiness modulate evaluations of information from trustworthy others. For instance, previous work has linked biased beliefs about others’ reciprocity to differences in how information is encoded in the orbitofrontal cortex (OFC) , a region of pivotal importance in value representation . However, it is still unknown whether a reputation as an honest person modulates information encoding and whether the OFC plays a role in such biased information processing. 

Here, we developed a trust-inducing paradigm (take advice game, TAG), which enables us to isolate social evaluation signals related to the other person’s trustworthiness (learnt through her honest and dishonest behavior) from nonsocial value signals related to one’s task performance (neural responses to winnings and losses). Being able to disentangle these two types of information was of pivotal importance to the two main objectives of this study. On the one hand, it allowed us to isolate brain signals related to representations of the other’s honest character. On the other, it enabled us to investigate any modulatory effects of the other’s honest character on information processing. In the TAG, participants, in the role of advisee, had to learn the trustworthiness of advisers from feedback about their honest or dishonest advice. After the TAG, participants, now in the role of investor, played a one-shot TG with the advisers who advised them previously. 

Using multivariate voxel pattern analysis (MVPA) in combination with functional magnetic resonance imaging (fMRI), we examined the relationships between honesty, dishonesty, and trust on the behavioral and neural level. On the behavioral level, honest behavior increases trust irrespective of proximal benefits associated with the act of trust. On the neural level, the honesty-based trustworthiness of the partner is represented in the posterior cingulate cortex (PCC), bilateral DLPFC, and left intraparietal sulcus (IPS). Importantly, neural signal in these brain regions predicts an individual’s willingness to trust the partner in a subsequent interaction. Further, enhanced integration of honesty into trustworthiness beliefs via stronger VMPFC-pTPJ connectivity is associated with higher trust levels later on. Finally, the partner’s honest character modulates neural responses to positive and negative outcomes in the OFC. 


## Results 
  
### Paradigms 
  
In the TAG (Fig.   and Supplementary Fig.  ), participants in the role of advisee had to rely on the advice of different advisers to choose the highest of two cards. As participants did not have any information about the cards’ numbers, they depended on the honesty of the advisers for their decisions. The advisers, on the other hand, could see only one of the two cards, that is, they knew more than the advisees, but did not have complete information about the cards. Hence, their advice was not about the winning card participants should pick, but rather additional information about the number of one of the two cards. In each trial, participants were paired with a different adviser (adviser phase). After the adviser sent his advice (advice phase), the advisee decided which card she wanted to pick (decision phase). Finally, the cards were disclosed to the advisee (feedback phase), who could see whether the adviser had been honest and whether she won or lost in that trial. Participants could win/lose €1 in each trial by choosing the card with the higher/lower number. After the TAG, participants in the role of investor played a one-shot TG with each of the advisers now in the role of trustee (Fig.  ). Investors were paired with each trustee and received an initial endowment of 10 monetary units (MUs) that they could share with the partner. Investors were told that the shared amount would be tripled by the experimenter and passed on to the trustee who, in turn, could decide to share back any amount of it.   
Paradigms.   a   Schematic representation of the take advice game (TAG). Advisers were given information about one of the two cards and could communicate this information to the advisee. Participants, in the role of advisee, made a decision based on the information received (decision phase). In the feedback phase, advisees saw the actual numbers on the cards, which informed them about the adviser’s honest behavior (honest vs. dishonest), and a green or red circle, which informed them whether they won or lost, respectively.   b   After the TAG, participants in the role of investor played a one-shot trust game (TG) with the advisers now in the role of trustee. Investors received a monetary endowment and decided whether they wanted to entrust some of this amount with the trustees. Investors were told that the shared amount was tripled by the experimenter and passed on to the trustee, who could decide to share back any portion of the tripled amount. See also Supplementary Fig.  
  


### Link between honesty and trusting behavior 
  
First, we tested whether honesty is associated with higher trust levels across contexts and regardless of proximal gains. In the TAG, individuals should be more willing to take the advice of honest advisers and distrust the advice of dishonest advisers. Our results demonstrate that participants took on average more advice from honest than dishonest others (  t   = 3.68;   p   < 0.001; 95% confidence interval (CI) = [0.03, 0.10]; Cohen’s   d   = 0.7; Fig.  ). Importantly, participants grounded their decisions to take an advice in the trustworthy character of the adviser (i.e., whether the adviser was honest or dishonest;   β     =   0.38; standard error (SE) = 0.12; 95% CI = [0.14, 0.62];   p     =   0.007). On the contrary, monetary winnings and losses did not impact participants’ decisions to take an adviser’s advice (  β     =   −0.001; SE = 0.07; 95% CI = [−0.14, 0.14];   p     =   0.980; Table  ). This suggests that our participants trusted an adviser based on the adviser’s trustworthy behavior and irrespective of their proximal benefits. Indeed, the majority of our participants (  M   = 88.2%) explicitly reported in an exit questionnaire (see Methods) that their decisions were based on the trustworthiness and advice of the advisers. Importantly, participants applied such trustworthiness-based strategy even though they were aware that it was not successful to gain more benefits (  χ   = 13.68,   p     =   0.0002).   
Behavioral results.   a   Trusting behavior in the take advice game over runs (left) and on average (right) toward honest and dishonest advisers. On average, participants took significantly more advice from the honest than the dishonest adviser (  t   test). Data points on the left were interpolated for visualization purposes and shadowed areas represent standard errors. White lines in the box-plots on the right represent average advice-taking behavior across participants. Each black dot represents one participant.   b   Amount of money entrusted in the trust game with honest (left) and dishonest (right) others correlated with participants’ willingness to take advice from the advisers (Spearman’s correlations). Each dot represents one participant. ***  P   < 0.001 
    
Mixed-effects logistic regression analysis of advice-taking behavior 
  
 β   coefficients (standard errors) from the generalized mixed-effects logistic regression model with maximal random-effects structure predicting advice-taking behavior (1 = advice taken; 0 = advice not taken).   P   values were based on a likelihood ratio test 

 SE   standard error,   CI   confidence interval 

*  p   < 0.01; **  p   < 0.001 
  

Moreover, although trust in the other’s advice was comparable for both honest and dishonest advisers in the very first trials of the TAG, participants quickly adjusted their behavior to the other’s honesty over the course of the social interaction (Fig.  ). Indeed, participants’ advice-taking behaviors toward the two advisers differed increasingly over time (  β   = 0.01; SE = 0.006; 95% CI = [0.0001, 0.024];   p     =   0.048), especially due to a significant, linear decrease in trust in the advice of dishonest advisers (  β   = −0.02; SE = 0.007; 95% CI = [−0.028, −0.002];   p     =   0.021). On the contrary, advice-taking behavior toward honest advisers did not significantly change over time (  β   = −0.005; SE = 0.006; 95% CI = [−0.016, 0.007];   p     =   0.410). 

Second, we investigated whether these specific effects of the other’s trustworthiness on advice-taking behavior in the TAG generalize to a different context and measure of trust (i.e., the TG). Our results confirm this, showing that advice-taking behavior in the TAG correlated with subsequent, economic trust decisions in the TG on average (  ρ     =   0.39;   p   = 0.031), and separately for both honest (  ρ   = 0.41;   p   = 0.021) and dishonest advisers (  ρ     =   −0.37;   p   = 0.040). That is, the more likely participants were to trust the advice of an adviser, the more willing they were to entrust that adviser with money in a subsequent interaction (Fig.  ). As expected, the amount of money shared with the advisers in the TG did not significantly correlate with participants’ monetary winnings in the TAG either on average (  ρ     =   0.17;   p   = 0.350) or separately for the two advisers (honest adviser:   ρ     =   0.30;   p   = 0.106; dishonest adviser:   ρ     =   0.01;   p   = 0.978). These results confirm that economic trust decisions in the TG did not represent a form of repayment for the benefits participants obtained from the adviser’s advice in the previous interaction, but rather reflected participants’ willingness to trust the adviser’s honesty in advice giving. 

Finally, we checked the proportion of positive and negative feedback received by our participants. Participants received on average the same amount of positive and negative feedback (mean difference = 0.0013 ± SD   =   0.07;   t     =   0.11;   p   = 0.916), despite more positive feedback when interacting with honest than dishonest advisers (honest advisers:   M   = 63.5% ± SD   =   7.4; dishonest advisers:   M   = 56.7% ± SD   =   5.0;   t     =   4.09;   p   < 0.001). 


### Neural representations of trustworthiness 
  
Next, we examined the neural patterns of the advisers’ trustworthy character inferred from their honest behavior and value information related to participants’ performance. In doing so, we investigated whether these neural patterns capitalize on similar brain regions informative of individual trust. Our task design elegantly allows this, since in the feedback phase, participants received information about both the other’s trustworthiness (honest/dishonest behavior) and their own task performance (winnings/losses). Hence, by applying a whole-brain searchlight MVPA to neural activations during the feedback phase with a leave-one-run-out cross-validation (LOROCV) procedure (Fig.  ), we could separately decode trustworthiness and value information to identify brain regions belonging to a trustworthiness decoding network and value decoding network, respectively. To this end, a support vector machine (SVM) was trained on   β   parameters estimated using two general linear models (GLMs) that coded trustworthiness information (GLM1) and value information (GLM2) in the feedback phase (see Methods).   
Decoding honesty and predicting trust. In two MVPAs applied to the feedback phase of the TAG (  a  ), a support vector machine (SVM) was trained to decode honest and dishonest advice (GLM1) to determine the trustworthiness decoding network (upper), and to decode winnings and losses (GLM2) to determine the value decoding network (lower). The trustworthiness decoding network (  b  ) included brain regions such as the PCC, DLPFC, and IPS, and could successfully distinguish neural signatures of honesty and dishonesty in out-of-sample individuals (  c  ). The value decoding network (  d  ) included the striatum and ACC and could successfully distinguish neural signatures of winnings and losses in out-of-sample individuals (  e  ). Finally, a multivariate prediction analysis with support vector regression (SVR) showed that the neural patterns of the trustworthiness decoding network successfully predicted individual economic trust decisions in the TG, thereby showing across-context generalizability (  f  ). Both out-of-sample classification and prediction analyses were based on a leave-one-subject-out cross-validation procedure and their significance tested using a permutation test with 10,000 permutations. Each dot represents one participant. See also Supplementary Fig.   and Supplementary Table  . MVPA, multivariate voxel pattern analysis; TAG, take advice game; PCC, posterior cingulate cortex; IPS, intraparietal sulcus; DLPFC, dorsolateral prefrontal cortex; ACC, anterior cingulate cortex; TG, trust game. Heatmap represents   t   values 
  

The trustworthiness decoding network revealed clusters with classification accuracy above chance in the PCC, right and left DLPFC, and left IPS (cluster-level, family-wise error corrected, FWEc, <0.05; Fig.   and Supplementary Table  ). Signal in these brain regions was able to classify the neural signatures of honesty and dishonesty of out-of-sample individuals with 68% accuracy (sensitivity: 68%; specificity: 68%;   p   < 0.0001, based on a nonparametric test of 10,000 permutations; Fig.  ). On the contrary, the value decoding network consisted mainly of regions in the medial PFC extending from the anterior cingulate cortex (ACC) to the striatum (voxel-level FWE <0.05; Fig.   and Supplementary Table  ). Signal in these brain regions was able to classify the neural signatures of positive and negative outcomes of out-of-sample individuals with 82% accuracy (sensitivity: 87%; specificity: 77%;   p   < 0.0002; Fig.  ). Hence, these analyses indicate a specific neural network representing the other’s social character (i.e., trustworthiness) that could be separated from neural signal representing value information. To note, classification accuracy of value information was much better than classification accuracy of social character information. These results concur with previous findings  and may hinge on the nature of social concepts, which are distributed neural representations that might be difficult to fully capture using an anatomical-based searchlight approach. 

Finally, we set out to characterize the peculiar functional associations of the trustworthiness decoding network. We first ran GLM analyses to control for possible confounds of the observed neural patterns. In particular, we computed another GLM1 adding parametric modulators to the feedback phase for risk (as mean-squared deviation from the expected outcome given the adviser’s advice) and congruency (as deviance of the adviser’s advice from the actual card number on the advised card). These analyses revealed that our results hold also after controlling for these potential confounding factors (Supplementary Fig.  ). 

Second, using meta-analytic functional decoding (neurosynth.org) , we quantitatively evaluated the representational similarity of the trustworthiness decoding network with neural activation patterns associated with specific psychological components. In particular, we compared the neural signatures of trustworthiness in our study against reverse inference meta-analytic neural patterns of neural images of previous studies stored in the Neurosynth database and associated with particular psychological terms. For this analysis, we chose twelve terms associated with the social and nonsocial domains, such as social cognition, theory of mind, rewards, congruency and risk (Supplementary Fig.  ). Results demonstrate that the trustworthiness decoding network was preferentially associated with psychological terms related to mentalizing and social cognition (Supplementary Fig.  ), validating the ability of our task in singling out neural patterns that likely underlie the formation of trustworthiness beliefs about the advisers. Next, we set up to test this peculiar functional role of the trustworthiness decoding network in representing the trustworthy character of others. 


### Neural representations of trustworthiness predict trust 
  
A central feature of the neural representation of a character trait, such as trustworthiness, is its ability to inform decisions across contexts . Thus, neural patterns decoding the other’s trustworthiness (i.e., within the trustworthiness decoding network, but not within the value decoding network) should be able to predict individual trust decisions in the TG. To test this, a multivariate prediction analysis with a LOSOCV procedure was performed. Prediction significance was tested against a random distribution of 10,000 permutations. Results demonstrate that the trustworthiness decoding network significantly predicted the amount of money entrusted in the TG by out-of-sample individuals (standardized mean-squared error, smse, = 0.80;   p   < 0.007; Fig.   and Supplementary Fig.  ). On the contrary, the predictive model using the neural signal of the value decoding network did not yield a significant prediction (smse = 1.06;   p     =   0.84; Supplementary Fig.  ). By showing that neural patterns decoding trustworthiness information about others predict an individual’s willingness to trust in a different social context, these findings indicate a peculiar functional role of those trustworthiness-decoding brain regions in representing behaviorally relevant information about another person’s social character. 


### Stronger integration of honesty signals correlates with higher trust 
  
MVPA identified neural patterns of brain signal entailing information about another person’s trustworthiness that were informative of an individual’s trusting behavior and were different from neural patterns related to value information. To further characterize brain regions more strongly recruited by honesty and dishonesty, and to test whether and how honesty modulates neural responses to value information, whole-brain univariate analyses were performed on the brain signal during the feedback phase. 

Contrast analyses between honesty and dishonesty revealed that dishonesty more strongly activated bilateral DLPFC, left IPS and IPL (FWEc <0.05; Fig.   and Supplementary Table  ), while the VMPFC and ACC were significantly more engaged by honesty (FWEc <0.05; Fig.   and Supplementary Table  ). These results indicate a stronger reliance of dishonesty on brain regions within the trustworthiness decoding network, suggesting that dishonesty likely requires recruitment of brain regions representing the other’s character to constantly optimize one’s beliefs about the other. On the contrary, honesty more strongly relied on medial prefrontal areas associated with evaluations of positive qualities of others and self.   
Honesty vs. Dishonesty. Univariate contrasts revealed that brain areas within the trustworthiness decoding network (i.e., IPL and DLPFC) were more engaged by dishonesty than honesty (  a  ), whereas honesty more strongly recruited the VMPFC (  b  ). Error bars indicate standard errors across participants. Each dot represents one participant. See also Supplementary Table  . IPL, inferior parietal lobule; DLPFC, dorsolateral prefrontal cortex; VMPFC, ventromedial prefrontal cortex; a.u., arbitary units. Heatmap represents   t   values 
  

The definition of two separate GLMs (i.e., GLM1 and GLM2) was necessary to estimate separate   β   images to train the machine learning algorithms in our previous multivariate classification and regression analyses. However, this leaves the question unanswered as to whether the observed neural signatures for honesty and dishonesty are specific to social information processing or are confounded by neural signatures of nonsocial value information processing. We thus tested the specificity of our findings by comparing the univariate results yielded by the two separate GLMs with results of a single parametric GLM, including only one feedback regressor and two categorical, parametric modulators (one coding for value information and one for the adviser’s trustworthiness; see Methods). Notably, this single parametric GLM allowed us to control for spurious signal by orthogonalizing the two parametric modulators. As can been seen in Supplementary Fig.  , our results hold also with this GLM definition, suggesting that the observed neural signatures of trustworthiness are specific to social information processing. 

Next, as the VMPFC has previously been shown to be functionally connected with brain regions associated with social cognition during socially relevant computations , we reasoned that honesty signals in the VMPFC may be integrated into beliefs about the other’s social character via functional connectivity with brain regions associated with social cognition. To define these potential pathways, a task-dependent functional connectivity analysis was implemented using the VMPFC as seed region. This functional connectivity analysis shows that the VMPFC was more strongly coupled to the left pTPJ (−40, −50, 30,   x  ,   y  ,   z  ; FWEsvc <0.05; Fig.  ) during honesty encoding than dishonesty encoding. We then reasoned that if the information flow between the VMPFC and left pTPJ during the feedback phase were specifically associated with the formation of trustworthiness beliefs about another person, the strength of this connectivity should be related to subsequent trust decisions, but not to individual monetary winnings. Indeed, functional connectivity between the VMPFC and left pTPJ during honesty and dishonesty encoding in the TAG significantly correlated with the amount of money entrusted in the TG to honest (  ρ     =   0.54;   p   < 0.002) and dishonest (  ρ     =   0.48;   p   = 0.006) advisers (Fig.  ). On the contrary, no significant correlations were found between individual winnings and the VMPFC-pTPJ connectivity for either honest (  ρ     =   0.29;   p   = 0.111) or dishonest (  ρ     =   0.11;   p   = 0.542) advisers (Fig.  ). These results suggest that functional connectivity between the VMPFC and left pTPJ likely reflects integration of honesty information into knowledge about the other’s social character. Specifically, stronger integration of honesty signal from the VMPFC into the pTPJ led to higher trust in the adviser during a subsequent interaction, reflecting our behavioral findings that the advisers were trusted more later on the more participants believed them to be honest.   
Task-based functional connectivity analysis. Task-based functional connectivity between the VMPFC and left pTPJ was stronger for honesty than dishonesty (  a  ). Critically, this functional connectivity correlated with an individual’s willingness to trust in the TG (  b  ), but not with one’s payoffs in the TAG (  c  ) (Spearman’s correlations). Blue dots on correlation plots on the left represent behaviors toward honest advisers, orange dots on correlation plots on the right represent behaviors toward dishonest advisers. Each dot represents one participant. VMPFC, ventromedial prefrontal cortex; pTPJ, posterior temporo-parietal junction; PPI, psychophysiological interaction; a.u., arbitary units. Heatmap represents   t   values 
  


### Honesty biases value information processing 
  
We then turned to test whether and how these specific activation patterns of honesty and dishonesty modulate brain responses to value information during the feedback phase. Previous behavioral studies have suggested that positive qualities of others bias information processing . Such a bias may hinge on trait-dependent differences in neural responses to novel information. We tested this hypothesis by looking at how honesty and dishonesty modulate neural responses to positive and negative outcomes (i.e., GLM3, see Methods). 

We first examined the neural responses to positive and negative outcomes during interactions with honest and dishonest advisers separately. Positive outcomes during both interactions with honest and dishonest advisers elicited similar activations in the striatum, and for honest advisers, these activations extended to the OFC (Supplementary Table  ). Similarly, negative outcomes engaged the middle cingulate cortex and inferior frontal gyrus for both honest and dishonest advisers (Supplementary Table  ). Next, we investigated the modulatory effects of honesty and dishonesty on positive and negative outcomes. This analysis revealed that brain regions encoding positive and negative outcomes were differently modulated by the honest character of the advisers. In particular, neural signal in the parietal cortex was modulated by dishonesty during both positive (right IPL; FWEc <0.05; Fig.  ) and negative (left IPS; FWEc <0.05; Fig.  ) outcomes (Supplementary Table  ). On the contrary, modulation of neural responses to outcomes by honesty was found only in the OFC during positive outcomes (FWEc <0.05; Fig.  ). These results indicate an asymmetry in the neural responses to positive and negative outcomes for honesty.   
Modulation of neural responses to value information. Whole-brain contrast analyses from GLM3 on the feedback phase yielded significant activations in the parietal cortex for dishonesty during both positive (  a  ) and negative outcomes (  b  ). Honesty, on the contrary, modulated only positive outcomes in the OFC (  c  ). An ROI analysis (  d  ) indicated higher activity in the OFC in response to positive outcomes when interacting with honest advisers (  t   test). Error bars indicate standard errors across participants. Each dot represents one participant. See also Supplementary Tables  – . ***  P   < 0.001. ROI, region of interest; IPL, inferior parietal lobule; IPS, intraparietal sulcus; OFC, orbitofrontal cortex; a.u., arbitrary units. Heatmap represents   t   values 
  

Using an independent region of interest (ROI) in the OFC, we more closely examined in a post-hoc ROI analysis this asymmetric modulation of positive outcomes by honesty (Fig.  ). Activity in the OFC was significantly higher in response to positive outcomes when interacting with honest advisers as opposed to dishonest advisers (honesty:   M   = −0.08; SD = 0.46; dishonesty:   M   = −0.44; SD = 0.35;   t   = 4.72;   p   < 0.0001, CI = [0.21, 0.52]; Cohen’s   d   = 0.85), while OFC activity during negative outcomes was comparable for the two advisers (honesty:   M   = −0.45; SD = 0.71; dishonesty:   M   = −0.57;   SD   = 0.65;   t   = 1.16;   p   = 0.257, CI = [−0.10, 0.36]; Cohen’s   d     =   0.21). This asymmetry in the neural responses to positive outcomes in the OFC suggests that value information processing may be biased during interactions with honest individuals. 



## Discussion 
  
Understanding others is pivotal for successful cooperation. In particular, other people’s character may function as a proxy for their likely behavior in a future encounter. Thus, trustworthy partners are likely to be trusted in the future, while untrustworthy others are likely to be avoided. In this study, we showed that the honest character of an adviser makes people more likely to accept the adviser’s advice and more willing to trust the adviser in a subsequent interaction. Moreover, neural signatures of the partner’s trustworthiness in the DLPFC, IPS, and PCC predicted individual willingness to trust the partner later on, and stronger integration of an honesty signal from the VMPFC into the pTPJ correlated with higher future trust in the partner. 

When no prior information about how a partner will behave is provided, individuals try to gather evidence about the partner’s social character to inform their decisions about what to do when interacting with that partner. Over the course of multiple interactions, information about the partner’s current behavior lays the groundwork for the formation of beliefs about the other’s reputation . Consistently with previous models of trust , being reliable and telling the truth contributes to an honest reputation that made participants more likely to accept advice. On the contrary, when participants realized that their initial trust in the partner’s advice was misplaced, they increasingly discounted the advice of dishonest advisers. Interestingly, even though the adviser’s advice was not associated with the best option in the game and did not bring higher benefits to the participants, participants repaid the advisers for their honesty in advice giving during a future trusting interaction. 

As there were no incentives for the advisers to help the advisees (except goodwill or a good reputation) and the advisees did not commit to reciprocate, the dynamics in play in our study resemble real-life scenarios where individuals need to interact with each other without requirements or guarantees from the interacting partner. For instance, trusting someone to give good advice or keep a secret is an act of trust triggered by impressions of the partner’s trustworthiness without the requirement of an initial generous act by the partner . In these contexts, individuals likely assume that the other person would comply with the shared social norms, which represent a cluster of expectations an individual can use to make good-enough estimations of another person's behavior . Over the course of multiple interactions, individuals need to quickly infer the trustworthiness of the other person on the basis of what they have learned from their actual behavior and might eventually consider adopting better behavioral strategies for current and future encounters with that person . 

Thus, trusting someone else in a social interaction requires the ability to form a belief about the other’s character (i.e., who the other as a person is) and tailor one’s behavior to the other’s actions and intentions. In our study, we observed that the partner’s trustworthiness (inferred from her honest or dishonest behavior) was decoded in four brain regions (i.e., the PCC, left IPS, and bilateral DLPFC), which were able to successfully classify neural responses to honesty and dishonesty in out-of-sample individuals. In particular, recruitment of the PCC, a central hub of the mentalizing brain system , is likely related to cognitive processes associated with trait judgments , while the IPS, in line with its role in processing expectations related to current goals and stimulus–response selection , likely sustains attribution of temporary beliefs to tune action selection . Finally, the DLPFC might be responsible for translating the knowledge about the partner into action. In particular, in line with its role in generous decisions  and group-based cooperation , the DLPFC might be involved in the decision to engage in prosocial actions in response to the partner’s behavior. 

Crucially, these brain regions have previously been observed to be interconnected during interpersonal interactions. In particular, the left IPS shows selective connectivity with the DLPFC and PCC while understanding others during social interactions , suggesting that these brain regions build an intertwined brain network engaged in representations of socially-relevant qualities of others. These representations may underlie individual, behavioral attitudes based on which adequate behaviors tailored to the current partner’s character and reputation are flexibly adopted. Moreover, such representations might be retrieved in future interactions with the partner, as their content is informative of the partner’s character and is thus useful to sustain individual choices that strongly rely on those character impressions. In line with this, in our study, we observed that neural signal in the PCC, left IPS, and bilateral DLPFC predicted the future willingness to trust the partner in a social context (i.e., in the TG), where participants made trust decisions based exclusively on their trustworthiness impressions of the partner from the previous interaction (i.e., from the TAG). 

Critically, the IPS and DLPFC, together with the IPL, were also more strongly recruited by dishonesty as opposed to honesty. These findings are in line with previous evidence that the IPS is consistently activated by others’ non-cooperative behavior , and that the DLPFC, together with the IPL, tracks violations of expectations  and decisions to lie . The stronger recruitment of these brain regions by dishonesty might reflect the need to constantly track the behaviors of dishonest partners for an online belief updating and a flexible behavior revision. In fact, on the behavioral level, we observed that advice-taking behavior toward honest advisers did not significantly change over time, whereas participants continuously adjusted their advice-taking behavior for dishonest advisers with a consistent decrease of trust in them over time. These results suggest that the recruitment of the DLPFC, IPS, and IPL is more strongly required in cases of norm-deviant behaviors (e.g., when other people are dishonest, unfair, or noncooperative) to carefully track the other’s actions and optimally adjust one’s own behavior. 

On the contrary, honesty was observed to more strongly recruit the VMPFC, a brain region previously associated with behaviorally-relevant representations of positive traits of others . In particular, the VMPFC was functionally coupled to the left pTPJ during honesty encoding in the TAG, and the strength of this functional connectivity was further correlated with higher trust in the adviser during the later interaction in the TG. In line with the pTPJ role in processing inferences on others’ mental states  and social prediction errors , these findings suggest that inferences on the partner’s intentions undertaken by the pTPJ might be supported by integration of novel, incoming information about the partner’s honesty encoded in the VMPFC. Interestingly, a recent work has indicated that connectivity of the left pTPJ with other social cognition regions supports behavioral trust and that the experimentally-induced disruption of trust (via aversive affect) was concomitantly followed by the suppression of pTPJ connectivity during trust decisions. These findings suggest a pivotal role of pTPJ connectivity in integration of behaviorally-relevant signal . In our experiment, stronger integration of an honesty signal likely led to more positive beliefs about the partner’s intentions, increasing one’s willingness to trust. Thus, the interplay between the VMPFC and left pTPJ represents a central neural mechanism underlying integration of character information for behaviorally-relevant inferences on others’ actions and intentions. 

Finally, we observed modulation of neural responses to value information by honesty in the OFC during outcome evaluations. Specifically, higher OFC activity was observed for positive outcomes received when interacting with honest partners. These results suggest that in line with its role in processing subjective values of both social and nonsocial rewards , higher neural activity in the OFC reflects an enhanced subjective value of nonsocial rewards induced by the positive character of the interacting partner. These neural findings might provide a mechanistic explanation for the positivity bias toward individuals with a good reputation that has been observed to influence learning processes . Given the OFC role in learning mechanisms , an asymmetry in the representation of positive and negative events associated with an individual of good social qualities in the OFC might promote a stronger susceptibility to reputational priors and a reduced flexibility in the revision of one’s beliefs about the partner. Consistently with that, decreased OFC activity has previously been associated with stronger resistance to political belief change during information encoding . Hence, an asymmetric valuation of new incoming information likely contributes to judgmental biases and suboptimal learning. 

Taken together, our results improve our understanding of how neural patterns representing honesty-based trustworthiness guide social behaviors in interpersonal interactions. The PCC and frontoparietal brain regions represent behaviorally-relevant knowledge about the other’s social character, likely taking a role in the flexible revision of one’s current behavior for optimal adaptation to the partner’s actions. Further, social behaviors such as trust are likely enacted based on the integration of character information from the VMPFC into the left pTPJ for reliable inferences on the good intentions of the partner. Finally, an asymmetric activity in the OFC in response to positive outcomes due to the good reputation of the interacting partner likely jeopardizes an individual’s ability to optimally form and update one’s beliefs about the other, fostering a broad array of judgmental biases. 

Although we here showed that trustworthiness-related neural signal successfully predicts individual trust decisions in a future social interaction, future studies are still needed to investigate in a brain-to-brain predictive framework whether these neural signatures of trustworthiness are also able to predict the neural correlates of individual trust decisions. Further, future studies, especially in advice-taking paradigms, might also consider controlling for individual susceptibility to social influence, which might, for instance, explain an individual’s propensity to take advice from others. Another interesting research question for future studies relates to how other factors of trustworthiness impressions (like competence and benevolence) interact with honesty to elicit trust and/or distrust in others. By shedding light on how social characters are represented in the brain and influence individual decisions, this work makes an important contribution to the extant literature on human cognition in a broad range of scientific fields, such as neuroscience, social psychology, sociology, economics, and political sciences. 


## Methods 
  
### Subjects 
  
Thirty-one participants (20 females) participated in the experiment (age: 24.29 ± 3.81   M   ± SD). Participants were recruited from the student community at the University. They were all right handed and had no history of neurological or psychiatric disorders. Participants gave written informed consent after a complete description of the study was provided. All the procedures involved were in accordance with the Declaration of Helsinki and approved by the Ethical Committee of the University of Lübeck, Lübeck, Germany. 


### Take advice game 
  
In the TAG, participants played as advisee a card game with eight different advisers in a randomized order. Participants were told that these advisers were other participants who were taking part in the same experiment and were preparing themselves in other rooms. Participants were told that roles in the game were randomly assigned by drawing a ball with their role from a lottery box and that all participants were going to do it prior to the experiment. They were told that for transparency reasons, the ball-drawing procedure was going to be performed in front of a camera on top of a screen where each participant could see each of the participants in the other rooms drawing their role. However, to guarantee anonymity, all cameras were mounted on top of the screen so that each participant was recorded only up to the chin. Camera adjustments were performed prior to the ball-drawing procedure to assure this. Moreover, to further guarantee anonymity, each participant needed to choose an avatar that represented themselves in the game (Supplementary Fig.  ). In reality, participants received always the advisee role and the other videos were pre-recorded. 

As advisee, participants’ task was to draw the card with the higher number. Numbers on the cards ranged from 1 to 9 (except for 5). As participants did not have any information about the card numbers, they needed to rely exclusively on the adviser’s advice for their decisions (establishing an adviser–advisee interdependency necessary for trust). Participants were told that the advisers could see only one of the two cards (adviser phase: 2–3 s) and could communicate this information to them (advice phase: 1 s). This implies that although advisers had more information than our participants, they did not know which card was the winning one, making this setting similar to real-life scenarios in which people generally ask for advice those who may know better, but advisers rarely have complete knowledge of life situations. Participants also knew that advisers could help them but did not have any benefits in doing so. However, both partners knew that after the TAG they were going to play a second game (i.e., the TG, see below), in which participants could repay the advisers for their honesty in advice giving. Thus, in the TAG, advisers were motivated to form a good reputation in the hope that participants would repay them later on. To note, however, participants did not promise or commit to repay the advisers for their advice. The dynamics set into motion by this design resembles real-life interactions in which honest behavior (e.g., giving good advice) has often no proximal benefits to an individual but may help her form a good reputation that might turn out advantageous in the future (a possible, distal benefit). 

Moreover, to disentangle trustworthiness information about the advisers (honesty/dishonesty) from value information about participants’ decisions (winnings/losses), the advice of honest advisers was made unpredictive of the winning card (i.e., 50% of the time information about the losing card was provided by the honest adviser). Thus, cards were drawn from a uniform distribution with pseudo-random sampling without replacement. The pseudo-random sampling procedure was optimized to have a realized probability of card drawing that approximates chance in both conditions, as would be expected in random drawing. A two-sample Kolmogorov–Smirnov test confirmed that the realized distributions of card numbers did not differ between advisers (K–S test = 0.25;   p   = 0.929). Participants then chose one of the two cards (decision phase: 1 s) and saw a final feedback (feedback phase: 1 s) in which they received both social information (the card numbers based on which they could infer the adviser’s trustworthiness) and nonsocial information (a green or red circle representing winnings and losses, respectively). In each trial, participants could win or lose €1. Intertrial stimulus intervals were 2–8 s (  M   = 2.6 s) long, whereas jitters between trials were 2–8 s (  M   = 4 s) long. Participants played a total of 5 runs with 48 trials each (24 with honest and 24 with dishonest advisers) for a total of 240 trials. 

Advice-taking behavior in the TAG was operationalized as the probability of choosing a card given the informativeness of the advice received. The optimal strategy in the game would be to choose more frequently a card when the adviser communicated that a number bigger than five was on that card but choose the other card when the adviser communicated that a number smaller than five was on that card. Moreover, as we manipulated the advisers’ honesty with four honest advisers sending accurate information and four dishonest advisers sending inaccurate information (with 100% contingency), we hypothesized that participants would employ the optimal card-choice strategy differently for honest and dishonest advisers. Analyses of card choice probabilities confirmed our hypotheses (Supplementary Fig.  ). A repeated-measures analysis of variance with card numbers as repeated measure yielded a significant main effect of card number (  F   = 83.13;   p   < 0.0001;  ) with participants being more likely to choose a card when a number higher than five was said to be on the card and less likely to do so otherwise. Importantly, an interaction effect between card number and advisers was also found (  F   = 4.86;   p   < 0.0001;  ), suggesting that participants were more consistently employing the optimal strategy when interacting with honest advisers but not when interacting with dishonest ones. 

To test the hypothesis that this interaction effect was due to the difference in trust in the advisers and was not simply driven by differences between specific cards, we ran post-hoc   t   tests and compared the average choice probability for the honest and dishonest advisers for cards 1–4 and cards 6–9. Results indicate participants were less likely to choose a card when honest advisers told them a low number was on the card (honest vs. dishonest advisers for cards 1–4:   t   = −2.97;   p   < 0.006), but more likely to choose a card when honest advisers told them a high number was on the card (honest vs. dishonest advisers for cards 6–9:   t   = 2.88;   p   = 0.007). These results suggest that participants were discounting the advice of a dishonest adviser, likely because they did not believe it to be informative. In other words, this decrease in the likelihood of the use of the optimal strategy for dishonest advisers suggests a devaluation of their advice. Overall, these findings indicate that for the same piece of advice, the likelihood someone is going to take that advice hinges on their trust in the adviser or, complementary, on how much they value the adviser’s advice (i.e., recognize it as informative). 

Finally, it has to be noted that although the reputation dynamics set in motion by our design closely resemble real-life scenarios, the fact that advisers provided either correct or incorrect advice in every trial might not seem very realistic. As we had eight different advisers (four honest and four dishonest), the task was still challenging enough to look like completely unrealistic and participants needed to learn trial by trial the behavioral conduct of each adviser, as they were not instructed about the underlying behavioral contingency. We preferred a 100% contingency for the advisers’ advice-giving behaviors to, for example, a probabilistic instantiation thereof because we wanted to avoid that the multivariate algorithm for the decoding of neural signal related to the social character of the advisers might have picked some spurious signal evoked, for instance, by the partner’s behavioral inconsistency or prediction error associated with subjective expectancies. However, future studies might want to consider introducing some variability in the behavior of pre-programmed human-like agents. 


### Trust game 
  
After the scanning session, participants played as investor a one-shot TG with the same partners who advised them in the TAG. Participants were endowed with 10 MUs for each adviser in the role of trustee and decided whether they wanted to share any of this initial endowment with them (economic trust decision). They were told that any amount they decided to share would be tripled by the experimenter and passed on to the trustee who could in turn decide to share back any portion of this tripled amount (reciprocity decision). The TG was used to probe the transfer effect of the honest reputation established in the TAG on individual trust in a new social interaction. 


### Exit questionnaire 
  
To acquire an explicit measure of the criteria and motives behind participants’ behavior in the TAG, after the experiment, participants were asked to report whether they used any particular strategy and whether they thought this strategy was successful (binary answer option). Although a significant portion of participants reported that they used a strategy in the TAG (  χ   = 5.89;   p   = 0.015), except for four participants, no one believed it was successful (  χ   = 13.68;   p   = 0.0002). 

Moreover, they were also asked to describe the criteria for their decisions in the TAG (answering the question: “which strategy did you use for your choices in the first game?”). Three researchers blind to the study design and purposes categorized participants’ free answers. The first rater identified three main strategies. The second and third raters identified further subcategories for a total of seven and eight categories, respectively. These could be grouped into the three main strategies of the first rater (averaged inter-rater reliability:   r   = 0.64). For each rater’s category, we estimated the percentage of participants using a particular strategy. We then averaged the percentage of participants using each strategy across raters. On average, participants made their decisions (1) intuitively (  M   = 11.8%: rater 1: 9.7%; rater 2: 16%; rater 3: 9.7%), (2) based on the advisers’ trustworthiness (  M   = 55.9%: rater 1: 54.8%; rater 2: 51.6%; rater 3: 61.3%), or (3) based on the advisers’ advice (  M   = 32.3%: rater 1: 35.5%; rater 2: 32.3%; rater 3: 29%). Thus, the majority of our participants (88.2%) explicitly reported to have made their decisions in the TAG based on the adviser’s trustworthy character and advice. 


### Neuroimage acquisition 
  
Data were collected with a Siemens MAGNETOM TRIO 3 Tesla scanner at the Freie Universität Berlin. The fMRI scans consisted of an average of 360 contiguous volumes per run (axial slices, 37; slice thickness, 3 mm; interslice gap, 0.6 mm; repetition time (TR), 2000 ms; echo time (TE), 30 ms; flip angle, 70°; voxel size, 3.0 × 3.0 × 3.0 mm ; field of view (FOV), 192 × 192 mm ). High-resolution structural images were acquired through a 3D sagittal T1-weighted MP-RAGE (magnetization prepared-rapid gradient echo) (sagittal slices, 176; TR, 1900 ms; TE, 2.52 ms; slice thickness, 1.0 mm; voxel size, 1.0 × 1.0 × 1.0 mm ; flip angle, 9°; inversion time, 900 ms; FOV, 256 × 256 mm ). 


### Neuroimage preprocessing 
  
Neuroimaging data analyses were performed on SPM12 (v. 6905;   http://www.fil.ion.ucl.ac.uk/spm/software/spm12/  ) in MATLAB 2016b (The Mathworks, Natick, MA;   http://www.mathworks.com/  ). The functional images were slice-timing corrected, corrected for voxel displacement using field maps and realigned for head movement correction to the mean image. Using the unified segmentation procedure , functional images were co-registered to their structural images and subsequently normalized into MNI (Montreal Neurological Institute) space using deformation fields (resampling voxel size: 2 × 2 × 2 mm ). Finally, functional images used for univariate analyses were spatially smoothed using a Gaussian filter (8 × 8 × 8 mm  full-width at half-maximum) to decrease spatial noise. Movement outliers were identified and excluded if head movements/translations were above 3 mm/rad. One run of two participants met these criteria and was therefore excluded from all analyses. 


### Behavioral analyses 
  
Differences in advice-taking behaviors between honest and dishonest advisers were tested with a paired   t   test (two-sided). The effect size (Cohen’s   d  ) was computed as follows: (  M   −   M  )/  σ  , where   M   and   M   are the average advice-taking behaviors for the honest and dishonest advisers, respectively, and   σ   is the standard deviation of the behaviors’ differences. A generalized mixed-effects logistic regression was implemented to investigated whether trial-by-trial advice-taking behavior was predicted by the adviser’s honesty irrespective of the benefits associated with the act of trust. A model with the following four regressors was built to predict trust in the adviser’s advice (1 = trust; 0 = distrust): one regressor coding for the adviser’s honesty, one for the advised card, one for the advised number, and one for the feedback in the previous trial played with the current adviser. Random-effects structure was based on a ‘maximal’ approach with by-subject and by-item random intercepts and slopes .   P   values were computed with a likelihood-ratio test by comparing the full model with the same model without the fixed effect of interest, but that it is otherwise identical in random-effects structure . A mixed-effects regression was further fitted to the difference of advice-taking behaviors toward honest and dishonest advisers with run as fixed-effects time variable and subject as random intercept to test the increase of trust difference over time. Two similar mixed-effects regression models were then separately fitted to each advice-taking behavior toward honest and dishonest advisers in order to examine increases/decreases of trust in the two advisers over time. To test whether trustworthiness relates to subsequent economic trust decisions in a different social context, advice-taking behavior in the TAG was correlated with the amount of money invested in the TG (Spearman’s correlations). To further probe that trust decisions in the TG followed from participant’s impressions of the partner’s trustworthiness in the TAG and were not simply reflecting a repaying behavior, correlation analyses were performed between average winnings in the TAG and money invested in the TG. 


### Univariate and ROI analyses 
  
Two GLMs with eight regressors of interest (two for each task phase) on the first level were defined for both univariate and multivariate analyses of fMRI data to be able to estimate beta parameters that uniquely capture neural signals related to trustworthiness and value encoding, respectively. GLM1 consisted of the following regressors: two regressors for the advisor phase, two regressors for the advice phase, two regressors for the decision phase and two regressors for the feedback phase coding the adviser’s trustworthiness (honesty/dishonesty). GLM2 entailed the same regressors as GLM1, with the exception that the two regressors for the feedback phase coded value information (winning/loss). 

Control analyses were performed to check that the neural signatures of trustworthiness were not confounded by other factors. In particular, we re-ran GLM1 adding further regressors and parametric modulators to account for variance that might be due to risk and congruency effects. To control for risk, two orthogonal parametric modulators were added to the two regressors coding honesty and dishonesty in the feedback phase; namely, a first-order term for reward probability given the adviser’s advice and a second-order term for reward variance (i.e., the mean-squared deviation from expected outcome), which is quadratic in reward probability   p   and refers to the expected risk given the adviser’s advice . Second, to control for contingency effects (i.e., informational deviance between the adviser’s advice and the actual card number on the advised card), we added a regressor coding for all feedback phases (i.e., across advisers) with duration 1 s and degrees of congruency (continuous variable) as parametric modulator. Further, to control that the observed neural signatures for honesty and dishonesty are specific to social information processing and are not confounded by neural signatures of nonsocial information processing, a single parametric GLM was built with only one feedback regressor and two categorical, parametric modulators, that is, first one coding for value information (1 = winning, −1 = loss) and then one coding for the adviser’s trustworthiness (1 = honesty, −1 = dishonesty). The two parametric modulators were orthogonalized to be able to capture unique variance related to social information processing. 

Finally, to separately investigate brain activations for responses to positive and negative outcomes when interacting with honest and dishonest advisers, and to analyze the modulation of neural responses to value information by honesty and dishonesty, GLM3 was defined encompassing a total of 10 regressors of interest. All task phases had the same regressors as GLM1 and GLM2, except for the feedback phase, for which four regressors were defined coding winnings and losses received when advised by honest and dishonest advisers, separately. In all GLMs, conditions were modeled as events using a stick function (i.e., setting the duration of each condition to 0). 

Motion parameters were further included as regressors of no-interest in all GLMs. A temporal high-pass filter with a cutoff of 128 s was applied for all GLMs. Results were whole-brain corrected for multiple comparison using a voxel-level threshold of   p   < 0.001 and a FWE  corrected threshold of   p   < 0.05 . The ROI analysis for the OFC (area s32) to post-hoc examine the modulation of positive outcomes by honesty was based on the probabilistic map provided by the SPM Anatomy toolbox, v. 2.2 . 


### Multivariate voxel pattern analyses 
  
Decoding analyses to investigate the neural representations of trustworthiness (honesty/dishonesty) and value (winnings/losses) information were performed using a linear SVM algorithm for binary classification and a whole-brain searchlight approach with a searchlight’s radius size of 10 mm. Applying an LOROCV, the SVM was trained on all but one run and tested on the left-out run. This procedure was repeated   n   times with   n   = 5 (total number of runs) and the algorithm’s cross-validated accuracy was computed. To decode character information related to the advisers’ trustworthiness, β images from the feedback phase of GLM1 (fitted to unsmoothed, normalized brain images) were used. To decode value information related to winnings and losses, β images from the feedback phase of GLM2 (fitted to unsmoothed, normalized brain images) were used. Searchlight decoding analyses were applied to all voxels within the whole-brain gray matter probability mask provided by SPM and thresholded at 0.1. 

Decoding generalization of the trustworthiness and value decoding networks was tested with a classification analysis using an LOSOCV approach in which the SVM was trained on   z  -scored average β images of all but one participant and tested on the left-out participant. Cross-validated accuracy of the group-level classification was tested for significance running a permutation test with 10,000 permutations (  n_perm  ). In each permutation, the SVM was trained on randomly permuted labels using the same LOSOCV approach of the true classification model. The sum of models trained on permuted labels that performed better than the true model was then computed (  p_models  ). The nonparametric   p   value was assessed including the observed statistics according to the following formula : (1 +   p  _  models  )/(1 +   n  _  perm  ). Multivariate prediction analyses to predict subsequent, economic trust decisions in the TG (individual averages of money entrusted to the advisers) from the trustworthiness and value decoding networks were based on the same LOSOCV procedure and permutation test but used support vector regression for prediction of continuous variables. 

Decoding analyses were run using The Decoding Toolbox TDT, v. 3.99  and custom MATLAB scripts. 


### Meta-analytic functional decoding 
  
To characterize the functional specification of the trustworthiness decoding network, a meta-analytic image decoding analysis was performed using the Neurosynth Image Decoder (neurosynth.org) . The Neurosynth Image Decoder allows to quantitatively estimate the representational similarity between any task-based activation pattern and meta-analytical activation patterns associated with particular terms and generated based on brain images in the Neurosynth database . Similarity was computed as Pearson’s correlations across all voxels between the task-based and the meta-analytical maps. We selected meta-analytic maps based on 12 different terms to test the specific a priori hypothesis that the trustworthiness decoding map more likely related to functional roles in the social domain as opposed to the reward, risk, and congruency domains. It has to be noted that the observed correlations are relatively small but in line with previous research . Moreover, while the analysis is quantitative, the conclusions that can be drawn are descriptive in nature, as there is no inference statistics that tested whether any of the observed correlation coefficients is significantly higher than the others. 


### Task-dependent functional connectivity analyses 
  
To test the information flow between the VMPFC underlying honesty signals and any regions across the whole brain, a task-dependent functional connectivity analysis was implemented using a whole-brain psychophysiological interaction (PPI)  analysis with seed region (10 mm radius) around the VMPFC peak coordinates yielded by the univariate contrast. The PPI-GLM consisted of a task regressor, a physiological regressor entailing deconvolved blood-oxygen-level-dependent signal from the seed region and a regressor for the interaction term with movement parameters as regressors of no interest. Significant connectivity was assessed with a voxel-level threshold of   p   < 0.001 and an FWE cluster-level threshold of   p   < 0.05 within the ROI . 


### Labeling and data visualization 
  
The SPM Anatomy toolbox v. 2.2  and MRIcron (  http://people.cas.sc.edu/rorden/mricron/install.html/  ) were used for anatomical labeling. MRIcroGL (  https://www.mccauslandcenter.sc.edu/mricrogl/home/  ) was used for brain visualizations. 


### Reporting summary 
  
Further information on research design is available in the   linked to this article. 



## Supplementary information 
  




 ## Data availability

The data that support the findings of this study will be provided to all readers upon request. ## Code availability

All relevant MATLAB code is available from the corresponding author upon request. </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-22'>
<h2>22. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/28855682/' target='_blank'>28855682</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> How spontaneous brain activity and narcissistic features shape social interaction</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Sci Rep</p>
<p><strong>Publication Year:</strong> 2017</p>
<p><strong>DOI:</strong> 10.1038/s41598-017-10389-9</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5577167/' target='_blank'>5577167</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Meets all inclusion criteria: (1) fMRI during a social-related task — a task comparing anticipation of touching an animate (human hand) versus inanimate (mannequin) target; (2) healthy adult participants aged 21–33 (N=32; task data N=21), within 18–60; (3) whole-brain voxel-wise analyses reported (paired-sample t-tests and voxel-wise covariate analyses with FDR correction). Does not violate exclusion criteria: not an ROI-only paper (whole-brain results are primary), not a review/meta-analysis, and participants had no reported psychiatric/neurological disorders. Therefore the study is eligible for inclusion in the review.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
There is an increasing interest in how ongoing spontaneous brain activity and personality provide a predisposition for the processing of environmental demands. It further has been suggested that the brain has an inherent sensitivity to the social environment. Here we tested in healthy volunteers if spontaneous brain activity contributes to a predisposition for social behavior and how this is modulated by narcissistic personality features associated with poor interpersonal functioning. Functional magnetic resonance imaging included a resting state and an experimental paradigm focusing on the anticipation of actively touching an animate (human hand) versus an inanimate target (mannequin hand). The experimental task induced a significant modulation of neural activity in left postcentral gyrus (PostCG), right culmen and, co-varying with narcissistic features, in right anterior insula (AI). Neural activity in anticipation of the animate target significantly correlated with spontaneous activity during the resting state indexed by the Power Law Exponent (PLE) in PostCG and AI. Finally, the correlation between spontaneous and task-induced activity in AI was mediated by narcissistic features. These findings provide novel evidence for a relationship between intrinsic brain activity and social behavior and show how personality could contribute to individual differences in our predisposition to approach the animate world. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (36737 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Since the early infancy we act in a social environment where we need to distinguish between the animate and the inanimate . This suggests an inherent sensitivity of our brain to the social environment . Conspecifics are intentionally approached as being similar to our selves, with similar inner experiences . Correspondingly, social interactions induce neural activity in sensorimotor and affective circuits which allows us to predict and understand others’ sensory experiences . 

Moreover, our personality is shaped by early interactions with the animate world . The narcissistic personality trait reflects a predisposition for individual differences in social functioning being specifically associated with an inflated sense of self/self-centeredness and dysfunctional interpersonal functioning . On a psychological level, individuals with pathological narcissism may be capable of social processing, but are disengaged from it . 

However, neither the exact neural mechanisms of the brain’s predisposition for intersubjectivity nor the role of differences in personality features such as narcissism are clear, yet. 

Stimulus-induced neural activity has recently been traced to the brain intrinsic or spontaneous activity . Raichle  proposed that the brain maintains an intrinsic state of preparedness for anticipating or predisposing the demands placed continuously over time. Indeed, it has been shown that spontaneous activity modulates variability in task-induced activity in sensory cortices . 

The brain’s spontaneous activity as measured in the resting state (when a participant is awake but not involved in a specific task) shows a complex temporal structure characterized by long-range temporal correlations (LRTCs) . LRTCs are related to a higher time-lagged autocorrelation indicating that the past pattern of a system has a stronger influence on its future dynamics . Concerning functional magnetic resonance imaging (fMRI), previous studies showed that the power law exponent (PLE) can provide a robust and reliable measure of LRTC’s . Higher LRTC’s are indexed by a higher PLE, and imply stronger low-frequency Blood Oxygen Level Dependent (BOLD) signal fluctuations and higher glucose metabolism in the brain . 

Initial functional brain states defined in terms of LRTC’s could influence the processing of upcoming stimuli in the environment. Indeed, recent studies demonstrated that the degree of the spontaneous activity’s LRTCs predisposes the neural processing of motor  and sensory (i.e., auditory and visual)  stimuli. 

Departing from this background, the present study aims at 1) testing whether task-induced activity during social interaction can be predicted by the spontaneous activity of the brain; 2) to investigate how narcissistic individual differences could mediate the relationship between spontaneous and task induced activity. 

In addition to resting state functional magnetic resonance imaging (fMRI), we applied a social interaction fMRI task requiring participants to actively touch an animate (another individual) or inanimate target (a mannequin). Touch plays an incipient role in intersubjectivity , being involved in social interactions already during the earliest stages of life . Furthermore, somatosensory (e.g. postcentral gyrus, inferior parietal gyrus) and affective (e.g. anterior insula, cingulate and orbitofrontal cortices) circuits are involved both in our own experience of touch and in the perception of others being touched . 

The experimental paradigm focused specifically on the anticipation of animate versus inanimate touch, anticipation referring to the time window preceding the action while already neurally encoding the action including its target . Thus, anticipation reflects a transition phase from a resting state to actual social interaction characterized by the emergence of internally generated behavior without realizing any overt action. 

For data analyses, firstly, regions of interest (ROIs) were defined based on the fMRI task (anticipation of animate versus inanimate touch). Secondly, the resting state PLE was calculated for these ROIs and its association with task-induced brain activity was tested. Thirdly, it was investigated if spontaneous and task-induced activity showed neural overlap in their correlation with narcissism. Fourthly, it was tested if the relationship between spontaneous and task-induced activity was modulated by narcissism. 

We hypothesized that task induced activity in sensorimotor and affective brain regions in anticipation of touching the animate target, but not the inanimate target, co-varied with spontaneous activity in terms of LRTC’s during a preceding resting state period, whereas narcissistic features could modulate this relationship. 


## Methods 
  
### Participants 
  
Thirty-two right-handed male participants (age 21–33; Mean = 25.4; standard deviation = 2.82) were recruited in this study. All participants had normal or corrected-to-normal vision capabilities. None of the participants reported a history of neurological or psychiatric disease, or substance abuse. Written informed consent was obtained from all participants after full explanation of the study procedure, in line with the Declaration of Helsinki. Ethics Committee for Biomedical Research of the provinces of Chieti and Pescara approved the experimental protocol. Participants were paid. 


### Data acquisition 
  
fMRI data were acquired by a Philips Achieva MRI scanner at 3 T (See Supplementary Information for more details). All 32 subjects completed the resting state fMRI acquisition. Twenty one out of the 32 participants (age 21–30; Mean = 24.9; standard deviation = 2.45) also completed task fMRI acquisition. In addition to fMRI scanning, all 32 participants completed the Pathological Narcissism Inventory, a 52-item multidimensional self-report measure which was designed specifically to assess both grandiose (NG) and vulnerable (NV) narcissism in the healthy and pathological population . fMRI scanning details and additional information about the PNI can be found in the Supplementary Information. 


### Experimental Procedure and Materials 
  
#### Resting state-fMRI 
  
During the two resting state-fMRI runs (6 minutes each), participants were instructed to watch a white fixation cross presented on a black screen, think of nothing in particular and keep their eyes open (they were monitored through a video camera placed in the MRI room). 


#### Task-fMRI 
  
The experimental task is based on that used in previous research  and is described in detail in the Supplementary Information. Briefly, during the task fMRI runs (8 runs of 7.8 minutes each), the participant completed a series of touch and no-touch trials. Trial order was randomized. Each trial, either touch or no-touch, started with a visual cue (1000 ms) consisting of a black and white line drawing followed by an attendance signal (red cross for 3000 ms). The drawing indicated the target of the touch (what had to be touched by the participant), that is, an animate (the hand of another volunteer who was standing next to the scanner) or an inanimate target (a mannequin hand). In the no-touch trials (60%), the red cross became black indicating to do noting and wait for the next trial. In the touch trials (40%), the cross became green for 6000 ms and the touch needed to be performed with a brush covert with either velvet (inducing a pleasant sensation when brushing on someone’s skin) or sandpaper (inducing an unpleasant sensation when brushing on someone’s skin). 

Since it was not predictable for the participant whether he actually had to perform the touch after the attendance signal, he was forced to be prepared to touch either the animate or the inanimate target after every visual cue. Therefore, the no touch trials allowed to study the anticipation of touching the animate or the inanimate target without the presence of any overt movements of the participant. 

Thus, two main conditions could be distinguished: the anticipation of touching an animate target (48 trials) and the anticipation of touching an inanimate target (48 trials). 

This task essentially differs from the previous studies for various aspects: 1) by adding the affective component through the valence of the touch (pleasant and unpleasant) the intrinsic link between emotion, self-related processing and social interaction was more specifically considered; 2) a slow event-related fMRI design was used (ITIs = 14000/16000/18000 ms) instead of fast event-related fMRI design; 3) the task was preceded by resting state runs (two independent 6 min-task free fMRI scans acquired before any task) to study the relation between rest and task conditions. 


#### Task fMRI analysis 
  
Pre-processing procedures of the fMRI data were implemented in Analysis of Functional NeuroImages software  and are described in the Supplementary Information. 

The contrast of principal interest concerned the anticipation of touch an animate target versus the anticipation of touch an inanimate target (is there a difference in the anticipation of touching a human animate hand in contrast to an inanimate mannequin hand?). A whole brain voxelwise paired-sample t-test was performed according to a random effect model to compare neural activity related to the anticipation of touching the animate target and to the anticipation of touching the inanimate target. 

Additionally, to test whether individual differences in the neural activity during the task were related to narcissism, whole brain analyses were performed comparing the neural activity during the anticipation of touching the animate target or the inanimate target with baseline, while using the PNI subscales of NG and NV as covariates. 

Statistical thresholds for all group statistical maps were set at q < 0.05 after False Discovery Rate (FDR) correction to search for modulations of brain activity by the different targets. The coordinates of the voxel clusters showing statistically significant effects were compared with the Talairach atlas available in AFNI software to label them in terms of anatomically defined regions and Brodmann’s areas (BA). 

To explore whether there were statistically significant modulations of BOLD response for the performance of an animate target and an inanimate target touch (touch trials) in the regions of interest (ROIs) modulated by the anticipation of touch, we performed a ROI based analysis. Avoiding circularity in the analysis, individual beta values were extracted from the voxel clusters (ROIs) showing a significant effect regarding the above described whole brain analysis for the anticipation of touch, that is, the no-touch trials. Beta values for each of these independent ROIs were then calculated from the average signal time course of the voxels included in each ROI concerning the performance of touch, that is, the touch trials. A paired-sample t-test was performed on the beta values regarding performance of an animate target touch and an inanimate target touch to establish if there also was a significant difference in neuronal response during touch performance regarding the ROI’s previously associated with the anticipation of touch. 



### Resting-State fMRI Analysis: Power Law Exponent (PLE) 
  
Power Law Exponent (PLE) analysis, as a measure of the temporal structure of low-frequency fluctuations , was performed on the resting state fMRI runs . PLE is considered suitable for the measure of scale free dynamics of fMRI data . Comparing different methods for computing fMRI time series complexity, Rubin and colleagues  demonstrated power spectrum based methods such as PLE being among the most robust measures. 

Scale-free dynamics are mathematically characterized by a power spectrum following the formula P ∝ 1/f , where P is power, f is frequency, and β is called the “power-law exponent” . After pre-processing, the time course per voxel was normalized to zero mean and unit variance (z-value) . Using methods previously optimized for fMRI , the normalized power spectrum of the fMRI signal was computed for each voxel using AFNI program: 3dPeriodogram. Similar to Welch’s method, the power spectra of the two resting state runs were averaged to reduce noise caused by imperfect and finite data, in exchange for reducing the frequency resolution. The power spectrum of the BOLD signal was further smoothed with a Hamming window (HM) of 7 neighboring frequency bins (HM = 7) . The averaged power spectra across voxels within the a priori ROIs (left PostCG, right culmen and right AI established before on whole brain analysis comparing different targets during the anticipation of touch) were extracted for each participant. The power spectrum was fitted with a power-law function P ∝ 1/f  using a least-square estimation (in a log frequency by log power plot) in the frequency range of 0.01~0.1 Hz . Finally, the power-law exponent, β, of each participant’s ROI was defined as the slope of the linear regression of log-power on log-frequency. 

In addition, we performed three different control analysis:   
To test the goodness of fit for scale invariance in the fMRI signal from particular region of interests we adapted a goodness of fit test developed for testing power-law distributions  and used by other authors in fMRI studies . For each ROI, its time series were extracted for each subject and subjected to PLE analysis for the resting state runs. 1000 time series of fractional Gaussian noise (fGn) with the same length and standard deviation as the original ROI time series were generated. Fractional Gaussian noise is a parsimonious model of stationary scale-free dynamics . Each synthetic fGn time series was subjected to the same PLE analysis as the original resting state data. The p value is defined as the fraction of synthetic time series with standard deviations of residuals from best fit that is larger than the original standard deviations of residuals from best fit of the fMRI time series. The larger the p value, the more plausible the fGn model is for representing the original fMRI time series, and the better the fit of the original data to a scale-free distribution. The hypothesis that the fMRI signal is scale free is plausible if the resulting p‐value is greater than 0.1, otherwise it is ruled out . 
  
To confirm the robustness of our frequency domain analysis (PLE) we also independently calculated the Hurst exponent in the time domain with detrended fluctuation analysis (H-DFA)  as a control index and calculated their correlation. 

Specifically, DFA measures the scaling of the root-mean-square fluctuation of the integrated and linearly detrended signals, F(T), as a function of time window size, T. The fluctuation F(T) is of the form F(T) = T , where H is the scaling exponent. 
  
Finally, we applied different Hamming Windows (HM = 3, 5, 9, 15) on the PLE calculation to test if the correlation between resting state activity (PLE) and task induced activity could be affected by different smoothing parameters. 
  


### Relationship between resting-state activity and task induced activity 
  
To establish if there was an association between resting state activity (PLE) and task induced activity in the ROIs, we performed Spearman correlation analyses (participant-based) with a 95% confidence interval (CI) based on 1000 bootstrap samples between resting state activity (Beta values) and task-activity (Beta values) for either anticipation of animate target or inanimate target. Bonferroni correction for multiple comparisons was performed on the obtained correlation coefficients, such that only   p   values (before correction) were considered significant below p < 0.05/number of calculated correlations. 

In addition to bootstrapping, the correlation was also controlled for all leave-one-out cohorts (N analyses with N-1 participants where each participant is excluded at a time). 


### Conjunction analysis: resting state activity and task induced activity with narcissistic features as covariates 
  
It was tested if the relationship between spontaneous activity and task-induced activity is modulated by PNI scores. Firstly, a whole-brain, voxel-wise conjunction analysis was performed to establish whether there was an overlap between brain regions in which task-induced and spontaneous activity both co-varied with narcissistic features. A random effect analysis of the overlap between the two contrasts was based on the minimum statistic compared with the conjunction null . This method controls the false positive error for conjunction inference and tests for common activations by creating the intersection of statistical maps thresholded at a specific alpha rate. 

Subsequently, a ROI-based partial correlation analysis was performed using the voxel clusters in which both task-induced activity and PLE correlated with NG or NV as obtained by the conjunction analysis. Specifically, the pair-wise relationships between PNI scores, and task-induced activity (beta scores of task-induced activity during the anticipation of animate touch) and spontaneous activity (beta scores of resting state PLE) in the ROIs were analyzed, while controlling for the third variable. 



## Results 
  
### Task fMRI data analysis: anticipation of animate target versus anticipation of inanimate target 
  
A whole brain voxel-wise paired-sample t-test between anticipation of the animate target and the inanimate target (“no touch trials”) elicited a significant effect in left postcentral gyrus (PostCG) and right culmen (t = 3.965; p = 0.0005; FDR corrected q = 0.05) (Fig.  , Table  ).   
Task-induced activity: (  a  ) Group statistical maps of whole brain voxelwise t-test between anticipation of animate target vs. anticipation of inanimate target (t = 3.965; FDR corrected, q = 0.05). (  b  ) Graphs of Beta values and Standard Errors extracted from activation clusters depicted in (  a  ). 
    
Brain regions showing a modulation of BOLD response by different experimental conditions and statistical information for the direct contrast between the anticipation of the animate target versus the anticipation of the inanimate target (FDR corrected), for the direct contrast between the anticipation of the animate target versus baseline (FDR corrected) and for the conjunction whole brain analysis between anticipation of animate target vs. baseline with covariate PNI-NG ∩ Resting state PLE vs. baseline with covariate PNI-NG. 
  
LH = left hemisphere; RH = right hemisphere. C-Mass Coordinates refer to Talairach space. PNI = Pathological Narcissistic Inventory; NG = Narcissistic Grandiosity. 
  

A single subject analysis for the anticipation of animate vs. inanimate target in four randomly selected single participants elicited a significant effect in left PostCG (Supplementary Figure  ). 

Examining the graphs, specifically for the anticipation of touching an animate target, we observed no appreciable modulation of BOLD response, compared to baseline, in the left PostCG, whereas a suppression of BOLD response (deactivation) was detected in the right culmen. By contrast, for the anticipation of touching the inanimate target we observed an increased activation, compared to baseline, in the left PostCG, but no appreciable modulation of activity, compared to baseline in the right culmen. 

An exploratory ROI-based analysis yielded the opposite pattern during touch performance (Fig.  ). Specifically, we found a significant difference between the two conditions (touch of an animate target and touch of an inanimate target) both in the left PostCG (p = 0.001) and for the right culmen (p = 0.001). In detail, we observed a greater activation in left PostCG as well as in right culmen during the active touch of the animate target compared to the inanimate target.   
Task-induced activity: ROI based analysis on touch performance in activation clusters obtained by the whole brain voxelwise t-test on the “no touch trials” (touch anticipation; Fig.  ). Bars represent the mean beta value across subject and Standard Error. * indicates p < 0.001. 
  

Regarding the co-variance with PNI scores, voxel-wise, whole brain one-sample t-tests on the anticipation of touching the animate target (versus baseline) with NG and NV as covariates elicited a significant effect of NG on BOLD responses in the right anterior insula (AI) (t = 3.828; p = 0.0005; FDR corrected q = 0.05) (Fig.  ), while no significant modulation was reported for NV.   
Task-induced activity: Group statistical maps of a whole brain voxelwise t-test between anticipation of animate target vs. baseline with PNI-narcissistic grandiosity (NG) as covariate (t = 3.965; FDR corrected, q = 0.05). 
  

Confirming that the relationship between task-induced activity and PNI scores was specific for the animate target, the same analysis on the anticipation of touching the inanimate target (versus baseline) with NG and NV as covariates yielded no significant effects (t = 3.621; p = 0.001; uncorrected). 


### Correlation between PLE and task induced activity 
  
The PLE values across participants (n = 32) in the left PostCG (mean = 0.44; SD = 0.27), in right culmen (mean = 0.37; SD = 0.23) and in right AI (mean = 0.43; SD = 0.19) are in accordance with previous studies . 

Correlations between resting state PLE and task induced activity were calculated, that is, for task-induced activity in anticipation of the animate and the inanimate touch, in left PostCG, right culmen and right AI (Fig.  ).   
Scatter plots showing predictive power (Spearman correlation) of PLE during the resting state for individual task induced activity in PostCG, culmen and AI ROIs during the anticipation of touching the animate and the inanimate target.   p   values reported in the figure are Bonferroni corrected. 
  

A negative and significant correlation between resting state PLE and task induced activity during the anticipation of touch the animate target was observed in left PostCG (r = −0.684, p = 0.006 Bonferroni corrected; 95% CI Lower: −0.874 Upper: −0.332; S.E. = 0.141) and in right AI (r = −0.592, p = 0.03 Bonferroni corrected; 95% CI Lower: −0.822 Upper: −0.217; S.E. = 0.154), but not in right culmen (r = −0.142, p = 0.540 – p = 0.54, uncorrected; 95% CI Lower: −0.600 Upper: 0.283; S.E. = 0.231). 

The correlation between PLE and task induced activity was also controlled for all leave-one-out cohorts (N analyses with N-1 participants where each participant is excluded at a time) and this procedure didn’t affect significance of the correlation coefficients for PostCG (min: r = −0.699 p = 0.001; max: r = −0.550, p = 0.012) and for AI (min: r = −0.668 p = 0.001; max: r = −0.543, p = 0.013). 

No significant correlation between resting state PLE and task induced activity during the anticipation of touch the inanimate target was observed in left PostCG (r = −0.342, p = 0.130 95% CI Lower: −0.686 Upper: 0.152; S.E. = 0.211), right culmen (r = 0.175, p = 0.447; 95% CI Lower: −0.339 Upper: 0.641; S.E. = 0.244) and right AI (r = −0.514, p = 0.017; 95% CI Lower: −0.867 Upper: 0.019; S.E. = 0.236). 

Hotelling-Williams test  was performed to test the equality of two correlation coefficients obtained from the same sample, with the two correlations sharing one variable in common. The test resulted significant for PostCG (z = 2.736; p = 0.006) indicating that the correlation between beta of animate touch anticipation and resting state PLE was significantly stronger than the correlation between beta of inanimate touch anticipation and resting state PLE. The difference was not significant for AI (z = −0.421; p = 0.673) and culmen (z = −1.112; p = 0.266). 


### PLE control analyses 
  
(1) Simulating 1000 time series with a stochastic Gaussian process of known long-range temporal dependence, we first showed that the fMRI signal is scale-free by analyzing the goodness of fit indices (left PostCG p = 0.25; right AI p = 0.22; right culmen p = 0.23). Thus, PLE is a suitable measure to quantify the scaling exponent of the fMRI signal. 

(2) To further validate the PLE that based on the frequency-domain approach, we applied a time-domain method (DFA) to test for their correlation. As expected, we observed a strong correlation between the two measurements in all the ROIs (for left PostCG, r = 0.722, p = 0.00001; for right culmen, r = 0.804, p = 0.00001; for right AI, r = 0.762, p = 0.00001). 

(3) To test the robustness of our results, we applied different smoothing parameters to determine the PLE values, more specifically by varying Hamming window size (HW = 3, 5, 9 and 15). These analyses showed that the correlation of PLE and task induced activity in Post CG and AI for the anticipation of the animate target was not affected by different HMs (Table  ).   
Statistics of the correlation between the Resting state PLE and task induced activity (Beta) in Left Postcentral gyrus, Right Culmen and Right Insula for the Anticipation of the Animate target and Inanimate target. 
  
HM = Hamming window size; LH = Left Hemisphere; RH = Right Hemisphere. *p < 0.008 after Bonferroni correction for multiple comparisons. 
  


### Conjunction analysis and partial correlations between Narcissistic Grandiosity, Resting State PLE and task induced activity for the anticipation of the animate target 
  
Conjunction analysis showed that right AI activity co-varies with NG both during a resting state (spontaneous activity indexed by PLE) and during task-induced activity (BOLD responses to the anticipation of the animate target) (Fig.  ; t = 7.820; p = 0.00000001). The same analysis using NV as covariates yielded no significant effects (t = 2.750; p = 0.01; uncorrected).   
Conjunction contrast between the anticipation of the animate target vs. baseline with covariate Narcissistic Grandiosity and resting state vs. baseline with covariate Narcissistic Grandiosity. 
  

Since spontaneous activity, task-induced activity and NG score all co-varied in AI, partial correlation coefficients were calculated to provide more insight in their interrelationship. 

Partial correlation yielded a significant positive association between PLE and NG, while controlling for task-induced activity (r = 0.475; p = 0.03; 95% CI Lower: 065 Upper: 0.813; S.E. = 0.189), a significant negative association between NG and task induced activity, while controlling for PLE (r = −0.593; p = 0.006; 95% CI Lower: −0.839 Upper: −0.077; S.E. = 0.203), but no significant association between PLE and task induced activity, while controlling for NG (r = −0.129; p = 0.588; 95% CI Lower: −0.563 Upper: 0.423; S.E. = 0.260) (see Fig.  ).   
Partial correlations model showing the statistic of each correlation controlling for the effect of the third variable in the model. 
  



## Discussion 
  
In the present study, we aimed to investigate whether task activity induced by the anticipation of social behavior (touching an animate target) could be related to the spontaneous activity of the brain during a preceding resting state period, and if this relationship may be mediated by narcissistic traits, particularly NG and NV. 

The main results showed that task-induced activity during the anticipation of the animate target (but not of the inanimate target) in left PostCG and right AI negatively correlated with the degree of LRTCs during a preceding resting state: the stronger the PLE in spontaneous activity in left PostCG and AI, the weaker the BOLD response in the same regions for the anticipation of the animate target (see Fig.  ). Interestingly, neural activity in right AI consistently correlated with NG, both during the resting state (PLE) and during task performance (BOLD responses in anticipation of the animate target). Additionally, NG was found to modulate the relationship between spontaneous and task induced activity in the right AI. These data provide, to our knowledge for the first time, evidence for a relationship between intrinsic brain activity and the anticipation of social interaction as well as for how this relationship could be influenced by personality features.   
Proposed model of the study visualizing the relationship between intrinsic activity brain activity, task induced activity and the modulation by narcissistic traits. In this model the anticipation is considered as a transitional phase between internal and external where the individual is aware of the external stimuli and is generating internally the behavior without realizing any overt action. 
  

With respect to the rest-task relationship, the detected negative relationship between resting state and task-induced activity is consistent with previous studies showing that the temporal structure of intrinsic brain activity during a resting state can provide a predisposition that shapes our interactions with the world . 

Our finding that individuals with stronger LRTC’s in PostCG and AI during a resting state show weaker task-evoked BOLD responses in the same regions during the anticipation of animate interaction, suggests that an individual’s spontaneous brain state defined in terms of LRTC’s might predispose the preparedness for social stimuli in these brain regions. 

The result that only the activity induced by the anticipation of the animate target touch, but not of the inanimate target touch, correlates significantly with the temporal structure of the endogenous brain activity in PostCG and in AI is in line with the idea that other individuals are approached as entities with similar inner experiences as our self . Indeed, PostCG and AI have been associated with the perception of one’s own as well as others’ sensations and feelings . Moreover, behavioral results based on “similarity” and “spontaneous social awareness” ratings of touch performance (see Supplementary Figure  ) showed that there is a significant difference in approaching the other (i.e. the animate target) as an entity with similar characteristics of our self, compared to the mannequin. 

Hence, the detected relationship between the spontaneous activity and task-induced activity in PostCG and AI supports the hypothesis that others’ bodily experiences might be already internally formulated, as something related to one’s own experiences and that sensory and affective circuits contain a memory trace of it . This seems to be in line with the finding that bodily arousal, linked to psychophysiological states, is associated with spontaneous brain activity during the resting state . 

Regarding the relationship between the anticipation and the performance of animate and inanimate touch, PostCG and culmen differentiated between the anticipation of animate and inanimate touch. These regions overlap with those consistently reported in research on sensory anticipation and action prediction . According to research on sensorimotor prediction, such sensory activity anticipating the consequences of an action, like touching, may attenuate activity induced by sensory stimuli . 

Considering this literature, we suggest that a similar predictive mechanism supported by internal simulation may apply to the anticipation of others’ sensations induced by one’s actions . In agreement with this, anticipatory activity in PostCG and culmen showed weaker responses for animate touch anticipation, compared to inanimate touch anticipation, whereas an exploratory ROI-based analysis of BOLD responses during actual touch performance showed the opposite pattern of activity in these regions: increased activity during animate touch performance, compared to the inanimate touch performance. Accordingly, also Gazzola and colleagues  showed increased activity in SI during (passively perceived) affective social touch. Moreover, it is interesting to note that somatosensory activity in SI also supports subjective self-perception induced by tactile stimuli . 

Finally, concerning individual levels of narcissism, our data showed that activation specifically for the anticipation of the animate target negatively co-varies with NG in right AI. As evidenced by a conjunction analysis, also spontaneous activity correlated with NG in the same voxels in AI. Partial correlations were performed concerning the relationships between task-induced and spontaneous activity in this AI cluster, and NG. These correlations indicated that the relationship between neural activity in anticipation of the animate target and spontaneous activity during a resting state in AI is no longer significant when controlling for NG, while task-induced activity during the anticipation of the animate target and spontaneous activity during a resting state in AI independently correlate with NG. 

On the one hand, the positive correlation between NG and LRTC’s in AI during the resting state period may be interpreted as an increased preoccupation for the self, more specifically the bodily and interoceptive self  during a rest/mind-wandering period . For instance, recent imaging studies showed recruitment of the right anterior insula during tasks focusing on the self  . On the other hand, the negative correlation between NG and task activity elicited by the animate target in AI may be interpreted as a consequent reduced activity regarding other individuals. This hypothesis is also supported by the proposed role of AI as part of the salience network  in constituting a crossroad switch between the internal and the external activity of the brain . Fan and colleagues  specifically showed a decreased deactivation of AI during processing of emotional faces in individual high on narcissistic trait. The authors interpreted their data as indicative of an increased of self-focus and disengagement from empathic processing in narcissistic individuals. The present results extend these findings by showing that higher NG may be related to an increased internal predisposition accompanied by a motivation-based disengagement from social processing . 

Thus, these results provide further insight into how personality features may influence brain activity anticipating social interaction. We propose that narcissism could function as a factor mediating between internal processing, related to the self, and external sensory information related to the social world. 

Some limitations of the study have to be mentioned. Firstly, we studied the relationship between resting state fMRI and task-induced BOLD responses . It can be argued that this approach is correlational and not directly addresses rest-task interactions . However, because we were interested in how individual spontaneous brain activity patterns could constitute an a priori predisposition for social behavior, intrinsic activity during an independent resting state could be indicated as a more appropriate measure than pre-stimulus activity or background intrinsic activity during task-performance in this context. Nevertheless, further studies have to address direct rest-task interaction integrating these alternative measures that are highly informative for deepening the interaction between endogenous activity and task-induced responses. 

Secondly, it can be argued that AI is not a region primarily involved in the discrimination between the animate and the inanimate target. However, AI could be specifically related to grandiose (but not vulnerable) narcissistic features during both the resting state and the anticipation of the animate target. Since NG is characterized by self-serving focus and a motivational based disengagement, it could be speculated that this relation expresses a more general disengagement from the external world in high NG participants. Although this might be not primarily related to the qualification of the target, it possibly is more pronounced for social processing . Further studies would be necessary to clarify this issue more directly. 

Thirdly, our sample was not constituted by clinical individuals and further research has to expand this study to clinical samples of pathological narcissism. However, our data lend support to the concept of narcissism as a continuum between healthy and pathological forms reflecting adaptive and maladaptive personality organization, respectively . 

In conclusion, our research sheds a novel light on how social task activity can be related to the spontaneous activity of the brain and how this interaction may be modulated by individual personality differences. Future research will need to expand this study to modalities of social interaction other than touch, and to other relevant aspects of personality which may modulate our way to relate with our self and with other individuals. 


## Electronic supplementary material 
  




 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-23'>
<h2>23. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/18431500/' target='_blank'>18431500</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Cooperation and Deception Recruit Different Subsets of the Theory-of-Mind Network</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2008</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0002023</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/2295259/' target='_blank'>2295259</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social cognition (theory-of-mind: cooperation, deception, cooperation/deception) with healthy adult participants (n=13; age range 22–38, within 18–60). The task required participants to attribute intentions/beliefs while being scanned. The paper reports exploratory whole-brain random-effects analyses (ToM vs non-ToM) and contrasts between conditions with whole-brain results (thresholds and cluster extent provided), although ROI-based follow-up was also performed. Participants had no neurological or psychiatric disorders. This is an original experimental fMRI study (not a review) and does not report data from clinical populations. Therefore it meets all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
The term “theory of mind” (ToM) describes an evolved psychological mechanism that is necessary to represent intentions and expectations in social interaction. It is thus involved in determining the proclivity of others to cooperate or defect. While in cooperative settings between two parties the intentions and expectations of the protagonists match, they diverge in deceptive scenarios, in which one protagonist is intentionally manipulated to hold a false belief about the intention of the other. In a functional magnetic resonance imaging paradigm using cartoons showing social interactions (including the outcome of the interaction) between two or three story characters, respectively, we sought to determine those brain areas of the ToM network involved in reasoning about cooperative versus deceptive interactions. Healthy volunteers were asked to reflect upon the protagonists' intentions and expectations in cartoons depicting cooperation, deception or a combination of both, where two characters cooperated to deceive a third. Reasoning about the mental states of the story characters yielded substantial differences in activation patterns: both deception and cooperation activated bilateral temporoparietal junction, parietal and cingulate regions, while deception alone additionally recruited orbitofrontal and medial prefrontal regions. These results indicate an important role for prefrontal cortex in processing a mismatch between a character's intention and another's expectations as required in complex social interactions. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (41032 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
The term “theory of mind” (ToM) describes both the ability to understand and predict the behavior of other people by making inferences about their mental states, their intentions, feelings, expectations, beliefs or knowledge, and to cognitively represent one's own mental states  . It is widely acknowledged that ToM evolved in hominids in response to the increasing complexity of social interactions, representing a powerful cognitive tool to determine whether or not a conspecific is willing to cooperate and reciprocate  , or tends to intentionally deceive and defect at the expense of others  . In humans, this cognitive mechanism is more or less permanently “online”, to the extent that we sometimes ascribe mental states to inanimate objects such as cars, computers etc  . Given that ToM requires quite large computational resources, it is not surprising that a dysfunction of the ToM mechanism is involved in a variety of neuropsychiatric disorders, including autism and schizophrenia and may cause severely compromised social competence in patients with such conditions  – . 

A number of functional brain imaging studies have revealed that ToM involves an extended neural network located in the frontal, temporal and parietal lobes bilaterally  ,  . Specifically, ToM recruits several cortical midline structures, including the medial prefrontal cortex (MPFC), the anterior cingulate (ACC), and the precuneus as well as lateral areas of the middle temporal lobes (MTL), the temporoparietal junction (TPJ), the superior temporal sulcus (STS) and the temporal poles (reviewed in  ,  – ). The area extending from the anterior cingulate cortex to the anterior frontal pole, particularly the paracingulate cortex, is supposed to be engaged in self-reflection, person perception and in making inferences about others' thoughts  . Furthermore, regions near the temporoparietal junction (TPJ) are thought to be involved in reasoning about the contents of another person's mind  ,  , attribution of a character's actual belief or state of knowledge  ,   and the discrimination between self and others  . Although hemispheric specialisation has been observed, the results are contradictory: while some studies found selective activity in right TPJ  ,  , others showed left TPJ to be necessary for representing other persons' beliefs  ,  . The mPFC and the ACC are thought to help distinguish self from other, to be engaged in error monitoring, and to differentiate salient from non-salient stimuli  ,  ,  . The role of the precuneus is less well known, but this brain area seems to be important for the experience of agency and self-consciousness  ,  . The temporal regions around the STS contain mirror neurons that play a decisive role in imitation and learning as well as in recognition of intentional movements  ,  . In addition, amygdalar, insular and orbitofrontal activity may contribute the affective “tone” to the evaluation of thoughts and intentions  . For example, the insula has been shown to be activated if unfairness is being recognised  . 

A prototypical task used in ToM research has been the ”false belief task”, which requires the subject to predict where a character will look for an object that has been displaced by another character unbeknownst to the first character. While successful performance in this task is considered a milestone in the development of ToM in young children  ,  , it does not entail “higher order” processes in the framework of interpersonal expectations and intentions such as beliefs of a character about the mental states of a third party–which is crucial to determine whether or not a person has an understanding of the intentions of others (i.e. “ I know that X does not know that Y wants to cheat upon him, and that Y knows that X cannot know what Y really intends to do”). 

It is as yet unknown whether an individual's understanding of another person's mental states about cooperative or deceptive intentions of a third party, resulting from false or true interpretations of the third party's actions and behavior, are processed in discrete brain regions of the ToM network. In this study, we therefore sought to examine whether a subject's evaluation of cooperative and deceptive interactions between two or three story characters elicits differential activation patterns within the ToM neural network. 

Accordingly, healthy participants were shown cartoon stories depicting scenarios of cooperation, deception or both; the participants' task was to attribute intentions and beliefs to the protagonists. The stories described either a) situations where one person wants another to cooperate to the advantage of both, b) situations where one person deceives another person, and c) situations where two persons cooperate to deceive a third person. Since the outcome of the scenarios was visible to the participants, the experimental design was suitable to examine the test subject's ability to represent a “true” or “false” belief held by one of the story characters. Moreover, the deception condition overtly signalled unfairness, whereas the cooperation condition clearly depicted reciprocity and fairness. By means of fMRI we investigated whether these concepts draw on different brain regions, i.e. whether the representation of a character's erroneous belief in the (unfair) deception condition recruits different brain regions compared to the mental representation of a character's correct inference of intentions in the (reciprocal) cooperation condition.. In addition, the combined cooperation/deception stories were introduced to determine brain regions commonly activated by the formation of a cognitive representation of both a cooperative and deceitful intention. In an additional baseline condition, we showed the same cartoons in jumbled order, the task of the participants was to answer questions regarding physical properties of the stimuli. 

Since involvement of temporoparietal junction and precuneus in intention and belief attribution has repeatedly been demonstrated, we expected these regions to be activated across all scenarios. In contrast, we hypothesised that the representation of a scenario depicting a character's concealed deceitful intention would recruit additional brain activation  . As a potential candidate for these more complex scenarios we predicted that the medial prefrontal cortex would be more strongly activated due to its involvement in disambiguating information, including discrepancies between one's own expectation and others' (covert) intentions  . Moreover, we expected that limbic and orbitofrontal structures such as the insula would differentially be activated by the deceitful scenario, which was associated with a high level of unfairness. We also assumed that increasing complexity of the social interaction in scenarios describing both cooperation and deception and an interaction of three characters would lead to more widespread brain activation due to the higher processing load involved. 


## Results 
  
### Imaging 
  
We analyzed results by directly contrasting all three types of stories, cooperation (COOP), deception (DEC) and cooperation/deception (COOPDEC) with each other, using a height threshold of p<0.02 and an extent threshold of k = 15. The contrasts were calculated for the ROIs derived from the preceding exploratory whole-brain analysis that compared activation during the ToM tasks with activation during the non-ToM tasks. These ROIs encompassed superior, medial and inferior frontal regions, and ACC, insula, as well as parietal and temporal regions including the TPJ and precuneus. In several of these ROIs, mentalizing about stories with a deception element yielded differential activation from mentalizing about stories with a cooperation element. Other regions were commonly activated by both types of stories, with spatially distinct peaks of activation (see   and  ,  ). 
   Brain activation in frontal, temporoparietal and temporal regions.  
Activation patterns are rendered on the brain surface in the contrasts of stories describing deception (DEC), cooperation (COOP) and both (COOPDEC). n = 13, extent threshold k = 15; height threshold p<0.02. 
     Brain activation in medial frontal, cingulate and parietal regions.  
Brain activation patterns are shown for the contrasts of stories describing deception (DEC), cooperation (COOP) and both (COOPDEC). n = 13, extent threshold k = 15; height threshold p<0.02. 
     Contrasts of the ToM task conditions cooperation (COOP), deception (DEC), and cooperation/deception (COOPDEC) (n = 13; height threshold p<0.02, extent threshold k = 15).        
As expected, stories containing both cooperation and deception elements recruited the largest regions, in comparison to the other conditions. Specifically, brain activation patterns of the stories containing both elements (COOPDEC) tended to show higher BOLD responses in the majority of ToM-activated regions, i.e. in bilateral TPJ, right anterior temporal cortex, left inferior and superior frontal cortex compared to COOP and DEC, respectively. These results suggest that the processing load for the more complex situation depicted in the COOPDEC scenarios might be higher than for the more straightforward one-to one interactions. 

Compared to DEC>COOP, the contrast COOPDEC>COOP showed larger activation in bilateral temporoparietal regions, while both contrasts yielded similar activation in inferior and superior frontal gyrus. Compared to COOP>DEC, the contrast COOPDEC>DEC shows larger activation in inferior frontal gyrus and righthemispheric parietal and temporal regions. 

#### Frontal activation 
  
The results from direct contrasts between stories containing elements of deception or cooperation or both showed differential activation patterns. Participants showed higher medial (lefthemispheric BA 9 and 10) and left inferior frontal (BA 47) activation when mentalizing about stories containing an element of deception compared to cooperation. On the other hand, mentalizing about cooperation alone, but not about the combined cooperation/deception stories, led to higher activation in superior frontal gyrus (lefthemispheric BA 9 and 10) when compared to deception alone. 

Moreover, within stories containing an element of deception, superior and medial prefrontal activation (left hemisperic BA 9) was higher in DEC compared to COOPDEC, while inferior frontal gyrus activation (lefthemispheric BA 47) was higher in COOPDEC than in DEC. 

On the other hand, within stories containing the element of cooperation there was higher activation in left superior frontal gyrus (BA 9) in COOP than in COOPDEC, while the opposite applied in bilateral inferior frontal gyrus (BA 47) and left medial frontal gyrus (BA 32), where COOPDEC stories led to higher activation than COOP stories. A higher activation of COOP in left superior frontal gyrus (BA 10) was also found compared to DEC. 

In general, these results suggest that stories containing a deception element activated predominantly left inferior and medial frontal gyrus. In spatially distinct regions of left superior frontal gyrus, higher activation was found in tasks containing only the cooperation element or the deception element, respectively (see   and  ,  ). 


#### Limbic activation 
  
In left posterior cingulate gyrus (BA 31), both types of stories containing a deception element led to higher activation than stories dealing with cooperation alone, while both types of stories containing a cooperation element led to higher activation in right posterior cingulate gyrus (BA 31) compared to the deception stories. 

Further differentiation between stories was found in right ACC (BA 33) and bilateral posterior cingulate gyrus (BA 23), where the activation was higher for DEC than for COOPDEC, and in left posterior cingulate (BA 30), where activation was higher for COOP than for COOPDEC (see  ,  ). 


#### Temporoparietal junction activation 
  
Both types of stories containing a deception element led to higher activation in left middle temporal gyrus (BA 39) than cooperation alone, while they activate right middle temporal gyrus (BA 39) less than cooperation alone. 

Furthermore, stories containing a cooperation element led to higher activation than DEC in several regions of the TPJ: in left superior and middle temporal gyrus (BA 12, 22, 39) and in right middle temporal gyrus, however, there are no TPJ regions where stories containing a cooperation element commonly show less activation than deception stories (see  ,  ). 


#### Other temporal regions 
  
Right middle temporal gyrus (BA 39) exhibits higher activation regarding stories containing a deception element than mere cooperation stories. Within stories containing deception, some regions in right middle temporal gyrus (BA 21, 37) are activated stronger by COOPDEC than by DEC, while a more superior situated region in left middle temporal gyrus appear to be activated stronger by DEC than COOPDEC (BA 22). 

There are no temporal regions that commonly exhibit higher activation in stories containing a cooperation element compared to deception. However, some temporal regions show differential activation when comparing COOP and COOPDEC, such as left superior temporal gyrus (BA 41), which is activated stronger by COOP than by COOPDEC, while regions in right superior (BA 21, 22) and middle temporal gyrus (BA 37) are activated stronger by COOPDEC than COOP. In general, stories containing a deception element apparently lead to higher temporal activation than those without. In particular righthemispheric middle temporal regions are predominantly involved in deception processing and/or even more in the combination of deception and cooperation (see  ,  ). 


#### Parietal regions 
  
Both types of stories containing a deception element yield higher activation in left precuneus (BA 7) than stories with only a cooperation element, however, when comparing deception type stories with each other, this same region is activated higher in DEC than in COOPDEC stories, and also activation in an adjacent precuneus region (BA 31 left) is higher in COOP compared to COOPDEC. No parietal region shows higher activation in COOPDEC compared to DEC and COOP, respectively. 

It appears that lefthemispheric precuneus BA 7 is activated predominantly when deception has to be processed, while BA 31 seems rather to be involved in processing cooperation. 



### Mean signal intensity 
  
An ANOVA comparing mean signal intensity in left medial (BA 9/10) and inferior frontal (BA 47) gyrus and in left temporoparietal junction (BA 22) in all three ToM task conditions revealed main effects of condition (F(2) = 7.917 p<0.001, region (F(2) = 4.830 p<0.01 and a significant condition*region interaction (F(4) = 9.910 p<0.001). Paired t-tests comparing activation in the same region for different conditions showed significantly higher activation in medial prefrontal cortex during DEC compared to COOP and COOPDEC (t(12) = 2.537 p<0.01 and t(12) = 2.290 p<0.01, respectively); in inferior frontal cortex during DEC and COOPDEC compared to COOP (t(12) = 3.041 p<0.01 and t(12) = 4.005 p<0.001), and in temporoparietal junction in COOPDEC compared to DEC (t(12) = 2.079 p<0.01) and COOP (t(12) = 4.173 p<0.001). T-tests comparing activation in the same condition for different regions showed significantly higher activation in medial PFC than in TPJ for DEC (t(12) = 3.179 p<0.01), and higher activation in TPJ than in inferior frontal gyrus for COOP and COOPDEC (t(12) =  3.726 p<0.01 and t(12) = 2.757 p<0.01) (see  ). 
   Activation in frontal and temporal regions during the different ToM conditions.  
The graph shows the mean signal intensity (+/− s.e.m.) (in arbitrary units) in these regions in the conditions DEC (black), COOP (white) and COOPDEC (grey), respectively. The ANOVA with the factors condition and region showed main effects of condition (F(2) = 7.917 p<0.001, region (F(2) = 4.830 p<0.01 and a significant condition*region interaction (F(4) = 9.910 p<0.001 with significantly higher activation in medial prefrontal cortex during DEC compared to COOP and COOPDEC (t(12) = 2.537 p<0.01 and t(12) = 2.290 p<0.01, respectively); in inferior frontal cortex during DEC and COOPDEC compared to COOP (t(12) = 3.041 p<0.01 and t(12) = 4.005 p<0.001), and in temporoparietal junction in COOPDEC compared to DEC (t(12) = 2.079 p<0.01) and COOP (t(12) = 4.173 p<0.001). Activation during DEC was significantly higher in medial PFC than in TPJ (t(12) = 3.179 p<0.01), and during COOP and COOPDEC significantly higher in TPJ than in inferior frontal gyrus (t(12) =  3.726 p<0.01 and t(12) = 2.757 p<0.01). 
  

### Behavioral measures 
  
Participants performed at ceiling level in the paper-and-pencil ToM story comprehension task that followed the fMRI session. The mean score was 23.0 for answering the ToM questionnaire alone (standard error 0.00) and 59.0 for the ToM questionnaire combined with the sequencing task (standard error 0.00). 



## Discussion 
  
In a functional magnetic resonance imaging paradigm using cartoons showing social interactions (including the outcome of the interaction) between two or three story characters, respectively, we sought to determine whether brain areas of the ToM network would be differentially involved depending on the nature and complexity of the observed interaction. The overall activation pattern observed in our ToM task showing activated regions in temporoparietal junction, precuneus, temporal cortex, cingulate areas, and prefrontal cortex corresponds largely to the findings of previous studies and the general notion of the theory-of-mind network  – . Since story comprehension of cooperative and deceitful scenarios was flawless in all participants, as indicated by the behavioral data, the observed activations most likely reflect adequate belief reasoning in all three task types. When considering the results from contrasting the three task conditions, it can be assumed that an area that is primarily involved in processing deception will most likely show up in the contrast DEC>COOP, but not its opposite, and potentially also in the contrasts DEC>COOPDEC or COOPDEC>DEC. An area primarily involved in processing cooperation should show up in the contrast COOP>DEC, but not its opposite, and potentially also in COOP>COOPDEC or COOPDEC>COOP. 

### Temporoparietal junction, precuneus and posterior cingulate regions are involved in the comprehension of cooperation and deception 
  
Mentalizing about scenarios describing both cooperation and deception (COOPDEC) always showed higher activated areas in the temporoparietal junction when compared to the DEC or COOP conditions alone. Moreover, the opposite contrasts of COOP>DEC and DEC>COOP exhibited activation in TPJ. COOP and COOPDEC tend to activate bilateral TPJ stronger than DEC, with COOPDEC moreover showing higher activation than COOP in these regions. In general, these results correspond to studies reporting temporoparietal activation in ToM tasks requiring belief reasoning  ,  . However, in contrast to lateralized effects found in recent imaging studies on belief reasoning, with right TPJ selectively activated in false belief   and belief attribution during moral judgments  , and the findings from lesion studies implicating left TPJ in belief reasoning  ,  , our results showed bilateral TPJ activation in both cooperation and deception conditions. A possible reason for the disparity of the observed activation pattern compared with previous studies could lie in differences in task requirements. Our stories were designed to force subjects to reason about (cooperative and deceitful)   intentions   of the story characters, whereas the study by Sommer et al. (2007) used stories where the   knowledge   of a story character had to be inferred. Hence, the higher processing demands placed on the ToM network by our task may well have recruited more bilaterally distributed TPJ activation than a standard task requiring comprehension of a false belief about the location of an object.. 

Accordingly, our findings expand upon previous findings on the role of the temporoparietal junction in ToM, suggesting that processing deception, cooperation or both activates bilateral TPJ. 

Precuneus activation was also observed in all contrasts of cooperation, deception, and cooperation/deception compared with the other conditions. These findings correspond to the study by Sommer et al.  , who also found precuneus activation in both false and true belief reasoning about object location. An fMRI study by Ochsner et al.   found left precuneus to be one of the regions activated by attributing emotions to other people and the self, together with posterior cingulate and prefrontal cortex. According to Vogeley & Fink  , the medial parietal cortex-together with medial prefrontal cortex-has a role in taking the first-person perspective and differentiating between actions controlled by the self versus other persons. However, in a PET study by Ruby and Decety  , there was more bilateral precuneus activation when taking a third person perspective than first person perspective. In an fMRI study that compared thinking about physical causality (physical event and its consequences) versus intentional causality (a subject's intentions and its consequences), the precuneus/posterior cingulate cortex was found to subserve reasoning about intentional causality  , a function that usually develops before false belief understanding. In accordance with the literature, our results therefore suggest that in ToM tasks, the precuneus performs a rather broad function, relating to perspective taking as well as attribution and processing of emotions and intentions, that is required for belief reasoning including comprehension of cooperation and intentional deception. 

Another region commonly activated to varying degrees in all contrasts across conditions is the posterior cingulate gyrus /posterior cingulate (BA 23, 30, 31). Posterior cingulate activation has previously been found in theory of mind research when reading stories about social interaction  ,  , in particular reading about a protagonist's thoughts  , and also specifically in tasks focussing on empathy  –here together with anterior cingulate, paracingulate gyrus and amygdala. These results hint at a role for posterior cingulate apparently related to social/emotional processing aspects of ToM, which in our study were present in both forms of belief reasoning. 


### Processing deception additionally recruits prefrontal cortex, insula and anterior cingulate 
  
Mentalizing about a situation involving intentional deception on the part of the acting character and not recognizing the deceitful intent on the part of the passive character additionally activates left orbitofrontal lateral, inferior, and medial frontal cortex, as seen in the contrasts of DEC vs COOP and COOPDEC, respectively, and in the contrast COOPDEC vs DEC. These results indicate that these prefrontal regions might have a central role in processing a mismatch between intentions and expectations of the protagonists, and also in processing emotional aspects of unfairness  . 

Regions in left lateral superior frontal gyrus, however, showed up in all contrasts, suggesting that adjacent, but spatially distinct areas in this region are involved in processing of cooperation and deception, respectively. 

Involvement of different frontal regions in ToM tasks has been observed in previous PET and fMRI imaging studies  ,  ,  ,  ,  . These studies, however, did not specify variations of cooperative or deceitful intentions shown in their tasks, nor did they explicitly request to evaluate expectations and intentions of the protagonists in a social setting. These studies revealed either left  ,   or right   activation of medial frontal and inferior frontal cortex during ToM tasks performance, or right orbitofrontal activation during recognition of mental states  , as well as specific medial frontal activation  . 

One recent neuroimaging study considering belief processing in ToM associated right lateral rostral prefrontal cortex, but not medial prefrontal cortex, with reasoning about a character's false belief  . The authors used a standard false belief task that described hiding and dislocation of objects, which required subjects to predict a behavior without intention attribution–as already pointed out, this constitutes an important difference to our task that may account for differential results. 

Two further studies found activation of medial prefrontal cortex in subjects playing games that involved trust and reciprocity, particularly when cooperative intentions had to be evaluated  ,  . At first sight these findings might seem contradictory to our results of deception-specific medial frontal activation. However, evaluating cooperative intentions also requires checking for a match or mismatch between one's own expectations and the other's intentions-which might include deception. Therefore such a task may be more similar to our deception task than to our cooperation task, where cooperation was evident and needed no additional evaluation in terms of the truthfulness of the cooperative intent. 

Moreover, our results are consistent with lesion studies showing that damage to the medial frontal lobe impaired detection of deception in a ToM task   and caused deficits in “affective” theory of mind, including evaluation of another person's emotional situation  . It is conceivable that these divergent findings on medial and orbitofrontal involvement in ToM reasoning result from different task paradigms that concentrate either on cognitive or affective aspects of the ToM task. In contrast to classic second-order false belief tasks, which require only a cognitive understanding of the difference between one person's knowledge and that of another, our ToM task required both cognitive and affective ToM in true and false belief conditions. Therefore, the higher activation of medial and orbitofrontal prefrontal regions in tasks requiring both the processing of a malicious intent of one character and the ignorance of that intent by another character might well be related to the stronger emotional valence and perception of unfairness in the deception scenario compared to cooperation. 

Interestingly, as shown by Abe et al., orbitofrontal medial PFC has also been found activated when subjects themselves were deceiving another person,  . In combination with our findings, these results indicate a general involvement of this region in deception processing, regardless of whether one's own actions or actions of others are concerned. These findings blend in well with the general role suggested for the anterior rostral medial prefrontal cortex (arMFC)–a region which corresponds largely to the area activated in our deception task-by Amodio & Frith  . Their review suggests that the arMFC is involved particularly in thinking about mental states and intentions–of self and others. 

Orbitofrontal/ventromedial PFC (BA 10/11) and dorsolateral PFC (BA 9/10/46) have also been found to participate in moral judgements  – . Before a moral judgment can be made, the inappropriate and harmful intention of an actor has to be detected and linked to empathetic engagement with the deceived person. In our study, participants did not have to judge the moral implications of the scheming person's behavior, because the outcome of each scenario was evident. Thus, subjects were merely requested to describe the deceiver's intention and the victim's ignorance. It is therefore conceivable that the activation during moral judgment in previous studies results from a more complex process in which a malicious intention has to be detected. Inferior frontal gyrus (BA 47) in ventrolateral orbitofrontal cortex has also been found activated in response to moral and social transgressions  , suggesting that the activation in left BA 47 during deception processing observed in our study may well relate to the moral implications of the depicted events. 

However, orbitofrontal cortex activation has to date rarely been found to be involved in theory of mind  . It has been suggested that orbitofrontal cortex belongs to a system responding to aversive reactions of others and is therefore also activated in intentional or unintentional violations of social norms  . These notions of orbitofrontal cortex involvement in evaluation of moral behavior and violation of social norms loosely correspond to our finding of involvement of orbitofrontal cortex in mentalizing about people who take advantage of the false beliefs of others to transgress social norms. 

Bilateral anterior cingulate regions also showed higher activation in conditions containing a deception element, in particular in the contrast DEC>COOP. These results correspond to those by Sommer et al.  , who found ACC activation in the contrast false vs. true belief. In their comparison of neuronal correlates of ToM and empathy, Völlm et al.   found empathy associated with enhanced activations of paracingulate, anterior and posterior cingulate; thus it might be conceivable that higher activation of anterior cingulate regions during processing of false belief situations relates to empathizing with the deceived character. The left insula region (BA 13) also exhibited higher activation in deception compared to the other conditions. In accordance with the results by Sanfey et al.  , this activation could relate to the perception of unfairness in the deception scenarios. 


### Conclusion 
  
Our results suggest that bilateral TPJ, precuneus, and posterior cingulate are regions involved in belief reasoning and evaluation of both cooperative and deceptive intentions of others embedded in a social interaction, at least if the outcome of the social interaction is directly observable. In contrast, orbitofrontal and medial prefrontal cortex, and anterior cingulate regions seem to be predominantly active during processing of a character's ignorance of a malicious intent against him, and attribution of deceptive intentions to a third party. To the best of our knowledge, this study is the first to further dissect the cognitive architecture of processing cooperation versus intentional deception. Our findings provide evidence for the hypothesis that different processes of ToM, namely the comprehension of cooperation and deception, are associated with different activation patterns of the neural network involved in social cognition. 



## Methods 
  
### Participants 
  
13 healthy participants (mean age 26.46 years, SD 5.3 years, range 22–38 years; 4 male participants, mean age 26.25 years, SD 4.78; 9 female participants, mean age 26.55 years, SD 5.79) without a history of neurological or psychiatric disorder or first-degree relatives with such illnesses took part in this study after giving written informed consent. The protocol was approved by the local ethics committee of the Ruhr-University Bochum. Prior to the experiment, participants received a handout informing them about the MRI procedure and the instructions for the ToM task. 


### Theory of Mind Task 
  
The theory of mind (ToM) task consisted of six different cartoon stories with four pictures each  , showing scenarios of: a) cooperation of two persons depicting reciprocality, b) deception, where one person deceives another person associated with overt unfairness, and c) cooperation of two persons to the disadvantage of a third person,-i.e. two cartoon stories of each type (Examples see  ). In order to compare activation elicited by ToM demands with non-ToM activation, we introduced a control (non-ToM) condition, where the pictures of the stories were presented in jumbled order. 
   Examples of the ToM cartoon stories presented to the subjects.  
Panels show (A) cooperation, (B) deception, and (C) cooperation/deception. (D) shows an example of a jumbled cartoon story presented in the non-ToM condition. 
  
For the purpose of acquiring fMRI data during performance of the task, the cartoon stories were projected onto a screen during the MR scanning session and presented to the participant via a 45° angled mirror fixed on the head coil. The mirror was adjusted to enable each participant to view the screen without having to move the head. Prior to scanning, a test image was displayed on the screen to ensure that the images were in focus and that the participant could comfortably see the pictures and read the questions. All four pictures of a given story were shown simultaneously on the screen, arranged in two rows in left to right order. In each condition (cooperation, deception, cooperation/deception and non-ToM control), at first the cartoon story was presented alone for 15 sec, then two questions were successively superimposed upon the screen (between the first and the second row of pictures) for 12 seconds each. The task of the participant was to regard the story attentively during the first phase and to think about the answer to each question as long as the question was displayed on the screen. 

In the ToM conditions, the questions referred to intentions and beliefs of the protagonists. While one question always referred to the intention of the acting character(s) (e.g. “What does the boy with the red pullover have in mind?”), which could be positive (cooperation) or negative (deception) for the other; the second question pertained to the belief of the reacting character (e.g. “What does the boy in the blue pullover expect from the boy in the red pullover?”), which could be false or true. False beliefs included the incorrect assumption that the other person wanted a positive social interaction (to cooperate, to play, to give a present) or had a problem and needed help. True beliefs correctly assumed a desire for a cooperative social interaction. In the non-ToM control condition, the questions referred to properties of objects displayed on the scene (e.g., “Is the background blue or yellow?”). 

The cartoon stories for the ToM and non-ToM condition were presented alternatingly in a blocked design with a total of 12 phases (6 ToM phases and 6 non-ToM control phases) of 39 sec duration each, always beginning with a non-ToM phase, with conditions of cooperation, deception and cooperation/deception presented in randomized order. Each experimental scanning session had a duration of approx. 7 min 48 secs. 


### Behavioural measures 
  
After the scanning procedure, the participants completed a paper and pencil version of the ToM task. In the first part of this task, the four pictures of each story were presented in a jumbled order and participants had to put them into the correct sequence. For each cartoon story sequenced correctly, subjects received 6 points (max. score 36 points). In addition, 23 open questions pertaining to the mental states of the cartoon characters were given, i.e. the 12 questions from the scanning session plus additional questions. Here each correct answer scored 1 point (max. total 23 points). The maximum total score for sequencing and questionnaire was 59 points (for details, see  ). 


### fMRI Data Acquisition 
  
Data were acquired using a whole body 1.5 T scanner (Magnetom Symphony, Siemens, Germany) equipped with a high power gradient system (30 mT/m/s; SR 125 T/m/s), using a standard imaging head coil. Blood-oxygen level dependent (BOLD) images were obtained with a single-shot SpinEcho-EPI sequence (TR 3000 ms, TE 60 ms, matrix 64×64, field of view 224 mm, slice thickness 3.0 mm, 0.3 mm gap between slices, voxel size 3.5×3.5×3.0 mm). To reduce noise and obtain an adequate signal-to-noise ratio we restrained the subjects' heads in order to prevent head motion, chose a voxel size of 3.5×3.5×3 mm and used a block length of 13 scans ( =  39 seconds) as well as a spatial smoothing algorithm of 6 mm FWHM in the single subject preprocessing. We acquired 30 transaxial slices parallel to the anterior commissure–posterior commissure (AC-PC) line. The area covered by the fMRI scans encompassed the complete cortex area extending from the superior pole of the cortex to the inferior pole of the temporal cortex. Additionally, anatomical images of each subject were acquired using an isotropic T1-3dGE (MPRAGE) sequence (TR 1800 ms, TE 3.87 ms, matrix 256×256, field of view 256 mm, slice thickness 1 mm, no gap, voxel size 1×1×1 mm) with 160 sagittally oriented slices covering the whole brain. 


### fMRI Data Analysis 
  
For preprocessing and statistical analysis of the fMRI data, we used the Statistical Parametric Mapping (SPM) Software, Version 5 (Wellcome Department of Cognitive Neurology, London, UK) implemented in Matlab (Mathworks, Sherbon, MA). The first 5 images of each fMRI session (total 157 images), during which the BOLD signal reaches steady state, were discarded from further analysis. Single subject preprocessing consisted of the following steps: realignment for motion correction, normalization to standard stereotaxic coordinates (MNI coordinates), smoothing at 6 mm  voxels, and first-level single subject data analysis. The acceptable limit of head motion was 2 mm for translational movements and 0.5° for rotational movements. 

To assess the differences between the individual ToM conditions (i.e. cooperation versus deception, deception versus cooperation/deception and cooperation versus cooperation/deception), we performed second-level paired   t  -test analyses by using first-level contrasts obtained for cooperation, deception and cooperation/deception minus the global non-ToM condition. To do this, in a first-level single subject analysis, contrast images were calculated for activation in the ToM conditions relative to the non ToM condition for each participant. The analysis encompassed the complete presentation phases of the cartoons, i.e. both processing of the story and answering the questions. The individual contrast images were then entered into an exploratory second-level random-effects analysis (one-sample   t  -test) of the activation patterns for all subjects, with a liberal threshold of p<0.02 (uncorrected) and with a minimum cluster size of k = 15 voxels-in order to find the areas involved in mentally answering questions requiring theory of mind in general. 

We restricted our further analysis to ToM-relevant areas found significantly activated in this first exploratory analysis comparing all ToM conditions to all non-ToM conditions. These hypothesis-driven regions of interest (ROIs) were identified by extracting activated clusters using the MARSBAR tool  . These clusters encompassed significantly activated regions in left TPJ, BA 21,22 (peak voxel at −58 −40 16), left precuneus, BA 7/31 (peak voxel at −6 −54 36), right Insula, BA 13 (peak voxel at 38 −22 24), left anterior cingulate, BA 33 (peak voxel at −2 6 20), right middle temporal gyrus, BA 21/37/39 (peak voxel at 60 −64 6 and 62 −6 16), bilateral inferior frontal gyrus BA 47 (peak voxels at −46 30 −10 and 40 20 −20), left medial frontal gyrus BA 9/10 (peak voxel −2 62 22) and BA 32 (peak voxel −12 16 50) and left superior frontal gyrus, BA 9/10 (peak voxel at −16 53 34). Using the MARSBAR procedure, box-shaped ROIs were refined based on these clusters by applying the end coordinates in the x,y,z dimensions of the activated areas as corner points of the boxes. To compare the different ToM conditions (cooperation, deception, cooperation-deception) with each other, contrasts within the described ROIs were calculated in a first-level single-subject analysis for each of the conditions separately, in each case compared to the overall non-ToM condition, resulting in three basic comparisons per subject. The resulting contrast images were then entered into second-level random-effects group analyses, i.e. into paired   t  -tests, by means of which we calculated direct contrasts between the activation patterns in all three conditions, resulting in six contrasts (DEC vs. COOP; DEC vs. COOPDEC; COOP vx DEC, COOP vs. COOPDEC, COOPDEC vs. DEC, and COOPDEC vs. COOP). Functional imaging results are reported as   t  -scores with a threshold of p<0.02 (uncorrected) and a minimum cluster size of 15 contiguous voxels. In view of the height threshold chosen, a minimum cluster size of 15 voxels was selected in order to further protect against including areas of spurious activation in our analysis. Maxima of significant activation were transformed into Talairach space  , anatomical labelling was performed using the Talairach Demon database  . 

Mean signal intensities (in arbitrary units) were calculated for all conditions using the MARSBAR toolbox for SPM for several regions of interest that showed activation differences between the task conditions. The resulting mean values for the activated regions were entered in an ANOVA (SPSS 11.5) comparison of the different conditions and regions. 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-24'>
<h2>24. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/27579051/' target='_blank'>27579051</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Neural Modulation in Aversive Emotion Processing: An Independent Component Analysis Study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Comput Math Methods Med</p>
<p><strong>Publication Year:</strong> 2016</p>
<p><strong>DOI:</strong> 10.1155/2016/2816567</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4992784/' target='_blank'>4992784</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study using a Face Matching Task (social/emotional face processing), which is a social-related task. Participants were healthy adults (n=10, mean age 25, within 18–60). The paper reports whole-brain analyses (first-level and second-level SPM whole-brain one-sample t-tests) and ICA whole-brain component maps (FDR-corrected spatial maps), not ROI-only results. No psychiatric or neurological patient groups were included. Therefore it meets all inclusion criteria (fMRI during social task, healthy adults 18–60, whole-brain results) and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Emotional processing has an important role in social interaction. We report the findings about the Independent Component Analysis carried out on a fMRI set obtained with a paradigm of face emotional processing. The results showed that an independent component, mainly cerebellar-medial-frontal, had a positive modulation associated with fear processing. Also, another independent component, mainly parahippocampal-prefrontal, showed a negative modulation that could be associated with implicit reappraisal of emotional stimuli. Independent Component Analysis could serve as a method to understand complex cognitive processes and their underlying neural dynamics. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (32521 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## 1. Introduction 
  
Emotion processing is crucial for social interaction. It has been suggested that both neuronal and behavioral responses are facilitated, whenever emotional faces with negative valence, such as fear or anger, are observed. It has been reported that the perception of affective scary faces indicates the presence of indirect stimuli that could potentially threaten individual integrity [ ]. 

The processing of affective faces of fear has an important social role, because it triggers emotional information capable of provoking a visceral response and thus enabling the necessary actions to preserve physical integrity [ ]. It also allows the detection of other persons' emotional state to modulate our responses during social interaction, by controlling or attenuating conduct; this is due to the human ability to consciously assess emotional stimuli through continuous reasoning and experience labeling [ – ]. 

A brain circuit implicated in emotions' processing has been described; it is composed mainly of the amygdala, anterior cingulate, insula, prefrontal cortex (mainly ventromedial and lateral orbitofrontal portions), and anterior portions of the temporal lobe [ – ]. 

Several paradigms have been used in fMRI studies to assess affective faces processing. Experiments have been reported, going from passive perception of emotional faces to those including conditions where the subject must produce a behavioral response involving decision making; in this case, responses can be either implicit, that is, the selection or judgment about the identity or gender of stimuli, or explicit, where emotions are assessed directly. Consistent findings have been reported in healthy and clinical populations, describing the increase in the BOLD response when aversive affective faces are compared to neutral faces, mainly in the amygdala; frontal regions such as the superior frontal gyrus, medial frontal gyrus, orbitofrontal cortex, and ventromedial cortex; temporal regions including the superior and medial temporal gyrus; other regions such as the fusiform gyrus, insula, anterior cingulate, among other structures [ – ]. 

Processing of aversive faces is also considered a biomarker of negative affectivity, which has been associated with neuropsychiatric pathologies and maladaptive personality traits. In a recent study, it is reported that an affective-cognitive bias (or the tendency to respond faster to a stimulus) facilitated the recognition of fear faces and led to shorter reaction times (compared to neutral faces), which correlated positively with a bilateral increment of ventromedial cortex, left subgenual cortex, and right caudate nucleus activities. This bias was also associated with personality traits such as harm avoidance [ ]. In another study, carried out in a population of heroin-dependent subjects, an increase in the left amygdala activity was observed, when heroin was administered to participants during the fearful face condition; this increase was positively correlated with other measures related to stress [ ]. 

Face Matching Task (FMT) [ ,  ] is one of the most commonly used paradigms to study affective processing; different versions have been adapted, which consider several conditions, but all of them allow the implicit and explicit assessment of affective processing, including aversive emotions, such as fear or anger (see Materials and Methods for the task description). In several studies, mainly based on region of interest (ROI) analysis and small volume correction analysis (SVC), the amygdala has been associated with FMT resolution, especially in aversive conditions [ ,  ]; furthermore, other hyperactive regions besides the amygdala have been observed, such as ventromedial cortex, orbitofrontal cortex, insula, and anterior cingulate in diverse populations of patients with affective disorders, for instance, acute stress [ ], depressive episodes [ – ], and first psychotic episode [ ]. These findings suggest that the performance during FMT can be considered a biological marker of emotional reactivity to aversive stimuli, besides being a consistent endophenotype of genetic susceptibility to the development of affective disorders characterized by emotional hypersensibility [ – ] and of traits such as impulsivity, aggression, and violence [ ]. 

The BOLD signal obtained by fMRI is based on the general linear model (GLM); its traditional analysis presents some limitations: on the one hand, it assumes voxels' independency, which limits the BOLD signal study to massive univariate analysis, which in most cases cannot capture the principle of biological plausibility, namely, the biological mechanism that underlies a process, such as cognitive functioning; on the other hand, it needs a reference model based on the hemodynamic response, which makes the analysis based on GLM less flexible than other approaches [ ]. 

An alternative to study and to characterize the neural networks associated with cognitive processing is functional connectivity; for its study several techniques, generally expressing the statistical dependency on observed data, have been proposed. Among them, Independent Component Analysis (ICA) is a multivariate technique that allows the observed BOLD signals' decomposition into neural networks or independent components (ICs). ICs refer to functionally independent neural networks that are simultaneously activated [ ]. After elimination of noise-related signals and the proper selection, these ICs represent the activity modulation of a set of brain structures that, in the case of fMRI, are time-related either to stimulus presentation or to a given condition. This technique does not depend on a reference model and as a final result allows the analysis of components, instead of voxels; that is, the brain regions represented by each component have a similar response associated with the cognitive process of interest and show temporarily coherent fluctuations [ ]. 

There are only a few studies, where ICA has been applied to observe the neural networks modulation during emotion processing. Escartí et al. [ ] used an auditory paradigm, where they manipulated the words' emotional tone; for a control group they reported four ICs temporally correlated with emotional stimuli, located at temporal, frontoparietotemporal, limbic-subcortical, and occipitocerebelar regions. The limbic-subcortical IC was then compared between schizophrenic subjects with and without auditory hallucinations, and they found a similar behavior between control and nonhallucinating subjects, while schizophrenic patients with hallucinations presented a hyperactivation of this component. 

In another ICA-based study a group of women with borderline personality was compared to a control group. A paradigm including neutral, masked fear and explicit fearful faces was used; the responses' analysis yielded a bilateral component that included the amygdala as a “seed” coactivated with the rostral portion of the anterior cingulate in the explicit fear condition; this functional connectivity was increased for the borderline personality group [ ]. 

Broicher et al. [ ] reported an amygdala IC, which showed coactivations with temporal, frontal, anterior cingulate, and hippocampal and cerebellar regions, under the passive view of intense fear faces videos; the functional connectivity of the amygdala with the aforementioned regions was reduced in a group of temporal lobe epilepsy patients. 

ICA has also helped to describe active networks in basal or resting state conditions; it has been suggested that those networks have a strong contribution for the development of some pathologies. In a study carried out in raped female teenagers, compared to a control group, fearful faces stimuli were used to observe the activity modulation of three networks associated with resting state: frontal-parietal, frontal-cingulate, and default mode network (DMN). The authors reported that the frontal-cingulate network, composed mainly of the anterior insula and anterior cingulate, showed an increased activity in the fear condition, more so in women having suffered a rape event [ ]. Another study in the same direction reported that the structures overlapping DMN (prefrontal medial cortex, ventral anterior cingulate, and precuneus) showed a negative modulation or deactivation to emotional stimuli, which suggests that DMN participates in the monitoring of internal emotional processing [ ]. 

To our knowledge, only one study of functional connectivity using the FMT has been reported. In that work, the time courses corresponding to the amygdala were extracted and correlation maps were computed between these time courses and those corresponding to all the other voxels, with the purpose of describing how the amygdala's activity modulates the rest of the regions when processing aversive emotions. It was reported that the right amygdala activation had a negative modulation on medial and superior frontal regions, anterior cingulate, inferior parietal, precuneus, and cuneus. On the other hand, the right amygdala activity modulated positively the activities of inferior frontal gyrus, insula, and superior temporal and subcortical regions [ ]. 

In summary, the findings about the brain regions implicated in emotional processing have been consistent in the literature. However, few studies have been reported using an approximation of functional connectivity, such as ICA, that captures the principles of biological plausibility, fundamental to understand cognitive processing; that is, it assesses the positive and negative modulations of temporally coherent neural networks. Furthermore, ICA have not been used to analyze responses to the widely used FMT paradigm, which has been suggested as a good biological marker of emotional reactivity and as a reliable endophenotype of genetic susceptibility to the development of affective disorders and maladaptive behaviors. Therefore, the purpose of the present study was to characterize the neural networks implicated in aversive emotional processing measured by FMT, using Independent Component Analysis. We hypothesized that ICs temporally associated with fearful stimuli processing will correspond to brain regions implicated in perception and regulation of aversive emotion stimuli, as well as negative affectivity, such as prefrontal, ventromedial, orbitofrontal, and anterior temporal areas. 


## 2. Materials and Methods 
  
### 2.1. Participants 
  
The sample was composed of ten healthy adults (5 males, 5 females) with a mean age of 25 ± 5.29 years and a mean of 15.5 ± 2.32 years of education (see Table S1 of the Supplementary Material for more details about sample selection available online at   http://dx.doi.org/10.1155/2016/2816567  ). All subjects signed an informed consent; they did not receive economical compensation for their participation; the project was approved by the ethics committee of the Centro Nacional de Investigación en Imagenología e Instrumentación Médica of the Universidad Autónoma Metropolitana. 


### 2.2. fMRI Paradigm 
  
An adaptation of Face Matching Task (FMT) [ ,  ] was developed; in this perceptual task subjects saw a trio of faces and they have to select one of the two faces (top) that was identical to the face in the bottom of the screen, so it was an implicit emotional task in which the subject made a judgment about the identity of the stimulus. Trials were presented in an event-related design. A total of 48 emotional faces (24 neutral, 24 fear) derived from a set of affective emotional faces were presented [ ]. In addition, 24 sensory-motor control stimuli, in which the emotional faces were replaced by scenes of interiors of houses, were presented in an interleaved manner with emotional faces. Each trial was presented sequentially in a pseudorandom order during 2000 ms with an interstimulus interval of 2100 ms. In summary, the fMRI paradigm consisted of three conditions: aversive affect processing (fear), neutral affective processing (neutral), and sensory-motor control (control) ( ). The experimental paradigm was presented by E-Prime 2.0 software (Psychology Software Tools, Pittsburg, PA, USA); stimuli were projected in a BOLD-screen (Cambridge Research Systems); reaction times (RT) were recorded using a two-button response pad (Current Designs). 


### 2.3. Image Acquisition 
  
Structural and functional magnetic resonance images were acquired in a Philips 3T Achieva scanner (Philips Medical Systems) using an 8-channel SENSE Head coil. Functional images were acquired using a Gradient-Echo Planar Imaging (EPI) sequence with the following parameters: TR = 2000 ms; TE = 28 ms; acquisition matrix = 80 × 80; voxel size = 1.87 mm × 1.87 mm × 5 mm; slice thickness = 4 mm; gap = 1 mm; flip angle = 90°; FOV = 128 × 128 mm; 24 axial slices, order of acquisition = interleaved. A 3D T1-weighted structural image was acquired for coregistration with the following parameters: TR = 7.5 ms; TE = 3.7 ms; acquisition matrix = 240 × 240; voxel size = 1 mm × 1 mm × 1 mm; slice thickness = 2 mm; no gap; flip angle = 8°; FOV = 256 × 256 mm. 


### 2.4. Image Preprocessing 
  
Images were preprocessed using Statistical Parametric Mapping software (SPM12,   http://www.fil.ion.ucl.ac.uk/spm/  ) implemented in Matlab 2014b (Math Works, Natick, MA, USA). Functional images were realigned to first volume, slice-timing-corrected, coregistered to structural image, normalized to MNI space with a voxel size of 2 × 2 × 2 mm , and then smoothed with a Gaussian FWHM kernel of 8 mm. 


### 2.5. GLM Analysis 
  
First level analysis for each subject was carried out using SPM12; the three experimental conditions were included as regressors, applying the canonic hemodynamic response function without derivatives. The six motion-correction parameters of each subject were also included in the model. A high-pass filter with a cutoff point of 128 seconds was applied to time series. Statistical images of the following contrasts were obtained with   P   < 0.005 (uncorrected),   k   = 10: face processing activation (neutral + fear > control); fear activation (fear > neutral); fear activation controlled by sensory-motor activity (fear > neutral + control). 

The second level whole-brain analysis was carried out through a one-sample   t  -test using the contrast images obtained in first level analysis, with   P   < 0.005 (uncorrected),   k   = 10. The labeling of coordinates was done according to the stereotactic atlas of Talairach and Tournoux [ ], as implemented in Talairach Client tool [ ,  ]. These results are presented in Table S2 and Figures S1, S2, and S3 of the Supplementary Material. 


### 2.6. Independent Component Analysis (ICA) 
  
ICA was carried out using the GIFT software (  http://icatb.sourceforge.net/  ). The procedure to estimate independent components (ICs) consists of several steps: first, the optimal number of ICs is estimated following the minimum description length criteria (MDL) [ ]. Then a two-step data reduction through principal component analysis is made [ ]. ICs are then decomposed to obtain the final number of components previously estimated through MDL; in the present study this step was carried out using the Infomax algorithm [ ]. An optional step is to test the stability of the estimated ICs via ICASSO [ ]. Then spatial maps of ICs and the associated time courses are calculated using a back-reconstruction approach, considering the results from ICA and data reduction steps [ ]. ICs are normalized to   z  -scores. 

GIFT determines the brain structures associated with each time course using a random factor analysis (one-sample   t  -test) as implemented in SPM8 with a threshold of   P   < 1 × 10  FDR-corrected;   k   = 30. This procedure allows obtaining spatial maps of the functionally connected brain structures in each IC. 

In the present study 29 ICs were estimated via MDL; the Infomax algorithm was used and 20 iterations were carried out using ICASSO method. The number associated with each IC (IC1, IC2,…, IC29) is arbitrary and corresponds to the output of the GIFT platform. 

The ICs of interest are usually selected as follows [ – ]:   
ICs with a stability index <0.9 in ICASSO must be removed; in the present study none of the estimated ICs were eliminated using this criterion. 
  
ICs are spatially sorted according to the templates of gray matter (GM), white matter (WM), and cerebrospinal fluid (CSF) included in SPM8; those ICs whose values of   R   > 0.02 for WM,   R   > 0.05 for CSF, and those whose value of   R   for GM is lesser than that obtained for WM and/or CSF are also discarded. In this study, after performing this step 6 ICs with values of   R   > 0.02 for WM were discarded; no ICs with   R   > 0.05 for CSF were found; and 8 ICs with   R   value for GM less than that obtained for the other tissues were discarded. 
  
The remaining 15 ICs were temporally sorted (multiple regression method) using the model estimation of the first level analysis, to obtain the beta values associated with the experimental conditions (control, neutral, and fear). The beta values represent the modulation of activity of the ICs temporally associated with the onset of the event convolved with the hemodynamic response. The modulation could be positive or negative, which corresponds, respectively, to activation or deactivation patterns during the stimulus processing. 
  


### 2.7. Statistical Analysis 
  
Reaction times and number of correct responses were analyzed using SPSS 20 software (SPSS, Chicago, IL). The number of correct responses was not normally distributed (  P  s < 0.05, Shapiro-Wilk) and therefore it was analyzed using a Friedman test for related samples. The pairwise comparisons were analyzed using the Wilcoxon signed-rank test for related samples, and a level of   P   < 0.05 was adopted. Reaction times were normally distributed (  P  s > 0.05, Shapiro-Wilk) and were analyzed using a repeated measures ANOVA; “condition” was included as within-subjects factor with three levels (control, neutral, and fear); a level of   P   < 0.05 was adopted. 

The statistical analysis of ICs was carried out as follows: because the remaining 15 ICs were normally distributed (  P  s > 0.05, Shapiro-Wilk), a repeated-measures ANOVA for each IC was carried out, to detect those ICs that were differentially implicated in each condition, as within-subject factor “condition” was included with three levels (control, neutral, and fear). Afterwards another repeated-measures ANOVA for each IC was carried out, to detect the differences in the modulation between neutral and fear faces, as within-subjects factor “condition” was included with two levels. These analyses were carried out using SPSS 20; a level of significance of   P   ≤ 0.05 was adopted. 



## 3. Results and Discussion 
  
### 3.1. Behavioral Performance 
  
The number of correct responses (CR) between conditions was statistically different (  P   = 0.001, Friedman) in all cases. In the control condition, subjects were more accurate (CR = 23.8 ± 0.42), followed by the fear condition (CR = 22.8 ± 0.63) and finally the neutral condition (CR = 21.5 ± 1.17). Pairwise comparisons indicated that all conditions were different (control versus neutral   P   = 0.005; control versus fear   P   = 0.020; neutral versus fear   P   = 0.023, all Wilcoxon). 

A principal effect of “condition” on reaction time was found (  F   = 20,399,   P   < 0.000). The subjects responded faster in the control condition (reaction time = 967.4 ± 201.35 ms), followed by the fear condition (reaction time = 1057.2 ± 215.25 ms) and finally the neutral condition (reaction time = 1207.69 ± 297.92 ms). According to the results of pairwise comparisons, all conditions were different from each other. 

Increases in accuracy and decreases in reaction times associated with fearful faces processing concur with previous reports indicating that the shift of attentional focus is manipulated during emotional processing in tasks similar to FMT [ ]. The speed to process aversive emotional stimuli (fear) has been interpreted as a cognitive-affective bias to categorize fearful stimuli, even in healthy populations. It has been suggested that this bias is related to personality traits such as harming avoidance, which has been associated with no clinical traits of anxiety [ ]. In the present study one of the inclusion criteria was to have normal levels of anxiety according to the Beck Anxiety Inventory; therefore, this speed in the categorization of fearful stimuli may be associated with a more cautious personality of our subjects, which does not imply a risk factor for the development of mood disorders [ ]. 


### 3.2. ICA Results 
  
The comparison of the ICs in the 3 conditions (control, neutral, and fear) allowed detecting that modulation of IC2 was different between conditions (main effect of condition:   F   = 4.5,   P   = 0.025). Pairwise comparisons indicated that the difference was between control and fear conditions (  P   = 0.003); this component showed a negative modulation during the fear condition. The “Write Talairach Table” function implemented in GIFT with the default options was used to detect regions with a strong negative modulation within IC2. Due to the functionally connected brain regions, the IC2 was named as “parahippocampal-prefrontal” ( , Figures   and  ). 

This analysis, in which the sensory-motor control condition was included, allowed observing that the negative modulation of IC2 “parahippocampal-prefrontal” included structures involved in emotional face processing. It should be noted that in pairwise comparisons the fear condition was different from the control condition; however, the neutral condition also had a negative modulation, without being different from the other two conditions, suggesting that this negative modulation could be associated with the processing of emotional facial stimuli. It is worth noting that it has been reported that neutral faces processing shares the neural substrate of nonneutral emotional conditions, with the only difference that what defines the neuronal differential response in these brain structures is the sensitivity, depending on the emotional conditions [ ,  ,  ]. It has also been reported by whole-brain analysis that neutral conditions are not different from those of fear [ ], suggesting that neutral faces processing involves some emotional contribution. 

Since our aim was to characterize functionally connected brain networks during aversive processing and given that the only difference between the neutral and fear condition was the expressed emotion, the neutral condition represents a more subtle control condition for fear processing; therefore beta values were obtained by multiple regression of both conditions. The repeated-measures ANOVA showed a significant component related to the aversive emotional processing (IC4) (main effect of condition:   F   = 5.99,   P   = 0.037). This component presented a pattern of positive modulation during aversive emotional processing; the corresponding network included frontal, limbic, occipital, temporal, and cerebellar regions, so it was named “cerebellar-medial-frontal” ( , Figures   and  ). 

Results obtained from comparing neutral and fear conditions showed a positive modulation in a network predominantly cerebellar-medial-frontal, which also included activations in temporal regions. Activations in regions such as parahippocampal, frontal, and fusiform gyrus are according to the findings reported in paradigms of face emotional processing and recognition in passive view [ ], shifting of the attentional focus [ ], and implicit emotional tasks [ ]. Specifically, our results are consistent with those reported using FMT in aversive emotional conditions (faces of fear and anger) against a motor control task (geometrical shapes) [ ,  ]. 

It is noteworthy that studies which have used the FMT have methodological differences in the contrasts between conditions. Traditionally, reported results are based on activations to aversive emotions (fear + anger) compared with control tasks that involve the pairing of geometric shapes. One of the advantages of using the FMT is its potential value as a biomarker of disorders and behavioral traits associated with negative affectivity [ ,  ,  ,  – ]. It has been suggested that the processing of faces of fear plays an important role in social interaction, as it allows modulating the behavioral response by observing the emotional state of the other [ ]. In this sense the negative affect is more related to fear: fear stimuli cause states of distress and this is perceived by the observer, facilitating socioemotional adaptive responses [ ]. Therefore, we believe that adapting the FMT to a condition of fear and making a direct comparison with the neutral condition allowed us to detect the neural network that may be more associated with negative affectivity. 

On the other hand, previous studies of FMT have focused on the amygdala activation, using ROIs and SVC analysis, reaching very consistent results regarding the role of the amygdala in the aversive emotional processing [ ,  – ]. In this sense, our results were not according to the differential activation of the amygdala between neutral and fear conditions; this may be due to differences in the analysis used in previous studies and the present study. 

Seed studies based on ICA and FMT have yielded interesting results. Seed analysis is based on the extraction of the time course of a ROI, which is associated with the presentation of a stimulus; correlation maps are then obtained between the time courses of the remaining voxels and the time course of the ROI [ ]. By using seed analysis amygdala activation in aversive emotion conditions has been reported; this activation modulated the functional connectivity in brain structures, included in the medial-frontal-occipital IC4 reported in this study [ ,  ]. Therefore it is probable that the analysis used in the present study is sensitive enough to detect the modulation of other regions outside the amygdala that are involved in the aversive emotional processing. Other studies of ICA and FMT have focused on the modulation of resting state such as the DMN and frontocingulate network, concluding that the modulation reported in these networks can be a good indicator of emotional reactivity and internal emotional monitoring [ ,  ]. It is interesting that the stimuli used by Cisler et al. [ ] are fearful faces and that the activity of frontocingulate network has been associated with the interoceptive sensory integration, suggesting that the increase in activity in conditions of fear is associated with the development of adaptive responses. 

One of the structures that showed a temporally coherent modulation during the fear condition within the IC4 was the superior temporal gyrus. This region in its anterior portions is anatomically connected with the orbitofrontal cortex and the amygdala [ ,  ], and it has been reported that alterations in structural connectivity between these regions may predispose to behaviors related to alterations in emotional processing, such as violence [ ]. The superior temporal gyrus, in animal and human models, has been implicated in socioemotional processing [ ,  ] indicating that the anatomical and functional integrity of this structure is essential for social interaction, since it allows modulating acceptable social responses. 

In fMRI studies about the processing of abstract concepts that define social behaviors, activations have been reported in anterior regions of the right superior temporal gyrus in healthy subjects [ ]; this is relevant as it has been proposed that the knowledge of these social actions, together with the emotional recognition and expression, is critical to establishing and maintaining relationships [ ,  ]. 

Other structures within the IC4, whose modulation in the fear condition was of interest, were those belonging to the cerebellum. Through ICA it was possible to detect that these regions are functionally connected with other corticosubcortical regions involved in emotional processing. The regulatory role of the cerebellum in the higher functions such as emotional processing has been previously described; in fact it has been described that cerebellar lesions produce significant clinical alterations in emotional processing and social skills [ – ]. In a recent study of functional connectivity in resting state, it was suggested that violent behavior, characterized by abnormalities in emotional processing, is related to dysfunction in a cerebellum-prefrontal cortex neural network, which was differentially connected between control and violent groups [ ]. This evidence in resting state, together with the results of positive modulation and cerebellar functional connectivity within IC4 of the present study, suggests that the cerebellum is involved in emotional processing. 

Another interesting finding was the negative modulation of IC2 which, as mentioned previously, includes regions involved in emotional processing. 

ICA allows decomposing the observed BOLD signal into independent components; however, a limitation of this technique is the accuracy to detect which state of the cognitive process or which feature of the stimulus is associated with each time course [ ]. In order to understand the type of modulation of the ICs of interest (i.e., IC4 had a positive modulation in the fear condition while IC2 presented a negative modulation to facial stimuli), the coefficients of temporal correlation between the onsets of fear and the time courses of these two components were reviewed. We observed that the correlation of the positively modulated IC4 was higher than the correlation of the negatively modulated IC2 (  r   = 0.1;   r   = 0.07), which may indicate that the activity observed in these components may be associated with different aspects of the emotional processing. That is, positively modulated IC4 could be associated with the perception and integration of emotional stimulus, while negatively modulated IC2, that was less temporally correlated with the onset of fear stimulus and included structures associated with emotional processing, may be associated with regulatory processes of emotion. In this sense it has been reported that the training of reappraisal skills decreases the response to stimuli that provoke emotional reactivity in brain regions involved in facial emotional processing [ ]. In behavioral studies it has been suggested that reappraisal of emotional stimuli is present even in an implicit way; that is, a high level of emotional awareness is not necessary to reduce emotional reactivity [ ]. It is likely that the sample of the present study, that was composed of healthy subjects, has an implicit mechanism of reappraisal of emotional stimuli that could be expressed as a negative modulation in active regions during processing of emotional stimuli. 

As a limitation of the present study we refer to the phenomenon of reappraisal of emotional stimuli as a possible mechanism that may be related to the negative modulation of IC2. In future studies it would be interesting to make an experimental design to evaluate this phenomenon directly. One of the strengths was the modification of FMT including fearful stimuli, which are more directly associated with negative affectivity. As previously mentioned, the FMT has been considered a good biological marker of this personality trait. 



## 4. Conclusions 
  
In summary, the results of the present study allowed us to observe that there are temporally coherent neural networks whose modulation, positive or negative, contributes to a complex phenomenon such as emotional processing. Through different statistical strategies we were able to disentangle some aspects of the emotional processing and also to detect differential modulation within brain structures implicated in both facial and emotional processing. 

ICA has advantages in the decomposition of the observed BOLD signal and has an important clinical value to detect functionally connected neural networks during cognitive processing. We believe that, from the perspective of brain function, ICA captures many of the theoretical principles about biological plausibility, resulting in more efficient modeling of the neural dynamics. 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-25'>
<h2>25. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/30430680/' target='_blank'>30430680</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Sex differences in own and other body perception</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Hum Brain Mapp</p>
<p><strong>Publication Year:</strong> 2018</p>
<p><strong>DOI:</strong> 10.1002/hbm.24388</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6587810/' target='_blank'>6587810</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study in healthy adult participants (N=30, mean age 26) who performed a body-perception task involving self–other judgments (a social-cognitive/self-referential task). Imaging used whole-brain analyses (FSL FLAME mixed-effects, MNI registration, whole-brain cluster correction reported); results are not limited to ROI analyses. Participants were screened as healthy (no neurological/psychiatric disorders reported). The paper is an original empirical study (not a review/meta-analysis). Therefore it meets all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Own body perception, and differentiating and comparing one's body to another person's body, are common cognitive functions that have relevance for self‐identity and social interactions. In several psychiatric conditions, including anorexia nervosa, body dysmorphic disorder, gender dysphoria, and autism spectrum disorder, self and own body perception, as well as aspects of social communication are disturbed. Despite most of these conditions having skewed prevalence sex ratios, little is known about whether the neural basis of own body perception differs between the sexes. We addressed this question by investigating brain activation using functional magnetic resonance imaging during a Body Perception task in 15 male and 15 female healthy participants. Participants viewed their own body, bodies of same‐sex, or opposite‐sex other people, and rated the degree that they appeared like themselves. We found that men and women did not differ in the pattern of brain activation during own body perception compared to a scrambled control image. However, when viewing images of other bodies of same‐sex or opposite‐sex, men showed significantly stronger activations in attention‐related and reward‐related brain regions, whereas women engaged stronger activations in striatal, medial‐prefrontal, and insular cortices, when viewing the own body compared to other images of the opposite sex. It is possible that other body images, particularly of the opposite sex, may be of greater salience for men, whereas images of own bodies may be more salient for women. These observations provide tentative neurobiological correlates to why women may be more vulnerable than men to conditions involving own body perception. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (46863 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## INTRODUCTION 
  
The neurobiology of identity and self‐concept is currently a hot topic among neuroscientists, and emerging data suggest that it is mediated by specific cerebral networks. One fundamental facet of identity is gender. While certainly influenced by cultural and other environmental factors, gender identity is, nevertheless, foremost shaped by the perception of one's own body and its sex characteristics. Yet, we know very little about how our brain processes identification of self in the context of the sex of one's body. How does our brain distinguish own body from other bodies? Are there specific neural networks for processing recognition of the sex of the body? Are there sex differences in how cerebral networks process recognition of the physical sex in relation to self? 

Self‐other distinction, crucial for human social interaction, relies mainly on the visual perception of the own and another person's body (Longo, Azañón, & Haggard,  ). This process can be viewed as a composition of three components: (1) those involving sensory perception of own body, (2) the specific perception of body ownership, and (3) the integration of own body into the concept of self. Neural regions, within more extended networks, specialized in visual body perception include the fusiform body area (FBA) and extrastriate body area (EBA), which are specialized in human body and body parts perception (Downing & Peelen,  ; Downing, Jiang, Shuman, & Kanwisher,  ; Peelen & Downing,  ; Schwarzlose, Baker, & Kanwisher,  ). The EBA and FBA, especially on the right side, were found to be involved in   own   body representation (Peelen & Downing,  ) and to show stronger responses after viewing pictures of one's own body compared to that of a same‐sex other (Vocks et al.,  ). These brain regions thus provide important self‐other information at a perceptual level of representation. Perception of body ownership primarily requires intact function of the temporo‐parietal junction (Limanowski & Blankenburg,  ). Higher order social cognition (e.g., mentalizing), self‐other distinction, and (own) body representation requires recruitment of cortical midline structures: the medial prefrontal cortex (mPFC), anterior and posterior cingulate cortex, and precuneus (Northoff & Bermpohl,  ). 

More specifically, the ventral and rostral medial prefrontal cortices (mPFC) have been shown to be involved in self‐relative to other‐evaluations and in affective processing of self‐relevant information. (Amodio & Frith,  ; Denny, Kober, Wager, & Ochsner,  ; Murray, Schaer, & Debbané,  ; van der Meer, Costafreda, Aleman, & David,  ). In contrast, the dorsal mPFC was suggested to be involved in the evaluation and decision‐making process of whether a certain stimulus is applicable to the self or to another person, and was associated with judgments about dissimilar others (D'Argembeau,  ; D'Argembeau et al.,  ; Denny et al.,  ; Mitchell, Macrae, & Banaji,  ; Murray et al.,  ; van der Meer et al.,  ). The posterior cingulate and precuneus areas have been associated with autobiographical and semantic memory retrieval about physical aspects of own body, may be responsible for integration of self‐relevant emotional information, and have been found to be important for self‐other differentiation (Northoff & Bermpohl,  ; Ruby & Decety,  ; van der Cruijsen, Peters, & Crone,  ; van der Meer et al.,  ). Of particular interest are findings in the precuneus cortex because this region is tightly connected with networks processing visual and pheromonal stimuli, and sexual arousal (Berglund, Lindström, & Savic,  ; Cavanna & Trimble,  ; Zhang & Li,  ). In concert with the cortical midline structures, activation in the (anterior) insula has consistently been associated with own body awareness and ownership, integration of internal affective bodily states, and with self and familiar face processing (Craig,  ; Kircher et al.,  ; Mega, Cummings, Salloway, & Malloy,  ; Tsakiris,  ; Tsakiris, Hesse, Boy, Haggard, & Fink,  ). 

Distortions of one's body image, including those that might arise during body perception, and impairments in social cognition are core symptoms of several psychiatric conditions, such as anorexia nervosa, body dysmorphic disorder, autism spectrum disorders, and in a subset of individuals with schizophrenia (American Psychiatric Association,  ; Beilharz, Castle, Grace, & Rossell,  ; Farrell, Lee, & Shafran,  ; Gardner & Brown,  ; Krumm, Ferraro, & Ingvalson,  ; Madsen, Bohon, & Feusner,  ; Priebe & Röhricht,  ; Röhricht & Priebe,  ; Ropar, Greenfield, Smith, Carey, & Newport,  ; Smeets, Smit, Panhuysen, & Ingleby,  ). Notably, several of these conditions show skewed sex ratios. Whereas, for example, autism spectrum disorders are more common in males than females, with a sex ratio of about 3:1 (Loomes, Hull, & Mandy,  ), eating disorders are much more prevalent in females (Hudson, Hiripi, Pope, & Kessler,  ; Keski‐Rahkonen & Mustelin,  ). Body dysmorphic disorder, on the other hand, has almost equal prevalence in males and females (Buhlmann et al.,  ; Koran, Abujaoude, Large, & Serpe,  ; Rief, Buhlmann, Wilhelm, Borkenhagen, & Brähler,  ). A direct link between gender and own body perception also represents the hallmark of gender dysphoria, a condition gaining increasing public attention. Gender dysphoria, termed “Gender Incongruence” in the latest ICD11 criteria of the World Health Organization (  https://icd.who.int/dev11/f/en#/http%3a%2f%2fid.who.int%2ficd%2fentity%2f411470068  ), is characterized by a perceived incongruence between a person's gender identity and his/her sex assigned at birth (DSM‐5, American Psychiatric Association,  ). This is possibly due to a disturbed own body perception with respect to gender identity (Burke, Manzouri, Dhejne, et al.,  ; Burke, Manzouri, & Savic,  ; Feusner, Dervisic, et al.,  ; Feusner, Lidström, et al.,  ; Manzouri, Kosidou, & Savic,  ). Gender dysphoria has traditionally been regarded to have a male (sex assigned at birth) predominance, although this has been questioned more recently (Steensma, Cohen‐Kettenis, & Zucker,  ; Zucker,  ). 

Whether and how own body perception differs between men and women is not known, although it has been hypothesized that women may be more sensitive to information about the own body image than men (Mitchison et al.,  ; Powell & Hendricks,  ). One of the few studies describing sex differences in brain activations upon viewing distorted images of one's own body (appearing with different degrees of thinness or fatness) found that women showed activations in the amygdala and prefrontal areas, suggesting more complex cognitive emotional processing, whereas men had activations in the primary and secondary visual streams, similar to object and spatial visual processing (Kurosaki, Shirao, Yamashita, Okamoto, & Yamawaki,  ). Shirao et al. ( ), investigating sex differences in brain activations during perception of negative body image related words, found amygdala activations in women, but hippocampal and prefrontal brain activations in men, suggesting a more cognitive rather than emotional processing of body image stimuli in men. 

Despite vivid discussions about the representation of one's own body image in the brain (Guterstam & Ehrsson,  ; Schauder, Mash, Bryant, & Cascio,  ; S Vocks et al.,  ; Wiebking et al.,  ), surprisingly little is known about the neural representation of sex or gender, thus how our brain processes perception of the sex of others' bodies in relation to self, and whether this process differs between men and women (Pavlova,  ). This issue is of special interest considering that the visual system is central for social communication, for example, for sexual attraction and partner selection. In line with this, sex differences in brain activations during body motion processing have been reported, with females showing increased activations in regions known to be involved in social cognition (Anderson et al.,  ; Pavlova, Sokolov, & Bidet‐Ildei,  ). In addition, perception of one's own in relation to another body's sex may contribute to self‐referential processes, for example, when comparing oneself to others of the same sex (“appearance competition”) (Jackson,  ). However, to the best of our knowledge, no study to date has investigated the neural correlates of gender identity, and sex differences in the perception of another person's body in the context of self. 

We therefore developed a body perception task paradigm (Feusner, Dervisic, et al.,  ; Feusner, Lidström, et al.,  ) in which male and female participants viewed photographs of their own body, same‐sex other bodies, opposite‐sex other bodies, and sets of bodies that were morphed in increments between own body and same‐sex and opposite‐sex other bodies. For each image, the participant rated the degree that the body appeared like them: “To what degree is this picture you?” Based on previous reports, we expected to find sex differences in brain activation during   own   body perception, such that women would show stronger activations in limbic brain regions (Kurosaki et al.,  ; Shirao et al.,  ). Furthermore, we expected that both men and women during own body perception and during the perception of bodies similar to their own (i.e., same‐sex other bodies) would recruit brain areas suggested to be involved in self‐referential processing and bodily self‐consciousness (Craig,  ; Ionta, Martuzzi, Salomon, & Blanke,  ; Northoff,  ; Northoff et al.,  ), such as the ventral mPFC and insula, in addition to regions involved in body perception in general (EBA and FBA). During perception of opposite‐sex bodies we predicted to find “other”‐related activations such as in the dorsal mPFC, precuneus, and TPJ (D'Argembeau et al.,  ; Eddy,  ; Van Overwalle,  ). Our paradigm allowed us to additionally test the novel question of whether brain activation patterns differ depending on the sex of the viewed body, independently of how that body was identified in relation to self, for instance, when the viewed body was of the opposite or same sex as the perceiver's but was in both events labeled as “not me.” 


## MATERIALS AND METHODS 
  
### Participants 
  
We enrolled 30 healthy participants (15 males, 15 females, mean age 26 ± 3.5 years) who performed the body perception task while we acquired functional magnetic resonance imaging (fMRI) data to measure brain activity. Participants were recruited via flyers and advertisements around the campus of The Karolinska Institute. Participants had no self‐reported neurological or psychiatric disorders and were not taking any psychotropic medications. The study was approved by the ethical committee of The Karolinska Institute (application number Dnr 2011/281–31/4) and each participant provided signed informed consent before entering the study. 


### Body perception task 
  
Participants were photographed from the front with a Nikon D90, 18–105 mm f/3.5–5.6 G ED VR camera, fixed on a tripod. Lightning, contrast, and luminance were identical during each photo session. Each participant wore a skin‐colored, skin‐tight, full body unitard, and was positioned against a wall in an identical manner. The purpose of using a full‐body unitard was to best approximate the view of one's own and other bodies in the nude while avoiding the discomfort of being photographed undressed. In addition, it eliminated any differences in skin tone that would have otherwise occurred from morphing images of participants' bodies to others' bodies. Hands, feet, and head in the photos were cropped, and the photos were then morphed with photos of five other male and five other female bodies acquired in an identical manner using FantaMorph Software, version 5.0 (Abrosoft  http://www.fantamorph.com/  ). Each participant's picture was morphed separately with pictures from five different female and five different male participant morph targets to degrees of 20%, 40%, 60%, 80%, and 100%, respectively (producing a total of 50 different morphed images). The “100%” images were simply unaltered photos of another person. We also included the unmorphed (0% morphed) picture of each participant (Figure  ). 
  
Examples of a scrambled image and a male's body images morphed, from left to right, to 20%, 40%, 60%, 80%, and 100% to the same (denoted by positive morph degrees) and the opposite (denoted by negative morph degrees) sex. Note that “100%” photographs were unaltered images of another person [Color figure can be viewed at   http://wileyonlinelibrary.com  ] 
  
The total number of morph conditions was thus 11: the unmorphed 0% and images morphed 20%, 40%, 60%, 80%, and 100% to the same sex and 20%, 40%, 60%, 80%, and 100% to the opposite sex. Images were also presented over two different presentation durations: short (0.5 s) and long (2 s) durations). We present results from trials of the long 2 s duration in the main text and results from trials of the short 0.5 s duration, as well as comparisons of the two presentation durations in the supplement. 

In each experiment, 15 repetitions were presented per morph percentage and for each of the two presentation durations, totaling 330 (15 × 11 × 2) experimental trials. Experimental trials were intermixed with 30 (15 for each of the short and long presentation durations) “scrambled” control images, created by phase scrambling an unmorphed body image using a Fourier phase randomization procedure (Näsänen,  ). Here, an image's phase spectrum is replaced with random values, keeping the amplitude spectrum of the image unaltered. Global low‐level properties (i.e., luminance, contrast, color distribution, and spatial frequency spectrum) of the original image are preserved while the shape information of the image is entirely degraded. Scrambled images were also shown at two different presentation durations, 2 s and 0.5 s, and there were a total of 30 scrambled image trials. 

Participants were instructed to respond as quickly as possible, rating the presented picture based on the degree to which it appeared like them, with the specific question “To what degree is this picture you?” Participants were instructed to press response button box keys 1 to 4, 1 corresponding to 0%–25% “me,” 2 to 25%–50% “me,” 3 to 50%–75% “me,” and 4 to 75%–100% “me.” Before starting the experiment, participants performed a practice session inside the scanner to ensure task comprehension. 

Using Presentation version 18.1 for stimulus delivery, trials appeared in randomized order across 3 runs of 9.5 min each, acquiring 280 volumes per run. There was a 1 min break between runs. Each run began with an instruction screen, followed by a fixation cross for 30 s. Each trial consisted of (a) an image presentation for either 0.5 s or 2 s, followed by (b) the appearance of a response screen for 1 s with button press options, followed finally by (c) a fixation cross for a jittered inter‐trial interval of 1–11 s. We used optseq2 (  http://surfer   .  http://nmr.mgh.harvard.edu  /optseq/), a genetic algorithm, to create jittered presentation timing with the highest efficiency. The presentation of images was balanced and randomized with respect to degree of morph and presentation time. 


### Body localizer task 
  
As an additional control condition and to localize those areas in the brain responsible for the specific processing of human bodies, participants performed the   body localizer task  . Participants viewed 16 alternating blocks (24 s duration) of images of either others' male or female clothed bodies (8 blocks) or chairs (8 blocks). A 10 s fixation screen was interspersed between every set of 4 blocks. To keep participants actively engaged in the task they were asked to press a button any time the exact same image (of either a chair or a body) would be presented twice in a row. 


### MR data acquisition 
  
Magnetic resonance imaging data was acquired on a 3 Tesla MRI scanner (Discovery 3 T GE‐MR750, General Electric, Milwaukee, WI). Functional MRI of both the body perception and body localizer tasks was performed with a gradient echo pulse sequence using a voxel size of 3.03 × 3.03 × 3.5 mm (TE = 30 ms, TR = 2000 ms, FoV = 23 cm, 41 bottom up interleaved axial slices, 3 mm thickness, 75° flip angle) and a 32‐channel head coil. 3D T1‐weighted Spoiled Gradient Echo pulse sequence (SPGR) images were acquired with 1 mm  isotropic voxel size (TE = 3.1 ms, TR = 7.9 ms, TI = 450 ms, FoV = 23 cm, 176 axial slices, 12° flip angle) using an 8‐channel coil. 


### Behavioral data analysis 
  
Sample characteristics and behavioral data of the fMRI task were analyzed using SPSS Statistics 21 (SPSS Inc., Chicago, IL). 

We calculated a   Self‐Perception Index   (Feusner, Lidström, et al.,  ) by multiplying the value of a participant's “self” rating (from 1 to 4) with the degree of morph. This degree of morph was 0 for the unmorphed image and was positive when images were morphed to the same‐sex other body (20%, 40%, 60%, 80%, 100%) and negative when images were morphed to the opposite‐sex other body (−20%, −40%, −60%, −80%, −100%). These weighted values were averaged for each participant and then divided by the number of rated images. Thus, greater positive values would indicate higher average “me” ratings for images morphed to a high degree to the same sex and greater negative values would indicate higher average “me” ratings for images morphed to a high degree to the opposite sex. Values closer to zero, on the other hand, would indicate higher average “me” ratings for images that were only slightly morphed from their own image. 

Furthermore, male and female participants were compared with respect to their ratings of “self” when viewing their own bodies compared to bodies morphed to either the same‐ and opposite‐sex (80% and 100%, and −80% and −100% morph degrees, respectively) to evaluate possible sex differences in self‐perception. 


### MR data analysis 
  
Data analysis was performed using FEAT (fMRI Expert Analysis Tool) version 5.0.8, part of FSL (FMRIB Software Library  http://www.fmrib.ox.ac.uk/fsl  ) (Jenkinson, Beckmann, Behrens, Woolrich, & Smith,  ). BOLD sequences were motion‐corrected (using the FMRIB linear image registration tool, MCFLIRT) and spatially smoothed (using FEAT) with a smoothing kernel of 5 mm. Portions of subject runs with notable movement greater than a maximum displacement of 1.5 mm were truncated if they occurred at the beginning or end of the run to minimize the effect of movement. An average of 59 TRs per run was truncated from 7 different runs of 6 subjects (3 female and 3 male controls) on account of movement. Functional images were registered to the participant's T1‐weighted image (using the FMRIB nonlinear image registration tool, FNIRT) after brain extraction using BET (implemented in FSL) with a fractional intensity threshold of 0.3. Images were then registered to the MNI‐152 brain for group analysis (using FNIRT). Higher‐level analysis was carried out first using Fixed Effects modeling to combine the three acquired runs per participant followed by a second higher‐level analysis using FLAME 1 (FMRIB's Local Analysis of Mixed Effects) for cross‐subject comparisons (Beckmann, Jenkinson, & Smith,  ; Woolrich,  ; Woolrich, Behrens, Beckmann, Jenkinson, & Smith,  ). We thresholded   z  ‐statistic group map images using a cluster‐forming threshold of   Z   > 2.3 and a corrected cluster significance threshold of   p   = .05. Cluster   p  ‐values were determined using a spatial smoothness estimated in FSL. In addition, to further explore the extent of sex differences in (own) body perception observed, contrasts directly comparing activations of men and women were explored at a lower threshold of   Z   > 2.0,   p   < .05, corrected. 

Our first set of questions was whether there are any sex differences in the perception of (1) one's own body, and (2) other bodies of the same or opposite sex, derived from images morphed 80% and 100% to same and opposite sex, respectively. Male and female participants were thus compared for the following contrasts: for (1) [own body (morphed 0%) – scrambled image]; for (2) [same‐sex other body (morphed 80–100%) – scrambled image], and [opposite‐sex other body (morphed 80%–100%) – scrambled image]. 

Our second set of questions was whether there are any sex‐differences in the processing of other bodies in contrast to one's own body, and if this would be affected by whether the other body is of same or opposite sex. We compared male and female participants, therefore, using the following contrasts: [same‐sex other body (morphed 80%–100%) – own body (morphed 0%)] and [opposite‐sex other body (morphed 80%–100%) – own body (morphed 0%)]. 

Finally, we sought to understand the neural correlates of cognitive self‐perception, utilizing participants' own behavioral measures of similarity to self as a parametric measure when viewing images morphed to either the same or opposite‐sex. Participants' responses to the question “To what degree is this picture you?” when viewing   any morphed   image (images morphed from 20% to 100%, excluding the unmorphed image of self) were parametrically modeled on a scale from 1 to 4 (see description of   Body Perception Task   above) and demeaned. Images morphed to the same‐sex and those morphed to the opposite‐sex were treated separately. This resulted in two continuous variables (for the same vs. opposite sex morphs, respectively) centered at 0, with higher values representing greater identification with “me.” In this way, neural processes involved in self‐perception could be separated from differences in perceiving same‐sex and opposite‐sex bodies of others. 



## RESULTS 
  
Sample characteristics and self‐perception indices are presented in Table  . Male and female participants did not differ in mean age or mean scores for handedness, and all participants identified as heterosexual. Self‐perception indices were positive for both groups, indicating, as reported earlier (Feusner, Dervisic, et al.,  ), self‐identification for images morphed to the same sex. Results from trials of the long 2 s duration are presented below, and the short 0.5 s duration results can be found in the supplement. Males' and females' ratings of self‐perception did not differ significantly at any morph degree (Figure  ). 
  
Sample characteristics and self‐perception indices 
      
Average morph ratings for men and women for each degree of morph. Ratings ranged from 1 (0%–25% “me”) to 4 (75%–100% “me”). Positive values indicate percentage morphed to the same‐sex, whereas negative values indicate percentage morphed to the opposite‐sex. Error bars indicate standard errors of the mean. There were no significant differences between groups at any morph degree [Color figure can be viewed at   http://wileyonlinelibrary.com  ] 
  
Despite the groups being of equivalent age, we reprocessed the analyses for all contrasts of the Body Perception Task, as presented below, using age as a covariate of no interest. The results were very similar as when age was not accounted for, and therefore are presented in the supplement (see Supporting Information Tables   and  , please compare to Tables   and  ). 
  
Brain (de)activation for the contrast own body perception (0% morph condition) > scrambled image (control condition) in men and women 
      
Sex‐differences in brain activation 
    
### Body localizer task 
  
As has been shown in previous studies, the   body localizer task   resulted in significant (  Z   > 2.3,   p   < .05, corrected) bilateral activation in areas specialized for body perception, in both males and females. These areas included bilateral lateral occipital cortices (EBA), temporal occipital fusiform gyri (FBA), precuneus, left angular gyrus, bilateral precentral gyri, and the right amygdala in males (see Supporting Information Table  ). When comparing males and females, males showed significantly (  Z   > 2.3,   p   < .05, corrected) greater activation in the bilateral motor cortex and superior frontal gyri (Table  ). 


### Own body perception 
  
On account of an error, one male participant did not see images of his own body but rather another participant's body during the scan. This participant was therefore excluded in all analyses involving   own body  . 

Contrasting perception of one's   own body   (0% morph) with the   scrambled   image baseline revealed significant (  Z   > 2.3,   p   < .05, corrected) activation in both men (N = 14) and women (N = 15) in the bilateral lateral occipital cortex, including the EBA, dorsal medial PFC, bilateral frontal operculum/anterior insula, caudate nucleus, and thalamus. There were no significant differences between groups (Supporting Information Figure   and Table  ). Both males and females showed right dominant deactivation in the precuneus, posterior cingulate, TPJ (bilateral, but right‐dominant middle temporal gyri, angular gyri, supramarginal gyri), right temporal pole, and fusiform gyri (Table   and Supporting Information Table  ). 


### Same‐sex other body perception 
  
Contrasting perception of   other bodies of the same sex   (80–100% morph) with the   scrambled   image baseline revealed significant (  Z   > 2.3,   p   < .05, corrected) activation in both (N = 15) men and (N = 15) women in the bilateral inferior lateral occipital cortices (EBA), fusiform cortices (FBA), bilateral caudate nucleus, thalamus, bilateral anterior insula, ventrolateral PFC, and dorsal mPFC, anterior cingulate cortices, and bilateral cerebellar hemispheres (Supporting Information Figure  ). In both groups, there was deactivation of the bilateral TPJ (middle temporal gyri, angular gyri, supramarginal, gyri) (Supporting Information Table  ). When comparing males and females, males showed significantly (  Z   > 2.3,   p   < .05, corrected) greater activation in the left superior lateral occipital cortex. Using a slightly more lenient threshold of   Z   > 2.0,   p   < .05, corrected, revealed additional, stronger activation in the precuneus cortex of males. The latter effect, however, was due to greater   de  activation in this area in females during perception of same‐sex other bodies (Table   and Supporting Information Table  ). 

Contrasting perception of other bodies of the   same sex   (80%–100% morph) with one's   own body   (0% morph) revealed significant (  Z   > 2.3,   p   < .05, corrected) activation only in males in the bilateral temporal occipital and fusiform cortex (EBA, FBA), left precentral gyrus, and left ventrolateral PFC (Figure  ). Women showed no significant differences in activation between perception of the own body and perception of other females' body. Although there were no significant differences between females and males at the   Z   > 2.3 threshold, lowering the threshold to   Z   > 2.0 revealed that men had significantly greater activation in the bilateral FBA and bilateral lateral occipital cortex (EBA) (Table  , Figure  ). 
  
Brain activation in men (blue‐light blue color) and women (red‐yellow color) when viewing images of (a) a same sex other body and (b) an opposite sex other body, contrasted to images of the own body, respectively, and (c) when viewing images of the own body contrasted to images of an opposite sex other body; MNI coordinates of the slices shown: (a)   x   = 30,   y   = −48,   z   = −14; (b)   x   = 4,   y   = −54,   z   = −12; (c)   x   = 4,   y   = 24,   z   = −4; R = right, L = left; color bars indicate   z   value of the presented contrast 
    
Sex differences in activation, with men (M) showing greater activation than women (F) when viewing images of (a) a same sex other body and (b) an opposite sex other body, contrasted to images of the own body, respectively; MNI coordinates of the slices shown: (a)   x   = −42,   y   = −66,   z   = −2; (b)   x   = 6,   y   = −74,   z   = 10; R = right, L = left; color bars indicate   z   value of the presented contrast 
  

### Opposite‐sex other body perception 
  
Contrasting perception of other bodies of the   opposite sex   (80%–100% morph) with the   scrambled   control images revealed significant (  Z   > 2.3,   p   < .05, corrected) activation in both men and women in the bilateral lateral occipital cortex including the EBA and FBA, and the right dorsolateral PFC. Both groups showed significant deactivation in the angular and supramarginal gyri. Women, in addition, showed deactivations in the precuneus and left frontal pole. Direct comparison of men and women revealed significantly greater activation in men in the bilateral EBA and FBA, precuneus, left middle temporal gyrus, right‐TPJ (angular, superior temporal, and supramarginal gyri), and left frontal pole (Supporting Information Figure   and Table  ). Using a slightly more lenient threshold (  Z   > 2.0,   p   < .05, corrected), men showed additional stronger activations compared to women in the bilateral caudate nucleus and left inferior frontal gyrus (Table  ). 

Contrasting perception of other bodies of the   opposite sex   (80%–100% morph) with one's   own body   (0% morph) revealed no significant (  Z   > 2.3,   p   < 0.05, corrected) activations in women, whereas in men there was significant activation in the (pre)cuneus cortex, bilateral TPJ (supramarginal, superior temporal, angular gyri), and right middle temporal gyrus (both anterior and posterior parts) (Figure  ). The direct group comparison revealed significantly stronger activations in men than in women in the bilateral precuneus, supra‐ and intracalcarine cortices, and lingual gyri (Figure  ). With a threshold of   Z   = 2.0,   p   < 0.05, corrected, men showed additional greater activations than women in the bilateral caudate nucleus and left accumbens, frontal pole, right‐TPJ (supramarginal, middle temporal, superior temporal, angular gyri), and the bilateral anterior insular cortices (Table  ). 

By contrast, women showed pronounced deactivation (i.e., greater activation to their   own   bodies compared to opposite sex bodies) in the bilateral anterior insula, right anterior cingulate cortex, left cerebellum, left postcentral gyrus, left precuneus, and bilateral (though right‐dominant) TPJ (Figure  c). Deactivations (activation to their   own   bodies more than to opposite sex bodies) in males were detected in the bilateral anterior cingulate gyri, right ventrolateral PFC, right‐anterior insula, and right‐superior parietal lobule (Figure  c). Thus, greater activations in response to own body compared with opposite sex bodies were observed in both men and women, but more pronounced in women. This indicates that the sex difference pattern in regions such as the anterior insula and right TPJ was driven by greater activation to own bodies than opposite sex other bodies in the women, rather than greater activation for opposite sex other bodies in men. 


### Response‐dependent perception of images morphed to same‐sex and opposite‐sex other bodies 
  
When viewing images morphed to the   same sex   (20%–100%), participants' ratings of greater self‐similarity (greater “me” rating) was significantly (  Z   > 2.3,   p   < 0.05, corrected) associated with activation in the left postcentral gyrus in both males and females. Participants' ratings of greater self‐similarity (greater “me” rating), when viewing images morphed to the   opposite sex   (20%–100%), was significantly (  Z   > 2.3,   p   < .05, corrected) associated with activation in the bilateral insula, anterior cingulate, and paracingulate in both males and females. 

By contrast, participants' rating of less self‐similarity (greater “not me” rating) of images morphed to the   same sex   (20%–100%) was significantly (  Z   > 2.3,   p   < .05, corrected) associated with activation in the precuneus and bilateral middle frontal gyri only in females. There were no significant associations for “not me” ratings in males. Participants' ratings of less self‐similarity (greater “not me” rating) when viewing opposite‐sex other bodies were significantly (  Z   > 2.3,   p   < .05, corrected) associated with activation in the bilateral TPJ and precuneus in both men and women. Men in addition showed significantly (  Z   > 2.3,   p   < .05, corrected) associated greater activations in the vmPFC and bilateral anterior temporal gyri. When males and females were directly compared regarding associations to greater “not me” ratings, males had significantly (  Z   > 2.3,   p   < .05, corrected) stronger associations in the bilateral amygdalae, precuneus, and posterior cingulate (Table  ). 

As noted above, brain regions that were associated with participants' ratings of self‐similarity (whether greater “me” or “not me” rating) differed when participants were viewing either the opposite or same‐sex—suggesting that the activation could be perceptually driven. To further investigate this possibility, we directly contrasted viewing of opposite versus same sex images in a combined group of males and females when parameterized to greater “not me” rating. Here, greater   “not me”   ratings when viewing bodies of the   same sex   versus the opposite sex were significantly (  Z   > 2.3,   p   < .05, corrected) associated with activation in the bilateral insula, bilateral vlPFC, right dlPFC, anterior cingulate cortices, left thalamus, and left cerebellum. By contrast, greater   “not me”   ratings when viewing bodies of the   opposite sex   versus the same sex were significantly (  Z   > 2.3,   p   < .05, corrected) associated with activation in the bilateral lateral occipital cortex (EBA), precuneus/posterior cingulate cortex, vmPFC, and left‐FBA, providing further evidence that the pattern of activation could be perceptually driven (Table   and Figure  ). 
  
Brain activation for parametrically modeled greater “not me” rating while viewing images morphed to the same versus opposite sex 
      
Across male and female participants, parametrically‐modeled “not me” ratings when viewing images of same sex and opposite sex other bodies of different morph degrees; red color = activation for the contrast “opposite sex – same sex bodies rated as ‘not me’”; green color = activation for the contrast “same sex – opposite sex bodies rated as ‘not me’”; MNI coordinates of the slices shown:   x   = 6,   y   = −66,   z   = 6; R = right, L = left; color bars indicate   z   value of the presented contrast 
  


## DISCUSSION 
  
The current study investigated whether cerebral processing of the perception of one's own body and of other bodies in the context of self differs between men and women. Perception of own, unmorphed bodies showed no sex differences, and involved activation of a set of brain regions previously described to be associated with perceptual recognition of self as well as during perceptual decisions about object identity (Ploran et al.,  ). This included body perception regions (EBA, FBA), and areas involved in self‐referential processing, such as the medial PFC, anterior insula, and thalamus (Amodio & Frith,  ; D'Argembeau,  ; D'Argembeau et al.,  ; Denny et al.,  ; Mitchell et al.,  ; Murray et al.,  ; van der Meer et al.,  ). Furthermore, activation of bilateral caudate nuclei was observed, congruent with previous reports about its involvement in processing of body and limb posture (Villablanca,  ). Finally, there was deactivation of the precuneus, right temporal pole, and both TPJ‐regions known to be involved in self‐other distinction, mentalizing, and perspective taking (Eddy,  ; Payne & Tsakiris,  ; van der Cruijsen et al.,  ). We also found activation in the cerebellum during own body perception, which is in line with a study describing its inclusion in a neuronal network underlying illusory own‐body perceptions (Schutter, Kammers, Enter, & Van Honk,  ). 

In sum, own body perception in the context of self involves cerebral processes related to one's own body schema, identification of self, as well as the specific distinction and comparison of self from and with others. Importantly, these processes do not seem to differ between men and women. 

Interestingly, and to the best of our knowledge not described earlier, during perception of   other bodies of the same   sex (contrasted to the   scrambled image  ), men and women engaged very similar brain areas as when viewing their own body, including the EBA, FBA, bilateral caudate, thalamus, bilateral anterior cingulate cortices, bilateral anterior insula, ventrolateral PFC, and dorsal mPFC. This was true also for the deactivation pattern (TPJ, temporal pole), with the only exception that it was more right‐lateralized in women than in men (Eddy,  ). 

One possible explanation for this similarity is that self‐referential information may be experienced and generalized to others who look similar to us (Platek, Krill, & Kemp,  ; Tsakiris,  ). It was also suggested that coactivation of the reward system and the dorsal anterior cingulate cortices during evaluation of self compared to others might contribute to the integration of social comparisons into evaluation of self (Lindner et al.,  ). Interestingly, an fMRI study (Lübke et al.,  ) that used body   odors   rather than visual body stimuli found very similar brain regions involved during perception of others' (males and females) body odors—the fusiform cortex, the anterior and posterior cingulate cortices, and the anterior insular cortex. 

As opposed to the “own, unmorphed body” condition, viewing another body of the same sex revealed a sex difference, with men having a more pronounced activation than women in the left lateral occipital cortex, which could be an indication of heightened attention towards same‐sex others. There was also a sex difference in the precuneus cortex, due to greater   de  activation of this region in female participants, implying that women might have less of self and same sex other differentiation compared to men (see further discussion). 

Notably, these sex differences in   same‐sex other   body perception became even more apparent when   contrasted to the own body   (0% morphed, rather than scrambled image). Whereas in female participants there was no significant difference in brain activation during own body and same‐sex other body perception, (there was a stronger   de  activation of the EBA), in male participants there was an increased activation of the FBA, left precentral gyrus and left ventrolateral PFC–when viewing another same sex body compared to the own body. A recent study showed that these latter brain areas were involved in decoding familiarity (of faces, bodies, and gait) (Hahn & O'Toole,  ). It may thus be possible that men show increased engagement, together with higher attentional load, in cognitive decision processes on differentiating between self and same‐sex others. This potentially could be evoking intrasexual competition (Buunk & Massar,  ) and/or could help to discern what is related and similar as opposed to different from self. Moreover, the sex differences in neural activations during perception of bodies similar to one's own may indicate that women more easily adopt other female bodies as “self” than men. This is also supported by the observed cerebellar activations during own and same‐sex other perception specifically in females, which have been reported to be involved in illusory own body perception (Schutter et al.,  ). Thus, our findings may be interpreted as that women may more easily be able to put themselves in other females' shoes, which require Theory of Mind (ToM), the ability to explain and predict other people's mental states, and cognitive empathy. Indeed, several previous studies have suggested sex differences in mind reading abilities as well as empathy (Adenzato et al.,  ; Frank, Baron‐Cohen, & Ganzel,  ; Krach et al.,  ; Schulte‐Rüther, Markowitsch, Shah, Fink, & Piefke,  ; Singer & Lamm,  ). 

A third major observation in this study related to perception of bodies of the opposite sex. When compared to the   scrambled image  , both men and women activated general as well as body perception‐specific attention circuits (EBA, FBA, right‐dorsolateral PFC). However, and notably, sex differences were most pronounced when contrasting viewing bodies of an opposite sex other to the   own body   (unmorphed image). The two groups differed distinctly in that men activated, whereas women   de  activated the precuneus and right TPJ. In addition, during viewing an opposite sex other body and when rating an image of their body that appeared female (morphed to the opposite sex) as “not me,” men showed activation in the visual cortex, caudate nucleus, precuneus, and bilateral amygdala, regions reported to be involved in other rather than self‐orientation (Bischoff et al.,  ; Eddy,  ), sexual arousal (Ponseti et al.,  ), and emotional salience (Gerber et al.,  ; Phan et al.,  ). 

Together, these data hint that the other body in relation to self might have a greater salience in men (van Hooff, Crawford, & van Vugt,  ), whereas for women images of the own body are more salient. The observed sex differences may have implications when trying to understand conditions involving own body perceptions such as anorexia nervosa, gender dysphoria, or autism spectrum disorders, which all show a sex skewed prevalence. Females previously were found to be more sensitive to information about their own body than males (Mitchison et al.,  ; Powell & Hendricks,  ), and therefore perhaps have a less distinct or a more vulnerable own body schema, rendering them more prone to internalized distorted perceptions of their own bodies. Females may also easier adopt other females' bodies as “self” and, conversely, do not accept the image of one's body as “self.” Worth mentioning is that all the participants were heterosexual, thus the discussion only pertains to heterosexual cis‐gender persons. 

In addition to investigating whether men and women engage different cerebral networks during perception of own and other bodies in the context of self, we also approached this at a different level: when distinguishing self from others, does the brain show differences depending on whether it is viewing the same or the opposite sex? To investigate this, we directly contrasted rating “not me” of same sex versus rating “not me” of opposite sex bodies. Here, greater   “not me”   ratings when viewing   same sex   bodies compared with opposite sex bodies was significantly associated with activation in regions involved in (illusory) own body perception and comparative processes (Kedia, Mussweiler, & Linden,  ). Yet, the same   “not me”   ratings but when viewing   opposite sex   bodies compared with same sex others did engage (body) perceptual and evaluative regions (Kedia et al.,  ). This suggests that the activations were dominated by perceptual—the type of visual body stimuli—rather than cognitive processes, since the latter was same in both cases: rating “not me.” 

Interestingly, and in support of this notion, a neuroimaging study using body odor stimuli from either the sisters or same‐sex best friends of a group of 12 women, showed that, independently of conscious recognition, olfactory‐based kin recognition activated self‐referential brain regions when smelling body odors of their sisters as compared to their female friends (Lundström, Boyle, Zatorre, & Jones‐Gotman,  ). In that study, kin recognition, via the mechanism of so‐called “automatic self‐referent phenotype matching” (Mateo & Johnston,  ), recruited self‐referential networks without any cognitive or conscious identification process involved. Together with the current study, these observations suggest that sensory body perception (visual or olfactory) seems to overrule cognitive perception (i.e., labeling a given body as “me” or “not me”), which was previously shown for other stimuli of high social and ecological importance, such as body odors, emotional faces, and infant crying and laughing sounds (Lundström, Boyle, Zatorre, & Jones‐Gotman,  ; Morris, Öhman, & Dolan,  ; Seifritz et al.,  ). Whether this overruling of sensory over cognitive perception also applies to other stimuli remains to be further investigated. 

Our findings should be viewed in light of its limitations. First, we did not assess participants' impression of the body stimuli afterward outside the scanner in terms of how attractive the opposite‐sex, or same‐sex body stimuli were perceived. It is possible that the male participants considered the opposite sex stimuli as more attractive than did the female participants, which might partially explain our findings of stronger attention and reward‐related brain activation in men for this condition. In addition, this information would have helped to establish more direct links between the activation patterns and cognitive/evaluative processes other than the subjective degree that the body was similar to theirs, about which we could only make post hoc inferences. We also did not obtain any ratings from independent raters of how similar the morph‐to stimuli bodies were to the participants' bodies and did not measure participants' body weight or body mass index. It may have theoretically been possible, by chance, that the female morph‐to bodies used were better comparable, in terms of, for example, height, weight, shape, or muscularity, to those of the female participants than how the male morph‐to bodies compared to the male participants' bodies. This might have affected the sex differences we observed in the same‐sex other versus own body condition. However, this is mitigated partially by the fact that based on the investigators' subjective impression, none of our participants had extremely different body composition than the morph‐to stimuli bodies; for example, none appeared obese or extremely underweight. Finally, though only (self‐reported) healthy participants were included, we did not perform a structured assessment of any prior or current eating disorder (or other psychiatric disorders). Therefore, we cannot rule out that there may have been (if the participants were unaware or did not report accurately) any disturbances in body image or possible concerns about the own body, that might have resulted in own‐body stimuli being much more emotionally salient and that might have been more common in one of the groups. 

In conclusion, we provide first evidence that the neural representation of own body does not differ appreciably between the sexes. In contrast, perception of other bodies, in particular of the opposite sex, could be a particularly salient social signal to men, whereas for women the own body likely has higher relevance. 


## CONFLICT OF INTERESTS 
  
The authors have no conflict of interest. 


## Supporting information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-26'>
<h2>26. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/28455517/' target='_blank'>28455517</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Neural Activity while Imitating Emotional Faces is Related to Both Lower and Higher-Level Social Cognitive Performance</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Sci Rep</p>
<p><strong>Publication Year:</strong> 2017</p>
<p><strong>DOI:</strong> 10.1038/s41598-017-01316-z</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5430668/' target='_blank'>5430668</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Study reports task-based fMRI in healthy adults (ages 18–55) performing a social-related task (imitate/observe emotional faces). Participants were screened healthy (SCID, urine tox) and no psychiatric/neurological disorders included. Whole-brain analyses were performed (spatio-temporal PLS across the whole brain with voxel-wise bootstrap ratios and a corroborating whole-brain GLM in SPM8; results presented as whole-brain voxel patterns in MNI space). Not a review/meta-analysis, and not an ROI-only study. All inclusion criteria met and no exclusion criteria violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Imitation and observation of actions and facial emotional expressions activates the human fronto-parietal mirror network. There is skepticism regarding the role of this low-level network in more complex high-level social behaviour. We sought to test whether neural activation during an observation/imitation task was related to both lower and higher level social cognition. We employed an established observe/imitate task of emotional faces during functional MRI in 28 healthy adults, with final analyses based on 20 individuals following extensive quality control. Partial least squares (PLS) identified patterns of relationships between spatial activation and a battery of objective out-of-scanner assessments that index lower and higher-level social cognitive performance, including the Penn emotion recognition task, reading the mind in the eyes, the awareness of social inference test (TASIT) parts 1, 2, and 3, and the relationships across domains (RAD) test. Strikingly, activity in limbic, right inferior frontal, and inferior parietal areas during imitation of emotional faces correlated with performance on emotion evaluation (TASIT1), social inference - minimal (TASIT2), social inference - enriched (TASIT3), and the RAD tests. These results show a role for this network in both lower-level and higher-level social cognitive processes which are collectively critical for social functioning in everyday life. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (34238 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Social interactions are complex processes which are built upon the perception and understanding of the actions, intentions, and mental state of others. Social cognitive neuroscience has suggested a dichotomy between low-level processes such as understanding motor actions or emotional processing and higher-level processes such as inferring the mental states of others (e.g. theory of mind) or detecting deception and sarcasm. This apparent dichotomy between lower level and higher level social cognitive processes is supported by behavioral , neuroimaging  and lesion studies . Neuroimaging studies have primarily examined these processes with two approaches: using tasks relevant to the perception of and interaction with other people’s actions (action observation and imitation), and using tasks relevant to infer the beliefs and desires of the other person (mentalizing). Lower level social cognitive processes such as action interpretation have been associated with activation of a lateral frontal-parietal network, the putative human analogue to the mirror neuron system observed in monkeys . Higher-level social cognitive processes, such as theory of mind, have been associated with activation of cortical midline regions, including the medial prefrontal cortex, posterior cingulate cortex, and precuneus, as well as temporoparietal junction and temporal pole. This network is also known as the ‘mentalizing’ system. Dual processing models have been proposed in which the lateral fronto-parietal network supports relatively automatic processes such as identifying motor actions while the mentalizing network supports controlled processes of attributing actions to complex social causes . 

Most neuroimaging studies examining the lateral fronto-parietal network have made use of hand actions or other forms of simple motor stimuli . As such, the role of this system has been mainly considered in the context of perceiving gross motor actions. Some have taken the concept of mirroring one step further, by arguing that the lateral fronto-parietal network is important for emotional empathy by permitting humans to feel what others feel, and potentially to assess or interpret emotional cues and social behaviour . Investigating this issue may be best served by paradigms utilizing socially relevant stimuli as opposed to simple motor acts. One such paradigm is the imitation and observation of emotional faces, which has been shown to activate the lateral fronto-parietal ‘mirror’ network . This is consistent with the notion that activation of this network can play a role in allowing people to empathize by imitating emotions . Activity in the right IFG has been positively correlated with self-report measures of empathy in healthy children , and has been shown to be more active in normally developing children than those with autism , with activity in autistic children inversely correlated with social impairment. However, the IFG has also been implicated in some higher level social cognitive processes, specifically the inhibiting self-perspective in social judgements . Recent work has also shown structural changes in right fronto-parietal cortex in more socially impaired people with schizophrenia , a group of individuals in whom higher-level social cognitive processes such as theory of mind are more prominently affected . These findings raise the question of whether neural activation during basic mirroring tasks is related to higher-level social cognitive abilities. 

Meta-analysis of fMRI data has shown little overlap between activity in the brain regions associated with the mirroring and mentalizing systems across a range of tasks , and brain lesion studies have suggested a dissociation between mirroring and mentalizing regions . As such, mirroring and mentalizing were initially thought to represent dichotomous systems which function relatively independently, and the role of mirroring in higher-level social cognition is a contentious issue . However, there is a growing body of evidence that the mentalizing and mirroring systems may interact during more complex social cognitive processing, such as watching social videos . Co-activation of mentalizing and mirroring regions has also been noted when viewing agents performing irrational actions, suggesting aspects of the mentalizing system may facilitate interpreting unexpected actions . The mirroring and mentalizing system may work together during social cognitive processing, although a specific role of the mirror system in higher-level cognitive processing has yet to be established. 

The purpose of this study is to determine whether brain regions activated during a facial emotion mirroring task are related to lower-level social cognitive performance, higher-level social cognitive performance, or both. We utilized a process specific social mirroring task (the facial imitate/observe task ) inside the fMRI, along with a battery of objective out-of-scanner social tests ranging from basic emotional-perception tasks to complex higher level social cognitive tasks such as detection of lies or sarcasm. Brain-behavior relationships were examined using the spatio-temporal partial least squares (PLS), a non-parametric multivariate approach . PLS identifies latent variables (LVs), linear combinations of fMRI signal amplitude at each voxel across time and a design matrix which can consist of either experimental conditions or correlations across conditions with behavioral scores. Each LV expresses a pattern of the common covariance between the design and the fMRI data. PLS is designed to handle data with high collinearity while simultaneously capturing essential non-redundant relationships among the data , overcoming the confounding influence of collinear variables in traditional multiple regression . This makes PLS an excellent approach to uncover relationships between brain activity and a set of social cognitive scores which are likely highly interrelated. We hypothesized that a) consistent with previous studies, imitating emotional faces would activate the mirroring network, more prominently in the imitate than the observe condition, and b) neural activity during imitation of emotional faces specifically (rather than imitating neutral faces or observing faces) would be associated with both lower-level and higher-level social cognitive performance. 


## Results 
  
### Task Effects 
  
Task PLS is a multivariate model-free approach to identify spatial patterns which share relationships across the experimental conditions. A task PLS was run on the data to replicate previous task-based analysis, and examine the underlying pattern of task task-evoked spatial activity. PLS generated 6 LVs (as there were three trial types, emotional faces, neutral faces, and fixation, and two conditions, Imitate and Observe). Permutation analysis (see methods below) showed significance (p < 0.05) in the first three LVs, which accounted for 61.6%, and 14.5%, and 12.9% of crossblock covariance respectively (Fig.  ). LV 1 was related to viewing faces as opposed to fixation trials, and showed a pattern related to the lateral frontal-parietal network similar to the results of previous studies . LV 1 was related to viewing faces in general rather than distinguishing between emotional and neutral faces, demonstrating that this pattern of faces >fixation in the mirroring network is the dominant pattern of neural activity within this task analysis. LVs 2 and 3 explain some of the remaining variance in the data not accounted for the pattern presented in LV 1, representing interaction effects showing different patterns of activity across the Imitate and Observe conditions. LV 2 shows a large amount of overlap with LV 1, suggesting some of the variance within those regions is explained by aspects of both LVs 1 and 2. The majority of the variance explained by LV 1, but some additional variance within those voxels is explained by the pattern of emotional faces >neutral and fixation in Imitate and increased activity in fixation trials for Observe, as seen in LV 2. LV 3 represents an interaction in which the relative effects of neutral faces and fixation are different in the Imitate and Observe tasks.   
Results from the first latent variable using task PLS analysis. Data is shown for LV1, 2 and 3. The top panel shows the design pattern (the contribution of each condition to the LV). Error bars are 95% confidence interval derived from the bootstrap analysis. The bottom panel shows the voxel pattern from the first lag of the PLS analysis rendered on the cortex. Sagittal slices are shown for X = −10 (left) and X = 10 (right). Voxel intensity is displayed as bootstrap ratio, a measure of reliability of voxels within the LV. Red-yellow regions show the pattern described by the design pattern, while blue regions show the opposite pattern. 
  

For consistency and replication of previous studies, we also ran a general linear model (GLM) in SPM8. The GLM showed a similar pattern as in previous studies and LV1 of the task PLS (see supplementary methods and Supplementary Figure 1). 


### Behavioral PLS 
  
Behavioral PLS examined the relationships between patterns of activity in the brain and social cognitive test scores. Scores from six social cognitive tasks were included: the Emotion Recognition (ER40) , the Reading the Mind in the Eyes Test, RMET , the Relationships Across Domains test (RAD) , and the three subtests of the Awareness of Social Inference Test Revised (TASIT-R) . TASIT1 can be considered a test of lower-level social cognitive functioning, while TASIT2 and TASIT3 are high-level tests. The behavioral PLS generated 36 LVs, as there were six experimental conditions (emotional faces, neutral faces, and fixation, separately for Imitate and Observe, and six social cognitive tests). Overall permutation analysis showed significance in the first two LVs, which accounted for 23% and 13.2% of crossblock covariance respectively. However, the split-half permutation reliability analysis (see methods) demonstrated that the relationship between the design pattern and brain pattern was not reliable within LV 1 and as such it was not considered further. In LV 2, neural activity during imitation of emotional faces was positively correlated with RAD, TASIT1, TASIT2, and TASIT3 (Fig.  , top panel). Neural activity for Fixation and Neutral faces during Imitate, as well as Neutral faces during Observe, was negatively correlated with those same test scores. As such, LV 2 shows a pattern of correlations during the imitation of emotional faces related to performance on TASIT1, TASIT2, TASIT3, and RAD.   
LV 2 of the behavioral PLS results. (  A  ) Design pattern showing the pattern of correlations between brain signal for each during event type and each behavioral score within the voxel pattern. Error bars represent 95% confidence interval based off a bootstrapping analysis of 1000 iterations. (  B  ) Voxel patterns for each lag, displayed as bootstrap ratio on the MNI152 brain. Data is shown for two sagittal views as well as rendered onto the cortex (8 mm search depth) to better visualize cortical activity. Red-yellow shows a correlation pattern matching the design pattern (  A  ), while blue regions show the opposite pattern. Each lag represents a time point (TR) following stimuli onset (which occurred during ‘Lag0’). 
  

The pattern of brain activity in LV 2 (Fig.  , bottom panel) when imitating emotional faces in lag 1 showed a positive relationship with performance on TASIT1 TASIT2, TASIT3, and RAD. Activity was present in right pars opercularis (within inferior frontal gyrus), right and left supramarginal gyrus, right motor cortex, bilateral anterior temporal regions, fusiform gyrus, and parahippocampal cortex. Activity was also noted in right anterior/mid cingulate, right rolandic operculum, right putamen, and the cerebellum. Activity in lags 4 and 5, which positively correlated with social cognitive performance, was notably present in anterior temporal regions as well as in posterior middle and inferior right temporal gyri. Several regions showed negative relationships to the design pattern (thus greater fMRI activity while imitating emotional faces in individuals with poorer social cognitive performance), including the left inferior frontal gyrus (pars operculum and pars triangularis), and bilaterally in the basal ganglia (greatest in left putamen and right globus pallidus). 



## Discussion 
  
The behavioral PLS results of this study showed a robust relationship between neural activity during a process-specific imitate-observe task and both lower-level and higher-level social cognitive performance. While a growing number of studies using complex stimuli have noted co-activation of mirroring and mentalizing regions , co-activity cannot be taken to conclude that mirroring has a strong role in higher level social cognition. The novelty of our study is that we showed complex relationships of neural activity during a simple and process-specific mirroring task with performance on objective out-of-scanner assessments of higher-level social cognitive performance. In addition, the PLS approach allowed us to include several assessments in a single analysis, providing data driven evidence of which assessments best capture these brain-behaviour relationships. These behavioral relationships were specific to imitation of emotional faces, rather than neutral faces. Several regions outside the right fronto-parietal circuit, including left IFG and some mentalizing regions (e.g. TPJ), also showed negative correlations with social cognitive performance, suggesting either compensatory responses or over-activation in participants with poorer social cognition. 

These findings of a relationship between activity in a simple mirroring task and higher level social cognitive processing scores suggest a relationship for the mirror network in higher-order social cognitive processing including complex tasks. Effective mentalizing in humans although likely primarily reliant on classic mentalizing regions may be further subserved by mirroring regions . Given that the relationships elicited were noted in assessments involving interpretation of dynamic interactive video tasks including human actors, it may be that such relationships are only evoked when we consider social cognition as a process involving integrating information from multiple processing levels. The mirroring network may not be solely for understanding the intentions and physical goals of motor acts . Our findings add to the debate regarding the role of this network in social cognition . Several authors have argued that this network is important not only for imitation or action perception, but also for emotional empathy and possibly even in cognitive empathy (sometimes used interchangeably with theory of mind) , consistent with the theory of embodied simulation , despite debate to the contrary . Through the combination of a process-specific in-scanner task, more naturalistic and objective social cognitive tests, and the PLS multivariate framework, we were able to uncover essential brain-behavior relationships for which traditional task contrasts or linear regression analyses may be less sensitive. 

Higher level social cognitive processing involves concepts related to both theory of mind and cognitive empathy, both complex constructs which likely encompass several mental processes. To date, there is only limited evidence of overlap in neural activity between high-level tasks related to the mentalizing network and low-level tasks related to the mirroring network . However, task based analysis is often performed by contrasting conditions, and many mirroring tasks have utilized stimuli with little or no direct social relevance, or tasks designed to evaluate highly specific social cognitive processes which may not be well suited to capturing overlap within these systems . By moving away from an ‘overlapping activity’ perspective into an approach focused on brain-behavior relationships, we were able to demonstrate that activity in the mirroring network is correlated with higher-level social cognitive abilities. This combination of pairing a process-specific task paradigm with dynamic social cognitive measures may be a powerful approach for probing relationships between social cognitive networks and real-life social cognitive abilities. 

The behavioral PLS LV correlating neural activation during imitation of emotional faces with TASIT and RAD scores also included some regions which are often considered part of the mentalizing network. While these regions did not robustly activate during the task PLS, their presence in the behavioural PLS reflects activation during the imitate task that is relevant for social cognitive performance. Positive relationships with social cognition and emotional faces were observed in the temporal pole bilaterally, a region implicated in mentalizing and theory of mind  as well as in processing deception . Activity was also noted in the posterior region of the superior temporal sulcus, which may be of particular interest as this area has been implicated in both the mirroring/imitation network  and the mentalizing network . The superior temporal sulcus may serve as an integrative region, sharing information between these two networks  and/or as serving as a relay point for high level visual information . The superior temporal sulcus has also been implicated in analyzing dynamic facial features , perceiving biological motion , and gaze perception . As such, this region is involved with perceptual processes necessary for both low-level and high-level social cognition. It remains to be seen if this region may serve as an integrative hub between the mentalizing and mirroring networks, though the posterior superior temporal sulcus shares connectivity within both networks  and has been implicated as an important region in social cognitive impairment in autism . 

Studies showing increased connectivity between the right IFG (a critical hub of the mirroring network) and the mentalizing network provide evidence for functional communications between these networks . This connectivity between mirroring and mentalizing regions has been shown to be disrupted in autism , raising the possibility that disrupted social cognition in autism may be driven not only by localized effects within one of these systems but also as a network level disruption in how these systems interact. Likewise, social cognitive deficits are increasingly recognized as a core feature of schizophrenia, strongly related to overall functional outcomes . People with schizophrenia have been noted to show reduced right IFG activity when imitating emotional faces as well as opposite relationships between self-reported empathy and right IFG activity compared to controls . As social cognitive impairment is present at, or potentially preceding the onset of psychosis , it is possible this relatively brief imitate/observe in-scanner task may be useful as a potential early risk marker of the disease. 

We found that increased activity in the left IFG was associated with poorer social cognitive performance, as well as in clusters in the left medial frontal cortex and the TPJ . One study examining resting state network connectivity noted over-connectivity of the left IFG in the mirroring network in participants with autism, consistent with our finding that over activity in the left IFG is associated with poorer social cognitive performance . A number of regions outside the mirroring or mentalizing networks also showed a negative relationship with social cognitive performance, including the basal ganglia, thalamus, occipital cortex and superior colliculus. These regions may be involved in emotional face processing . We propose three possible explanations for the negative correlations between this pattern of neural activity when imitating emotional faces and social cognitive performance: 1) prolonged neural activity related to less efficient processing resulting in a greater magnitude of hemodynamic signal, as may be suggested by increased activity in regions associated with visual and face processing; 2) compensatory activity in which individuals with less efficient processing make greater use of the left IFG to compensate for lack of activity on the right (the compensatory hypothesis); or 3) over activity in the left IFG resulting in competition with right IFG, resulting in interference or an decrease in network coherence and deficits in social cognitive test performance (the dedifferentiation hypothesis). One possible explanation is that participants with poor performance may be attempting to compensate by activating aspects of the mentalizing system during lower-level social cognitive processing. It has been suggested that the anterior cingulate cortex, a region noted in the behavioral PLS, is involved in biasing activity towards either mentalizing or simulation . 

We did not find reliable relationships between the ER40 and RMET with neural activity to emotional faces. The ER40 and RMET rely on static images which fail to capture the full complexity of social cognitive processing, unlike the TASIT which requires interpretation of video scenarios of complex human interactions and the RAD which involves interpreting stories. It may be that more complex and process-general tests are required to more fully elicit relationships between activity in the simulation and mentalizing networks . Supporting this assertion, correlations between TASIT test scores and the observed voxel pattern in the PLS analysis were as high as 0.8, indicating a very strong relationship between mirroring network activity and social cognitive performance measured by TASIT1 (a lower-level task), as well as higher-level tasks TASIT2, and TASIT3. Some recent studies using more naturalistic higher-level social-cognitive paradigms, such as videos, have implicated IFG activity , and a small number of recent studies involving more complex social interaction tasks have noted co-activation in mirroring and mentalizing regions . 

Here we provide evidence that neural activation while imitating emotional faces is related to performance on dynamic and objective ‘real-life’ assessments of even the most complex social cognitive tasks. Given the relatively small sample size, further research expanding into a larger sample would be worthwhile to replicate and extend these findings. However, our findings suggest that patterns of neural activation during basic imitative behaviour may be a surrogate marker for highly complex social function in humans. The paradigm demonstrated here may be particularly useful for early identification studies in neurologic and psychiatric disorders with social cognitive impairment, and in intervention studies using ‘target engagement’ as a marker of early treatment response. 


## Methods 
  
### Participants 
  
Twenty-eight healthy adult participants were initially included in this study. Average age of participants was 34.3 ± 11.7 years, with 18 men and 10 women, 23 right-handed participants, and an average level of education of 15.1 ± 2.22 years. Participants aged 18 to 55 were included in the study. All participants completed the Edinburgh handedness Inventory and were administered the Structured Clinical Interview for DSM-IV disorders (SCID) to rule out possible psychiatric illness. Urine toxicology screening was performed to further ensure that no participant with a current substance use disorder was included in the study. Additionally, exclusion criteria included a first degree relative with a history of psychotic mental disorder, a history of head trauma resulting in unconsciousness, or a history of seizure or other neurological disorders. The protocol was approved by the research ethics board of the Centre for Addiction and Mental Health, University of Toronto, all research was conducted in accordance with the declaration of Helsinki and the tri-council policy statement on Ethic Conduct for Research Involving Humans. All participants gave informed consent, and signed an institutionally approved informed consent form, prior to any research procedures. 


### Social Cognitive Assessments 
  
The Emotion Recognition (ER40) task consists of 40 images of whole faces making emotional expressions, with participants selecting from four possible emotional responses . The Reading the Mind in the Eyes Test (RMET)  consists of 36 trials showing only the eyes of a black and white face, with four possible choices to describe what the person is feeling (e.g. amused, irritated, cautious, contemplative). The RMET is considered a test of empathic abilities as it measures the ability to judge emotional states from looking at the eyes. The Relationships Across Domains (RAD) test  presents 25 written vignettes of 2–4 lines followed by three statements which describe the behaviour of the male-female dyad from each vignette in domains of social life different from that vignette. Participants indicate if the behavior described in each statement is likely or unlikely to occur based on what was learned from the vignettes. The Awareness of Social Inference Test, Revised (TASIT) uses short video vignettes to measure emotional perception and theory of mind . The TASIT is divided into three parts. Part 1 (TASIT1) consists of 24 short videos of actors portraying different emotional states (happy, sad, fear, disgust, surprise, and anger). Part 2 (TASIT2; social inference – minimal) consists of 15 videos showing sincere or sarcastic interactions between two actors, followed by four questions relating to what the actors were thinking, doing, meaning to say, and feeling. TASIT2 is considered a test of theory of mind. TASIT part 3 (TASIT3; social inference – enriched) consists of 15 vignettes in which the speaker is making an assertion which is literally untrue, but can represent either sarcasm or an attempt at deception. Success in TASIT3 requires the ability to detect deception in social encounters. In total, six social cognitive scores were derived from these tests (ER40 reaction time, RMET, RAD TASIT1, TASIT2, and TASIT3). Age was regressed out of all social cognitive test scores. 


### MRI Scanning 
  
MRI scanning was conducted on a Discovery 3 T MR750 machine from General Electric at the Centre for Addiction and Mental Health. The Imitate/Observe task was part of a longer multimodal MRI protocol to which each participant consented. Each block of the task (Imitate and Observe) was collected in counter-balanced order as a separate echo-planar imaging scan, with TRs = 3 sec, TE 30 ms, voxel size 3 mm isotropic, 50 slices, 64 × 64 matrix with FOV = 192 mm, flip angle = 77, and 110 TRs per scan. The first 5 TRs were excluded prior to any preprocessing to allow for magnetic steady-state. 


### Imitate/Observe Task 
  
The participants performed an imitate/observe task as previously described  while being scanned. Participants were shown full-color photographs from an ethnically diverse set of 16 individuals (eight males and eight females) expressing five different facial expressions (fearful, sad, happy, angry, or neutral). During one scanning session, participants were instructed to imitate the expression on the faces (the   Imitate   session), while in the other session participants were instructed to observe the face (the   Observe   session). Each run consisted of 80 faces (16 per facial expression) plus 16 fixation trials presented in a pseudorandomized order determined using Optimize Design 11  to maximize contrast efficiency. Each trial lasted three seconds, with the faces presented for two seconds and a jittered ISI (500 ms to 1500 ms). The order of sessions (Imitate or Observe) was counter-balanced across participants. Participants practiced the task prior to MRI scanning and were instructed to minimize motion during the imitation, only using their facial muscles when matching the expressions. A video recording during the scan confirmed that all participants were following instructions (i.e. imitating during the imitate session but not during observe). 


### fMRI data analysis - Preprocessing 
  
The initial preprocessing stages were slice time corrected and motion corrected in SPM8 (Wellcome Department of Cognitive Neurology, London, UK). Individual sessions were subjected to single-session independent components analysis (ICA, from the MELODIC module in FSL 5.0.6). ICA reports were visually examined, and any ICAs which were clear artifacts were removed based on a set of established criteria. On a case by case basis where some large motions contaminated the ICAs, data ‘scrubbing’ was performed using a spline interpolation. Generally, two TRs were removed for each motion spike, and no more than three TRs were permitted per motion spike and a maximum of three motion spikes were removed from any scan. Of the 56 sessions (Observe and Imitate for the 28 participants) scrubbing was performed in 16 sessions. In nine of these cases (four Observe sessions and five Imitate sessions) scrubbing was not successful. Possible reasons for unsuccessful ‘data scrubbing’ include large movements exceeding three TRs, more than three large movements, or over 90% of ICA components classified as artifact after data scrubbing. These sessions were subsequently excluded from further analysis, leaving neuroimaging data from 20 of the original 28 individuals for final analysis. Data were then de-noised based on the selected noise ICA components using FSL 5.0.6 (reg_filt). Normalization into MNI space was done using SPM8, and images were smoothed with an 8 mm Gaussian kernel. 


### Partial Least Squares Analysis 
  
Patterns of task related activity and relationships between social cognitive test scores and BOLD signal were examined using spatio-temporal PLS , a multivariate approach which allows for detection of spatial patterns and dependant variables across the brain without the need for a-priori selected contrasts across experimental conditions. PLS is designed to handle data with high collinearity while capturing essential non-redundant relationships among the data , overcoming the confounding influence of collinear variables (e.g. cognitive tests) in traditional multiple regression. Additionally, PLS is also well suited to studying the relationships between numerous variables even in the presence of a relatively small sample, which is ideal for our purposes as it allows us to examine a range of social cognitive batteries. PLS produces latent variables (  LVs  ) relating patterns of experiment task activity or behavioral measures with spatial patterns of neural activity across time points (scans, referred to as    lags   , normalized to the scan in which the stimuli was presented, labeled as lag0). As a model free non-parametric approach, PLS is ideal to examine complex relationships amongst the battery of social cognitive scores and neural activity when imitating and observing emotional faces. 

A task-PLS analysis was conducted to replicate the regions of activity in the SPM8 GLM. Brain data from an 18 second window (corresponding to 6 lags) was normalized to the first lag (lag0) to create a data matrix for each condition, stacked across participants. Cross covariance was calculated between the data matrix and a design matrix consisting of vector of experimental conditions (in the task PLS, emotional faces, neutral faces, and fixation crosses, separately for Imitate and Observe). The resulting cross-covariance matrix was then decomposed using singular value decomposition, which created a set of orthogonal latent variables (  LVs  ) which optimally represent spatio-temporal relationships between voxels and experimental conditions. For each LV, a pattern of voxels at each lag value (the ‘brain pattern’) demonstrates the relationship with activity in the voxel at that lag and the ‘design pattern’ (representing the weights of each experimental event). Voxel weight is expressed as salience, which is proportional to the covariance of activity in that voxel and the design pattern expressed by that LV. 

Behavioral PLS was used to examine relationships between social cognition and neural activity. Behavioral PLS examines patterns of covariance between scores and neural activity for each trial type across lags. As such the design pattern is the correlation between the overall pattern of neural activity in each condition and each social cognitive score. For the behavioral PLS, neural activity to emotional faces, neutral faces, and fixation (separately for imitate and observe) was related to the six social cognitive test scores from our battery, deterministically producing 36 LVs. 

Statistical evaluation of each LV was performed using split-half permutation testing. A total of 500 permutations were run, with 100 split-half permutations within each. The overall permutation score determines if the effect represented by the LV is sufficiently strong to be differentiated from random noise, while the split-half analysis provides a measure of the stability of relationships between voxel patterns and design patterns in the data for each latent variable. As the permutations are performed at the level of the entire PLS analysis (rather than on individual LVs), multiple comparisons for the number of LVs is not necessary. In the split-half, the ‘BrainCorr’ value tests the reliability of the voxel pattern for a given design pattern associated with an LV, while ‘DesignCorr’ tests the reliability of a given voxel pattern for the behavioral pattern associated with that LV. Results are expressed as p-values. LV’s were considered significant if the overall permutation and at least one of the BrainCorr or DesignCorr was less than 0.05. A bootstrapping procedure with 1000 iterations was used to test if specific voxels were reliably related to the LV. A bootstrap ratio for each voxel was calculated as the voxel salience divided by its bootstrap standard error. A bootstrap ratio of 2.5 (corresponding to >95% reliability) was used to threshold all voxel pattern maps in PLS. 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-27'>
<h2>27. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22590530/' target='_blank'>22590530</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Regional Brain Responses in Nulliparous Women to Emotional Infant Stimuli</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2012</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0036270</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3349667/' target='_blank'>3349667</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study meets all inclusion criteria: it used functional MRI while participants (healthy, nulliparous adults ages 19–29) completed social-related tasks (viewing infant faces of varying affect and listening to infant cries), and participants were screened as healthy with no psychiatric/neurological disorders. The paper reports whole-brain, random-effects analyses with family-wise error correction and cluster thresholds (i.e., not limited to ROI analyses). It is an original empirical fMRI study (not a review/meta-analysis) and the participant age range falls within 18–60. No exclusion criteria are violated. Therefore the study should be INCLUDED.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Infant cries and facial expressions influence social interactions and elicit caretaking behaviors from adults. Recent neuroimaging studies suggest that neural responses to infant stimuli involve brain regions that process rewards. However, these studies have yet to investigate individual differences in tendencies to engage or withdraw from motivationally relevant stimuli. To investigate this, we used event-related fMRI to scan 17 nulliparous women. Participants were presented with novel infant cries of two distress levels (low and high) and unknown infant faces of varying affect (happy, sad, and neutral) in a randomized, counter-balanced order. Brain activation was subsequently correlated with scores on the Behavioral Inhibition System/Behavioral Activation System scale. Infant cries activated bilateral superior and middle temporal gyri (STG and MTG) and precentral and postcentral gyri. Activation was greater in bilateral temporal cortices for low- relative to high-distress cries. Happy relative to neutral faces activated the ventral striatum, caudate, ventromedial prefrontal, and orbitofrontal cortices. Sad versus neutral faces activated the precuneus, cuneus, and posterior cingulate cortex, and behavioral activation drive correlated with occipital cortical activations in this contrast. Behavioral inhibition correlated with activation in the right STG for high- and low-distress cries relative to pink noise. Behavioral drive correlated inversely with putamen, caudate, and thalamic activations for the comparison of high-distress cries to pink noise. Reward-responsiveness correlated with activation in the left precentral gyrus during the perception of low-distress cries relative to pink noise. Our findings indicate that infant cry stimuli elicit activations in areas implicated in auditory processing and social cognition. Happy infant faces may be encoded as rewarding, whereas sad faces activate regions associated with empathic processing. Differences in motivational tendencies may modulate neural responses to infant cues. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (35644 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
During early development, pre-linguistic vocalizations, such as cries, and facial expressions are the primary means of infant communication. Both cries and facial expressions from the infant communicate salient information regarding their emotional states and needs and may elicit affection and nurturing from adults  . The interpretation and response to needs underlying infants’ sensory cues may significantly influence the infant’s development  ; thus, the processing of the emotional content of infant stimuli is of developmental significance. 

Utilizing auditory and visual sensory cues, functional magnetic resonance imaging (fMRI) studies have begun to examine mothers’ neural responses to emotional infant stimuli (e.g.,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ). Although auditory stimuli, like cries, may be experienced behaviorally differently than images of infants, considerable overlap is found in neural activation patterns  ,  . Specifically, regions such as the midbrain, hypothalamus, thalamus, basal ganglia, anterior cingulate cortex (ACC), and prefrontal cortex are commonly activated in fMRI studies of parental responses to infant cues, suggesting the involvement of motivation and reward circuitry  ,  . 

As individual differences in motivational tendencies may influence sensitivity to emotional stimuli and/or attachment processes, an exploratory examination of the relationship between brain activation patterns and individual differences in behavioral tendencies may be helpful in characterizing the neural responses to emotional infant stimuli. A prominent theory of behavioral tendencies predicts individual differences to engage or withdraw from emotionally or motivationally relevant stimuli  ,  . In this model, a behavioral activation system (BAS) exists to govern approach behavior toward rewarding stimuli, operating orthogonally to a behavioral inhibition system (BIS) that mediates withdrawal behavior from punishing stimuli. Measures such as the BIS/BAS scale   can be used to assess these tendencies. An improved understanding of how individual differences in behavioral inhibition and activation might relate to neural correlates of infant emotion processing could prove important in identifying features influencing adult-infant interactions. 

In addition to BIS/BAS, evidence suggests that other factors may influence neural responding to infant stimuli. For example, comparisons of different stages in parenting (e.g., two to four weeks postpartum versus three to four months postpartum) have revealed differential patterns of brain activation, suggesting that experience with an infant over the initial months postpartum likely involves significant changes in responsivity to infant cues  ,  . As the experience of parenting may influence responses to infant stimuli, it is necessary to investigate the neural responses to infant stimuli in nulliparous women. Such investigations are important as they will not only inform studies of maternal responses to infant stimuli and help characterize shifts in maternal brain function, but also provide insight into a large group of women with more variable experiences with, and propensities towards, infants. 

Therefore, in the current study, we sought to examine neural responses of nulliparous women to infant cries and faces of varying intensity and valence, respectively. Specifically, we investigated infant cries of differing distress (high, low) levels and infant faces of varying affect (happy, sad, neutral) in nulliparous women using fMRI. We hypothesized that both cry types, relative to a neutral auditory stimulus, would recruit regions previously implicated in response to cries, including the superior temporal gyrus (STG), insula, and cingulate cortices. Moreover, based on the perceived aversiveness of the cries, we predicted that high-distress cries, compared to low-distress cries, would be associated with relatively increased activity in these same regions. With regard to infant facial stimuli, we predicted that happy faces, compared to neutral ones, would activate regions associated with positive emotion and reward processing, including the ventral striatum and orbitofrontal cortex (OFC)  ,  ,  ,  ,  ,  . Sad faces, compared to neutral ones, were hypothesized to activate brain areas implicated in dysphoric and/or empathic responses such as the amygdala and cingulate cortex  . Using a BIS/BAS measure, we predicted that behavioral activation, which reflects responses to stimuli of reward and non-punishment  , would correlate with activations related to rewarding stimuli such as happy infant faces. We further predicted that behavioral inhibition, which is associated with heightened arousal, passive avoidance, and anxiety  , would correlate with regional brain activations related to more aversive stimuli, such as high- and low-distress cries. 


## Methods 
  
### Subjects 
  
Nineteen native-English-speaking, right-handed nulliparous women gave informed written consent and participated in this study approved by the Yale Human Investigation Committee. All research was conducted in accordance with the Declaration of Helsinki. One subject had excessive motion in multiple fMRI runs and was excluded from analyses; another subject completed only four of seven functional runs and was also excluded. The remaining 17 subjects were between the ages of 19 and 29 (M = 22.7, SD = 2.9) years and were in good health with no history of psychiatric or neurological disorders, and had normal or corrected-to-normal vision. Racial and ethnic composition consisted of ten Caucasian, two Asian-American, two African-American, one Pacific-Islander, and two Hispanic women. 

All subjects completed the BIS/BAS scale  , a 24-item valid and reliable self-report questionnaire rated on a 4-point scale (strong agreement to strong disagreement) measuring behaviorally aversive (i.e., behavioral inhibition) and appetitive (i.e., behavioral activation) motivations. The BIS/BAS factors into four subscales, with one factor assessing inhibition (BIS) and three factors assessing activation. The three BAS subscales assess the pursuit of appetitive goals (BAS drive), tendency to seek rewarding experiences (BAS fun-seeking), and responsiveness to reward (BAS reward-responsiveness). 


### Auditory Stimuli – Infant Cries 
  
Cry stimuli were generated from stimuli described previously  . Cries were elicited from infants between the ages of 27 and 32 days who were without serious illness at birth and during their one-month checkup. Cries were recorded in the infants’ homes before the infants were fed and required no additional external stimulation. Detailed information about the recording procedure is reported elsewhere  . We used four two-second segments generated by two infants. The cries were categorized as either high- or low-distress, resulting in both a high- and low-distress exemplar from both infants. We used two exemplars for each level of distress to avoid measuring differences associated with the physical properties of one particular cry. Prior to imaging, the distress level of the cries was verified by an independent group of ten nulliparous female participants (ages 19 to 24 years) who rated the cries on a scale of 1 (calm) to 10 (distressed). High-distress cries were rated as significantly more distressed (M = 8.06, SD = 1.3) than low-distress cries (M = 3.54, SD = .82) (  t   = 11.52,   p  <.0001). 

In addition to cries, subjects heard a “neutral” auditory stimulus, which consisted of a two-second segment of 1/f, or “pink” noise. Pink noise has a frequency of 1/f, indicating that the power spectral density is inversely proportional to the frequency. Pink noise was used as a neutral stimulus because it is not produced by a human and, as compared to white noise, is considered more naturalistic as it occurs in natural systems, speech, and music  . Additional information on the acoustic properties of the cries and neutral stimulus has been previously reported  . 


### Visual Stimuli 
  
Photographs of infant faces between the ages of five and ten months were adapted from Strathearn and McClure   and were previously used by our group  . Twenty-one images from each of the six infants, resulting in a total of 126 images, were balanced for both gender and race (Caucasian and African American). The infant-face images displayed happy, neutral, and sad affective states. The size, luminance, and contrast for all face stimuli were standardized, and faces were presented on a black background. Prior to imaging, face stimuli were rated by an independent group of 11 participants on a scale of 1 (happy) to 10 (distressed) to assess the perceived affect level. A repeated measures ANOVA of the infant-face ratings on the three emotions (happy, neutral, sad) was significant (  F  (2, 20) = 146.43,   p  <.001). Pairwise comparisons showed that happy faces (M = 2.19, SD = 0.75) were rated as significantly less distressed (Mean difference = −1.55, SD = 1.15,   p   = .006) than neutral faces (M = 3.74, SD = 1.43). Neutral faces were rated as significantly less distressed (Mean difference = −4.16, SD = 1.28,   p  <.001) than sad faces (M = 7.90, SD = 0.34). 


### Design 
  
Stimuli were presented using E-Prime software (Version 1.2; Psychology Software Tools Inc., Pittsburgh, PA). The auditory stimuli were delivered via headphones with no visual display. The visual stimuli were displayed foveally at the fixation point for 1000 ms and followed by a fixation cross. Subjects received seven functional runs, each consisting of 42 trials (six trials of each condition of interest and six one-back memory trials). The conditions of interest were high-distress cry, low-distress cry, pink noise, happy face, sad face, and neutral face. Trials of all conditions were presented in a counter-balanced succession. The duration of the inter-trial-interval (ITI) was jittered (4000–14000 ms) to allow event-related analysis and to minimize stimulus expectation. 

During each run, subjects were asked to attend to the stimulus sequence of faces and cries. A one-back memory task was included to maintain and assess subjects’ attention during the task and were modeled but not included in further analyses. On a small proportion of trials (14%), subjects were presented with a row of question marks and either a visual stimulus (infant face) was presented above the question marks or an auditory stimulus (cry or pink noise) was delivered via the headphones. The question marks cued the subject to make a yes/no decision via a stimulus response box as to whether the current stimulus was identical to the stimulus of the preceding trial (i.e., a one-back memory task). Analysis of catch trial data revealed a mean accuracy rate of 91.27±0.05% (mean ± SD). 


### Data Acquisition 
  
Data were acquired with a Siemens Trio 3T magnetic resonance imaging system (Siemens AG, Erlangen, Germany) using a standard 12-channel head coil. Localizer images were acquired for prescribing the functional image volumes, aligning the eighth slice parallel to the plane transecting the anterior and posterior commissures. Functional images were collected using a gradient echo, echoplanar sequence (repetition time [TR] = 2000 ms; echo time [TE] = 30 ms; flip angle [FA] = 80°, field of view [FOV] 20 cm×20 cm, 64×64 matrix, 3.4 mm 3.4 mm in-plane resolution, 4 mm slice thickness, 32 slices). Each stimulus run consisted of 163 volumes, including an initial rest period of 12 seconds (to achieve signal stability) that was removed from analyses. High-resolution structural images were also collected (sagittal MPRAGE acquisition, TR = 2530 ms; TE = 3.66 ms; FA = 7°; FOV = 25.6 cm×25.6 cm; number of excitations [NEX] = 256×256×1; 1 mm slice thickness, no gap; 176 slices). 


### Image Analysis 
  
Following prior published protocols  , functional data were preprocessed using SPM5 (Wellcome Functional Imaging Laboratory, London, United Kingdom). Preprocessing included slice-time correction to the first slice of each volume; SPM5’s two-pass realign-to-mean strategy, which ultimately realigns all functional images to a mean functional image; coregistration of the anatomical image and the average of these realigned functional images; coregistration of all functional images using the parameters obtained from coregistration of the mean image; application of the SPM Unified Segmentation process to the anatomical scan, using prior information from the International Consortium for Brain Mapping (ICBM) Tissue Probabilistic Atlas and estimation of non-linear warping parameters  ; warping the functional images to the Montreal Neurological Institute (MNI) template space; reslicing into isometric 3 mm×3 mm×3 mm voxels; and subsequent smoothing of functional images using a 6 mm Gaussian kernel. All functional runs were inspected for motion in excess of one voxel, for which one participant was excluded from the analysis. 

Once the functional images were preprocessed, first-level robust regression was performed using the standard general linear model but with iteratively reweighted least squares using the bisquare weighting function for robustness  ,  , as implemented in MATLAB 7.3 (Mathworks, Natick, MA; robust.m). Motion parameters and high-pass filter parameters were added as additional regressors of no interest. Once conditions were estimated using percent signal change for each participant, a second-level, random effects analysis was performed to estimate contrasts between conditions using NeuroElf (NeuroElf.net) and following our prior methods. To correct for multiple comparisons we then used a Monte Carlo simulation, which takes into account the voxel-wise and cluster-volume thresholds to establish family-wise error (FWE) correction. Only regions with corrected   p  <.05 (i.e., α<.05) threshold at an uncorrected voxel-level threshold of   p  <.01 at each tail and a cluster of 45 were considered to be significantly activated or deactivated in the whole-brain analysis. Whole-brain correlations were computed to assess the relationship between brain activation and behavioral inhibition and activation as assessed by the BIS/BAS. To adequately correct for the multiple comparisons conducted in the correlation analysis with multiple measures, we employed a conservative Bonferroni correction to both height and whole-brain level thresholds across 24 exploratory correlations. Clusters were considered significant at a FWE corrected   p  <.05 threshold and subsequently Bonferroni-corrected with a corrected   p  <.002 threshold (at an uncorrected voxel-level threshold of   p  <.0005 at each tail and a cluster of 17). Anatomical labels of all results were confirmed using the Talairach Daemon toolbox as well as manually, using a human brain atlas  . 



## Results 
  
### Brain Activations to Infant Cries 
  
When comparing low-distress cries to pink noise, increased activation was observed in bilateral STG, right middle temporal gyrus (MTG), bilateral precentral and postcentral gyri, right inferior parietal lobe (IPL), left superior and medial frontal gyri (SFG and MFG), left putamen and left claustrum. Relatively diminished activation was observed in left caudate and right MFG/OFC. When comparing high-distress cries to pink noise, increased activation was observed in bilateral STG, right MTG, right precentral and postcentral gyri, right SFG, right MFG, right inferior frontal gyrus (IFG), bilateral amygdala, and left culmen. Relatively diminished activation was observed in the right STG and right insula. When comparing high-distress cries to low-distress cries, diminished activation was observed in bilateral STG, right MTG, left IPL, right superior occipital gyrus, and left precuneus; no regions showed increased activation ( ;  ). 
   Regional Brain Activations during the Perception of Infant Cries.           Regional Brain Activations during the Perception of Infant Cries.  
Axial slices of regional brain activations for a) low-distress cries versus pink noise, b) high-distress cries versus pink noise, c) and high-distress cries versus low-distress cries. Color on T1 template images from SPM5 indicates significant increases (red color) and decreases (blue color) in BOLD signal. The right side of the brain is on the right. The number under each brain image indicates z-axis coordinates of the image in the MNI (Montreal Neurological Institute) template space. The only voxels displayed on the brain images are regions with corrected p<.05 threshold at an uncorrected voxel-level threshold of p<.01 at each tail and a cluster of 45. 
  

### Brain Activations to Infant Faces 
  
For happy versus neutral infant faces, greater activation was observed in left ventral striatum, left caudate head, left ventromedial prefrontal cortex (vmPFC)/OFC, and right IFG. Relatively diminished activation was observed in left cingulate gyrus, bilateral precentral gyrus, right SFG, right STG, left supramarginal gyrus, and left insula. For sad versus neutral infant faces, greater activation was observed in bilateral precuneus, left cingulate gyrus, right MTG, bilateral middle and inferior occipital gyri, right fusiform gyrus (FG), left precentral gyrus, left IPL, left lingual gyrus, right SFG, bilateral MFG, right IFG/OFC, and left ACC. Relatively reduced activation was observed in the left insula, left transverse temporal gyrus, and right STG. For happy versus sad faces, relatively greater activation during the presentation of sad faces was observed in the right IFG, bilateral FG, right STG, right supramarginal gyrus, right cuneus, left MTG, left middle occipital gyrus, right precentral gyrus, and right MFG; no regions demonstrated greater activation for the presentation of happy faces relative to sad faces ( ;  ). 
   Regional Brain Activations during the Perception of Infant Faces.           Regional Brain Activations during the Perception of Infant Faces.  
Axial slices of regional brain activations for a) happy versus neutral infant faces and b) sad versus neutral infant faces. Color on T1 template images from SPM5 indicates significant increases (red color) and decreases (blue color) in BOLD signal. The right side of the brain is on the right. The number under each brain image indicates z-axis coordinates of the image in the MNI (Montreal Neurological Institute) template space. The only voxels displayed on the brain images are regions with corrected p<.05 threshold at an uncorrected voxel-level threshold of p<.01 at each tail and a cluster of 45. 
  

### BIS/BAS Scores and Correlations with Brain Activity 
  
The mean ± SD scores of the 17 subjects on the BIS/BAS scale components were 22.12±2.76 for the BIS, 10.76±2.22 for BAS drive, 11.29±1.93 for BAS fun seeking, and 17.35±1.54 for BAS reward-responsiveness. These scores fall within the standard mean score range for healthy subjects  . 

The scores on the BIS and two BAS subscales (drive and reward-responsiveness) were correlated with brain activation contrasts. BIS scores positively correlated with right STG activity in both the comparisons of high-distress cries versus pink noise and low-distress cry versus pink noise. The BAS drive subscale scores inversely correlated with activations in the: 1) right putamen, right caudate extending into the thalamus, right lateral globus pallidus, and left medial globus pallidus in the contrast between high-distress cries and pink noise; and 2) left angular gyrus in the contrast between high-distress cries and low-distress cries. The BAS drive subscale scores positively correlated with right superior occipital gyrus in the contrast between sad and neutral faces. BAS reward-responsiveness scores inversely correlated with left precentral gyral activation in the contrast between low-distress cries and pink noise ( ;  ). 
   Regional Brain Activations during the Perception of Infant Cries and Faces Correlated with Behavioral Measures of Motivation as Assessed by BIS/BAS Subscales.           Regional Brain Activations during the Perception of Infant Cries and Faces Correlated with Behavioral Measures of Motivation as Assessed by BIS/BAS Subscales.  
a) Axial slice of regional brain response for low-distress cry versus pink noise that correlates with scores on the BIS scale. b) Axial slice of regional brain response for high-distress cry versus pink noise that correlates with scores on the BIS scale. c) Axial slice of regional brain response for high-distress cry versus pink noise that correlates with scores on the BAS drive scale d) Axial slice of regional brain response for sad versus neutral infant faces that correlates with scores on the BAS drive scale. e) Axial slice of regional brain response for low-distress cry versus pink noise that correlates with scores on the BAS reward-responsiveness scale. Color on T1 template images from SPM5 indicates significant increases (red color) and decreases (blue color) in BOLD signal. The right side of the brain is on the right. The number under each brain image indicates z-axis coordinates of the image in the MNI (Montreal Neurological Institute) template space. The only voxels displayed on the brain images are regions with corrected p<.002 threshold at an uncorrected voxel-level threshold of p<.0005 at each tail and a cluster of 17. 
  


## Discussion 
  
The current study used fMRI to examine the neural correlates of how nulliparous women respond to emotional infant stimuli, specifically cries of varying distress levels and facial expressions of varying affect. Overall, regions activated in response to cries in nulliparous women (e.g., the STG and MTG) are consistent with those identified in cry processing in previous studies of both non-parents and parents  ,  ,  . For the face stimuli, we observed different regional brain activations in response to sad and happy infant faces. Regions such as the vmPFC, OFC, and ACC, which are commonly activated in fMRI studies of parental responses to infant cues, demonstrated activation during the presentation of infant faces  ,  . Furthermore, neural responses to the cry and face contrasts correlated with self-reported measures of behavioral inhibition and activation suggesting that neural responses to infant stimuli vary as a function of motivational approach and avoidance tendencies. 

### Regional Brain Activations during the Perception of Low- and High-Distress Cries Relative to the Control Stimulus 
  
We found increased activation to low-distress cries relative to the control stimulus in bilateral STG, right MTG, right IPL, and bilateral precentral and postcentral gyri. Similarly, high-distress cries relative to pink noise identified increased activation in bilateral STG, right MTG, and bilateral precentral and postcentral gyri. Findings in STG and frontal cortices are common in fMRI paradigms utilizing infant cry stimuli and may reflect auditory processing and social cognition  ,  . Several fMRI studies have linked activations of STG and IPL to representations of others’ intentions and mental states  ,  . Thus, activation in these areas during the perception of cries may reflect an attempt to understand the emotional states associated with cries of varying distress levels. The STG has also demonstrated increased activity in response to angry speech relative to neutral speech  ,  . Therefore, activation in STG may reflect the aversive nature of the cries. 


### Regional Brain Activations during the Perception of Low- Relative to High-Distress Cries 
  
Nulliparous women demonstrated greater activation for low-distress relative to high-distress cries in bilateral STG, right MTG and left IPL. Increased activation in auditory-processing regions for low- relative to high-distress cries may reflect the greater acoustic variability in the low-distress cries. Specifically, low-distress cries tend to have more numerous shorter bouts whereas high-distress cries tend to have fewer bouts and fewer breaths (see Appendix for cry characteristics). Accordingly, low-distress cries might be considered more complex and may generate relatively increased STG and MTG activation. From a behavioral perspective, high-distress cries may produce more unequivocal responses in adults (e.g., “The infant is clearly distressed and needs immediate attention.”), whereas low-distress cries may produce more complex, and potentially ambiguous, behavioral responses as the adult attempts to understand the cries’ meanings (e.g., “How greatly distressed is the infant? Will the cries cease without my attention?”). The potentially equivocal nature of these responses may relate to the observed increased insular activation, which has been associated with decision-making processes and empathy  ,  . Additionally, the greater recruitment of brain regions during low-distress cries relative to high-distress cries may stem from differential previous experiences of the nulliparous women with infants, which was not assessed in this study. Further research on the relationship between specific acoustic properties of cries and the neural and emotional responses they generate is necessary for understanding the differential responses to cries of varying properties. 


### Regional Brain Activations during Viewing of Happy Faces 
  
Consistent with our hypothesis and findings from previous studies involving the processing of infant visual stimuli  ,  ,  ,  , viewing of happy infant faces compared to neutral ones engaged the OFC. The OFC contributes importantly to maternal “reward” circuitry  ,  , and increased activation in this region may reflect the rewarding nature of a happy infant face, which may help elicit care-giving behaviors. Considered a component of the brain’s “reward system,” the OFC receives ascending dopamine projections from the ventral tegmental area (VTA)  ,  . Studies with pleasant visual, tactile, and olfactory stimuli have found increased activation in the OFC that depends on the pleasantness rather than the intensity of stimulation  ,  . The OFC is therefore considered to have a critical role in representing the reward value of a stimulus. Greater activation for happy faces was also seen in the striatum, a structure receiving projections from the VTA and OFC   and implicated in reward-related learning and motivated behaviors  ,  ,  . The increased striatal activation in nulliparous women may relate to the coding of happy infant affect as a positive sensory cue. 


### Regional Brain Activations during Viewing of Sad Faces 
  
For the sad versus neutral face contrast, activation was observed in the precuneus, cuneus, and left posterior cingulate cortex (PCC). Both the precuneus and PCC have been implicated in the processing of sad adult faces   and show greater activation when adults evaluate their own or other’s emotional states  . A longitudinal neuroimaging study of depressed patients found differential brain activations according to depression status  , suggesting that areas involved in the discernment of negative affective facial expressions may relate to dysphoric response patterns. The PCC has also been implicated in stress responses  , suggesting that stress neurocircuitry may be activated by sad faces. Alternatively, the activation of the precuneus and PCC may indicate that nulliparous women engage in the attribution of emotion while viewing sad infant visual stimuli, as the PCC has been associated with evaluating the affective valence of external stimuli  , and the precuneus has been implicated in empathic processes  . 

Sad faces also activated the ACC, a region involved in the processing of emotional information  . Data implicate the ACC in attending to, and regulating, arousal associated with affective states  , as increased blood flow has been reported in dorsal and rostral regions of the ACC when attending to subjective emotional states and experiences  ,  . Regions along the border between the rostral ACC and the mPFC have been associated with theory of mind tasks, such as the ability to infer mental states of others  . The increased activation in ACC therefore suggests that the nulliparous women in this study may have engaged in social and emotive processing while viewing the sad infant facial stimuli. 


### Regional Brain Activations during Viewing of Sad-Relative-to-Happy Faces 
  
For the comparison of sad versus happy faces, the right IFG, bilateral FG, and right cuneus demonstrated increased activity. Both the IFG and FG have been widely implicated within circuitry involved in the processing of adult emotional faces and are considered as “core” regions of emotional face processing  ,  . The FG has been implicated in the processing of facial stimuli  , including in learning affective values of faces  , with greater FG activation observed to faces of negative affect  . The precuneus has also been implicated in the processing of adult emotional faces, particularly in response to sad faces  . Precuneus response to emotional faces appears influenced by individual genetic variation   suggesting the value of face perception investigations of individual differences. Together, the findings suggest that the neural underpinnings of infant emotional face processing share similarities with those underlying adult emotional face processing and that that individual differences are important to consider in the processing of facial stimuli. 


### Regional Brain Activations and Individual Differences in Behavioral Inhibition and Activation 
  
Our findings suggest that individual differences in motivational tendencies may influence neural correlates underlying the processing of infant emotional cues. Specifically, higher self-reported behavioral inhibition was related to greater activation in right STG during the perception of low-distress cries relative to pink noise, as well as high-distress cries relative to pink noise. The BIS measure assesses responsiveness to signals of negative outcomes, particularly tendencies to inhibit behavior that may result in undesirable consequences (e.g., “If I think something unpleasant is going to happen, I usually get pretty worked up.”). The recruitment of right STG during the perception of low- and high-distress cries preferentially in women with high BIS scores may therefore relate to the aversive nature of cries, with individuals more prone to behavioral inhibition demonstrating a greater STG response. 

Higher self-reported behavioral drive was associated with greater activation in the right superior occipital gyrus when viewing sad versus neutral faces. The occipital cortex, including the superior occipital gyrus, has been linked to affective processing, with occipital cortical activity correlating with poor social adjustment and impaired social cognition in individuals with psychotic disorders  . Thus, the current findings relating behavioral drive to superior occipital gyral activation during viewing of sad faces not only implicates a region implicated in social processing in a population often characterized by poor motivation drive and interpersonal difficulties, but also suggests that early visual processing may be particularly relevant to responses to sad infant facial cues in behaviorally driven individuals. 

In the current study, individuals with higher reward-responsiveness showed lower activity in the left precentral gyrus when listening to low-distress cries compared to pink noise. The precentral gyrus, involved in motoric responding, has been implicated in the processing of rewarding and aversive stimuli. For example, healthy subjects as compared to individuals with borderline personality disorder, a condition characterized by emotional dysregulation, showed greater recruitment of the precentral gyrus during responses to aversive as compared to neutral stimuli  . Healthy women but not those with bulimia nervosa showed increased activation of the precentral gyrus in anticipation and receipt of a milkshake reward  . Thus, these findings suggest that individual differences in precentral gyral activations to aversive and rewarding cues may have important clinical implications. The current findings suggest that individual differences in both approach and avoidance motivational tendencies are related to neural activations involved in attentional and emotional processing. The extent to which these behavioral and neural measures relate to specific aspects of adult-infant interactions requires additional investigation. 


### Limitations, Strengths, and Future Directions 
  
Several limitations exist. First, the facial stimuli were derived solely from infants. Future investigations involving facial stimuli from individuals of varying ages may be helpful in elucidating how brain responses may be modulated by the physical maturity of facial features being viewed. Furthermore, the cries were gathered solely from newborn infants, limiting the possibility of having a comparable happy auditory condition such as laughter. Additionally, the age difference of the infants used for the cry and face stimuli makes comparisons between the two sensory domains difficult. However, we did find increased activation in precuneus, right MTG, left precentral gyrus, and left IPL for sad faces relative to neutral ones, as well as for cries relative to pink noise. Future fMRI investigations are needed to continue identifying regions activated across these sensory modalities. Second, the subjects in the study were healthy nulliparous women of childbearing age. Information regarding subjects’ desire and plans to be in a caretaker role, as well as the degree of their present interaction with infants, may help to further account for individual differences in the processing of infant stimuli. Additionally, studies of childbearing women could examine how neural responses to infant affective cues may change in healthy mothers at varying times postpartum. Third, the study excluded men. Examination of similarly aged men and parents of both sexes could investigate potential influences of sex and parenthood, respectively. Fourth, the study involved healthy subjects. Future studies of mothers and nulliparous women in whom parent-child interactions may become impaired, such as during maternal depression and substance abuse, could help investigate processes of particular relevance to the health of vulnerable youth. Despite these limitations, the findings provide initial insight into the neural processing of infant cues in nulliparous women and how individual differences in motivational tendencies relate to brain responses to infant stimuli. 

In summary, the current study provides an initial examination of how emotional infant stimuli are perceived by healthy, nulliparous women. Cries of varying distress levels differentially recruited regions associated with auditory and empathic processing. With regard to the visual infant stimuli, our findings suggest that happy faces are encoded as rewarding stimuli in the brain, whereas sad faces induce increased activation in regions associated with empathic processing. The study is also the first to investigate appetitive and aversive motivational tendencies in relationship to the processing of infant emotional cues, and the findings suggest a relationship between individual differences in motivational tendencies and brain response patterns to infant cues. These findings also indicate the utility of this approach to investigate a broader range of individual differences with respect to neural activations and their clinical correlates in response to infant stimuli. 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-28'>
<h2>28. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31593216/' target='_blank'>31593216</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> A look at actions: direct gaze modulates functional connectivity of the right TPJ with an action control network</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Soc Cogn Affect Neurosci</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1093/scan/nsz071</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6917026/' target='_blank'>6917026</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This fMRI study tested social processing: participants performed a gaze-based spatial stimulus-response task using anthropomorphic virtual characters (social gaze). Sample comprised healthy adults (N=30 after exclusions), ages 19–41 (within 18–60). The paper reports whole-brain voxelwise activation analyses (second-level flexible factorial, cluster-forming p<0.001 uncorrected and cluster FWE p<0.05) and whole-brain results for main effects and interactions. It is not an ROI-only report, not a review/meta-analysis, and participants did not have psychiatric or neurological disorders. Therefore it meets all inclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>   ABSTRACT  
Social signals such as eye contact and motor actions are essential elements of social interactions. However, our knowledge about the interplay of gaze signals and the control of actions remains limited. In a group of 30 healthy participants, we investigated the effect of gaze (direct gaze   vs   averted) on behavioral and neural measures of action control as assessed by a spatial congruency task (spatially congruent   vs   incongruent button presses in response to gaze shifts). Behavioral results demonstrate that inter-individual differences in condition-specific incongruency costs were associated with autistic traits. While there was no interaction effect of gaze and action control on brain activation, in a context of incongruent responses to direct gaze shifts, a psychophysiological interaction analysis showed increased functional coupling between the right temporoparietal junction, a key region in gaze processing, and the inferior frontal gyri, which have been related to both social cognition and motor inhibition. Conversely, incongruency costs to averted gaze were reflected in increased connectivity with action control areas implicated in top-down attentional processes. Our findings indicate that direct gaze perception inter-individually modulates motor actions and enforces the functional integration of gaze-related social cognition and action control processes, thereby connecting functional elements of social interactions. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (33873 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
The interdependency of gaze processing and motor actions plays a key role in our everyday social interactions. Underlining their joint functioning, empirical studies have revealed a strong overlap between brain areas that process hand and gaze movements (e.g.  ). Furthermore, it has been shown that social gaze impacts goal-directed movement precision ( ) as well as reaction speed ( ;  ). The latter, however, could not be observed in individuals with autism spectrum disorder ( ), who are also characterized by abnormalities in motor behaviors as well as the processing of eyes and observed movements ( ;  ). 

In social interactions, a specific role needs to be attributed to the perception of direct gaze, which reflexively attracts attention ( ;  ). Crucially, direct as compared to averted gaze has been described as a signal that conveys the intention to interact ( ). In line with this, empirical evidence suggests a facilitation effect of direct gaze on imitative behavior ( ;  ) as well as an attentional effect of gaze cues on manual responses to target stimuli ( ;  ). Yet, besides imitation and beyond attentional guidance of gaze, social interactions might require re-actions to gaze movements that are compatible but not identical with observed actions ( ). Still, how gaze interacts with action control processes on the behavioral and brain level and how the specific gaze context modulates functional connectivity between gaze and action control areas, particularly when tendencies towards spatial congruency need to be suppressed, remains unclear. Therefore, we systematically investigated how the perception of direct or averted gaze affects action control in the context of an fMRI-compatible and previously established spatial stimulus-response compatibility (SSRC) paradigm ( ;  ). Instead of using social and non-social stimuli as in previous studies, we realized a 2 × 2 factorial design by asking participants to generate button presses in a spatially congruent or incongruent manner (factor congruency: CON   vs   INCON) in response to gaze shifts produced by an anthropomorphic virtual character (VC), whose initial gaze position was either direct or averted (factor gaze: direct   vs   averted). As dependent variables, we measured task performance (accuracy) and reaction time (RT) as well as brain activity obtained via BOLD fMRI. 

In line with empirical evidence, incongruent compared to congruent reactions incur increased computational load and thus, lead to prolonged RTs and a decreased percentage of correct responses ( ;  ). Additionally, the incongruency effect should be reflected in an increased activation in a bilateral dorsal fronto-parietal network of frontal motor areas and superior parietal lobules, a network responsive to increased top-down attentional demands and need for increased action control ( ;  ). For the main effect of direct compared to averted gaze, we hypothesized brain regions sensitive to eye contact and gaze-related movements ( ;  ), namely the temporoparietal junction/posterior sulcus temporalis superior (TPJ/pSTS) and the fusiform gyrus, to show increased BOLD signal in response to direct gaze stimuli ( ;  ;  ). 

The main focus of this study was to investigate the interaction between the perception of gaze and mechanisms of action control. While some evidence suggests a general facilitation effect of direct gaze ( ,  ), in other studies, an association of direct gaze and accelerated reactions has only been found for compatible stimulus-response mappings ( ;  ;  ). On the brain level, both motor control areas such as the inferior frontal cortex as well as the gaze sensitive TPJ have been implicated in the interaction of gaze and motor control processes ( ;  ). Building on this, the present study tested whether the same brain regions are differentially recruited as representations of gaze-dependent incongruency costs. Furthermore, in light of evidence that indicates gaze-dependent functional connectivity changes of the TPJ/pSTS with an extended gaze perception network ( ) as well as multi-modal functional coupling of the right TPJ ( ), we expected gaze and action control networks to interact at the level of right TPJ connectivity, reflecting a differential integration of gaze-related and action control processes. Thus, in order to systematically investigate the relationship of gaze-specific incongruency costs in terms of functional connectivity, we conducted a psychophysiological interaction analysis and analyzed whether the interplay of the gaze context and action control demands modulates the functional connectivity between the right TPJ and an ‘action control network’, being composed of all action-associated brain regions as defined by a Neurosynth ( ) search including the search term ‘action’. In a context of direct gaze and an increased demand for action inhibition due to spatial incongruence, we expected to see increased functional coupling between our seed region, which was located in a functional cluster that has been related to social cognition ( ), and particularly the IFG, indicating an integration of gaze-related social cognition and action control ( ;  ;  ). 

In light of autism-related differences observed in the original version of our SSRC task ( ), we further obtained measures of autistic traits and hypothesized to replicate a positive relationship between autistic traits and gaze-specific incongruency costs. 


## Methods 
  
Thirty-two volunteers (15 females) participated in our study. Due to neurological and psychiatric conditions (sleeping disorder, ventricumegaly), two participants were excluded from all further analyses. The remaining 30 participants (14 females) had a mean age of 24 (s.d. = 5.08, range = 19–41), normal or corrected-to-normal vision, no history of neurological or psychiatric history and were right-handed as assessed by the Edinburgh Handedness Inventory ( ). The mean group autism quotient (AQ) ( ) was 14.99 (s.d. = 6.38, range = [6, 32]). All participants gave informed written consent and received a fixed monetary compensation of 30€. At the end of the experiment, participants were debriefed and thanked for their participation. The study protocol followed the guidelines of the Declaration of Helsinki and was approved by the ethics committee of the Ludwig-Maximilians-Universität München. 

### Experimental design and procedure 
  
The paradigm used in this fMRI study resembled an adapted version of previously used SSRC paradigm ( ;  ). Instead of asking participants to respond to the gaze movement of an anthropomorphic VC or the movement of a geometric symbol as in previous studies, VCs were always present. This allowed us to keep the social stimulus constant while now systematically manipulating exposures to direct compared to averted gaze. 
  
Experimental task. (  A  ) One of two female VCs demonstrating direct gaze in the congruent condition [indicated by the initial cue ‘GLEICH’ (German for ‘same’)]. The first gaze shift to the left requires a congruent left button press, the second gaze shift to the right a right button press. (  B  ) One of two male VCs demonstrating averted gaze in the incongruent condition [indicated by the initial cue ‘GEGEN’ (German for ‘opposite’)]. The first gaze shift to the left requires an incongruent right button press, the second gaze shift to the right a left button press. 
  
Before the experiment and before entering the fMRI scanner, participants received detailed instructions on the overall procedure and MRI safety. During the experiment, they were asked to respond as fast as possible to gaze shifts shown by the VC by pressing a right or left button using the right or left index finger, respectively. The experiment consisted of 24 blocks of 12 events each with 50% left- and 50% right-directional gaze shifts, realizing a 2 × 2 factorial design: congruent blocks were instructed by the initial cue ‘GLEICH’ (German for ‘same’) and required participants to respond to gaze shifts in a spatially compatible manner, i.e. pressing the ipsilateral button. The initial cue ‘GEGEN’ (German for ‘opposite’) introduced blocks of spatially incompatible responses, where participants had to press the contralateral button in response to a gaze shift, for instance the right button had to be pressed following a gaze shift to the left ( ). Each cue was presented once for 1500 ms at the beginning of each block of 12 gaze shifts and each block was followed by a jittered inter-stimulus interval of 15 to 17 s. During the experiment, participants did not receive any feedback on their performance. Besides the factor ‘congruency’, our second experimental factor ‘gaze’ was expressed by the VC either looking up (averted gaze) or facing the participant (direct gaze). Pixel coordinates and the timing of gaze shifts were identical over all conditions. In each block, male participants experienced one of two male VCs while female participants were confronted with one of two female VCs. The appearance of either of the two same sex VCs was equally likely. Stimuli were presented through the software package Presentation (Neurobehavioral Systems, Inc.; Version 18.1) on an fMRI compatible computer monitor (refresh rate = 59 Hz, resolution of 1024 × 768, viewable region of 500 mm × 380 mm) and were created manually in Poser 10 (Smith Micro Software, Inc., CA, USA). As stimuli of the present study differed from stimuli of previous studies, a pre-study was conducted to control for unbalanced stimuli preferences. Twelve volunteers (employees, 8 females) from the Max Planck Institute of Psychiatry rated all four VCs on a five-level Likert scale on attractiveness, valence, arousal and other characteristics (Supplementary Table S1). A repeated measures ANOVA using stimulus type (VC 1–4) and characteristics (Supplementary Table S1) revealed no significant effect of stimulus type (  F  [1,11] = 0.94,   P   = 0.43) or interaction effect on VC ratings,   F  (1,11) = 1.15,   P   = 0.10. All volunteers correctly indicated whether the VC demonstrated direct or averted gaze and whether the gaze was directed to the left or right. 


### Behavioral and questionnaire data preprocessing 
  
RTs, the dependent variable that expressed the behavioral outcome of action control, reflected the time frame between the onset of the gaze shift and the button press of the participant. We applied the following RT data preprocessing steps (e.g.  ;  ): trials with no answer, multiple answers or incorrect answers were categorized as error trials. Further, trials with responses two standard deviations from the participant-specific mean RT over all conditions were interpreted as anticipation error or missed response and also labeled as error trials. In total, 9.4% of all trials were error trials. In order to exclude uninformative task blocks, e.g. blocks in which participants missed the initial instructive cue, blocks with more than 25% error trials (> = 3 error trials/block) were not considered in subsequent analyses, resulting in an average exclusion of one block per participant (Supplementary Table S2 for details). Task performance reflected the mean percentage of correctly answered trials of all correct and error trials, which was calculated for each combination of experimental conditions. The AQ of participants was assessed in order to evaluate the relationship of autistic traits and gaze-specific incongruency costs. To conserve comparability of AQ scores, missing values (four participants did not fill in one item each) were interpolated over the individual sub-scale values of the respective item filling in the missing data point. 


### Behavioral data analyses 
  
Main effects and interaction effects of experimental conditions on task performance and RTs were tested by means of repeated measures 2 (gaze: direct   vs   averted) × 2 (congruency: congruent   vs   incongruent) ANOVAs. To test whether direct gaze modulates responses in the congruent or incongruent condition, we implemented post-hoc contrasts of conditions (direct_CON   vs   averted_CON; direct_INCON   vs   averted_INCON) as Bonferroni corrected paired two-sided   t  -tests. After calculating the RT incongruency costs, i.e. RT slowing in incongruent compared to congruent trials, we obtained the difference in RT incongruency costs between the direct and averted gaze condition (incongruency costs direct—incongruency costs averted) as a measure of direction and size of effect of gaze on RT incongruency costs. To further analyze the relationship of the difference in RT incongruency costs between the direct and the averted gaze condition, we correlated the measure with AQ scores. Here, due to non-normally distributed AQ scores (Shapiro–Wilk statistic = 0.93,   P   < 0.05), the non-parametric two-sided Spearman’s rank correlation statistic was used. 



## fMRI data analysis 
  
Participants completed the experiment inside a 3T MR scanner (MR750, GE, Milwaukee, USA). The procedure comprised a single functional run of 290 volumes of 40 slices (32-channel head coil, AC-PC-orientation, 96 × 96 matrix, 3 × 3 mm voxel size, 3 mm slice thickness, 0.5 mm slice gap). First, structural T1-weighted images were acquired [BRAVO FSPGR pulse sequence, 1 mm isotropic voxels, repetition time (TR) of 6.2 ms, echo time (TE) of 2.3 ms]. Second, during the experiment, T2 -weighted functional images were obtained by means of gradient echo planar imaging (TR of 2000 ms, TE of 20 ms, 90° flip angle) and the first four functional volumes we removed to control for non-equilibrium effects. FMRI data preprocessing and analysis were performed in SPM12 (Statistical Parametric Mapping Software, Wellcome Department of Imaging Neuroscience, London;   http://www.fil.ion.ucl.ac.uk  ) and included the following steps: functional images were spatially realigned to the mean functional image (rigid body transformation). Next, functional and structural images were co-registered. Both structural and functional images were spatially normalized to the Montreal Neurological Institute (MNI) template using tissue segmented T1-weighted anatomical images (BRAVO FSPGR pulse sequence, 1 mm isotropic voxels, TR of 6.2 ms, TE of 2.3 ms). Functional images were resliced to 2 × 2 × 2 mm voxel size. Finally, a 3D Gaussian Kernel with full width of half maximum of 8 mm was used for smoothing. 

All valid experimental blocks (RT data preprocessing) were modeled as epochs in a general linear model (GLM) with an average duration of 54 s (range 46–64 s). Experimental factors, i.e. ‘gaze’ (direct   vs   averted gaze) and ‘congruency’ (congruent   vs   incongruent) were captured in four different regressors of interest. Error blocks were modeled by a regressor of no interest. Our GLM design matrix further contained 26 confound regressors of no interest: the first 24 contained six z-standardized rigid body motion realignment parameters, their temporal derivatives and the squared values of both realignment parameters and derivatives ( ). Another two regressors captured confounding signal from white matter and cerebrospinal fluid. Here, we obtained a binarized mask from the respective segmented individual structural images using a 0.95 threshold in SPM’s image calculator (imcalc tool) and calculated the first principal component of the respective tissue type, explaining 85.42% (s.d. = 4.28%) and 79.11% (s.d. = 5.85%) of variance in the signal ( ). No global scaling was applied and low-frequency signal drifts were filtered out (128 s cutoff period). In order to correct for temporal autocorrelation of the data, voxel-wise maximum likelihood estimators were calculated ( ). 

Studying the effect of congruency and gaze as well as their interaction, BOLD signal during main effects and interactions of conditions were analyzed in a second-level flexible factorial design. A binarized group-specific explicit grey matter (GM) mask (sum of participant specific probability of GM > 0.05; imcalc tool) contained all voxels of interest. Besides our two experimental factors, we added a ‘subject’ factor, accounting for subject-specific heteroscedasticity, and implemented SPM’s default settings of unequal variances within each factor. In order to analyze the main effects of congruency and gaze, we contrasted congruent and incongruent as well as direct and averted gaze conditions [congruency: (direct_CON + averted_CON) > (direct_INCON + averted_INCON), (direct_INCON + averted_INCON) > (direct_CON + averted_CON); gaze: (direct_CON + direct_INCON) > (averted_CON + averted_INCON), (averted_CON + averted_INCON) > (direct_CON + direct_INCON)]. Statistical interactions of conditions were modeled as contrast of incongruency costs in the direct and averted gaze conditions [IA1: (direct_INCON > direct_CON) > (averted_INCON > averted_CON), IA2: (averted_INCON > averted_CON) >(direct_INCON > direct_CON)]. 
  
Behavioral measures  .   (  A  ) Mean percentage of correct responses and (  B  ) left panel: mean RTs; right panel: mean RTs for direct and averted gaze in the congruent condition. Light blue lines mark a decrease in RT from direct to averted; dark blue lines mark an increase. The light blue solid line represents the mean decrease in RTs from the direct to the averted gaze condition. Black horizontal lines represent the mean values, boxes represent the standard error of the mean (SEM), blue vertical lines the standard deviation (s.d.). 
  
Moreover, we conducted a generalized condition-specific psychophysiological interaction analysis ( ) to investigate the context-dependent functional coupling between gaze and action processing areas. Based on the available literature and a term-based meta-analysis in Neurosynth ( ), we identified a region typically labelled as right TPJ ( ) as the seed region for our gPPI analysis. The coordinates of our seed region [44, −52, 12] represented the peak coordinates in the brain map of the term ‘gaze’ (retrieved 2 October 2018 from   www.neurosynth.org  , z-score = 7.33) and were further situated in a functional sub-section of the right TPJ involved in social cognition ( ; Neurosynth, retrieved 3 June 2019, meta-analytic association of peak coordinates with terms ‘default network’, ‘mentalizing’). After creating a sphere of 6 mm radius in marsbar ( ; Supplementary Figure S1A), we extracted the first eigenvariate of our seed sphere and allowed actual ROIs to vary in size between participants, but restricted them to first level masks generated by SPM12. In order to investigate the context-dependent functional coupling of our right TPJ seed with brain areas involved in action control, we retrieved an associative ‘action’ mask from Neurosynth ( : retrieved 2 October 2018 from   www.neurosynth.org  ). After smoothing (3D Gaussian Kernel with full width of half maximum of 4 mm) and binarization (imcalc, i1 > 0.1, Supplementary Figure S1B), it was implemented as explicit mask in our second level analysis. Specifically, we were interested in the functional coupling of the right TPJ and the action network for the statistical interactions of our experimental conditions [IA1: (direct_INCON > direct_CON) > (averted_INCON > averted_CON)] and [IA2: (averted_INCON > averted_CON) > (direct_INCON > direct_CON)]. 

Statistical maps of the activation analysis are shown at a cluster-forming threshold of   P   < 0.001 (uncorrected) and a cluster threshold of   P   < 0.05 (FWE). In the psychophysiological interaction analysis,   P  -values were thresholded at   P   < 0.05 (FWE) at voxel level. The Anatomy Toolbox ( ; Version 2.2c) and the AAL atlas in MRIcron ( ) were used for functional localization and the Surf Ice software for brain visualizations (  https://www.nitrc.org/projects/surfice/  ). 


## Results 
  
### Behavioral results 
  
As expected, a repeated measures ANOVA focusing on the condition-specific performance revealed a significant main effect of congruency on the percentage of correct responses,   F  (29,1) = 32.09,   P   < 0.001, η  = 0.53. There was no main effect of gaze [  F  (29,1) = 1.80,   P   = 0.19, η  = 0.06] or an interaction effect of congruency and gaze on performance,   F  (29,1) = 1.27,   P   = 0.27, η  = 0.04 ( ). 

A second repeated measures ANOVA demonstrated a significant main effect of congruency also on RTs,   F  (29,1) = 134.71,   P   < 0.001, η  = 0.82. Neither did gaze impact participants’ RTs [  F  (29,1) = 1.30,   P   = 0.26, η  = 0.04] nor did the interaction effect of experimental conditions reach significance,   F  (29,1) = 3.88,   P   = 0.06, η  = 0.12 ( ). Post-hoc contrasts showed that congruent RTs were significantly higher in the direct gaze compared to the averted gaze condition,   t  (29) = 2.86,   P   < 0.01, R  = 0.22. Incongruent RTs, however, did not differ between gaze conditions,   t  (29) = 0.17,   P   = 0.87.   presents the condition-specific performance and RTs. 
  
Condition-specific RTs and accuracy. Brackets contain the standard deviation (s.d.). 
  
Condition-specific RT incongruency costs, i.e. the increase in RTs in incongruent compared to congruent trials, are displayed in  . On average, RTs of incongruent reactions increased by 48 ms (s.d. = 27 ms) in the direct gaze condition and by 56 ms (s.d. = 27 ms) in the averted gaze condition. Building on this, a two-sided Spearman’s rank correlation analysis indicated a significant negative correlation between AQ scores and the difference in RT incongruency costs for direct as compared to averted gaze,   rs  (28) = −0.40,   P   < 0.05 ( ). 
  
Condition-specific RT incongruency costs. Boxes represent the SEM. 
    
Linear association of AQ scores and the difference in RT incongruency costs (ranks) between experimental conditions (direct—averted). 
  

### fMRI results 
  
Applying a cluster-forming threshold of   P   < 0.001 (uncorrected) and a cluster threshold of   P   < 0.05 (FWE), incongruent contrasted to congruent trials [(direct_INCON + averted_INCON) > (direct_CON + averted_CON)] were associated with a differential increase in BOLD signal in the right inferior parietal lobule, left superior parietal lobule and right middle frontal gyrus ( ). For the reversed contrast [(direct_CON + averted_CON) > (direct_INCON + averted_INCON)], a large cluster of 2319 voxels emerged in the bilateral medial prefrontal cortex (MPFC), including voxels in the superior medial gyri, superior frontal gyri and the anterior cingulate cortices, spreading to the right medial cingulate cortex. Congruent compared to incongruent trials further elicited activation in the right IFG as well as the left cerebellum and posterior part of the left fusiform gyrus ( ). 
  
Main effects of conditions in the left (L) and right (R) hemisphere  .   (  A  ) Incongruent   vs   congruent, (  B  ) congruent   vs   incongruent, (  C  ) direct   vs   averted gaze. The cluster forming threshold was set to   P   < 0.001 (uncorrected), the cluster threshold to   P   < 0.05 (FWE) and cluster size (A) k > 414 voxels, (B) k > 287 voxels, (C) k > 638 voxels. [(A) SPL: superior parietal lobule, mFG: medial frontal gyrus; MFG: middle frontal gyrus (B) SFC: superior frontal cortex, FFG: fusiform gyrus, ACC: anterior cingulate cortex, MPFC: medial prefrontal cortex, CRBL: cerebellum; IFG: inferior frontal gyrus (C) lPS: intra-parietal sulcus]. 
  
During direct gaze   vs   averted gaze [(direct_CON + direct_INCON) > (averted_CON + averted_INCON)], increased signal was found in the right intraparietal sulcus ( ). The contrast of averted gaze   vs   direct gaze [(averted_CON + averted_INCON) > (direct_CON + direct_INCON)] did not show any suprathreshold activation. Similarly, significant clusters emerged in neither of the interactions of congruency and gaze [IA1: (direct_INCON > direct_CON) > (averted_INCON > averted_CON)] and [IA2: (averted_INCON > averted_CON) > (direct_INCON > direct_CON)] (Supplementary Table S3 for coordinates, T-values and cluster sizes). 

In our psychophysiological interaction analysis, we analyzed how the right TPJ was coupled with the action network for the interactions of the experimental factors, i.e. IA1 and IA2 (Supplementary Figure S2 and Table S4 for coordinates, T-values and cluster sizes of all PPI contrasts). Statistical maps were thresholded at   P   < 0.05 (FWE) at voxel level. Results demonstrated that for IA1, which represented increased BOLD incongruency costs for direct compared to averted gaze, the right TPJ showed context-dependent connectivity with the IFG and the right middle temporal gyrus ( , brown color map). For IA2, reflecting increased BOLD incongruency costs for averted compared to direct gaze, activation in the seed region was coupled to activation in a dorsal network of superior and inferior parietal lobules, pre- and postcentral gyri, temporal gyri, occipital gyri, left superior, posterior medial, middle and IFG, right paracentral gyrus, left putamen and right cerebellum ( , blue/green color map). 
  
Interaction effects in a psychophysiological interaction analysis in the left (L) and right (R) hemisphere  .   IA1 (brown): (direct_INCON > direct_CON) > (averted_INCON > averted_CON), IA2 (blue/green): (averted_INCON > averted_CON) > (direct_INCON > direct_CON). The results were FWE corrected at   P   < 0.05 voxel level. [IFG: inferior frontal gyrus, MTG: middle temporal gyrus MFG: middle frontal gyrus, PreCG: precentral gyrus, PostCG: postcentral gyrus, SPL: superior parietal lobule, OccG: occipital gyrus, CRBL: cerebellum, ITG: inferior temporal gyrus; pmFG: posterior medial frontal gyrus; ParaCG: paracentral gyrus]. 
  


## Discussion 
  
The present study investigated the effect of gaze perception on behavioral and neural correlates of action control of non-imitative re-actions. Our results demonstrate context-dependent functional integration of gaze and action control processes and our behavioral findings are in line with theories suggesting a relationship between gaze effects and autistic traits. 

As hypothesized, we found a significantly lower percentage of correct responses and longer RTs when participants had to respond in a spatially incompatible manner to the VCs’ gaze shifts ( ;  ;  ). Moreover, in line with a priori expectations, key regions of the so-called dorsal fronto-parietal attention network showed increased activation in incongruent as compared to congruent experimental blocks, possibly reflecting the increased need for top-down control ( ;  ). 

The opposite contrast, namely congruent   vs   incongruent, depicted increased brain activation in the left posterior fusiform gyrus and the MPFC. Given the lack of significant results in previous studies, we did not have specific hypotheses about the present contrast. A possible explanation for the brain activation found might be that similar to the sensitivity of the left fusiform gyrus towards faces and shapes ( ), MPFC activation has previously been found in response to spatially congruent gaze shifts, potentially representing occurrences of joint attention ( ). Hence, in a situation of low task difficulty, participants might have used free cognitive capacities to thoroughly process the social encounter with a VC ( ). Alternatively, representing a central hub of the default mode network, which is known as the task-negative network (e.g.  ), MPFC activation might indicate the occurrence of stimulus-independent thoughts that have been referred to as ‘day dreaming’ or mind wandering ( , Neurosynth, retrieved 3 June 2019: association of peak coordinates with terms ‘default mode’, ‘mentalizing’). Despite of the richness of literature on the decisive role of the IFG in response inhibition processes (e.g.  ), in the present contrast, the right IFG was activated during congruent blocks not requiring to withdraw from or cancel motor actions. Instead, the IFG might have come into play through holding representations of the CV’s gaze movements and hence, might have supported action understanding ( ;  ; Neurosynth, retrieved 3 June 2019: association of peak coordinates with terms ‘decision task, ‘comprehension’, ‘reappraisal’). Further, in light of its implication in gaze-grasping mappings ( ;  ), the IFG might have promoted a congruent button pressing by translating the gaze movement into a finger movement that corresponded to the direction of the gaze. Here, future research needs to clarify the specific role of the IFG during congruent task conditions. 

Direct compared to averted gaze was followed by increased brain activation in the right intraparietal sulcus, a region known to be involved in visuo-spatial aspects of action planning, the understanding of complex or irrational actions and the integration of visual and motor computations ( ;  ;  ). However, contrary to our hypotheses, direct gaze was not accompanied by increased activation in the right TPJ and fusiform gyrus—a result that might be caused by block design-induced habituation effects ( ). 

Incongruency costs describe the behavioral or neural cost of performing a spatially incompatible motor response. In the present study, we were interested in the differences in incongruency costs between the direct and averted gaze conditions. Contrary to our hypothesis, incongruent RTs did not differ between the direct and the averted gaze condition. As has been shown previously ( ), in a more difficult task situation, gaze did not have an impact on behavior. However, contrary to the reported facilitation of motor imitation with direct gaze, in our study, the translation of a gaze shift into a left- or right-handed button press was less time-consuming for averted gaze movements. Thus, our results indicate that the facilitation effect of direct gaze might not apply to non-imitative behaviors. Consistent with behavioral results, there was no interaction effect of experimental conditions at the brain level. 

The difference in RT incongruency costs between the direct and averted gaze condition represented a measure of the gaze-depended incongruency effect on reaction speed. A correlation analysis showed that high AQ values were associated with higher incongruency costs in the averted gaze condition, whereas the difference in incongruency costs between conditions diminished and even changed towards higher incongruency costs in the direct gaze condition with decreasing AQ scores. This result points towards inter-individual differences in the sensitivity towards social gaze, as a function of autistic traits. In this sense, individuals with low AQ scores might be more susceptible to the influence of direct gaze than individuals with higher AQ values. 

How the communication between the right TPJ and the action network changes depending upon the interplay of the experimental factors was addressed by means of a psychophysiological interaction analysis. Importantly, studies have indicated a functional partitioning of the right TPJ into an anterior and a posterior cluster: while the global functional integration of the anterior cluster suggests a mediating role in shifting from one functional brain state to another ( ), our ‘gaze’-associated seed region overlaps with the posterior TPJ cluster, implicated in social cognition, imagination and episodic memory retrieval ( ). As hypothesized, the context-dependent connectivity between our seed and the IFG, known to be involved in the integration of action inhibitory tendencies and motivational, emotional or social input (e.g.  ;  ; Neurosynth, retrieved 3 June 2019: association of peak coordinates with term ‘theory of mind’), was increased for incongruency costs in the context of direct gaze. As a consequence, the connection between the right TPJ and the IFG might reflect an upregulated exchange of gaze information and inhibitory control processes in the context of direct gaze. Moreover, in parallel to the association of our TPJ region to object or scenic imagination ( ), the IFG has been discussed not only to contribute to reactive but also proactive motor control ( ;  ). Accordingly, it would be possible that the IFG has been involved in preparing or anticipating a reorientation response that might have been supported by gaze-related input from the TPJ. In line with this post-hoc hypothesis, the right middle temporal gyrus has been indicated in mapping hypothetical motor actions to perceptual input ( ). 

Conversely, costs for reacting incongruently in the context of averted as compared to direct gaze movements were represented in increased functional connectivity between our seed region and major parts of the action network, predominantly in the left hemisphere and including the parietal lobules, the primary motor and sensory cortex, the frontal and temporal gyri. Besides belonging to the action network, the superior parietal and frontal regions are also relevant in top down attentional control processes ( ;  ) and have been shown activated in working memory tasks, during spatial attention towards or the planning of actions ( ). In summary, incongruency costs for averted gaze appear to manifest in more wide-spread connectivity that encompasses somatosensory motor areas. Incongruency costs for direct gaze, however, are reflected in increased connectivity with brain regions that are involved in both action control and social cognition. 

In conclusion, the results of the present study shed new light onto the neurobiology that underlies the specific role of direct gaze in social encounters: by increasing the connectivity of multimodal brain regions, the processing of direct gaze results in an integration of brains regions implicated in action control and social cognition. In this way, direct gaze could be seen as contributing to a comprehensive processing of the social situation that goes beyond a strongly stimulus-driven orientation. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-29'>
<h2>29. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31729105/' target='_blank'>31729105</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Getting into sync: Data‐driven analyses reveal patterns of neural coupling that distinguish among different social exchanges</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Hum Brain Mapp</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1002/hbm.24861</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/7268064/' target='_blank'>7268064</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study used whole-brain dual-fMRI hyperscanning while participants performed an interactive social task (cooperative, competitive, control rounds), satisfying ‘functional MRI during a social-related task’. Participants were healthy adults (38 individuals; mean age 22.44, SD 1.90), within the 18–60 range. Analyses were whole-brain (preprocessing, group-independent component analysis and ISC across whole-brain components), not ROI-restricted. The paper is an original empirical fMRI study (not a review/meta-analysis) and does not report clinical or patient samples. Therefore all inclusion criteria are met and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
In social interactions, each individual's brain drives an action that, in turn, elicits systematic neural responses in their partner that drive a reaction. Consequently, the brain responses of both interactants become temporally contingent upon one another through the actions they generate, and different interaction dynamics will be underpinned by distinct forms of between‐brain coupling. In this study, we investigated this by “performing functional magnetic resonance imaging on two individuals simultaneously (dual‐fMRI) while they competed or cooperated with one another in a turn‐based or concurrent fashion.” To assess whether distinct patterns of neural coupling were associated with these different interactions, we combined two data‐driven, model‐free analytical techniques: group‐independent component analysis and inter‐subject correlation. This revealed four distinct patterns of brain responses that were temporally aligned between interactants: one emerged during co‐operative exchanges and encompassed brain regions involved in social cognitive processing, such as the temporo‐parietal cortex. The other three were associated with competitive exchanges and comprised brain systems implicated in visuo‐motor processing and social decision‐making, including the cerebellum and anterior cingulate cortex. Interestingly, neural coupling was significantly stronger in concurrent relative to turn‐based exchanges. These results demonstrate the utility of data‐driven approaches applied to “dual‐fMRI” data in elucidating the interpersonal neural processes that give rise to the two‐in‐one dynamic characterizing social interaction. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (41944 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## INTRODUCTION 
  
Social interactions unfold as a two‐in‐one dynamic (Koike, Tanabe, & Sadato,  ; Redcay & Schilbach,  ), whereby each individual's behavior is simultaneously an antecedent to and a consequence of their interaction partners' actions. At the level of the brain, this emerges through an indirect chain of interpersonal neural events; one interactant's brain responses initiate an action that, in turn, elicits systematic neural responses in their partner to drive a reaction. In this light, the particular dynamic of an interaction emerges through a reciprocal process of between‐brain contingencies, or “neural coupling” (Hasson & Frith,  ). Elucidating the patterns of neural coupling that underlie different forms of social exchange might therefore provide an interpersonal neural substrate of interactive behavior, but this requires the development of new paradigms and analytical techniques for social neuroscience research (Hasson & Honey,  ; Schilbach et al.,  ; Zaki, Bolger, & Ochsner,  ). In response to this, a new wave of “two‐person” or “in situ” social neuroscience has emerged (Hari, Himberg, Nummenmaa, Hämäläinen, & Parkkonen,  ; Kasai, Fukuda, Yahata, Morita, & Fujii,  ; Redcay & Schilbach,  ; Schilbach et al.,  ), whereby the brains of two or more individuals are measured simultaneously while they interact with one another. Such “hyperscanning” allows researchers to explore how social interactions take shape through real‐time processes of interpersonal neural coupling. 

Hyperscanning has been performed successfully with functional magnetic resonance imaging (fMRI), electroencephalography (EEG), functional near‐infrared spectroscopy, and magnetoencephalography (for reviews, see Babiloni & Astolfi,  ; Scholkmann et al.,  ). With these techniques, studies have revealed various patterns of neural coupling elicited during social interaction; while temporally contingent brain responses are observed between interactants during verbal and non‐verbal communication (Ahn et al.,  ; Bilek et al.,  ; Pérez, Carreiras, & Duñabeitia,  ), between‐brain synchrony or “alignment” (Hasson & Frith,  ) is reported during cooperative and competitive joint‐action tasks (e.g., Cheng, Li, & Hu,  ; Sänger, Müller, & Lindenberger,  ; Shaw et al.,  ; Toppi et al.,  ). Interestingly, brain regions implicated in social cognitive processes feature frequently in patterns of neural coupling across various types of social interaction, presumably reflecting the mutual recruitment of mechanisms that permit the transmission and encoding of social information. Within the temporo‐parietal junction (TPJ), for example, brain responses become synchronized and/or contingent between interactants during economic exchanges (Jahng, Kralik, Hwang, & Jeong,  ; Tang et al.,  ; Zhang, Liu, Pelowski, Jia, & Yu,  ), verbal and non‐verbal communication (Bilek et al.,  ,  ; Kinreich, Djalovski, Kraus, Louzoun, & Feldman,  ; Rojiani, Zhang, Noah, & Hirsch,  ; Wilson, Molnar‐Szakacs, & Iacoboni,  ), and cooperative joint‐action tasks (Abe et al.,  ). This is perhaps unsurprising given the putative role of the TPJ in inferring the intentional and motivational states of others (Bardi, Six, & Brass,  ; Carlson, Koenig, & Harms,  ; Eddy,  ; Frith & Frith,  ), a process that is essential for interacting successfully with others. 

Experimental paradigms employed in hyperscanning studies often confound multiple forms of social exchange, however, making it impossible to identify the discrete patterns of neural coupling associated with different types of interactive behavior. In a theoretical framework proposed by Liu and Pelowski ( ), social interaction is suggested to comprise three distinct dimensions: interaction structure (concurrent or turn‐based actions), goal structure (cooperative or competitive goals), and task structure (tasks achieved independently or interdependently). As such, to advance our understanding of how different patterns of neural coupling give rise to interactive behavior, we must first delineate among these dissociable dimensions (Konvalinka & Roepstorff,  ). Recently, our team adapted for hyperscanning research, an interactive task capable of such delineation, in which pairs of players either co‐operate or compete with one another in a turn‐based or concurrent manner to reconstruct a geometric pattern (Špiláková, Shaw, Czekóová, & Brázdil,  ). Employing this task within a dual‐fMRI hyperscanning study, we revealed brain responses in both interactants that were contingent upon the immediately preceding behavior of their co‐player. Furthermore, these brain responses dissociated among discrete dimensions of the interaction; we observed greater inter‐reactive brain responses during co‐operative exchanges within regions implicated in social cognition, while competitive exchanges elicited stronger brain reactions within neural systems involved in motor planning and updating. This demonstrated the potential for hyperscanning to elucidate patterns of interpersonal brain events underlying different forms of social exchange. 

A number of questions emerged from these results; however, first, in an event‐related design, we applied general linear modeling to identify brain signals in each player that reflected direct reactions to a specific aspect of their co‐player's behavior—namely, the end point of their preceding action. As such, we observed interpersonal brain–  behavior   contingencies rather than brain‐to‐brain coupling. It remains to be seen, then, whether patterns of between‐brain coupling between co‐players on this task also differentiate between dissociable dimensions of social exchange. Second, by modeling brain responses to a discrete, predefined element of the players' behavior, we captured interpersonal brain–behavior relationships during an isolated snapshot of the entire social exchange. This offers limited insight into the interpersonal brain events that unfold dynamically throughout a sustained interaction, through which the nature of the exchange takes shape. 

Data‐driven techniques have been developed to provide an alternative way of analyzing hyperscanning data, offering a means to address these outstanding questions. By evaluating dual‐fMRI data in a model‐free, hypothesis‐free manner, whereby no a priori assumptions are made, these techniques are more appropriate for the non‐linear, unpredictable dynamic of naturalistic social exchange (Nastase, Gazzola, & Keysers,  ). Recently, Bilek et al. ( , 2017) demonstrated how two such data‐driven techniques can be combined to investigate neural coupling during social interaction. With group‐independent component analysis (gICA), one can extract spatio‐temporal patterns of brain responses from a set of continuous recordings acquired from multiple interacting dyads. By assessing the dyad‐specific time‐course along which a given pattern is expressed, it is then possible to identify the common element of all exchanges to which those brain responses are associated; for example, one pattern might represent brain responses elicited during all instantiations of co‐operative interactions, while another relates more closely to competitive exchanges. With a second model‐free analytical technique—inter‐subject correlation (ISC) analysis (Hasson, Nir, Levy, Fuhrmann, & Malach,  )—we can then investigate whether the time‐course of neural signals within these data‐defined patterns of interaction‐specific brain responses are correlated, or aligned, between pairs of interacting individuals throughout a sustained interaction. 

To examine whether dissociable patterns of neural coupling emerged during different forms of social exchange, in the present study, we applied gICA‐informed ISC analysis to dual‐fMRI data acquired from pairs of interactants performing our interactive task. Driven by our previous findings, we expected different patterns of neural alignment to delineate among co‐operative and competitive exchanges. Furthermore, we predicted stronger alignment during concurrent relative to turn‐based exchanges, given that players must monitor and adapt to their co‐players' behavior in real‐time during the former, giving rise to temporally coupled inter‐brain contingences. 


## METHODS 
  
### Participants 
  
The analyses presented below were applied to a subset of the data collected under Špiláková et al. ( ); specifically, 19 pairs of individuals who underwent the exact same dual‐fMRI protocol—a necessary requirement for the analytical procedure. These 38 healthy individuals were recruited from Brno, Czech Republic. The mean age of this sample was 22.44 (  SD   = 1.90) years. Participants were paired into 19 same‐sex dyads (11 male–male) matched on self‐evaluated handedness (34 right handers), age (mean difference = 5.79 [  SD   = 4.29] months) and education (highest qualification). The individuals comprising a pair met for first time at the scanning facility on the day of the experiment and were instructed together about the task and experimental procedure. The study was approved by the Research Ethics Committee of Masaryk University, and all participants gave their informed consent prior to the scanning procedure. Participation was rewarded with 200 CZK (approximately €8). 


### The pattern game 
  
The pattern game is an interactive task developed originally by Decety et al. ( ), which we have adapted recently for hyperscanning research (Špiláková et al.,  ). In this game, two players either cooperate or compete with one another over recursive rounds to recreate patterns made up of blue and yellow tokens. Each player is assigned the color blue or yellow, which identifies them throughout the entire game. Prior to each round, players are shown an instruction that allocates one to the role of Builder and the second to either Helper, Hinderer, or Observer (referred to collectively as Other; e.g., “Blue builds, Yellow helps”). While the task of the Builder is always to recreate the pattern as fast as possible, the characteristics of the patterns mean that they can do so more easily with assistance from the Other. The role assigned to the Other then defined one of three conditions: during   Cooperation   rounds, they work with the Builder to help them reconstruct the pattern; in   Competition   rounds, they must work against the Builder and attempt to hinder them from achieving this. In   Control   rounds, the Other is instructed to simply observe the Builder recreating the pattern. Players alternated between the role of Builder and Other on each round. 

Players made their moves by placing tokens sequentially into specific locations of a playing board. Each round began with one of the players' tokens presented on either side of the monitor above the playing board, and using a four‐button controller they moved it leftward or rightward to a desired columnar location before dropping it into the lowest empty row. On each round, both players could place up to five tokens within a time limit of 25 s. The round ended if (a) the pattern was recreated successfully, (b) both players had placed all of their tokens, or (c) 25 s had elapsed. The experiment consisted of two blocks of 48 pseudorandomized rounds: 16   Cooperative  , 16   Competitive  , and 16   Control  . In the first block, participants took turns to place their tokens sequentially (  Turn‐Based   condition). In the second, players were free to place their tokens simultaneously (  Concurrent   condition). Throughout a round, the Builder's token was always in the lower row, closer to the playing board; as such, if both players attempted to place their token at the same columnar position simultaneously, the Builder's token always dropped to the lowest row with the Other's token positioned above it. Figure   presents an overview of the task, which was programmed in MATLAB (v2018b, The MathWorks, Inc.) using the Cogent 2000 toolbox (developed by the Cogent 2000 team at the FIL and the ICN, and John Romaya at the LON at the Wellcome Department of Imaging Neuroscience; RRID:SCR_015672). 
  
Snapshots of stimuli during the Turn‐based Co‐operation (a) and Competition (b) rounds, and Concurrent Co‐operation (c) and Competition (d) rounds. In all examples, the Builder is assigned to the same color as the target pattern (i.e., yellow in a and d, blue in b and c), and scores by placing tokens in locations that recreate the pattern (indicated by solid red lines). The Other is assigned to the opposing color (blue in a and d, yellow in b and c), and scores by placing their tokens in locations that serve to help or hinder the Builder (dashed red lines); since the latter is achieved by placing tokens within the pattern space, thereby obstructing the Builder, the scoring location of Others and Builders are the same in Competitive rounds (solid red lines) 
  

### MRI data acquisition 
  
Brain imaging was performed using two identical 3T Siemens Prisma scanners located within the same facility, both equipped with a 64‐channel HeadNeck coil. First, we acquired high‐resolution whole‐brain T1‐weightened anatomical images (MPRAGE; TR/TE/TI = 2300/2.33/900 ms; flip angle = 8°; field of view = 252 mm × 224 mm; in‐plane matrix size = 252 × 224; slice thickness = 1 mm; 240 sagittal slices; iPAT GRAPPA accel. factor = 2; phase encoding = A>P; no fat suppression; acquisition time = 317 s). Functional time series were then recorded in two runs, each containing 570 volumes (approximately 20 min) acquired after four dummy scans—the turn‐based block was always followed by the Concurrent block. Blood‐oxygen‐level dependent (BOLD) images were obtained with T2*‐weighted echo planar imaging, with parallel acquisition (i‐PAT GRAPPA accel. factor = 2; 34 axial slices; TR/TE = 2000/35 ms; flip angle = 60°; field of view = 204 mm × 204 mm; in‐plane matrix size = 68 × 68; slice thickness = 4 mm; 34 axial slices; phase encoding = A>P). Axial slices were acquired in interleaved order, each one oriented parallel to a line connecting the base of the cerebellum to the base of orbitofrontal cortex to ensure whole‐brain coverage. A single external programmable signal generator (Siglent SDG1025,   http://www.siglent.com  ) initiated the acquisition sequence of both scanners to ensure maximal synchronization (mean asynchrony in volume acquisition = 1.69 [  SD   = 0.65] ms). Likewise, a single computer was used to present synchronized experimental stimuli to both scanners, and to record the timings of radio frequency pulses. 


### Neuroimaging data analysis 
  
The pre‐processing and analysis of functional and structural brain images was performed using various utilities within FMRIB's software library (Jenkinson et al.,  ; SCR_002823). gICA was performed using the GIFT toolbox for MATLAB (v2.0e;   http://mialab.mrn.org/software/gift  ; Calhoun, Adali, Pearlson & Pekar,  ), and ISC analyses were performed with in‐house scripts written and executed in MATLAB (v2018b, The MathWorks, Inc.). 

#### Pre‐processing 
  
For each pair, we obtained four time series (two for each participant—one acquired during the   Turn‐Based   block, the other during the   Concurrent   block) that were pre‐processed independently in the following manner: First, slice‐timing correction for interleaved slice acquisition was applied to the functional images, and each time‐series was detrended and high‐pass filtered across time (Gaussian‐weighted least‐squares straight‐line fitting; sigma = 50.0 s) and spatially smoothed with a 5‐mm full‐width half‐maximum Gaussian kernel. Motion correction was then performed with MCFLIRT (Jenkinson et al.,  ). To remove any residual motion artifacts, or signal caused by physiological noise (e.g., heart rate and respiration), we performed single‐session Independent Component Analysis with MELODIC (Beckmann & Smith,  ) to identify 50 spatio‐temporal components of the BOLD signal. Artifactual components were identified automatically using the Spatially Organized Component Klassifikator (SOCK; Bhaganagarapu et al.,  ), and any signals corresponding to these problematic components were regressed out of the time‐series using   fsl_regfilt  . Since these artifactual components were orthogonal to the signal removed previously by the high‐pass filter, there was no re‐introduction of noise (Lindquist, Geuter, Wager, & Caffo,  ). In our pre‐processing pipeline, the components returned by MELODIC that were identified as artifactual and subsequently regressed out of the time series (the set of nuisance covariates) were drawn from data that had been high‐pass filtered already. Finally, with FLIRT, the time‐series were registered to a corresponding high‐resolution structural image using Boundary‐based Registration, and this, in turn, was registered linearly to the Montreal Neurological Institute (MNI)‐152 template (12 degrees of freedom). 


#### Group‐independent component analysis 
  
We performed gICA to identify common aggregate spatial maps across the entire samples that are expressed through unique time‐courses for each subject. An alternative approach is to allow for unique spatial maps but common time courses, but this is less appropriate for fMRI data (see Calhoun et al.  ). 

The input consisted of 76 functional brain images (38 participants [19 pairs] × 2 blocks [  Turn‐based   and   Concurrent  ]), each containing 570 volumes. Two data reduction steps were first performed: principle component analysis (PCA) was applied initially to each individual time‐series, resulting in a set of 68 components from each of the 76 time‐series, and subsequently to all the resulting components concatenated into one matrix. The second PCA resulted in a set of 20 spatially orthogonal principal components. The optimal number of components to be extracted from each of these PCAs was determined by computing the minimum description length (MDL). The MDL principle is a formal version of Occam's razor, which determines an appropriate model complexity by extracting the maximum amount of information from the data without overfitting (Sammut & Webb,  ). Next, spatial gICA was performed on these reduced data using the INFOMAX algorithm to identify group‐level components that were independent of one another (Langlois, Chartier, & Gosselin,  ). To ascertain the reliability of these spatial components, gICA was run 20 times and the resulting estimates were compared using ICASSO: each estimated independent component occupies one point in the signal space, and if a component is reliable then each run of the algorithm should produce one point in the signal space that is very close to the “real” component. Thus, reliable independent components correspond to clusters that are small and well separated from the rest of the estimates. In contrast, unreliable components correspond to points which do not belong to any cluster. A cluster quality index,   I  , is then used to evaluate what clusters are the most compact and isolated; this index is computed as the difference between the average intra‐cluster and average extra‐cluster similarities. Eventually,   I   is equal to one for an ideal cluster (Himberg, Hyvärinen, & Esposito,  ). This ICASSO analysis revealed that all 20 components achieved very high cluster quality indices over all iterations (  I   = .97–.98). This part of the gICA pipeline is illustrated schematically in Figure  a. 
  
Group‐Independent Component Analysis (gICA) pipeline. (a) Two data reduction steps were performed on the pre‐processed data: PCA was first applied to each individual time‐series, and then to all the time‐series concatenated into one matrix. Next, gICA was performed on these reduced data using the INFOMAX algorithm, revealing 20 reliable components. (b) After the removal of five artifactual components, the remaining 15 components were back‐reconstructed to the individual input time‐series. Applying multiple regression to the subject‐specific time‐series revealed four components that were expressed along a time‐series aligned with interaction‐specific conditions. Note: Magnifying glasses represent stages of data reduction 
  
After visual inspection of the reliable components emerging from ICASSO, five were identified as artifactual and excluded from further analyses (e.g., components reflecting heartbeat, white matter, and cerebrospinal fluid; see Figure S1). Since the remaining 15 components were extracted from time‐series acquired during cooperative   and   competitive exchanges, and in both turn‐based   and   concurrent interactions, each one could express all dimensions of interaction equally or a specific dimension/combination of dimensions independently. To identify components that reflected brain responses associated with each condition (  Co‐operation, Competition  , and   Control  ), we used the results of the PCA data‐reduction steps to back‐reconstruct each component to the individual input time‐series. This resulted in a time‐course for each component specific to each subject in each block. Multiple regression analysis was then computed: For each participant, the explanatory variables were their subject‐specific back‐reconstructed time‐course for each independent component, and the outcome variable was their unique task design for each condition within each block. This resulted in subject‐specific   β  ‐values for each of the three conditions during the   Concurrent   or   Turn‐based   block (six   β  ‐values for each participant for each component). These   β  ‐values were then compared using paired‐samples   t  ‐tests to identify interaction‐specific components; that is, components for which the back‐reconstructed time‐course for each participant fit their task design of the experimental conditions more than the   Control   condition (  β   > 0 and   β   >   β  ; or   β   > 0 and   β   >   β  ), and showed greater fit for either the   Cooperation   or   Competition   condition. For components to be selected, this had to be true in both concurrent and turn‐based condition. This procedure, illustrated in Figure  b, identified four interaction‐specific components. 


#### Inter‐subject correlation analysis 
  
Next, to calculate the degree of neural alignment in each condition we computed matrices of cross‐correlations between the back‐reconstructed time‐series of interaction‐specific components for each interacting pair, separately for the   Turn‐based   and   Concurrent   block (e.g., correlation between the time‐series of component #1 in the Blue player and component #2 in their Yellow co‐player, in the   Turn‐based   block). For each component, Pearson correlations were applied to the entire back‐reconstructed time‐series from within each block (570 volumes). The resulting correlation coefficients were transformed to   z  ‐values, and the median was used as a coupling coefficient. To determine the significance of the resulting coefficients, we performed a randomization test with 10,000 permutations: in each iteration, we randomly selected 38 non‐interacting pairs (retaining the role of each participant; e.g., component #1 in the Blue player of one pair, and component #2 from the Yellow player of a different pair) and computed a median z‐transformed coefficient as above. This produced a null distribution of correlations among non‐interacting pairs for each interaction‐specific component, against which the significance of coupling between each interacting pair was then compared (see Figure 4a). Pairwise comparisons among the four non‐artifactual, interaction‐specific components revealed significantly higher correlations among interacting compared with non‐interacting pairs after Bonferroni correction (α = .05/4 ). Finally, to assess whether differences existed in the strength of neural coupling between the   Concurrent   and   Turn‐based   interactions, for each interaction‐specific component, we compared the within‐pair correlation coefficients using a Wilcoxon sign‐rank test (e.g., the coefficients calculated for all interacting pairs for Component #1 in the   Turn‐based   block were compared with those calculated for all interacting pairs for Component #1 in the   Concurrent   block). This analysis is illustrated in Figure  . 
  
Inter‐subject correlation (ISC) pipeline. For the seven non‐artifactual interaction‐specific components resulting from gICA, ISCs were computed for interacting pairs and compared with those between non‐interacting individuals. Finally, for each component, the ISCs between interacting pairs were compared between the Turn‐based and Concurrent blocks 
  
While   I   obtained from ICASSO was >0.9 for each cluster (component), to ensure that the individual back‐reconstructed time‐series were stable even with a slight change in the spatial configuration of the component, we ran the gICA and subsequent post‐processing analysis five times with the exactly same parameters. In the following section, we report only the results that were replicated in each of these five iterations. 




## RESULTS 
  
gICA revealed one component that was related more strongly to instances of the   Cooperative   compared with the   Control   rounds (component 10 in Figure S1; referred to herein as Coop#1), while three were associated more strongly with   Competitive   than   Control   rounds (components 13, 14, and 18; referred to herein as Comp#1, Comp#2, and Comp#3, respectively). The spatial pattern of brain regions comprising Coop#1 included bilateral precunei, bilateral clusters centered on the superior temporal sulci (STS) but extending dorsally to the TPJ and ventrally to the fusiform gyri, bilateral dorso‐lateral prefrontal cortices, and the cerebellum. Interestingly, Comp#1 consisted entirely of brain responses localized to the cerebellum. Those encompassed by Comp#2, however, included right precuneus, right superior frontal gyrus extending into prefrontal cortex, right caudate nucleus, right parietal inferior gyrus, and left cerebellum. In Comp#3, the brain responses were present bilaterally in superior frontal gyri, anterior cingulate cortex (ACC), anterior insulae (AI), precunei, the cerebellum, and left precentral gyrus. These results are presented in Figure  a. 
  
Results of gICA‐informed ISC analyses. (a) Spatial maps of four components identified by group‐Independent Component Analysis (gICA), which were expressed in individual brains along time‐series that corresponded to instances of cooperative or competitive interactions. (b) The randomization test revealed that the back‐reconstructed time‐series for each component were correlated significantly more strongly (  p   < .05, Bonferroni corrected) between interacting compared with non‐interacting players. Histograms show the null‐distribution of median correlation coefficients across all non‐interacting pairs—the frequency (y‐axis) with which correlations of different strengths (x‐axis) were identified across all permutations. The red line presents the median correlation coefficient across all interacting pairs. (c) Comparisons between the correlation coefficients (y‐axis) for all interacting pairs between the Concurrent (CN) and Turn‐based (TB) blocks. Note: Components emerging from gICA are overlaid onto the Colin27 template (Holmes et al.,  ) in MNI space 
  
For each of these components, ISC analyses revealed that the back‐reconstructed time‐courses were correlated more strongly between interacting than non‐interacting pairs after (  p   < .05, Bonferroni corrected; see Figure  b). Furthermore, this measure of neural alignment between interacting dyads was significantly stronger during the   Concurrent   relative to the   Turn‐based   block for Coop#1 (mean coupling coefficient: CN = .31 [range = −.05–.51] vs. TB = .14 [range = −.02–.27];   W   = 187,   Z   = 3.70,   p   < .001), Comp#1 (mean CN = .13 [range = −.01–.30] vs. TB = .03 [range = −.07–.15];   W   = 161,   Z   = 2.66,   p   = .008) and Comp#3 (CN = .35 [range = .04–.45] vs. TB = .25 [range = .01–.40];   W   = 176,   Z   = 3.26,   p   = .001). For Comp#2, however, neural coupling did not differ significantly between blocks (CN = .29 [range = .03–.48] vs. TB = .33 [range = −.15–.44];   W   = 54,   Z   = ‐1.65,   p   = .09). These results are illustrated in Figure  c, and detailed further in Table S1. 


## DISCUSSION 
  
To investigate whether different patterns of neural coupling between individuals emerge during dissociable types of interaction, we analyzed dual‐fMRI “hyperscanning” data acquired from dyads engaged in a variety of interactions using a combination of two techniques: a data‐driven gICA and subsequent ISC. This gICA‐informed ISC analysis revealed a distinct spatio‐temporal pattern of brain response that followed a time‐course associated with co‐operative exchanges, and three independent patterns that corresponded more closely to competitive interactions. More importantly, the time‐courses of all these components were correlated significantly between pairs of interactants, and these distinct patterns of interpersonal brain‐to‐brain alignment delineated among concurrent and turn‐based exchanges. These results demonstrate the utility of data‐driven approaches applied to hyperscanning data in elucidating the interpersonal neural processes that give rise to the two‐in‐one dynamic characterizing social interaction. 

Appreciating fully the ability of gICA‐informed ISC analysis to distinguish among different dimensions of interpersonal interactions requires an evaluation of the analytical process: The inputs were time‐series acquired during both cooperative   and   competitive conditions, and in both turn‐based   and   concurrent interactions. As such, components emerging from the gICA could express all interaction dimensions equally, or a specific dimension/combination of dimensions independently. Indeed, multiple regression applied to the back‐reconstructed time‐series revealed that only four of the 15 non‐artifactual components were specific to either cooperation   or   competition. By examining correlations in the time‐series of these patterns across all players—both interacting   and   non‐interacting pairs—we were then able to identify patterns of neural alignment that were both specific to real interactions and distinguished between co‐operative and competitive exchanges performed in a concurrent or turn‐based manner. 

The collection of brain regions expressing interpersonal neural coupling during co‐operative exchanges, Coop#1, encompassed bilateral precunei, STS, TPJ, and the cerebellum. A substantial body of research has shown that the precuneus, STS, and TPJ comprise a network of brain regions co‐activated during experimental tasks requiring the attribution of mental states to others, such as desires, intentions, and beliefs (Bardi et al.,  ; Carlson et al.,  ; Eddy,  ). Based on its engagement during visuo‐spatial mental imagery (e.g., Ghaem et al.,  ; Hanakawa et al.,  ), and both implicit and explicit metalizing (for meta‐analytic reviews, see Schilbach et al.,  ; Wolf, Dziobek, & Heekeren,  ), it is believed that the precuneus is involved in the representation of others' perspectives (Cavanna & Trimble,  ). Similarly, the TPJ responds when individuals are required to infer another person's perspective when it differs from their own (e.g., Dumontheil et al.,  ; Mazzarella et al.,  ); that is, when distinctions must be made between self‐ and other representations (Lamm, Bukowski, & Silani,  ; Uddin, Molnar‐Szakacs, Zaidel, & Iacoboni,  ). 

Since co‐operative interactions require both individuals to act in line with a common goal and in a manner that complements their interaction partner's behavior (Sebanz, Bekkering, & Knoblich,  ), it is perhaps unsurprising to observe neural alignment throughout these brain systems; both individuals must attempt to predict their co‐player's intentions and expectations in order to modify their own actions accordingly (Hampton, Bossaerts, & O'Doherty,  ; Jara‐Ettinger, Baker, & Tenenbaum,  ; Kestemont et al.,  ; Kestemont, Vandekerckhove, Ma, Van Hoeck, & Van Overwalle,  ). Indeed, brain‐to‐brain synchronization within the TPJ and STS has been reported during economic exchanges (Jahng et al.,  ; Tang et al.,  ; Zhang et al.,  ), cooperative joint‐action (Abe et al.,  ), and communicative tasks (Hirsch, Zhang, Noah, & Ono,  ; Kinreich et al.,  ; Rojiani et al.,  ; Wilson et al.,  ). What is surprising, however, is the ability of a data‐driven analysis to identify spatio‐temporal patterns of brain response that delineate among social interactions along the goal dimension, and within which the strength of neural alignment differentiates between exchanges along the interaction dimension. 

The first pattern of neural responses elicited during competitive exchanges, Comp#1, consisted exclusively of the bilateral cerebellum. An expansive corpus of research into the functions of the cerebellum points to its primary role in sensory prediction and the formation of expectations through interactions with the environment (Leggio & Molinari,  ; Nixon,  ). Within this pattern, neural alignment was significantly stronger during concurrent than turn‐based competitive interactions. We suggest this reflects greater inter‐brain contingencies in visuo‐spatial processing mechanisms during real‐time interaction, whereby each player must simultaneously predict and adapt to the behavior of their partner. 

The second spatio‐temporal pattern of brain responses elicited during competitive exchanges that were aligned between interacting players, Comp#2, comprised brain regions localized primarily to the right hemisphere, including lateral prefrontal cortex, caudate nucleus, inferior parietal cortex, and precuneus, but also the left cerebellum. The inferior parietal cortex is considered a higher‐order brain area involved in the visuo‐spatial control of motor behavior (Culham, Cavina‐Pratesi, & Singhal,  ; Gallivan & Culham,  ). Given the abovementioned putative role of the cerebellum in similar motor‐related spatial processing, this pattern of neural alignment might index temporally coupled dependencies in visuo‐motor processes during competitive interactions. Interestingly, the caudate nucleus has been implicated in response switching (Grahn, Parkinson, & Owen,  ), and the concerted engagement of the precuneus and the caudate nucleus has been observed during the planning and generation of strategic moves during competitive interactive games (Wan et al.,  ). Taken together, interpersonal neural coupling within this collection of brain regions might reflect the mutual recruitment of processes involved in the monitoring of a co‐players behavior and subsequent updating of one's own motor actions to allow for flexible co‐adaption during competitive interactions. Importantly, while all spatio‐temporal patterns were relatively unresponsive during the control condition, in which participants simply viewed the actions of their co‐player, within this collection of brain regions we observed no significant differences in the strength of inter‐player neural coupling between concurrent and turn‐based competitive exchanges. This might reveal a pattern of alignment common to both forms of competitive interaction, allowing individuals to plan their next move on the basis of their co‐player's preceding action. 

The third pattern of brain responses expressing neural alignment between players engaged in competitive interactions, Comp#3, encompassed the superior frontal cortices, ACC, AI, precuneus, and cerebellum. This converges with the findings of Wilson et al. ( ), who report ISCs of brain function during verbal communication within the ACC, lateral frontal cortices, and the precuneus. A network of frontal activations incorporating the dorsal ACC and AI constitute the so‐called salience network, which is thought to be responsible for identifying behaviorally relevant stimuli. In a previous study, we observed a similar pattern of neural alignment within the dorsal ACC and AI between players involved in an interactive game of economic exchange; more specifically, inter‐brain alignment in these regions was associated with the degree of reciprocity expressed between players (Shaw et al.,  ). We interpreted this to reflect the mutual effort of players to modify their own behavior according to that of their opponent, a process necessary to compete successfully in an inter‐dependent context. In this light, stronger alignment with a neural saliency‐detection system during concurrent compared with turn‐based competitive exchanges might index a greater effort of both players to process and react dynamically to their opponent's moves; during concurrent exchanges, each player's actions present a continuous flow of salient information to their opponent, demanding more flexible co‐adaptation. 

Interestingly, all but one of these patterns shared a common feature—neural alignment within the precuneus. This brain region is connected reciprocally to many other parts of the brain, and is considered a member of the so‐called “rich club”—a group of neural hubs that are interconnected among themselves (van den Heuvel & Sporns,  ). Our results suggest that the precuneus plays a central role in various forms of inter‐dependent social exchange; it may provide a channel through which social information is transmitted interpersonally and relayed to other brain systems to permit adaptive responses during social interaction. It is also interesting that no pattern. 

These distinct patterns of brain coupling provide unique insights into the interpersonal neural processes that unfold during dissociable forms of social exchange. In three of the components identified by gICA (Coop#1, Comp#2, and Comp#3), ISCs between interacting pairs were strongest during concurrent exchanges. This converges with the results from neuroscientific investigations that have employed dual‐EEG to investigate patterns of between‐brain alignment during unconstrained interpersonal behavior (Dumas, Martinerie, Soussignan, & Nadel,  ; Dumas, Nadel, Soussignan, Martinerie, & Garnero,  ); greater inter‐brain coherence is reported among interactants engaged in self‐initiated, spontaneous interactions compared with exchanges that are guided externally by an experimenter—a distinction paralleling that between turn‐based and concurrent exchanges. Importantly, these results do not simply reflect the degree of similarity in motoric‐ or sensory‐related brain responses: First, inter‐brain covariance was significantly stronger between pairs of interacting co‐players compared with pairs of non‐interacting players selected at random. Second, such interaction‐specific between‐brain covariance was observed in both concurrent and turn‐based exchanges—this index of neural coupling was present even when individuals took turns to observe the actions of their co‐player before making a reactive response, but more so when the players reacted to one another concurrently. Third, we only extracted this index of neural coupling from within spatio‐temporal patterns of brain response that followed a time‐course aligned more with experimental than control rounds. During control rounds, one individual (the Builder) recreated a pattern without any help or hindrance from the Other, while the Other observed the Builder passively. Hence, ISCs were extracted from patterns of brain response elicited during inter‐dependent interactions, whereby the moves of each individual were mutually dependent upon their co‐player's actions. As such, stronger ISCs during concurrent compared with turn‐based exchanges presumably reflects greater interpersonal neural alignment as both players monitor, evaluate, and adapt to the behavior of their co‐player in real‐time. 

It is important to acknowledge that the results of the present study must be reproduced in larger samples before we can evaluate properly the utility of gICA‐informed ISC for hyperscanning research. A more rigorous evaluation of this analytical technique also requires the present results to be reproduced with other interactive paradigms, and with designs that overcome any potential limitations of the current study. For example, dyads in our experiment always performed a block of turn‐based interactions before a block of concurrent exchanges; since the concurrent condition added a level of complexity to turn‐based interactions, our intention was to minimize fatigue and maximize motivation between the first‐ and second‐half of the procedure. In doing so, however, we may have introduced order effects, and so our results require reproduction in other procedures for which such influences cannot exist. 

Future research should also examine whether the interaction‐specific patterns of neural coupling revealed here extend to more real‐world social situations. Hyperscanning permits social neuroscience to be conducted in ecologically valid contexts; Toppi et al. ( ), for example, used dual‐EEG to investigate inter‐brain events among aircraft pilots during flight simulations, revealing patterns of between‐brain coherence that differentiated between various cooperative scenarios. It would be interesting to see whether the same patterns of neural coupling that we have observed with our interactive experimental task delineate among social exchanges with real‐world implications. Studies should also investigate if the patterns of interaction‐specific coupling observed in the present study are modulated by characteristics that have been shown to alter between‐brain events; should they truly reflect the social aspects of interpersonal exchanges; they should be influenced by the sex of interactants (Cheng et al.,  ) and the language used during verbal interaction (Pérez et al.,  ). 


## Supporting information 
  
 ## DATA AVAILABILITY STATEMENT

Data are not shared, but can be made available upon request. </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-30'>
<h2>30. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/27313976/' target='_blank'>27313976</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Pruning or tuning? Maturational profiles of face specialization during typical development</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Brain Behav</p>
<p><strong>Publication Year:</strong> 2016</p>
<p><strong>DOI:</strong> 10.1002/brb3.464</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4907975/' target='_blank'>4907975</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study reports whole-brain fMRI results (group-level mixed-effects analyses) in a healthy adult sample (n=51, ages 18–42) who performed a face-processing task. Face perception is a social-related task, and adults fall within the 18–60 range. The paper is not a review/meta-analysis and does not involve participants with psychiatric or neurological disorders. Although the study also includes children, it presents adult whole-brain results (and adult-only analyses used for ROI definition), so it is appropriate for inclusion in a meta-analysis of social-related fMRI in healthy adults. The fact that the paper additionally conducts ROI analyses does not exclude it, because whole-brain results are provided.</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
## Introduction 
  
Face processing undergoes significant developmental change with age. Two kinds of developmental changes in face specialization were examined in this study: specialized maturation, or the continued tuning of a region to faces but little change in the tuning to other categories; and competitive interactions, or the continued tuning to faces accompanied by decreased tuning to nonfaces (i.e., pruning). 


## Methods 
  
Using fMRI, in regions where adults showed a face preference, a face‐ and object‐specialization index were computed for younger children (5–8 years), older children (9–12 years) and adults (18–45 years). The specialization index was scaled to each subject's maximum activation magnitude in each region to control for overall age differences in the activation level. 


## Results 
  
Although no regions showed significant face specialization in the younger age group, regions strongly associated with social cognition (e.g., right posterior superior temporal sulcus, right inferior orbital cortex) showed specialized maturation, in which tuning to faces increased with age but there was no pruning of nonface responses. Conversely, regions that are associated with more basic perceptual processing or motor mirroring (right middle temporal cortex, right inferior occipital cortex, right inferior frontal opercular cortex) showed competitive interactions in which tuning to faces was accompanied by pruning of object responses with age. 


## Conclusions 
  
The overall findings suggest that cortical maturation for face processing is regional‐specific and involves both increased tuning to faces and diminished response to nonfaces. Regions that show competitive interactions likely support a more generalized function that is co‐opted for face processing with development, whereas regions that show specialized maturation increase their tuning to faces, potentially in an activity‐dependent, experience‐driven manner. 

 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (68649 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
The development of functional brain architecture that supports specialized cognitive functions, like face processing, is continually debated. In the IS (Interaction Specialization) account of functional brain development (Johnson  ), functional specialization is achieved by a dynamic interplay of changes in brain‐to‐function mappings. One key feature of the IS account is the presence of competitive interactions in these mappings such that a given brain region increases its tuning to a particular category while pruning back responses to other categories (Fig.  A). A consequence of this is that a particular brain region may show a preference for nonface categories earlier in development, or show no specific domain preference, but as the brain matures, the region becomes more narrowly tuned to faces and the preference for nonfaces will diminish with development. 
  
Hypotheses associated with different accounts of face and object processing development. Hypothetical specialization indices are shown on the   y  ‐axis and age is shown on the   x  ‐axis. A face specialization index is shown in red; an object specialization index is shown in blue. Competitive interactions are characterized by increased specialization for faces with age but decreased specialization for objects with age in the same brain region. Specialized maturation is characterized by increased specialization for faces with age but no developmental change for objects in the same brain region. 
  
Testing the developmental time course of both faces and nonfaces is critical in order to distinguish among different constraints on the development of functional specialization. As shown in Figure  B, an alternative to competitive interactions is specialized maturation of a brain region, or increased tuning to faces but no pruning of responses to non‐preferred categories. This outcome would be predicted by the Maturational account (discussed in Johnson  ; Joseph et al.  ) or Constructivist viewpoints (Quartz  ). In these alternative accounts, the primary process is increased tuning of a region to faces but minimal pruning back of nonpreferred responses. The maturational viewpoint posits that this increased tuning is determined genetically whereas the constructivist view posits that increased specialization is accomplished through Hebbian learning and dendritic growth, but not synaptic loss. Although Johnson (Johnson  ,  ) has suggested that there is little neurobiological evidence for the constructivist account, Farah et al. ( ) provided evidence for a strong form of the maturational viewpoint in their study of a boy who acquired a lesion at 1 day of age and showed the classic neurobehavioral profile of prosopagnosia when tested at age 16: deficits in face but not object processing and damage to bilateral occipital and occipito‐temporal cortex. They concluded that “prior to visual experience, we are destined to carry out face and object recognition with different neural substrates. This in turn implies that some distinction between face and object recognition, and the anatomical localisation of face recognition, are explicitly specified in the genome” (p. 122) and “the distinction between faces and other objects, and the localisation of faces relative to other objects, is fully determined prior to any postnatal experience” (p. 117). However, if the maturational account is viable then children should show the same preference for faces in occipito‐temporal cortex (or in the more specific “fusiform face area,” FFA; (Kanwisher et al.  ) as adults do. Moreover, if portions of the fusiform gyrus are completely devoted to face processing from birth, then other objects should not recruit that region. However, neither of these conditions holds, because the FFA responds to objects other than faces (Joseph and Gathers  ) and perceptual expertise with other categories can recruit the FFA (for example “Greebles” (Gauthier et al.  ); chess configurations (Bilalic et al.  )). Moreover, as discussed more below, specialization for faces increases with age. This suggests that a strong form of the maturational viewpoint may not be viable. We instead investigate the constructivist idea that a brain region may increase in tuning to faces without pruning of nonface responses. 

Systems‐level approaches to cortical development that use fMRI or functional connectivity analyses have not yet distinguished between the IS and alternative accounts. In an in‐depth treatment of this topic, Joseph et al. ( ) outline the conditions that should be met in order to support the IS versus maturational/constructivist accounts. Nearly all of the fMRI studies that have examined developmental changes in functional organization for basic face processing (i.e., not including higher social cognitive functions such as facial emotion, social evaluation, mentalizing; (Aylward et al.  ; Gathers et al.  ; Golarai et al.  ,  ; Haist et al.  ; Joseph et al.  ; Passarotti et al.  ; Peelen et al.  ; Pelphrey et al.  ; Scherf et al.  ,  ) have supported a pattern of increased specialization for faces with age, indicated by increased magnitude or extent of FFA response to faces versus nonfaces. However, this outcome would be predicted by both the IS and alternative viewpoints, as shown in Figure  . For both competitive interactions and specialized maturation, the relative difference between face and nonface response increases with age, but the difference between the two accounts is driven by the response to nonfaces as a function of age,   in the same brain region where face specialization increases with age  . Specialized maturation predicts no change in nonface response with age whereas competitive interactions predict a decrease in nonface response with age. Prior studies have either examined the relative response to faces versus nonfaces (which is inconclusive with respect to the IS or maturational accounts) or showed no developmental change for nonfaces in regions that are object‐preferential or not preferential for faces (Golarai et al.  ,  ; Scherf et al.  ,  ; Peelen et a0l.  ; Joseph et al.  ). Also, these studies did not examine age trends separately for faces and nonfaces   in the same brain region   which is the only way to distinguish these two accounts. This study accomplishes this, which represents a significant advance in teasing apart the constraints on cortical development of face expertise. In the present conceptualization, the strongest evidence for competitive interactions would be that the   same   brain region demonstrates a developmental tradeoff in tuning for different categories (Fig.  ). 

One study has provided some evidence for the phenomenon of tradeoffs in tuning for different categories. Cantlon et al. ( ) showed a face‐specific response in the right FFA in 4 to 5 year olds, suggesting very early specialization of this cortical region for faces. Interestingly, though, face matching accuracy (measured outside of the scanner) was negatively correlated with the right FFA's response to letters, but was not correlated with the response to faces. In other words, face‐matching performance at this very early age was more strongly linked to changes in the FFA's tuning to the   nonpreferred category   (letters) than tuning to the preferred category (faces). The authors interpreted this result as driven by pruning back responses to the nonpreferred category with development, rather than driven only by increased tuning to the preferred category. 

Because so few studies have investigated developmental changes in both pruning and tuning processes at a systems level with fMRI, this study will examine both phenomena. It is possible that some regions are indeed largely destined to process faces without competition from other nonface categories, whereas other regions co‐opt the kind of processing that is initially applied to objects, or to both faces and objects more generally, in order to fine tune face processing. To our knowledge, no fMRI studies have examined this possibility. 

To delineate among different accounts of development of face specialization, this study examines face and object specialization changes during childhood (younger group: 5–9 years; older group: 9–12 years) and in adulthood in a network of regions implicated in face processing in adults. In order to examine age trends for faces and nonfaces (objects) simultaneously, the present study compares each category to an active control condition, viewing visual textures, which enables scaling each category's response to a common activation baseline rather than comparing faces and objects directly. This allows us to distinguish between competitive interactions and specialization maturation profiles. The study also explores various approaches to index face and object specialization. The measure of face (or object) specialization used in this study scales the differential response to faces versus nonfaces to the maximum value for each subject in each region, thereby controlling for age‐related magnitude differences when measuring face or object selectivity. To our knowledge, other studies did not scale responses in this manner. Because the goal is to examine how face specialization develops, the face‐preferential ROIs (regions of interests) are defined in adults, as an estimate of the endpoint of the developmental process. Adults are expected to demonstrate more face specialization than children given prior literature findings. ROIs are defined using a subset of the adults, but hypotheses about IS and the alternative accounts are tested in the full sample of adults and children to maximize statistical power. Because the full sample was not used to define the ROIs, hypothesis testing was separate from ROI definition. However, we also conduct analyses using the smaller sample of adults and all children in order to test hypotheses completely independently from ROI definition (Kriegeskorte et al.  ). 

The analytic approach examines age group effects in the adult face network (using ANOVAs conducted in ROIs) to explore interactions of age and category specialization (face or object specialization index) in face preferential regions. Although the ROI are defined in adults, it is possible that children recruit face‐ regions that are different from the regions recruited by adults, as demonstrated in a prior study (Joseph et al.  ). The finding that children recruit different regions from adults is consistent with the IS account in that some regions lose functionality over development to make way for different regions to be specialized. This study does not test this particular hypothesis directly, but will explore additional regions recruited for faces in children, both at the group level and at the individual‐subject level. 

The IS account will be supported by findings of competitive interactions (Fig.  A) in regions that are specialized for faces in adults; that is, there will be decreased object‐specialization (pruning) and increased face‐specialization (tuning) with age in the same brain region. Although Figure  A illustrates greater object‐ than face‐specialization in younger children, this is not necessary to support competitive interactions. However, it would be compelling to show that a brain region is initially recruited for objects, but then becomes tuned to faces with development. The Maturational and Constructivist viewpoints will be supported by findings of specialized maturation (Fig.  B); that is, there will be increased face‐specialization (tuning) but no changes in object specialization with age (no pruning). This study will reveal whether pruning or tuning mechanisms are more prominent in the development of specialized brain networks for face processing. Knowing which regions show a specialized maturation profile versus competitive interactions has strong implications for the understanding the degree of neuroplasticity present in the brain for face processing. In turn, this knowledge could inform behavioral interventions for individuals who encounter difficulty with various face capacities, as in Autism Spectrum Disorder, Williams Syndrome or developmental prosopagnosia by targeting the neurobehavioral domains that are most likely modifiable through learning and experience. 


## Method 
  
### Participants 
  
Forty‐eight healthy right‐handed children (23 males, 5.5–12 years, mean age = 8.7 years, SD = 1.94) were enrolled in and completed the study, but due to excessive head motion (i.e., more than 20% time points with relative displacement >0.5 mm), data from eight participants were eliminated. The remaining 40 child data sets were separated into two age groups similar to the age groups used in prior studies (Gathers et al.  ; Joseph et al.  ,  ): 21 younger children (seven males, 5.5–8.4 years, mean = 7.1 years, SD = 0.86) and 19 older children (11 males, 9.3–11.7 years, mean = 10.5 years, SD = 0.59). This age grouping is also well motivated based on the finding that some aspects of face processing show significant developmental changes around age 10 or are already adult‐like by this age (Diamond and Carey  ; McKone et al.  ). Twenty three of these subjects’ data were used as healthy controls reported in (Joseph et al.  ), but that paper did not analyze face‐ and object‐specialization indices as a function of different kinds of maturational profiles (specialized maturation or competitive interactions) as in this study. 

Fifty‐nine healthy right‐handed adult volunteers (29 males; mean age = 26.5 years, SD = 6.0, range 18–42) were compensated or received course credit for participation. Due to excessive head motion (max absolute motion >1.75 mm, or half the voxel size), data from eight participants were eliminated, leaving 51 adult participants (26 males; mean age = 26.7 years, SD = 6.1, range 18–42). Results from the adult group have been reported in (Collins et al.  ), but the analysis of face‐ and object‐specialization indices in this study was not reported in that prior study. 

No participants reported neurological or psychiatric diagnoses or pregnancy and all provided informed consent before participating. All procedures were approved by local Institutional Review Board. 


### Stimuli and procedure 
  
Three different categories of visual stimuli were used in the present face localizer task: face photos, manmade object photos, and texture patterns. These visual stimuli were organized into a block‐design task which consisted of nine 17.5 sec blocks (three for face, three for object, and three for texture) with 12.5 sec fixation period interleaved. During each task block, 10 different yearbook face photos, manmade objects, or texture pattern were shown. Each photograph was presented for 1000 msec following a fixation of 750 msec. During each fixation block participants saw a black crosshair on a white background. Participants were asked to press a button each time a stimulus appeared using a fiber‐optic response pad (MRA Inc., Washington, PA) to ensure attentive processing. All groups showed a high rate of response (Adults: 97.9%; older children: 91.5%; younger children: 84.8% (due to a technical issue three adults’ and one younger child's responses were not recorded and not included in above accuracy calculation), indicating that even the younger children attended to the stimuli. Each participant completed one face localizer run and four other functional runs of a matching task in counterbalanced order. Results from the matching task are not reported here. 


### fMRI Data acquisition and analysis 
  
Images were acquired on a Siemens 3T Trio MRI system (Erlangen, Germany) at two different sites, but the hardware and software versions were identical across sites. Scanning included a 109‐volume (272.5 sec) whole‐brain functional scan (gradient echo EPI; TE = 30 msec, TR = 2500 msec, flip angle = 80°, FOV = 22.4 cm × 22.4 cm, interleaved acquisition of 38 axial contiguous 3.5‐mm slices) and a T1‐weighted anatomical scan (MPRAGE; TE = 2.56 msec, TR = 1690 msec, TI = 1100 msec, FOV = 25.6 cm × 22.4 cm, flip angle = 12°, 176 contiguous sagittal 1‐mm thick slices). Field map information (to correct geometric distortions caused by static‐field inhomogeneity) was also collected. E‐prime software (version 1,   www.pstnet.com  ; Psychology Software Tools) running on a Windows computer connected to the MR scanner presented visual stimuli and recorded the time of each MR pulse, visual stimulus onset, and behavioral responses. 

Preprocessing and statistical analysis were conducted using FSL (v. 4.1.7, FMRIB, Oxford University, Oxford, U.K.). For each subject, preprocessing included geometric distortion correction, motion correction with MCFLIRT, spatial smoothing with a 7‐mm FWHM Gaussian kernel and temporal high‐pass filtering (cutoff = 100 sec). Statistical analyses were then performed at the single‐subject level (FEAT v. 5.98). Each scan was modeled with three EVs (explanatory variables; faces, objects, and textures) convolved with a double gamma HRF, and a temporal derivative. Baseline blocks were not explicitly modeled. For the analysis of children's data, in addition to including six head motion parameters (three translational, three rotational) as confound EVs, we further included a spike EV which reflected all time points with relative displacement >0.5 mm to regress out the motion artifacts. We opted to use a single spike EV rather than scrubbing (multiple spike EVs), because the number of time points we had to detect any single effect (e.g., Face, Object or Texture activation) is relatively smaller than the number of time points used in other designs (e.g. continuous resting state) when scrubbing is typically applied. Since scrubbing basically removes the time point in question, this approach could seriously degrade power to detect the effects of interest in this study. 


### Regions‐of‐interest definition 
  
Half of the adult subjects (  n   = 25) were randomly selected (13 males, 20–41 years of age) to define the ROIs for the present study. Face > object, face > texture, and face > fixation statistical maps were calculated at the individual subject level, then a mixed‐effects group analysis (using FLAME 1 + 2) yielded group‐level statistical parametric maps for face > fixation and face > object contrasts in the 25 adults. For each adult subject, contrast maps were registered via the subject's high‐resolution T1‐weighted anatomical image to the adult MNI‐152 template (12‐parameter affine transformation; FLIRT) yielding images with spatial resolution of 2 mm . Group contrast images were thresholded using clusters determined by   Z   > 2.3 and a corrected cluster significance threshold of   P   = 0.05. Face‐preferential regions were defined by the logical combination (Joseph et al.  ) of face > object and face > texture contrasts, with cluster local maxima based on the face > object contrast. We identified 14 local maxima across the brain in this step, and the ROIs were defined as 7 mm‐radius spheres centered on these local maxima. A 7 mm radius sphere was chosen because our image smoothing kernel was 7 mm. 


### Regions of interest analysis 
  
For each ROI defined in the 25 adults, % signal change relative to fixation was extracted for each event type (faces, objects, textures) from the first level analysis (using FSL's Featquery tool) for each subject (51 adults, 19 older children, 21 younger children). Percent signal change for the three categories (face, object, texture) for each subject and region was then used to compute an FSI (face specialization index) and an OSI (object specialization index). As there is no standard approach to computing a specialization index, we explored different formulas (outlined in Appendix S1). Based on its distributional properties and better face validity, we adopted FSI  and OSI  for the primary analyses:   where  and   F  ,   O  ,   T   are percent signal change for faces, objects, or textures, respectively, relative to baseline. 

Similarly,  

This formula is a modification of that used by Joseph et al. ( ) with an adjustment for negative values described by Simmons et al. ( ). This formula scales the face‐ (or object‐) preferential response to the maximum value of Fpc, Opc, and Tpc which addresses potential age differences in BOLD signal magnitude. FSI  and OSI  will range from −1 to 1, with more positive values indicating greater specialization for faces (or for objects in the case of OSI ) and more negative values indicating a preference for the other two categories. 

Although the specialization index is the primary‐dependent variable in this study, we also determined whether percent signal change relative to baseline for the face condition was different from 0 in each age group separately for each ROI. This analysis is important for illustrating that even if the FSI is 0 for an age group, this does not imply that there was no activation in a region. A specialization index of 0 indicates that there was no preferential activation for faces (or objects), but the percent signal change could be greater than 0. To test this, a one‐sample   t  ‐test was used to determine whether percent signal change was greater than 0 for a given region and age group. 


### Analysis of FFA size 
  
Given that other studies have reported developmental changes in FFA extent (Golarai et al.  ,  ; Scherf et al.  ; Peelen and Kastner  ; Haist et al.  ), the present study explored whether FSI  or OSI  would be different for different FFA sizes. A series of right FFAs that differed in size were generated from the Face > Object contrast in the 25 adults that were used to define ROIs for the primary analysis by applying different statistical thresholds (from   z   = 1.4 to   z   = 3.0 step = 0.1, uncorrected, no cluster correction). The reason for using   z   = 1.4 as the minimum threshold was that this was the lowest threshold at which a succinct region consistent with the FFA emerged. At lower thresholds the FFA was connected with activations around lateral occipital cortex. BOLD signals were extracted and FSI  and OSI  were further examined as a function of FFA size using univariate ANOVA to test if the main effect of age was significant for each FFA size and one‐sample   t  ‐tests to determine whether FSI  was different from 0 for each FFA size and age group. 


### Analysis of individual‐subject face‐preferential responses 
  
One concern with using a group‐defined ROI to assess degree of face specialization is that the BOLD signal is averaged and smoothed, thereby potentially diluting face specialized responses in some individuals. This may especially be a concern with developmental studies given that some studies report different loci of activation to faces in children compared to adults (Gathers et al.  ; Joseph et al.  ; Passarotti et al.  ). To address this, we isolated face‐preferential voxels for each individual subject. Face‐preferential voxels were defined from the Face > Object contrast in each subject within an anatomically defined right fusiform ROI (from the AAL atlas (Tzourio‐Mazoyer et al.  )). Individual right fusiform masks were generated in subject's native EPI space based on the inverse transformation matrix used to register native space to MNI atlas space (which was generated in the previous registration step). Individual‐subject voxels that survived an uncorrected threshold of   z   = 3.1, or   P   < 0.001 (similar to the approach used by Golarai et al. ( )) were then submitted to ANOVAs to determine age effects on the number of significant voxels, location of the peak voxel, and degree of face and object specialization among surviving voxels. 



## Results 
  
### Group‐level activation results 
  
Face‐ preferential regions for the 25 adults used for ROI definition are outlined in Table   and illustrated in Figure  . As expected, face‐preferential regions included the right FFA and OFA (occipital face area), right IFG (inferior frontal gyrus), dmPFC (dorsomedial prefrontal cortex), right pSTS (posterior superior temporal gyrus), right posterior MT (middle temporal cortex), bilateral AMG (amygdala), and bilateral occipital pole, as well as other brain regions. These regions served as ROIs in which FSI  and OSI  were further examined. 
  
Regions of interest (listed from anterior to posterior) isolated from a subset of the adults and results of the ROI analyses 
      
 ROI  s (regions of interest) used in the present study.   ROI  s were defined as face‐preferential in half of the adult sample, using   GRF   cluster correction,   P   < 0.05 (see text and Table   for more details). l, left; r, right;   AMY  , amygdala;   FFA  , fusiform face area;   IFG  ‐oper, inferior frontal gyrus, pars opercularis;   IFG  ‐orb, inferior frontal gyrus, pars orbitalis;   OFA  , occipital face area;   pSTS  , posterior superior temporal sulcus;   MT  , middle temporal gyrus; dm  PFC  , dorsomedial prefrontal cortex. 
  
We also examined the Face versus Object and Texture activation map (which is similar to face‐preferential activation) in each age group separately in order to examine whether younger children recruit different regions than older children or adults as reported by Joseph et al. ( ). Figure   shows the statistical parametric map from the contrast Face versus Object and Texture in each age group separately (all adults were included here). The left side of the figure shows activation that survived an uncorrected threshold and the right side shows activation that survived cluster correction. One obvious point from these results is that younger children show no activation at corrected thresholds, but show some, albeit scant, activation at an uncorrected threshold, including the right FFA. Most of the activations in older children overlapped with activations in adults with the exception of fairly extensive bilateral operculum activations, near primary auditory cortex (Fig.  B, green arrows). Notably, though, much of the activation in adults is missing in both older and younger children including the extensive occipital, anterior temporal, frontal and AMG activation. 
  
Face versus Object and Texture activation for each of three age groups: (A) younger children, (5–9 years), (B), older children, (9–12 years), (C) adults. The left panel shows results for an uncorrected threshold and the right panel shows results using cluster correction. The green arrows indicate regions of activation in older children that were unique to that age group. 
  

### Regions of interest results 
  
In each ROI, a 2 (Category: FSI , OSI ) × 3 (Age: younger children, older children, adults) mixed ANOVA was conducted (with age as a between‐subjects variable and category as a repeated measure) to determine whether face or object specialization varied across age. Each maturational profile predicts that there will be a Category × Age interaction, but the presence of an interaction by itself would not distinguish between competitive interactions and specialized maturation. Therefore, in regions that showed a Category × Age interaction, we examined the simple effect (Keppel and Zedeck  ) of age group for FSI  and OSI  separately. If the simple effect of age was significant only for FSI  (and if FSI  increased with age) then specialized maturation would be supported. If the simple effect of age was significant for both FSI  and OSI  (and if FSI  showed an increase but OSI  showed a decrease with age), then competitive interactions would be supported. Results are summarized in Table  . 

Of the 14 regions, 11 regions showed a significant or marginally significant Age × Category interaction. Bilateral occipital poles and the left OFA did not show an interaction so no simple effects analyses were conducted in these regions. However, simple effects analyses conducted in the other 11 regions provided evidence for both specialized maturation and competitive interactions (Fig.  ). The right pSTS, right AMG and right IFG‐pars orbitalis all showed evidence for specialized maturation in that the Category × Age interaction was significant and the simple effect of age was only significant for FSI  indicating increased tuning to faces with age but not objects. The right FFA, dmPFC, and bilateral thalamus showed weak patterns of specialized maturation, because either the simple effect of age for FSI  or the interaction was marginally significant. Competitive interactions emerged in the right IFG‐ pars opercularis and left AMG, in that the simple effect of age was significant for both FSI  and OSI  and these age trends were in opposite directions, indicating increased tuning to faces and increased pruning of responses to objects. A weaker form of competitive interactions emerged in the right OFA and right MT, because one or two of the simple effects was marginally significant. 
  
Developmental trajectories in   ROI  s (regions of interest).   ROI  s with profiles of specialized maturation or competitive interactions are shown “Strong” profiles mean that the Age × Category interaction was significant and the simple effect(s) or interest were also significant. “Weak” profiles mean that either the Age × Category interaction or the simple effect(s) or interest were marginally significant * indicates that   FSI   or   OSI   was significantly different from 0 for the given age group according the a one‐sample   t  ‐test. Error bars are standard error. 
  
Another analysis was conducted to confirm that the regions showing competitive interactions had a different age profile of object‐specialization than regions showing specialized maturation, as the profile for object‐specialization is what differentiates the two accounts. OSI  was averaged in the seven regions that showed specialized maturation and in the four regions that showed competitive interactions to yield two OSI  values per subject. These values were then submitted to an ANOVA with OSI  as the dependent variable, profile type (competitive interaction, specialization maturation) as the repeated factor and age (adult, older, younger) as the between‐groups factor. If the two profile types are indeed different in terms of object specialization, then the Age × Profile interaction should be significant and the simple effect of age should only be significant for the competitive interactions profile. This was confirmed with a significant Age × Profile interaction,   F  (2, 88) = 3.2,   P   = 0.046, and a simple effect of age only for the competitive interaction profile,   F  (2, 88) = 6.9,   P   = 0.002, but not for specialized maturation,   F  (2, 88) = 1.5,   P   = 0.226. 

Although a significant age effect for either category or both categories reflects developmental change, it is not clear at which age specialization emerges. Potentially, this could be tested by conducting post hoc   t  ‐tests between age groups to determine whether children show lower (or higher) specialization than adults. However, these post hoc comparisons could reveal significant age differences, even if face or object specialization itself was not very pronounced. In other words, it would be important to determine whether FSI  and OSI  were different from 0 at any age because that would indicate that significant face or object specialization emerged at that age. Therefore, for each significant simple effect of age (for FSI  or OSI  or both) we conducted a one‐sample   t  ‐test against 0 for each age group separately. For specialized maturation, these   t  ‐tests were only conducted for FSI ; for competitive interactions, these   t  ‐tests were conducted for both FSI  and OSI  (given that these were the significant simple effects of age). An early developmental process would be indicated if younger children's FSI  or OSI  showed a significant deviation from 0. A late developmental process would be indicated if only adult's FSI  or OSI  significantly deviated from 0. The ages at which the FSI  or OSI  deviated from 0 is indicated by asterisks in Figure  . For specialized maturation regions, the bilateral thalamus, dmPFC and right IFG‐orbitalis showed significant face specialization only in adults indicating later developmental specialization, whereas in the right FFA, right pSTS, and right AMG, significant face specialization was present for older, but not younger children indicating earlier specialization occurring sometime before age 9. For regions showing competitive interactions, the left AMG, right OFA and right MT showed significant face specialization for older children and adults and the right IFG pars opercularis showed significant face specialization only for adults. Right OFA and left AMG also showed significant object specialization only for younger children. Results were similar using only half of the sample, with only a few exceptions (see Appendix S2). 

Although FSI  and OSI  served as the primary specialization indices, the results for the other approaches to calculating face and object specialization are presented in Appendix S2. The main effects and interactions results are somewhat similar across measures, especially between FSI  and FSI . But note that FSI  measure was chosen based on its distributional properties and greater face validity and not based on the significance of results from the repeated measures ANOVAs. 

The one‐sample   t  ‐test to analyze whether percent signal change was different from 0 for the face condition revealed that fMRI signal was different for adults in all regions (  P   < 0.05). For older children, fMRI signal for faces was different from 0 in all regions (  P   < 0.05), except the IFG‐orbital, right thalamus, and right MT. For younger children, fMRI signal for faces was different from 0 in the right FFA, right and left OFA, the right IFG‐opercular and right IFG‐orbital cortex (  P   < 0.05), but not in left and right AMG, left and right thalamus, dmPFC, MT or the pSTS, the IFG‐orbital, right thalamus, and right MT. 


### Results for the analysis of FFA size 
  
Other studies have reported that the right FFA increases in size with age (Golarai et al.  ,  ; Scherf et al.  ; Peelen et al.  ; Haist et al.  ) and the results in Figure   also indicate that this is also the case when the same threshold is applied to all age groups (in this case,   P   = 0.005, uncorrected). Consequently, the failure to find face specialization in the youngest children in this study may be due to using a larger FFA (as defined in adults) which may have included many voxels that were not specialized for faces in children. In other words, if a smaller FFA (i.e., roughly the same size as the FFA shown in Figure   for younger children) had been applied to the child data, the FSI  may be comparable to that of adults, or it might be significantly different from 0, because it would only include the most face specialized voxels in younger children. We also examined whether a larger FFA than used in the primary analysis would dilute FSI  in any age group to further determine whether face specialization depends on spatial extent of activation, more generally. 

To test these possibilities, we examined age effects on FSI  (and OSI ) as a function of FFA volume (Fig.  ). For FSI , age group effects were significant at each FFA volume greater than 0.43 mL (  P   < 0.05) with adults showing a higher FSI  than younger children but not older children. For smaller FFA volumes (  z   > 2.9, size < 54 voxel or 0.43 mL), the age effect was no longer significant. However, one‐sample   t  ‐tests that examined whether FSI  was different from 0 at each FFA volume for each age group revealed that FSI  was different from 0 at all volumes for adults and older children but was not different from 0 at any volume for younger children. OSI  was not significantly different from zero at any size for any age groups. Therefore, the present findings related to increased FSI  with age (at least in the right FFA) are not driven by arbitrary thresholding or activation extent because they are consistent across different levels of thresholding, with the exception of very small volumes. OSI  did not show any age differences as a function of FFA size. 
  
(A)   FSI   (Face specialization index) as a function of   FFA   (fusiform face area) volume in each age group. The * indicates that the main effect of age was significant at each of the volumes greater than .43 mL. All   FSI   values for adults and older children were significantly greater than 0 according to one‐sample   t  ‐tests. (B)   OSI   (Object specialization index) as a function of   FFA   volume in each age group. None of the   OSI   age effects was significant. Error bars are standard error of the mean. (C) Illustration of different   FFA   volume sizes. (D) Illustration of the location of the peak face‐preferential voxel in each subject who showed one or more voxel in the anatomically defined fusiform gyrus at an uncorrected   P   < 0.001. (E) The average number of suprathreshold face‐preferential voxels in the fusiform gyrus by age group. (F)   FSI   and   OSI   calculated in all suprathreshold voxels as a function of age group (  n   = 8 younger children,   n   = 15 older children and   n   = 39 adults). All specialization indices were different from 0 according to a one‐sample   t  ‐test. 
  

### Individual‐subject face‐preferential responses 
  
The percent of subjects that showed surviving face preferential voxels in the anatomically defined fusiform gyrus was 76% of adults, 63% of older children and 50% of younger children. These voxels were scattered throughout the posterior, mid‐ and anterior fusiform gyrus (Fig.  D). The effect of age group on number of surviving voxels in the fusiform was marginally significant,   F  (2, 61) = 2.99,   P   = 0.058 (Fig.  E). Post hoc comparisons using Tamhane's   t  ‐test indicated that adults had more surviving voxels than younger (  P   = 0.001) but not older (  P   = 0.33) children. Among subjects with suprathreshold voxels, the majority of adults (74%) had 10 or more suprathreshold voxels, whereas only half of older children (53%) and only 12% (1 out of 8) of younger children had 10 or more surviving voxels. Interestingly, the effect of age on the anterior‐posterior locus of the peak voxel in the fusiform was marginally significant,   F  (2, 61) = 2.66,   P   = 0.079, as was the effect of age on the dorsal‐ventral locus of the peak voxel:   F  (2, 61) = 3.1,   P   = 0.053. Children activated a more anterior and ventral aspect of the fusiform than did adults; however, post hoc comparisons indicated no significant differences. In addition, among subjects that showed suprathreshold activation, the Category × Age repeated measures ANOVA revealed a significant interaction,   F  (2, 59) = 11.8,   P   < 0.0001. The simple effect of age on FSI  was significant,   F  (2, 61) = 3.98,   P   = 0.024. Younger children showed a higher FSI  (  P   = 0.0001) than adults (Fig.  F). The effect of OSI  was also significant,   F  (2, 61) = 13.04,   P   = 0.0001. In this case, adults showed a lower OSI  than older children (  P   = 0.002). To explore whether some of these age group differences in various aspects of activation (number of voxels, locus or degree of face and object specialization) reflect a developmental change (rather than some other individual difference), we conducted Spearman rank correlations with age among children. However, none of these features of activation was correlated with age. 



## Discussion 
  
One of the primary goals of this study was to determine whether children show the same degree of face specialization as adults in brain regions recruited by adults for face processing. Several different types of analyses converged on the finding that younger children do not show the same degree of face specialization as adults. This was demonstrated by lower face specialization indices in younger children, no activation that survived statistical thresholds in the voxel‐wise group analyses in younger children, fewer younger children who show supra‐threshold voxels when individual‐subject ROI were examined, and fewer surviving voxels in younger children's fusiform gyrus ROIs. 

Also, face specialization increased with age in many critical components of the face network, in agreement with other studies (Aylward et al.  ; Golarai et al.  ; Peelen et al.  ; Joseph et al.  ,  ). Face specialization was present in older children in the majority of regions (right FFA, right AMG, left AMG, right pSTS, right MT and right OFA) but did not emerge until young adulthood in frontal regions (right dmPFC, right IFG‐orbital, right IFG‐opercular) and the thalamus. The finding of delayed specialization in frontal regions is not surprising given the protracted development of these regions (Paus  ). Importantly, the face‐specialization index not only assessed degree of face preference relative to nonface categories but also controlled for age‐related differences in activation magnitude. Therefore, the developmental changes in the present study were scaled to the maximum level of activation in a region for each individual. Moreover, the lack of face specialization in younger children was not driven by failure to activate some of the core face network regions because younger children showed an fMRI signal that was greater than baseline in the right FFA, bilateral OFA and the two inferior frontal regions. However, these regions were not more strongly activated for faces compared to the other two experimental conditions, as was the case in adults. In addition, degree of face specialization was not dependent on the volume of the group‐defined FFA (see Section  ). The majority of the findings in the present paper support the idea of minimal face specialization in younger children, as a group, but a subset of children showed face specialization in the fusiform gyrus, which is discussed more in Section  . 

Another major goal was to determine whether regions that showed increased face specialization with age had concomitant decreases in object specialization, in support of competitive interactions, or whether increased face specialization emerged with no change in object specialization with age, in support of specialized maturation. The present study provided evidence for both specialized maturation and competitive interactions in the development of functional properties of adult face network regions. The evidence for each of these frameworks is discussed in turn below. 

### Specialized maturation 
  
Within the developmental time window examined here, several regions primarily in the right hemisphere showed increased face specialization with age, but no changes in object specialization with age – the right FFA, right pSTS, dmPFC, right AMG, right IFG‐orbitalis and bilateral thalamus. Hence, cortical specialization for faces emerges gradually in these regions, but not by competing with object representations. In one sense, specialized maturation could indicate a developmental process that unfolds gradually over time and is immune to functional reorganization with development, as predicted by the Maturational viewpoint (as discussed in Johnson  ; Joseph et al.  ). The strong form of this framework suggests that the specialized function of a particular brain region is determined at birth, and others have made a similar argument with respect to face processing (Farah et al.  ). However, face specialization did not emerge until adulthood in the frontal regions and the bilateral thalamus and face specialization was present in older children in the right AMG, right FFA, right pSTS. Neither of these outcomes supports the strong form of specialized maturation, but they do support the constructivist viewpoint that tuning to faces increases with age, but not by competing with responses to nonfaces. 

Another consideration regarding the interpretation of specialized maturation is that this particular maturational profile may only hold within the developmental time window examined here. It is entirely possible that in an earlier time window, evidence for competitive interactions would emerge in that regions that showed face‐specialized maturation may show object specialization at an earlier age than tested in this study. Cantlon et al. ( ) tested face‐specialization in the right FFA (compared to responses to other visual categories) in 4‐to‐5 year old children and showed a face‐preferential response even at this early age, rather than a preference for nonfaces, which would support specialized maturation of this region in an earlier time window. However, they also showed that face identification accuracy in children was correlated with a lower right FFA response to nonfaces (letters), but was not correlated with the right FFA response to faces. They interpreted this finding as a marker of pruning, or the attrition of responses to nonpreferred categories. In the present conceptualization this would be consistent with competitive interactions. Consequently, specialized maturation of the right FFA observed within the developmental time window of this study may have been preceded by competitive interactions earlier in development. However, without specifically testing earlier developmental windows using the present analytic approach, we cannot rule out that competitive interactions emerge earlier in development in the right FFA. 

Interestingly, most of the regions that showed specialized maturation during childhood (right pSTS, right FFA, right IFG orbitalis and right dmPFC) overlap with regions involved in social cognition and mentalizing. For example, the pSTS/TPJ (temporo‐parietal junction) is a central locus in processing the mental states of others (Saxe and Powell  ). The pSTS and right IFG orbitalis are associated with perceptions of trustworthiness in faces (Verosky and Todorov  ) and inferring feelings or mental states of others from facial information (Moor et al.  ; Spunt and Lieberman  ; von dem Hagen et al.  ; Johnston et al.  ). The regions showing specialized maturation are also reported to undergo developmental change. For example, the right FFA continues to develop throughout adolescence (Golarai et al.  ; Passarotti et al.  ; Peelen et al.  ) and the right IFG is reported to have similar developmental trajectories as the fusiform gyrus, in terms of signal change or activation ratio (Shaw et al.  ). Functional development of the STS has also been reported (Moor et al.  ) (but see Golarai et al. ( ) who reported no differences across ages in the size of the STS face‐selective region). Hence, this study's findings of increased face specialization with age in these regions are consistent with other findings of development of these regions. The present study additionally showed that none of these regions exhibited face specialization at the youngest age (5–8 years). 


### Competitive interactions 
  
Competitive interactions emerged in the left AMG, right MT, right IFG pars opercularis and right OFA. In each of these regions face specialization increased with age while object specialization decreased with age. Although these regions are often reported in face processing tasks, it is interesting to note that they are not typically or as strongly associated with social information processing, like the specialized maturation regions described above are. In fact, these regions are characterized by their participation in more general perceptual or cognitive functions that may not be face‐specific. The AMG, for example, has been described as part of a salience detection system that is rapidly engaged for any salient or important stimulus (Ohman et al.  ). Likewise, although the right OFA is an integral part of the face network, and receives feed‐forward and re‐entrant feedback from face‐sensitive areas, including the FFA (Kadosh et al.  ), the OFA has been recently described as involved in making fine perceptual discriminations of visually homogenous categories other than faces (Haist et al.  ; Collins et al.  ). The precise function of OFA is still not clear as it seems involved in the processing of different face properties (Maurer et al.  ; Pitcher et al.  ) and both early (Pitcher et al.  ) and later face processing stages (Rotshtein et al.  ). Nevertheless, the OFA does seem more strongly implicated in perceptual processes that are not necessarily face‐specific. 

The regions showing competitive interactions are also reported to undergo developmental change. Although age group comparisons of AMG activation have yielded mixed findings as to whether children and adolescents show less, more or comparable levels of activation compared to adults (Lobaugh et al.  ; Killgore and Yurgelun‐Todd  ; Guyer et al.  ; Hoehl et al.  ; Vasa et al.  ; Ebner et al.  ) studies that have examined correlations with age over a developmental time window (as opposed to group comparisons of adults versus children or adolescents) also report that AMG activation for neutral faces (Joseph et al.  ) or emotional faces versus scrambled images increases with age (Todd et al.  ; Pagliaccio et al.  ). Similarly, the present study showed increased face specialization with age in the left AMG. The right OFA also undergoes developmental change (Joseph et al.  ). Joseph et al. ( ) conducted a functional connectivity analysis using graph‐theory and showed that connectivity of the right OFA changes not only during childhood but also from childhood to adulthood. Specifically, the right FFA and right OFA coalesced into the same module during childhood, but were dissociated into different modules by adulthood. Hence, the right OFA and AMG tend to show fairly dynamic changes in functionality during childhood, which is consistent with the present finding that these regions shift from object to face specialization during development. 


### Potential interactions among face network components 
  
Johnson ( ) has suggested that the increased specialization of function during development is accomplished by the interaction or connectivity patterns among brain regions. As an example, increased tuning in receptive fields and synaptic pruning in surrounding cortical areas is one potential developmental mechanism that may lead to increased cortical specialization of function with age. Although the study did not address connectivity or interactions among brain regions directly, one potentially interesting finding in this study relevant to this point is that profiles of specialized maturation and competitive interactions were often juxtaposed in spatially proximal brain regions. As outlined in Table  , these couplings were observed in occipito‐temporal, lateral temporal and inferior frontal cortex. In the occipito‐temporal cortex, the right FFA showed (weak) evidence for specialized maturation whereas right OFA showed (weak) evidence for competitive interactions. As described above, the right OFA may subserve early perceptual processes that differentiate visually similar items from each other (Haist et al.  ; Collins et al.  ) or process more elemental features (Maurer et al.  ; Pitcher et al.  ). These different types of processing are not necessarily face‐specific, but are likely essential to engage this processing for some face tasks. The right FFA has been attributed with more face‐specific processing such as identifying specific persons, which relies on being able to make fine distinctions among individual faces, a process that also engages the OFA, but not exclusively for faces (Haist et al.  ; Collins et al.  ). Of note, this same capacity for fine perceptual differentiation is a component process of perceptual expertise. Another possible function of the right FFA is to integrate features into a unified face percept (Nichols et al.  ; Collins et al.  ). This integrative process may depend on input about individual face features from the OFA (Pitcher et al.  ). Although the exact function of the right FFA is debated, we suggest that as a person matures, the increased tuning to faces in the right FFA may depend on co‐opting the perceptual processing engaged in the right OFA. More specifically, in order to identify faces at an expert level (as typical adults do), the right FFA may depend on the process of perceptual differentiation in the right OFA. Children may lack the synergistic coupling between these two regions (see Cohen Kadosh et al. ( )). Similarly, if the right FFA is involved in integrating face features into a unified percept, the right OFA may provide critical input of processing face features (Pitcher et al.  ). In fact, (Joseph et al.  ) recently reported that integrating face features into a holistic face percept may not emerge until adulthood. Therefore, the right OFA would not be recruited preferentially for processing face features in children if there is no need to integrate those features in the right FFA. These speculations on the development of coupled processing of the right OFA and right FFA will need to be tested in future studies, preferably with effective connectivity analysis. 
  
Summary of development profiles in nearby brain regions 
    
Another similar coupling of maturational profiles was with the two regions located in right posterior lateral temporal cortex, the pSTS and MT, which showed specialized maturation and competitive interactions, respectively. Area MT is considered the primary site for processing visual motion (Tootell et al.  ), whereas Haxby et al. ( ) has suggested that pSTS is involved in perceiving the changeable aspects of faces, a higher order abstraction that relies on understanding biological motion. In fact, pSTS is heavily involved both in perceiving biological motion (Grossman et al.  ), but also in perceiving eye gaze or other socially relevant information (Pierce and Redcay  ). Again, the more basic perceptual processing region MT is not necessarily face‐specific, but this region can be recruited for face‐specific processing (Miki and Kakigi  ; Rossi et al.  ) and we suggest that it becomes increasingly more strongly co‐opted for face tasks with development. 

Finally, two frontal regions, the right IFG‐orbitalis and right IFG‐opercularis, showed a similar coupling. Johnston et al. ( ) suggested that the right IFG‐orbitalis is involved in active motor mirroring or imitation in contrast with IFG‐opercularis which is more involved in passive motor mirroring. In addition, Spunt and Lieberman ( ) showed that the IFG‐orbitalis was involved in attributing reasons for why an actor was displaying emotions whereas the IFG‐opercularis was involved in determining which facial features were being used to display an emotion. Others have also reported that the IFG‐opercularis is involved in executing and perceiving facial expressions (Carr et al.  ; Dapretto et al.  ). In both of these examples, the IFG‐orbitalis is involved in a higher level of processing social information, related to taking another person's perspective in order to accomplish the task at hand. The IFG‐opercularis is involved in the more basic function of motor mirroring that is not necessarily face‐specific. 

Although we did not find the same pattern of spatially proximal activation in the AMG or thalamus, the right AMG and posterior bilateral thalamus showed specialized maturation of faces. Some have suggested that the AMG may automatically process faces (Winston et al.  ). In addition, Dyck et al. ( ) recently suggested that the right AMG is involved in automatic emotional responses to faces whereas the left AMG (which showed competitive interactions in the present study) is more involved in intentional mood control, suggesting a more generalized role for the left AMG. The thalamus activation in the study was consistent with the location of the pulvinar nucleus. Nguyen et al. ( ) reported that the pulvinar contains cells that respond very rapidly (within 50 msec) to face‐like patterns in nonhuman primates. Taken together, these findings suggest that the right AMG and bilateral thalamus may be involved in rapid, automatic face detection, even in younger children, but as individuals mature, these regions become even more tuned specifically to faces. 

In sum, the regions that show competitive interactions during the development of face specialization in this study are implicated in particular perceptual or cognitive functions that apply not only to faces, but to other categories as well. Presumably, these functions are co‐opted for faces as an individual develops and motivation toward social stimuli increases (Scherf et al.  ), as outlined in Table  . The later maturation of face specialization in these regions may support a role in continuously optimizing face processing performance after childhood. We do not suggest, however, that these regions are necessarily permanently co‐opted for face processing in the adult, so that they become dedicated only to faces; rather, they are likely recruited more strongly for face‐specific processing given specific tasks demands in order to achieve high levels of expertise with processing faces. 


### Development of the right FFA 
  
The present study showed that the right FFA is among those ROIs that developed early, in that FSI  was significantly different from 0 in older children and adults (whereas some ROIs only showed a significant FSI  in adults). Cantlon et al. ( ) also reported face specialization in the right FFA very early in development. Haist et al. ( ) reported no increase in signal magnitude in the right FFA from age 6 to 16, also suggesting early development of the right FFA (but FFA volume did increase in that study). Joseph et al. ( ) reported an increase in face specialization with age in the right FFA, but this region did not show the most pronounced developmental change: other visual areas, including the left FFA and right OFA showed stronger increases in face specialization with age. A recent study (Joseph et al.  ) examined developmental changes in face specialization using the same FSI as in the present study from 6 to 17 years of age. Face specialization increased significantly with age in the left FFA but not in the right FFA. Conversely, some prior studies have reported that the FFA continues to develop throughout adolescence (Golarai et al.  ; Passarotti et al.  ; Peelen et al.  ). In general, the right FFA does appear to show increases in face specialization with age, but in some studies these changes were modest compared to other brain regions. 

An important consideration about the degree of face‐specialization in the fusiform gyrus is that there is individual variability in the location of the FFA (Saxe et al.  ). For this reason, some studies in adults prefer to analyze individual‐subject face preferential responses rather than use group‐defined ROIs. This is also an important consideration in developmental studies because face network organization can shift and change with age. If, in fact, the location of the “FFA” changes with age, the group‐defined ROI approach may underestimate the degree of face specialization in children. This is an important issue, but we note that it asks a different question than the primary question in this study, which was: Do children show the same degree of face specialization as adults show in regions that are recruited by adults during face viewing? The answer to this question is no, at least with respect to younger children, as discussed at length above. However, the analysis of individual‐subject face‐preferential responses addresses a separate, but important question: Do children show face preferential responses in a different location than adults do? Although the group maps in Figure   indicate that younger children only show face‐preferential activation at an uncorrected level, we further addressed whether younger children show face‐preferential activation in a different location in the right fusiform gyrus by analyzing individual‐subject face‐preferential responses. This analysis revealed that some children show a strong face preference in the fusiform gyrus, even stronger than that of adults when all suprathreshold voxels were considered for a subject. However, younger children activated fewer face‐preferential voxels than adults and only 1 of the younger children activated more than 10 voxels in the fusiform gyrus, compared to the majority of adults who activated 10 or more. Also, the locus of the peak face‐preferential response was more anterior than that of adults and the locus did not correlate with age in children. In summary, the analysis of individual‐subject face‐preferential responses indicates that some children do exhibit strong face specialized responses, albeit in a more anterior locus than adults. However, the primary analysis in this study indicates that as a group, children do not show the same degree of face preference as adults in the fusiform gyrus, but some individual children do show a face preference. 


### Developmental changes in the functional organization for face processing 
  
Although many studies on the development of face processing have focused on specific functional regions (FFA, OFA, STS, and parahippocampal place area), some studies have examined whole‐brain networks (Haist et al.  ,  ; Joseph et al.  ; Passarotti et al.  ). In general, when whole‐brain activation patterns are considered, children show more diffuse (Passarotti et al.  ), more extensive (Haist et al.  ) or qualitatively different (Joseph et al.  ) patterns of activation compared to adults. The specific regions that are recruited differently in children than adults vary widely across studies, and no consistent pattern has emerged. This inconsistency could be due to the different statistical contrasts used, which may highlight different demands on perceptual differentiation. For example, Joseph et al. ( ) and Haist et al. ( ) contrasted faces with objects that had three‐dimensional structure, and reported more additional regions of activation in children versus adults. In contrast, this study and Passarotti et al. ( ) study, which contrasted faces versus textures, reported fewer additional regions of activation in children. Another reason for inconsistent regional activation patterns across studies may be the age windows examined. In general, as Joseph et al. ( ) suggested, children over age 8 show activation patterns that are more consistent with adults than do children under age 8. This study confirmed this general trend. The developmental period from 8 to 10 years of age may represent an important transitional period for the development of face specialized responses, based on behavioral findings (Carey and Diamond  ; Mondloch et al.  ; McKone et al.  ). In addition, electrophysiological findings suggest that from 8 to 10 years of age, there is a marked decreased in latency of the face‐specific N170 but latency remained fairly stable after age 10 (Taylor et al.  ; Itier and Taylor  ). Consequently, this age range may represent a particularly dynamic period of functional brain reorganization to support higher level face functions of decoding emotions and social cognition. In complex and dynamic systems, periods of transition are marked by greater variability as the system reorganizes (Smith and Thelen  ). Hence, the regional differences found across studies may reflect greater variability in brain‐to‐function mappings as the system reorganizes (Scherf et al.  ). 


### Limitations 
  
One potential limitation of this study was that we did not sample a continuous age range throughout childhood and adolescence. Although there were clear developmental differences detected within this time window of 5–12 years, a more rigorous test of the maturational and IS accounts would involve examining ages much younger (toddler or preschool ages) or older (adolescents) than tested here. For example, in regions that showed specialized maturation, it is possible that a pruning process occurs before age 5. Similarly, some face‐related processing shows nonlinear development from childhood to adolescence (Scherf et al.  ), so regions that appear to be specialized for faces in older children may regress in adolescence. However, Joseph et al. ( ) used similar methods as used in the present study and examined face specialization from age 6 through 18. That study showed significant increases in face specialization with age that appeared to be linear through the adolescent years; however, linear versus nonlinear trends were not tested in that study. Therefore, it would be important for future studies to characterize such developmental trajectories as a step toward elucidating mechanisms of change and plasticity for specialized cognitive capacities. 

Another potential limitation of this study was the use of a passive viewing task, which may not be ideal for revealing neurodevelopmental changes in face processing. The advantage of using a passive viewing task is that it is simple enough even for the youngest subjects, thereby controlling for demands on cognitive processing across age groups. However, passive viewing does not necessarily capture the relevant perceptual and cognitive processes that are known to change with age, such as configural versus analytic face processing (Diamond and Carey  ) or decoding emotion in faces (Todd et al.  ; Marusak et al.  ). In this case, then, the present task may have underestimated maturational changes. A task that required active processing of the stimuli might engage face processing areas more in children. Consequently, future studies should address whether the maturational changes observed here with passive viewing apply to paradigms that require more active processing of faces. 

Another limitation was that, in some cases, the maturational profiles of specialized maturation and competitive interactions were only weakly supported, indicated by either a marginally significant interaction or simple effect, or both. These marginal effects could be driven by higher variability in small samples. Indeed, when only half of the adult subjects were analyzed, some of the significant interactions and simple effects obtained with the full adult sample became marginally significant or not significant (Appendix S2). However, in this case, the adult means remained quite stable when the adult sample was half the size. This does not necessarily guarantee that the means for children would also remain stable, however. Different rates of maturation and different inherent face capabilities can have a significant impact on brain response to faces. In fact, the analysis of individual‐subject face preferential activation peaks indicates significant variability across subjects. Therefore, the ideas of specialized maturation and competitive interactions should be tested in larger samples of children in future studies. 



## Conclusion 
  
The present study provided evidence for increased tuning of face responses during development with or without pruning of nonface responses. The majority of neuroimaging studies of typical face development have focused primarily on tuning processes. However, in order to examine pruning processes, which is a significant developmental event, studies should focus on both face and nonface responses in an extended network of brain regions. The primary finding from this study was that regions associated with higher level face capacities like social cognition showed stronger evidence for specialized maturation, or increased tuning for faces with age but no change in object tuning. In contrast, regions associated with more basic perceptual functions like detecting salient stimuli, processing visually similar categories (i.e. perceptual differentiation), visual motion and motor mirroring showed evidence for competitive interactions; that is, increased tuning for faces occurred in parallel with greater pruning of nonface responses. Interestingly, these developmental profiles of specialized maturation and competitive interactions are often co‐localized in spatially contiguous areas of cortex, suggesting that the more basic perceptual processes may provide essential input into the more face‐dedicated brain regions. However, early in development, these regions are not recruited more strongly during face processing. The coupled recruitment of these regions may thus increase with age, thereby supporting increased expertise for faces with development. 


## Conflict of Interest 
  
None declared. 


## Supporting information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-31'>
<h2>31. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/28592863/' target='_blank'>28592863</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Human cortical activity evoked by contextual processing in attentional orienting</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Sci Rep</p>
<p><strong>Publication Year:</strong> 2017</p>
<p><strong>DOI:</strong> 10.1038/s41598-017-03104-1</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5462779/' target='_blank'>5462779</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of attentional orienting using social cues (eye gaze and voice) versus non-social cues (arrow and tone). Participants were healthy adults (N=22, mean age 22.95 yrs, right-handed, no neurological/psychiatric disorders). The methods report whole-brain random-effects analyses with voxel-wise FWE correction and whole-brain contrasts (with additional small-volume corrections for a priori ROIs), i.e. not ROI-only results. The task is social-related (gaze/voice contextual processing). All inclusion criteria are met and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
The ability to assess another person’s direction of attention is paramount in social communication, many studies have reported a similar pattern between gaze and arrow cues in attention orienting. Neuroimaging research has also demonstrated no qualitative differences in attention to gaze and arrow cues. However, these studies were implemented under simple experiment conditions. Researchers have highlighted the importance of contextual processing (i.e., the semantic congruence between cue and target) in attentional orienting, showing that attentional orienting by social gaze or arrow cues could be modulated through contextual processing. Here, we examine the neural activity of attentional orienting by gaze and arrow cues in response to contextual processing using functional magnetic resonance imaging. The results demonstrated that the influence of neural activity through contextual processing to attentional orienting occurred under invalid conditions (when the cue and target were incongruent versus congruent) in the ventral frontoparietal network, although we did not identify any differences in the neural substrates of attentional orienting in contextual processing between gaze and arrow cues. These results support behavioural data of attentional orienting modulated by contextual processing based on the neurocognitive architecture. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (47097 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
The ability to assess another person’s direction of attention is paramount in social communication. For example, we are able to identify a person’s focus based on their eye gaze, thus enabling an understanding of other people’s inner state (such as thoughts, beliefs, and desires) . Similar to eye gaze, non-social stimuli also play important roles in influencing attention, such as an arrow on a road sign. However, compared with eye gazes, non-social directional stimuli are not helpful when making conclusions regarding someone’s cognitive state, such as speculating about what a person wishes to do. 

Over the past two decades, cognitive psychologists have focused on comparing the role of directional gaze and arrow cues in attentional orienting. These studies have typically investigated attentional orienting based on gaze and arrow cues using a modified version of Posner’s cueing paradigm . For example, Friesen and Kingstone  presented non-predictive gaze cues at the centre of a screen prior to the presentation of a peripheral target (right or left). Before the onset of the target, a centrally presented directional cue (e.g., eye gaze) appears on screen. Under valid conditions, the cue will accurately indicate the subsequent target location, whereas under invalid conditions, the cue will indicate the opposite location. A rapid response to a validly cued target indicates an allocation of attention (i.e., orienting) to the target location prior to target onset. In contrast, a delayed response to an invalidly cued target occurs when the onset of the target at the opposite location, indicating a reorienting of attention to the target. Previous studies  have commonly demonstrated that arrow cues automatically trigger attentional shifts in the same manner as gaze cues. These studies have demonstrated that both gaze and arrow cues trigger attentional shifts when they are counterpredictive of a target location , facilitate response time when discriminating the target following the cue , have comparable sensitivity to object-based selection  and the stimulus onset asynchrony between the cue and target . 

Recent neuroimaging studies regarding attentional orienting have attempted to investigate differences in cortical activity between gaze and arrow cues. These studies have focused on two attentional networks (reviewed by ). The dorsal frontoparietal network, with regions centred around the intraparietal sulcus (IPS), superior parietal lobule (SPL)/Brodmann’s area (BA)5, 7, and frontal eye field (FEF)/BA8, may be responsible for orienting of attention to a validly cued target in the cueing paradigm, but also for reorienting attention to an invalidly cued target . The ventral frontoparietal network, with regions centred on the temporoparietal junction (TPJ)/BA39, 40, 22 and ventral frontal cortex (VFC)/BA44, 45, 47 (including parts of the middle frontal gyrus (MFG) and inferior frontal gyrus (IFG)), may only be responsible for reorienting attention. Most previous studies  have demonstrated that the differences in cortical activity associated with social gaze and arrow cues are quantitative rather than qualitative, although some studies  have reported evidence suggesting different mechanisms for these cues. For example, Tipper   et al  .  reported attentional orienting to both eye gaze and arrow cues engaged extensive dorsal and ventral frontoparietal networks, but the magnitude of activation differed between these networks. However, these studies only examined the differences between gaze and arrow cues under simple conditions (e.g. a dot or letter as the target). Given that Birmingham and Kingstone  suggested that the apparent difference in attentional orienting between gaze and arrow cues might be distinguished only when the cues were embedded in a rich environment, it is thus important to examine the differences between gaze and arrow cues under more complex conditions. 

Some studies have highlighted the importance of contextual processing (i.e., the semantic congruence between the cue and target) in attentional orienting when using arrows or eye gaze as cues. Previous studies  have demonstrated that attentional orienting is facilitated through contextual processing when using arrows as cues. For example, Ristic   et al  .  examined attentional orienting based on whether facial gaze and arrow cues could be triggered through the contextual processing of cue-target colour contingencies. The results indicated that attentional orienting elicited by an arrow rather than an eye gaze was sensitive to colour-congruent target stimuli; an attentional orienting effect for blue arrows was only evident for blue targets. However, other studies  have demonstrated that attentional orienting with facial gaze was facilitated through a strongly contextual relationship between the cue and target when there was congruence in meaning between the cue and target. For example, Bayliss   et al  .  reported that compared with disgusted faces, the gaze direction of happy faces more effectively oriented attention to pleasant targets. These findings indicated that participants could employ contextual information in attentional orienting by arrows or eye gaze cues to effectively capture important information, although the context effect might be observed only when targets are presented at a specific context of colour and emotion for gazes and arrows. These findings raised a question regarding whether attentional orienting differs between eye gaze and arrow cues when these cues were influenced through contextual processing. 

At a neural level, researchers have shown activity in the TPJ and superior temporal sulcus (STS)/BA21, 22 associated with contextual processing in attention. Geng and Vossel  reviewed previous evidence, indicating that the TPJ (anatomically, the TPJ is strictly defined as the cortex at the intersection of the posterior superior temporal, supramarginal, and angular gyri) was engaged in terms of “contextual updating” in attention. For example, Weidner   et al  .  demonstrated that cortical activity in TPJ increased when the contextual processing of the relationship between the cue and target was incongruent as opposed to congruent (i.e., when the target-defining dimension (orientation or colour) was incongruently rather than congruently cued). Moreover, Noppeney   et al  .  observed that the activity in STS increased when a sound or speech target was incongruent (e.g., a car picture paired with the spoken word ‘owl’) as opposed to congruent (e.g., a cat picture paired with the spoken word ‘cat’) with prior visual information. This finding indicated that context also modulated the activity of STS. Consistently, when a strong relationship was established between the target word and a word sound that had been previously presented, the results showed the enhanced activation for thematically related categories (e.g., picture + frame) and response suppression for taxonomically related categories (e.g., chair + armchair) in the left STS . In the present study, we focused on these brain regions to examine the influence of neural systems in relation to gaze and arrow cues through contextual processing focused on the relationship between the cue and target in attentional orienting. 

In the present study, we examined the neural activity of attentional orienting with social gaze and arrows as cues using Posner’s cueing paradigm. Based on a previous study , two sounds (a social voice and a tone) were manipulated as targets to determine the contextual relationship between cue and target; that is, social gaze and social voice and arrow and tone as congruent meaning conditions, and social gaze and tone and arrow and social voice as incongruent meaning conditions. The aims of this study are as follows: (1) We first wanted to examine whether the influence of neural activity in TPJ and STS differed between gaze and arrow cues in response to contextual processing of the relationship between cue and target. (2) Furthermore, given that previous studies  have characterised the functional mechanisms of the orienting and reorienting of attention (i.e., valid and invalid conditions) in dorsal and ventral frontoparietal networks, respectively, we considered it important to specifically investigate these functional mechanisms and how they were modulated through the contextual processing of the relationship between cue and target. Specifically, if different neural activity was observed for gaze and arrow in response to the contextual processing of cue-target, we would subsequently examine whether the neural activity for attentional orienting differed with contextual processing between gaze and arrow cues at the dorsal and ventral frontoparietal networks, respectively. In contrast, if no difference between gaze and arrow was evident, we would then examine only the influence of neural activity for attentional orienting by contextual processing in both gaze and arrow cues in these two attentional networks. 


## Methods 
  
### Participants 
  
This research was approved by the local ethics committee of Capital Medical University, Beijing, China. No foreseeable risk to the participants was present, and personal identifying information was not collected. Participants provided written informed consent and background information. All procedures complied with the ethical standards of the 1964 Declaration of Helsinki regarding the treatment of human participants in research. In total, 22 volunteers (9 women, 13 men; mean ± SD age, 22.95 ± 2.61 years) participated. All participants were right-handed, as assessed by the Edinburgh Handedness Inventory , and had normal or corrected-to-normal visual and auditory acuity. 


### Stimuli 
  
Visual and auditory stimuli were almost identical to those used in a previous behavioural study (at a sound level comfortable to each participant) . Previous studies have demonstrated that female faces are less resemblance to angry expressions than male faces, and male faces are perceived as less likeable  and more powerful . To avoid any differential influence of expression (e.g., anger), a Japanese female face with neutral expressions was used for this task (Fig.  ). The image was obtained from a previous study , in which the emotional intensity of facial stimuli with neutral expressions was assessed. The results confirmed that these facial images were considered neutral rather than emotional. Based on these findings, it is reasonable to propose that the female face image in the present study conveyed neutral facial expressions. Moreover, three versions of each face were produced: one version with a direction of gaze straight ahead, another version with the pupils averted leftward, and a third version with the pupils averted rightward. The faces measured approximately 4.7° wide and 6.9° high. For the arrow cue, a symmetrical arrow was presented as the cue stimulus, with an arrowhead at one end and a tail at the opposite end. The arrows measured 4.7° in width by 1.7° in height and were light grey.   
Illustration of the stimulus presentation. 
  

Furthermore, two types of auditory stimuli were presented as targets. One type was sampled from a woman: an/i/voice sound (F0 frequency of 300 Hz), which is similar to the /iy/sound in English. The other type was a pure tone of similar frequency to the F0 voice (300 Hz), which was produced using the Audacity software package (  ver. 1.3.13; Audacity store.com  ). The duration of the stimulus presentation was 150 ms. 


### Apparatus 
  
These stimuli were generated on a computer and presented to the participants via a custom-built, magnet-compatible audio-visual system during magnetic resonance (MR) scanning. To attenuate the acoustic noise that accompanies fMRI (functional magnetic resonance imaging) scanning, shooting earmuffs were used. Participants viewed visual stimuli on a back-projection screen. The auditory stimuli were identical to those presented in a previous study  via an air-conductive tube to participants. Presentation software (ver. 10.2; Neurobehavioral Systems) was used to generate auditory and visual stimuli on a Windows computer. In addition, the participants generated their responses using a keypad (Current Designs Inc., Philadelphia, PA, USA). 


### Procedures 
  
The sequence of stimulus presentation is shown in Fig.  . For each trial, a fixation cross was initially presented for 300 ms in the centre of the screen. A neutral stimulus with a straight eye gaze (gaze trail) or transverse lines (arrow trail) was subsequently presented at the location. After 350 ms, a cue stimulus (gaze or arrow) in the right or left direction was presented in the centre of the screen. The stimulus onset asynchrony (SOA) between the auditory target and cue was fixed to 200 ms. Subsequently, an auditory stimulus target (voice or tone sound) was presented in the left or right ear for 150 ms through headphones. Consistent with previous studies , the participants were asked to answer quickly and precisely whether or not they heard the auditory target on the left or right side of the headphones by pressing the corresponding key on the switch keypad using their dominant index or middle fingers, respectively. Response times (RT) were measured in each trial. A standard procedure for the Posner’s cueing paradigm removed cue stimuli before a target stimulus appeared on the display. However, when using a facial gaze as a cue, many studies e.g. refs   and   also implemented a modified cueing paradigm in which the cue remained on the screen until a response was obtained or a set time had elapsed. For this study, we designed a contextual processing condition between the cue and target. To establish a strong and obvious contextual relationship between the cue and target, the cue remained until a response was obtained or 1000 ms had elapsed. The targets appeared randomly on the same or opposite side of the cue direction when the cue was directed left or right. The target appeared at the cued location in 50% of the trials. The participants were told that the cue did not predict the target location and were instructed to fixate on the centre of the screen in each trial. 

The fMRI analysis relied on a within-subject three factorial design, with the cue condition (gaze or arrow), context condition (i.e., the congruence of meaning between the cue and target, which could be congruent (social gaze and social voice or arrow and tone) or incongruent (social gaze and tone or arrow and social voice)), with validity condition (valid or invalid) as the repeated factors. Sixty trials were performed under each condition. Our experimental design was based on a mixed block/event-related paradigm, facilitating a more complete utilisation of the BOLD signal and enabling a deeper interpretation of how the regions of the brain function on multiple timescales . Consistent with a previous study , alternating blocks of experimental trials of cue condition and blocks of baseline were presented. Within the condition blocks, congruence trials were presented in a pseudorandom event-related distribution. 


### MRI acquisition 
  
The images were acquired using a 3.0-T Trio Tim Scanner-vision whole-body MRI system (Siemens, Erlangen, Germany) to measure activation using a head coil. The functional images comprised 33 consecutive slices parallel to the anterior-posterior commissure plane, covering the entire brain. A T2*-weighted gradient-echo planar imaging (EPI) sequence was used with the following parameters: TR = 2000 ms, TE = 30 ms, flip angle = 90°, field of view = 220 × 220 mm, matrix size = 64 × 64, and voxel size = 3.4 × 3.4 × 3.5 mm . The slices covered most of the brain, including the entire temporal cortex, but excluding the most inferior parts of the cerebellum. We also acquired high-resolution isotropic T1-weighted images (TR = 1900 ms, TE = 2.52 ms, flip angle = 9°, field of view = 250 × 250 mm, 176 sagittal slices, voxel size = 1 × 1 × 1 mm ). 


### Behavioural data analysis 
  
The data were analysed using the SPSS software package (ver. 21.0). Incorrect responses (1.76% of the trials) and RT of less than 100 ms or more than 1000 ms were excluded from the RT analysis (1.18% of the trials), and trials in which a response occurred prior to the target onset were also excluded. The mean RT under conditions was calculated for each participant. The mean RT was analysed using a three-way analysis of variance (ANOVA) with cue (gaze, arrow), context (congruent, incongruent), and validity (valid, invalid) as within-participant factors. To examine whether an interaction was significant, if present, a follow-up simple main effect (i.e. assessing the effect of each independent variable at each level of the other independent variable) analysis was conducted to interpret the result. 


### Image data analysis 
  
Data preprocessing and statistical analyses were performed using the Statistical Parametric Mapping software package (SPM12; Wellcome Department of Cognitive Neurology, London, UK;   http://www.fil.ion.ucl.ac.uk/spm/software/spm12  ) implemented in MATLAB 2013b (Math Works). The functional images from each run were realigned using the first scan as a reference to correct for head movements. The movement parameters generated during spatial realignment indicated that all subjects moved less than 2 mm during the course of the trial. The T1 anatomical image was preprocessed using an intensity inhomogeneity correction. Then, T1 anatomical images were coregistered to the first scan of the functional images. Next, the coregistered T1 anatomical image was normalised to the Montreal Neurological Institute space using a unified segmentation-spatial normalisation approach . The parameters from this normalisation process were subsequently applied to each of the functional images. Finally, these spatially normalised functional images were resampled to a voxel size of 2 × 2 × 2 and were spatially smoothed in three dimensions using an 8-mm full-width-at-half-maximum Gaussian kernel. 

We used random-effects analyses  to identify significantly activated voxels exhibiting interesting effects. First, we performed a single-subject analysis . The BOLD response was modelled as the neural activity, convolved with a canonical haemodynamic response function (HRF), which yielded regressors in a general linear model (GLM) for each condition. We used a high-pass filter comprising a discrete cosine basis function with a cut-off period of 128 to eliminate the artefactual low-frequency trend. To correct the global fluctuation related to motion artefacts, global scaling was conducted. Serial autocorrelation, assuming an AR (1) (first-order autoregressive) model, was estimated from the pooled active voxels with a restricted maximum likelihood procedure and used to whiten the data and design matrix . 

The contrast images from the first-level analyses from all subjects were subsequently used for the second-level group statistics. First, for each participant, the data were best fitted at every voxel using a combination of effects of interest. These data were delta functions representing the onsets of the eight conditions, given by the crossing of our 2 × 2 × 2 factorial design: cue (gaze, arrow) × context (congruent, incongruent) × validity (valid, invalid), convolved with the SPM12 haemodynamic response function. Second, based on the behavioural results, a 2 × 2 × 2 (cue × context × validity) factorial ANOVA was used to investigate the relationship between behavioural results and brain activation. Based on a methods analysis , the statistical maps exhibited a spatial extent threshold at p < 0.05, family-wise error (FWE)-corrected for multiple comparisons, and an intensity threshold at p < 0.001, uncorrected for multiple comparisons at the whole-brain level was used to protect against false-positive activations. The peak voxels of clusters exhibiting reliable effects are reported in MNI coordinates. We had an a priori hypothesis regarding the activity of contextual processing in TPJ and STS, and the influence of contextual processing in dorsal and ventral frontoparietal networks. Based on anatomical masks using the WFU Pickatlas tool, a small-volume correction was also employed to the a priori regions of interest, attributed to the anatomical structures in left/right hemisphere of the STS with BA21, 22, the IPS and SPL with BA5, 7, the FEF with BA8, and the IFG with BA44, 45, 47, separately. Consistent with the whole-brain level, we used small-volume correction at a voxel spatial extent threshold at p < 0.05, FWE corrected, and an intensity threshold at p < 0.001, uncorrected for multiple comparisons. Finally, to quantify neural responses with the influence of attentional orienting under context conditions, we used the MarsBaR software package  to extract percentage changes in BOLD signals for congruent and incongruent contexts under valid and invalid conditions, averaged across voxels with given regions of interest (ROI) using spheres with a radius of 8 mm. Then, the means of the percent signal change (PSC) between the conditions were compared using repeated-measures ANOVA. All statistics were calculated using the SPSS software package (ver. 21). 



## Results 
  
### Behavioural results 
  
The data pertaining to errors did not reveal any significant main effect or interaction (all   p   > 0.05), thus indicating that the participants suffered no speed-accuracy trade-off (Table  ).   
Mean response times (ms), standard deviations, and percent errors (%E) as a function of cue, context, and validity. 
  

The mean RT under each condition are listed in Table  , and the mean differences in RT between the invalid and valid conditions are shown in Fig.  . A three-factor repeated-measures ANOVA was used to analyse the RT. The analysis revealed a main effect of cue (  F   (1, 21) = 12.412,   p   = 0.002,   η   = 0.371), with faster responses under the eye gaze (339.7 ms) versus arrow (351.3 ms) condition. In addition, we also observed a significant main effect of context (  F   (1, 21) = 8.213,   p   = 0.009,   η   = 0.281), with faster responses under congruent (341.3 ms) versus incongruent (349.7 ms) conditions, and validity (  F   (1, 21) = 25.247,   p   < 0.001,   η   = 0.546), with faster responses under valid (334.8 ms) versus invalid (356.2 ms) conditions.   
Response times (RT) results in attentional orienting. Mean (with SE) RT presented for valid and invalid conditions as a function of a cue type condition (gaze or arrow). **  p   < 0.01. 
  

A significant interaction of context × validity was observed (  F   (1, 21) = 4.907,   p   = 0.038,   η   = 0.189), but no significant interaction was detected for cue × context (  F   (1, 21) = 0.166,   p   = 0.688,   η   = 0.008), cue × validity (  F   (1, 21) = 0.048,   p   = 0.828,   η   = 0.002), or cue × context × validity (  F   (1, 21) = 0.108,   p   = 0.746,   η   = 0.005). 

The   post hoc   test revealed a significant difference between context conditions under invalid conditions (  p   = 0.004) but not under valid conditions (  p   = 0.182) with a faster response for congruent (349.9 ms) versus incongruent (362.5 ms) under invalid conditions, indicating an RT benefit for targets that match the context (e.g. social) of the cue under invalid conditions but not under valid conditions. This result suggests that the disengagement of attention from cued locations is facilitated through contextual processing. These findings demonstrated that attentional orienting is modulated through contextual processing only under invalid conditions, enabling the investigation of the neural substrates underlying the behavioural response of the contextual processing between the cue and target in attentional orienting induced by gaze and arrow cues. 


### Supplementary analysis of the influenced by the gender 
  
Because previous studies have reported that gaze-triggered orienting is different between genders (e.g., refs   and  ), we added gender (male, female) as between-participant factor to supplement the influence of the gender based on the main (3-way) ANOVA of RT data analysis, although 22 participants were recruited with gender unbalance including 9 women and 13 men. The results found a significant interaction between gender and the validity (  F   (1, 20) = 9.591,   p   = 0.006,   η   = 0.324) but not between gender and other factors (all   F   (1, 20) ≤ 2.54,   p   > 0.1). However, the   post hoc   test did not reveal a difference between genders under valid or invalid conditions (both   p   > 0.1), although a faster response was observed for valid compared with invalid conditions in both male (323.5 vs. 335.6 ms,   p   = 0.017) and female (351.1 vs. 386.0 ms,   p   < 0.001) participants. Thus, the results of the present study suggest that attentional orienting through contextual processing was not influenced by the gender of the participants. 


### fMRI results 
  
Next, based on the behavioural results, we investigated the patterns of brain activation associated with cross-modal attention. In the primary analysis, we performed 2 cue conditions (gaze, arrow) × 2 context conditions (congruent, incongruent) × 2 validity conditions (valid, invalid) repeated-measures ANOVA. 


### Main effects of cue, validity, and context 
  
In a whole-brain analysis, the gaze trials evoked significantly greater activity than arrow trials in a many clusters of voxels. One of these clusters included the fusiform gyrus (BA 19), extending from the extra-striate visual areas into the occipital and temporal cortices (Supplementary Fig.  , Table  ). In contrast, greater activity for arrow than for gaze trials was observed in the right hemisphere of temporal lobe, including the middle temporal gyrus (BA 37), and the left hemisphere of occipital lobe, including the middle occipital gyrus (BA 19) (Supplementary Fig.  , Table  ). These results were consistent with previous evidence , thus indicating that gaze versus arrow cues increased activation in various occipital and temporal areas, whereas the reverse contrast evoked activation in occipital regions. 

Furthermore, in a whole-brain analysis, invalid gaze and arrow cues evoked a significantly larger response than valid gaze and arrow cues in the left frontal hemisphere and the limbic system, including the inferior and middle frontal gyrus, and the anterior cingulate (Supplementary Fig.  , Table  ). These results were also consistent with those of a previous study  that revealed common activity in the IFG by conjunction analyses to response gaze and arrow cues in attentional orienting. However, activation was not observed by valid versus invalid gaze and arrow cues. 

To highlight the neural underpinnings of RT modulated through contextual processing, we examined the difference between congruent and incongruent contextual meanings of the cue-target. The results of the whole-brain analysis indicated that the congruent condition evoked a significantly smaller response than the incongruent condition in the left hemisphere parietal, including TPJ (BA 40). Additionally, anatomical region-based small-volume corrections revealed significant activation in the temporal lobe, including STS (BA21/22). (Fig.  , Table  ) These findings indicated that activity in left TPJ and STS regions was associated with the contextual processing of the cue-target, but this activation was not observed in the congruent versus the incongruent condition. Furthermore, to examine the differences between gazes and arrows in contextual processing, we investigated whether the neural activity in these regions differed between gaze and arrow cues. The results revealed no significant difference between gaze and arrow cues, indicating that comparable neural activity was elicited by contextual processing between gaze and arrow, thereby influencing valid and invalid orienting within attentional orienting. Next, we assessed the cue condition, focusing on its influence in contextual processing for both gaze and arrow cues in attentional orienting.   
In response to incongruent versus congruent context conditions, exploratory whole-brain analysis indicating that the left TPJ is significantly activated, and small-volume-correction analysis showing that the left STS is significantly activated based on an anatomical mask. A voxel-wise spatial extent threshold   p   < 0.05, FWE-corrected, and an intensity threshold   p   < 0.001, uncorrected, were used. 
    
Main effect of incongruent condition: incongruent > congruent. 
  
BA = Brodmann’s area; FWE = family-wise error; a voxel-wise spatial extent threshold at   p   < 0.05, FWE corrected, and an intensity threshold at   p   < 0.001, uncorrected. 
  


### Interaction of context and validity conditions 
  
A 2 (context: congruent, incongruent) × 2 (validity: valid, invalid) ANOVA was performed to investigate the influence of activation by the contextual relationship of cue-target in attentional orienting networks. The results of the whole-brain analysis revealed a significant interaction in left hemisphere TPJ (BA 40). Additionally, anatomical region-based small-volume corrections revealed significant activation in the left hemisphere IFG (BA 47) regions (Fig.  , Table  ).   
(  a  ) In response to the interaction between context and validity conditions, exploratory whole-brain analysis showing left TPJ significantly activated, and small-volume-correction analysis showing left IFG significantly activated based on an anatomical mask. A voxel-wise spatial extent threshold   p   < 0.05, FWE corrected, and an intensity threshold   p   < 0.001, uncorrected, were used. (b) Mean (±SE) and percent signal changes (PSC) in the left hemisphere TPJ and IFG regions are shown. These areas are overlaid on the mean normalised structural MRI from all subjects in this study. n.s:   p   > 0.05; **  p   < 0.01. 
    
Interaction between context and validity conditions. 
  
BA = Brodmann’s area; FWE = family-wise error; a voxel-wise spatial extent threshold at   p   < 0.05, FWE corrected, and an intensity threshold at   p   < 0.001, uncorrected. 
  


### ROI analysis 
  
The results of the interaction were expanded using an ROI-based analysis. Figure   and Table   present the location and pattern of the response in all ROIs in which a signal change was extracted. These responses were located in left TPJ and IFG regions. The PSC in these regions was analysed using a 2 (context: congruent, incongruent) × 2 (validity: valid, invalid) repeated-measures ANOVA. A significant interaction was observed in the left TPJ and IFG regions. Moreover, the post hoc test revealed that PSC was smaller when the contextual meaning of cue-target was congruent vs. incongruent in all regions under invalid conditions (all   p   < 0.05) but not under valid conditions (Fig.  , Table  ). These results indicated that the influence of contextual processing on the neural activity for attentional orienting was observed under invalid conditions but not under valid conditions.   
ROI results. 
  
ROIs represent previously examined areas that exhibited a significant interaction between context and validity conditions in a 2 × 2 ANOVA (with a voxel-wise spatial extent threshold at   p   < 0.05, FWE corrected, and an intensity threshold at   p   < 0.001, uncorrected).   *p   < 0.05, *  *p   < 0.01. 
  



## Discussion 
  
We examined attentional orienting by gaze and arrow cues under a localising task in which participants were asked to indicate whether the target (voice and tone) was heard on the left or right side of the headphones. The combination of cues and targets varied across trials, reflecting contextual relationship processing, where the contextual meaning of the cue-target was congruent (social gaze and social voice and arrow and tone) or incongruent (social gaze and tone and arrow and social voice). Although the behavioural results showed no difference between gaze and arrow cues, a RT benefit was observed for targets matching the context of the cue under the invalid condition. This finding suggested that a disengagement of attention from cued locations was facilitated through contextual processing. Previous studies  have demonstrated that attentional orienting can be influenced by contextual processing when targets were presented in a specific context (e.g., colour or emotion) for gaze or arrow cues. Compared with a previous study  in which attentional orienting based on a contextual effect for gaze and arrow was investigated in the context of colour (i.e., schematic white/black eyes as the cue and a black square as the target), the present study examined attentional orienting through contextual processing using facial gaze and voice, which seems to more closely resemble a real-world environment. Furthermore, although another study  examined attentional orienting through gaze cues influenced by emotional context for 80 different images (e.g., a chimney image) as targets, the present study only manipulated two sounds as targets, potentially easing the establishment of a pairing between the cue and target. That is, the pairing of gaze and voice was easily established, and arrow and tone represented the other pair. Thus, the present study observed attentional orienting through contextual processing when using gaze and arrow as cues. Based on these findings, the results of the present study extended those of previous studies , indicating that attentional orienting through centrally presented cues, irrespective of cue characteristics (e.g. social or non-social), could also be modulated by contextual relationship processing between the cue and target. 

Importantly, consistent with the behavioural results, the main analyses of fMRI data revealed that neural substrates were not different in response to the contextual relationship processing of cue-target for gaze and arrow cues. Previous studies  have revealed that neural substrates in the regions of the TPJ and STS were associated with contextual processing. Consistently, to highlight the neural underpinnings of RT modulated by contextual processing, the results of the present study also demonstrated that the left STS and bilateral TPJ were specifically involved in contextual processing under both gaze and arrow conditions. The results also indicated that these regions were weakly activated when the relationship of cue-target was congruent (the expected target matching the context of the cue) compared with incongruent (the expected target non-matching the context of the cue). We suggest that these regions may be the locations of an inhibitory mechanism, which enhanced neural activity to suppress the processing of incongruent predictions for targets from cue stimuli. Given that the activity of these regions did not differ between social gaze and arrow cues, we further suggest that a comparable neural system was elicited by contextual processing for gaze and arrow cues and further influenced the attentional process. This idea is consistent with previous studies  that demonstrated the differences in attention to social and non-social cues were quantitative rather than qualitative. 

Interaction analyses in behavioural results indicated that a different pattern of attentional orienting by contextual processing was elicited for valid and invalid conditions. That is, a RT benefit was observed for targets matching the context (e.g. social) of the cue under invalid conditions, but not under valid conditions. We propose that the different patterns between valid and invalid conditions may be influenced through the overlap of the time window between contextual processing and attentional orienting. Electrophysiological studies have demonstrated that the activity of temporal staging differed between valid and invalid conditions . These studies reported an amplitude enhanced at P1 (a positive component at occipital electrode sites between 70 and 100 ms post-target onset) in attentional orienting with gaze as the cue under valid versus invalid conditions, whereas a greater amplitude at P3 (a positive component at central/parietal/midline electrode sites between 300 and 500 ms post-target onset) was observed under invalid versus valid conditions. However, in previous studies , the N300 (a negative component at frontal electrode sites at approximately 300 ms) - N400 (a negative component at central/parietal electrode sites at approximately 400 ms) wave reflected an updating of context information. For example, Demiral   et al  .  observed a stronger N300-N400 effect elicited through a semantic context when the contextual scene was presented before the target in a spatial attention task. Given that the pattern of attentional orienting by contextual processing differed between valid and invalid conditions, we suggest that this finding may be influenced through associations with the activities of temporal staging between the influence of attentional orienting (i.e. the mechanism of valid and invalid conditions) and the contextual processing component. Compared with the early stage (70–100 ms) under valid conditions, the time window of processing overlapped with that of contextual information and attentional orienting under invalid conditions at a later stage (300–500 ms), in which these processes could be integrated to suppress a violation of expectancies (the expected target matching the context of the cue) when the contextual relationship of cue-target was incongruent. In addition, we speculated that varying SOA conditions may influence expectations, and the patterns of attentional orienting by contextual processing for valid and invalid conditions could be modulated in the present experiment. That is, if the target was presented at a short SOA prior to the expectation of the subject, then attentional orienting by contextual processing may not be influenced under valid or invalid conditions, whereas if the target was presented at a long SOA after the expectation of the subject, then attentional orienting by contextual processing might be influenced under invalid conditions. 

Furthermore, the results of the interaction analyses in fMRI also demonstrated the influence of contextual processing on neural activity for attentional orienting under invalid but not valid conditions. Such neural activities were observed in the left hemisphere TPJ and IFG, an area in the ventral frontoparietal network that may be responsible for invalidity orienting (for reviews, see refs   and  ). As mentioned above, analyses of the fMRI data revealed that the left STS and TPJ were involved in the contextual processing of the relationship between the cue and target. The activity in the left TPJ region overlapped in processing the contextual relationship of cue-target and invalidity orienting in attention. Additionally, consistent with the pattern of neural activity for contextual processing in the left STS and TPJ, we observed that when the relationship of cue-target was congruent versus incongruent based on ROI analyses, less activity was observed in all of these brain regions. This result suggests that from the left TPJ to the IFG in the ventral frontoparietal network, neural signals for contextual processing were transferred to invalidity orienting in attention, in which the intrinsic connection pathway is present among these regions . Compared with incongruent conditions, we suggest that the lower activity in the ventral frontoparietal network when the contextual processing of the relationship between cue and target is congruent under invalid conditions may reflect a disengagement of attention from cued locations at a lower cost, which is readily elicited. This idea may explain the behavioural data obtained under invalid conditions, indicating that a lower cost is associated with processing when the contextual processing of the relationship between the cue and target was congruent versus incongruent; thus, participants could disengage attention from the cued location to rapidly capture a target. 

### Implications of the present study 
  
Previous behavioural studies  had demonstrated that attentional orienting by gaze or arrow cues could be modulated through contextual processing. Consistent with these studies, the behavioural results in the present study also revealed that RT in attentional orienting was modulated through contextual processing. In particular, we observed that attentional orienting was modulated through contextual processing under invalid conditions. Given that the present study identified the influence of the neural substrates by contextual processing under invalid conditions in ventral frontoparietal networks, we suggest that this finding may account for the behavioural data regarding attentional orienting through contextual processing based on the neurocognitive architecture. 

In addition, a behavioural study demonstrated impaired attentional orienting when the cue-target relationship is weak (i.e., incongruent context) in individuals with autism spectrum disorder (ASD) , a finding that raises a question regarding whether individuals with ASD exhibit impairment of gaze-triggered attention because activity is impaired in the neural mechanism in the ventral frontoparietal network. Given that impaired gaze-triggered attention may impede and differentially affect the development of the ability to understand the mental state of another individual in social communication , we suggest that an atypical function in the ventral frontoparietal network, particularly in the processing of contextual information, may be associated with the atypical development of social cognition, further suggesting an important direction for future studies combining brain imaging and treatment interventions for social processing deficits in individuals with ASD. 


### Limitations 
  
First, we tested attentional orienting by contextual processing using gaze and arrow as cues with two types of targets (social voice and tone) under only visual-auditory cross-modal conditions. Given the complexity of real life, future studies should examine attentional orienting by contextual processing using two types of targets under visual-visual unimodal or visual-tactile cross-modal conditions in which attentional orienting by contextual processing may also play an important role. 

Second, the present study involved two types of contextually related cues and targets. In contrast with faces and voices, which are immediately paired in a congruent context, the pairing of the tone and arrow might be influenced through the increasing number of trials throughout the experiment. To evaluate this possibility, all experimental blocks were divided into two parts (first and last half of the block), and a four-factor repeated-measures ANOVA (block × cue × context × validity) was used to analyse the RTs. Given that a significant 4-way interaction was observed (  F   (1, 21) = 5.09,   p   = 0.04,   η   = 0.195), two 3-way repeated-measures ANOVA (block × cue × context) was performed under valid and invalid conditions separately. Although no significant interaction was detected for block conditions under invalid conditions, (all   p   > 0.1), we observed that the main effect of context (  F   (1, 21) = 11.74,   p   = 0.003,   η   = 0.36) was significant with faster response to congruent than incongruent conditions (349.0 vs. 361.5 ms), thus indicating that contextual processing between the cue and target was immediately established at both gaze and arrow pairings. However, under valid conditions, although we observed no significant main effect of context (  F   (1, 21) = 1.41,   p   = 0.25,   η   = 0.063), a significant interaction of block × cue × context was observed (  F   (1, 21) = 12.67,   p   = 0.002,   η   = 0.38). The   post hoc   test revealed a significant difference between context conditions (  p   = 0.045) with a faster response to congruent than incongruent conditions (327.4 vs. 346.9 ms) when using arrows as cues in the last half of the block, thereby indicating that attentional orienting by contextual processing could be influenced by increasing the number of trials throughout the experiment under valid conditions when the tone target was matched with arrow cue. In the present study, attentional orienting was modulated through contextual processing under invalid conditions. Thus, we suggest that this effect may be elicited through immediately established pairing between arrow and tone, rather than increasing the number of trials in the experiment. However, future studies should investigate the mechanism of how contextual processing is influenced by increasing the number of trials through the experiment. 

Finally, in the present study, we directly contrasted the context conditions by gaze and arrow cues in invalid and valid trials to reveal differences in attentional orienting. Previous studies  manipulated a neutral cue (e.g. direct gaze) as a baseline condition to examine differences in the neural mechanisms between valid and invalid attentional orienting conditions. However, compared with a non-directional arrow as a neutral cue, Engell   et al  .  suggested that a direct gaze, as a neutral cue, was perceived as directional rather than non-directional, which was problematic in terms of comparing social versus non-social cueing in an fMRI study. Future research should investigate the need for a baseline condition in which the neural gaze and arrow cues involve no spatial information and have the same effect on neural activity, such as closed eyes and non-directional arrows. 



## Conclusions 
  
In this study, we observed that the response time in attentional orienting by gaze and arrow cues was modulated through contextual processing between the cue and target when contextually congruent and incongruent under invalid conditions in behavioural studies. Additionally, on the neural level, activity in the left TPJ and STS was observed with attentional orienting by gaze and arrow cues in response to contextual processing of the relationship between the cue and target. However, we did not observe any difference in the neural substrates between social gaze and arrows by contextual processing in attentional orienting. This finding adds further evidence in support of the notion that the differences in attention to social and non-social cues are quantitative rather than qualitative. Importantly, both behavioural and fMRI results indicated that the influence of contextual processing on neural activity for attentional orienting occurred under invalid conditions. Such an increase was observed in the ventral frontoparietal network when the cue and target were incongruent rather than congruent. This finding may provide an explanation for the behavioural data regarding attentional orienting by contextual processing based on the neurocognitive architecture. 


## Electronic supplementary material 
  




 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-32'>
<h2>32. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/30085122/' target='_blank'>30085122</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Oxytocin Facilitates Approach Behavior to Positive Social Stimuli via Decreasing Anterior Insula Activity</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Int J Neuropsychopharmacol</p>
<p><strong>Publication Year:</strong> 2018</p>
<p><strong>DOI:</strong> 10.1093/ijnp/pyy068</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6165955/' target='_blank'>6165955</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study reports task-based fMRI in healthy adult humans (male students mean age 21.35) performing an approach-avoidance task that explicitly contrasts social vs nonsocial stimuli, addressing social-related processing. Participants are within the 18–60 range and screened as healthy; no psychiatric/neurological disorders reported. Although ROI analyses were a priori used, the methods state and the results refer to additional exploratory whole-brain analyses (thresholded and reported), so whole-brain results are available rather than ROI-only reporting. The paper is an original empirical fMRI study (not a review/meta-analysis). Therefore it meets all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.93</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
## Background 
  
The neuropeptide oxytocin can extensively modulate human social behavior and affective processing, and its effects can be interpreted in terms of mediating approach-avoidance motivational processes. However, little is known about how oxytocin mediates approach-avoidance behavior and particularly the underlying neural mechanisms. 


## Methods 
  
In a randomized, double-blind, between-subject design, the present pharmaco-fMRI study used an approach-avoidance paradigm to investigate oxytocin’s effects on approach-avoidance behavior and associated neural mechanisms. 


## Results 
  
Results revealed that oxytocin generally decreased activity in the right striatum irrespective of response (approach/avoidance) and social context, suggesting an inhibitory effect on motivational representation during both appetitive approach and aversive avoidance. Importantly, while on the behavioral level oxytocin selectively enhanced accuracy when approaching social positive stimuli, on the neural level it decreased left ventral and right dorsal anterior insula activity in response to social vs nonsocial positive stimuli compared with the placebo treatment. The left ventral anterior insula activity was negatively correlated with the corresponding accuracy difference scores in the oxytocin but not in the placebo group. 


## Conclusion 
  
Given the role of the ventral anterior insula in emotional processing and the dorsal anterior insula in salience processing, the oxytocin-induced suppression of activity in these regions may indicate that oxytocin is acting to reduce interference from hyper-activity in core regions of the emotional and salience networks when approaching salient positive social stimuli and thereby to promote social interaction. Thus, oxytocin may be of potential therapeutic benefit for psychiatric disorders exhibiting avoidance of social stimuli. 

 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (26657 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'>  
## Significance Statement 
  
The hypothalamic neuropeptide oxytocin (OT) plays an important role in modulating human social behavior. These effects can be interpreted in terms of OT’s actions on basal approach-avoidance (AA) motivational processes, as proposed by the general AA hypothesis of OT (GAAO). However, few studies have evaluated the proposed OT effects on AA behavior and particularly the underlying neural mechanisms. Using neuroimaging combined with intranasal OT administration, the present study revealed that while OT selectively enhanced behavioral accuracy when approaching social positive stimuli, it decreased left ventral and right dorsal anterior insula (AI) activity in response to social vs nonsocial positive stimuli compared to the PLC treatment, with the left ventral AI activity being negatively correlated with the corresponding behavioral accuracy only in the OT group. These findings provide the first confirmatory evidence for the GAAO by demonstrating that OT facilitates human approach behavior to social positive stimuli via inhibiting AI activity. 

 
## Introduction 
  
Across species, the hypothalamic neuropeptide oxytocin (OT) regulates social behavior, particularly bonding and maternal care ( ;  ). During the last 2 decades, the number of studies examining oxytocinergic regulation of human behavior via intranasal administration of OT has steadily increased. While OT can facilitate appetitive approach behaviors, such as interpersonal trust and generosity ( ;  ), pair bonding and maternal behavior ( ;  ) and emotional empathy and face recognition ( ;  ), it can also promote aversive avoidance behavior by increasing envy and schadenfreude ( ), ethnocentrism (e.g., trust and empathy;  ;  ), group-serving dishonesty ( ), and noncooperation ( ;  ). 

To account for these complex and somewhat contradictory findings,   proposed in their general approach-avoidance (AA) hypothesis of OT (GAAO) that the broad effects of OT on human behavior are mediated by its actions on basal AA motivational processes. More specifically, within this extended overarching framework, OT’s complex behavioral effects are considered to be rooted in its modulation of the salience of personally relevant and emotionally evocative stimuli not necessarily restricted to social contexts ( ; cf.   for the social-approach/withdrawal hypothesis and   for the social salience hypothesis). However, surprisingly few studies have experimentally evaluated the proposed effects of OT on AA behavior and particularly the underlying neural mechanisms. 

In a previous study that examined the effects of intranasal OT on human AA behavior, OT was found to accelerate both approach and avoidance behavior towards emotionally negative stimuli such as disgusted faces ( ;  ). Using similar paradigms, OT also facilitated approach towards angry faces with a direct gaze ( ). Furthermore, in the context of pair bonding, OT was found to modulate interpersonal space by decreasing the preferred distance men in a romantic relationship kept between themselves and an unknown attractive woman ( ). However, these studies predominantly used emotional faces to investigate OT’s actions on AA behavior and were thus unable to determine whether observed effects were driven by its well-established actions on increased attention and attraction to faces per se ( ;  ;  ;  ;  ). Moreover, the neural substrates mediating OT’s effects on AA behavior also remain unclear, with initial evidence showing decreased amygdala activity only when approaching angry faces ( ). Since this latter study also used facial stimuli, this again precludes any definitive conclusion as to whether findings simply reflect the well-documented anxiolytic effect of OT in decreasing amygdala responses to threatening facial expressions ( ;  ) rather than specific effects on AA behavior. 

The present study has therefore employed a face-independent AA task combined with fMRI to investigate OT’s specific effects on AA behavior and the underlying neural mechanisms involved. Thus, social and nonsocial scenes rather than facial experimental stimuli were used to determine specific effects of OT on AA behavior per se to avoid its potential confounding effects on face processing. Participants were instructed to approach positive (appetitive approach) and avoid negative (aversive avoidance) stimuli during the AA task. In accordance with the GAAO that OT modulates salience of cues that are personally relevant and emotionally evocative but not necessarily specific to social contexts ( ), we hypothesized that OT would (1) facilitate approach behavior to positive stimuli, particularly more emotionally evocative social ones, and associated activity in the motivational and emotional salience core regions such as the striatum and anterior insula, and (2) decrease avoidance behavior via attenuating amygdala reactivity to negative stimuli, particularly more emotionally evocative negative social ones. 


## Methods And Materials 
  
### Participants and Treatment 
  
A total of 83 healthy male students (mean age=21.35 years, SD=2.48) participated in a randomized, double-blind, between-subject experiment and were randomly assigned to receive either intranasal OT (40 IU; Oxytocin Spray, Sichuan Meike Pharmacy Co. Ltd, China) or placebo (PLC; same ingredients other than OT, i.e., sodium chloride and glycerin). To control for potential confounding effects from personality traits or mood states, subjects completed Chinese versions of validated psychometric questionnaires before treatment, including the Positive and Negative Affect Schedule ( ), Autism Spectrum Quotient ( ), Empathy Quotient ( ), and NEO 5-factor inventory ( ). To further control for a potentially confounding influence of altered mood states, subjects were asked to complete the Positive and Negative Affect Schedule 3 times: after they first arrived (pretreatment), before MRI scanning (posttreatment), and finally after scanning (post-scan). Subjects received OT/PLC treatment in accordance with a standardized protocol ( ), and fMRI acquisition started 45 minutes after treatment. A total of 7 subjects were excluded due to technical issues during data acquisition (4 subjects) or excessive head movement (3 subjects). Thus, 39 subjects in the OT group and 37 subjects in the PLC group were included in the final analysis. In postscan interviews, subjects were unable to identify better than chance whether they had received OT or PLC (χ =0.21,   P  =.646). Written informed consent was obtained from all subjects before study inclusion. All procedures were in accordance with the latest version of the Declaration of Helsinki and approved by the ethical committee of University of Electronic Science and Technology of China. 


### The AA Task 
  
In a revised AA task ( ), participants were instructed to make approach responses to positive social or nonsocial stimuli (e.g., happy friends meeting or beautiful landscapes) and avoidance responses to social or nonsocial negative stimuli (e.g., victims or environmental pollution). In a prestudy, we selected 620 pictures mostly from the International Affective Picture System ( ) and additionally from the Internet that were rated in terms of valence and arousal (9-point Likert scale) by an independent sample of 34 healthy volunteers (18 males). Based on this data, a total of 112 stimuli (28 pictures per category, positive vs negative and social vs nonsocial) were selected: social positive (valence: mean±SD=2.36±0.27; arousal: 6.27±0.35), social negative (valence: 2.47±0.26; arousal: 6.65±0.46), nonsocial positive (valence: 1.68±0.39; arousal: 6.25±0.42), and nonsocial negative (valence: 1.87±0.55; arousal: 6.10±0.70). Note that the valence rating scores were transformed to the distance from the neutral midpoint of the 9-point scale. Each picture was presented for 3 seconds at a 624- × 468-pixel resolution followed by a jittered inter-stimulus interval of 2 to 6 seconds. Subjects were instructed to pull the positive stimuli towards their body by pressing the “down” key and push the negative stimuli away from their body by pressing the “up” key successively via a response pad during the 3-second presentation. To realistically convey approach and avoidance of the stimuli for the subjects, each pulling-associated button press would enlarge the picture by 100×75 pixels while each pushing response would decrease the size of the picture by 100×75 pixels. All subjects preformed 10 practice trials before entering the scanner and were instructed to respond as fast and accurately as possible during the experiment. 


### Image Acquisition and Data Analysis 
  
Images were collected using a 3 Tesla, GE Discovery MR750 system (General Electric Medical System, Milwaukee, WI). During each fMRI scan, a time series of volumes was acquired using a T2*-weighted echo-planar pulse sequence (repetition time: 2000 ms; echo time: 30 ms; number of slices: 39; slice thickness: 4 mm; gap: 1 mm; field of view: 240×240 mm; resolution: 64×64; flip angle: 90°). To control for any anatomic abnormalities and increase normalization accuracy during preprocessing, additional T1-weighted images were acquired obliquely with a 3-dimensional spoiled gradient echo pulse sequence (repetition time: 6 milliseconds; echo time: 2 milliseconds; flip angle: 9°; field of view: 256×256 mm; acquisition matrix: 256×256; number of slices: 156; slice thickness: 1 mm). 

Images were processed using SPM8 (Wellcome Department of Cognitive Neurology, London;   https://www.fil.ion.ucl.ac.uk/spm/software/spm8/  ) ( ). The first 5 functional images were deleted to achieve magnet-steady images, and the remaining images were realigned to correct for head movement based on a 6-parameter rigid body algorithm. After co-registering the mean functional image and the T1 image, the T1 image was segmented to determine the parameters for normalizing the functional images to Montreal Neurological Institute (MNI) space. These normalized images were finally spatially smoothed using a Gaussian kernel (8 mm full-width at half maximum). 

The first-level design matrix included 4 condition-specific regressors (social positive/negative, nonsocial positive/negative) convolved with the canonical hemodynamic response function and the 6 head-motion parameters as nuisance regressors. Contrast images for each stimulus condition, all positive and all negative were created separately. On the second level, group differences were analyzed using 2-sample   t   tests. Interactions were tested using an ANOVA model implemented in a flexible factorial design. Based on our region-specific hypotheses, the analysis focused on core regions involved in salience processing ( ;  ) and appetitive/approach (social/nonsocial reward) and withdrawal/avoidance (punishment/threat) motivational processes ( ;  ,  ;  ;  ;  ), that is, the amygdala, the AI, and the striatum. Importantly, these regions strongly overlap with the network mediating the social cognitive and affective effects of intranasal OT ( ;  ;  ;  ;  ). Regions-of-interest (ROIs) were anatomically defined using the Automated Anatomic Labeling atlas ( ). Within the unilateral a priori ROIs, a threshold of   P  <.05 family-wise error (FWE) peak-level correction was set for multiple comparisons using small volume correction (SVC). Parameter estimates used for plotting and brain behavior associations analysis were extracted for each subject from a 6-mm sphere centered on the peak voxel within corresponding ROIs. For additional exploratory whole-brain analyses, a threshold of   P  <.05 corrected at peak level was used and only clusters >10 voxels are reported. 



## Results 
  
### Questionnaires 
  
Two-sample   t   tests on questionnaires measuring mood, autistic traits, empathy, and personality traits revealed no significant differences between the treatment groups (Ps>.136;  ). 


### Behavioral Results 
  
For response times, a repeated-measures ANOVA was performed with social context (social vs nonsocial) and response type (approach vs avoidance) as within-subject factors and treatment (OT vs PLC) as between-subject factor. This revealed a significant main effect of response type (F(1, 74)=250.46,   P  <.001), with subjects being significantly faster to approach positive than to avoid negative stimuli (1617.33±176.84 vs 1776.95±184.28). The interaction between social context and response was also significant (F(1, 74)=19.04,   P  <.001), with posthoc tests reavealing that subjects were faster to approach social compared with nonsocial positive stimuli (1600.86±172.73 vs 1633.79±180.49) but slower to avoid social than nonsocial negative stimuli (1784.72±181.76 vs 1769.18±187.65). There were no other significant effects (  P  >.106). 

In terms of response accuracy (RA), there was a significant main effect of social context (F(1, 74)=15.75,   P  <.001), with a higher accuracy for social compared with nonsocial stimuli (95.4%±5.7% vs 93.7%±5.4%). The main effect of response type was also significant (F(1, 74)=109.59,   P  <.001), with a higher accuracy for approaching positive than avoiding negative stimuli (97.5%±3.4% vs 91.7%±5.8%). While the interaction between social context, response type, and treatment was not significant (F(1, 74)=0.76,   P  =.385), an exploratory pairwise comparison revealed a significantly higher RA only for social (  P  =.031) but not nonsocial positive stimuli (  P  =.568) in the OT relative to the PLC group ( ). The interaction between social context and response type was marginally significant (F(1, 74)=3.18,   P  =.079), suggesting a trend of higher accuracy to social vs nonsocial stimuli for positive (  P  <.001; 98.8%±2.1% vs 96.2%±4.0%) but not negative stimuli (  P  =.280; 92.1%±6.1% vs 91.3%±5.6%). There were no other significant effects (  P  >.361). Given the slightly higher valence scores for social compared with nonsocial positive stimuli, to clarify whether the valence difference would confound the significant OT’s effects, we further conducted a correlation analysis between valence scores for individual pictures by independent raters and RA for social and nonsocial positive stimuli in the experimental subjects and found no significant associations either for social (Pearson r=0.061, df=28,   P  =.759) or nonsocial positive stimuli (Pearson r=- 0.044, df=28,   P  =.823). Thus, the magnitude of the positive valence score for the individual pictures did not influence response accuracy. 
  
Response accuracy in response to each condition in the oxytocin and placebo groups. Error bars show standard errors. 
  

### fMRI Results 
  
We first examined unspecific effects of treatment (OT vs PLC) independent of response type and social context using a 2-sample   t   test. This revealed decreased right striatum activity (MNI=22, 2, 8, t=4.05,   P  =.025 SVC, voxels=48;  ) in the OT compared with the PLC group (OT  <PLC  ). 
  
(A) Decreased right striatum activity in the oxytocin (OT) compared with the placebo (PLC) group. (B) Decreased activity in the right striatum and the left dorsal anterior insula (AI) in the OT compared with the PLC group during appetitive approach. (C) Decreased activity in the right striatum and the right amygdala in the OT compared with the PLC group during aversive avoidance. Statistic maps were displayed with a   P  <.005 uncorrected threshold. Error bars show standard errors. 
  
Next, we examined treatment effects and interactions between treatment and social context on appetitive approach and aversive avoidance separately. For appetitive approach, decreased activity in the right striatum (MNI=20, 2, 6, t=3.96,   P  =.031 SVC, voxels=29) and the left dorsal AI (MNI=-38, 12, 6, t=3.52,   P  =.040 SVC, voxels=11;  ) was found in the OT compared with the PLC group (OT  <PLC  ). Examining the interaction between treatment and social context (OT  <PLC  ) during approach behavior revealed significant interaction effects in the left ventral AI (MNI=-42, 6, -6, t=3.57,   P  =.022 SVC, voxels=14;  ) and the right dorsal AI (MNI=48, 12, 2, t=3.40,   P  =.036 SVC, voxels=7;  ), suggesting that OT decreased activity in these regions during approach of social relative to nonsocial positive stimuli. 
  
Oxytocin (OT) decreased the left ventral anterior insula (AI) (A) and the right dorsal AI (B) activity in response to social relative to nonsocial positive stimuli (OT  <placebo [PLC]  ). Statistic maps were displayed with a   P  <.005 uncorrected threshold. Error bars show standard errors. 
  
With respect to aversive avoidance, OT decreased activity in the right striatum (MNI=24, 2, 10, t=4.31,   P  =.011 SVC, voxels=58) and the right amygdala (MNI=28, -4, -18, t=3.34,   P  =.025 SVC, voxels=2;  ) irrespective of social context (OT  <PLC  ). Examination of interaction effects between treatment and social context during avoidance behavior (OT  <PLC  ) revealed no significant effects (  P  <.05 SVC). There were also no other significant effects in the a priori ROIs (  P  <.05 SVC). For completeness, additional effects beyond the a priori ROIs on the whole-brain level are reported in   (  P  <.05). 


### Brain Behavior Associations 
  
Correlation analyses between extracted parameter estimates from the left ventral and the right dorsal AI (social positive>nonsocial positive) and RA difference scores (social positive − nonsocial positive) were conducted separately to explore associations between OT-induced modulation on neural responses and corresponding behavioral indices. Results showed a significant negative correlation between activity in the left ventral AI (MNI=-42, 6, -6) and RA difference scores in the OT (Pearson r=- 0.346, df=39,   P  =.031;  ) but not in the PLC group (Pearson r=0.039, df=37;   P  =.818). The correlation difference between groups was tested using the Fisher z-transformation test and revealed a marginally significant difference between the OT and PLC groups (Fishers z-score=-1.672,   P  =.094). 



## Discussion 
  
The present study investigated OT’s effects on AA behavior and corresponding neural mechanisms using emotional scenes and specifically examined whether the effects generalize across social and nonsocial contexts. On the neural level, a significant main effect of treatment was observed in the right striatum, with OT generally decreasing activity in this region irrespective of response type and social context. Furthermore, separate examination of appetitive approach and aversive avoidance revealed that while OT specifically decreased the left dorsal AI activity during approaching positive stimuli, it decreased right amygdala activity during avoidance of negative stimuli. Additionally, exploring the role of social context revealed evidence for a selective enhancement effect of OT on RA when approaching social relative to nonsocial positive stimuli. This behavioral effect was accompanied by decreased left ventral and right dorsal AI activity in response to social vs nonsocial positive stimuli in the OT compared with the PLC group, with the relative difference in left ventral AI activity and RA for social vs nonsocial positive stimuli exhibiting a negative association following OT. By contrast, during aversive avoidance, no evidence for the social specificity of OT was observed. These findings provide support for the GAAO by showing that OT modulates activation of motivational and emotional salience core regions during both approach to positive and avoidance to negative stimuli across social and nonsocial contexts and that OT specifically facilitates approach behavior to more personally relevant and emotionally evocative stimuli, namely positive social stimuli, via inhibiting AI activity. 

Examination of unspecific OT effects on AA behavior revealed significantly decreased activity in the right striatum following OT across both response type and social contexts. The striatum has been strongly involved in both approach (social/nonsocial reward) and avoidance (punishment/threat)-motivated behavior ( ;  ,  ;  ;  ). Thus, OT may inhibit motivational representation both during appetitive approach and aversive avoidance. Furthermore, OT additionally decreased left dorsal AI activity during approach to positive stimuli across social and nonsocial contexts. As a core hub of the salience network ( ;  ), the reduced dorsal AI activity may thus reflect an OT-evoked decrease in the salience of positive stimuli when subjects approached them. 

The observed inhibitory effects of OT on striatum and AI activity seem to conflict with both the proposal that it enhances the salience of social cues ( ) and some previous findings that OT-induced alterations on human social behavior are associated with increased activity in the striatum and AI ( ;  ;  ;  ). Given that OT effects on social behavior are often highly context and person dependent ( ), this inconsistency could be due to different paradigms and contexts used in these previous studies. In previous studies, subjects were asked to passively process certain stimuli, whereas the present study using an AA task required subjects to actively approach or avoid them. 

It is notable that OT also decreased activation of the left ventral and right dorsal AI during approaching social relative to nonsocial positive stimuli. Given the role of the ventral AI in emotional processing ( ;  ;  ) and the dorsal AI in salience processing ( ;  ), these attenuated AI activities may indicate a more robust inhibitory effect of OT on decreasing both the emotional and salience processing of social positive stimuli that are more personally relevant and emotionally evocative ( ). Consistent with previous observations that OT can enhance processing of positive facial emotion ( ;  ;  ;  ), the present study found evidence that OT may specifically facilitate RA during approaching social but not nonsocial positive stimuli. Thus, the oxytocinergic downregulation of AI activation may act to attenuate interference caused by hyperactivation of the AI when subjects approach external social positive stimuli, resulting in enhanced accuracy of social information processing and facilitation of social interaction. This assumption is further supported by the presence of a significant negative correlation between the left ventral AI activity and the RA difference between social and nonsocial positive stimuli following OT but not PLC administration. However, it should be noted that the difference in brain-behavior correlation between groups was only marginally significant, and thus inferences regarding this effect of OT need to be drawn with caution. 

Additionally, OT was found to decrease amygdala activity during avoidance responses to negative stimuli independent of social context. This finding is in line with the anxiolytic action of OT via inhibiting amygdala responses to threatening stimuli ( ;  ). Based on the GAAO ( ), the absence of a social-specific effect of OT on avoiding negative stimuli suggests that threatening social and nonsocial stimuli may be comparable in terms of personal relevance and emotional evocation, perhaps due to the high survival relevance of threating events during evolution ( ). 

Given that we found no significant personality and mood difference between OT and PLC groups, this argues against confounding effects of pretreatment between-group differences on the observed effects of OT. However, individual differences in personality traits have been shown to mediate approach and avoidance behavior, as proposed by the (revised) Reinforcement Sensitivity Theory ( ;  ). More specifically, previous studies have demonstrated associations between the functional organization of the salience network, particularly the AI, and its interactions with anxiety-related traits such as harm avoidance ( ;  ,  ). Thus, future studies should consider examining the role of individual differences in personality traits on AA behavior and their potential modulatory effects on the effects of OT in this domain. Moreover, within this context, the present findings may lend support for potential therapeutic benefits of OT for psychiatric disorders such as social anxiety and autism exhibiting altered approach/avoidance towards social stimuli ( ;  ;  ;  ). 

There are several limitations in the present study. Firstly, considering that organisms have primarily evolved mechanisms to approach stimuli associated with positive outcomes and to avoid those associated with aversive ones, we only asked subjects to approach positive and avoid negative stimuli. Effects of OT on approaching negative and avoiding positive stimuli thus remain to be determined. Secondly, we used only male subjects to avoid possible confounding effects from menstrual cycle; thus, the present conclusions are limited to males and sex differences remain to be explored. Thirdly, another potential limitation is that we cannot completely exclude the possibility of a complex interaction involving differences in social and nonsocial stimuli valence and OT effects on response accuracy during approach behavior. However, for positive valence stimuli, we found no association between individual picture valence and response accuracy for either social or nonsocial stimuli, suggesting that valence differences are unlikely to have had a major impact on our results. Finally, we do not know if the effects we observed with a 40-IU dose of OT may also be observed with lower doses. A previous study has revealed a dose-dependent effect of OT (12, 24, and 48 IU), with the 24-IU dose being most effective in inhibiting amygdala activity during negative emotional processing ( ). However, in 2 previous studies from our group, we reported evidence for comparable effects of 24- and 40-IU doses on both behavioral and neural changes in the context of empathy and self-processing in humans ( ;  ). 

In conclusion, the present study provides first evidence for the GAAO by demonstrating that while OT inhibits motivational representations both during appetitive approach and aversive avoidance, it facilitates human approach behavior to more general positive social stimuli via inhibiting AI activity. This inhibitory effect of OT may reduce interference from emotion-facilitated hyperactivation of core regions of the emotional and salience networks when approaching external social salient positive stimuli and consequently be of benefit in promoting social interaction. 


## Supplementary Materials 
  
Supplementary data are available at International Journal of Neuropsychopharmacology (IJNPPY) online. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-33'>
<h2>33. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/20098696/' target='_blank'>20098696</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Common Premotor Regions for the Perception and Production of Prosody and Correlations with Empathy and Prosodic Ability</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2010</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0008759</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/2808341/' target='_blank'>2808341</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of prosody perception and production tied to social communication and empathy (social-related processing). Participants were healthy adult native-English speakers aged 18–58 (within 18–60). The experiment used whole-brain fMRI acquisition and whole-brain random-effects analyses (FDR-corrected maps reported), with additional small-volume correction steps; primary results are whole-brain rather than ROI-only. The sample excludes neurological/psychiatric disorders and is not a review/meta-analysis. Therefore all inclusion criteria are met and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
## Background 
  
Prosody, the melody and intonation of speech, involves the rhythm, rate, pitch and voice quality to relay linguistic and emotional information from one individual to another. A significant component of human social communication depends upon interpreting and responding to another person's prosodic tone as well as one's own ability to produce prosodic speech. However there has been little work on whether the perception and production of prosody share common neural processes, and if so, how these might correlate with individual differences in social ability. 


## Methods 
  
The aim of the present study was to determine the degree to which perception and production of prosody rely on shared neural systems. Using fMRI, neural activity during perception and production of a meaningless phrase in different prosodic intonations was measured. Regions of overlap for production and perception of prosody were found in premotor regions, in particular the left inferior frontal gyrus (IFG). Activity in these regions was further found to correlate with how high an individual scored on two different measures of affective empathy as well as a measure on prosodic production ability. 


## Conclusions 
  
These data indicate, for the first time, that areas that are important for prosody production may also be utilized for prosody perception, as well as other aspects of social communication and social understanding, such as aspects of empathy and prosodic ability. 

 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (36433 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Prosody, the melody and intonation of speech, involves the rhythm, rate, pitch and voice quality to relay linguistic and emotional information from one individual to another. A significant component of human social communication depends upon interpreting and responding to another person's prosodic tone as well as one's own ability to produce prosodic speech. However there has been little work on whether the perception and production of prosody share common neural processes, and if so, how these might correlate with individual differences in social ability. 

The   production   of prosody is well known to be a specialization of the premotor cortex, in particular the inferior frontal gyrus (IFG), with emotional prosody more strongly activating the right hemisphere and linguistic prosody more strongly activating the left hemisphere  ,  . Research on the   perception   of prosody has largely focused on the right temporal lobe. However, despite this emphasis, there is some indication that the premotor cortex may also be involved  ,  ,  . Nevertheless, premotor contributions to prosody perception have not been well studied. 

There is limited evidence that there may be common frontal areas active for both the perception and production of prosody; patients with lesions to frontal areas seem to have difficulty with both the perception and production of prosody  . However, these lesions are often very large and it is difficult to discern if the same brain areas are utilized in the two tasks. If the same areas were to be involved, it may indicate that, at least under some circumstances, the acoustic signals from another person's prosodic speech are transformed into articulatory signals in order to understand prosodic meaning. That is, it may imply that in order to understand someone else's prosodic intonation, we may utilize our own motor representations of how we would produce the given intonation. 

Indeed, there is a growing body of data indicating that premotor areas are sensitive to the sounds of actions  – . This activation is somatotopic, such that the sounds of hand actions activate the hand premotor areas and the sounds of mouth actions activate the mouth premotor areas  . The finding that regions in motor-related cortices are active for both the production and perception of a particular action is commonly referred to as “mirror system” activation. This data has also been extended for speech perception, showing that premotor mouth areas involved in producing speech are also involved in perceiving speech  ,  . The latter data indicate that motor areas may be involved in the processing of speech, particularly in noisy environments like the fMRI scanner room  . The current research investigates whether a similar pattern could be found for prosody. It also extends the findings of the auditory mirror system to include processing that is relevant to social and emotional information  . 

Furthermore, there is evidence that activity in premotor areas that respond to the sounds of actions correlates with one's ability to empathize with others  . This finding supports the idea that mapping the perception of other people's actions onto one's own motor representations (simulation) may be an important aspect of empathy. There is also evidence that individuals who score low on measures of empathy (as in psychopathic personality as well as autism) have poor prosodic ability  . Investigating the role of prosodic ability and its neural processes has clinical implications in clarifying the role of affective deficits in psychopathy. For this reason, we are particularly interested in exploring the relationship between prosody, empathy, and the mirror system. 


## Materials and Methods 
  
### Participants 
  
Twenty right-handed, native-English speaking volunteers with no history of neurological or psychiatric conditions participated in the experiment. One subject was eliminated from all analyses due to technical errors, bringing the total to 19 subjects (13 females; 18–58 range, mean 28.1). All subjects had normal or corrected-to-normal vision and normal hearing. All assessments were made by screening questionnaires and all subjects gave informed written consent. Human subjects approval for this study was approved by the Institutional Review Board at the University of Southern California. 


### Stimuli and Task Procedures 
  
The main goal of the study is to determine if there are common regions for the production and perception of prosody. For this reason, the functional imaging component of the experiment consisted of two tasks, one to investigate prosody production and another to investigate prosody perception. Half of the subjects performed the production task runs first, while the other half performed the perception task first. Subjects were trained on the tasks prior to scanning. 

#### Production task 
  
Nonsense syllables were used to reduce/exclude additional linguistic processing (e.g., syntax, semantics)  . Subjects were asked to produce the phrase “da da da da da” in different intonations: happy, sad, question, and neutral. Participants were also instructed to produce no speech on some trials (rest condition). Note that our control condition, “neutral” intonation, will still contain intonation, as a flat pitch profile is still a pitch profile. However, it should nevertheless contain less prosodic information than the other conditions. Subjects were presented with a visual cue at the onset of each trial. A line drawing of a face was used to cue the participant to produce one of five task conditions (happy, sad, question, neutral, rest). As   shows, the mouth of the line drawing varied for each cue (smile, frown, question mark for question, straight line for neutral, and X for rest). The visual cue was presented on the screen for 1 s followed by a gray screen and subjects were asked to produce speech as soon as the gray screen appeared. Subjects were trained prior to scanning to produce speech in a tone of voice that matched the presented visual cue. Each seven and a half minute functional run consisted of ten trials of each condition (including rest) for a total of 50 trials, and each subject performed three functional runs of the production task (30 trials per condition total). Participants' performance during the production task were monitored by an experimenter via headphones and recorded through an fMRI-safe microphone and digital voice recorder. Prior testing of the recording setup indicated that while the quality of the recordings were affected by the MRI background noise and conduction through the tubing, these degradations were minimal and did not affect subsequent analyses of voice data. A further concern when subjects produce speech is the possibility for motion artifacts. Our design minimized movement artifact by training subjects prior to scanning to move their heads minimally while producing speech, by using phrases that require minimal jaw movement (e.g.,“da”), and by using other sophisticated motion correction techniques (e.g., an on-line acquisition correction technique during scanning, and use of motion parameters as regressors in the analyses). 
   Schematic of the prosody production task design.  
A visual cue is presented 1 s, followed by 8 s of blank screen. Acquisition of functional volumes occurred during the last 2 s of the blank screen. The conditions were “happy”, “sad”, “question”, “neutral” (not shown in figure), and “rest”. The presentation order of the conditions was randomized for each subject. 
  

#### Perception task 
  
The perception task had the identical design as the production task except for the stimuli; no visual stimuli were presented. Instead, each trial began with a delay of 1 s followed by an auditory stimulus of duration 2 s. The auditory stimuli consisted of voice recordings (“da-da-da-da-da” recorded by an actress) that depicted the conditions happy, sad, question, and neutral. As in the production task, nonsense syllables were chosen to minimize effects of semantics and syntax. Subjects were instructed to listen to the auditory stimulus and to especially attend to the intonation of the voice. All auditory stimuli were pre-tested prior to the experiment. As in the production task, each seven and a half minute functional run consisted of 10 trials of each condition, plus 10 trials where no auditory stimulus was delivered (rest trials), for a total of 50 trials. Each subject performed three functional runs of the perception task (30 trials per condition total). 



### Image Acquisition 
  
Functional MRI images were acquired with a Siemens MAGNETOM Trio 3T machine. In order to ensure that participants could hear the auditory stimuli during the perception task and that we could take audible voice samples during scanning of the production task, we used a sparse sampling paradigm throughout the experiment  ,  . In this paradigm, we minimized scanner noise by acquiring one volume 6 s after event onset to capture the peak of the hemodynamic response to the stimulus  . In the production task, volumes were acquired 6 s after the offset of the visual cue (which was approximately the onset of the subjects' speech production); in the perception task, functional acquisitions occurred 6 s following stimulus onset. Functional volumes were acquired with a echo planar T2*-weighted gradient echo sequence (TR = 9000 ms; TA = 2000 ms; TE = 30 ms; flip angle = 90°; 192 mm FoV; 64×64 voxel matrix; 29 axial slices (interleaved); 3×3×4.5 mm voxels, no gap). A high-resolution T1-weighted structural scan (MPRAGE; TR = 1950 ms; TE = 2.56 ms; flip angle = 90°; 256 mm FoV; 256×256 voxel matrix; 208 coronal slices; 1×1×1 mm voxels) as well as a T1-weighted structural scan with the same slice prescription as the functional images (coplanar; TR = 702 ms; TE = 17 ms; flip angle = 55°; FoV = 192 mm; 192×192 voxel matrix; 29 axial slices; 1×1×4.5 mm voxels) were also acquired from all subjects. Acquisition of functional volumes employed Siemens' prospective acquisition correction (PACE) technique for motion correction, in which head movements are calculated by comparing successively acquired volumes and are corrected on-line  ,  . 


### Image Processing 
  
Functional images were preprocessed and analyzed with SPM2 software (  www.fil.ion.ucl.ac.uk/spm/  ; Wellcome Department of Imaging Neuroscience, London, UK). Images were corrected for slice timing and then normalized to MNI space (using the EPI.mnc template) to allow across-subject comparisons. Motion parameters were calculated for the functional images. Images were then un-warped using the motion parameters and then spatially smoothed with a 7.5 mm Gaussian filter. In each task (production and perception), each condition (happy, sad, question, neutral, rest) was estimated with a Finite Impulse Response, and motion parameters were added to the design matrix as nuisance variables to minimize the effects of head movements during scanning. Scans were excluded from analysis if translational motion greater than 3 mm was detected; no participant exceeded this amount of translational motion. The finite impulse response model was used because our sparse sampling paradigm made it impossible for us to model the entire length/shape of the hemodynamic response function, and thus we needed to analyze each trial/volume as an impulse function. T-contrasts were computed to observe differences between conditions. Group analyses were performed using random effects models with contrast estimates from individual subjects and were thresholded at p<0.05 (FDR multiple comparisons correction) with a minimum cluster size of 5 contiguous voxels. 

#### Task-related activity for prosody 
  
To observe brain regions involved in the processing of prosody, we performed the contrasts “happy-neutral” and “question-neutral”. These contrasts were performed for the production and the perception task separately. The “happy-neutral” and contrast will reveal brain regions involved in emotional prosody processing, while the “question-neutral” contrast will reveal brain regions involved in linguistic prosody processing. The “sad” condition was not used in this analysis because 1) “happy” and “sad” emotions may be processed differently (e.g., Davidson's Approach-Withdrawal Hypothesis  ); 2) if “sad” were included, then the “emotional” and “linguistic” prosody tasks will not be balanced; 3) acoustical analysis indicated that “sad” is more similar to the neutral prosody condition than the “happy” condition, and different from both “happy” and “question” conditions (see supplementary materials,  ). Thus omitting the “sad” condition from this analysis allows us to maximize the difference between our control condition and question prosody condition. 


#### Common regions for perception and production of prosody 
  
To determine brain regions involved in both the production and the perception of emotional prosody, we observed whether regions associated with emotional prosody production were also active during emotional prosody perception. The same procedure was applied for linguistic prosody production and perception. We first obtained a thresholded map for the production task contrast (“happy-neutral” for emotional prosody; “question-neutral” for linguistic prosody; p<0.05, FDR, k>5). Individual clusters from the thresholded production contrast maps were then used as masks to determine whether prosody perception also activated voxels within those regions. These masks were then used to apply small volume correction (SVC) to the corresponding prosody perception contrasts. 



### Behavioral Measures 
  
We were further interested in how activity in brain areas involved in prosody production/perception may correlate with an individual's ability to produce or perceive prosody. Furthermore, because of the relationship between prosody perception and empathy described in clinical literature  , we were also interested in finding a correlation between brain regions active during prosody perception and an individual's scores on measures of affective empathy. Thus, in addition to the fMRI experiment, we also administered questionnaires to our participants outside of the scanner in order to obtain measures of prosody ability and empathy. These measures were used to correlate prosodic ability to empathy as well as with the functional activations during the fMRI experiment. 

#### Assessment of prosodic ability 
  
To assess prosody   production   ability, two raters subjectively scored the voice recordings taken from participants during the fMRI production task on the level of expression of a subset of the trials. The scoring was performed after the scanning session. A 5-point Likert scale was used to judge prosodic ability, with “1” corresponding with “could not determine intended condition”, to “5” corresponding with “could absolutely determine intended condition; superb expression.” Three randomly selected “happy” and “sad” trials from each scanning run were scored, and average scores for “happy”, “sad”, and “happy&sad” were obtained for each subject. To assess prosody   perception   ability, we administered a separate questionnaire where subjects listened to 28 audio clips depicting the conditions happy, sad, question, and neutral, and were to determine the four conditions each clip belonged to. An accuracy score of the proportion of correctly determined clips was obtained for each subject as a measure of how well a person can distinguish between different prosody conditions. 


#### Assessment of empathy 
  
To obtain a measure of empathy in our subjects, we administered two questionnaires: the Interpersonal Reactivity Index (IRI)   and the Psychopathic Personality Inventory-Revised (PPI-R)  . The IRI, a self-report measure assessing specific dimensions of empathy, consists of 4 subscales, each measuring a unique component of empathy. As our aim was to correlate emotional aspects of empathy with individual ability to perceive emotional prosody, we focused on the component of the IRI thought to reflect an affective component of empathy, Personal Distress (PD; e.g., “When I see someone who badly needs help in an emergency, I go to pieces”  . The other subscales of the IRI are Fantasy Scale (FS), Empathic Concern (EC), and Perspective Taking (PT). EC is another form of affective empathy, while FS and PT are considered to be cognitive forms of empathy. These subscales were not included in the hypotheses. The PPI-R also consists of multiple subscales and factors, each representing some psychopathic personality trait. The affective component of psychopathic personality has generally been thought to be inversely related to empathy; individuals who exhibit psychopathic personality traits and show symptoms of antisocial personality disorder are also likely to show callousness and a lack of empathy  ,  . Specifically, the Coldheartedness scale (C) of the PPI-R reflects a propensity toward callousness, guiltlessness, and lack of sentimentality, and is related to a lack of affective empathy. Thus, the PPI-R Coldheartedness scale was used as an additional measure of affective empathy, and we predicted that it would negatively correlate with prosody perception. 



### Correlations between Prosody Perception and Empathy 
  
#### Behavioral 
  
To determine whether an individual's ability to perceive prosody is related to their empathy, we performed correlations between subjects' scores on the prosody perception questionnaire and empathy scores. Once again we focused on components of empathy and performed correlation analyses using subscales that relate specifically to affective empathy, the Personal Distress scale of the IRI and the Coldheartedness scale of the PPI-R. 


#### fMRI 
  
To determine prosody-related brain regions whose activity correlates with prosody perception and empathy ability, we ran simple regression models at the group level for the contrast “happy&sad-neutral” using individuals' empathy scores as regressors. To observe which brain regions show a linear relationship to empathy, contrast estimates of “happy&sad-neutral” perception were correlated with PD scores from the IRI and C scores from the PPI-R to elucidate correlations between affective empathy and neural activity during emotional prosody perception. These analyses were thresholded at p<0.005 uncorrected with a cluster threshold of k>5 voxels. Both the “happy” and “sad” conditions were included in this analysis as we posited that the neural systems involved in perceive both these intonations was related to empathic ability. 



### Prosody Production Ability Correlated with Emotional Prosody Production 
  
Do individuals who are better at producing prosody show more activity in motor regions involved in prosody production? To investigate this we correlated areas that were active for emotional prosody production with the behavioral measure of prosody production ability. To observe which brain regions show a linear relationship to prosody production ability (i.e., the voice production ratings), we correlated each subject's “happy&sad-neutral” production task contrast estimates with their voice ratings. 



## Results 
  
### Task-Related Activity for Prosody 
  
#### Emotional prosody production 
  
The contrast “happy-neutral” for the production task revealed activations in the left inferior frontal gyrus, bilateral anterior middle temporal gyri, bilateral lingual gyri, left cuneus, right midbrain, right fusiform gyrus, left middle frontal gyrus, right anterior cingulate gyrus, bilateral thalami, left superior frontal gyrus, right middle occipital gyrus, left middle cingulate gyrus, right caudate, right insula, left anterior superior medial gyrus, and bilateral posterior superior medial gyri (p<0.05, FDR, k>5). A complete list of results is available in the supplementary materials ( ). In addition, a whole-brain contrast against rest is shown in   and against control in  . Regions specifically involved in emotional prosody perception as compared to control are shown in  . 


#### Linguistic prosody production 
  
The contrast “question-neutral” for the production task revealed widespread activations across many regions, including portions of the superior, middle, and inferior frontal gyri bilaterally, the supplementary motor area, medial regions of the parietal and occipital cortices, the lingual gyri bilaterally, portions of the left insula, posterior regions of the middle temporal gyri bilaterally, the left superior temporal gyrus, and portions of the anterior cingulate cortex (p<0.05, FDR, k>5. A complete list of results is available in the supplementary materials ( ). In addition, a whole-brain contrast against rest is shown in   and against control in  . Regions specifically involved in linguistic prosody perception as compared to control are shown in  . 



### Shared Networks for Emotional Prosody 
  
In order to determine whether brain regions active while producing emotional prosody were also active when perceiving emotional prosody, we created masks from the thresholded production contrast “happy-neutral”, and observed whether these regions were also active in perception. Masks from the production contrast were used to perform small volume corrections to the perception contrast “happy-neutral”. As predicted, motor related regions in the left inferior frontal gyrus (pars opercularis; BA44) and the left middle frontal gyrus (BA 6; dorsal premotor cortex) were significantly active. The left middle cingulate gyrus, right caudate, and right thalamus also survived SVC (p<0.05, FWE, k>5) ( ). 
   Regions of overlap between prosody production and perception.  
Red = Emotional prosody production regions (p<0.05, FDR; T>3.48) that were also active for perception (p<0.05, FDR (SVC); T>2.38). Green = Linguistic prosody production regions (p<0.05, FDR; T>3.80) that were also active for perception (p<0.05, FDR (SVC); T>2.45). A region in the left inferior frontal gyrus appears to be involved for the production and perception of both emotional and linguistic prosody. 
  

### Shared Networks for Linguistic Prosody 
  
We further predicted that motor-related regions would be commonly active for the perception and production of linguistic prosody. In support of our hypothesis, motor-related regions including the left inferior frontal gyrus (pars opercularis; BA44) and left middle frontal gyrus (BA 6; dorsal premotor cortex) and bilateral superior frontal gyri (BA 6) were active for both tasks. The left anterior cingulate cortex and left insula also survived SVC (p<0.05, FWE, k>5) ( ). 


### Behavioral Results 
  
#### Empathy scales 
  
 IRI  . All 19 subjects completed the IRI. The mean scores (and standard deviations) for each subscale are as follows: FS = 19.21 (5); EC = 18.63 (4.7); PD = 8.58 (5.31); PT = 18.26 (5.94). These values are similar to those originally reported by Davis (1980) and are within two standard deviations of the normed mean.   PPI-R  . One subject did not complete the PPI-R due to experimental difficulties; one participant reported 2 standard deviations above the mean and the remaining 17 participants scored within normal range (+/− 1.5 SD) (mean = 29.16; std = 6.33). As the PPI was originally normed on a college population, our patterns reflect the normal bell curve expected for this measure. 


#### Correlations between prosody perception ability and empathy 
  
As expected, correlations between behavioral measures of prosody and empathy revealed significant results for the PD scale of the IRI and for the C scale of the PPI-R. The PD scale correlated positively with performance on the prosody perception task (r = 0.46; R-sq = 0.21; p(one-tailed) <0.0287). This finding is consistent with our prediction that prosody perception ability will be related with affective empathy. The C scale was found to correlate negatively with performance on the prosody perception task (r = −0.47; R-sq = 0.22; p(one-tailed) <0.0297). Because the C scale is an indicator of deficits in affective empathy, the finding of a negative correlation between C scale scores with prosody perception is expected. It should be noted that in future studies, larger sample sizes would be more optimal in testing these scales, and further allow for more stringent analyses to test the hypotheses. Graphs of performance and production scores are shown in   and scatter plots for these correlations are shown in  . 



### Affective Empathy Scores Correlated with Emotional Prosody Perception: fMRI Results 
  
A correlation analysis between individual differences in the PD score from the IRI and contrast estimates during emotional prosody perception indicates regions in the left inferior frontal gyrus (pars triangularis) and right cerebellum as showing activity that positively correlates with PD scores (p<0.005; uncorrected, k>5) ( ). The R-sq for the left IFG is 0.42 with a 95% confidence interval of 0.12–0.73. 
   Regions involved in emotional prosody perception correlated with empathy.  
 A  ) Correlation between emotional prosody perception brain regions and individual differences in PD (IRI) scores. Orange  =  regions that show positive correlation (p<0.005 uncorrected; Z>2.88).   B  ) Correlation between emotional prosody perception brain regions and individual differences in C (PPI-R) scores. Blue  =  regions that show negative correlation (p<0.005 uncorrected; Z>2.88).   C  ) Correlations between emotional prosody production brain regions and performance on prosody production task (rating scores) (p<0.005 uncorrected; Z>2.88). 
  
For the PPI-R, higher scores in the cold-heartedness scale (C) indicate deficits in empathic ability. Thus here we focused on a negative correlation with the C score and neural activity during emotional prosody perception. A correlation analysis between individual differences in the C score from the PPI-R and contrast estimates during emotional prosody perception indicates regions in the frontal cortex, including bilateral superior, middle, and inferior frontal gyri, bilateral cingulate sulcus, bilateral anterior insula, bilateral transverse temporal gyrus (Heschl's gyrus), bilateral superior temporal gyrus, and right TPJ show activity that negatively correlates with C score (p<0.005; uncorrected, k>5) ( ). The R-sq for a region within the left inferior frontal gyrus (pars opercularis) is 0.54 with a 95% confidence interval of 0.26–0.92. While the results reported here support our hypotheses, it should be noted that larger sample sizes would greatly reinforce this finding, and would better allow for effects to be tested with more stringent tests. 

Further post-hoc analyses in the perception/IRI and perception/PPI-R analyses, indicate that the correlations are driven in part by processing of neutral stimuli. Whereas we report a positive correlation in the left inferior frontal sulcus between PD score (IRI) and the “happy&sad - neutral” contrast, this correlation is influenced by a negative correlation between activity during “neutral” and PD score. Likewise, in the left inferior frontal gyrus (L IFG), we report a strong negative correlation between the Coldheartedness score (C; PPI-R) and the “happy&sad - neutral” contrast. This correlation is also in part influenced by a positive correlation between C score and “neutral” activity. 


### Prosody Production Ability Correlated with Emotional Prosody Production 
  
A linear regression between individual differences in prosody production ability and contrast estimates during emotional prosody production indicates motor-related regions in the right inferior frontal gyrus (pars triangularis), the left superior frontal gyrus, and right middle frontal gyrus to be positively correlated to prosody production ability (p<0.005; uncorrected,  ), although this result did not meet the cluster threshold of k>5 voxels. The R-squared for this result is 0.36 with a 95% confidence interval of 0.04–0.67. 



## Discussion 
  
### Common Brain Regions for the Production and Perception of Prosody 
  
We found areas in the premotor cortex, including the left inferior frontal gyrus and the left dorsal premotor cortex were active for both the perception and production of prosody. This was true for both emotional prosody and linguistic prosody. These results are consistent with previous findings of activity in premotor regions during prosody perception  ,  . The current result indicates a link between perception and production, where brain areas that are commonly thought to be involved with motor planning are also active for perception. While there have been numerous previous reports of perceptual processing in motor areas for action observation  – , for the sounds of actions  ,  , and even for speech  , to our knowledge this is the first report of “mirror” processing for prosody. It may indicate that some components of prosodic perception involve mapping the heard speech to areas that are important for producing that same speech. Such mapping of acoustic signals to articulatory signals is reminiscent of the motor theory of speech perception  . This finding is also in line with the proposed “‘as-if’ body loop” where individuals utilize sensory-motor regions to implicitly simulate perceived or imagined experiences  , as well as other studies that indicate that frontal regions are involved in prosodic perception  ,  ,  ,  . While we do not state that this is the only way that prosodic perceptual processing occurs (and clearly other regions are found to be active when just comparing prosody perception to control), activity in the premotor regions might contribute to the processing more or less strongly in particular circumstances, such as in subtle or more ambiguous instances  . Indeed, the topic of motor contributions to speech processing has been a subject of great debate  ,  , and we take the view that motor contributions to speech processing are one several processing strategies that may be utilized, depending on speech context (e.g., noisy/quiet)   and the task demands. 

The inferior frontal gyrus and premotor cortices are known to have connections to auditory areas, in particular though the arcuate fasciculus  . This “dorsal stream” of speech perception from auditory regions to inferior frontal regions may provide a sensory-motor interface that is important for mapping perceived speech onto articulatory processes  ,  . Thus, inferior frontal areas have the possibility for auditory and motor processing, and in fact are known to respond to the sounds of a variety of hand and mouth actions  . In the case of prosody, we hear our own prosody as we produce it. With time, co-activation of production and perception, through Hebbian learning, could strengthen the activity in multimodal premotor areas to either the afferent or efferent component of the speech, thus producing the areas that we find in this study to be active for both perception and production of prosodic speech. 

Interestingly, our data indicate that common motor areas for production and perception of prosody were found in only the left hemisphere (left IFG and premotor cortices). This was true for both linguistic and emotional prosody. Thus, while emotional prosody perception and also prosody production are known to activate the right hemisphere each  , “mirror” regions for prosody seem to be stronger in the left hemisphere. This is consistent with all previous reports of an auditory mirror system as being lateralized to the left hemisphere  ,  , and may indicate a special role in the left premotor cortex for more multimodal processing (motor, visual, and auditory), while the right equivalent areas instead may be stronger in motor and visual properties rather than auditory properties. 

One possible limitation in this analysis is the possibility that participants implicitly made facial movements during perception trials. Outside the scanner, electromyographic recordings were taken from some subjects to test this possibility, and these results of this analysis, indicating a lack of facial muscle movement during perception trials, are included in the supplementary materials ( ). However it should be noted that any study on perception is limited by the possibility of implicit movement unless measured directly inside the scanning session. 


### Correlations with Affective Empathy 
  
Prosodic ability is known to correlate with deficits associated with affective components of empathic processing. This is best observed in individuals with psychopathy. These individuals, who often score low on emotional aspects of empathy, also tend to score poorly on the ability to perceive prosody  . Our behavioral results further support a positive correlation between ability to perceive prosody and ability to feel emotional aspects of empathy, constructs measured by the PPI-R scale of cold-heartedness (C) and the IRI scale of personal distress (PD). Thus we also looked at individual differences in emotional components of empathy [lower scores on (C) measure on the PPI-R, and personal distress (PD) measure on the IRI], and correlated these with areas that were active for the perception of emotional prosody. We found that individuals who scored higher on these measures of empathy showed more activity during emotional prosody perception in anatomically the same premotor areas that we previously found to be active for the perception and production of prosody, including the bilateral inferior frontal gyrus and premotor cortex. They also were found to show less activity in this region during neutral prosodic intonation, indicating that more empathic individuals utilize premotor regions for emotional prosodic perception, but less for non-emotional stimuli. This data support the notion that components of empathy to emotional stimuli may rely on simulation processes carried out, in part, by motor-related areas  ,  . Thus, in order to understand someone else's prosodic intonation, we may simulate how we would produce the given intonation ourselves, which in turn may be a component of the process involved in creating empathic feeling for that individual. These data indicate that individuals who score higher on scales of affective empathy also show more activity in motor-related areas during prosody perception. Our findings extend previous correlations between the mirror neuron system and individual differences in empathy to include, for the first time, an emotional auditory stimulus: happy or sad prosodic intonation. 

The negative correlation with the C score showed additional areas in the left anterior insula and the superior temporal gyrus. The insula activation might indicate more emotional processing when perceiving emotional stimuli by individuals who are more empathic. Activity in temporal areas may indicate that individuals who are more empathic might also initially process the perceived intonation more than other individuals as well. It is interesting to note that the motor-related activations are bilateral while the temporal activations are observed only in the right hemisphere. The right hemisphere temporal activations are consistent with previous studies of prosody perception; however the motor activities are instead consistent with the bilateral control of the mouth muscles, important for prosody production (see supplementary materials,  ). 


### Correlations with Prosodic Ability 
  
Correlations between behavioral measures of prosody production ability and brain regions that are active during prosody production indicate that individuals who are better at producing prosody activate areas important for motor planning of prosody more than individuals that are poor at prosody production. Because here we focus on affective prosody production alone, we find activity predominately in the right hemisphere, as one would expect. While such a finding has been found for other areas of motor expertise  , this is the first time we find such an effect for aspects of non-verbal aspects of language processing. A similar correlation for prosody perception, while interesting, was not possible due to a ceiling effect on the behavioral measures of perception ability; an abnormal population may be more relevant for such a correlation. 



## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-34'>
<h2>34. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/27814379/' target='_blank'>27814379</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> The Difference between Aesthetic Appreciation of Artistic and Popular Music: Evidence from an fMRI Study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2016</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0165377</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5096663/' target='_blank'>5096663</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study used task-based fMRI in healthy adult participants (male, 18–24 y), meeting the age and health criteria. Participants completed an in-scanner behavioral task (listening to musical excerpts and rating aesthetic ‘beauty’), and the authors report whole-brain analyses (voxel-wise contrasts with cluster-level FDR correction) showing activation of default-mode/ToM and reward regions. The paper interprets these activations as engagement of cognitive empathy/social-cognition networks for artistic music, so it assesses social-related processing (implicit ToM/empathy). No exclusion criteria apply (not an ROI-only report, not a review, no clinical sample). Therefore the study is eligible for inclusion as an fMRI study of social-related processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.8</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
To test the hypothesis that pleasure from artistic music is intellectual while that from popular music is physiological, this study investigated the different functional mechanisms between aesthetic appreciation of artistic and popular music using fMRI. 18 male non-musicians were scanned while they performed an aesthetic rating task for excerpts of artistic music, popular music and musical notes playing and singing (control). The rating scores of artistic and popular music excerpts were both significantly higher than that of control materials while the scores of them were not different. The fMRI results showed both artistic and popular conditions activated the VS and vmPFC, compared with control condition. When contrasted popular and artistic condition directly, we found popular music activated right putamen, while artistic music activated right mPFC. By parametric analysis, we found the activation of right putamen tracked the aesthetic ratings of popular music, whereas the BOLD signal in right mPFC tracked the aesthetic ratings of artistic music. These results indicate the reward induced by popular music is closer to a primary reward while that induced by artistic music is closer to a secondary reward. We also found artistic music activated ToM areas, including PCC/PC, arMFC and TPJ, when compared with popular music. And these areas also tracked aesthetic ratings of artistic music but not those of popular music. These results imply that the pleasure from former comes from cognitive empathy. In conclusion, this study gives clear neuronal evidences supporting the view that artistic music is of intelligence and social cognition involved while the popular music is of physiology. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (30202 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
The aesthetics of artistic work has long been considered as disinterested, detached and intellectual, while that of popular work is perceptual and physical [ – ]. However, such speculative perspective is far from the essential characteristic within diverse levels of aethetics. Due to the advancement of neuroscience technologies, more researchers were committed to explore the neural basic of aesthetics, emerging a new research field of “Neuroaesthetics”. In the early period of the 1900s, the neural mechanism of aesthetic judgment or preference for artistic objects attracted the more interest of neuroscientists[ ]. It was found that brain regions recruited by artistic appreciation were highly overlapped with the reward circuit. For example, OFC and ventral striatum which are two typical reward regions were found to be activated during the appreciation of beautiful paintings[ – ]. Recently, researchers have tried to figure out the universal brain correlates for more extensive aesthetics. In research by Ishizu and Zeki, the arousals of mOFC and ventral striatum was reported for both the visual (artistic painting) and acoustic (music) aesthetics[ ]. Furthermore, Brown and his colleagues applied the meta analyses of activation likelihood estimation to demonstrate a core circuit for positive-valence aesthetic appraisal[ ]. The anterior insular, NAcc, pregenual ACC, anterior midcingulate cortex, dorsomedial nucleus of thalamus, ventral basal ganglia, and mOFC were concordantly activated across all four modalities (i.e., visual, acoustic, tactile and osphretic) during aesthetic processing. These regions defined a general aesthetic network including the anterior insular, ventral basal ganglia, rACC and mOFC. In this article, aesthetic processing was naturalized as the appraisal of valence of perceived objects, which involves an interaction between interoceptive and exteroceptive processing. In other words, aesthetic is rooted in a comparison between subjective awareness of current homeostatic state and exteroceptive perception of objects in the environment. However, it has been argued that this is just a general cognitive process that not only can be applied to art objects but also to non-art objects[ ]. 

Though these studies contributed significantly to exploring the general neural mechanism for aesthetics, the implications for artistic appreciation still have not been charaterized. For instance, Brown’s aesthetic model assumes an integrated neural basis for aesthetics of all sensory modalities rather than a different basis for different types, resulting in a finite identification for disparate kinds of aesthetics. Moreover, a meta-analysis research comparing the brain responses to monetary, erotic and food reward outcomes found that for the secondary reward elicited higher activation in the frontal of OFC, whereas the primary reward elicited higher activation in the frontal insular. This meta-analysis study found possible segregated regions involved in different reward processes [ ]. Krik and his colleagues[ ] found a similar pattern of results. Architects and non-architects were asked to make aesthetic judgments of architectural and control stimuli. The results indicated that experts and non-experts differentially recruited bilateral medial orbitofrontal cortex (OFC) and subcallosal cingulate gyrus during the task, even in the absence of a difference in the aesthetic rating made by these two groups. By contrast, activity in nucleus accumbens (NAcc) exhibited a similar response pattern. These findings suggested a dissociable role between these regions in the aesthetic evaluation. 

To answer the question “why music and other artworks activate this same circuitry”, Brown et al.[ ] argued that “[aesthetic processing] evolved first for the appraisal of objects of survival advantage, such as food sources, and was later co-opted in humans for the experience of artworks for the satisfaction of social needs.” Given the high correlation between regions for reward and aesthetic processing, we speculated that brain activation would also be disparate for different kinds of aesthetics. In a recent fMRI study [ ], our laboratory found that facial beauty involved both the subcortical reward region putamen and the cortical reward region OFC, while moral beauty involved only the OFC. The selective activation of the ventral striatum(VS) and OFC for different types of aesthetic was suggested to represent the association between aesthetics and the physiological or social demands. Given this finding, we hypothesized that the high level artistic work that was related with social needs would elicit higher activation in the frontal cortex, whereas the low level popular work that was related with physical needs would elicit higher activation in the striatum region. 

In the modernist view, genres of art develop a hierarchy[ ,  ]. Artistic music, as a higher and complex form, demands an intellectual response. While popular music can not combine popularity and complexity, because popularity requires accessibility. In contrast to artistic music, popular music is more simplistic and repetitive. Therefore, popular music encourages a passive perceptual and physical engagement. It is lack of intellectual challenge and social truth. In the present study, we employed the functional magnetic resonance imaging (fMRI) to explore the neural processes of reward that arise in the appreciation of artistic and popular music. We assumed that high level music would elicit larger activity in OFC or other cortical reward region, and low level music would elicit larger activity in subcortical reward region. 


## Material and Methods 
  
### Ethics Statement 
  
The current study was approved by the Academic Committee of the School of Psychology at South China Normal University. All participants gave written informed consent before participating in the experiments. 


### Participants 
  
Eighteen volunteers (male; 18–24 years old) were recruited from local universities for the fMRI experiment. All of them were philharmonics, but not music professional, who had engaged in some musical training or activities (e.g., choir, Musical Instruments class) before the experiment. They were right handed and reported no prior history of neurological or psychiatric problems. Participants were given a small payment after the experiment. 


### Stimuli 
  
The musical materials selected for the present research consisted of popular music excerpts, artistic music excerpts (opera), and clips of meaningless musical notes in form of playing and singing (please see supplementary material for demo, including  : popular music sample,  : artistic music sample and  : control material sample). The former two musical materials were snipped from songs from CDs or the internet with the theme of love. These songs were all performed by female vocalists, and the lyrics were in languages other than English and Chinese. The notes clips were made in our lab and applied as control stimuli. With the GoldWave (Version 5.58, GoldWave Inc.,   www.goldwave.com  ), all stimuli were standardized to a proper length and identical volume (16dB). Each excerpt began with 500 ms of gradual fade in, and ended up with 500 ms of gradual fade out. 30 popular music, 32 artistic music and 35 notes clips were prepared for pretesting. The duration of the popular and artistic music was between 12–24 s, and that of the notes was 10–15 s. Moreover, beauty and familiarity evaluations for all these materials were collected using a 7-point Likert scale from another eighteen participants, who shared the same age and musical experience with the fMRI participants. 

Based on the pretesting, 40 musical excerpts were selected by matching the beauty, familiarity and length, with half for the popular music and half for the artistic music. The familarity ratings for popular and artistic music were: 3.41±0.33 vs. 3.31±0.37; the beauty ratings for popular and artistic music were: 5.17±0.35 vs. 4.98±0.37; and the lengths for popular and artistic music were: 17.80±2.65s vs. 17.85±3.88s. For these three dimensions, there was no significant difference between popular and artistic music (  ps  >0.05,all). 28 clips of musical notes playing and singing were chosen for the baseline condition by matching the familiarity and total duration between musical (popular and artistic music) and non-musical (note) materials. The average length of notes clips was 12.14±1.27s. The familiarity ratings for note clips (3.29±0.49) were not remarkably different from those for popular and artistic music excerpts, whereas the beauty ratings of note clips (2.81±0.33) were significantly lower than those of musical materials, both   p   = .000 (LSD). 

All the auditory stimuli were present binaurally with a high-quality MRI-compatible headphone system (SA-9800B, Shenzhen Sinorad Medical Electronics, Inc.). The volume of auditory stimuli was individually adjusted before fMRI scanning. Participants were asked to close their eyes during the experiment and open their eyes during the break. Visual instructions were presented on a screen back-projected on a head coil-mounted mirror. 


### Procedures 
  
The experiment program was conducted by the E-Prime 1.2 (Psychology Software Tools, Inc., Pittsburgh, PA). Prior to fMRI scanning, participants underwent a training session to become acquainted with the procedures. In the training session, the materials and the number of trials were not the same as formal experiment. 

The fMRI experiment consisted of 4 consecutive scanning runs. Each run contained 17 stimuli epochs, with 5 for each musical condition and 7 for the control condition. The sequences of stimuli for the four runs were presented as follows (p = popular epoch; a = artistic epoch; c = control epoch): 1) c, p, c, a, c, a, c, p, c, a, p, p, a, c, a, p, c; 2)c, p, a, c, a, p, p, a, c, p, c, a, c, a, p, a, c; 3)p, a, c, p, c, a, c, a, p, c, a, a, c, p, c, p, a, c; 4) c, a, p, c, a, c, p, c, p, a, c, a, p, c, p, a, c. Half of the participants were assigned to the main stimuli sequence (i.e., 1,2,3,4), and half were assigned to the alternative sequence (i.e., 3,4,1,2). Each run started with a blank lasting for 4 s, and then the music excerpt was presented. During inter-stimulus interval (ISI), participants had to rate the beauty of each stimulus by pressing the corresponding key. The duration of ISI was about two thirds of the presentation time of previous stimuli. The whole experimental run lasted for 420 s without any stimuli during the last 10s. All participants were asked to close their eyes during each experimental run, and open their eyes during rest. 

After the fMRI session, participants were required to rate the following two questions for all stimuli using a 7-point Likert scale (response format: 1 = "not at all"; 4 = "medium"; 7 = "extremely"): A. The beauty of the music; and B. The familiarity of the music. 


### MRI Data Acquisition 
  
MRI data were acquired using a 3T whole-body scanner (Siemens TIM TRIO). Functional images were obtained using a multislice echo plannar imaging (EPI) sequence (36 slices, slice thickness 3.5+0.7 mm gap, TR = 2.2 S, TE = 30ms, field of view = 220*220mm2, 64*64 matrix, flip angle: 90°). Scanning slices were aligned approximately parallel to the AP-PC plane, and interval scanning was carried out from the bottom up. For spatial normalization, a high-resolution T1-weighted anatomical image was acquired after EPI acquisition, using fast spin echo sequence(176 slices, 1×1×1mm, FOV = 256*256mm2, TE = 2.43ms, TR = 2530ms). 


### fMRI Data Analysis 
  
The obtained fMRI data were preprocessed and analyzed using the statistical parametric mapping (SPM8; Wellcome Trust Center for Imaging, London, UK;   http://www.fil.ion.ucl.ac.uk/spm  ). For stabilization of magnetization, the first five volumes of each session were discarded. Data preprocessing was done with default setting of SPM8. EPI images were co-registered and normalized to the T1 standard template in Montreal Neurological Institute (MNI) space (resampling voxel size: 2×2×2mm), and smoothed with a Gaussian kernel with 6 mm FWHM. 

After preprocessing, we carried out both factorial model and parametric model analyses [ ]. For the factorial model, first level analysis was performed on each subject by estimating the variance of musical epoch according to a general linear model (GLM). Three kinds of musical epochs were modeled as separate regressors convolved with the canonical hemodynamic response function. For the parametric model, trials of pop music or artistic music were respectively included into a single regressor, accompanied by a parametric regressor of according post-aesthetic rating. For both models, six motion parameters estimated during the realignment procedure were included as covariates of no interest. 

At the group level, all images were subjected to a voxel-wise contrast and one way ANOVA-within subject analysis to assess statistical significance for the factorial model. ROI analyses with two sample t-tests were further performed in whole brain clusters showing a significant contract between popular music and artistic music conditions. Marsbar (version 0.42) was applied to extract the beta value, with spherical ROIs of 10mm radius for putamen, 12mm radius for other areas. The central location of each ROI was determined by the results of factorial model analysis. For the parametric analysis, one-sample t-tests were used to reveal the regions in which the BOLD signal correlatively changed with the aesthetic rating scores of popular and artistic music, respectively. A tow-sample t-test was also used to find out the areas response differently to the rating of the two type of music. For the above models, global analyses were conducted at a voxel threshold of   P  <0.002 (uncorrected), and a cluster threshold of FDR<0.05. Small volume correction (SVC) was used, with a 10 mm radius centering a sphere on the coordinate of the ventral striatum peak voxel, and a 12 mm radius centering a sphere on the coordinate of the peak voxels of other regions. 

The behavioral data of scanning rating, and post-scanning ratings were analyzed by the One-way ANOVA (using LSD in post hoc analysis) via software SPSS16. 



## Results 
  
### Behavioral Results 
  
Beauty ratings during scan and post-scan were both concerned and analyzed. During fMRI scanning the beauty ratings of popular music (3.29±0.52) did not differ from those of artistic music (3.24±0.58),   P   = 0.80 (LSD); however, beauty ratings of both musical materials were significantly higher than those of control notes (1.88±0.57), both   P  <0.01 (LSD). In the post-scanning the beauty ratings for the three types of stimuli displayed the same pattern as those in the fMRI scanning, with larger ratings for popular (5.16±0.29) and artistic (5.00±0.28) music than control notes (2.21±0.55), both   P  <0.01 (LSD). The analysis of the familiarity ratings in the post-scanning was also performed, yielding no remarkable differences between these three types of stimuli, with 3.45±0.49 for popular music, 3.31±0.41 for artistic music, and 3.26±0.31 for control notes,   P   = 0.25 (one-way ANOVA). 


### fMRI Results 
  
As can be seen in  , higher BOLD responses in bilateral mOFC and ventral striatum were observed for popular and artistic music than for notes.   shows coordinates, T value, and cluster sizes of the significant activation revealed by these contrasts respectively. A direct contrast between popular and artistic music demonstrated that popular music induced more activation in right putamen (see  ), and artistic music induced more activation in right rACC (see   and  ). Further analyses on the beta values extracted from these two ROIs revealed that, for the right putamen, there were greater activation for popular music condition than for artistic music condition,   t  (34) = 2.30,   P   = 0.03. In contrast, for the right rACC, there were greater activation for the artistic music condition than for the popular music condition,   t  (34) = 2.68,   P   = 0.01. 
   Brain activation of popular and artistic music vs. control material.  
Larger activity in bilateral mOFC and bilateral ventral striatum were found for popular(A) and artistic(B) music than for control material. 
     Activation of reward circuit in the contrast of popular and artistic music.  
(A) Popular music evoked larger BOLD response in the right putamen (26, 6,2) than artistic music; (B) Artistic music evoked larger BOLD response in the right rACC than popular music (BA24/32, 12,36,0). (C) Mean beta values and SD of the ROI analysis in putamen and right rACC for popular music and artistic music comparing control condition, respectively. Within every single ROI, beta values of both popular music and artistic music conditions were first subtracted by the mean beta value of control condition in the same ROI, before two sample t-test. 
     Regions showing a main effect at   p  <0.05 with FDR correction at the cluster level for contrasts Popular music > Notes Clip and Artistic music>Notes Clip.           Regions showing a main effect at p<0.05 with FDR correction at the cluster level for contrasts Popular music > Artistic music and Artistic music>Popular music.        
We also found popular and artistic music both elicited more default mode network/Theory of Mind (DMN/ToM) regions, such as arMFC, PCC/PC, temporal pole, and parahippocampal gyrus, than the notes clip (please see  ). Some other regions, such as angular gyrus and hippocampus, were also observed to show significantly more activation for artistic music than for control note (see  ). DMN/ToM regions, such as left arMFC (BA32/10), left angular gyrus, left inferior temporal gyrus, left hippocampus/parahippocampus, right hippocampus and right inferior temporal gyrus, showed greater BOLD response to artistic music than to popular music (see   and  ). The result of ROI analysis also revealed the significant difference of Beta values in these areas(  P  < 0.01,   t   = 2.80;   P  < 0.01,   t   = 4.02;   P  < 0.01,   t   = 2.89;   P  < 0.01,   t   = 2.91). 
   Cognitive empathy regions were activated in the contrast of artistic vs. popular music.  
(A) The regions consisted of left arMFC, left PC/PCC, left angular gyrus, left hippocampus /parahippocampus, and left and right inferior temporal gyrus. (B) Mean beta values and SD of the ROI analysis in left arMFC (-6,36,20), left PC/PCC (-4,-42,46), left angular gyrus (-32,-80,32) and left hippocampus (-28,-22,-14) for popular music and artistic music comparing control condition, respectively. Within every single ROI, beta values of both popular music and artistic music conditions were first subtracted by the mean beta value of control condition in the same ROI, before two sample t-test. 
  
The parametric analysis revealed similar results. For popular music, as the post aesthetic ratings increased the activation level of right putamen increased (see   and  ). The activity of right interior frontal gyrus and some cerebellar area such as culmen, tonsil and declive also showed linear relationships to aesthetic ratings. We also found a cluster located in supplementary motor area (SMA) in which the activity tracked with aesthetic ratings of popular music. However, the small volume correction only revealed a marginal significant(  P   = 0.058). For artistic music, we found positive linear correlation between the aesthetic ratings and the activation level in several regions, including rACC, arMFC and PCC(see   and  ). However, we can not found any brain regions tracking aesthetic ratings of popular music more synchronously than those of artistic music or regions tracking aesthetic ratings of artistic music more synchronously than those of popular music. 
   Cerebral regions tracking increasing aesthetic rating of popular music and artistic music.  
(A) Cerebral regions tracking increasing rating of popular music included right putamen and IFG. (B) Regions tracking increasing rating of artistic music included right rACC, left arMFC and PCC. 
     Regions tracking increasing aesthetic ratings of popular music and artistic music.        


## Discussion 
  
In the present study, artistic music, popular music and musical notes playing and singing were manipulated to investigate the general and specific neural correlate for acoustical aesthetic. The artistic music was related with higher VS activation compared with control notes. Moreover, the artistic music activated more right mPFC than popular music. These findings indicated the mechanism differences between artistic music and non-artistic music reflects in the reward circuits. In the previous studies focused on neuroaesthetics, parameter or category design was commonly applied, and they focused on the form beauty based on abstract graphics [ ], external beauty based on facial stimuli [ – ], and art beauty based on painting, music, dancing, and sculpture stimuli [ ,  ,  – ]. Two reward circuits were found to be involved in processing of different kinds of beauty: one is the cortical reward circuit (includes mOFC); another is the sub-cortical reward circuit, such as striatum (includes putamen, caudate, and nucleus accumbens). However, inconsistent activation patterns of these two circuits for aesthetics were reported in previous research. For facial beauty, nucleus accumbens and OFC were separately found to be activated in the condition of facial beauty in some research[ ,  ,  ]; whereas in some other studies, these two regions were simultaneously activated for beautiful faces [ ,  ,  ]. For painting beauty, Vartanian and Goel found that the BOLD response of caudate was decreased as the likable ratings got smaller [ ]; Kavabata and Zeke [ ] reported a larger activation of OFC during the appreciation of a beautiful painting. Moreover, OFC and caudate were simultaneously activated when viewing beautiful paintings in other research [ ,  ]. 

These findings demonstrate possible diverse activation patterns in cortical and sub-cortical reward circuits for different aesthetics, which raises a further question about which factors would determine the connection between aesthetics and brain activity. Most recently, an attempt by Wang and Mo [ ] produced some exciting findings and should shed light on this issue. They compared the networks of moral beauty and facial beauty, and found that moral beauty representing advanced social needs recruited only the cortical reward region OFC, whereas facial beauty recruited both the OFC and the subcortical reward region putamen. Given that, we supposed that the correlation between aesthetic objects and the physical (basic) or social (advanced) demand would determine the activation pattern of prefrontal reward region and striatum in reward circuit. That is, the more the aesthetic object relied on basic demand, the more VS would be involved; the more the aesthetic object relied on advanced social demand, the more prefrontal reward regions would be involved. 

The present research was conducted to further verify our aesthetic-demand hypothesis by comparing the appreciation process between artistic music (high level) and popular music (low level) via fMRI technology. As expected, popular and artistic music both elicited larger activation in VS than control note, and popular music evoked larger activation in right putamen than artistic music. The parametric analyses also revealed that the activation of putamen tracked aesthetic ratings of popular music significantly more synchronously than those of artistic music. For the cortical circuit, popular and artistic music both elicited larger BOLD response in mOFC (BA11) than control note. Moreover, artistic music evoked larger BOLD response in right rACC (BA32) than popular music. The BOLD signal in right rACC and the adjacent anterior prefrontal cortex (aPFC, BA10) also showed higher correlation with the aesthetic rating of artistic music than with the popular music. 

mOFC and rACC were found activated in response to the reward stimuli[ ,  – ]. In a study about cross-modality aesthetic, the activity of mOFC in BA11 was observed during visual or acoustical art appreciation. The nearby regions such as rACC (BA32) and aPFC (BA10) also showed sensitivity to the beauty[ ]. The latter two regions were collectively considered as medial prefrontal cortex (mPFC) [ ,  ], which would also be preferentially recruited by the value of rewards as mOFC [ – ]. It is worth noting that, in the present study, the beauty ratings for artistic and popular music were not significantly different. Therefore, the beauty rating difference can not be responsible for the higher activation of mPFC for artistic music than for popular music. Considering the parametric analysis results which suggested that the activation level of mPFC was much more correlative with artistic music rating, we propose that the increased mPFC activity for artistic music would derive from the greater affection for artistic stimuli. Our view agreed with the results of Trost and colleagues in which they examined the neural correlates for disparate musical emotions[ ]. In this study, emotions, such as tenderness, peacefulness, transcendence, and nostalgia, which were characterized by sublime aesthetic also features recruited more rACC than other emotions. Alternatively, rACC has been considered to serve a role in recruiting greater attentional control for emotion processing[ ,  ]. Under these circumstances, the activation of rACC in artistic music appreciation in present study might reflect more intensive intellectual efforts. In summary, the results of present study supported our first hypothesis that the high level artistic work, which was relevant to social needs or more intensive intellectual response, would elicit higher activation in the frontal cortex, whereas the low level popular work, which was relevant to physical needs, would elicit higher activation in the striatum region. 

In addition, we also found that artistic music evoked higher arousal in the default network/ToM than popular music, which indicated larger involvement of social cognition for artistic music appreciation. Empathic engagement between an audience and art works is considered as another crucial element for artistic appreciation[ – ], especially in the music domain. From this point of view, an audience could understand or experience the intention, affective and feeling implicated in the artworks through empathy. Based on the studies of normal and brain lesion participants, two types of empathy—emotional empathy and cognitive empathy—have been identified[ ,  ]. Emotional empathy is a pure emotional contagion, which relies on the mirror neuron system (MNS), while cognitive empathy is more advanced and relies on the mentalizing or theory of mind (ToM) system. Although default network/ToM regions were also found to be activated during art work appreciation in previous studies, activation in these areas was never considered to reflect cognitive empathy [ ,  ,  ]. For example, in a study of Brown and colleagues[ ], participants were asked to listen to beautiful but unfamiliar music, which elicited activation in the left rACC (BA32), retrosplenial cortex (BA29/30), and hippocampus. The activation of these regions was interpreted as the representation of emotion processing. In another work of musical appreciation, sublime music evoked the activity of vmPFC and hippocampus/ parahippocampus, this finding was determined to be an automatically associative processes for this kind of music [ ]. But more and more evidence verifies the possible association between the default mode network for art appreciation and social cognition. In the study of Geday and Gjedde [ ], strong emotion caused a decrease of the deactivation of the arMFC during the task. Moreover, this effect disappeared in the situation without self-involvement, which demonstrated the possible influence of social cognition on arMFC activation. More recently, Vessel [ ] found that the most moving art works were related to the higher arousal in arMFC, PCC, and hippocampus. These findings were attributed to the personal relevance during aesthetic experience. Aesthetic was proposed as a process that requires personal relevance to combine the perception and emotional reaction. Given that, the larger activation for artistic music than for popular music in default network/ToM related regions should not represent the beauty difference between these two types of music, because no significant difference in beauty rating were found in our study. The parametric analysis results in this paper also gave additional evidence for the role of these areas in music appreciation. These results also exclude the possibility that the DNM have just been recruited in artistic music condition for a simple music monitoring task, even given that DMN is also relevant to internal goal or simple tasks. In summary, the more sensitive response in DMN/ToM related regions to artistic music appreciation than popular music appreciation would represent the greater involvement of advanced social cognitive empathy for artistic music than popular music. 


## Conclusions 
  
This study applied fMRI technology to explore the disparate neural activations in appreciation of popular and artistic music. Both sub-cortical (e.g., VS) and cortical (e.g., vmPFC) reward regions engaged in artistic and popular music aesthetic appreciation, while the sub-cortical reward region (e.g., putamen) was more sensitive to popular music while the cortical region (e.g., mPFC) was more sensitive to artistic music. In addition, the cognitive empathy regions, including PCC/PC, TPJp and arMFC, were more responsive to artistic music than popular music and control notes, implying more social cognition involved artistic music aesthetic appreciation. In conclusion, this study gives clear neuronal evidences supporting the view that artistic music is of intelligence while the popular music is of physiology. 


## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-35'>
<h2>35. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/29813018/' target='_blank'>29813018</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Cognitive regulation alters social and dietary choice by changing attribute representations in domain-general and domain-specific brain circuits</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> eLife</p>
<p><strong>Publication Year:</strong> 2018</p>
<p><strong>DOI:</strong> 10.7554/eLife.31185</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5973829/' target='_blank'>5973829</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Meets all inclusion criteria: study used functional MRI while participants completed a social-related task (the altruism/dictator-style task manipulating focus on Ethics/Partner), participants were healthy adults (mean age ~28, range within 18–60), and whole-brain analyses were reported (searchlight MVPA and whole-brain group-level tests with FWE cluster correction). Although supplementary ROI analyses were performed post-hoc, primary results and decoding maps derive from whole-brain searchlight analyses and are not limited to ROI-only results. No psychiatric/neurological populations were included. Therefore the study should be included.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Are some people generally more successful using cognitive regulation or does it depend on the choice domain? Why? We combined behavioral computational modeling and multivariate decoding of fMRI responses to identify neural loci of regulation-related shifts in value representations across goals and domains (dietary or altruistic choice). Surprisingly, regulatory goals did not alter integrative value representations in the ventromedial prefrontal cortex, which represented all choice-relevant attributes across goals and domains. Instead, the dorsolateral prefrontal cortex (DLPFC) flexibly encoded goal-consistent values and predicted regulatory success for the majority of choice-relevant attributes, using attribute-specific neural codes. We also identified domain-specific exceptions: goal-dependent encoding of prosocial attributes localized to precuneus and temporo-parietal junction (not DLPFC). Our results suggest that cognitive regulation operated by changing specific attribute representations (not integrated values). Evidence of domain-general and domain-specific neural loci reveals important divisions of labor, explaining when and why regulatory success generalizes (or doesn’t) across contexts and domains. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (79776 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Choices often require us to weigh competing considerations. Does a decadent piece of cake merit the pounds we’ll put on afterwards? Should the pleas of a homeless person trump our own selfish needs? Empirical evidence suggests that the answer to these questions depends in part on a decision maker’s goals ( ) and can be affected by intentional control ( ;  ;  ). Cognitive regulation of decision making thus serves an important function in goal-directed behavior ( ), relying on attention, working memory, and executive control to promote particular, goal-congruent choices (e.g., eat healthier, be kinder). Cognitive regulation of decision making is an important technique in therapeutic interventions for problematic behaviors, including obesity ( ), addiction ( ), and other decision making disorders ( ). Previous findings have significantly advanced our understanding of the psychological and neural bases of cognitive regulation of decision making ( ;  ;  ;  ), yet important questions about its computational underpinnings remain. At what level of the processing stream does goal-dependent cognitive regulation change the typical trajectory of choice? Does it operate in the same manner in different contexts, or does it depend on the domain? Answering these questions has important ramifications for understanding when people succeed or fail to implement their regulatory goals during decision making, why some people seem to succeed more often than others, and whether there are neural targets for treatment or biomarkers to identify at-risk individuals. 

In studies of basic choice, weighted additive utility models have been used successfully to capture patterns in human behavior across a variety of domains ( ;  ). In these models, decision makers compute the decision value (DV) of each option as the weighted sum of its choice-relevant attributes   ( ;  ) and compare them to make a choice. Recent neuroscience work provides evidence in favor of this model, observing signals related to the value of specific attributes in distinct cortical and subcortical areas, for both social ( ;  ) and non-social choices ( ;  ). In turn, signals correlated with the overall, integrated decision value of an option have been observed in multiple regions, such as the ventromedial prefrontal cortex (VMPFC) and ventral striatum ( ;  ;  ;  ;  ;  ;  ). A key goal of neuroeconomics is to describe how these attribute and decision value computations change as a function of regulatory goals and contexts, and to link such changes to regulatory success. Here, we sought to address three important questions about this process. 

First, at what level does cognitive regulation operate to change value representations? Based on the neuroeconomic model outlined above, we hypothesized two possibilities. The   attribute-level   hypothesis suggests that cognitive regulation of decision making could alter value representations at a relatively low level, by amplifying or diminishing attribute representations directly in a distributed set of specific, dedicated attribute-coding areas, similar to attentional effects on visual object encoding ( ). Alternatively, the   integration-level   hypothesis suggests that cognitive regulation of decision making might operate at comparatively higher levels in centralized, domain-general value integration areas such as the VMPFC ( ;  ). 

Second, we aimed to explicitly test whether cognitive regulation alters value representations at the   same   level regardless of domain, or whether it differs as a function of attributes, goals or choice domain. For example, some attributes (such as taste) may be innate and prepotent, while other attributes (such as health or social considerations) may be more abstract or effortful to construct ( ;  ;  ). We sought to test whether these distinctions might affect where and how cognitive regulation operates to alter value representations during decision making. We also sought to determine whether this translates into distinct regulatory capacities as a function of regulatory goal or choice domain. 

Finally, we sought to shed light on whether information represented in VMPFC and dorsolateral prefrontal cortex (DLPFC) supports either attribute-level or integration-level changes in value during cognitive regulation of decision making. For example, some experimental evidence supports the idea that the DLPFC might represent more abstract attributes like health ( ;  ), and that regulatory control could modulate interactions between the DLPFC and VMPFC to change attribute weights in integrative decision value computations ( ;  ;  ;  ). However, several failures to observe changes in the VMPFC during cognitive regulation of decision making ( ;  ;  ) suggest the need to either measure value computation in a more sensitive way, or to identify alternate routes to behavioral change. 

Addressing these issues requires investigating regulatory control across multiple attributes and domains, using a sophisticated array of approaches for identifying changes in the representations of both specific attributes and integrated value signals. We used functional magnetic resonance imaging (fMRI) to measure brain responses while subjects completed two choice tasks, separated in time by up to 24 months ( ). Choices involved foods varying in healthiness and tastiness (food task) or monetary proposals varying in payoffs for subjects and an anonymous partner (altruism task). To mimic the kinds of cognitive reframing approaches that are often used in therapy for decision making disorders ( ;  ), both tasks asked subjects to adopt distinct regulatory goals designed to highlight different choice attributes (e.g., ‘focus on the food’s healthiness’, ‘focus on your partner’s feelings’). To pinpoint whether and how regulation altered specific attribute representations or integrative value computations at the behavioral and neural level, we combined a multi-attribute extension of the drift diffusion model (DDM) ( ;  ) with multivariate pattern analyses (MVPA) of neural responses ( ;  ). MVPA approaches to fMRI data exploit information encoded across multiple voxels and have been suggested to detect information that would be missed by conventional univariate analyses ( ). Past research on cognitive regulation has relied primarily on mass univariate approaches, which could account for some of the inconsistencies observed in the literature. Our study used MVPA to examine whether and how directed attention to specific goals affects the neural information content (i.e., decoding accuracies) for attribute values in different social and non-social decision contexts. We hypothesized that goal-dependent changes in neural decoding accuracies would match predictions on altered attribute weights from the behavioral computational model. We investigated where such changes occurred, whether they operate in generic or domain-specific manner, and whether they predicted specific aspects of regulatory success across individuals. 
   fMRI Paradigms and Choices.  
(  A  ) Food Task. Subjects chose between on-screen food items that varied in tastiness and healthiness and a neutral default food. Choices were made in ‘Natural’ [NC], ‘Focus on Health’ [HC], and ‘Focus on Taste’ Conditions [TC]. (  B  ) Altruism Task. Subjects chose between on-screen proposals that affected the payoff of themselves ($Self) and an anonymous partner ($Other) and a default option ($20 for both). Choices were made in ‘Natural’ [NC], ‘Focus on Ethics’ [EC], and ‘Focus on Partner’ Conditions [PC]. (  C  ) (  D  ). Bar plots illustrate condition-wise percentages of healthy (C) and generous (D) choices (M ± SD), and subject-specific scores (circles). *p < 0.05, corrected,  p < 0.05, uncorrected. (  E  ) Computational behavioral model (DDM). Choices (yes/no) are made when the sequential accumulation of noisy value information that unfolds over time crosses the predefined upper or lower threshold for choice. The relative decision value (RDV) at a point in time (t) is computed as the weighted sum of choice relevant attributes plus noise (ε) (i.e., RDV  = RDV + w  * Tastiness + w  * Healthiness + ε ). In the example displayed here, the value of a candy bar will tend to accumulate in a positive direction if the weight on Tastiness is high (blue line), yielding a choice in favor of a tasty but unhealthy item. However, the value of the food item is more likely to accumulate in a negative direction if the weight on Healthiness is high (brown line). Note that saying Yes can sometimes indicate a healthy choice, and sometimes an unhealthy choice. (RT = reaction times [sec]; figure adapted from [ ;  ]). 
 
   Drift diffusion model (DDM) fits to behavior in both choice tasks.  
(  A  ) Correspondence in the altruism task between observed acceptance rates (top) and response times (bottom) for different proposal types (bars) and model predictions (blue circles, determined using best-fitting parameters for each subject). On average, subject-level correlation between observed and predicted acceptance rates across trial types was generally quite high. (  B  ) Correspondence in the food task between observed and model-predicted acceptance rates (top) and response times (bottom) for foods of varying taste and healthiness (subject-specific ratings outside the scanner). For illustration purposes, for both tasks model fit to behavior is shown for eight bins created based on the displayed color scheme (right) for variations in choice-relevant attributes (increased attribute values from left to right). Thus, bar colors correspond to trials with specified combination of attributes. 
  
 

## Results 
  
### Behavior 
  
To identify how value computations change to accommodate regulatory goals, our analysis strategy proceeded in the several steps. First, on the behavioral level, we confirmed that regulatory goals resulted in altered choice behavior. We also used our computational behavioral models (multi-attribute drift diffusion models, DDMs) to link these alterations to amplification or suppression of the influence of specific choice-relevant attributes on choices. 

#### Choice behavior 
  
Choices in both tasks varied considerably by regulatory goal ( ). In the food task, subjects made choices in three conditions: Respond Naturally [NC] (‘respond as you naturally would’), Focus on Health [HC] (‘focus on the healthiness of the food when making the choice’), and Focus on Taste [TC] (‘focus on the tastiness of the food when making the choice’), implemented in interleaved blocks (see Appendix 1 – Instructions for regulatory conditions in both choice tasks for instructions). We defined a healthy choice as accepting the on-screen food if it was healthier than the default food (based on subject-specific healthiness ratings obtained outside of the scanner, see Materials and methods), and rejecting it otherwise. As expected, subjects made significantly healthier choices during HC (M ± SD: 78.83% ± 18.46) compared to both NC (44.31% ± 10.71) and TC (41.99% ± 11.46; paired t-tests: p’s < 0.001, Bonferroni corrected unless stated otherwise). They also made marginally less healthy choices during TC than NC (p = 0.043, uncorrected; repeated measures ANOVA across all conditions: F(2,35) = 97.01, p < 0.001). 

In the altruism task, subjects were instructed either to Respond Naturally [NC] (‘respond as you naturally would’), Focus on Ethics [EC] (‘focus on doing the right thing and consider the ethical or moral implications of your choice’), or Focus on Partner [PC] (‘focus on your partner’s feelings and how the other person is affected by your choice’) (see Appendix 1 – Instructions for regulatory conditions in both choice tasks for instructions). We defined an altruistic choice as accepting an on-screen proposal whose outcome (relative to the default) benefitted the other at a cost to the self, or rejecting one in which the subject stood to benefit but their partner did not. As expected, subjects made altruistic choices significantly less often under NC (28.71% ± 15.48) compared to EC (49.94% ± 16.22) or PC (66.97% ± 24.35; p’s < 0.001; F(2,35) = 65.96, p < 0.001) ( ). Altruistic choices were also significantly higher in PC than EC (p < 0.001), suggesting that directing attention to another persons’ feelings generally increased altruism more effectively than considering social and moral norms. Overall, these findings confirmed that regulatory goals resulted in altered choice behavior in the food task and the altruism task. 


#### Regulatory success 
  
Given the considerable individual heterogeneity in the extent of these changes, we also sought to understand whether this heterogeneity might be consistent across tasks and regulatory instructions. Regulatory success – defined as goal-consistent changes in percent healthy or altruistic choices ( ) (e.g., the increase in healthy choices during HC compared to NC) – covaried across tasks ( ). People who chose healthy foods more often when attending to a food’s healthiness also behaved more altruistically when focusing on pro-social attributes. These results did not depend on the delay between tasks (partial correlations controlling for delay of up to 24 months, M ± SD: 16.42 ± 8.66, range: 1 to 24) or differences in baseline responding   within   a particular condition: the percentage of healthy and altruistic choices during NC blocks of both tasks did not correlate (all p’s > 0.05, uncorrected). Instead, they were driven by choice behavior during regulation: healthy choice during HC correlated with altruistic choice in both EC (r = 0.45, p < 0.05) and PC (r = 0.66, p < 0.001). Overall, these findings indicate that an individuals’ regulatory success generalized across choice domains. We found no significant correlation of self-reported motivation to comply with instructions with regulation success in the food task (all p’s > 0.14, uncorrected) or the altruism task (all p’s > 0.16, uncorrected) (Appendix 1 – Self-reported motivation to comply with instructions and observed regulation-success). 
   Correlation of regulatory success (RS) in both choice tasks.      

#### Computational parameter estimates (DDMs) 
  
We hypothesized that changes in choice behavior could result either from increased weighting of goal-consistent attributes (e.g. healthiness in HC), decreased weighting of goal-inconsistent attributes (e.g. tastiness in HC), or both. We tested these possibilities by fitting multi-attribute DDMs to behavior, separately for each subject in each condition and task (see Appendix 1 – Drift diffusion model for details). Model fits to behavior indicated that we were able to capture both choices and RTs with high accuracy ( ). Supplemental analyses also confirmed that the DDM did not perform worse in capturing behavior during regulation conditions compared to natural choices (Appendix 1 – Drift diffusion model). To determine if regulatory goals altered weights assigned to distinct attributes, we computed repeated measures ANOVAs with regulatory goal as a within-subject factor, separately for each attribute. 

As predicted, regulatory goals in the food task changed the weights assigned to tastiness and healthiness (all F(2,35) ≥ 103.36, p’s < 0.001; see   for attribute-specific estimates; for complete list of model-estimates and RTs see  ). Healthiness influenced food choices   more   in HC, and   less   in TC, compared to NC ( , all p’s ≤ 0.001). By contrast, tastiness influenced food choices less in HC, compared to both NC (p < 0.001) and TC (p < 0.001) ( ). No differences emerged between NC and TC (p = 0.47, uncorrected, 2-tailed), suggesting that decision processes in TC likely resemble natural choice contexts. 
   Goal-dependent modulation of attribute value encoding.  
 Behavioral   weights (left column) assigned to attributes in food choices (  A  . Healthiness,   C  . Tastiness) or altruistic choices (  E  . $Self,   G  . $Other,   I  . Fairness) varied by regulatory goal (estimates of drift diffusion models, DDMs).   Neural   decoding accuracies of attribute values (right column) also varied across conditions in specific brain regions (  B  . Healthiness,   D  . Tastiness,   F  . $Self,   H  . $Other,   J  . Fairness) (p < 0.05, FWE corrected at cluster-level) (estimates of Support Vector Regression models, SVRs). Bars represent median estimates (blue = behavioral DDMs, red = neural SVRs; black boxes signify 25–75 percentile, lines illustrate the overall distribution), HC = Health Condition, NC = Natural Condition, TC = Taste Condition, PC = Partner Condition, EC = Ethics Condition, L = left hemisphere, R = right hemisphere, LPFC = Lateral Prefrontal Cortex, SFG = Superior Frontal Gyrus, MFG = Mid Frontal Gyrus, TPJ = Temporoparietal Junction, SFS = Superior Frontal Gyrus. 
 
   Goal-dependent modulation of neural value encoding in DMPFC ($Self) and Precuneus ($Other) in the altruism task.  
Panel displays average decoding accuracies for clusters where neural representations of attributes varied across regulation conditions for neural Support Vector Regressions (SVRs) (p<0.001, FWE corrected at cluster-level). Bars represent median estimates; black boxes signify 25–75 percentile, lines illustrate the overall distribution. HC = Health Condition, NC = Natural Condition, TC = Taste Condition, PC = Partner Condition, EC = Ethics Condition, L = left hemisphere, R = right hemisphere. 
  
    Model-estimated weights (w) assigned to choice-relevant attributes in the food task and altruism task (DDMs).    
Regulatory goals had a similarly dramatic influence on attribute weights in the altruism task (all F(2,48) ≥ 21.48, p’s < 0.001;  ). Subjects’ choices were swayed more strongly by their own monetary outcome ($Self) in NC compared to PC (p < 0.001) and marginally compared to EC (p = 0.059, uncorrected, 2-tailed) ( ). Moreover, the influence of their own payoffs on choices decreased more dramatically in PC than EC (p < 0.001). In contrast, estimated weights on the partner’s monetary outcome ($Other) increased for both pro-social regulatory conditions compared to NC (p’s < 0.001), with marginally higher weights in PC than EC (p = 0.013, uncorrected, 2-tailed) ( ). Fairness of proposed payouts (−1*|$Self - $Other|) influenced choices significantly less in NC compared to EC (p < 0.001), and marginally less compared to PC (p = 0.021, uncorrected, 2-tailed). Weight on fairness was also significantly higher in EC than PC (p < 0.001) ( ). Note that within-task results for the altruism task are reported for the slightly larger sample size of 49 subjects. Considering only the subset of subjects that also participated in the food task (N = 36) yielded comparable weights for attributes in altruistic choices ( ). Overall, the results suggest that regulatory goals changed choice behavior by both increasing weighting of goal-consistent attributes (e.g. healthiness in HC) and decreasing weighting of goal-inconsistent attributes (e.g. tastiness in HC). 



### Neural encoding of choice attributes and effects of regulation 
  
Next, we examined neural underpinnings of goal-consistent increases/decreases in the influence of attributes on altered choices in both tasks. This analysis step was designed to provide evidence for the effects of regulation at the attribute-level or integration-level. Both hypotheses suggest that changes in the influence of distinct attributes on choice should correspond to changes in neural encoding of those attributes. However, they make different predictions about   where   these changes should be observed. The attribute-level hypothesis predicts that attributes are encoded in attribute-specific brain areas and that regulation should result in changes to these local representations. By contrast, the integration-level hypothesis suggests that attribute-specific areas should encode attributes similarly   regardless   of the regulatory goal. Instead, altered representations should appear only within centralized brain regions associated with value-integration, such as the VMPFC, and should be detectable in a common signal associated with integrated values. We tested these distinct predictions by examining where attribute values were represented in the brain, and how these representations varied as a function of regulatory focus. We also explicitly tested whether the locus of effect differed across attributes (e.g. tastiness/healthiness, $Self/$Other/Fairness) or choice domain (e.g. social, non-social). 

#### Neural encoding of choice attributes and decision values across conditions 
  
Our behavioral results suggest that a weighted combination of different choice-relevant attributes captures behavior in both choice tasks ( ), implying that attribute information should be represented in the brain. However, the generality and specificity of this encoding has important implications both for theories about how different attributes are constructed, and how regulation operates to modulate their influence. We first sought to determine which brain regions reliably encoded trial-by-trial variation in a given attribute across experimental conditions and goals. Thus, this first set of decoding analyses tested   if   neural activation patterns encode attribute values, irrespective of whether one or several conditions drive this predictive information. To this end, we averaged the condition-specific decoding maps of an attribute for each subject and tested for brain regions that reliably predict values of the attribute at the group level. Consistent with predictions, information about each attribute could be decoded significantly above chance in multiple brain regions ( ), including the VMPFC, and, for some attributes, the DLPFC. This was also true for trial-by trial encoding of decision values (DVs, corresponding to observable choices in the altruism and food task). See   (main effects) for a complete list of results and details on the clusters in the (V)MPFC and DLPFC for the neural decoding of DVs. 
   Neural prediction of trial-wise attribute values in food choices and altruistic choices.      

#### Conjunction of neural representations of choice attributes 
  
Given the robust coding of individual attributes, we asked whether any brain regions encoded   all   attribute values across all contexts, as might be expected of domain-general areas contributing to value integration processes. A formal conjunction of all attribute-specific decoding maps (Healthiness, Tastiness, $Self, $Other, Fairness; thresholded at p < 0.05, FWE cluster-level correction, height threshold of p < 0.001) identified VMPFC ([MNI −6, 49, 1],  ) as well as a handful of other regions ( ). This suggests that the VMPFC contains information on trial-wise values of   all   choice-relevant attributes, consistent with its hypothesized importance for valuation and choice. 
   Conjunction of neural representations of attribute values.  
Multivariate response patterns in the VMPFC encoded trial-wise values of all choice-relevant food attributes (Tastiness, Healthiness) and altruistic attributes ($Self, $Other, Fairness) across regulation conditions, as indicated by a conjunction of attribute-specific decoding maps thresholded at p < 0.05, FWE corrected at cluster-level. 
 
   Conjunction of brain areas that encoded trial-by-trial values of all attributes.  
Attribute values for Healthiness, Tastiness, $Self, $Other, Fairness. Each attribute was thresholded at p < 0.001, cluster-level corrected, k = 10 voxels. Not displayed are clusters in the supplemental motor area ([MNI −3 26, 46], 43 voxels) and visual cortex ([MNI −28,–85, 32], 15 voxels, [MNI −21,–67, 40], 10 voxels). Coordinates refer to center of mass for the identified clusters in MNI space (Montreal Neurological Institute), R = right hemisphere. 
  

   Exploratory functional connectivity analyses.  
(  A  ) Region of the VMPFC (red) where increased connectivity with the DLPFC during Health vs. Natural and Taste focus conditions correlates with Δw Healthiness in Health vs. Natural and Taste Focus. The yellow region shows the VMPFC ROI defined by the conjunction of all attributes. Orange indicates overlap. Inset: DLPFC seed region. (  B  ) Region of the VMPFC (red) where decreased connectivity with the DLPFC during Partner and Ethics conditions compared to Natural predicted decreases in Δw $Self in Partner and Ethics vs. Natural condition. The yellow region shows the VMPFC ROI defined by the conjunction of all attributes. Inset: DLPFC seed region. (  C  ) Region of the Precuneus where increased connectivity with the VMPFC during Partner vs. Ethics conditions Δw $Other weight in Partner vs. Ethics trials. Yellow region shows the VMPFC ROI defined by the conjunction of all attributes. Inset: Precuneus seed region. All results are shown thresholded at p < 0.005 uncorrected. 
  
 

#### Goal-dependent representations of choice attributes and decision values 
  
Having confirmed that attribute values (and decision values) could be decoded from neural response patterns, we next asked whether, how and where neural information content changed as a function of regulatory goals. We hypothesized that altered behavioral weights of an attribute should be mirrored by changes in the neural encoding of that attribute as expressed in varying predictive accuracies. Crucially, these analyses allowed us to test whether goal-dependent change in neural encoding of attribute values occurs in attribute-specific regions or at a common neural locus regardless of attribute or domain. For each attribute, we used a repeated measures ANOVA implemented in SPM together with condition-specific decoding accuracy maps to test for changes in neural information on attribute values across conditions (see  ). This allowed us to identify brain regions where neural information content about an attribute, or decision values ( ), was enhanced or diminished in a way that matched behaviorally-estimated changes in attribute weighting (thresholded at p < 0.05, cluster-level corrected, height threshold of p < 0.001; see  ). 
   Goal-dependent coding of attribute values (left to right).  
For each participant, we created a spherical searchlight (left panel, black sphere) and extracted multi-voxel response patterns for every trial of a choice task (middle panel). Next, we trained a support vector machine (SVM) regression model with data of 8 runs (80 trials), using neural response patterns as features and trial-wise attribute values as labels (e.g. a food’s perceived tastiness). Test data consisted of data of the ninth run (10 trials) for which we predicted the trial-wise attribute values solely based on neural response patterns of these trials. The decoding accuracy (average of 9-fold cross-validation) was assigned to the central voxel of the sphere from which we extracted the neural data (right upper panel). This procedure was repeated for every measured voxel (left panel, dotted red line), yielding a whole brain accuracy map for an attribute, separately for each task condition and participant. Finally, at the group level (lower right panel), we used these whole-brain accuracy maps to test for brain regions where predictive information on an attribute was increased/decreased depending on the task condition, based on predictions of the behavioral computational model (DDM). (Note that condition-specific accuracy maps also allowed testing for main effects of neural encoding of an attribute (i.e. encodes attribute values), irrespective of whether one or several conditions drive the effect.). 
     Goal-dependent change of neural information content on attribute values.      
##### Healthiness 
  
Behavioral model-fitting suggests that healthiness was weighted more heavily in HC compared to both NC and TC ( ). Consistent with model-based predictions, decoding accuracies in the right lateral prefrontal cortex (LPFC) were higher when focusing on health [HC] compared to both other task conditions ([HC >NC], and [HC >TC]) and combined [HC > (NC, TC)];  ;  ). 


##### Tastiness 
  
Behaviorally, tastiness was represented less strongly in HC compared to NC and TC, with no significant differences between the latter ( ). Decoding accuracies in the right superior frontal gyrus (SFG), extending to the mid frontal gyrus (MFG), closely matched these predictions [(NC, TC) > HC] ( ). Neural representations of trial-wise tastiness were also significantly higher for separate comparisons of [NC > HC] and [TC > HC], but did not differ between NC and TC. Only two other regions (visual cortex and left motor cortex) followed this pattern ( ). 


##### $Self 
  
Estimates of the best-fitting behavioral parameters for $Self suggest that neural information representing subjects’ own benefits should decrease in both pro-social regulation conditions (PC and EC) compared to NC ( ). Formal tests of this pattern ([NC > (EC, PC)]) identified neural responses in both DMPFC ( ) and the MFG (p < 0.001, uncorrected;  ; for [NC] > [EC] significant at p < 0.05, cluster-corrected). 


##### $Other 
  
Based on the behavioral model we predicted that, compared to NC, the partner’s benefits should be represented more strongly when attending to either ethical implications or the other’s thoughts and feelings ( ). Surprisingly, no brain regions matched this precise pattern (for [(PC, EC) > NC], or [PC > NC], or [EC > NC], at p < 0.05, cluster-corrected). However, a comparison of [PC > EC] revealed that decoding accuracies in the bilateral precuneus and right temporoparietal junction (TPJ) ( ) ( ) were significantly more predictive of the others’ payoffs when goals focused on the partner compared to ethical implications. Supplemental ROI analyses within these two areas indicated that average predictive accuracies were significantly higher in PC than NC, partially confirming the prediction of amplified information for $Other [PC > NC] from the behavioral model ( ). 


##### Fairness 
  
Behaviorally, fairness of payoffs for self and partner influenced choices more strongly when attending to ethics [EC] and, to a lesser extent, the partner’s feelings [PC] ( ). Consistent with model-based predictions, decoding accuracies in the left superior frontal sulcus (SFS) predicted the degree of fairness more strongly in the two regulatory conditions compared to natural choice contexts ( ). Contrary to the model prediction, comparisons of [EC > PC] (and [PC > EC]) did not yield any significant results, suggesting that both regulation conditions increased neural representations of fairness considerations to a comparable level. 

Notably, repeated measures ANOVAs also allowed testing for changes in neural attribute representations or decision values that were   not   predicted by changes in the behavioral DDM estimates. These supplemental tests did not yield any further significant results (p < 0.05, FWE cluster-corrected). 


##### Decision values 
  
See   for details on goal-dependent coding of decision values in both tasks. Only two regions (motor cortex in food task [TC > HC], cerebellum in altruism task [EC >PC]) were found to be significant (p < 0.05, FWE cluster-corrected). We thus focused on goal-dependent changes in information content on attribute values. 



#### A common hub for cognitive regulation of attribute values in the DLPFC 
  
To determine whether any areas might serve as a common pathway for goal-dependent changes in encoding of choice attributes, we computed 2-, 3- and 4-way conjunctions of all clusters that showed modulations of predictive information across conditions ( ). A cluster in the MFG ( ), hereafter referred to as DLPFC, emerged in the 3-way conjunction of voxels that flexibly encoded attribute values for Healthiness, Tastiness, and $Self. We found no other areas showing such a convergence of attributes. 
   Domain-general locus of goal-dependent attribute coding.  
(  A  ) Conjunction of voxels in DLPFC that flexibly encoded attribute values of Healthiness, Tastiness, and $Self across conditions within the respective task (p < 0.05, FWE corrected at cluster-level). (  B  ) Cross-condition decoding analyses tested for shared neural code in the DLPFC conjunction area across attributes and regulatory goals. Multivariate SVR models were trained on data in one condition (e.g. Taste NC) and tested on another (e.g. Taste TC), and vice versa (2-fold cross-validation; within-cell sanity checks used split-half approach). Red illustrates significant cross-condition decoding, blue illustrates non-significant results (permutation tests, cutoff-values of 95th percentile of empirical null-distribution).   Within-attribute decoding   (yellow frames): similar neural codes in DLPFC encode values of an attribute across contexts/regulatory conditions (with the exception of 2 of 18 tests).   Cross-attribute decoding  : neural response patterns that encode values of one attribute don’t allow predicting values of another attribute (neither within-task [tastiness-healthiness] nor across tasks [tastiness-$Self, healthiness-$Self]), independent of contexts. This pattern of results indicates that goal-sensitive representations of attribute values in DLPFC rely on attribute-specific neural codes. 
  
This finding suggests that the DLPFC acts as a domain-general circuit for goal-sensitive value representations. But what does this convergence in the DLPFC signify? On the one hand, the DLPFC might encode a   unitary decision value signal   that is sensitive to current goals. While limited to a specific set of attributes, this would support the integration-level hypothesis. If this was the case, the same code that represents a food’s tastiness in the food task (e.g. when focusing on taste) should also permit decoding of other attribute values used in other contexts (i.e., healthiness when focused on health, $Self in natural settings of altruistic choice). On the other hand, the DLPFC might compute attribute-specific representations in a goal-sensitive manner. This hypothesis is more consistent with attribute-level modulation. In this case, encoding of attribute values in this region should be unique to each specific attribute (i.e. codes for one attribute should not permit decoding of other attributes). We tested these competing predictions in a post-hoc ROI-based analysis examining the extent to which neural codes for one attribute in one context (e.g. tastiness in TC) generalize across attributes and contexts (e.g. healthiness in HC). These post-hoc decoding analyses differ from the previous set of analyses: more specifically, to probe for shared neural code in the DLPFC, we trained the SVM regression model on data of one attribute in one condition and see if it allows predicting trial-wise values of   another   attribute in the same or different regulatory condition (and vice versa, 2-fold cross-validation). We also tested for common neural codes for the same attribute across regulatory contexts. 

Results most clearly supported the attribute-level hypothesis. While codes for each attribute (tastiness, healthiness, and $Self) in the DLPFC generally allowed for decoding of the same attribute in other conditions at significant or marginally significant levels, no attribute allowed for coding of a   different   attribute, regardless of condition ( ). This supports the idea that the DLPFC acts as a domain-general mechanism for representing different attributes in a goal-sensitive manner, using unique codes for each attribute. 


#### No evidence for goal-dependent coding of attribute values and decision values in the VMPFC 
  
The vmPFC has previously been suggested to encode attribute values as a function of their current relevance to choice control ( ). Notably, our analyses on the whole brain level did not reveal any significant variation of attribute value encoding in this area as a function of the regulatory goal. However, in light of previous evidence, we conducted a number of post-hoc ROI-analyses to probe in a more sensitive manner for goal-dependent value coding in the VMPFC (see Appendix 1 – ROI-based post-hoc tests to identify goal-consistent value coding in the VMPFC). While activation patterns in the VMPFC (as well as several other regions) reliably predicted overall decision values in both tasks, regulation failed to modulate decoding accuracies for decision value ( ) or for   any   specific attribute (Appendix 1 – ROI-based post-hoc tests to identify goal-consistent value coding in the VMPFC), and did not predict individual differences in regulatory success (Appendix 1 – ROI-based post-hoc tests to identify goal-consistent value coding in the VMPFC). 



### Individual differences in regulatory success 
  
Are some people   generally   more successful using cognitive regulation of decision making or does it depend on the choice domain? Why? To address these questions, we examined the generality and specificity of value representations and their role in regulatory success. In particular, we predicted that if regulatory success operates through common   domain-general   mechanisms, individual success in regulating the effects of one attribute should be correlated with regulatory success in modifying different attributes in completely different contexts. Consequently, neural responses within such a domain-general neural locus should predict individual differences in people’s regulatory success across domains. By contrast, to the extent that cognitive regulation of decision making operates at the attribute-level in a   domain-specific   manner, success regulating one attribute in one domain should be uncorrelated with regulatory success for other attributes in other domains. It should also be predicted by neural activation in distinct, non-overlapping brain regions. 

#### Regulatory success in goal-dependent attribute weighting 
  
Although our previous analyses suggested that regulatory success as measured by frequency of healthy and generous choices was correlated across participants, this analysis did not examine how such success relates to changes in specific attributes. Thus, to determine whether regulatory success operates through common channels across attributes and domains, we first tested using behavior whether subjects’ ability to modulate specific attribute weights (estimated in separate DDMs) was correlated across the two tasks. Consistent with the notion of a common neural mechanism (in DLPFC), successful reduction in the weight on selfish considerations (Δw $Self) in altruistic choices was correlated with successfully amplifying the weight on health considerations in food choices (e.g., r = 0.50, for Δw $Self [NC - PC] and Δw Healthiness [HC - NC], p < 0.05, corrected) and suppressing the weight of taste considerations in food choices (e.g., r = 0.45, Δw $Self [NC - PC] and Δw Tastiness [NC - TC], p < 0.05, corrected). Notably, however, enhancement of the weight on another person’s outcomes did   not   correlate with changes in other attributes (all p’s > 0.05, uncorrected). See   for detailed list of results. Overall, this pattern suggests that regulation may operate through both common and distinct channels as a function of specific attributes, a point we return to in the neural results below. 


#### Domain-general predictions of individual differences in regulatory success in DLPFC 
  
Our preceding neural decoding results support a model in which regulation alters specific attribute representations within domain-general brain areas for some attributes (e.g., tastiness, healthiness, $Self) and within domain-specific areas for other attributes (e.g., $Other, fairness). This idea may explain the specific pattern of correlations we observed in behavioral measures of regulatory success and makes a further prediction: if the integrity and flexibility of the DLPFC is only necessary for representing certain attributes in a goal-consistent manner, then responses in this region should predict regulatory success only for those attributes that converge in this area, while regulatory success for other attributes (e.g., $Other) should be predicted by other regions (e.g., TPJ or precuneus). We tested this hypothesis using a cross-subject decoding approach: in a nutshell, this decoding analysis tested whether multi-voxel activation patterns in an ROI (e.g. DLPFC) allowed predicting an individuals regulatory success in a choice task, solely based on the participants regulation-related neural activation patterns (see Materials and methods and Appendix 1 – Multivariate regression of individual differences in regulatory success for details). The analyses focused on an ROI in DLPFC (with supplemental tests for TPJ, precuneus, and VMPFC) and regulatory success scores defined both by changes in attribute weights and by percentage of goal-consistent choices. 

As hypothesized, regulation-related neural activation patterns in the right DLPFC conjunction area ( ) during the food task reliably predicted how well a subject decreased taste weights and increased health weights in food choices (Δw Tastiness [(NC, TC) - HC]: r = 0.51, p < 0.014, permutation test; Δw Healthiness [HC - (NC, TC)]: r = 0.42, p < 0.041). Predictions further improved when we focused on altered attribute weights for HC versus TC (Δw Tastiness [TC - HC]: r = 0.68, p = 0.002; Δw Healthiness [HC - TC]: r = 0.47, p = 0.014). Similar results were found when we predicted subject-specific changes in regulation success based on improved dietary choices (ΔHealthy Choices [HC - (NC, TC)]: r = 0.50, p = 0.016; ΔHealthy Choices [HC - TC]: r = 0.46, p = 0.027), demonstrating that regulation-related neural predictions extend to actual behavior with real consequences. 

Next, we asked whether neural activation patterns in the right DLPFC also predict individual differences in regulation success in the altruism task. Remarkably, neural patterns in DLPFC during   food   choices predicted subjects’ ability to reduce the weighting of their own monetary payoffs during   altruistic   choices separated in time by an average of 16 months from the food task (Δw $Self [NC - (EC, PC)]: r = 0.50, p = 0.015; Δw Self [NC - PC]: r = 0.55, p = 0.005; permutation tests). They also predicted increases in generous behavior when attending to pro-social attributes (ΔGenerous Choices [(PC, EC) - NC]: r = 0.63, p < 0.001; ΔGenerous Choices [EC - NC]: r = 0.44, p = 0.028; ΔGenerous Choices [PC - NC]: r = 0.63, p = 0.002). Supplemental analyses suggest that predictive information on altered generosity was driven by neural information on changes in the attribute encoded in the DLPFC ($Self) and not by other attributes of the altruistic choice task (e.g., $Other, fairness) (see Appendix 1 – DLPFC-based prediction of goal-consistent changes of generosity is driven by goal-consistent changes in attribute representations of $Self (but not $Other or Fairness)). We also confirmed that decoding accuracies were not correlated with the delay between both choice tasks (all p’s > 0.05, uncorrected), indicating that predictions of individual difference scores of regulatory success were unrelated to temporal delays between tasks. Complementary decoding analyses based on brain data obtained during altruistic choices revealed similar patterns, further supporting our findings ( ). 


#### Precuneus encodes individual differences in regulatory success in altruistic choice 
  
Strikingly, patterns in the DLPFC did not decode regulatory success for social attributes that were flexibly encoded in other regions of the brain (i.e., $Other, Fairness). A post-hoc analyses tested whether neural activation patterns that encoded values of $Other in a goal-consistent manner would allow predicting individual differences in regulatory success in the altruism task. We found that response patterns in the precuneus reliably predicted individuals’ altered generosity in the altruism task (ΔGenerous Choices [PC - EC]: r = 0.57, p = 0.002 [CI: −0.41, 0.38]; ΔGenerous Choices [(NC, PC) - EC]: r = 0.61, p = 0.004 [CI: −0.41, 0.41]), suggesting that domain-specific attribute coding contributes to individual differences in regulatory control. 


#### VMPFC does not encode individual differences in regulatory success 
  
Because of its hypothesized role in valuation, a post-hoc analyses also examined whether the VMPFC region that encoded all attributes predicted regulatory success in either choice task. However, local activation patterns in VMPFC were   not   predictive of regulatory success for any attribute (all p’s > 0.31). This result suggests that while this region may encode all choice-relevant attributes, it was not the locus for changes in value representation in this task. However, exploratory functional connectivity analyses provided subtle hints that the VMPFC could be indirectly related to regulatory success through its modulation of both DLPFC and precuneus (see   and Appendix 1 – Changes in functional connectivity with the VMPFC correlate with regulatory success for details). 




## Discussion 
  
Cognitive regulation of decision making represents a crucial tool for altering behavior to fit momentary goals (e.g. eat healthy, be kinder). Capitalizing on the strengths of behavioral model-fitting ( ) and the greater sensitivity of neural multivariate pattern analysis ( ), we demonstrate how regulatory goals modulate value representations at the level of choice-relevant attributes, supporting goal-consistent behavior. Unexpectedly, cognitive regulation of decision making did   not   reliably modulate value signals within the VMPFC. Instead, regulatory effects converged to modulate a subset of distinct attribute representations in both the social and non-social domain within a region of the DLPFC that has previously been implicated in value-based choice ( ;  ;  ). Cognitive regulation of decision making also altered attribute representations for specific   social   attributes in distinct areas, including TPJ and precuneus. This pattern of neural convergence and divergence was reflected by behavioral patterns of covariation in regulatory success across tasks, made more remarkable by the fact that they were measured anywhere from weeks to more than a year apart. Our results provide important and novel insights into the domain generality and specificity of cognitive regulation of decision making, explain when and why regulatory success generalizes across contexts and domains, and raise exciting new questions for exploration. 

### Attribute-level vs. integration-level effects of cognitive regulation of decision making 
  
Do goals (e.g. eat healthier, be kinder) influence construction of value by operating on distinct attribute representations, or by changing integration of these values in centralized, common-value regions of the brain? Our results provide three key pieces of evidence in favor of attribute-level value modulation by cognitive regulatory control. First, although the VMPFC contained reliable information on the values of   all   attributes and encoded overall decision values across social and non-social contexts, these signals showed   no   modulation by regulatory goal for any attribute or decision value and did not predict individual differences in regulatory success. Moreover, no other area showed a complete correspondence between behavioral and neural effects of regulation, arguing against a single, centralized locus for effects of cognitive regulation on decision making. Second, we observed goal-dependent representations of some attributes (i.e., others’ benefits) in distinct, specialized brain regions like the TPJ and precuneus. Third, although we observed converging effects of regulation for a subset of attributes in the DLPFC (including tastiness, healthiness, and self-related benefits), representations of these attributes utilized distinct, differentiated codes. Taken together, although our results do not preclude the possibility that in other contexts cognitive regulation of decision making might operate on a single, centralized value integration mechanism, they suggest that it may often operate by changing distinct attribute representations. 


### Domain-general vs. domain-specific effects of cognitive regulation 
  
If cognitive regulation of decision making is mediated by changes in distinct attribute representations, when might we expect regulatory success – or failure – to generalize across contexts and domains? Our results indicate that although the DLPFC used distinct codes to represent different attributes, it may nevertheless be a common denominator in regulatory success across domains. Behaviorally, goal-consistent shifts toward ‘virtuous’ behavior in one domain (i.e. healthier food choice) correlated with shifts in the other (i.e. more generosity). This covariation was driven by correlated changes in the behavioral weighting of   precisely   those attributes represented in the DLPFC (i.e., tastiness, healthiness, and self-related benefits), but not in attributes encoded elsewhere (i.e. other-related benefits, fairness). These findings are even more remarkable given delays of up to 24 months separating the two choice tasks (average 16 months), ruling out alternative explanations like memory, mood, or priming effects. Thus, the DLPFC may represent a stable individual resource permitting flexible representation of specific attributes according to current goals. 

At the same time, goal-consistent changes in pro-social attributes (e.g. others benefits) appeared in areas like the TPJ and precuneus, especially when focused on the partner’s thoughts and feelings. This accords with growing evidence linking these regions to   domain-specific   computations related to Theory of Mind (ToM) ( ;  ;  ) and representing others’ mental states and needs during social choice: for instance, activation patterns in the rTPJ were recently shown to encode individual differences in the level of ToM during altruistic choice ( ). Notably, activity in these regions did not encode other social attributes (e.g., fairness) or their goal-consistent changes. Moreover, focusing on ethical and normative reasons for giving (which may require less focus on others’ specific thoughts and feelings) increased altruistic choice, but actually   decreased   representations of the other’s payoffs in these regions. Thus, the TPJ and precuneus appear to encode features specifically related to representing others’ outcomes in a goal-sensitive manner, pointing to specialized loci of cognitive regulation in social choice domains. 


### The role of VMPFC and DLPFC in valuation and cognitive regulation 
  
Our study adds to a growing body of experimental work finding that behavioral effects of regulation can occur in the absence of corresponding changes to either overall levels of VMPFC response ( ;  ;  ), or VMPFC representation of specific attributes like taste ( ). They also raise the intriguing possibility that the flexibility of DLPFC attribute representations may be particularly important for compensating when regulation of the VMPFC fails, a finding also observed in other studies of cognitive regulation of decision making ( ). This raises an important question: what determines the capacity of the DLPFC to properly represent these different attributes? Intriguingly, exploratory connectivity results suggested that this may actually derive, at least in part, from functional interactions with the VMPFC area that represented all choice-relevant attributes, with the strength of connectivity between DLPFC and VMPFC correlating with regulatory success. Although speculative, this finding is consistent with research in both animals and humans suggesting that the VMPFC may modulate affective attribute representations in other areas ( ;  ). These results could also suggest that VMPFC represents an earlier stage in the value construction process, with DLPFC representations emerging more closely to response. Future work including the use of measures with higher temporal precision may help to elucidate when and how interactions between the VMPFC and DLPFC determine regulatory success in different contexts. 


### Explaining individual differences in regulatory success and failure 
  
Our study is the first to document goal-consistent changes for   all   choice-relevant attributes, across diverse choice domains, both within and across individuals, shedding light on when and why regulatory efforts may succeed or fail. Our findings point to important divisions in regulatory success as a function of choice attributes and domain: an individual who struggles both to resist cheesecake and ignore their own self-interest may nevertheless have little difficulty in harnessing regulation to represent others’ needs and use this as input into social choices. This has important implications in treatment for decision making disorders: if therapeutic interventions fail when focused on one attribute (e.g., be less selfish), a switch to strategies focused on other attributes (e.g., think more about others) might be more effective. Future work will need to explore the full range of domains and attributes in which regulation could play an important role (e.g., risk, intertemporal choice, etc.) in order to determine the extent to which regulatory effects vary or converge across attributes and domains. 

It is also worth noting that goal-consistent changes in attribute representations were generally exceptions rather than the rule.   Most   regions permitting attribute decoding showed   no   discernable change in representation of attributes as a function of goal. This may explain why regulatory success often feels so difficult: unregulated attribute representations in some areas (including the VMPFC) may continue to leak into choices, complicating regulatory success. It also argues against a trivial interpretation of our results that the changes we observed are simply uninteresting reflections of behavior: we observed highly specific and localized success-related changes in regions like DLPFC, TPJ, and precuneus, but not in other areas. This suggests that these regions may perform a special role in mediating the impact of regulatory goals on behavior. 


### Limitations and future directions 
  
We cannot completely rule out that regulatory affects on behavior and attribute representations might partly reflect differences in motivation to satisfy expectations of the experimenter. However, we note that the specific patterns of convergence and divergence in regulatory success argue against this interpretation of our results: we suspect that if this were the case, we would not have observed either the distinct profile of within-subject correlations in regulatory success for different attributes, or differences in their neural correlates. Nevertheless, further research will be needed to fully resolve the extent to which individual differences in regulatory success result from limits in motivation or limits on capacity. Work examining whether gray matter volume in either the DLPFC and VMPFC predicts regulatory success across individuals might help to resolve such issues ( ). Tying laboratory measures of regulation to real-world consequences also remains a necessary future step in understanding the significance of these findings. 

Our results also point to a number of other open questions and future directions. The implementation of a strictly data driven approach confirmed that several   a priori   hypothesized regions of interest such as the VMPFC or the DLPFC are crucial for implementing cognitive control of goal-directed choice. However, we cannot rule out that other brain regions not identified by the current analyses (e.g. the ventral striatum) also contribute to decision making during regulation. Indeed, we observed changes in attribute decoding in restricted, non-overlapping areas of visual and motor cortex for some but not all attributes, which might reflect non-causal changes in visual attention or motor preparation, but could also be important precursors to downstream changes in areas like the DLPFC, TPJ and precuneus. 

The close correspondence between neural patterns and model-estimated changes in behavioral weighting suggests that our information-based neural measure captured a critical aspect of changes in neural computations during goal-dependent behavior. However, further investigation is necessary to understand what separates attributes whose representations converged in DLPFC from those that did not. One exciting avenue for future research will be to identify the precise factors that determine whether and when the DLPFC acts as the site for cognitive regulation of value. Understanding this distinction may help to predict when an individual will show more global deficits in regulatory success and when those deficits will tend to stand apart from success or failure in other domains or contexts. 



## Materials and methods 
  
### Participants 
  
Fifty-five healthy volunteers (25 female, M ± SD: 28 years ± 5.02) participated in the altruism task. A subset (N = 37, 17 female, 29 years ± 5.24) also completed the food task. Sample size for both established fMRI tasks were selected based on previous successful implementations of the food task ( ) and the altruism task ( ). All subjects had normal or corrected-to-normal vision and were free of psychiatric or neurological history. Subjects received $20/hour for their participation, plus the money from a trial selected randomly at the end of the altruism task. They also received a randomly selected food item at the end of the food experiment that had to be consumed in the lab. The altruism data of five subjects and the food data of one subject were excluded from further analyses due to excessive movement (>3 mm/3degree). The altruism data of another subject was excluded from the analysis due to invariant choice behavior. All subjects gave written informed consent and Caltech’s Internal Review Board approved the study. 


### Tasks 
  
Subjects performed two separate fMRI tasks as part of a large-scale cross-sectional research project. Task order was fixed, with the food task completed on average 16 months (SD: ±8.66; range: 1–24) after the altruism task to specifically probe for common and distinct computations in non-social and social goal-dependent choices. 

#### Food task 
  
 The non-social fMRI task was a modified version of an established food task ( ). On every trial, subjects chose between one of 90 food items presented on-screen (4 s) and a default food chosen prior to scanning ( ). Subjects responded by pressing one of four buttons corresponding to ‘strong yes’, ‘yes’, ‘no’, ‘strong no’ (displayed at the bottom of the screen), using a button box placed in their right hand. The assignment of choice preferences to buttons was fixed throughout the task and the right-left orientation of the scale was counterbalanced across subjects. Inter-trial intervals varied from 1 to 4 s (average of 2 s), during which a white fixation cross was presented against a black background. After scanning, one trial was randomly drawn to determine what the subject would eat before leaving the lab. If subjects failed to respond within the 4 s of the selected trial either the on-screen or the default option was randomly chosen. 

Subjects made food choices under three conditions:   Respond Naturally   (‘respond as you naturally would’, [NC]),   Focus on Health   (‘focus on the healthiness of the food when making the choice’, [HC]), or   Focus on Taste   (‘focus on the tastiness of the food when making the choice’, [TC]) (see Appendix 1 – Instructions for regulatory conditions in both choice tasks for instructions). Importantly, subjects were explicitly instructed to always make the decision based on their preference, regardless of the condition. Every condition comprised nine blocks (with 10 trials per block), resulting in a total of 90 trials per condition. Prior to every block, detailed instructions appeared for 4 s. In addition, during food display, a short description (‘Respond Naturally’, ‘Focus on Health’, ‘Focus on Taste’) appeared at the top of the screen to remind participants of the current instruction. Each of the nine functional scanning runs contained one block of every condition (i.e., three task blocks per run), with the order of conditions randomized across runs and subjects. The only exception was the first task block, which was pre-assigned to ‘natural’ for every subject. Practice trials as well as a short quiz prior to scanning ensured that subjects understood the instructions for each condition and were comfortable with the timing of the task. 

Food items varied in their perceived tastiness and healthiness and included healthy snacks (e.g., apples, broccoli) and junk foods (e.g., candy bars, chips). Items were selected based on subjects ratings in a self-paced computerized task prior to scanning that assessed perceived tastiness (5-point Likert scale, ‘very untasty’ to ‘very tasty’) and healthiness (5-point Likert scale, ‘very unhealthy’ to ‘very healthy’) of 200 food items ( ;  ). Ninety food items were selected from this larger set to cover the range of health and taste ratings in a roughly uniform manner. In addition, for each subject we chose one default food that was perceived as neutral for taste and health. Each food item was presented once in each of three choice conditions, with presentation order randomized across blocks, functional runs, and subjects. To ensure the motivational saliency of the food items, subjects were asked to refrain from eating 4 hr prior to testing. Stimulus presentation was implemented using high-resolution color pictures (72 dpi) and Psychophysics Toolbox Version 3 ( ) together with Matlab (2014a). 


#### Altruism task 
  
The altruism task was an fMRI compatible version of the dictator game modified from ( ). On every trial, subjects were presented with a monetary proposal that affected their own ($Self) and another persons’ ($Other) monetary payoff ( ). Subjects had 4 s to chose between the on-screen proposal and a constant default allocation ($20 to both) by pressing one of the four response buttons (‘strong yes’, ‘yes’, ‘no’, ‘strong no’; direction counter-balanced across subjects). Payouts for self and other ranged from $0 to $40 and always involved a tradeoff between self and other (i.e. prizes for one individual were equal or less than the default, while prizes for the other individual exceeded the default). Thus, subjects always had to choose between acting altruistically (benefitting the other at a cost to oneself) or selfishly (benefitting oneself at a cost to the other) on every trial. At the end of the experiment, one trial was randomly selected and implemented according to the subjects’ choice. If subjects failed to respond within 4 s for this trial, both individuals received $0. 

Similar to the food task, subjects performed the task under three different conditions:   Respond Naturally   (‘respond as you naturally would’, [NC]),   Focus on Ethics   (‘focus on doing the right thing and consider the ethical or moral implications of your choice’, [EC]), or   Focus on Partner   (‘focus on your partner’s feelings and how the other person is affected by your choice’, [PC]). Subjects were reminded to always make their choice based on their preference, regardless of the condition. Conditions were implemented in separate blocks of 10 trials each, with the beginning of a new block signaled by a short reminder instruction (4 s). Matching the food task, subjects performed 9 blocks of each condition (i.e., 90 trials per condition and a total of 270 trials), with the block order counter-balanced across subjects and functional runs, with the exception that the first two blocks were always natural choice trials. Choices in these NC blocks were used to estimate a logistic regression [Choice = w  * $Self + w  * $Other] and used for a subject-specific selection of 30% of proposals most likely to elicit generous behavior and 30% of proposals likely to elicit selfish behavior. The remaining 40% of trials were randomly chosen from the full proposal space. Practice trials and a quiz prior to scanning verified that subjects were capable and comfortable to make the choice within 4 s. 


#### Probabilistic choices 
  
To decrease experimental demand and to ensure anonymity in the altruism task, subjects were informed that implementation of their choices was probabilistic and that in 40% of trials their choices would be reversed ( ). Subjects were informed that their partner would only know the proposal and the outcome of the randomly chosen trial, but not their decision (i.e., if the outcome was due to the subjects’ choice or a choice reversal). The implementation was as follows: After each choice (jittered delay of 2–4 s), an outcome screen (4 s) informed subjects of the implementation of choices (implemented/choice reversal), followed by a jittered inter-trial interval of 1–4 s (average of 2 s) before the next choice screen appeared. Computerized control questions during training confirmed that subjects understood the probabilistic nature of the task and that it was still in their best interest to choose according to their individual preferences. In the food task, we matched the probabilistic implantation in the altruism task, and informed participants prior to scanning that their choices would be implemented with 60% probability. 

Data from an independent behavioral pilot study (N = 17, 11 female, M ± SD: 24.12 years ± 5.83) confirmed that choices under almost perfect implementation (90%) closely matched those observed under 60% implementation conditions (within-subject design, all p’s > 0.37, uncorrected, for paired t-tests of RTs, percentage of generous and healthy choices). These findings strongly suggest that the probabilistic nature of the task did not systematically alter preference-based choices in both tasks. 



### Behavioral computational model (DDM) 
  
We used a multi-attribute extension of the standard drift diffusion model (DDM) ( ;  ) to capture behavior in both the food and altruism task, using a maximum-likelihood procedure similar to that described in ( ) to find the best-fitting parameters (see Appendix 1 – Drift diffusion model for details). For capturing behavior in the food task, we fit a model using five parameters: two parameters for the weights on tastiness and healthiness, a parameter for non-decision time (NDT) representing perceptual and motor processes, and two parameters specifying the initial height of the choice-determining threshold (b) as well as the exponential decay rate of this threshold toward zero (d) as the time limit for responding approached. For capturing behavior in the altruism task, we fit a model using six parameters: three parameters related to the weights on $Self, $Other, and fairness (−1*|$Self - $Other|), as well as parameters related to NDT, b, and d (see   for details). 


### Functional image acquisition 
  
Functional imaging was performed on a 3T MRI scanner (Magnetom Trio, Tim System, Siemens Medical Systems, Erlangen) equipped with a 32-channel head coil. T2*-weighted functional images were obtained using an echoplanar imaging (EPI) sequence (TR = 2.5 s, TE = 30 ms, flip angle = 85°, 3 × 3 × 3 mm, matrix size 64 × 64, 47 axial slices, descending sequential acquisition order). For the altruism task, a maximum of 1521 volumes were acquired. For the food task we acquired 990 volumes. High-resolution T1-weighted structural images were acquired at the end of each scanning session using an MPRAGE sequence (TR = 1.5 s, TE = 2.91 ms, flip angle = 10°, TI = 800 ms, 1 × 1 × 1 mm, matrix size 256 × 256, 176 slices). 


### fMRI data analysis 
  
Functional images were analyzed using the statistical parametric mapping software SPM12 (  http://www.fil.ion.ucl.ac.uk/spm  ) implemented in Matlab. Preprocessing consisted of slice-time correction (reference slice 47), spatial realignment (by first registering each subjects’ data to the first image of each run, then all functional runs were co-registered with each other), and normalization to the Montreal Neurological Institute (MNI) brain template (EPI template). For every subject, we estimated several general linear models (GLMs), using a canonical hemodynamic response function (hrf), and a 128 s high-pass cutoff filter to eliminate low-frequency drifts in the data. 

#### Trial-wise estimates of choice phases: GLM1 (food task) and GLM2 (altruism task) 
  
These GLMs aimed to identify brain responses that encode trial-by-trial variations in attributes (i.e., foods’ healthiness or tastiness in the food task; payoffs for subjects and confederate and the fairness of the offer in the altruism task) and decision-values (four-point response from ‘strong no’ to ‘strong yes’) during choice periods. To this end, these models obtained a trial-wise measure of BOLD responses during food (GLM1) and altruistic choices (GLM2) at the time of the choice. For each subject, GLM1 included a regressor for each choice period (R1-R270) in the food task, lasting from the onset of a food presentation to the button press that represented the choice for the trial. In addition, the model estimated a separate regressor for the outcome phases for each functional run, movement parameters, and run-wise session constants as regressors of no interest. GLM2 mirrored GLM1 and estimated regressors of interest for every altruistic choice (R1-R270), lasting from the onset of the monetary proposal to the button press that signified the choice in this trial. GLM2 also estimated regressors of no interest including outcome phases, movement parameters, and session constants. Estimated responses for the regressors of interest – the choice periods of each task (R1-R270 from GLM1 and 2, respectively) – were then used as inputs for the multivariate decoding analyses (support vector regressions, SVRs) described below. 


#### Neural computational model: within-subject decoding of choice attributes 
  
This multivariate pattern analysis (MVPA) aimed to identify brain regions that encode trial-by-trial fluctuations of choice-relevant attributes (e.g. foods healthiness, payoff to self) or decision values (four-point response from ‘strong no’ to ‘strong yes’), and to assess how current goals affect neural information on the attribute level. Thus, these decoding analyses allowed us to explicitly test if regulation-based changes in   neural   information on choice-relevant variables (e.g., healthiness of foods) matched predictions from the   behavioral   computational model. 

For each choice attribute and each condition, we applied a separate support vector regression (SVR) analysis in combination with a whole-brain ‘searchlight’ approach ( ). The key advantage of the searchlight decoding approach is that it does not depend on a priori assumptions about informative brain regions and ensures unbiased information mapping throughout the whole brain ( ;  ). For every subject, we defined a sphere with a radius of 4 voxels around a given voxel v  of the measured brain volume ( ;  ;  ;  ) For each of the N voxels within this sphere, we extracted trial-wise parameter estimates of a particular condition (i.e., 90 of the 270 trial-wise regressors of choice periods from GLM1 (food task) or GLM2 (altruism task)). N-dimensional pattern vectors were created separately for each of the 90 trials of the respective fMRI task. Neural pattern vectors for 8 of the 9 task blocks (‘training data’) served as input features, with trial-wise values of the attribute (e.g., healthiness rating) as labels of the prediction. The prediction was realized using a linear kernel support vector machine regression (  http://www.csie.ntu.edu.tw/~cjlin/libsvm  ) (ν-SVR) with a fixed cost parameter c = 0.01 that was preselected based on previous implementations of this decoding approach ( ;  ;  ;  ). The resulting model provided the basis for the prediction of the trial-wise values of an attribute (e.g. healthiness ratings) of the 10 trials of the remaining task block (‘test data’) based on their neural response patterns. This procedure was repeated nine times, always using pattern vectors of a different task block as test data, yielding a 9-fold cross-validation. Predictive information about the choice attribute was defined as the average Fisher’s z-transformed correlation coefficient between the value predicted by the SVR model and the actual values of an attribute in these trials ( ;  ;  ;  ). This decoding accuracy value was assigned to the central voxel of the searchlight. The procedure was repeated for every voxel of the measured brain volume, yielding a three-dimensional decoding accuracy map for every subject, separately for each choice attribute and each condition. Decoding maps were smoothed (6 mm full width at half maximum, FWHM) and submitted to two different random-effects group analyses. 

First, to establish that neural response patterns encode the current value of a choice-relevant attribute during choices, we averaged subjects’ decoding accuracy maps for a particular attribute obtained in the three conditions (e.g., separate SVRs for healthiness in NC, HC, and TC). Subject-specific average information maps were than used in a random effect second level analysis (single t-test as implemented in SPM) and tested against chance level at a statistical threshold of p < 0.05 (FWE cluster-corrected, height threshold of p < 0.001). Note that if resulting cluster sizes at this statistical threshold prevented effective functional localization (i.e., clusters that exceeded 6000 voxels), we report results at p < 0.05, FWE corrected at voxel-level. Second, to examine if predictive neural information on a choice attribute varied systematically across the three conditions of the respective task, we used a repeated measures ANOVA as implemented in SPM. Only regions that passed the statistical threshold of p < 0.05 (FWE corrected at cluster-level, height threshold of p < 0.001) are reported. 

We also compared the results of the multivariate SVRs with those of a conventional univariate analysis (see  , and Appendix 1 – Univariate Analysis of fMRI Data). However, note that multivariate decoding approaches have been prosed to be more sensitive than traditional mass-univariate approaches: because multivariate pattern classifiers take advantage of information encoded across multiple voxels and exploit systematic differences in voxel selectivity within a specific brain region, they have been suggested to detect information that would be missed by conventional analyses ( ). 

There is a potential concern that the some intervals of the response scales for choice attributes (e.g. tastiness) or decision values (‘strong no’, ‘no’, ‘yes’, ‘strong yes’) might be subjectively larger than other intervals. While the present data don’t allow ruling out this potential concern, previous implementations of the response scales in both established tasks suggest that the operationalization of attribute-specific judgments and decision values allows to reliably identify value signals in the brain ( ;  ;  ;  ). 


#### Neural computational model: cross-subject decoding of individual differences in regulatory success 
  
This multivariate decoding analysis investigated whether neural activation patterns predict individual differences in regulatory success. A cross-subject decoding approach was used to test for information on the   degree   to which cognitive regulation affected attribute weights and choices. Clusters identified in the repeated measures ANOVA (see above) were defined as regions of interest (ROIs). Importantly, a main goal of our study was to test for potential common neural substrates underlying context-sensitive weighting of choice-attributes across choice-domains. Hence, these decoding analyses focused on voxels identified in a formal conjunction of the significant clusters for flexible representations of Healthiness, Tastiness, and $Self (at p < 0.05, FWE corrected at cluster-level, height threshold of p < 0.001; see  ). First, we tested if neural activation in this ROI obtained during food choices encodes subject-specific regulation success in the food task, but also in an independent social altruism task. To this end, we extracted parameter estimates for all voxels in the ROI ( ) from subjects first-level GLM1 (food choices) using the contrast image [HC > (NC, TC)] (based on DDM results suggesting differential attribute representations for this comparison,  ). Resulting pattern vectors (one per subject) were used as input features for the prediction and individual difference scores in regulation success served as labels. Regulation success was defined using difference scores in DDM parameters (e.g., Δw Tastiness [HC – (NC, TC)]) and in observed choice behavior (e.g., ΔHealthy choices [HC – (NC, TC)]). Predictions used a linear ν-SVR (libSVM) with a fixed cost parameter c = 0.01 (similar to within-subject decoding) and a leave-one-subject out approach (yielding a 36-fold cross-validation). Decoding accuracies reflect correlations of the observed and predicted regulation score. Statistical significance was assessed by comparisons to empirical null-distribution (realized by randomly permuting the pairing of subjects’ neural pattern vectors and behavioral regulation scores 1000 times). Only decoding accuracies above the 95th percentile of null-distributions were considered statistically significant ( ). As a sanity check, analyses were repeated training on data obtained during altruistic choices (see  ). 

Note that   ROI-based cross-subject   decoding analyses used permutation tests to assess the statistical significance of the predictions instead of simple t-tests (as implemented in SPM) applied to the   whole-brain within-subject   searchlight decoding maps. Regarding the latter, computational costs for estimating empirical null-distributions for several tens of thousands of searchlight analyses - implemented separately for every attribute, decision-value, condition, and subject - prevented us from using permutation tests for whole-brain decoding analyses. However, supplemental analyses that used t-tests to statistically assess ROI-based results yielded similar results as permutation tests, demonstrating that both statistical approaches generate comparable interpretations for the present data. Notably, empirical permutation-based null-distributions for ROIs also confirmed the theoretical chance level of the prediction that underlies statistical inferences for the whole-brain searchlight results (t-tests as implemented in SPM). Nevertheless, statistical tests based on empirical null-distributions can be viewed as superior insofar as they address the potential concern that means and distribution of predictions based on chance alone might vary across brain regions. 

Note also that the ROI ( ) used for this analysis was defined based on a fully independent and orthogonal set of tests for altered decoding accuracies across task conditions at the group level. Thus, ROI-selection was not subject to double dipping ( ). 



 ## Data availability

Functional imaging and behavioral data is deposited at the project's Open Science Framework (OSF) page (osf.io/wa4cs). The project page also makes available the derived statistical maps (univariate and multivariate decoding analyses), regions of interest (ROIs) used in analyses of functional imaging data, processed behavioural data, and details on the experimental procedure. </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-36'>
<h2>36. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/21709175/' target='_blank'>21709175</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Direction-Sensitive Codes for Observed Head Turns in Human Superior Temporal Sulcus</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Cereb Cortex</p>
<p><strong>Publication Year:</strong> 2011</p>
<p><strong>DOI:</strong> 10.1093/cercor/bhr061</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3306570/' target='_blank'>3306570</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study in healthy adult volunteers (final sample ages 22–38) using dynamic head-turn stimuli that are explicitly social cues (perceived gaze/attention). Participants completed a task during functional MRI acquisition. The paper reports both ROI-based analyses and whole-brain exploratory analyses (full gray-matter–masked volume) with familywise error correction, so results are not limited to ROI-only reporting. It is an original empirical fMRI study (not a review) and does not involve clinical or disordered participants. All inclusion criteria (fMRI during social-related task; healthy adults 18–60; whole-brain results) are met and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Humans and other primates are adept at using the direction of another's gaze or head turn to infer where that individual is attending. Research in macaque neurophysiology suggests that anterior superior temporal sulcus (STS) contains a direction-sensitive code for such social attention cues. By contrast, most human functional Magnetic resonance imaging (fMRI) studies report that posterior STS is responsive to social attention cues. It is unclear whether this functional discrepancy is caused by a species difference or by experimental design differences. Furthermore, social attention cues are dynamic in naturalistic social interaction, but most studies to date have been restricted to static displays. In order to address these issues, we used multivariate pattern analysis of fMRI data to test whether response patterns in human right STS distinguish between leftward and rightward dynamic head turns. Such head turn discrimination was observed in right anterior STS/superior temporal gyrus (STG). Response patterns in this region were also significantly more discriminable for head turn direction than for rotation direction in physically matched ellipsoid control stimuli. Our findings suggest a role for right anterior STS/STG in coding the direction of motion in dynamic social attention cues. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (44493 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Humans and other primates share a remarkable ability to accurately perceive where other individuals are attending and use this information to change their own attentional state ( ). Many higher order social cognitive processes depend on such gaze following behaviors ( ;  ). Although changes to gaze direction and head view are inherently dynamic, to date the majority of human neuroimaging research has used static facial stimuli to study the neural representation of such social cues ( ). In view of macaque neurophysiology evidence that neurons responsive to dynamic head turns do not respond to static views of the same head ( ), it is vital to explore the neural coding of dynamic social stimuli. Here, we demonstrate that a region in human superior temporal sulcus (STS)/superior temporal gyrus (STG) contains a distributed representation of perceived head turn direction, thus supplying a necessary perceptual component to support a range of social behaviors. 

Neurons in macaque anterior STS play a well-established role in representing the perceived direction of others' social attention cues, as conveyed by head orientation, gaze direction, and body posture ( ,  ;  ;  ). However, these constitute only a minority of visually responsive STS neurons and are either spatially distributed ( ) or are organized into fine-grained patches well beyond the resolution of conventional functional MRI (fMRI;  ). This distributed representation poses a significant signal-to-noise challenge for attempts to study similar effects with human fMRI, where each voxel likely samples millions of neurons in ways that are only indirectly related to the neuronal spike trains commonly measured in macaque neurophysiology ( ;  ). 

Unlike the typical anterior STS region identified by research in the macaque, most human fMRI studies report that social attention cues activate posterior STS and regions of adjacent STG and middle temporal gyrus (MTG;  ;  ). Similar posterior temporal regions are also more responsive to faces than to control stimuli ( ;  ). Most of these studies find that posterior STS is more responsive to averted than to direct gaze ( ), but the opposite pattern has also been observed (e.g.,  ;  ). Furthermore, posterior STS responds more when an actor gazes away from a target than when the gaze direction is congruent with the target location ( ), suggesting that posterior STS is influenced by contextual effects, rather than by the direction of the social attention cue as such. Even in the absence of overt contextual manipulations, comparisons between direct and averted gaze may indirectly manipulate the engagement of approach/avoidance mechanisms and other higher order social cognitive functions associated with direct and averted gaze, such as theory of mind responses to eye contact ( ;  ;  ). Thus, the litmus test for direction sensitivity is whether brain responses to different averted social attention cues can be distinguished in the absence of other contextual manipulations. 

When such tests for direction sensitivity between different averted cues were carried out, one study found direction-sensitive fMRI adaptation to static images of gaze cues in right anterior, rather than posterior, STS ( ). Another study that applied multivariate pattern analysis (MVPA) to a posterior STS region of interest (ROI) observed no distinction between different averted views of static heads ( ) but did find that this ROI distinguished direct from averted head views across different head identities, suggesting an identity-invariant representation. These head view effects are consistent with the pattern of univariate sensitivity for direct against averted gaze observed in previous univariate research ( ). Considered collectively, this literature suggests a broad role for posterior STS in representing social attention cues, but unlike the evidence from macaque anterior STS, there is little indication that posterior STS represents such cues in a direction-sensitive manner. 

Outside the laboratory, cues to another's focus of attention are intrinsically dynamic in nature, but this issue has received limited attention in controlled experiments. There is initial evidence that a small subset of neurons in macaque anterior STS are tuned to dynamic changes in head turn direction ( ;  ), but it remains unclear how the human brain codes such stimuli. In humans, posterior STS responds more to dynamic head turns than to both scrambled controls and static head views. However, neither anterior nor posterior STS has been found to show direction-sensitive coding of head turn direction, as measured by standard univariate fMRI ( ). This absence of direction sensitivity is unsurprising, since neurons with such responses are unlikely to be clustered at a sufficiently large spatial scale to be detectable with univariate fMRI ( ;  ). 

MVPA has recently been applied to detect representations thought to be coded in fine-grained patterns beyond the resolution of standard fMRI ( ;  ;  ). In the current study, we apply this method to determine whether distributed response patterns in the human STS region contain distinct direction-sensitive codes for observed head turns. If a classifier can use response patterns from the STS region to distinguish between leftward and rightward head turns, this would suggest that the underlying response patterns code head turn direction. However, leftward and rightward motion can also produce classification effects in regions without selectivity for social attention cues ( ). In order to avoid such confounding contributions of low-level motion, we included a set of rotating ellipsoid control videos. Previous work investigating head turn responses in macaque neurophysiology ( ;  ) or direction-specific responses to static gaze ( ) did not include such nonsocial controls, so an important aim of the current study was to establish that any direction-sensitive effects are specific to the social stimuli. Furthermore, we aimed to localize pattern effects to specific regions through the use of a searchlight algorithm that operated within the anatomically defined STS region. The STS region in this study included STG and MTG, in line with previous findings that social perception and gaze stimuli produce peaks that sometimes fall outside the STS proper ( ;  ). 


## Materials and Methods 
  
### Participants 
  
Twenty-one right-handed healthy volunteers with normal or corrected to normal vision participated in the study (12 males, mean age 29 years, age range 22–38). Volunteers provided informed consent as part of a protocol approved by the Cambridge Psychology Research Ethics Committee. Four volunteers were removed from further analysis: Two due to poor performance at the behavioral task whilst in the scanner (accuracy of less than 50%) and 2 due to fatigue and excessive head movements. 


### Experimental Design 
  
Volunteers viewed 1000-ms video clips of 45° leftward and rightward head turns and comparable ellipsoid rotations ( ; e.g., videos, see   Supplementary Material  ). Volunteers were instructed to monitor the stimulus set for infrequent deviant response trials (1 of the 8 experimental videos, rotated 4° from the upright position) and responded to detected deviants with a button press. The deviant response trials were drawn from all experimental conditions, and the degree of rotation was chosen after behavioral pilot tests to produce an attentionally demanding task without ceiling effects. 
  
Example video frames for turning heads (  A  –  B  ) and rotating ellipsoids (  C  –  D  ). The stimuli were full color but are presented in grayscale for printing purposes (for full color stimuli, see   Supplementary Videos  ). The videos were presented at 24 frames per second. All video frames are from leftward motion conditions. Rightward conditions were created through mirror reversal of the same video clips. The 2 ellipsoid identities (  C  –  D  ) were created by Fourier-scrambling face textures from the first frame of the 2 head videos (  A  –  B  ). 
  
Two actors with matched head motion patterns were selected for the head turn videos. The ellipsoid control stimuli were rendered and animated in Matlab (Mathworks) and were texture mapped with the Fourier-scrambled face textures from the 2 head identities. The 2 motion directions were created by mirror reversing video clips with a single direction, thus ensuring that the stimulus set was physically matched across motion directions. This produced a total of 8 stimuli (2 heads, 2 ellipsoids, each rotating leftward or rightward), which were treated as individual conditions. 

The stimuli were back-projected onto a screen in the scanner, which volunteers viewed via a tilted mirror. The stimuli were presented on a black background within a circular aperture (7° visual angle in diameter). The experiment was controlled using Matlab and the Psychophysics toolbox ( ). 

The experiment was divided into sets of 240 trials, each of which was independently randomized. Parameter estimates from each set formed an independent set of training examples for classification. The trials were presented within a rapid event-related design. Four volunteers completed a 6-set version of the experiment (approximately 40 min effective time) and 13 completed a 12-set version (80 min). Each set contained 240 trials: 80 null trials, where a fixation cross remained on the screen throughout the trial (1500 ms) and 160 experimental trials (80 heads, 80 ellipsoids), where each trial consisted of a video clip (1000 ms) followed by fixation (500 ms). Each condition was repeated 18 times in a set. Sixteen deviant response trials were randomly sampled from the experimental conditions and responses to these trials were modeled with a separate nuisance regressor of no interest. The trials within the set were presented in a pseudorandomized order, where repeats of the same trial were slightly clustered in order to increase design efficiency ( ). Every second set was followed by a 15-s rest period, which was cued by a text prompt on the screen. The scan acquisition continued during the rest periods, and volunteers were instructed to remain still. 


### Imaging Acquisition 
  
Scanning was carried out at the MRC Cognition and Brain Sciences Unit, Cambridge, United Kingdom, using a 3-T TIM Trio Magnetic Resonance Imaging scanner (Siemens), with a head coil gradient set. Functional data were collected using high-resolution echo planar   T  -weighted imaging (EPI, 40 oblique axial slices, time repetition [TR] 2490 ms, time echo [TE] 30 ms, in-plane resolution 2 × 2 mm, slice thickness 2 mm plus a 25% slice gap, 192 × 192 mm field of view). The acquisition window was tilted up approximately 30° from the horizontal plane to provide complete coverage of the occipital and temporal lobes. Preliminary pilot tests suggested that the use of this high-resolution EPI sequence resulted in reduced signal dropout in the anterior STS region, relative to a standard resolution sequence (3 × 3 × 3.75 mm voxels). All volumes were collected in a single continuous run for each volunteer. The initial 6 volumes from each run were discarded to allow for   T   equilibration effects.   T  -weighted structural images were also acquired (magnetization prepared rapid gradient echo, 1 mm isotropic voxels). 


### Imaging Analysis 
  
Imaging data were processed using statistical parametric mapping 5 (SPM5;   www.fil.ion.ucl.ac.uk/spm  ). All functional volumes were realigned to the first nondiscarded volume, slice time corrected, and coregistered to the   T   structural volume. The processing pathways for univariate analysis and MVPA diverged after these common steps ( ). 
  
Processing pathways for fMRI analysis. All processing nodes take the result of the previous node in the hierarchy as input. With the exception of the searchlight classification analysis, all processing steps were implemented using standard SPM5 functionality. 
  
Univariate analysis was carried out using standard processing steps in SPM5. Structural volumes were segmented into gray and white matter partitions and spatially normalized to the Montreal Neurological Institute (MNI) template using combined segmentation and normalization routines. Functional volumes were normalized according to the parameters of this transformation, smoothed (10-mm full width at half mean Gaussian kernel, FWHM), and high pass filtered to remove low frequency drift (128-s cutoff period). 

Subject-specific generalized linear models were used to analyze the data. The models included one regressor per condition and nuisance regressors for deviant response trials, volunteer responses to nondeviant trials, and for nulling scans that contained excessive noise or movement ( ;  ; greater than 10 units intensity difference from the mean scaled image variance or more than 0.3 mm translational or 0.035 radians rotational movement relative to the previous volume). The volunteer-specific models included 0–135 such scan nulling regressors (mean 35). The experimental predictors were convolved with a canonical hemodynamic response function, and contrast images were generated based on the fitted responses. These contrast images were then entered into second-level permutation-based random effects models using statistical nonparametric mapping (SnPM;  ; 10 000 permutations, 10-mm FWHM variance smoothing). 

Multivariate pattern analyses were carried out using functional volumes that had been realigned and slice timing corrected but had not been spatially normalized to the MNI template ( ). Each volunteer's data were modeled using a generalized linear model with similar regressors as in the univariate analysis, with the exception that each set of trials was modeled using a separate set of regressors. Individual parameter volumes from the first half of the data set was then averaged pairwise with the corresponding volume from the second half of the data set, thus reducing session effects at the expense of halving the number of training examples. This produced 3 or 6 final sets of examples to be used for classification, depending on the number of available sets before averaging. The example volumes were   z  -scored so that each voxel within a set had a mean of 0 and a standard deviation of 1 across examples in that set. Finally, each example was gray matter masked using the tissue probability maps generated by the segmentation processing stage. 

The resulting example volumes were used as input to a linear support vector machine classifier (as implemented in PyMVPA;  ). All MVPA used a searchlight algorithm ( ), in which classification is carried out within a spherical region (5 mm radius) that is moved through the volume. Leave-one-out cross-validated classification accuracy estimates (percent correct) were mapped back to the center of each searchlight, thus producing a classification accuracy map. 

The classification accuracy maps for each volunteer were normalized to MNI space, smoothed (10-mm FWHM), and entered into second-level nonparametric random effects models in SnPM. We used nonparametric tests because the discontinuous nature of the gray matter–masked data means that conventional familywise error (FWE) correction for multiple comparisons using random field theory in SPM5 would be inappropriate. We also wished to avoid making distributional assumptions about the first-level classification accuracy maps. 

In line with the hypothesized site of our effects, we restricted our primary analysis to the right STS region, which was defined anatomically by the first author based on the mean   T   volume for the sample. In line with previous evidence that social perception and eye gaze effects in the STS region extend into STG and MTG ( ;  ), the mask included these gyri, whilst leaving out voxels in inferior temporal sulcus (inferior) or lateral fissure (superior) (  Supplementary Fig. 1  ). We report   P   values corrected for multiple comparisons (FWE,   P   < 0.05) within this ROI (5162 voxels,   y   −58 to 22 mm MNI). We also carried out an exploratory analysis in a mirror-reversed version of the STS mask to test for effects in left STS. The use of a mirror-reversed mask sacrifices some anatomical precision in left STS but preserves the same voxel count and spatial structure in both masks. Visual inspection of the relation between the left STS mask and the mean   T   volume suggested that the mask followed the anatomy of the sulcus in a comparable manner to the right STS mask. Finally, effects that survived correction for the full volume are also reported (FWE,   P   < 0.05). All analyses were restricted to a group gray matter mask, which was formed by the union of each volunteer's normalized individual gray matter mask. This mask ensured that we only considered effects in regions actually covered by the searchlight analysis. 



## Results 
  
### Behavioral Task 
  
Volunteers were asked to detect the occasional 4° rotation of the video stimuli and were able to detect such deviant response trials adequately (mean accuracy 71%, standard error 4%). A repeated measures analysis of variance (ANOVA) of accuracy scores with the factors of stimulus type (head, ellipsoid) and motion direction (leftward, rightward) yielded no main effects and no interaction (  F   < 2.4,   P   > 0.14 for all effects), suggesting that volunteers did not assign attention differently to the heads and ellipsoids or to the 2 motion directions. 


### Multivariate Pattern Analysis 
  
#### Superior Temporal Sulcus 
  
Our primary hypothesis was that the right anterior STS region distinguishes between leftward and rightward perceived head turns. In line with this prediction, a group analysis of the MVPA searchlight results for the right STS region showed that classification of head turn direction was significantly more accurate than expected by chance in a right anterior STS/STG site (  P   = 0.005 FWE, 50 4 −14 mm MNI,  ; for individual subject results, see   Supplementary Fig. 2  ). By comparison, left–right classification of rotation direction in the ellipsoid control stimuli exceeded chance in middle STS (  P   = 0.037 FWE, 50 −14 −10 mm MNI,  ). 
  
Group results for MVPA, displayed on the mean   T   volume for the sample. Effects are displayed corrected for multiple comparisons within the right STS region (panels   A  –  C  ; hypothesis-driven analysis,   P   < 0.05 FWE) or the full gray matter volume (panels   D  –  F  ; exploratory analysis,   P   < 0.05 FWE). The highlighted portion of each panel shows the extent of the mask. (  A  ) Classification of left–right head turns in the right STS/STG region. (  B  ) Classification of left–right ellipsoid rotations in the right STS region. (  C  ) Right STS regions where left–right classification of head turns was more accurate than classification of ellipsoid rotations. (  D  ) Classification of left–right head turns in the full gray matter volume. (  E  ): Gray matter regions where left–right classification of head turns was more accurate than classification of ellipsoid rotations. (  F  ) Gray matter regions where the weights acquired by training the classifier on left–right head turns for one head identity generalized to left–right head turns in the other head identity. 
  
The peaks of these head turn and ellipsoid rotation effects were approximately 18 mm apart and the activated regions did not overlap, which raises the question of how distinct the 2 effects are. We addressed this by computing the difference between the classification maps for head turn and ellipsoid rotation in each volunteer. These difference maps were entered into a group analysis, which showed that left–right classification was more accurate for head turns than for ellipsoid rotations in right anterior STS/STG (  P   = 0.027 FWE, 52 12 −12 mm MNI,  ). This effect overlapped with the head turn classification effect (8 mm distance between peaks, 40% overlap), suggesting a common origin. No STS region showed significantly more accurate direction classification for ellipsoid rotations than for head turns. 

We tested whether the left–right head turn codes were invariant to head identity by training the classifier on the left–right turns of one head and applying the learned weights to left–right turns of the other head. Left–right classification did not generalize across head identity at any site in right STS. Similarly, there was no significant left–right generalization across ellipsoid identities and no left–right generalization across stimulus type (head and ellipsoid). 

We also carried out an exploratory analysis of effects in the left anatomically defined STS region. No left STS regions showed above-chance classification of observed head turn direction. However, a region in left anterior STS distinguished ellipsoid rotation direction with above-chance accuracy (  P   = 0.01 FWE, −56 −8 −16 mm MNI,   Supplementary Fig. 3  A   ). Direction classification accuracy was significantly higher for ellipsoid rotation than for head turns in a similar region (  P   = 0.041 FWE, −58 −4 −16 mm MNI,   Supplementary Fig. 3  B   ). No other classification effects were significant in this ROI. 


#### Whole-Brain Analysis 
  
Beyond our hypothesis-driven search within the anatomically defined right STS region, we also carried out an exploratory analysis within the full gray matter–masked volume to identify other effects of interest. Classification of left–right head turns exceeded chance in a region including calcarine sulcus and occipital pole (  P   < 0.001 FWE, 16 −96 0 mm MNI,  ). This region is likely to include visual areas V1, V2, and V3, but in the absence of a retinotopic localizer, we use the general term early visual cortex to describe this region. Left–right ellipsoid classification did not produce significant effects in any region. Left–right classification was significantly more accurate for head turns than for ellipsoid rotations in a similar early visual region (  P   < 0.001 FWE, 14 −96 2 mm MNI,  ). A similar region in early visual cortex also allowed left–right classification to generalize across head identities (  P   < 0.001 FWE, 14 −96 2 mm MNI,  ) but not across stimulus types. No regions outside of early visual cortex showed significant effects for any of these comparisons. 



### Univariate Analysis 
  
We used a conventional univariate analysis in SPM5 to address whether the observed classification effects could be attributed to large-scale response level differences between the conditions. To make comparisons between MVPA and univariate results simpler, the univariate analysis also used nonparametric permutation-based random effects analysis of group effects (SnPM, for details, see Materials and Methods). We also explored whether direction classification of head turns colocalized with greater univariate responses to heads than to ellipsoids. 

#### Superior Temporal Sulcus 
  
No regions inside the anatomically defined right STS ROI responded selectively to one head turn direction over the other or to one ellipsoid rotation direction over the other, suggesting that the left–right classification effects in this region did not co-occur with large-scale univariate direction sensitivity. 

Collapsing across motion direction, right posterior STS responded significantly more to heads than to ellipsoids (  P   < 0.002 FWE, 48 −44 16 mm MNI,  ), while a region in middle STG bordering on the edge of the ROI responded more to ellipsoids than to heads (  P   = 0.004 FWE, 60 0 0 mm MNI,  ). Thus, univariate selectivity for heads over ellipsoids occurred in posterior STS, 57 mm from the left–right head turn classification peak in anterior STS/STG. The peaks for univariate selectivity for ellipsoids over heads and for left–right ellipsoid rotation classification were separated by 20 mm. Neither of the univariate effects overlapped with the classification effects. 
  
Group results for the univariate analysis, displayed on the mean   T   volume for the sample. Effects are displayed corrected for multiple comparisons within the right STS region (panels   A  –  B  ; hypothesis-driven analysis,   P   < 0.05 FWE) or the full gray matter volume (panels   C  –  D  ; exploratory analysis,   P   < 0.05 FWE). The highlighted portion of each panel shows the extent of the mask. (  A  ) Greater univariate responses to heads than to ellipsoids in the right STS region. (  B  ) Greater univariate responses to ellipsoids than to heads in the right STS region. (  C  ) Gray matter regions with greater univariate responses to left than to right head turns (warm colors) or with greater univariate responses to right than to left head turns (cool colors). The effects do not overlap at any site. (  D  ) Gray matter regions with greater univariate responses to heads than to ellipsoids. 
  
Within the left STS ROI, a posterior region responded more to heads than to ellipsoids (  P   = 0.004 FWE, −52 −58 14 mm MNI,   Supplementary Fig. 3  C   ) and left middle STS responded more to ellipsoids than to heads (  P   = 0.014, −66 −18 −14 mm MNI,   Supplementary Fig. 3  D   ), mirroring the results obtained in the right STS region. No left STS regions responded preferentially to head turn or ellipsoid rotation in one direction relative to another. No other comparisons reported above were significant in the left STS analysis. 


#### Whole-Brain Analysis 
  
A univariate analysis of the gray matter–masked full volume revealed significant univariate selectivity for left over right head turns that was restricted to left early visual cortex (  P   < 0.001 FWE, −12 −94 0 mm MNI), and conversely, selectivity for right over left head turns restricted to right early visual cortex (  P   < 0.001 FWE, 14 −92 4 mm MNI,  ). These effects almost completely overlapped the left–right head turn classification effect in early visual cortex (100% overlap for left over right, 91% overlap for right over left), suggesting that the classification effects co-occurred with large-scale univariate effects. Note that the laterality of these early visual effects is opposite to what would be expected for a stimulus that moves into the right and left visual hemifields, a point we return to below. No regions showed a preference for one ellipsoid rotation direction over the other in the whole-brain analysis. 

A comparison of univariate responses to heads over ellipsoids and ellipsoids over heads revealed a network of activations (  Supplementary Table 1  ). Of primary interest to the current study, bilateral early visual cortex responded more to heads than to ellipsoids (  P   < 0.001 FWE, 18 −96 −4 mm MNI,  ), and this early visual effect overlapped the left–right head turn classification effect (91% overlap). Thus, the left–right head turn classification effects occurred in a region where we also observed univariate selectivity for head turn direction and preferential responses to heads over ellipsoids. Bilateral regions in posterior MTG also responded more to heads than to ellipsoids (right:   P   = 0.001 FWE, 52 −74 2 mm MNI. Left:   P   = 0.001 FWE, −50 −72 14 mm MNI). These coordinates are close to those previously reported for motion area MT ( ; conversion from Talairach to MNI coordinates with tools from  ). Because we did not include a specific localizer scan to distinguish MT from MST or other motion areas, we refer to this region as MT+. The MT+ regions showed no direction-sensitive responses in the univariate or classification analyses, even at reduced thresholds (  P   < 0.01, uncorrected). 



### Follow-up Experiments 
  
The pattern of univariate effects in early visual cortex suggested to us the presence of eye movements in the experiment. If volunteers tracked the heads as they turned, this would have placed the stimulus primarily in the hemifield ipsilateral to the direction of motion, which could explain the ipsilateral univariate activations in early visual cortex. Eye tracking was not available when the main experiment was undertaken, so we carried out follow-up eye tracking and fMRI experiments with 3 principal aims: First, to test whether the head turns used in the main experiment elicit eye movements; second, to assess whether the eye movement effects could be removed with a revised experimental paradigm; and finally, to test whether the fMRI effects reported in the main text remained in the absence of statistically significant eye movement effects. 


### Follow-up Materials and Methods 
  
Five volunteers from the final sample used in the main experiment returned to participate in additional experiments. Eye movements were monitored using a video-based infrared eye tracker (500 Hz acquisition outside the scanner, 50 Hz acquisition inside the scanner; Sensomotoric Instruments). We analyzed the change in horizontal fixation position at the end relative to the start of each trial using custom code developed in Matlab. 

Imaging data were acquired and analyzed using identical parameters as in the main experiment, with the exception that no averaging of the first and second half of the experiment was carried out, since this would have yielded an unacceptably small number of observations for first-level statistics. Furthermore, each set was scanned in a separate run to allow recalibration of the eye tracker between sets. As in the main fMRI experiment, we used a searchlight analysis. We based single-volunteer inference on binomial tests at each voxel in the ROI. 


### Follow-up Eye Tracking with the Original Design 
  
Five volunteers carried out an abbreviated version of the main experiment outside the scanner (3 sets, 540 trials), while their eye position was monitored. First-level ANOVAs revealed that each volunteer showed a significant stimulus type (head, ellipsoid) by motion direction (leftward, rightward) interaction (  Supplementary Table 2  ). This interaction reflected consistent fixation shifts in the direction of the head turns, with nonsignificant or weaker fixation shifts in the direction of the ellipsoid rotations. 


### Follow-up Eye Tracking with Revised Design 
  
We carried out a second eye tracking experiment with a revised paradigm that included a fixation cross during the presentation of the video clips. Volunteers were also strongly instructed to maintain fixation at all times. We included only the head turn conditions in order to obtain a maximal number of trials for the head left–right comparison whilst minimizing volunteer fatigue. In this second experiment, the head turn left–right eye movement effect was reduced to nonsignificance in 4 of 5 volunteers ( ). 
  
Follow-up eye tracking and fMRI experiments. (  A  –  C  ) Mean horizontal fixation change plotted separately for the 3 volunteers selected for the final analysis in the revised fMRI experiment. Positive values reflect a leftward shift in fixation over the trial, while negative values reflect a rightward shift. The horizontal axis gives fixation performance in the original task, the revised task, and the revised task as measured during the fMRI experiment. The error bars give ±1 standard error of the mean. Comparisons with significant differences between the head turn directions are highlighted by asterisks (  t  -tests,   P   < 0.05). It can be seen that the revised design abolished the eye movement effect in these volunteers. (  D  –  F  ) Left–right head turn classification results for the 3 volunteers in the final sample of the fMRI experiment. The volunteers are shown in the same order as in   A  –  C  . Results are overlaid on each volunteer's   T   volume and are masked to only include effects within the highlighted right STS region (  P   < 0.001, uncorrected). It can be seen that even in the absence of eye movement effects, anterior STS/STG codes head turn direction. (  G  –  I  ) Results as in   D  –  F   but masked to show effects within a 20 mm radius of the peak early visual head turn classification effect from the main study. It can be seen that the effects in early visual cortex also remain when eye movements are controlled. 
  

### Follow-up fMRI Experiment with Revised Design 
  
We tested whether our main classification findings in STS/STG and early visual cortex survived in the absence of eye movements by carrying out a second fMRI experiment with the revised experimental paradigm. We recruited the 4 volunteers who showed no significant eye movement effects in the eye tracking test outside the scanner. Volunteers completed a full 6-set version of the revised experiment (1080 trials, for details, see Material and Methods), while their eye position was monitored. One of the 4 scanned volunteers showed a significant fixation shift in response to the head turns whilst being scanned (  t   = 8.72,   P   = 0.003). This volunteer was removed from further analysis. 

Although the 3 remaining volunteers showed no significant eye movement effects (as observed in separate tests before and during scanning), left–right classification of head turns in the right anterior STS region was greater than chance in 2 volunteers (  P   < 0.05, Bonferroni FWE corrected for the right STS mask) and at reduced thresholds in the third (  P   < 0.001, uncorrected,  ). The final volunteer also showed an effect in posterior STS (  P   < 0.05, FWE). 

All 3 volunteers showed significant left–right head turn classification effects in early visual cortex (  P   < 0.05 Bonferroni FWE corrected for a 20 mm radius sphere centered on the peak head turn classification effect in the main experiment,  ). However, unlike the main experiment, where this effect was joined by univariate response preferences for head turns in a direction ipsilateral to the visual hemifield (  Supplementary Fig. 4  A   ), we now observed preferentially contralateral responses to head turn direction (  P   < 0.001, uncorrected,   Supplementary Fig. 4  B   ). Thus, although the classification effects in early visual cortex were accompanied by univariate effects also in the revised experiment, laterality of these univariate effects was reversed. 



## Discussion 
  
Appropriate social behavior is dependent on accurately inferring where others are attending. In the visual domain, this inferential process is likely to involve direction-sensitive coding of social attention cues, such as head turns. In experiments, these stimuli are often abstracted to static views, which fails to capture their dynamic character in natural social interaction. Here, we demonstrate that response patterns in human right anterior STS/STG distinguish between leftward and rightward dynamic head turns. Furthermore, left–right head turns were significantly more discriminable in this region than left–right ellipsoid control stimuli. A similar analysis of the left STS region revealed no left–right classification of head turn direction at any site in the ROI. 

The peak coordinates for left–right classification of head turn direction in the current study are in close proximity to a previous demonstration of direction-sensitive fMRI adaptation to static gaze ( ; 16 mm distance between peaks). Considered collectively, these results suggest a general role for right anterior STS/STG in supplying higher order social cognitive processes with important information about the direction of another's attentional shifts, whether these are conveyed by static gaze in a front-facing head or dynamic head turns. Consistent with this social role, we also demonstrate that direction sensitivity does not extend to nonsocial control stimulus motion in this region. An important question is whether such direction-sensitive responses to dynamic and static social cues are driven by a single representation of the direction of another's social attention ( ) or whether dynamic information is coded separately, as indicated by the finding that STS neurons tuned to head turn motion do not respond to static head view displays ( ;  ). 

Neurons in macaque anterior STS are tuned to the direction of social attention cues ( ;  ). However, most human fMRI studies have reported gaze or head turn effects in posterior rather than anterior STS regions ( ). Our classification effects appear more consistent with the typical recording site in macaque anterior STS than with previous univariate fMRI effects in human posterior STS. Compared with standard univariate analysis, MVPA and fMRI adaptation techniques confer greater sensitivity ( ). This increased sensitivity makes more rigorous comparisons possible, for instance between left and right averted social attention cues. Accordingly, we also observed greater consistency between human fMRI and single unit evidence from the macaque (see also  ,  ;  ). Known human–macaque discrepancies in the function of posterior STS and surrounding areas suggest that a simple correspondence between human and macaque may not apply to all high-level visual areas ( ), but such a simple correspondence nevertheless offers a useful working model for the representation of social attention cues. 

The pattern of results we observed in posterior and anterior portions of the right STS region also highlights how large-scale univariate response level differences can dissociate from multivariate classification performance ( ;  ;  ). Similar to previous studies ( ), we found that right posterior STS responded more to heads than to ellipsoids, while no such preferential responding was observed in anterior STS/STG. The left–right head turn classification effects showed the opposite pattern, with significant effects in anterior but not posterior regions. There are clear parallels between this pattern of effects and a recent report where face identity classification was possible in an anterior inferotemporal region, which did not respond preferentially to faces over places, while no such face identity effects appeared in the more posterior fusiform face area, even though this region responded more to faces than to places ( ). Face identity and head turn direction are both important dimensions for face processing, yet multivariate sensitivity for manipulations along these dimensions does not appear to colocalize with univariate selectivity for faces over other object categories. Although more systematic studies of these within- and between-category dissociations are needed before their theoretical implications for face perception can be fully considered, the current results indicate that studies where data analysis is restricted to functional ROIs defined by face selectivity are at risk of missing potentially important effects ( ;  ). 

Neurons with social attention responses in macaque STS are often invariant to the identity of the individual conveying the cue ( ). In this study, we observed no generalization between response patterns evoked by left–right head turns across the 2 identities. Although there is some initial evidence to suggest that STS neurons can code both head view and head identity ( ), it is in our view unlikely that the representation across STS is identity-specific. For instance, it has previously been shown that direct and averted static head views can be distinguished across identity in posterior STS ( ). Given that separate training of left–right classification for each identity involves half as much data as compared with when this dimension is collapsed, it is more likely that our experiment was not sufficiently sensitive to detect any such identity-invariant head turn representations. 

Our results suggest that the anterior STS region distinguishes the direction of perceived head turns. The follow-up eye-tracking experiment suggested that volunteers' eye movements tended to follow the direction of head turns, thus presenting a potential confound to the interpretation of our results. To rule out an eye movement account of our reported classification effects, we demonstrated in a revised fMRI experiment that a subset of volunteers from the main experiment showed significant left–right head turn classification in the right STS region, even though these volunteers showed no significant eye movement effects during pretests or whilst in the scanner. Thus, even though our main analysis is potentially limited by an eye movement confound, the head turn direction codes in the right anterior STS region remain when this confound is removed. The absence of prior reports of eye movement responses in the anterior STS region is also consistent with this interpretation ( ;  ). By contrast, even minute eye movements elicit responses in early visual cortex ( ), and an eye movement account would seem to account well for the pattern of ipsilateral univariate selectivity we observed in the main experiment, with leftward and rightward head turns producing responses in left and right early visual cortex, respectively. Notably, this ipsilateral pattern of effects reverted to the expected contralateral response preference in the univariate analysis of the follow-up experiment, even though left–right head turn classification in early visual cortex was significant in both the original and the follow-up experiments. These results suggest that the classification effects in the 2 data sets were driven by distinct large-scale univariate effects: a primarily eye movement-related response in the main experiment and a visually-evoked response in the follow-up experiment. 

The pervasive tendency for volunteers to follow social attention cues points to an intriguingly close link between action and perception in this system, which is worthy of further enquiry. Previous investigators found that static gaze cues also evoke small eye movements in the perceived gaze direction ( ). Indeed, 2 of the 5 volunteers who were tested with eye tracking in the current study were unable to consistently suppress eye movements in response to the head turns, even in the presence of a fixation cross and strong instructions to maintain fixation. Although interesting in their own right, these eye movement effects also suggest that investigators who seek to isolate effects of perceived gaze direction would be well advised to monitor the volunteer's own gaze. 

Previous studies have found that socially relevant motion engages MT ( ;  ). Consistent with this literature, we observed a univariate response preference for heads relative to ellipsoids in bilateral superior temporal regions likely corresponding to MT+. Despite this category preference for heads relative to ellipsoids, we obtained no evidence that response patterns in this region distinguish head turn direction. In previous studies that attempted to decode motion directions, direction sensitivity was weaker in MT than in earlier visual areas ( ;  ), which the authors attribute to MT's smaller anatomical size compared with earlier visual areas. Although neurophysiological data suggest considerable direction sensitivity in both MT and early visual cortex ( ), such response properties may interact with area size when measured with coarse-grained methods such as fMRI, thus producing apparently weaker or nonsignificant effects in smaller areas ( ). Note also that both the absence of a functional MT localizer and the use of weaker, more transient motion stimuli may have rendered our analysis less sensitive to direction-sensitive responses in MT+, compared with previous studies ( ;  ). Thus, we do not exclude the possibility that head turns produce direction-sensitive MT+ responses, although we were unable to find evidence for this. 

In conclusion, we have presented evidence that response patterns in human right anterior STS/STG distinguish between leftward and rightward dynamic head turns. Such direction sensitivity was not detected for physically matched ellipsoid control stimuli. The anterior site of this effect is consistent with evidence from macaque neurophysiology ( ;  ) but does not colocalize with regions showing greater univariate responses to heads than to ellipsoids. In this respect, multivariate pattern approaches show great promise in linking evidence from single neurons in the macaque to large-scale response patterns in human fMRI. 


## Supplementary Material 
  
 Supplementary material   can be found at:   http://www.cercor.oxfordjournals.org/  


## Funding 
  
 (grant   to A.J.C.;   to J.B.R); Wellcome Trust (  to J.B.R.). 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-37'>
<h2>37. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/25671708/' target='_blank'>25671708</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Simulating Fiction: Individual Differences in Literature Comprehension Revealed with fMRI</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2015</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0116492</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4324766/' target='_blank'>4324766</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Study used task-based fMRI in healthy adult participants (n=18; ages 18–27) while they listened to literary excerpts that were annotated for mentalizing (social cognition) and action content. The main contrasts include mentalizing-related processing and the authors report whole-brain group results (e.g., aMPFC cluster for Mentalizing > Action and Action > Mentalizing clusters), meeting the requirement for whole-brain results. Although ROI analyses and localizers were used, whole-brain analyses are reported and interpreted. Participants were healthy, within the 18–60 age range, and the task probes social-related (theory-of-mind/mentalizing) processing. No exclusion criteria (clinical samples, review-only, ROI-only reporting) apply. Therefore the study meets all inclusion criteria for the review.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
When we read literary fiction, we are transported to fictional places, and we feel and think along with the characters. Despite the importance of narrative in adult life and during development, the neurocognitive mechanisms underlying fiction comprehension are unclear. We used functional magnetic resonance imaging (fMRI) to investigate how individuals differently employ neural networks important for understanding others’ beliefs and intentions (mentalizing), and for sensori-motor simulation while listening to excerpts from literary novels. Localizer tasks were used to localize both the cortical motor network and the mentalizing network in participants after they listened to excerpts from literary novels. Results show that participants who had high activation in anterior medial prefrontal cortex (aMPFC; part of the mentalizing network) when listening to mentalizing content of literary fiction, had lower motor cortex activity when they listened to action-related content of the story, and vice versa. This qualifies how people differ in their engagement with fiction: some people are mostly drawn into a story by mentalizing about the thoughts and beliefs of others, whereas others engage in literature by simulating more concrete events such as actions. This study provides on-line neural evidence for the existence of qualitatively different styles of moving into literary worlds, and adds to a growing body of literature showing the potential to study narrative comprehension with neuroimaging methods. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (36222 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Narratives play an important role in human life, and it is more and more acknowledged that fiction is a powerful player in human development as well as in adulthood (e.g. [ , , ]). Despite its importance, it is largely unknown what the brain networks are that support our unique ability to move into a fiction world. While it is uncontroversial that people   are   moved into fiction worlds [ , ], it is unclear   how   readers do this. People differ greatly in how they engage in fiction (e.g. [ , – ]), but the neurocognitive mechanisms behind narrative engagement remain unclear (see [ ] for related work on theatre). Here we use neuroimaging to investigate individual differences during the comprehension of literary fiction stories. 

One way in which participants engage with stories, is via simulation of the story’s content. Recent philosophical and neuroscientific evidence shows that it is important to distinguish at least two neurocognitively distinct components of simulation when considering the understanding of narratives (e.g. [ ]). First,   sensori-motor simulation   is evidenced by activation of motor and visual cortices when people comprehend language related to actions and scenery [ – ]. The second component relates to our ability to understand thoughts, intentions and beliefs of others, sometimes called   mentalizing   [ ]. The distinction between these two components important for fiction understanding is theoretically motivated (e.g. [ ]), and supported by neural findings (e.g. [ , ]). 

In this study participants listened to excerpts (4 to 8 minutes long) from literary novels, while neural activity was measured across the whole brain by means of fMRI. We chose to use listening rather than word-by-word reading, because relatively long fragments are used and therefore listening is expected to be the most convenient option for participants in the scanner. Supposedly, this would not result in crucial differences in terms of the mental simulation they employ. Previous studies did find differences in brain activity between listening and reading (with more individual differences in activity for reading), but also several core regions shared between modalities [ ]. More importantly for the purposes of the present study, it has been shown that regions involved in mentalizing [ ] and action understanding [ ] are activated independent of presentation modality. It is an open question whether mentalizing differs during reading or listening to narratives, but based on the previous literature we expect the two modalities to engage overlapping neural correlates. 

Stories were tagged for motor (‘action’) and mentalizing content, and memory for the stories was debriefed afterwards. Brain regions known to be involved in the two kinds of simulation were localized with standardized localizer tasks. Target regions were left and right motor regions for sensori-motor simulation [ ], and anterior medial prefrontal cortex (amPFC), right temporoparietal junction (rTPJ) and precuneus for mentalizing [ , ] (see   section). Importantly, measurement of brain activity during story comprehension was done on-line, and without additional tasks for the listener. 

Some recent neuroimaging studies relate to the issue of mentalizing and sensori-motor simulation during the comprehension of narratives. For instance, Wallentin and colleagues showed that part of the visual cortex which is sensitive to perceiving visual motion, is also activated when participants heard pieces describing movement in a retelling of ‘The Ugly Duckling’ [ ]. Similarly, Speer and colleagues showed that parts of short children’s stories containing action descriptions activated the motor cortex [ ]. In an interesting recent approach, Altmann and colleagues presented short stories (around 40 words per story) to participants. Stories were either labeled as fact (describing an event that actually took place) or as fiction. Most interesting for the current approach was that stories that were labeled as fiction led to stronger activation in medial prefrontal cortex (among other regions), whereas labeling stories as describing actual facts led to higher activation levels in the premotor cortex (again, amongst other regions) ([ ]; see also [ , ]). 

In this study we follow up on this previous work by using more extended (i.e. longer) excerpts from literary fiction, written for adults, in order to give participants an experience of engaging with fiction that is relatively close to their real-world experience. We have a special focus on individual differences in simulation and mentalizing during narrative comprehension. Previous work has found that participants differ in how much they engage parts of the mentalizing system during the reading of texts labeled as fiction [ ], as well as that participants differ in how much they engage in sensori-motor simulation during language comprehension [ , ]. Here we combine these two to see how participants differ in their engagement of these two important subprocesses of narrative comprehension while listening to natural, unmodified literary fiction. 


## Materials and Methods 
  
### Participants 
  
Eighteen healthy, naïve native speakers of Dutch without psychiatric or neurological problems, and with normal or corrected-to-normal vision and no hearing problems took part in the experiment. Four participants were male, fourteen female. The average age was 22.2 years (range 18–27). Data for the ‘Theory-of-Mind localizer’ of one participant showed artifacts (Nyquist ghosting) and were therefore removed. Written informed consent was obtained prior to the study, and ethical approval was obtained from the local ethics committee (CMO Committee on Research Involving Human Subjects, Arnhem-Nijmegen, The Netherlands, protocol number 2001/095), in line with the Declaration of Helsinki. Participants were paid either in money or in course credit at the end of the study. 


### Story stimuli 
  
Sound recordings of three literary stories were selected from the Corpus of Spoken Dutch (‘Corpus Gesproken Nederlands’, [ ]). Recordings were spoken at a normal rate, in a quiet room by female speakers (one speaker per story). The fragments were taken from literary novels, and all contained descriptions of actions, characters, scenery, and plot and character development. Duration of the fragments was 3:49, 7:50, or 7:48 minutes, and the number of words was 622, 1291, and 1131 words per story. In order to create an experimental baseline condition, reversed speech versions of the story fragments were created (using Audacity 2.03,   http://audacity.sourceforge.net  ). 

The story fragments were annotated for Action and for Mentalizing content over the course of the story. Quantification of the content at specific time points in the story was done with PRAAT [ ], and consisted of assigning sentence parts which contained Action descriptions or Mentalizing descriptions to either category. A sentence part was coded as Action if it contained action of a person or an object. A sentence part was coded as Mentalizing if a character’s mental states (emotions, desires, intentions and/or beliefs) were described, as well as when a character was described in terms of his or her personality ( ). Sentence parts were predefined in the corpus, and never contained more than one main verb. Taken together, the Mentalizing sentence parts made up 22.9% of the total story durations, and the Action sentence parts 25.6%. A sentence part could contain more than one kind of description: the two descriptors had 11.1% overlap. Mean duration of the Mentalizing events (sentence parts) was 1.58 seconds (s.d. 0.76 sec.), and 1.75 seconds for Action events (s.d. 0.70 sec.). In total there were 252 Mentalizing events, and 225 Action events. 
   Example of stimulus scoring.        

### Procedure 
  
 Main task  . The main task was always carried out first. Participants were auditorily presented with the three story fragments while they were lying in the MRI scanner. Intermixed with the stories, the three reversed speech versions of the stories were played. There was no additional task but to listen to the materials carefully and attentively. There was a short break after each fragment. The stories were presented in counterbalanced order across participants, with the reversed speech version always being played either before or after the specific story it was created from. 

 Localizers for regions of interest  . After presentation of the stories, localizer scans were taken to define regions of interest (ROIs) that were hypothesized to be active during either motor simulation or during mentalizing. ROIs for motor simulation were defined by having participants carry out a localizer task for action execution. Simple hand action was required (opening and closing of the fingers of both hands)—a fast method that has proven to reliably elicit the motor cortex in studies of action language comprehension [ , ]. Each trial started with a fixation cross presented for 1 s, followed by one of the words HANDS or REST for 10 s in white text on a black screen. Participants were required to continuously open and close their hands (Hand blocks), or to not move (Rest blocks). There were six of these trials per condition. The trials were presented in a pseudorandom order so that a specific condition was not presented more than twice subsequently. 

The task that was used to define mentalizing ROIs was based on an existing Theory-of-Mind localizer [ ]. Here, the version designed by Dodell-Feder, Koster-Hale, Bedny and Saxe was used, in a Dutch translation [ , ]. The task consists of a ‘false belief story’ task that activates regions that are known to be specifically activated when thinking about other persons’ beliefs and intentions. Followed by an initial instruction screen that stayed up until button press, participants read 20 short stories, divided in two blocks of ten. Each trial started with a fixation cross that was presented for a time interval randomly jittered between 4 and 8 s, in steps of 250 ms (intertrial interval). Then a story of two or three sentences was presented in white text on a black screen for 10 s. Each story was followed by a single-sentence statement that could be true or false. This statement stayed on the screen for 5 s, and within this time participants had to make a left button press for true, right for false statements. Half of the stories belonged to a   false photograph   (non-Mentalizing), half to a   false belief   (Mentalizing) condition: regions were defined on the basis of this contrast. That is, they reflected where activity was greater for the false belief condition than for the false photograph condition. The stories were presented in pseudorandom order, so that the same condition was never presented more than two times in a row. 

On the basis of the two localizer tasks, regions of interest were created. This was done for the action localizer, by taking significant clusters from the ‘hands > rest’ contrast, using a statistical threshold of p<0.05 Family Wise Error-corrected at the voxel level. For the Mentalizing localizer, the contrast ‘false belief > false photograph’ (story plus subsequent test statement together) was used. Results were corrected for multiple comparisons by combining a voxel-wise threshold of p<0.001 with a cluster extent threshold computed using the theory of Gaussian random fields, to arrive at a statistical threshold with a p<0.05 significance level [ ]. The different procedure for statistical thresholding was motivated by the fact that action execution leads to very strong and easily detectable activations, warranting a more conservative thresholding procedure. The mean brain activity in each ROI (technically the mean beta weights per condition) during story comprehension was extracted per regressor (Mentalizing content, Action content) per participant, using the SPM toolbox MarsBaR [ ]. 

 Post-hoc memory test  . Participants, once out of the scanner, got a surprise test to check their memory for each of the stories. Participants were not told about this memory test before the start of the experiment. There were five multiple-choice questions per story fragment, with three possible answers (A, B, C) each. The questions were asking for general content, varying in level of detail (Example: What could be seen at the horizon? A. wind mill, B. watchtower, C. radio mast). Memory scores were summed, providing an overall score of participants’ memory and on-line attention to the story. 


### fMRI data acquisition and preprocessing 
  
Images of blood-oxygen level dependent (BOLD) changes were acquired on a 3T Siemens Magnetom Trio scanner (Erlangen, Germany) with a 32-channel head coil. Pillows and tape were used to minimize participants’ movement, and earphones used for presenting the stories also minimized scanner noise. Functional images were acquired using a fast T2*-weighted 3D EPI sequence [ ], with high temporal resolution (TR: 880 ms, TE: 28 ms, flip angle: 14 degrees, voxel size: 3.5 x 3.5 x 3.5 mm, 36 slices). High resolution (1 x 1 x 1.25 mm) structural (anatomical) images were acquired using an MP-RAGE T1 GRAPPA sequence. 

Preprocessing was performed using the Matlab toolbox SPM8 (  http://www.fil.ion.ucl.ac.uk/spm  ). After removing the first four volumes to control for T1 equilibration, images were motion corrected and registered to the first image. The mean of the motion-corrected images was then coregistered with the individual participants’ anatomical scan. The anatomical and functional scans were spatially normalized to the standard MNI template. Finally, all data were spatially smoothed using an isotropic 8 mm full width at half maximum (FWHM) Gaussian kernel. 


### Stimulus presentation 
  
Stimuli were presented with Presentation software (version 16.2,   http://www.neurobs.com  ). Auditory stimuli were presented through MR-compatible earphones. Presentation of the story fragments was preceded by a volume test: a fragment from another story but with comparable voice and sound quality was presented while the scanner was collecting images. Volume was adjusted to the optimal level based on feedback from the participant. All visual stimuli were projected onto a screen using a projector outside the MR scanner room, which could be seen by participants through a mirror mounted over the head coil. Responses to the Mentalizing localizer task were recorded with two button boxes (left and right hand). The story parts of the experiment required no response (listening only). 


### Data analysis 
  
At the single-subject level, statistical analysis was performed using a general linear model, in which beta weights for each regressor of interest are estimated using multiple regression analysis [ ]. In this model, the two regressors of interest (‘Mentalizing’ descriptions and ‘Action’ descriptions) were modeled as their true durations, convolved with a canonical hemodynamic response function [ ]. The variance inflation factor (VIF) of the two regressors of interest was calculated, to ensure that unique variance could be attributed to each regressor. The VIF of ‘Mentalizing’ and ‘Action’ was 1.22, which is low, and well within the range for assessing multicollinearity, in which values bigger than 10 are problematic [ – ]. The motion estimates of the motion correction algorithm (linear, quadratic and first-derivative regressors for three translations and three rotations) were modeled as regressors of no interest to account for head motion. 

To address the question about individual differences in kinds of simulation, activity for the Action regressor in action ROIs was correlated with activity for the Mentalizing regressor in mentalizing ROIs. The rationale behind this analysis is that if people differ in whether they engage more in one type of simulation compared to the other, we should find that there is a relationship between activity in the mentalizing network during Mentalizing descriptions, and activity in the neural action network during Action descriptions. All correlations were two-sided Pearson’s correlations, and to guard against false positives, all correlation results were corrected for the number of comparisons by changing the critical alpha value using Bonferroni correction. 

As a control analysis, the same correlation analysis was repeated on the data acquired while participants listened to the reversed speech fragments, for which the Mentalizing and Action regressors are meaningless. Naturally, no significant correlations were expected between regions and different regressors in this analysis. A direct comparison between correlation values of the real and reversed speech sessions was done using Steiger’s test [ ]. 

To see if the action ROIs and the mentalizing ROIs were each co-activated during story comprehension, Action regressor activity in each of the action ROIs was correlated with the other action ROIs, and Mentalizing regressor activity in each of the mentalizing ROIs was correlated with the other mentalizing ROIs. We expect the ROIs for each condition to co-activate, in line with previous studies (see e.g. [ ] for action ROIs, and [ , ] for mentalizing ROIs). 

Finally, as another control analysis, activity for the Action regressor in mentalizing ROIs was correlated with activity for the Mentalizing regressor in action ROIs. No relationship between those regressors and ROI activity was expected, and therefore also no significant correlations between the mentalizing and action ROIs. 

Although our main hypothesis concerned the mentalizing and action neural networks, we additionally performed a whole-brain analysis to assess whether there were activations of interest outside of our target networks. Statistical group analysis was performed by directly contrasting one of the sentence part regressors with the other. Participants were treated as a random factor in this analysis (“random effects model”, [ ]). Results were corrected for multiple comparisons by combining a voxel-wise threshold of p<0.001 with a cluster extent threshold computed using the theory of Gaussian random fields to arrive at a statistical threshold of p<0.05 [ ]. 



## Results 
  
### Behavioral 
  
Participants answered on average 9.9 (s.d. 1.11) questions correct of the 15 questions asked in the post-hoc memory questionnaire (multiple choice, three alternatives, 5 questions per story). Participants performed well above chance (p<0.001 for all stories) on the memory test, and there were no differences between the three stories (F(2, 16) = 1.41, p = 0.27; mean story 1: 3.17 (s.d. 1.25), story 2: 3.67 (s.d. 1.09), story 3: 3.11 (s.d. 0.96)). This indicates that participants paid attention to the story content, and that this was equally the case for all three stories. 


### Localizers 
  
The results of the localizer tasks show that the localizers worked well: both revealed activations in sets of areas that were expected based on previous literature (see below). 

 Action localizer  . The action localizer activated the cortical motor system robustly. The ‘hands > rest’ contrast resulted in activations in the precentral and central motor regions bilaterally, as well as in the supplementary motor area (SMA), and in the cerebellum ( ). Since we had no a priori hypothesis about distinctions within the motor system during sensori-motor simulation, and to reduce the number of tests in the correlation analysis, we combined the cortical ROIs into two motor cortex ROIs, one for the left hemisphere, and one for the right hemisphere (MNI coordinates of centre voxel: left -34 -23 56, right 32 -20 58). This means the cerebellum was excluded from further analysis. 
   Results of the localizer scans.  
Whole-brain analysis results for the action localizer scan in yellow (hand action execution versus rest), and for the mentalizing localizer in blue (false belief stories versus false photograph stories [ ]). The action localizer activated the cortical motor system robustly, and the mentalizing localizer led to activations in the previously defined mentalizing (or Theory-of-Mind) network. Areas from the localizers were used in the main analysis as regions of interest. Results are displayed at a statistical threshold level of p<0.05, corrected for multiple comparisons. 
  
 Mentalizing localizer  . The regions of interest defined from the Mentalizing localizer’s ‘false belief > false photograph’ contrast were the medial prefrontal cortex, left and right temporo-parietal junction, left and right middle temporal gyrus, and the precuneus ( ). Given previous research, and in order to restrict the number of statistical tests, we selected, as mentioned above, the mentalizing ROIs from the results that are most commonly reported in previous literature, namely aMPFC (MNI coordinates -3 50 -10, rTPJ 51 -60 25, and precuneus -1 60 37 [ , ]). 


### ROI analysis 
  
Mentalizing regressor activity in the mentalizing ROIs was correlated with Action regressor activity in the action ROIs. A significant negative correlation was found between the action ROIs activation for Action descriptions, and the aMPFC mentalizing ROI activity for Mentalizing descriptions ( ;  ). This shows that participants who engaged the aMPFC when listening to mentalizing content, did engage the cortical motor system less when listening to Action descriptions, and vice versa. Importantly, the same correlations were not observed for the reversed speech data (all p>0.5;  ). A direct comparison using Steiger’s Z-test [ ] of the correlation values showed that correlations between aMPFC and motor regions during the real speech fragments were more negative than during the reversed speech fragments (z = -1.74, p = 0.04). A similarly negative correlation was found between right TPJ activity during mentalizing content and right motor cortex during action content ( ), and although this effect did not reach statistical significance, it is still sizeable (r = -0.40), and importantly in the same direction as the aMPFC-motor cortex correlation. No significant correlation was observed between Mentalizing activation in the precuneus, and Action-related activation of either of the Motor regions ( ). 
   Results of the correlation analysis.  
Scatter plots of activation levels (beta weights) of Mentalizing regions (x-axes) while participants listened to mentalizing content, and activation in Motor regions while participants listened to Action content (y-axes).   A  ) There is a negative correlation between Mentalizing regressor activity in the aMPFC mentalizing ROI (x-axis) and Action regressor activity in the left precentral action ROI (y-axis). This illustrates the individual differences in engaging with fiction, with a gradient going from those who engage exclusively in mentalizing, to participants that engage much more in motor simulation ( ).   B  ) Relationship between Mentalizing activation in right TPJ and Action content activation in right motor cortex. There is a negative relationship, which is sizeable (r = -0.40), but does not reach statistical significance.   C  ) No relationship was observed between Mentalizing activation in the precuneus and Action content in left Motor regions. Activity is expressed as the mean (over voxels in a ROI) of beta weights of a specific regressor in the regression model. The beta weights reflect the fit of BOLD activity with the modeled response to either Action or Mentalizing events. Every dot represents activation from one participant. 
     Correlations between mentalizing and action regions.           Correlations between mentalizing and action regions for the reversed speech control data.           Brain maps illustrating activation clusters for the Mentalizing regressor contrasted against the Action regressor (red) and the Action regressor contrasted against the Mentalizing regressor (blue).  
All activations are corrected for the multiple comparisons at p<0.05. 
  
The mentalizing ROIs were co-activated as is evidenced by the correlations between mentalizing ROIs while participants listened to Mentalizing content ( ). The rTPJ and precuneus showed a significant correlation with each other during mentalizing content. The correlation of aMPFC with the other two regions of the mentalizing network was not statistically significant ( ). It is possible that the aMPFC stands out from the rest of the mentalizing regions (see  ), but we are cautious to draw this conclusion from the present findings since the non-significant correlations of aMPFC with rTPJ and precuneus are still sizeable (r = 0.39 and r = 0.42 respectively), which is in between medium and large effect size in Cohen’s convention [ ]. These numbers cannot be taken as suggesting an absence of correlation. 
   Correlations within sets of co-activated regions.        
The action ROIs (left and right motor regions) correlated significantly with each other while participants listened to Action descriptions ( ). 

As a final control analysis, Mentalizing regressor activity in action ROIs was correlated with Action regressor activity in mentalizing ROIs (‘swapped correlations’), and no significant negative correlations were found, as was expected (all p>0.2). This is extra evidence that the negative correlations displayed in   and  , are specific to the content of the stories driving mentalizing and action regions. 

Activation levels in none of the ROIs were correlated with later memory for the stories, neither for the Mentalizing regressor, nor for the Action regressor (all p>0.12). 


### Whole-brain analysis 
  
Comparing activation for the Mentalizing regressor versus the Action regressor, a cluster in anterior medial prefrontal cortex was found, close to (and partially overlapping) the aMPFC region from the mentalizing localizer ( ;  ). For the Action regressor (versus the Mentalizing regressor), both left and right superior temporal gyrus were significantly activated, as well as the posterior cingulate cortex, extending into BA 7 ( ;  ). Activation levels of these four regions for both regressors compared to baseline are displayed in  . 
   Bar plots showing mean activation levels (‘beta weights’) of each of the regressors (Mentalizing in black, Action in white) against baseline, in each of the regions found in the whole-brain analysis ( ).  
 A  ) left superior temporal gyrus.   B  ) right superior temporal gyrus.   C  ) posterior cingulate cortex.   D  ) anterior medial prefrontal cortex. Error bars represent standard error of the mean (s.e.m.). 
     Results of whole-brain analysis.        


## Discussion 
  
Understanding fiction is more than an enjoyable pastime. Sharing narratives is a key component of human development (e.g. [ , , ]), and there is evidence for the long-held conjecture that engagement with fiction renders people more empathic, presumably because of its enhancement of Theory-of-Mind abilities in the short and long term [ , , ]. Another pointer towards the importance of fiction is that storytelling occurs in all cultures, and has existed throughout large part of human history [ ]. Here we used fMRI to measure individual differences in narrative engagement on-line, measuring neural activation while people listened to excerpts from literary stories. 

We show that participants employ mentalizing and motor simulation differently during fiction comprehension. There was a negative correlation between the activation in part of the cortical mentalizing network (anterior medial prefrontal cortex, aMPFC) for Mentalizing content in the story, and activation in the cortical motor network when participants listened to content related to Action. This suggests that there is a gradient among people in the way they engage with a narrative. Some rely mostly on mentalizing, others rely more on (sensori)-motor simulation, and yet others rely on both. This research gives more insight into individual differences in ways of engaging with fiction, by showing that there is no bimodal distribution with ‘simulators’ versus ‘non-simulators’, but that most readers rely on a specific type of simulation more than others. Some people are moved into a fiction story by mainly focusing on the thoughts and beliefs of others, whereas others pay more (implicit) attention to more concrete events such as action descriptions. 

These findings add to recent insights about the two complementary systems for understanding actions and goals. A meta-analysis showed that the mirroring system (anterior intraparietal sulcus and premotor cortex) and the mentalizing system (TPJ, mPFC, and precuneus) play complementary roles, depending on how abstract the presented actions and/or goals are [ ]. Another recent study, found that when participants were told to focus on the motive behind an action, the mentalizing system became active, whereas the mirroring system was activated when they focused on the implementation of an action [ ]. 

Here, we observed this distinction between the two networks on the individual difference level, and within the broader scope of not just understanding actions and goals, but entire fictional stories. Apparently, when participants are explicitly told to use either kind of simulation, they will, but without instructions individual differences will play a larger role. Clearly, the fact that participants differed in their reliance on mentalizing or motor simulation during fiction comprehension does not mean that some are   incapable   of mentalizing or engaging in motor simulation. For instance, we did observe robust group-level activations to the Theory-of-Mind localizer task. The individual differences during narrative comprehension rather reflect an implicit preference, showing what participants do when processing fiction without additional task constraints. 

It should be noted that the correlation we observed between Mentalizing and Action networks, only holds for one of the Mentalizing regions, namely the anterior medial prefrontal cortex. It is tempting to conclude that this region plays a privileged role during fiction comprehension, in comparison to the other parts of the mentalizing network (right TPJ and precuneus in the present study). Van Overwalle and Vandekerckhove [ ] suggest that aMPFC and TPJ each fulfill specific roles during mentalizing. Anterior MPFC is thought to be activated by descriptions of stable characteristics and enduring traits, TPJ by more temporary intentions and beliefs [ ]. Indeed, a large part of the mentalizing descriptions in our story materials consisted of personality trait descriptions. While it is possible that aMPFC shows up in our analysis for this reason, we are cautious with drawing strong conclusions on the respective roles of aMPFC and rTPJ / precuneus in the mentalizing network. The correlation values between right TPJ and precuneus and the motor cortex were still sizeable, and the correlations between the mentalizing regions (aMPFC, right TPJ, and precuneus) were all sizeable. Moreover, there is evidence from connectivity analyses that anterior MPFC and right TPJ are strongly connected [ , ]. Finally it is important to note that by characterizing the stimuli a priori (i.e., tagging the stories for action and mentalizing content) and by selecting relevant action and mentalizing ROIs based on functional localizers, the interpretation of the results does not rely strongly on reverse inference of the type that has been criticized before [ , ]. 

Our results nicely complement previous observations of individual differences in employment of mentalizing or sensori-motor simulation during story comprehension. Altmann and colleagues showed that individual differences in self-reported mentalizing correlate with the coupling of the aMPFC to other mentalizing regions during the reading of short stories labeled as fictional [ ]. Other studies using behavioral measures show that individuals differ in how much they engage in sensori-motor simulation during language comprehension [ , ]. Our finding of individual differences is somewhat at odds with recent neuroimaging studies that found evidence for simulation across the study sample. For instance, Speer and colleagues found that premotor cortex was activated when participants heard action related descriptions, and Wallentin and colleagues showed involvement of visual motion areas when participants listened to descriptions of motion, and activations of the amygdala when participants listened to emotionally laden parts of a narrative [ , , ]. In contrast, we do not observe consistent activations in motor regions with group-level statistics (the regions we find are, in fact, in line with [ ]), but show that there are sizeable individual differences in participants’ sensitivity to action-related parts of the narrative. Note that we did observe activation of the aMPFC at the group level for listening to mentalizing-related parts of the story. One speculative reason for the difference across studies is in the difference in stimulus materials. Speer and colleagues [ ] presented descriptions of activities of a 7 year old child (from ‘One boy’s day’, by Barker and Wright, [ ]), and Wallentin and colleagues [ , ] used a classic fairy tale (‘The ugly duckling’, by H. C. Andersen) as materials. This is in contrast to the pieces of literary fiction, written for an adult audience, that we used here. The descriptions from ‘One boy’s day’ and ‘The ugly duckling’ could either be more concrete in their descriptions to start with, or participants may flexibly adapt to the genre they listen to (e.g. [ ]), leading to a more heterogeneous response in the case of the different genres employed in the present study. The present data do not allow for testing these suggestions, and they should serve as inspiration for future research. 

A final point is that our focus on sensori-motor simulation and mentalizing, two important factors in literary comprehension, is not meant to claim that there are no other ways to engage with fiction (e.g. [ ]). 

A remaining question is how the qualitative experience of fiction differs between people that rely more on the one kind of simulation compared to the other. It is likely that a qualitatively different type of engaging with a narrative leads to a qualitatively different experience of that narrative. We found no relation between memory performance and activation levels in any of the regions of interest, indicating that the difference in reading style that we observed does not lead to a difference in memory for the stories. The memory questions that we asked were however rather general, and perhaps not sensitive enough to pick up on fine-grained differences between participants. Moreover, it was not possible to qualify memory questions as being more indicative of mentalizing or motor simulation. This is in line with the findings by Happé and colleagues who observed different activations in medial prefrontal cortex in autistic as compared to healthy control participants, but did not observe differences in memory for stories [ ]. Future research should investigate how individual differences in engaging with literature influence the phenomenological experience of a given narrative. 

From a more methodological point of view, the present study adds to a recent line of work showing that using neuroimaging to gain more insight into discourse / narrative comprehension is feasible and can give important insights about language comprehension at the level of narrative (e.g. [ , , – ]). 

In sum we provide on-line neural evidence for the existence of qualitatively different styles of engaging with fiction. Participants could be placed on a continuum of how much they relied on mentalizing or motor simulation while listening to literary fiction stories. People differ in how they are moved into a fiction world, and the current study qualifies part of how this is the case. Future work should be geared towards understanding what the consequences of these individual differences are for the understanding and appreciation of literature. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-38'>
<h2>38. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/30615116/' target='_blank'>30615116</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> I See Your Effort: Force-Related BOLD Effects in an Extended Action Execution–Observation Network Involving the Cerebellum</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Cereb Cortex</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1093/cercor/bhy322</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6373696/' target='_blank'>6373696</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study used task-based whole-brain fMRI in healthy adults (final N=12, mean age 26 years) during action observation of another person (AO) and action execution (AE). Observing another’s effort/force to infer intention qualifies as social-related processing (action observation/imitation/mentalizing). The paper reports whole-brain GLM analyses (SPM12) with voxel-wise results and conjunctions, and also cerebellar SUIT analyses; results are not limited to ROIs. Participants were healthy and within the 18–60 age range. The study is empirical (not a review) and does not involve clinical/psychiatric populations. Therefore it meets all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Action observation (AO) is crucial for motor planning, imitation learning, and social interaction, but it is not clear whether and how an action execution–observation network (AEON) processes the effort of others engaged in performing actions. In this functional magnetic resonance imaging (fMRI) study, we used a “squeeze ball” task involving different grip forces to investigate whether AEON activation showed similar patterns when executing the task or observing others performing it. Both in action execution, AE (subjects performed the visuomotor task) and action observation, AO (subjects watched a video of the task being performed by someone else), the fMRI signal was detected in cerebral and cerebellar regions. These responses showed various relationships with force mapping onto specific areas of the sensorimotor and cognitive systems. Conjunction analysis of AE and AO was repeated for the “0th” order and linear and nonlinear responses, and revealed multiple AEON nodes remapping the detection of actions, and also effort, of another person onto the observer’s own cerebrocerebellar system. This result implies that the AEON exploits the cerebellum, which is known to process sensorimotor predictions and simulations, performing an internal assessment of forces and integrating information into high-level schemes, providing a crucial substrate for action imitation. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (45878 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Social behavior is based on understanding the actions of others and predicting appropriate reactions and subsequent interactions. In this context, perceiving the force applied to objects by others is crucial for understanding their intentions, for predicting the success of self-generated actions, and for dynamic movement control in interactions. However, there is still debate over the question of whether, when observing someone else performing an action, we mirror the actual movement dynamics or simply its goals ( ;  ;  ;  ;  ;  ;  ). Understanding, through observation, the force involved in movements performed by others can prime the force imparted during subsequent action executions (AE) ( ). The achievement of a better understanding of how force is represented in observation could facilitate and improve the clinical application of action observation (AO) in neurorehabilitation ( ;  ;  ). Although AE and observation have been studied using several techniques ( ;  ;  ;  ;  ), the neuronal processes involved in mirroring the motor effort of others have still not been fully explored. 

The most renowned imitation learning hypothesis claims that “mirror neurons” are activated by observation of actions performed by others ( ) and that the brain simulates the observed action by using the motor system as a forward model ( ;  ;  ;  ;  ), recruiting hierarchically organized brain circuits ( ;  ). On a broader perspective, the brain has been proposed to include a “mirroring system” which can understand the intentions of others from observing movements (“body” reading) and a “mentalizing system” which can infer the intentions of others reconstructing hypothetical events (“mind” reading) ( ;  ). In this context, even though magnetic resonance imaging (MRI) does not allow neuronal populations to be studied directly, functional MRI (fMRI), thanks to the blood-oxygenation-level-dependent (BOLD) effect ( ), can be used to study neuronal activation during both execution and observation of actions. fMRI studies ( ;  ;  ;  ) support the notion that, during observation of a complex motor task, the AE network (AEN) and the AO network (AON) combine to form an action execution–observation network (AEON), which provides the neural infrastructure for imitation learning. Although the “core AEON” structures are the premotor cortex and a limited number of parietal and temporal cortical areas ( ), it is now clear that the AEON also comprises the supplementary motor area and the inferior frontal gyrus, as well as large sections of the somatosensory and occipitotemporal cortices ( ). Furthermore, the cerebellum and basal ganglia have also been suggested to play a role in an extended circuit underlying action understanding ( ), to the point that the cerebellum is now considered to play a role as an adaptive predictor in AO ( ). This idea derives from the general theory of cerebellar functioning, wherein the cerebellum is seen as a forward controller in behavioral schemes that concern the interaction of the body with the external world, instructing the cerebral cortex in a predictive manner ( ;  ;  ;  ;  ). Moreover, a growing body of evidence from both lesion and fMRI studies ( ;  ;  ;  ;  ) suggests that the cerebellum plays a crucial role in action–perception coupling, coordinating the application of an appropriate force and its timing to generate movement, and thus operating in a forward mode ( ;  ;  ). On these bases, it can be hypothesized that predicting how to move by observation entails processing of force and involves an extended AEON that includes the cerebellum together with a complex set of cortical areas. 

In the present study, aiming to identify the network involved in force perception, we exploited a paradigm that recently showed how a complex set of linear and nonlinear BOLD responses are elicited in several brain regions, including the cerebellum, when varying the force applied to an object ( ;  ;  ). We used this grip-force (GF) squeeze ball paradigm to assess whether: 1) the AON presents both linear and nonlinear BOLD-GF associations during observation of the squeeze ball task; 2) the AEN and the AON share a common neural substrate, corresponding to the extended AEON; and 3) regions identified as part of the AEON exhibit linear and nonlinear BOLD-GF associations. The results of this work indeed support the existence of force-related BOLD effects not only in AE but also in the extended AEON, which includes the cerebellum. 


## Materials and Methods 
  
### Subjects 
  
A total of 14 right-handed healthy volunteers (9 females) were initially recruited for this study. However, 2 participants were excluded from further analysis: one who failed to follow the task instructions and another who presented head motion (translation in the   z   direction) >2 mm. The final sample thus comprised 12 subjects (7 females; mean age 26 ± 3.5 years). The handedness of each subject was evaluated using the Edinburgh handedness scaling questionnaire ( ); the mean laterality index was 82 (±16). All participants had normal or corrected-to-normal vision. No subject had a history of neurological or psychiatric disease. All the participants received a detailed explanation of the experimental procedures before participating in the experiment. The local research and ethics committee approved the study and all participants gave their written informed consent. 


### MRI Scanner and Scanning Sequences 
  
A 3 T Philips Achieva MR scanner (Philips Healthcare, Best, The Netherlands) with a 32-channel head coil was used to perform a 3D T1-weighted anatomical scan and 3 T2*-weighted echo-planner imaging (EPI) fMRI scans. The 3D T1-weighted sequence acquisition parameters were as follows: 3D inversion-recovery prepared gradient-echo (fast field echo) sequence with inversion time (TI) 824 ms, echo time (TE)/repetition time (TR) 3.1/6.9 ms, flip angle 8° and voxel size 1 mm isotropic. The fMRI acquisition parameters were: TR/TE 2.5/35 ms, 2.7 mm thick slices with interslice gap of 0.3 mm positioned axial-oblique to include the cerebellum, 3 × 3 mm  in-plane resolution, field of view 192 × 192 mm , SENSE factor 2, flip angle 90° and 200 repeated volumes. 


### Experimental Design 
  
All the participants completed 3 randomized event-related fMRI sessions (Fig.  ): AE, AO, and AO with visual cue (AOvc). In all cases, all the stimuli were projected onto the same white screen, which was kept in the same position throughout; short-sighted participants used nonmagnetic visual aid goggles. The 3 experimental sessions are described below. 
  
Experimental paradigm. The figure shows a pictorial representation of the 3 conditions that were used in the behavioral and fMRI sessions: (  A  ) action execution (AE), (  B  ) action observation (AO), and (  C  ) action observation with visual cue (AOvc). The stimuli are shown above the arrow whereas the activity of the subject is shown below the arrow. During fMRI, every session lasted 8:33 min and the trials were administered in a counterbalanced and randomized order. The active trials (each lasting 3 s) were repeated 75 times and were divided equally between the 5 grip forces. A rest time of 2–12 s was allowed between active trials. 
  

### Squeeze Ball Event-Related Paradigm 
  
This paradigm, previously described elsewhere ( ;  ;  ), consisted of a visuomotor event-related power grip task, in which the order and timing of trials and rest periods was optimized to introduce temporal jittering and randomization of the applied GF strength (see below). The task was performed using an MR-compatible sphygmomanometer inflation bulb (“squeeze ball”) connected to a computer suite (located outside the scanner room) running the fMRI paradigm presentation. Compression of the ball resulted in an air pressure measurement proportional to the force exerted, which was recorded at a sampling rate of 20 Hz. In all, 75 active trials were performed, divided equally into sets of 15 corresponding, respectively, to GF levels representing 20%, 30%, 40%, 50%, and 60% of the subject’s maximum voluntary contraction (MVC). MVC had previously been measured in each subject using the same force device (i.e., by asking the subject to continuously squeeze the power ball) and this value was used to set the GF target for each trial. 

Trials were performed in a counterbalanced and randomized order as obtained using the OptSeq optimization software ( ). The rest time between squeezing trials—this lasted between a minimum of 2 s and a maximum of 12 s, and was cued by a black crosshair located at the center of the screen—was also randomized to introduce temporal jittering between the task and data acquisition. Rest time accounted for 55% of the whole fMRI session (500 s). The visual cue used in the trials was a black static horizontal bar (presented for 3 s), which indicated the target GF level to reach. This cue was projected onto an MR-compatible white screen and shown together with an interactive colored bar, indicating the actual force level reached and thus providing real-time feedback to the subject about his/her own performance. The GF task was performed with the right (dominant) hand during the AE session. 

A female actor was also filmed while performing the task in the control room of the scanner suite. The resulting video showed her whole right hand and forearm, filmed against a plain colored background, with the palm facing up. While recording the task, the computer also recorded the visual feedback she received (i.e., the visual cue bar), which was used to create a further video (in which the cue bar was superimposed on the forearm and hand) to be used in the AOvc session. Premiere Pro CS5 (Adobe System Software, CA, USA) was used for video editing. 


### AO (AO and AOvc) Behavioral Sessions 
  
Before and after the fMRI sessions, subjects underwent behavioral sessions during which they were asked to watch the AO and AOvc videos (the order of presentation of the videos was randomized among subjects) and to verbally report their own perception of the GF, that is, 20%, 30%, 40%, 50%, or 60% of the MVC of the actor’s hand shown squeezing the ball in the video (perceived GF). These sessions served to test their recognition of the GFs observed, to saturate any learning effect before the actual fMRI experiment, and to test possible differences in learning effects between the pre- and post-MRI behavioral sessions. The purpose of running 2 AO behavioral sessions, AO and AOvc, was to assess whether GFs can be appreciated from subtle (and natural) cues alone—as in the AO condition (e.g., changes in the color of the hand with increasing effort and accompanying tendon contraction)—or whether subjects also need to see symbolic visual feedback, as in the AOvc condition. Performance accuracy was assessed for each of the 5 GF levels by calculating the number of correct answers and the mean difference between the perceived GF (pGF) and the GF actually applied by the actor during the video recording (aGF). 


### AE Training Session 
  
After the AO behavioral sessions, just before the fMRI one, subjects were trained using a 2-min paradigm having a design similar to the above-described event-related one, with GF levels ranging from 10% to 70% of their MVC. The training session involved practising the task outside the scanner bore. 


### AE Session 
  
Subjects performed the AE task following the visual instructions described above. Their feedback was recorded at a sampling rate of 20 Hz during the task. The data collected served to include subject-specific performance in the statistical analysis. 


### AO Session 
  
Subjects observed the video showing the right hand of the actor performing the squeeze ball task. They were asked to keep their gaze at the center of the projection screen indicated by a cross during rest periods, to relax, not to touch the squeeze ball, and to think about nothing throughout this fMRI recording session (as opposed to trying to guess the force or the next action). 


### AOvc Session 
  
The subjects received the same instructions as in the AO session. The only difference, compared with the AO condition, concerned the stimuli: the video again showed the actor’s right hand performing the squeeze ball task, but this time the image was overlaid with a translucent representation of the visual feedback that the actor had received during the recording of the video (thus an indication of her performance). This session was originally included as part of the behavioral study as it was unclear whether force perception demands some kind of visual feedback on the performance, such as that provided by the real-time bar (symbolic guided action observation). However, since the AO condition alone was found to be sufficient to disclose perception of force-related effects, the AOvc data were not considered further for the purposes of this study. 


### Data Analysis 
  
#### Behavioral Data Analysis 
  
The group mean accuracy of the subjects’ perceptions (pGF) was calculated overall by measuring all correct responses as a percentage of all perceived forces (at 20%, 30%, 40%, 50%, and 60% of MVC of the hand squeezing the ball in the video), and also separately for each of the following sessions: AO before MRI, AOvc before MRI, AO after MRI, and AOvc after MRI. A number of statistical tests were performed. First, we used paired sample   t  -tests to assess possible significant differences between ratings in the AO versus the AOvc sessions; that is, considering the mean accuracy of pGF in the 2 conditions (considering “AO before MRI” vs. “AOvc before MRI” and then “AO after MRI” vs. “AOvc after MRI”). Second, a repeated measures ANOVA with Bonferroni correction was implemented to investigate learning effects, that is, testing for different performances within the AO and the AOvc sessions (“AO before MRI” vs. “AO after MRI” and then “AOvc before MRI” vs. “AOvc after MRI”). A statistical threshold of   P   < 0.001 was considered significant. Finally, to characterize the challenging nature of the AO task, we assessed the correlation between the actor’s actual performance (i.e., the GF applied by the actor performing the task and recorded while filming) and the subjects’ perceptions of that GF (i.e., the pGF, as reported by each subject during the “AO before MRI” behavioral session), using the correlation coefficient (  r  ) and the significance level (  P  -value). The statistical analysis was performed using the Statistical Package for the Social Sciences (SPSS) software (version 21.0). 



### fMRI Data Analysis 
  
#### Whole Brain 
  
Image analysis was performed with SPM12 ( ), implemented in Matlab15b (Mathworks, Sheborn, MA), using conventional preprocessing steps: slice timing, realignment, coregistration, estimation of (nonlinear spatial) normalization parameters between the 3D T1-weighted volume and the standard SPM12 template, application of the normalization parameters to the fMRI EPI volumes, and smoothing with an 8 mm isotropic full-width half maximum (FWHM) Gaussian kernel. The GF trials were modeled as delta functions ( ) with parametric modulation according to GF. A general linear model (GLM) including polynomial expansions up to the fourth order was applied following the procedures described by Alahmadi et al. ( ;  ). As discussed in previous work, the polynomial expansion allows nonlinear relationships to be characterized in an unbiased way, by modeling a mixture of linear and nonlinear responses in a parsimonious fashion. Interpretation of the nonlinear order lends itself to hierarchical testing (e.g., second-order effects are interesting only after removing first-order effects) ( ) and neurophysiological studies have reported different response profiles that have distinct nonlinear forms ( ;  ;  ;  ). Moreover, polynomial expansions are the most common form of expansion (in the absence of boundary conditions) when estimating neurometric functions from imaging data ( ;  ). 

In our setting, the 0th order represents the main effect of hand gripping (executed or observed) compared with the rest condition, irrespective of the level of GF applied. The first order represents any linear dependency on GF level (executed or observed), while nonlinear orders represent more complicated neurometric functions such as U-shaped (second order), sigmoid (third order) and quadratic (fourth order) functions. The parametric modulation of the stick functions—encoding grip trials—with the polynomial expansion of GF produces stimulus functions that can then be convolved with a canonical haemodynamic response function for subsequent standard GLM analyses ( ). 

At the first level of analysis (within subject), the realignment parameters were included in the GLM as regressors of no interest ( ) and   t   statistics were used to test for the effects of each polynomial coefficient. The associated contrast images of each of the 5 polynomial coefficients were then entered into a second (between-subject) level analysis and tested with one-sample   t  -tests, following standard procedures. The same analysis pipeline was followed for the AE and AO sessions. In the AO session, the GF levels corresponded to those recorded from the actor’s performance. A voxel-wise threshold of   P   < 0.001 (minimum extent 5 voxels,   P  =   P   uncorrected for multiple comparisons) was used to define clusters. A threshold of   P   < 0.05 was applied to the spatial extent of clusters that survived multiple comparisons corrections. The anatomical designations of significant clusters were determined using the SPM Anatomy Toolbox (Version 2.2b). The same criteria were used for AE and AO sessions. 


#### SUIT 
  
The fMRI analysis pipeline, optimized for whole-brain analysis, can give suboptimal results in the cerebellum ( ). Therefore, to focus on the cerebellum, we used SUIT (spatially unbiased infratentorial template), a high-resolution atlas template of the human cerebellum and brainstem, which is part of the SPM12 software package ( ). The following steps were performed: 1) Extraction of each subject’s cerebellum and brainstem from their corresponding whole-brain 3D T1-weighted anatomical images; 2) Normalization of the anatomical images to the SUIT template using nonlinear deformations; 3) Re-slicing of the functional contrast images produced from the first-level analysis using the deformation produced from step 2) and masking out activation outside the region of interest (i.e., the cerebellum). The normalized cerebellum functional contrast images (of each polynomial order) from each subject were then smoothed with an 8 mm FWHM Gaussian kernel and submitted to a (between-subject) standard second-level random effects analysis, testing for increasingly higher-order nonlinear effects within the cerebellum with one-sample   t  -tests. Significant clusters were defined using a height threshold of   P   < 0.001 (and a minimum extent of 5 voxels). The anatomical designations of regionally specific effects were defined using a high-resolution probabilistic atlas defined within the SUIT template ( ). The resulting statistical parametric maps (SPMs) were projected on to the flat map of the cerebellum provided with the SUIT template ( ). 


#### Conjunction 
  
To identify, in terms of a parametric response to GF, the extended AEON, engaged both in AE and AO, we performed a simple conjunction analysis. This entailed testing for action observation effects at a corrected level of significance within a search volume defined by AE. 

We first used the SPM, testing for 0th order effects in order to localize the combined effect of AE and AO independently of GF, that is, to identify regions that showed a conjunction of AE/AO effects, irrespective of parametric force effects. We then identified regions that showed potential nonlinear responses to GF in both action observation and execution. In order to do so, we used a full factorial design and SPMs of the   F   statistic, testing for one or more significant polynomial coefficients in both execution and observation to obtain maps of the combined AE/AO force-related effect (FRE). Specifically, we used the SPMs of the   F   statistic, testing for a parametric effect of GF under AE (threshold   P  < 0.0001 for the whole brain analysis and   P   < 0.001 for the SUIT analysis) as a localizing contrast to define a search region within which to identify nonlinear effects under action observation (using the equivalent   F   contrast and a small volume correction to   P   < 0.05). Finally, we used the   F   statistic of the first-order effects to investigate the linear FRE and the   F   statistic of the higher-order effects to investigate the nonlinear FRE. 




## Results 
  
BOLD fMRI signals were recorded from 12 healthy subjects during one visuomotor and 2 visual tasks for the purpose of comparing brain activation under AE and AO conditions, when different GF levels are applied to an object (in this case a squeeze ball). 

### AO Behavioral Responses 
  
The behavioral performance, at group level, when watching the AO and AOvc videos, is shown in Fig.  . The accuracy of the perceived grip force (pGF) significantly differed between AO and AOvc, both before (  P   = 0.002) and after (  P   = 0.00008) the MRI session. Within the AOvc condition, pGF accuracy was higher after MRI (  P   = 0.003), while no significant differences were found in the AO condition (  P   = 0.955). As expected, GF recognition was higher in AOvc than AO (mean accuracy ± SD, 76 ± 22 and 39 ± 7, respectively), although at the end of the experiment, some subjects reported that the bar indicating levels of force (the visual cue) had not influenced their behavioral responses during AOvc. AO data showed a positive correlation between aGF and pGF (  r   = 0.98,   P   = 0.005) (Fig.  ), thus, confirming that the subjects were able to infer the actor’s movement in quantitative terms. Given that subjects correctly perceived the strength of the applied GF also when watching the AO video without the visual cue, subsequent analysis of fMRI data concerned only the AE and AO conditions. 
  
Group performance during action observation behavioral tasks. The box plot shows the relative accuracy (ACC) of force estimation in the different action observation (AO) and action observation with visual cue (AOvc) behavioral sessions (before and after the fMRI sessions). Significant differences between conditions are indicated (paired   t  -test). 
    
Relationship between applied and perceived grip force during the action observation behavioral task. The plot shows the relationship between grip force (GF) actually applied (aGF, i.e., GF presented on the video) and GF perceived (pGF, i.e., by the subjects watching the video) during the behavioral action observation (AO) task performed before and after fMRI recordings. The circles are individual subject responses and the line represents the group mean performance. A significant positive correlation was found between aGF and pGF (  R   = 0.98,   P   = 0.005). 
  

### Whole Brain—BOLD Effects 
  
Regionally specific effects for 0th (main effect), linear (+1st, −1st) and nonlinear (+2nd, +3rd, +4th, -3rd) order responses were detected, using whole-brain analysis, on AE and AO. Full data with figures and tables detailing significant effects (including coordinates,   T   values and cluster extents) are provided as  . AE activated many more regions than AO (Fig.  ), while both experimental conditions elicited regionally specific effects at 0th, −1st, and −3rd orders. Specifically, AO induced effects not only at the 0th order, but also at +3rd, 1st, and −3rd orders. These results reflect the presence of FRE during action observation. 
  
Whole-brain BOLD effects in action execution and observation. Brain maps at the group level corresponding to different orders of the BOLD-GF association in the action execution (AE, in red) and action observation (AO, in blue) conditions. The images show areas of activation at different orders. Note that both force-related and unrelated BOLD effects are found in the cerebral cortex and cerebellum. A threshold   P  < 0.001 (  k   ≥ 10;   P   =   P   uncorrected for multiple comparisons) was used for display purposes. The shape of the orthogonalised polynomial function that was fitted to the signals is shown for the (A) 0, (  B  ) +1st, (  C  ) +2nd, (  D  ) +3rd, (  E  ) +4th, (  F  ) −1st, and (  G  ) -3rd orders, to the right of the corresponding image showing significant clusters. In this and all the following figures, right is right and left is left. 
  

### Whole Brain Conjunction 
  
#### AE and AO Main Effect (0th Order) 
  
Several areas belonged to the extended AEON (in terms of a conjunction of zero order effects), and they included the occipital and temporal lobes, inferior and superior parietal cortices, precentral and postcentral gyri, inferior frontal gyrus, insula, thalamus and cerebellum. The occipitotemporal cluster extended into the cerebellar lobules VI and VII and cerebellar Crus I (Fig.   and Table  ). 
  
AEON: BOLD main effect. 3D whole-brain renderings of the main effects (0th order) in action execution (AEN), action observation (AON) and action execution–observation (AEON) networks. Note, in the AEON, the considerable overlap of effects in both the cerebral cortex and the cerebellum. Different thresholds were used for the 3 maps:   P   < 0.0001 (  k   ≥ 10;   P   =   P   uncorrected for multiple comparisons) was used for the AE condition;   P   < 0.05 (  k   ≥ 10;   P   =   P   uncorrected for multiple comparisons) was used for the AO condition; and   P   < 0.05 (  k   ≥ 10), with a small volume correction applied to the AO map, was used to obtain the AEON. 
  
  
AEON: main effect (0th order) 
    


#### Force-Related Effects (Linear and Nonlinear Orders) 
  
FREs (Fig.   A   and Table  ) were jointly expressed in several brain regions: supramarginal gyrus, calcarine gyrus, temporal gyrus, parietal lobe, insula, postcentral and precentral gyri, inferior frontal gyrus, middle cingulate cortex, posterior–medial and superior frontal cortices, rolandic operculum, lingual gyrus, basal ganglia, and cerebellum. A limited number of brain regions, that is, the precentral and postcentral gyri (Fig.   B  ), exhibited a linear FRE (+1st and −1st orders) in both AE and AO. The most prevalent joint FREs were nonlinear (+2nd, +3rd, +4th, −2nd, −3rd, −4th orders) and identified in the: supramarginal gyrus, angular gyrus, precentral and postcentral gyri, occipital lobe, inferior and middle temporal gyri, rolandic operculum, inferior and superior parietal cortices, inferior and middle frontal gyri, middle cingulate cortex, insula, thalamus and cerebellum (Fig.   C  ).
   
AEON: force-related BOLD effects 
    
  
AEON: force-related BOLD effects. 3D whole-brain renderings of the force-related effects: (  A  ) force-related effects (FRE), (  B  ) linear force-related effects (linear FRE), and (  C  ) nonlinear force-related effects (nonlinear FRE) in action execution (AEN), action observation (AON) and action execution–observation (AEON) networks. Note, in AEON, the prevalence of nonlinear associations in both the cerebral cortex and the cerebellum. Different thresholds were used for the 3 maps:   P   < 0.0001 (  k   ≥ 10;   P   =   P   uncorrected for multiple comparisons) was used for the action execution condition;   P   < 0.05 (  k   ≥ 10;   P   =   P   uncorrected for multiple comparisons) was used for the action observation condition; and   P   < 0.05 (  k   ≥ 10), with a small volume correction applied to the AO map, was used to obtain the AEON. 
  


### SUIT—BOLD Effects 
  
The AE condition detected more activated cerebellar regions than the AO one did (Fig.  ). In AE cerebellar specific effects were detected in lobule V and VIII (+1st order), lobule VI (0th and +4th orders), lobule VII (0th order), and Crus I (0th, +4th and −3rd orders). AO effects were observed in lobule VI (0th and −3rd orders), Crus I (0th order), and Crus II (+4th order). 
  
Cerebellar BOLD effects in action execution and observation. SUIT flat maps at the group level corresponding to different orders of the BOLD–GF association in action execution (AE) and action observation (AO) conditions. Note the force-related and main (0th order) BOLD effects in different cerebellar areas. In the images, areas of activation at different orders of effect are shown for both AE (in red) and AO (in blue). A SUIT flat map with labels of cerebellar lobules is shown in the bottom right corner. A threshold   P   < 0.001 (  k   ≥ 10;   P  =   P   uncorrected for multiple comparisons) was used for display purposes. 
  

### SUIT—Conjunction 
  
#### AE and AO Effect (0th Order) 
  
Lobules VI and VII and Crus I and II were jointly involved in AE and AO (Fig.  ). 
  
Cerebellar component of AEON: main BOLD effects. SUIT flat maps of the main effects (0th order) in the cerebellar component of the action execution (AEN), action observation (AON) and action execution–observation (AEON) networks. Note, in AEON, the extended involvement of posterior and lateral areas of the cerebellum. Different thresholds were used for the 3 maps:   P  < 0.001 (  k   ≥ 10;   P   =   P   uncorrected for multiple comparisons) was used for the action execution condition;   P   < 0.05 (  k   ≥ 10;   P   =   P   uncorrected for multiple comparisons) was used for the action observation condition; and   P   < 0.05 (  k   ≥ 10), with a small volume correction applied to the AON map, was used to obtain the AEON. 
  

#### Force-Related Effects (Linear and Nonlinear Orders) 
  
FREs were jointly identified in: Crus I and lobules V and VI (Fig.   A  ). A cluster in lobule V presented a linear FRE (+1st and −1st orders) while a nonlinear FRE (+2nd, +3rd +4th, −2nd, −3rd, −4th orders) was found in 2 clusters in lobule VI and IX (Fig.   B   and   C  , respectively). 
  
Cerebellar component of AEON: force-related BOLD effects. SUIT flat maps of the (  A  ) force-related effects (FRE), (  B  ) linear force-related effects (linear FRE), and (  C  ) nonlinear force-related effects (nonlinear FRE) in the cerebellar component of the action execution (AEN), action observation (AON) and action execution–observation (AEON) networks. Note, in AEON, the distribution of force-related BOLD effects over several cerebellar areas in the anterior and posterior cerebellum. Different thresholds were used for the 3 maps:   P   < 0.001 (  k   ≥ 10;   P  =   P   uncorrected for multiple comparisons) was used for the action execution condition;   P   < 0.05 (  k   ≥ 10;   P  =   P   uncorrected for multiple comparisons) was used for the action observation condition; and   P   < 0.05 (  k   ≥ 10), with a small volume correction applied to the AON map, was used to obtain the AEON. 
  



## Discussion 
  
In this study, we report for the first time the existence of force-related BOLD effects in an extended AEON involving cerebral and cerebellar regions that are both motor and associative in nature. These regions not only respond to observed and executed actions, but also share patterns of linear and nonlinear BOLD responses to parametric variations in GF. Linear BOLD–GF associations occurred in motor regions, while nonlinear BOLD–GF associations were found in regions specific to somatosensory state estimation, motor simulation and cognitive control. The cerebellum was found to be a key structure within the AEON, showing regional-specific correlations with force. These effects support the concept that the AEON extends to the cerebellum and to a set of cortical regions that are critical for imitation learning. The results are discussed and integrated with our current understanding of brain function in terms of the intrinsic functional connectivity of 7 fundamental networks (visual, somatomotor, ventral and dorsal attention, frontoparietal, limbic and default networks) ( ). 

### Behavioral Performance and Learning Effects 
  
The subjects were found to be able to evaluate visually the efforts of others. There are 3 considerations indicating that this ability was independent of learning during the test ( ). First, in order to saturate learning, all the subjects underwent AO training before the fMRI experimental sessions; this training is known to facilitate motor learning ( ;  ) and increase force production by optimizing motor neuron recruitment ( ). Second, the order of presentation of the AE, AO, AOvc sessions was randomized, thus limiting a potential variability in attentional load (e.g., induced by fatigue). Third, the accuracy in force detection was higher in AOvc than in the AO sessions. Therefore, independently of subject performance, the visual cue has a facilitator effect with respect to naturalistic stimulation (i.e., actual movement and changes in body parts during action), but the latter is nonetheless sufficient to perceive the intensity of another’s movements. 

It should be noted that in the AOvc condition we detected a learning effect, implying a facilitation of force recognition along trials. Moreover, we detected a higher variability of performance between participants in the AOvc compared with the AO condition; this might be due to attention being focused either on the visual cue or on the hand itself. However, the debriefing at the end of the experiment indicated that several participants had ignored the bar. For these reasons, we did not further consider the AOvc condition in our analysis. 


### BOLD Effects Elicited by AE and AO 
  
The BOLD effects elicited by AE occurred mostly in areas directly involved in motor planning, execution, and control ( ) (for a detailed description see Table  ). The main effect of AE was observed in premotor and sensorimotor cortices as well as in parietal, occipital and cerebellar cortices devoted to global sensorimotor processing ( ) and included in visual, dorsal attention and somatomotor networks, while a linear activation with force was found in primary motor cortex and anterior cerebellum, that actually do encode force ( ) and belong to the somatomotor network. Nonlinear relationships with GF were found in parietal, frontal, cingulate and insular cortices, and in thalamus, basal ganglia and cerebellum, which form large-scale loops involved in the control of fine precision grip forces and motor learning ( ;  ;  ). These loops could be linked with visual, ventral and dorsal attention, frontoparietal, somatomotor and default networks. Minor differences with previous squeeze ball studies ( ) could be related to the higher complexity of the present paradigm (which included behavioral training sessions and 3 different tasks).
   
Summary of BOLD effects for AEN, AON, and AEON 
    

The BOLD effects elicited by AO were recorded in an extended and distinctive set of occipital, parietal and frontal regions involved in motor but also sensory and cognitive processing (for a detailed description see Table  ). The main effect of AO was observed in the occipital and parietal regions related to motion perception and attention ( ;  ) that are considered to be part of the visual network and the ventral and dorsal attention networks. Linear responses with respect to GF occurred mainly in the postcentral gyrus, involved in processing proprioceptive and tactile representations of the manipulated object ( ) and included in the somatomotor network. Nonlinear responses with respect to GF occurred in occipital and temporal cortices and inferior parietal lobule, involved in object recognition ( ), inhibition of movement ( ), spatial focusing of attention ( ), and intention understanding ( ). These functions are supported by the inclusion of activated regions in the visual, dorsal attention and default networks. These components, either main or FREs, probably provide the substrate for the interpretation and simulation of the actions of others ( ), while actual movement is inhibited. 

The detection of specific nonlinear force-related BOLD effects in areas involved in AE or AO could imply complex task-related interplay of different neuronal populations (e.g., inhibitory and excitatory) within local networks. Understanding the biophysical basis of such nonlinearities will need realistic models and further investigation of neurovascular coupling under different conditions. 


### The Common Neural Substrate of AE and AO 
  
The AEON, identified as the voxels shared by AEN and AON, was observed in cerebral cortex, thalamus, basal ganglia, and cerebellum ( ) (for a detailed description see Table  ). The main effect of AEON was observed in occipital cortex, middle temporal gyrus, precentral and postcentral gyri, inferior and superior parietal lobules, insula, thalamus, and posterior cerebellum. These areas are involved in visual imagery of hand gestures, including visuospatial and motion processing ( ;  ), forward/inverse control for movement planning and execution, action style processing ( ), inhibition of motor execution to prevent imitative responses ( ). These are, indeed, the fundamental ingredients of motor planning based on observation of actions ( ). The activation of inferior and superior parietal lobules (which are part of the core mirror network) ( ) with occipital cortex, precentral and postcentral gyri and insula, suggest that AEON includes components from the visual, mirroring/somatomotor, ventral and dorsal attention networks. 

The AEON areas showing FREs were also extensively distributed in occipital cortex, superior temporal gyri, inferior and superior parietal lobules, precentral and postcentral gyri, inferior frontal gyrus, medial frontal gyrus, precuneus, cingulate gyrus, caudate, thalamus, and cerebellum. These areas are involved in the experience and observation of touch ( ), maintenance of spatial attention during goal-directed actions ( ;  ;  ), sensorimotor integration, and force amplitude generation and prediction ( ;  ). Moreover, the medial frontal gyrus is considered, with the temporoparietal junction, the “core network” of attribution of mental states ( ;  ) while the precuneus has been proposed to have a role in mental imagery to represent others’ perspective ( ). Therefore, FREs are particularly important in conferring the ability to detect the effort of others not just requiring the intervention of the mirroring/somatomotor, ventral and dorsal attention and frontoparietal networks but also of the mentalizing/default network. 

Interestingly, activation in the AEON areas was mostly nonlinear, while linear relationships with GF were found only in a restricted part of the precentral and postcentral cortices ( ) that are included in the mirroring/somatomotor network. Therefore, the AEON is engaged mainly in a nonlinear fashion during force processing. 


### Cerebellar Involvement in AEON 
  
The cerebellum is known to operate as a generalized forward controller ( ) that aids motor planning by predicting the sensory consequences of a motor act, such that a motor plan is coded in terms of an anticipatory sensory state ( ;  ;  ). In the present context, the sensory state would be provided by AO, and motor predictions would be based on internal cerebellar representations of the system (body and muscle) state ( ;  ). Thus, the cerebellum is well geared for simulating movements after receiving information about the movement of others, in terms of the appropriate sequence (timing) and force (gain) ( ;  ). 

The cerebellum is strongly interconnected with the cerebral cortex through 7 fundamental resting-state networks ( ). In particular,  ) clearly identified in the cerebellum distinct mirroring and mentalizing networks (as part of the larger somatomotor and default networks respectively) that were directly connected to homolog networks in the cerebral cortex. Confirming this network structure, Van Overwalle and colleagues reinterpreted their initial meta-analysis ( ) in terms of this network structure and found strong evidence for it ( ). In addition, a meta-analytical connectivity analysis revealed a strong distinction between anterior mirroring and posterior mentalizing areas in the cerebellum linked to classic mirror and mentalizing areas in the cerebral cortex ( ). This was confirmed by functional connectivity studies relating mentalizing and executive control functioning to the cerebellum ( ). Therefore, the cerebellum could also be involved in predicting the consequences and scope of other’s actions by reconstructing hypothetical events ( ;  ). 

It should be noted that, in our study, cerebellar responses were embedded in a larger cluster that included occipitotemporal areas. The combined activation in the AEON in lobules VI and VII and Crus I and II could be considered part of the ventral and dorsal attention, frontoparietal, and mentalizing/default networks compounded by the mirroring/somatomotor network from specific FREs ( ). Indeed, the linear FRE in lobules V, part of the mirroring/somatomotor network, reveals the involvement of cerebellum in motor functions ( ;  ;  ). The nonlinear effect in lobules VI and IX, part of both mirroring/somatomotor and mentalizing/default networks, would suggest the cerebellar involvement in the integration of motor processing and cognitive/emotional control ( ). 

Altogether, these effects confirm the cerebellar involvement in both mirroring and mentalizing networks. Moreover, these patterns of linear and nonlinear responses in the cerebellar components of the AEON are consistent with results showing that motor-generating areas respond linearly with GF, while associative and cognitive areas have a more complex relationship with GF. These response profiles may reflect distributed responses, mediated by connections that have been characterized structurally and physiologically in rodents, primates, and humans ( ;  ;  ;  ;  ;  ,  ). 


### High-Order Force–BOLD Relationships in the Cerebellum and Cerebral Cortex 
  
While a monotonic relationship between BOLD response and GF levels was found in primary motor areas (M1 and anterior cerebellum)—and could be related to the increased neuronal recruitment with increasing GF ( ;  )—nonlinearities were typically detected in areas implicated in multimodal integration and higher aspects of motor control (premotor, associative and sensory areas both in the cerebral cortex and the cerebellum), where a complex blend of signals converges to regulate motor output. It has been previously argued ( ) that second-order responses at intermediate force levels could be “metabolically optimal” and reflect more efficient processing in a motor regime requiring fewer corrective actions and less attention to sensory inputs. For example, nonlinearity may be due to fluctuation of attention levels modulating neural activity ( ). However, it should be appreciated that it is difficult to make detailed neurophysiological inferences based exclusively on fMRI signals. For example, nonlinearities (including nonlinear neuronal responses, nonlinear engagement of local inhibitory circuits, nonlinear mapping from neuronal activity to haemodynamic responses and finally, nonlinearities associated with the haemodynamic response function generating T2* signals) could arise at a number of different levels ( ;  ). The engagement of the underlying neuronal circuits, both in the cerebral cortex and the cerebellum, may benefit from further investigation using repetition-suppression fMRI paradigms ( ;  ) or multivoxel pattern analysis ( ) in conjunction with animal recordings and large-scale model simulations ( ). 


### Potential Limitations 
  
Despite the coherent functional framework emerging from this investigation, the relatively small number of subjects may affect its statistical power in detecting active areas. Although previous studies used similar numbers of subjects, a larger sample may be beneficial to confirm our findings. However, it is important to note that significant results obtained using a small sample usually mean that the effect size is large ( ). From a statistical point of view, the use of parametric models is an efficient way of accommodating nonlinear (neurometric) response functions within the established GLM framework ( ). However, given the concern that detection of active areas may have been reduced because of habituation due to multiple engagement in AO ( ), it would be useful to devise alternative paradigms in order to refine our AEON parametric characterization. 



## Conclusions 
  
The extended AEON identified in this fMRI study engages large-scale brain networks capable of remapping the visual detection of the actions, and also effort, of others onto the observer’s own motor system. These circuits, furnish not only understanding of other people’s goals, that is, the “mirror” effect ( ), but also the building blocks of executive control, impacting on various aspects of motor planning and programming, working memory, selective attention, and behavioral inhibition ( ;  ;  ;  ;  ;  ;  ). The cerebrocerebellar loops, using the motor system as a forward model ( ;  ;  ;  ;  ), could play a crucial role in sensorimotor prediction and internal simulation of movement. It has been suggested that the insular and cingulate cortices, activated in parallel to the sensorimotor loops, allow exteroception to be integrated with interoception ( ;  ;  ) and external observational cues to be transformed into internal sensorimotor plans. The identification of this extended AEON as a plausible substrate for imitation learning could facilitate and improve the clinical application of action observation in neurorehabilitation ( ;  ;  ). 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-39'>
<h2>39. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/19620621/' target='_blank'>19620621</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> The Selectivity and Functional Connectivity of the Anterior Temporal Lobes</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Cereb Cortex</p>
<p><strong>Publication Year:</strong> 2009</p>
<p><strong>DOI:</strong> 10.1093/cercor/bhp149</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/2837089/' target='_blank'>2837089</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study with healthy adult participants (n=12; ages 20–32). The task includes social-related processing: learning and encoding facts about people (person-fact encoding) contrasted with buildings and hammers. Whole-brain analyses were performed (random-effects ANOVA, conjunction analyses, cluster-size correction across the brain) and whole-brain domain-specific and domain-general activations and functional connectivity maps are reported. The paper is not an ROI-only report, not a review/meta-analysis, and does not involve clinical/neurologic or psychiatric populations. Therefore it meets all inclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
One influential account asserts that the anterior temporal lobe (ATL) is a domain-general hub for semantic memory. Other evidence indicates it is part of a domain-specific social cognition system. Arbitrating these accounts using functional magnetic resonance imaging has previously been difficult because of magnetic susceptibility artifacts in the region. The present study used parameters optimized for imaging the ATL, and had subjects encode facts about unfamiliar people, buildings, and hammers. Using both conjunction and region of interest analyses, person-selective responses were observed in both the left and right ATL. Neither building-selective, hammer-selective nor domain-general responses were observed in the ATLs, although they were observed in other brain regions. These findings were supported by “resting-state” functional connectivity analyses using independent datasets from the same subjects. Person-selective ATL clusters were functionally connected with the brain's wider social cognition network. Rather than serving as a domain-general semantic hub, the ATLs work in unison with the social cognition system to support learning facts about others. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (53824 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
It is now generally accepted that the representation of knowledge in the human brain depends on broadly distributed neural circuits that are differentiated by conceptual categories and their associated perceptual, motor, and affective properties ( ;  ;  ). At least 2 important questions remain unresolved, however. The first is whether a property-based model of the conceptual system is sufficient to support all conceptual phenomena (see   for a discussion of these issues). The second pertains to the systemic architecture linking these property regions. 

Recently, semantic hub models have grown in influence by offering answers to both of these questions ( ;  ). With regard to the first, these models assert that property circuits are necessary, but not sufficient to support conceptual knowledge; that in addition to property regions one must posit the presence of an amodal, domain-general representational hub. With regard to the second question, these models assert that the anterior temporal lobe is the domain-general hub through which property regions are connected. 

The anterior temporal lobes are regarded as the likely location of the semantic hub, largely on the basis of evidence from semantic dementia patients. Semantic dementia, a variant of frontotemporal dementia, is a progressive degenerative disorder characterized by damage to the anterior temporal lobes in its earliest stages, followed by widespread deterioration in more posterior temporal and frontal cortices ( ). Semantic dementia patients typically exhibit impaired performance on a variety of semantic memory tests across multiple categories of knowledge, whereas other cognitive abilities remain relatively intact ( ;  ;  ). Recent studies have shown that deficits in semantic dementia are more highly correlated with pathology along the lateral surface of the anterior temporal lobes, as compared with more medial temporal cortex ( ;  ;  ). 

Upon closer review, however, the neuropsychological evidence for an anterior temporal hub is not so clear as it might first appear. First, the pathology in semantic dementia is not restricted to the anterior temporal lobes. The pathology often extends up into frontal cortex (Hodges and Patterson 2007; Brambati et al. 2009). In addition, voxel-based morphometry demonstrates that semantic memory impairments in semantic dementia patients are as strongly correlated with pathology in the posterior fusiform as to pathology in the anterior temporal lobe ( ). Second, resection of the temporal lobes to treat intractable epilepsy does not lead to the catastrophic, domain-general semantic memory deficits one might predict if this region is the seat of conceptual knowledge ( ). Proponents of an anterior temporal hub argue that this simply reflects the fact that the surgery removes abnormal tissue that no longer serves its normal function due to pathology-related reorganization. Although this is undoubtedly true ( ), it is not, however, as if the surgery or damage to this region is without cognitive consequences. Anterior temporal resection, or damage due to conditions such as herpes encephalitis, is often associated with significant episodic memory deficits, as well as notable domain-specific semantic impairments typically including recognizing and naming famous and familiar people ( ;  ;  ;  ;  ;  ,  ;  ; Tsukiura et al. 2003). These findings suggest that the anterior temporal lobes support person-specific knowledge, with the left hemisphere being relatively more important for person naming. 

Given its prominent role in semantic hub models, one would expect a veritable mountain of neuroimaging evidence that the anterior temporal lobes are involved in conceptual processing. Significantly, the majority of imaging studies, whether using positron emission tomography (PET) or functional magnetic resonance imaging (fMRI), have not observed anterior temporal lobe activation during conceptual processing. Instead most find posterior temporal or frontal cortex activations (see  ;  ). To the extent that anterior temporal activation is observed during conceptual processing, it is usually in the context of social conceptual processing tasks ( , forthcoming; for review see  ) along with the medial prefrontal cortex (PFC), the posterior superior temporal sulcus (pSTS), the amygdala, and the precuneus; regions that are widely regarded as the brain's social cognition network ( ). For example, the anterior temporal lobe is frequently activated by theory of mind tasks ( ), as well as to famous and familiar faces (Sergent and Signoret 1992;  ;  ;  ;  ;  ;  ;  ;  ). The findings of   are of particular interest to the present study as they used a verbal fact recall task and observed that activity in the left anterior temporal lobe reflects recall of associations between names and faces, whereas right anterior temporal activity reflects recall of faces and person-related semantic information. 

Aside from the processing of social concepts, functional neuroimaging evidence for anterior temporal lobe involvement in conceptual processing has been inconsistent. Although this would seem to be a major challenge to the model, proponents of anterior temporal hub accounts cite 2 reasons for this dearth of evidence. First is the claim that fMRI is blind to the anterior temporal lobes ( ,  ). Relative to other brain regions, image quality in the anterior temporal lobes is degraded due to distortions of the magnetic field caused by air–tissue interfaces. Hub proponents have often addressed this problem by using PET imaging, which does not suffer from the same signal deficits, but with spatial resolution that is 2 to 3 times lower than that of most fMRI studies. Indeed, some PET studies have provided support for anterior temporal hub accounts by demonstrating anterior temporal activations during conceptual processing ( ;  ,  ;  ;  ;  ;  ). Additionally, a parallel literature has developed showing activation of the ATLs during sentence-level processing using both reading and auditory–verbal stimuli ( ;  ,  ;  ;  ;  ;  ,  ;  ). These studies often report that the ATL is activated for syntactically correct versus incorrect sentences that control for semantic content, thus indicating a potential role for the ATLs in the representation of syntax. 

A second argument put forth for why imaging studies of conceptual processing often do not find anterior temporal activation is that they employ tasks that require subjects to process concepts at a level that is too general to engage the region, or because they compare categories at different levels of specificity. By this account, the aforementioned person-knowledge effects in the anterior temporal lobes do not reflect social information processing per se, but rather the comparison of specific classification (e.g., famous faces) with more general classification (e.g., nonfamous faces, animals, tools) ( ;  ). 

Hub accounts claim that the anterior temporal lobes are the seat of human conceptual knowledge, storing amodal conceptual representations, irrespective of category. On the other hand, a different account asserts that the anterior temporal lobes are domain-specific and involved in the representation of person knowledge. Based on the issues and controversies described so far, directly testing these 2 accounts requires: 1) an fMRI study with adequate signal quality in the anterior temporal lobes; 2) processing of multiple object categories, at least one of which is people; 3) each processed at the same level of specificity; 4) with the same type of information across categories; and 5) a nonconceptual control condition. 

To meet these requirements, we used fMRI scan parameters optimized for imaging the anterior temporal lobes to study subjects while they learned facts about 4 different unfamiliar and unique people, places, and hammers, or performed a nonconceptual control task, in this case a Riser Letter Detection task. In the scanner, subjects were presented only written sentences describing the age, location, and occupation/usage of the people, places, and hammers, ensuring that all categories were processed at the same level of specificity and with the same types of information (e.g., see  ). If the anterior temporal lobes serve as a hub for domain-general conceptual processing, then we should expect to find anterior temporal lobe regions that respond equally to all 3 categories over and above the nonconceptual Riser Letter Detection Task control condition. If on the other hand the anterior temporal lobes are part of a domain-specific social information processing network, then we should expect to find anterior temporal regions that exhibit reliably greater activation for person information as compared with either building or hammer information. Additionally, if the social information processing account of the anterior temporal lobes is correct, then we should also expect that any person-selective regions in the anterior temporal lobes will exhibit reliable functional connectivity with the previously well-described social-processing circuit distributed throughout the brain. To test this last prediction, subjects also underwent a low-level Vigilance Task scan before performing the Fact Encoding Task scans. During this scan, subjects simply pressed a button whenever they saw a fixation mark change color, which occurred approximately once a minute. With this independent data set we were able to evaluate the entrained “resting-state” functional connectivity of the anterior temporal lobes. 
  
Examples of stimuli 
    

## Materials and Methods 
  
### Participants 
  
Twelve right-handed, native English-speaking volunteers were paid for their participation (7 females; age range, 20–32 years). All subjects completed health questionnaires and none reported a history of head injury or other neurological problems. In accordance with the National Institutes of Health Institutional Review Board protocols, all subjects read and signed informed consent documents. 


### Experimental Design 
  
Subjects performed 3 tasks while undergoing fMRI. During the first functional scanning run, subjects performed a simple Vigilance Task. In the subsequent 3 scanning runs, participants performed alternating blocks of the Fact-Learning Task and the Riser Detection Task. 

#### Person-Building-Hammer Fact-Learning Task 
  
Subjects were instructed to remember facts described by short sentences presented in black font against a white background. Each sentence described a fact about 4 unique but novel persons, buildings, or hammers, each labeled with a different proper name (see   for example stimuli). For each unique exemplar, subjects learned an age, location, and usage/occupation fact (e.g., “the gilbert building is forty-five years old”; “the gilbert building is located in baton rouge”; “the gilbert building is used for community meetings”). Our decision to have subjects learn the same attributes about the 3 different categories’ exemplars was motivated by our desire to have subjects process the 3 categories at the same level of specificity and using similar types of information. We believe this is important because hub proponents have claimed that greater item specificity leads to greater anterior temporal lobe activation ( ;  ). In addition, the stimulus sentences were balanced across categories for average number of words and letters per sentence. 

During the task instruction period prior to entering the scanner, subjects were presented with photographs of each unique entity and given its name but no other information. At the conclusion of the instruction period, subjects were again shown the photographs and asked to recall each exemplar's name. Subjects who were unable to recall the correct name upon seeing its photograph were given extra time to study the photo and learn the corresponding name. 

In the scanner, subjects only saw sentences; no pictures were presented. In each 18-s Fact-Learning Task block, subjects read sentences describing the 3 facts for a particular exemplar, each presented for 6-seconds. The presentation orders of sentences describing the individual exemplars were varied within and between categories, and presentation orders of the age, location, and usage/occupation facts were randomized within each block. Subjects were shown the 3 facts about an exemplar once during each run and 3 times over the course of the experiment. 

After being removed from the scanner, subjects were asked to first recall the critical information for each fact learned while in the scanner. They were presented with the same sentences they read in the scanner, but with the critical fact replaced with a blank space (e.g., “the gilbert building is located in _________”). After completing the recall trials, subjects were given a forced-choice recognition test for all facts. 


#### Entrained “Resting-State”/Vigilance Task 
  
To evaluate functional connectivity, we chose to use a simple vigilance task because it provides images of the brain's functional connectivity in a more constrained context than the typical “resting-state” scan, whereas keeping the subjects’ information processing load to a minimum. In the vigilance task subjects fixated a cross in the center of a grey background and pressed a button anytime the fixation mark changed colors (mean interchange duration = 60 s, range 30–90 s). These data provided an independent data set for exploring the functional connectivity of brain regions activated in the subsequent Fact-Learning Task scanning runs. 


#### Riser Detection Task 
  
Riser Detection letter strings were constructed by scrambling the letters used in the Fact-Learning Task, and contained the same number of spaces as the text strings in the Fact-Learning Task. By doing so, we controlled for the amounts of visual stimulation and visual scanning between the 2 tasks. There were 13 Riser Detection blocks in each scanning run. In each 18-s Riser Detection Task block subjects saw 3 letter strings, presented individually for 6 s in black font against a white background. The subjects’ task was to count the number of “riser letters” in nonword letter strings and press a button on a response box held in the right hand if the total was an odd number. Subjects were instructed that the letters b, d, f, h, k, l, and t are riser letters because they each have some portion that rises up above the tops of most other lower-case letters. This task is a modified version of the “feature detection task” used by  . 



### Imaging Details 
  
Stimuli were back-projected onto a screen at the head of the scanner and viewed by subjects via a mirror mounted on the head coil. Stimulus presentation and response collection both during scanning and the recall and recognition tests were controlled using Eprime (  www.pstnet.com  ). 

During the Vigilance Task scanning run, 140 echoplanar MR volumes depicting blood oxygenation level dependant (BOLD) contrast were collected with a 3T General Electric scanner. In each echoplanar image (EPI) volume 42 contiguous 3-mm thick slices were collected in the axial plane, ensuring whole-brain coverage (echo time [TE] = 27 ms, repetition time [TR] = 3500 ms, flip angle = 90°, voxel size = 2.3 mm × 2.3 mm × 3 mm). The 3 Fact-Learning Task runs used the same volume parameters, although 143 volumes were collected per run. High-resolution structural images were collected as the first and last scans in each session (TE = 6 ms, TR = 25 ms, flip angle = 15°, voxel size = 0.9 mm × 0.9 mm × 1.2 mm). A General Electric 8-channel send-receive head coil was used for all functional and structural scanning runs, with a SENSE factor of 2 used to minimize EPI distortions in anterior temporal regions while also reducing gradient coil heating over the course of the scan session. As demonstrated by measurements of temporal signal-to-noise (the ratio of the average signal intensity to the signal standard deviation), signal quality in the anterior temporal lobes was very good (see  ). 
  
Temporal signal-to-noise ratio (TSNR) maps showing EPI image quality over the anterior temporal lobes. The color gradient indicates the TSNR of the smoothed EPI time course data overlaid on the AFNI Talairach N27 atlas brain. TSNR was calculated by dividing the mean signal intensity at a voxel by the standard deviation of its signal time course. The color map is thresholded at a TSNR of 40, with all areas in red indicating a TSNR of at least 200. Simulations indicate that a TSNR of 40 (indicated in the map by light blue) is the minimum to reliably detect effects between conditions in fMRI data (Murphy et al. 2007). Note that virtually all of the anterior temporal lobes far exceed this threshold, with many anterior temporal regions exceeding a TSNR of 200. 
  
Prior to statistical analyses, image preprocessing was conducted using the AFNI software package ( ). The first MP–RAGE anatomical scan was coregistered to the second MP–RAGE, and the 2 were then averaged to produce a single high-quality anatomical image of the subject's brain. Next, each subject's EPI volumes were coregistered to the 130th volume of the final EPI scanning run, and smoothed in the axial plane with an isotropic 6-mm full width half max Gaussian kernel. Following application of slice time correction, and removal of the first 3 volumes from each run, EPI signal intensity measurements at each time point were normalized to reflect the percent signal change from the voxel's signal time course mean. 


### fMRI Statistical Analyses 
  
Multiple regression was used to analyze the Fact-Learning Task data. The regression model included one regressor for each of the 3 fact categories (people, buildings, and hammers) with the Riser Detection Task periods composing the signal baseline. The 3 task regressors were constructed by convolving a box-car function with a width of 18-s beginning at the onset of a condition's blocks with a gamma-variate function to adjust the predictor variable for the delay and shape of the BOLD response. In addition, regressors of no interest were included to account for each run's signal mean, linear, quadratic, and cubic signal trends, as well as 6 motion parameters (3 translations and 3 rotations). 

Subjects’ beta maps for each condition were then transformed to Talairach space, and resampled to a 2-mm isotropic resolution. Finally, a repeated measures random effects ANOVA was used on the aggregated group data to evaluate differences between conditions at the population-level. 

We used the conjunction analysis methods described by   to identify regions where the activity patterns across conditions conformed to domain-specific and domain-general response patterns. A domain-specific response was defined as a cluster of activity where a particular condition exhibited reliably greater activity than each of the other Fact-Learning Task conditions. For example, to qualify as a person-selective region, each voxel in a cluster of activity had to satisfy 2 separate statistical tests: person > building AND person > hammer. Because this conjunction assumes a particular directionality, each of the individual tests were thresholded at   P   < 0.05 one-tailed within the 3 regions of interest (ROIs) described below, and at   P   < 0.005 one-tailed outside the ROIs. As described by  , the conservative estimate of the probability of a conjunction is the   P  -value associated with the minimum statistic among the conjoined tests, which in this case is   P   < 0.05 one-tailed in the ROIs and   P   < 0.005 one-tailed outside the ROIs. To implement corrections for multiple comparisons at the   P   < 0.05 level, we used Monte Carlo simulations implemented in AFNI's AlphaSim to identify the required cluster-size threshold, given the voxel-wise probability and the volume in the statistical map (see below) separately for each of the tests in a conjunction. Because the clusters of activity for each test in a conjunction were corrected for multiple comparisons, and should thus be regarded as reliable, so too can the intersections between the clusters. Nevertheless, because it is possible that small areas of intersection between clusters from different statistical tests could be induced by spatial smoothing and resampling, we applied a small cluster-size threshold of at least 10 voxels (defined in the original scanning resolution) on all areas of conjunction. 

In contrast to the domain-specific clusters, domain-general clusters were defined as regions where responses for all 3 categories were reliably greater than the Riser Detection Task, but where activity did not differ between categories in the Fact-Learning Task. To this end, we used conjunction analyses similar to those used to identify domain-specific clusters. First we identified regions where each of the categories in the Fact-Learning Task responded reliably above the Riser Detection Task with a   P  -value of 0.05 one-tailed in the ROIs and   P  -value of 0.005 one-tailed outside the ROIs, again with each test corrected separately for multiple comparisons at the   P   < 0.05 level using cluster-size correction (see below). Importantly, the conjunction probability for domain-general clusters was equal to the conjunction probability of the domain-specific clusters. Finally, to remove regions showing a bias toward a particular category, a mask was applied to the data to remove all regions exhibiting a difference with   P   < 0.25 between any 2 categories in the Fact-Learning Task. Again, as with the domain-specific regions, a cluster-size threshold of at least 10 voxels was applied to all areas of conjunction to ameliorate concerns that smoothing or resampling induced the observed domain-general clusters. 

There were 3 region of interest volumes used in the cluster-size threshold calculations: the anterior temporal lobes, the posterior middle temporal gyrus, and the parahippocampal gyrus. The anterior temporal lobes were defined as all areas in the temporal lobes anterior to the limen insula ( ; located at approximately   y   = 3 in the left hemisphere and   y   = 5 in the right hemisphere of the AFNI Talairach N27 atlas brain). This ROI included only temporal cortex, and did not include any portion of the amygdala. Within the volume of this region, defined bilaterally, a cluster-size threshold for individual tests among the conditions was determined to be at least 1056 mm  (132 resampled voxels sharing at least one edge). The posterior middle temporal gyrus between   y   = −40 and   y   = −69 was selected as a ROI given its association with tool processing (for review see  ). Within this region, the cluster-size threshold was determined to be at least 1216 mm  (152 voxels sharing at least one edge). The parahippocampal gyrus was also selected as a ROI given its association with location representation ( ;  ). Within this region, the cluster-size threshold was determined to be at least 992 mm  (124 voxels sharing at least one edge). Finally, outside these 3 ROIs, clusters of activity had to exceed a size threshold defined by the volume of the brain minus the volumes of the 3 ROIs, rendering a cluster-size threshold of at least 848 mm  (106 voxels sharing at least one edge). (The cluster size threshold for the regions outside the ROIs is smaller than the cluster size threshold within the ROIs because the   P  -value threshold outside the 3 ROIs is more stringent by an order of magnitude;   P   < 0.05 vs.   P   < 0.005.) 

Functional connectivity analyses were implemented on the subjects’ Vigilance Task scanning run, with seed voxels determined by the highest average   t  -values across the statistical contrasts used in the group conjunction analyses. The connectivity analyses proceeded in the following manner. First, at the subject-level, multiple regression was used to model the run's signal mean, linear, quadratic, and cubic signal trends, as well as 6 motion parameter regressors. In addition, the average signal time course from the subject's ventricles was included to further account for global signal changes. The residual time course for each voxel was then used in the subsequent analyses. Time course residuals for the anterior temporal lobe seed voxels were then used as predictors in separate regression analyses, to produce a map of the correlations between each voxel in the brain and a given seed voxel. These   r  -values were then converted to   Z  -values using Fisher's   r  -to-  Z   transformation. Next, the subjects’   Z  -maps were included in a random effects, one-sample t-test to identify voxels whose means differed from zero with   P   < 0.0005. Finally, these statistical maps were corrected for multiple comparisons at the   P   < 0.05 level by applying a cluster-size threshold of at least 296 mm  (37 voxels sharing at least one edge). The resulting maps show brain regions where activity across subjects was reliably correlated with a seed-voxel's time course while subjects performed the Vigilance Task scanning run, a dataset that was independent of the Fact Encoding Task scanning runs. 



## Results 
  
### Behavioral Results 
  
Responses to color change events in the Vigilance Task were quick and accurate (RT: M = 614 ms, SD = 159 ms; detection accuracy: M = 70%, SD = 22%). In contrast, subjects found it difficult to provide responses on the Riser Detection Task within the allotted time for each trial (RT: M = 4768 ms, SD = 130 ms; detection accuracy: M = 26%, SD = 13%, responses occurring earlier than 2 standard deviations from the response mean were filtered out, as were responses occurring later than the 6-second trial duration). The riser detection accuracy scores reflect the fact that subjects had to perform the task under significant time constraints, rather than indicating that they were performing the task poorly. The letter strings presented to subjects were rather long because they were constructed by scrambling the fact-learning sentences, and as a result it was difficult for subjects to provide responses before the stimuli disappeared from the screen. 

After scanning, subjects demonstrated good recall of the information presented during the Fact-Learning Task (Person fact recall: M = 72%, SD = 17%; Building: M = 63%, SD = 17%; Hammer: M = 65%, SD = 21%). Although subjects recalled more person facts than building facts,   t  (11) = 4.31,   P   < 0.005, person and hammer fact recall were equivalent,   t  (11) = 1.13,   P   = 0.28, as was recall of building and hammer facts,   t  (11) = 0.38,   P   = 0.71. As with recall, recognition performance was good for all categories (Person fact recognition: M = 87%, SD = 17%; Building: M = 77%, SD = 17%; Hammer: M = 74%, SD = 24%). Although subjects recognized more person facts than hammer facts,   t  (11) = 2.55,   P   < 0.05, person and building fact recognition were not reliably different, t(11) = 1.88,   P   = 0.09, nor were recognition of building and hammer facts,   t  (11) = 0.49,   P   = 0.63. 


### The Anterior Temporal Lobes are Engaged while Acquiring Person Knowledge 
  
Two lateral anterior temporal regions exhibited person-selective responses (  A  ,  ). The 2 clusters, located bilaterally in homologous locations in the temporal pole and superior temporal gyri, responded more during person-fact encoding than during building-fact or hammer-fact encoding. Aside from these 2 regions, there were no other category-selective responses in the anterior temporal lobes. To demonstrate the robustness of the person-selective effects to a different voxel selection strategy ( ), and to assess whether statistical mapping was even necessary to observe person-selective responses in this region, we used an anatomical region of interest approach to examine the average response across all voxels in the anterior temporal lobe ROIs for each of the 3 conditions. As can be seen in   B  , person-fact encoding produced greater activation than either building- or hammer-fact encoding across the entirety of the left and right anterior temporal lobes, but no differences were observed between buildings and hammers (left anterior temporal: person > building,   t  (11) = 1.95, one-tailed   P   = 0.04; person > hammer,   t  (11) = 2.27, one-tailed   P   = 0.02; building versus hammer,   t  (11) = 0.65, 2-tailed   P   = 0.53; right anterior temporal: person > building,   t  (11) = 2.10, one-tailed   P   = 0.03; person > hammer,   t  (11) = 2.75, one-tailed   P   = 0.01; building versus hammer,   t  (11) = 1.14, 2-tailed   P   = 0.29). 
  
Anterior temporal lobe activations 
      
Person-selective responses in the anterior temporal lobes. (  A  ) person-selective clusters in the anterior temporal lobes identified using conjunction analyses. The rendered surfaces show the person-selective clusters in the left and right hemispheres where person > building AND person > hammer with   P   < 0.05 and cluster-size corrected for the volume of the anterior temporal lobes. (  B  ) Activity in the anterior temporal lobe ROIs. The rendered surfaces show the extent of the anterior temporal ROIs in the left and right hemispheres. The bar graphs demonstrate the average percent signal change across subjects in the left and right anterior temporal ROIs relative to the nonconceptual (riser detection) control task. In both ROIs, the responses to person-fact encoding were reliably greater than the responses to building- or hammer-fact encoding. Responses during building- and hammer-fact encoding were not different from each other. Error bars on bar charts in both panels indicate ±1 standard error of the subject means. 
  
No domain-general responses were observed anywhere in the anterior temporal lobes. In other words, there were no regions in the anterior temporal lobes where activity was equivalent for person, building, and hammer fact learning and where these 3 conditions produced reliably greater activation than the Riser Detection Task, our nonsemantic control condition. 


### Fact Encoding Effects Outside the Anterior Temporal Lobes 
  
Although the current experiment's focus is the function of the anterior temporal lobes, domain-specific and domain-general responses were observed in other brain regions ( ). 
  
Domain-specific and domain-general responses outside the anterior temporal lobes indentified using conjunction analyses. Domain-general responses (shown in gold) were observed in various regions outside the anterior temporal lobes, including the left inferior and superior frontal gyri, the left middle temporal gyrus, and the hippocampus. A hammer-selective cluster (shown in blue) was observed in the left middle temporal gyrus (L pMTG) immediately posterior to a domain-general cluster. More medially, building-selective clusters (shown in green) were observed in left and right middle occipital gyri. Person-selective clusters (shown in red) were observed along the midline in the medial PFC and the precuneus, among other regions. All clusters are corrected for multiple comparisons. 
  
#### Domain-Specific Encoding Effects 
  
Outside the anterior temporal lobes, person-selective encoding effects were observed in regions commonly implicated in social processing, including the medial PFC, precuneus and posterior cingulate, and the right pSTS. In addition, the superior parietal lobule was also activated bilaterally, as was the left insula (see  ). Contrary to our prediction, place-selective effects were not observed in the parahippocampal gyrus. Instead, large areas of place-selective activity were observed bilaterally in the lingual, cuneus, and middle occipital gyri, as well as the right cerebellum. Finally, as predicted, hammer-selective activity was observed in the left posterior middle temporal gyrus. 
  
Domain-specific and domain-general activations outside the anterior temporal lobes 
    

#### Domain-General Encoding Effects 
  
Although domain-general encoding effects were not observed in the anterior temporal lobes, other brain regions did exhibit these effects (see  ). For example, a large area of domain-general activation was observed to stretch from the left inferior frontal gyrus into the middle frontal gyrus. Additionally, domain-general activation was observed in the left hippocampus, the left middle temporal gyrus, left angular gyrus, and the right cerebellum. 



### Functional Connectivity: Anterior Temporal Person-Selective Regions are Part of the Wider Social Cognitive Network 
  
Further support for the person-selective nature of the anterior temporal lobes comes from functional connectivity analyses using independent data sets. We used the Vigilance Task scanning runs to examine the functional connectivity with the peak activations in the left and right anterior temporal person-selective clusters identified in the Fact-Learning Task. The left anterior temporal person-selective cluster was functionally connected with brain regions frequently implicated in social cognition, including the medial PFC, the pSTS, the amygdala, and the precuneus/posterior cingulate bilaterally, and in the left lateral portion of the fusiform gyrus ( ). In addition to the other social-processing regions, activity in the left anterior temporal person-selective cluster was tightly coupled with activity in the corresponding region in the right anterior temporal lobe. Finally, activity in the left anterior temporal person-selective region was correlated with activity in regions known to support more general information processing, including the left inferior frontal gyrus and the left hippocampus (see   Supplemental Table 1   for a complete list of regions functionally connected with the left anterior temporal seed voxel). As with the left hemisphere, activity in the right anterior temporal person-selective cluster was correlated with activity in regions previously implicated in social processing, including the medial PFC bilaterally, the amygdala bilaterally, the left posterior cingulate/precuneus, the left fusiform gyrus, and the left anterior temporal lobe ( ). In addition, this region was functionally connected with a host of more general information processing areas, including the left inferior frontal gyrus, the left perirhinal cortex, and the superior frontal gyrus bilaterally (see   Supplemental Table 2   for complete list). 
  
The person-selective clusters in the anterior temporal lobes are functionally connected with the wider social cognition network. Color overlays indicate clusters of functional connectivity with the anterior temporal seed voxels measured in the independent Vigilance Task scanning run. The left and right anterior temporal seed voxels were identified as those voxels in each hemisphere with the highest average   t  -value for the person > building and person > hammer   t  -maps in the Fact-Learning Task scanning runs. The depicted functional connectivity   t  -maps were obtained as follows. First, for each subject a Pearson correlation map was constructed showing correlation between each voxel and an anterior temporal seed voxel. Second, these   r  -maps were converted to   Z   score maps. Finally, these   Z  -maps were included in a random effects, one-sample   t  -test to identify voxels whose means differed from zero with   P   < 0.0005 and cluster-size corrected for multiple comparisons across the whole brain at   P   < 0.05. 
  


## Discussion 
  
### Person-Selectivity in the Anterior Temporal Lobes 
  
In the present study the anterior temporal lobes exhibited strong category-selectivity while subjects learned facts about people, relative to building- and hammer facts. The person-selective responses in the conjunction analyses were observed in nearly identical anterolateral regions of the superior temporal gyri and temporal poles in the 2 hemispheres. Domain-general effects were not observed in the anterior temporal lobes, although they were found in other brain regions, including the hippocampus and left inferior frontal gyrus. The absence of domain-general anterior temporal effects in our data cannot be due to poor signal quality because we observed statistically reliable clusters of activity in the lateral anterior temporal cortex, the anterior temporal region with the highest temporal signal-to-noise ratios in the present data ( ), and the area predicted to be the domain-general semantic hub based on pathology in semantic dementia ( ;  ;  ). 

Eschewing cluster mapping altogether, we evaluated separately for each hemisphere the average response of the entire temporal lobes anterior to the limen insula. Even when using this gross anatomical-ROI approach, the anterior temporal lobes responded selectively when encoding information about people. In both hemispheres, the response profile was highly person-specific, with little difference in the responses to buildings and hammers. 

The conjunction analysis was an extremely conservative measure requiring significantly greater activity for the person-fact learning than building-fact learning and greater activity for the person-fact learning than hammer-fact learning. Additionally, each of these tests independently had to reach significance after correction for multiple comparisons. The fact that we replicated the person-fact selectivity in the ROI analysis, which aggregated activity across the entire anterior temporal lobe, demonstrates the robustness of this effect. Including all the voxels in the anterior temporal lobe did not wash out the statistically reliable categorical effects observed in the conjunction analysis. 

The findings of the cluster-mapping and anatomical-ROI analyses were further strengthened by the functional connectivity profiles of the anterior temporal lobes, with the present study being the first to describe the functional connectivity of this region. The anterior temporal person-selective clusters, identified in the Fact-Learning Task scans, were found to be functionally connected with virtually the entire social cognition network, as measured during the independent Vigilance-Task scan. The functional connectivity findings reported here agree with tracer studies in the macaque, where strong anatomical connectivity is observed between the temporal pole and the amygdala, superior temporal gyrus, area TE (potential monkey homologue of human fusiform gyrus), and the medial frontal cortex ( ;  ). 

Given the results of the conjunction analyses, the anterior temporal ROI analyses, and the functional connectivity analyses on independent data, we can be confident that the person-selectivity observed in the anterior temporal lobes was not a product of the particular statistical-mapping procedure, or the particular task, or the particular stimuli presented to subjects, or even the particular seed voxel within the anterior temporal lobe. Rather the results appear to reflect this region's underlying function and connectivity within a network supporting social cognition. 


### Social Conceptual Processing in the Anterior Temporal Lobes 
  
Recently,   reported activation of the anterior superior temporal gyrus when subjects made meaning-relatedness judgments for social concepts. In the present study, the person-specific effects in the anterior temporal lobe stretched from the middle temporal gyrus up into the superior temporal gyrus. Given the differences in the paradigms and stimuli, it is remarkable how much agreement exists between our findings, and those reported by  . 

Zahn and colleagues observed a reliable difference between social and animal concepts in the superior temporal gyrus, with much weaker effects of each condition versus fixation in the middle temporal gyrus. They speculate that there may exist an inferior–superior gradient for multisensory versus abstract person-specific knowledge, with the former located in middle temporal gyrus, and the latter located in the superior temporal gyrus. Although this is one explanation for these findings, it is not the only explanation. Alternatively, it could be that the anterior temporal lobes are relatively more responsive to animate than inanimate entities, with the superior temporal gyrus being particularly responsive for human-animate attributes (such as the social abstract concepts used by Zahn et al.). By this account, we observed more inferior middle temporal activity, in addition to the superior temporal activity, because we compared animate to inanimate entities (e.g., people vs. buildings and hammers). This account also finds support in the both our ROI analyses using the entirety of the anterior temporal lobes, and in the functional connectivity findings, which showed correlated spontaneous fluctuations between our anterior temporal lobe person-selective regions and the wider social/animacy network. 

Yet another possibility is that in Zahn and colleagues’ data the signal quality might be poorer in middle temporal gyrus than in superior temporal gyrus. Zahn and colleagues only observed middle temporal activity in statistical comparisons that presumably have much higher contrast-to-noise ratios, namely the social and animal concepts versus a simple fixation baseline. Note, however, that this contrast does not control for many nonconceptual differences between the task performed by subjects (e.g., reading words and making meaning-relatedness judgments) and the fixation baseline condition. By this account, we may have observed more inferior effects, in addition to the superior temporal effects, because of better signal quality over this region (e.g., see   and refer to Imaging Details section). 

Although we are not certain which of the above-described explanations account for the differences between our findings and those reported by Zahn and colleagues, we strongly believe that the overall findings of the 2 studies exhibit significant agreement and are mutually supportive. 


### Person-Selectivity in the Anterior Temporal Lobes Does Not Simply Reflect Encoding Effort 
  
Given that subjects generally remembered more person facts than building or hammer facts, one might argue that the person selectivity in the anterior temporal lobes simply reflects encoding effort. There are at least 5 arguments against this account. First, not all brain regions responded selectively for person-fact encoding. Indeed, as just described, many regions responded selectively to other categories. This suggests that there was not a general encoding effort effect for the person facts. Second, regions such as the left inferior frontal gyrus and the hippocampus that would be expected to show a task difficulty or encoding effort effect do not exhibit selectivity for person-fact encoding, but rather responded in a domain-general fashion (e.g., responded equally to all categories). Third, given that we have much more experience learning new information about people, relative to buildings and hammers, it seems unlikely that one would find more activation for learning person facts relative to the other categories if the activity in this region is driven by encoding effort. Fourth, better person fact recall (vs. building fact recall) or recognition (vs. hammer fact recognition) does not guarantee differences between conditions at encoding. The recall and recognition differences could be entirely mediated by storage or retrieval processes. Finally, and perhaps most convincingly, using independent, non-task-related data we observed functional connectivity between the person-selective clusters in the anterior temporal lobes and the wider social cognition network, a finding that strongly supports our interpretation that the activation observed in this area reflects its role in social cognition, not encoding effort. 


### Domain-Specificity Outside the Anterior Temporal Lobes 
  
Outside the anterior temporal lobes, we observed other domain-specific effects. Encoding hammer facts selectively engaged a posterior region of the left middle temporal gyrus. This finding was predicted a priori, given that the region is consistently activated during conceptual processing of tool categories and tool-related verbs using both pictorial and linguistic stimuli (e.g.,  ;  ; for recent reviews see  ;  ;  ). Large place-selective responses occurred bilaterally in the cuneus and up into middle occipital gyrus. This region, near the transverse occipital sulcus, has been previously implicated in scene perception, navigation, and the representation of large-scale features (such as buildings) in the visual environment ( ;  ;  ). Finally, in addition to the anterior temporal lobes, learning facts about people elicited category-selective responses in other social cognition regions. Person-selective responses were observed in the medial PFC, a region that supports mentalizing about others’ mental states ( ;  ); the right pSTS, a region commonly implicated in the perception and conceptualization of biological motion ( ,  ); and the precuneus, a region implicated in social perspective-taking and representation of the self ( ). 


### Domain-General Responses 
  
We found no evidence for a domain-general hub in the anterior temporal lobes. This does not mean however that hub theories in general are incorrect. Rather, it only means that if a domain-general representational hub exists in the brain, it is not in the anterior temporal lobes. In fact, we did find domain-general areas. One region was a large area in left frontal cortex stretching from the inferior frontal gyrus up to the middle frontal gyrus. Based on findings from earlier research, this region serves as a control-center for conceptual processing, guiding retrieval and postretrieval selection of property information stored in posterior cortex, irrespective of category ( ;  ;  ). Similarly, domain-general responses were observed in the hippocampus, a region long known to support the acquisition of new knowledge ( ). It is unlikely that either of these regions serve as representational hubs in the sense previously attributed to the anterior temporal lobes. For example, although damage to the left inferior frontal gyrus results in word-finding deficits, it does not disrupt conceptual knowledge per se ( ;  ;  ). Similarly, although damage to the hippocampus greatly affects new learning, it does not result in conceptual deficits for previously acquired knowledge ( ). 

We also observed domain-general responses in the left middle temporal gyrus (immediately anterior to the domain-specific “hammer” cluster), the left angular gyrus, and the right cerebellum, all regions shown previously to be engaged when subjects learn new facts and associations ( ;  ). Of these regions, the left middle temporal gyrus may be of particular interest in future studies, as it is often implicated in domain-general conceptual processing ( ;  ). 


### Conceptual Processing during the Fact-Learning Task 
  
Semantic memory/conceptual processing involves retrieving information about objects and words that is not immediately available in a stimulus itself. This is perhaps most easily recognized in the case of conceptual processing for words, where the word itself is merely an arbitrary symbol, and so understanding its meaning necessarily requires attributions and inferences about the word's referent. A bedrock principle in cognitive psychology is that reading words automatically activates word meaning (e.g., consider the ubiquity of Stroop effects). Thus, reading the sentence stimuli in our task engaged our subjects’ conceptual systems. Given this, we simply needed to ensure that they actually read the sentence stimuli. To accomplish this we told subjects to remember the information they learned because their memory would be tested at the end of the study. 

Our task allowed us to directly compare 3 familiar categories for which subjects had a great deal of previously acquired conceptual knowledge, while being reasonably certain that subjects processed the categories at the same level of specificity and with the same amount of knowledge about the specific exemplars presented in the scanner. Although the specific exemplars were unfamiliar, subjects’ comprehension of the sentence stimuli meant that the task engaged retrieval of pre-existing category-knowledge. Good evidence for this comes from the neuroanatomical distribution of the activations we observed. Consider the person-fact learning condition. Learning facts about specific peoples’ occupations, ages, and places of birth activated regions previously demonstrated to represent biological motion (posterior STS;  ,  ), mentalizing about other's mental states (medial PFC;  ;  ), and social perspective-taking and representation of the self (precuneus;  ). The facts learned by subjects about a particular person did not contain references to that person's physical motions, their mental states, or social interactions, and thus these activations are neural signatures of conceptual inferences about the exemplars. Similarly, the hammer facts never described the hammers in motion, yet we can deduce that subjects were engaged in conceptual inference about the hammer exemplars because we observed activation in a region of the middle temporal gyrus known to represent nonbiological (tool) motion ( ). These activations further strengthen our confidence that the fact-learning task was successful at engendering conceptual processing, and warrants our claims about the anterior temporal lobe's role in conceptual processing. 

Because all 3 conditions required fact learning, comparisons among the categories should cancel-out domain-general conceptual processes, leaving only domain-specific conceptual processes. Now, in light of this, consider the claims of the domain-general semantic hub account, which asserts that the anterior temporal lobes are the domain-general hub of the human conceptual system irrespective of the task context through which conceptual information is accessed. In fact, hub models explicitly claim that the anterior temporal semantic hub is engaged in any and all varieties of conceptual processing tasks (e.g., see  ). If this is correct, then we should have observed greater anterior temporal lobe activation for all categories compared to the nonsemantic control task, and equivalent activations for all categories in our task. We did not. This leaves us with only 2 options. The first option is that the anterior temporal lobes are domain-specific for person knowledge during sentence comprehension, but the same tissue is domain-general in other task contexts (perhaps after consolidation from the hippocampus to the neocortex), and also exhibiting strong functional connectivity with the wider social cognition network. The second option is that the anterior temporal lobes are domain-specific for person knowledge regardless of the conceptual processing context, and also strongly functionally connected to the wider social cognition circuit. Option one assumes a remarkable switch in domain selectivity from one task context to another, and we can think of no evidence for such a switch either in the anterior temporal lobe or indeed anywhere else in the brain. Option 2 is also a more parsimonious account. 



## Conclusion 
  
Rather than serving as a domain-general conceptual hub, the anterior temporal lobes appear to support person knowledge. Using both typical statistical-mapping approaches, as well as gross anatomical-ROI analyses, we observed person-selectivity in both the left and right anterior temporal lobes. Further, in independent data sets these regions were functionally connected with the social cognition network. Future studies should seek to better understand the information content within the anterior temporal lobes. In this regard, it is important to note that there exists both neuropsychological and neuroimaging evidence that this regions plays a critical role in the representation of unique entities ( ;  ;  ;  ). The present study compared responses among different categories of unique entities, rather than between unique and nonunique entities. As such, it will be important for future studies to clarify the relationship between the unique entity findings, and the results reported here. 

More generally, the findings reported here help to clarify the architecture of the human conceptual system. As demonstrated in many earlier studies, conceptual knowledge is supported by a widely distributed network of property regions that represent in part the content of conceptual representations, as well as auxiliary regions such as the hippocampus and left inferior frontal gyrus that support memory acquisition and retrieval processes generally. The precise architecture of this system, namely the nodes through which regions are functionally connected, remains an important and controversial question. In the present study, no evidence was obtained in support of the claim that the anterior temporal lobe is a domain-general representational hub. Rather, the findings strongly suggest that the anterior temporal lobe is a component in a network supporting an important class of knowledge: social concepts ( ). Describing how the components of this and other conceptual processing networks connect and communicate is a major challenge for all neural theories of the human conceptual system. Developing a better understanding of both the functional and structural connectivity among these regions, and how these connections develop over the lifespan and change with experience, remains a critical and unfinished task. 


## Supplementary Material 
  
 Supplementary material   can be found at:   http://www.cercor.oxfordjournals.org/  


## Funding 
  
. 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-40'>
<h2>40. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22768085/' target='_blank'>22768085</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Neural Network Development in Late Adolescents during Observation of Risk-Taking Action</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2012</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0039527</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3387168/' target='_blank'>3387168</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study meets all inclusion criteria: (1) It used functional MRI during a social-related task — participants observed others’ hand actions (risk-taking vs. safe), an established social/action-observation paradigm probing social cognition/emotional processing. (2) Participants were healthy late-adult adolescents (18.1–22.8 years), within the 18–60 age range. They were screened for neurological/psychiatric disorders. (3) Results are reported as whole-brain analyses using SPM (whole-brain contrasts, conjunctions, and cluster-based inference), not ROI-only analyses. No exclusion criteria are violated (not a review/meta-analysis, no clinical sample, no ROI-only reporting). Therefore the study is eligible for inclusion in the meta-analysis of fMRI studies on social-related processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Emotional maturity and social awareness are important for adolescents, particularly college students beginning to face the challenges and risks of the adult world. However, there has been relatively little research into personality maturation and psychological development during late adolescence and the neural changes underlying this development. We investigated the correlation between psychological properties (neuroticism, extraversion, anxiety, and depression) and age among late adolescents (  n   = 25, from 18 years and 1 month to 22 years and 8 months). The results revealed that late adolescents became less neurotic, less anxious, less depressive and more extraverted as they aged. Participants then observed video clips depicting hand movements with and without a risk of harm (risk-taking or safe actions) during functional magnetic resonance imaging (fMRI). The results revealed that risk-taking actions elicited significantly stronger activation in the bilateral inferior parietal lobule, temporal visual regions (superior/middle temporal areas), and parieto-occipital visual areas (cuneus, middle occipital gyri, precuneus). We found positive correlations of age and extraversion with neural activation in the insula, middle temporal gyrus, lingual gyrus, and precuneus. We also found a negative correlation of age and anxiety with activation in the angular gyrus, precentral gyrus, and red nucleus/substantia nigra. Moreover, we found that insula activation mediated the relationship between age and extraversion. Overall, our results indicate that late adolescents become less anxious and more extraverted with age, a process involving functional neural changes in brain networks related to social cognition and emotional processing. The possible neural mechanisms of psychological and social maturation during late adolescence are discussed. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (48242 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
 Late adolescence   is a unique and important period for human development. Erikson (1994) examined the concept of   identity   in relation to late adolescence  ,  . Although Erikson considered identity formation to be a life-long process, he emphasized late adolescence as a key stage in his developmental theory, constituting a particular critical development period when a sense of personal and social identity becomes integrated through ‘identity crisis’. Newman and Newman (2007, 2009) redefined Erikson’s criteria regarding developmental stages, dividing adolescence into early and late adolescence, such that late adolescence (18–24) is distinguished from adolescence (12–18)  ,  . Erikson theorized that identity develops when young people are given a psycho-social ‘moratorium’, referring to an opportunity in which they can experiment with different social roles before making permanent commitments to an occupation, to intimate relationships, to social groups and communities, and to a philosophy of life. This ‘moratorium’ period   closely corresponds to ‘college age’; attending college provides students with consciousness-raising experiences to learn about themselves and others through exposure to diverse perspectives, opinions, and ways of living  ,  ,  . Examining psychological changes in college-age late adolescents is valuable in elucidating the ongoing process of human identity integration or maturity  ,  ,  . 

Understanding the late adolescence period is also of particular importance because dynamic psychological changes, such as human identity integration or maturity, continue throughout this period, as social and affective instabilities are overcome. Contrary to a long-held assumption that the brain is largely mature by the end of childhood, recent neuroimaging studies have provided increasing evidence that adolescence involves profound brain growth and change  ,  . For example, increases in white matter volume have been reported throughout childhood and adolescence, particularly in the prefrontal and parietal cortices (e.g.,  ,  ,  ,  ,  ,  ,  . In addition, grey matter volume has been reported to increase in the prefrontal and parietal cortices during the preadolescent stage, followed by a steady decline during late adolescence  ,  . These findings indicate that brain development in adolescence is not linear, and that the brain volume of a typical early adolescent is measurably different to that of a typical late adolescent. In addition, these findings suggest that brain regions involved in planning, decision-making, cognitive reasoning, or controlling impulses and emotions undergo refinement through adolescence at least into a person’s twenties (i.e., late adolescence). 

In addition to the morphometric studies discussed above, behavioral techniques have been used to examine brain development during late and post adolescence. For example, a behavioral study using a mentalizing task requiring theory of mind and executive function reported that social abilities like ‘theory of mind’ continue to improve from adolescence to adulthood  , further suggesting that developmental changes continue throughout the late adolescent phase. Another study using a gambling task reported that the rate of risky choices did not significantly change between early (12–15 y.o.) and mid (15–18 y.o.) adolescence, but was significantly reduced in adulthood (25–35 y.o.)  . These findings indicate that a profound ‘shift’ in cognitive or emotional regulation ability during late adolescence may occur in the transition from adolescence to adulthood. Functional neuroimaging studies of mental-state attribution have reported decreases in frontal cortex activity between adolescence and adulthood  , providing further evidence that a developmental shift occurs during late adolescence, i.e., from adolescence to adulthood. A similar discrepancy between adolescence and adulthood has been observed in the neural correlates of emotional processing. For example, in processing fearful facial expressions, adolescents were found to exhibit a strong reliance on the emotional network in the brain, while adults tended to rely more on an attentional network  . In addition, adults, compared with adolescents, exhibited decreased activity in the hippocampus during the encoding of negative images  . In accord with the studies discussed earlier, this evidence indicates that late adolescence is important as a transitional period from adolescence to adulthood, involving the maturation of emotional regulation and cognitive processing in social situations. 

Several studies have reported the usefulness of a five-factor model that describes five distinct personality traits for parsing personality constructs in late adolescents  ,  ,  . Of the five factors, neuroticism and extraversion are of particular interest, as they are believed to be crucial for the development of healthy social interactions and to exert an over-arching influence on affect and mood. Extraversion is characterized by an increased tendency to be optimistic, and to experience positive emotions and enhanced sociability. Conversely, neuroticism is defined as an increased tendency to worry and to experience psychological distress, accompanied by negative affect and over-sensitivity to negative cues. Functional neuroimaging studies have demonstrated that task-evoked brain activity varies with neuroticism and extraversion scores in the prefrontal cortex and cingulate cortex  ,  ,  ,  ,  . Thus, these two personality traits are strongly associated with emotional experience and may modulate emotion-evoked brain activity  . 

Development of personality traits occurs not only in adulthood, but also in childhood and adolescence  . Neuroticism and extraversion are consistently included in personality models, including 3-factor and 5-factor models  ,  ,  . In addition, the two dimensions seem to be most related to age, educational level, and positive/negative life events from late adolescence to young adulthood  ,  ,  . A longitudinal study of college students reported that an increase in positive life events with age was associated with extraversion, while an increase in negative events was associated with neuroticism  . Another longitudinal study showed that extraversion in high school students predicted their experience of more positive life events over 4 years later in their college- or work-life, while their neuroticism predicted the experience of more negative life events  . These studies highlight the importance of understanding extraversion and neuroticism during late adolescence. 

Moreover, a meta-analysis of 92 longitudinal studies revealed that the largest changes in personality traits occurred between ages 18 and 30, and, specifically, that late adolescents typically become more socially dominant (a facet of extraversion) and less neurotic  . The study indicates that late adolescence is a critical period for the development of personality traits, showing that extraversion and neuroticism are influential for late adolescents in adapting to society as they mature. 

Recently, extraversion and neuroticism were also shown to impact on structural features of the prefrontal cortex in adult and elderly populations  ,  , suggesting that extraversion and neuroticism are related to structural brain development in the earlier stages of life. Low extraversion and high neuroticism are also associated with depression, anxiety  , and phobia  , which are all related to psychological and psychiatric problems frequently occurring in late adolescence  ,  . Neuroticism also predisposes individuals to develop chronic functional pain/pain disorders   and mood disorders  ,  , which are also common problems among late adolescents  ,  . The way in which adolescents become extraverted and less neurotic with regard to the challenging external environment during the late adolescent period is a developmental issue that has not been adequately addressed. Moreover, the neural correlates of this process are currently unclear. 

In a review study examining social and emotional development during late adolescence, depressive and anxiety symptoms were found to be predictive of changes in psychosocial functioning  . For example, rejection sensitivity (the tendency to anxiously expect, readily perceive, and intensely react to rejection) appears to be particularly salient in late adolescence as anxiety or angry expectation  , and was linked to a relative increase in adolescent depressive and anxiety symptoms  . Similarly, social anxiety was predictive of physical/psychological ‘dating aggression’ among late adolescents  . Moreover, healthy adolescents between 12 and 21 years old, who engaged in more extracurricular activities (i.e., participation in organized sports teams, clubs, etc.) and experienced higher quality family relationships, presented with significantly less depressive symptoms  . Since late adolescents face increasingly complex social situations, symptoms of depression and anxiety may be particularly damaging for the development of social competence. 

In the current study, we used functional magnetic resonance imaging (fMRI) to measure neural responses elicited by the observation of actions associated with a certain risk. Moreover, we investigated the influence of developmental differences of psychological properties among late adolescents. We administered psychological questionnaires to measure anxiety, depression, neuroticism, and extraversion, all of which play a crucial developmental role in the establishment of identity during late adolescence. During fMRI scanning, participants viewed hand movements associated with a risk of harm (risk-taking actions) or no risk of harm (safe actions). This task was designed to represent common situations involving potential risks in an everyday environment, providing an index of how late adolescents are likely to cope with potential risks in their social lives in the future. Late adolescence is a challenging period characterized by pervasive social role changes across many domains  ,  . Salient tasks of late adolescence include goals relating to friendship, academic success, and social conduct, giving way to occupational and romantic goals as late adolescents move into young adulthood  . The large number of changes faced in late adolescence make it an unstable time, but also reflects the explorations that take place during the late adolescent years. Many of the changes made by late adolescents are for the purpose of some new period of exploration, in love, work, or education. In accord with this notion, it is possible that a late adolescent’s level of tolerance of risk-taking actions may become entrenched as they are frequently confronted with challenging social situations during late adolescence. Here, we postulated that action observation of risk-taking would be a developmental indicator of motivation to overcome a broad range of difficulties in the world. Although teenagers are generally regarded as engaging in more ‘risky behavior’, such as binge drinking, cigarette smoking, having casual sex partners, violence and other criminal behavior etc  ,  ,  , it should be noted that in this study we do not use the term ‘risk-taking’ to refer to a tendency to such a ‘risky behavior’. Rather, we use ‘risk-taking’ to refer to a more positive concept, whereby adolescents confront and manage the difficulties facing them. 

Although this is an exploratory analysis, we hypothesized that late adolescents will become less anxious, less neurotic, less depressive, and more extraverted as they age, measured by the correlation between age and questionnaire scores, and that neural responses to the observation of risk-taking actions will be modified as adolescents become tolerant of risks in the external environment. Furthermore, we hypothesized that the developmental aspects of their tolerance to the external environment (measured as the correlation between questionnaire scores and age) will be mediated by changes of neural circuitry. These changes may involve the limbic or paralimbic systems (e.g., insula) or brainstem, which are central to the processing of affective information. In addition, the changes may also affect the prefrontal areas, which are important for emotional regulation. Activity in the anterior insula has been found to be associated with empathic maturity during the observation of emotional expressions among children  . This finding supports the notion that the insula is relevant to social functioning in everyday life. 


## Materials and Methods 
  
### Participants 
  
Twenty-five participants in their late adolescence took part in this experiment (12 females and 13 males, from 18 years and 1 month to 22 years and 8 months,   M   ±   SD   years: 20.60±1.09). All participants were undergraduate students and had normal or corrected-to-normal vision. All participants were right-handed (lateralization quotient for the right side of more than 90%) as assessed by the Edinburgh Handedness Inventory  . Written informed consent was given before participation in the study, which was specifically approved by the Institutional Ethical Review Board of the National Center of Neurology and Psychiatry, Japan. All participants were screened to rule out head trauma, the use of medication, history of neurological or psychiatric disorders, and other serious medical conditions. 


### Image Acquisition 
  
Images were acquired using a 1.5 T Magnetom Vision plus MRI scanner (Siemens, Erlangen, Germany). We acquired a unique high-resolution structural image (T1-weigthed anatomical images; 3D MP-RAGE sequence, repetition time; TR  = 11.4 ms, echo time; TE  = 4.4 ms, flip angle  = 15°, 256×256 matrix, slice thickness 1.25 mm) with 144 sagittal slices after the functional runs. Each functional run involved the acquisition functional echo-planar imaging (EPI) volumes (gradient-echo, TR  = 3,000 ms, TE  = 40 ms, field of view; FOV  = 192 mm, flip angle  = 90°, 64×64 matrix, slice thickness 3.5 mm), each with 36 interleaved slices approximately parallel to the anterior commissure-posterior commissure line. Stimuli were displayed on a screen positioned at the rear of the scanner, which the participant could comfortably see through a mirror mounted on the standard head coil. 


### Psychological Measures 
  
Prior to the fMRI session, participants completed the Maudsley Personality Inventory (MPI)  ,  , Spielberger State-Trait Anxiety Inventory (STAI)  ,  , and the Self-rating Depression Scale (SDS)  ,  . The MPI consists of 80 items, each assessing a constellation of traits, also providing a measure of personality along the neuroticism and extraversion scales. The STAI-trait is a self-report instrument of the longstanding quality of trait anxiety. The STAI-trait consists of 20 items, and high total scores indicate more trait anxiety. The SDS was developed as a self-administered measure of depression severity, with higher scores indicating more severe depression. The 20 items of the scale address each of the four most commonly found characteristics of depression: pervasive effects, physiological equivalence, other disturbances, and psychomotor activities. 


### Action Observation Stimuli and Procedure 
  
The action observation experiment involved two types of video clips, ‘risk-taking’ (video of a person’s hand performing an action with clear potential for causing harm to oneself) and ‘safe’ (showing a person’s hand performing an action with no clear danger) ( ). The stimuli are described in detail in  . It should be noted that the video clips were not created to convey the meaning of problematic behaviors among adolescents, such as using drugs or alcohol, driving drunk, smoking, unprotected sex, or other offensive or criminal activities. Rather, the video clips presented participants with situations involving common risks that most people are exposed to in everyday life. Each functional run began and ended with the presentation of a white fixation dot for 9 s. Between these two fixation periods, video clips from the two conditions were presented in alternating 21 s blocks. Each block consisted of a 21 s video clip, and each baseline consisted of a 9 s fixation period. Each block contained videos depicting three different risk-taking actions, or three different safe actions. Half of the blocks showed people performing actions from the right of the screen, and half from the left. Participants completed 10 blocks of each condition during a single scan. The order of presentation of the stimuli was determined according to an optimized random sequence for each block. The brightness of the screen, the intensity of contrast (luminance contrast and texture contrast), the velocity of hand actions, and the representation of objects were equalized for all task/control video clips. The total duration of the risk-taking video clip equaled the duration of the safe video clip (the length of each video clip was 7.0 s). Three functional runs, lasting 10 minutes each, were collected for each participant. The hand movements of participants were monitored by direct visual inspection and video-monitoring from the back of the fMRI tunnel. No visible movements were noted during the presentation of the experimental stimuli. 
   Examples of movies (risk-taking and safe).       Experimental conditions and Visual Analog Scale (VAS) score (100-0) for each condition.        

### Behavioral Measures 
  
After the scanning procedure, each participant was shown the video clips again, and asked to answer specific questions related to them. To test subjective evaluations of the degree of risk, participants were asked to rate their subjective experience of the video clips using a visual analog scale (VAS) (1) from feelings of risk to safety (i.e. to what extent did you feel alarmed while watching the video clip?) and (2) from feelings of anxiety to comfort (i.e. how anxious did you feel while watching the video clip?). 


### fMRI Data Analysis 
  
Image processing was carried out using statistical parametric mapping software (SPM8, the Wellcome Trust Centre for Neuroimaging, London, UK). The functional time series was motion corrected, slice timing corrected and smoothed with a Gaussian kernel of 8 mm full-width at half-maximum. The corresponding high-resolution structural image (the T1 image as the source image) was registered to the first EPI image as the reference image. The co-registered structural image was then transformed into standard anatomical space using the Montreal Neurological Institute structural template (MNI 152). These parameters were used to normalize all functional images. Following preprocessing, ‘Risk-taking’ and ‘Safe’ condition, and motion parameters (six realignment parameters) were entered as regressors. A high-pass filter (hpf) of 128 sec was also applied as regressors. The risk-taking and safe blocks were convolved with a hemodynamic response function without derivatives, and modeled as 21 s boxcar regressors. The 9 s fixation periods were modeled as implicit baseline blocks. Next, a first fixed level of analysis was computed subject-wise using the general linear model. The following T-contrasts were estimated: risk-taking, safe, risk-taking vs. safe, and safe vs. risk-taking. 


### Neural Response to Observation of Risk-taking versus Safe Actions 
  
To test our hypothesis that activation in areas related to action observation would be significantly enhanced when actions involved risk-taking, we compared activation in each condition using linear contrasts (risk-taking versus safe and safe versus risk-taking). The resulting set of voxel values for each contrast constituted a statistical parametric map of the   t   statistic SPM(  t  ). Anatomical localization was performed in MNI coordinates. Talairach coordinates (Talairach Daemon,   www.talairach.org/daemon.html  ) were used for anatomical localization to be compared with Brodmann areas  . Significant activations were defined using a lenient height-threshold of   p  <0.001, uncorrected, and an extent threshold of   k   = 10 (voxels), to reduce the risk of false negatives. Our use of cluster size thresholding combined with uncorrected   p   values was intended to adequately control for the prevalence of false positives  . This threshold suffices to eliminate speculation that effects observed in the primary parametric analysis are an artifact due to non-specific reductions in BOLD signal. 


### Neural Activity Associated with Age and Psychological Measures 
  
This analysis aimed to reveal the brain regions in which activity mediates the age-related change of psychological properties that are essential in individual maturity during late adolescence. In a second-level random-effect analysis, participant’s imaging data were regressed with psychological scores (neuroticism, extraversion, anxiety and depression) and age with a multiple regression analysis. The correlation map of neural responses to risk-taking action (the main SPM(  t  ) contrast of risk-taking vs. safe actions) with age and the correlation map of the same neural response with each of the psychological scores were calculated separately. A conjunction analysis was then performed to show overlapping areas of the two correlational maps: an age-related activation map and a personality-related map. 

Parameter estimates were extracted from the regions surviving the conjunction analyses that tested for statistical mediation using the INDIRECT macro for SPSS (  http://www.afhayes.com/  )  ,  ,  ,  . According to Baron and Kenny (1986), four steps are required to establish that neural activity in a particular region mediates the relation between age and psychological properties: (1) showing that age is associated with psychological properties; (2) showing that age is associated with neural activity in the region; (3) showing that neural activity in the region predicts psychological properties when controlling for age; and (4) showing that the relation between age and psychological properties is reduced when controlling for neural activity in the region. For a sample of 20–80 participants, statisticians recommend the use of bootstrapping methods for testing the statistical significance of mediation (rather than the Sobel test, which is appropriate for larger samples;  ,  . The current study used the bootstrapping approach outlined by Shrout and Bolger (2002), which provides a mean estimate of the indirect effect (i.e., the path through the mediator) and the associated 95% confidence interval. A confidence interval that does not contain zero indicates statistically significant mediation (  p  <0.05). Cook’s distance metric was used to test whether data from a few individuals unduly influenced the strength of the bivariate relationships. A value (age, psychological property, and neural activity) greater than 1 for a data point represents a statistical outlier  . No point had a Cook’s distance greater than 0.5, indicating that none of the correlations were dependent on statistical outliers. 



## Results 
  
### Behavioral Measures 
  
 shows descriptive features of psychological measurements (neuroticism, extraversion, anxiety-trait, and depression scores) and the correlation coefficients between these scores and age. The scores of neuroticism, anxiety, and depression were negatively correlated with age (  r   = −0.49, −0.56, and −0.54, respectively), and extraversion scores were positively correlated with age (  r   = 0.44), suggesting that the late adolescents became less neurotic, less anxious, less depressive, and more extraverted with age. These scores were used for the multiple regression analysis of neural responses, regressed with age and psychological variables. 
   Psychological assessment scores and correlation coefficients with age for each score.        
 shows the scores of subjective ratings using the visual analog scale for each video clip. To test the efficiency of the categorization of the stimuli in terms of risks, the scores of 1) participants’ subjective levels of risk-taking and 2) the extent to which they felt anxious when observing the stimuli were compared between the two within-participant categories (risk-taking and safe actions in video clips). The results indicated that participants experienced significantly stronger feelings of risk-taking and anxiety during the observation of risk-taking compared with safe actions (  F   = 151.16,   p  <0.001, and   F   = 93.73,   p  <0.001, respectively, using repeated-measures ANOVA). To validate the video clip task used in this study, we calculated the correlation coefficients of the subjective ratings of the feeling (“risky” and “anxious”) induced by the actions in the video clips with psychological assessments (correlation coefficients   r   are provided in the  ). The VAS scores of feeling “risky” about Risk-taking actions were positively correlated with anxiety (  r   = 0.41), and negatively correlated with extraversion (  r   = −0.42). VAS scores for feeling “anxiety” about Risk-taking actions were positively correlated with neuroticism and anxiety (  r   = 0.44 and 0.44, respectively), and negatively correlated with extraversion (  r   = −0.40). In contrast, VAS ratings for safe actions were not correlated with any psychological assessment. These results indicate that the video task in this study (the observation of risk-taking action) provides a suitable measure of the psychological factors of interest in this study, and can be used to examine important developmental processes in the late adolescence period. 
   Correlation coefficients between psychological assessments and subjective ratings (“risky” and “anxiety”) about the actions in video clips.        

### Neural Response to Risk-taking versus Safe Actions 
  
We compared the neural activation elicited by observing risk-taking versus safe actions across the whole brain ( ,  ). The results revealed that risk-taking actions elicited significantly stronger activation, mainly in the bilateral middle frontal gyrus (BA9/10), superior frontal gyrus/frontal pole (BA8/10), supramarginal gyrus (BA39/40), inferior parietal lobule (BA40), superior temporal gyri (BA22/39), middle occipital gyri (BA18/19), and cuneus (including the calcarine sulcus) (BA17/18/19) compared with safe actions. Additional areas of significant activation were also found in the left middle temporal gyrus (BA21/22), medial frontal gyri (supplementary motor area) (BA6), superior parietal gyrus/lobule (BA7), precentral gyrus (BA6), posterior cingulate (BA23), fusiform gyrus (BA37), lingual gyrus (BA17), insula (BA13), and declive. In the right hemisphere, we observed significant activation in the precuneus (BA7) and postcentral gyrus (BA2). No regions exhibited greater activation while viewing safe actions compared with risk-taking actions associated with risk. 
   Brain images of neural activity in response to the observation of the object-related hand movement task for risk-taking actions vs. safe actions.  
Statistical threshold for illustrating the clusters was   p  <0.001 uncorrected. The bar on the right shows the range of   t   scores for statistical parametric mapping. Calc. S, calcarine sulcus; FG, fusiform gyrus; FP, frontal pole; MFG, middle frontal gyrus; MTG, middle temporal gyrus; Occ, occipital cortex; SMA, supplementary motor area; SMG, supramarginal gyrus; SPG, superior parietal gyrus. 
  

### Neural Responses Mediating Relationship between Age and Psychological Properties 
  
Finally, we performed a conjunction analysis to reveal common brain activity that correlated both with age and psychological scores (neuroticism, extraversion, anxiety, and depression) ( ). A positive correlation between age and neural response to observation of risk-taking action [  r  ,   p  <.001] and a positive correlation with extraversion [  r  ,   p  <.001] were found to overlap in the insula [BA13,   r   = 0.70,   r   = 0.76], middle temporal gyrus [BA22,   r   = 0.68,   r   = 0.70, ], and precuneus [BA19,   r   = 0.67,   r   = 0.67]. A positive correlation with age [  r  ,   p  <.001] and a negative correlation with anxiety [  r  ,   p  <.001] were found to overlap in the angular gyrus/supramarginal gyrus [BA39,   r   = 0.68,   r   = −0.79, ], precentral gyrus [BA6,   r   = 0.67,   r   = −0.73, ], and red nucleus/substantia nigra [  r   = 0.66,   r   = −0.79]. Parameter estimates were extracted from the regions surviving the conjunction analysis. The parameter estimates were used in a series of analyses testing for statistical mediation. 
   Brain regions mediating association between psychological measurement and age.        
As shown in  , insula activation (BA13) mediated the relation between age and extraversion. This insula activation was positively associated with age and extraversion (age:   β   = 0.44; extraversion controlling for age:   β   = 0.41). The relationship between age and extraversion (  β   = 0.28) was reduced when controlling for activity in the insula (  β   = 0.22). Bootstrapping revealed that the insula significantly mediated the relation between age and extraversion (mean indirect effect  = 5.35, 95% confidence interval ranging from 0.37 to 11.78). The results indicate that, as late adolescents’ age, their neural responses to the observation of risk-taking actions increase in the insula and middle temporal, lingual, and precuneus areas. These changes were related to developmental changes of the participants’ psychological properties, such as increased extraversion. In particular, the insula significantly mediated the relation between age and extraversion. Also, age-related increases of neural activation in the angular gyrus, precentral gyrus, and red nucleus (and substantia nigra) were found to contribute to decreasing anxiety with age. 
   (A) Scatterplots of associations between insula activity (BA13, peak in MNI space: −40 −10 20) and age for the peak of the clusters surviving conjunction analysis with an independent regression of extraversion.  
Left panel: association between age and insula activity (  r   = 0.60,   p  <0.01). Right panel: association between extraversion and insula activity (  r   = 0.61,   p  <0.01). (B) Brain regions that mediated the relationship between age and extraversion. Parameter estimates (risk-taking > safe contrast) extracted at the region identified by conjunction analyses were independently regressed by age and psychological properties. Mediation tests were based on methods described by Shrout and Bolger (2002) and Baron and Kenny (1986). (a) Regression slope of age predicting neural activity; (b) regression slope of neural activity predicting extraversion, controlling for age; (c) regression slope of age predicting extraversion; (c’) regression slope of age predicting extraversion, controlling for neural activity. Bootstrapping was used to estimate indirect effects (Shrout & Bolger, 2002; see also Preacher & Hayes, 2004). A confidence interval that does not overlap with zero indicates statistically significant mediation. *Indicates significant difference from zero,   p  <0.05. Coordinates are given in MNI space. 
  


## Discussion 
  
The primary question motivating the present study was whether late adolescents become more extraverted, less neurotic, and less anxious as they age, and whether such changes might reflect increased tolerance to the challenges of the adult world. In addition, we also sought to test how brain function reflects developmental changes occurring in late adolescent psychology. 

The results revealed several major findings. First, we observed significant correlations between age and scores on psychological parameters that have been hypothesized to play central roles in the development of the late adolescent mind: younger people tended to become more extraverted and less neurotic, less anxious and less depressive with age during late adolescence, even within the small age range in our sample. Levels of neuroticism have been previously reported to decline with age until around age 80  . However, extroversion has also been found to decline with age  . Reports of the correlation of age with depression and anxiety are, however, inconsistent. While some studies have reported no age-related difference on the SDS and STAI among students aged 18–28  , another study reported correlations of anxiety and depression with age in a population with a mean age of 33.0 years  . To date, there has been no study reporting detailed changes of these psychological properties within a small age range in late adolescence. The robust association of age with neuroticism, extraversion, anxiety, and depression in our study indicates that the late adolescent mind undergoes dramatic changes within a short period of time. These changes appear to be unique and distinct from psychological changes that occur across the longer lifespan. Future studies with larger samples will be necessary for elucidating the nature of these dramatic changes in late adolescence. 

Analysis of the “risk vs. safe” contrast revealed neural activation in areas broadly associated with action recognition. These results indicate that observing risk-taking compared with safe actions in our task elicited neural activation in; 1) occipital visual areas including the calcarine sulcus and fusiform gyrus, which are related to lower-level processing of visual information and sending output information to the action recognition network; 2) the bilateral superior and inferior parietal regions, which have been implicated in action recognition and representation  ; 3) the posterior middle temporal gyrus, which is located in the middle of the ventral pathway and serves as a central node in the association of actions and meanings  ; 4) the supramarginal gyrus or inferior parietal area, widely considered to be homologous to the monkey parietal mirror neuron system, which is critical for encoding and recognition of gestures such as object–related postures and movements  ; 5) the posterior cingulate area associated with human awareness, self-reflection  , and memory retrieval  ,   etc. and 6) the frontal pole (superior frontal gyrus), which has been implicated in retrospective monitoring of observed actions that affect one’s future actions  ,  . Therefore the results suggest that the risk content of the observed action in the video clips enhanced the broad spectrum of visually-guided action recognition processing; the network of visual input and its processing appear to encode the meaning of the observed action and even the reflective or retrospective monitoring of the action’s outcomes. As a result, the risk-related content of the action enhanced a broad network associated with action recognition. This finding indicates that risk-taking situations may increase cognitive load in the entire action recognition system, commanding more attention to the actions shown in the video clips. One possible explanation for the result is that risky actions are relatively unusual and involve novelty, which may cause more brain activation. In the present study, however, it is unlikely that factors related to novelty exerted a substantial effect on brain activation, because the situations depicted in the video clips were not unusual. Rather, the videos depicted common situations that often occur in everyday life. In addition, the degree of novelty of the experimental stimuli was controlled using control video clips. Although we did not observe strong activation in affect-related brain areas, another explanation is that the present results reflect some affective impact on brain activation related to risk-taking context. For example, activation in the mirror neuron system while observing action can be enhanced by motivational and affective aspects of the observed action, (e.g.,  ). Thus the action recognition system may be modulated by the affective context of the risk-taking actions of observed actions. 

Alternatively, processing risky actions may require more cognitive resources, involving the estimation and monitoring of possible outcomes of observed actions (see  . This notion is in accord with our current finding that the frontopolar region was more engaged while observing risk-taking compared with safe actions. In addition, a previous study reported that the superior part of the frontal polar area exhibited stronger activation when participants thought about the future compared with when they thought about the past  . Moreover, human lesion studies have indicated that the frontal polar area may be involved in generating insights into one’s future  ,  ,  . On the basis of the current findings, taken together with previous evidence, we hypothesize that risk-taking actions require more cognitive resources to process, involving the estimation of action outcomes resulting in stronger activation in the frontopolar cortex. 

The posterior cingulate cortex (PCC) was also activated by risk-taking vs. safe actions. This region may be another center for risk-related brain activity, which has been suggested by previous animal studies. For example, it has been reported that PCC activation in monkeys is sensitive to risk in decision making tasks  . In addition, the PCC is reported to exhibit activation when monkeys make risky choices, and to become more active with greater perceived risk  . These reports are consistent with the present finding that the observation of risk-taking actions (compared to safe ones) activated the PCC. The PCC is reciprocally connected to parietal areas (action recognition network) and receives feedback input from the prefrontal cortex (see the review in  ), which is involved in estimating the possible outcomes of action. Activation in this area may have exhibited risk-related sensitivity, together with the other regions listed above. 

The main finding in the current study was that neural activation during the observation of risk-taking (compared with safe) actions was correlated with age and some psychological measures, especially, extraversion and anxiety. These results indicate that these psychological properties have important developmental components during late adolescence, and that these developmental changes are represented by brain activation related to the observation of risk-taking actions in the insula and the parietal-temporal-occipital association area (middle temporal gyrus, lingual gyrus, and precuneus). Furthermore, we found that the insula significantly ‘mediated’ the relationship between age and extraversion. 

The insula is a multifunctional cortical region involved in emotional processing  ,  ,  ,  ,  ,  , speech-motor function  ,  ,  ,  ,  ,  , aversive experience  , both physical (i.e. visceral and somatic pain) and emotional (i.e. affect and mood) experience  ,  ,  , conscious awareness (interoceptive awareness)  , and emotional awareness  . The insula also plays a critical role in the processing of risk-taking during decision-making  , suggesting that insula activity may also be modified by the risk-taking context of the observed action in our study. 

The present finding of a correlation between insula activity and extraversion is consistent with the results of a previous positron emission tomography (PET) study   showing that the blood flow of the insula cortex was correlated with extraversion. Introversion (low extraversion) is associated with anxiety through increased limbic activation (in the insular cortex and amygdala), and is affected by genetic factors  . A morphometric study also revealed that extraversion correlated positively with gray matter volume of the insula  . Importantly, a previous fMRI study   revealed that extraversion correlates with neural responses to   positive   word stimuli in the bilateral insula. It is possible that, although the insula response to observing risk-taking actions may reflect an elevated alertness to the risk of harm in the environment, the participants did not experience substantial negative affect, as would be the case if they suffered from severe neuroticism or anxiety/depression. Rather, participants may have been receptive to the new challenges evoked by the task, which could result in the relationship between insula activity and a personality trait relating to a more positive aspect of affect, i.e., extraversion. Although insula activity reflects the processing of arousal or novelty  ,  , this may be accompanied by positive affect to some extent. 

While insula activity is related to extraversion, the insula has also been found to exhibit developmental changes  ,  . A neuroimaging study revealed increased activation in the insula with age in response to a risk-taking task  . Studies of individuals with clinical or developmental disorders consistently show insular morphometric changes, such as gyrification   and reduction of the insular volume in Williams syndrome  , which further suggests developmental changes in the insula. The current finding of an age-related increase in insula activation may also support the notion that the level of affective (particularly positively-valenced) engagement in risk-taking action increases with age in late adolescence. Overall, the current results, which show a link between age and insula activity as well as a link between insula activity and extraversion, suggest that insula activity may ‘mediate’ the development of extraversion. 

Our results also revealed that activity in the posteromedial parietal cortex (including the precuneus) correlated positively with extraversion. Gamma et al., (2000) report a similar positive correlation between extraversion and rCBF in the precuneus, consistent with the current findings  . Extraversion is related to the active seeking of social or interpersonal engagement, and the precuneus is also related to processing social information and estimating interpersonal relationships. For example, the precuneus is activated during ‘forgivability’ judgments in social scenarios   and in the attribution of emotions to the self and others  . Moreover, a number of studies have identified that the precuneus is modulated by agency and intentions in action/movement recognition  ,  , and moral judgments  . The precuneus, in parallel with its social functions, shows age-related changes of brain activity during theory of mind tasks  ,  . The correlation between extraversion and activity in the precuneus, with its age-related changes, suggests that increased precuneus activation may mediate the process of late adolescents becoming increasingly extraverted and exhibiting improved social functioning with age. 

In the current study, as late adolescents aged, activity in the angular gyrus and precentral gyrus increased, and was negatively correlated with anxiety. In a previous fMRI study  , participants were told that an electrodermal stimulation could occur at any time (“threat”) or that no stimulation would occurs (“safe”). The results revealed stronger activity in the “safe” condition than in the “threat” condition in the angular gyrus and precentral gyrus. Thus, these regions may reflect enhanced perceptions of safety, consistent with the current finding of a negative correlation between the activity in these two regions and the level of anxiety. Simmons et al.   also reported reduced activity in the posterior superior temporal cortex adjacent to the angular gyrus in anxiety-prone participants compared with control participants during the observation of aversive images. Moreover, the more repetitively the emotional facial pictures were presented the stronger the neural activity was in the angular/posterior superior temporal gyrus and precentral gyrus, such that the activation in these areas correlated with participants becoming habituated to the emotional stimuli and becoming less anxious  . The precentral gyrus has dense connections with the angular gyrus  , and the angular gyrus and precentral gyrus have been reported to exhibit coactivation during a range of cognitive tasks, including lexical  ,   and calculation tasks  . These findings suggest the existence of a network involving these two areas. Moreover, both the angular gyrus and precentral gyrus are included in the default-mode network (DMN), a prominent large-scale brain network that exhibits strong activity during the resting state and deactivation during cognitively demanding tasks  ,  . We propose that maturation of a network including the angular gyrus and precentral gyrus may play an important role in stabilizing affective states during late adolescence. 

Several limitations of the current study should be considered. First, the sample size was relatively small for studying personality-related factors. This may have reduced the statistical power of our analysis, potentially influencing the results. Additional studies with larger sample sizes and more detailed longitudinal behavioral and cognitive testing focusing on the developmental aspects of personality are required to verify these novel findings. Second, our mediation analysis design, consisting of three variables, may have omitted many other variables that influence both insula response and extraversion in the same direction, potentially resulting in a positive bias in the results. For example, it has been reported that empathic ability is correlated with insula activity  . In addition, some evidence suggests that empathic individuals are more likely to be extraverted  . Moreover, an independent variable can have multiple mediators, which would have been omitted in this design. These potential confounds are likely to affect mediators and dependent variables in the same way. Future studies should take into account other potential mediators. Third, the conjunction analysis shown in Supplementary   may contain false positives, meaning that the results should be corrected for multiple comparisons (e.g. Bonferroni correction). Applying the Bonferroni correction would increase the likelihood of false negatives, however. Since the current study is an exploratory examination, it may be appropriate to consider the statistical significances of conjunction analyses as preliminary values at this point. Additional studies using the Bonferroni correction will be needed to more rigorously test our hypothesis. Fourth, we found a negative correlation of age and anxiety with activation in the red nucleus/substantia nigra, but no significant effect of the main contrast (risk-taking vs. safe; in Supplementary  ). The substantia nigra contains dopamine-containing neurons  ,  . Moreover, the sequence planning and timing-related motor functions in the substantia nigra indicate dopaminergic gating of motor sequences  ,  . Future studies will be required to investigate this issue in more detail. Fifth, as shown in  , multiple correlation analyses were computed between psychological measurements. This may have led to significant effects due to chance in each correlation analysis, such as correlation coefficients between the subjective ratings of the two kinds of video and the four psychological measurements. Adopting a more conservative corrected alpha level, however, would increase the likelihood of false negative results. In the current study, we adopted a thresholding method (  p  <0.001, uncorrected, with 10 contiguous voxels) that was initially proposed more than a decade ago   and has been used in many fMRI studies. A number of alternative methods of correction for multiple comparisons currently exist (e.g.,  ,  ), and the thresholding method in our study is not the only one available. It is important to note that the present correlational analysis constitutes an exploratory finding. Future studies will be required to test whether the current data can be replicated. 

Overall, our findings indicate that late adolescents become less neurotic, less anxious, less depressive, and more extraverted as they age. These changes are associated with activity in brain regions related to social cognition and emotional processing. 


## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-41'>
<h2>41. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31100434/' target='_blank'>31100434</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Dyadic interaction processing in the posterior temporal cortex</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Neuroimage</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1016/j.neuroimage.2019.05.027</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6610332/' target='_blank'>6610332</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study in healthy adults (N=21, ages 18–35) that used dynamic social interaction stimuli (videos of two actors engaging in arguing/celebrating/laughing). Participants completed an in-scanner task (passive viewing with a frame-freeze detection) while BOLD data were acquired. The paper reports whole-brain preprocessing and GLM estimation and describes whole-brain searchlight analyses (in addition to ROI analyses), satisfying the requirement for whole-brain results. The sample is healthy and within the 18–60 age range, it is an original empirical fMRI study (not a review/meta-analysis), and it does not report clinical/psychiatric populations. Therefore it meets all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Recent behavioural evidence shows that visual displays of two individuals interacting are not simply encoded as separate individuals, but as an interactive unit that is 'more than the sum of its parts'. Recent functional magnetic resonance imaging (fMRI) evidence shows the importance of the posterior superior temporal sulcus (pSTS) in processing human social interactions, and suggests that it may represent human-object interactions as qualitatively 'greater' than the average of their constituent parts. The current study aimed to investigate whether the pSTS or other posterior temporal lobe region(s): 1) Demonstrated evidence of a dyadic information effect - that is, qualitatively different responses to an interacting dyad than to averaged responses of the same two interactors, presented in isolation, and; 2) Significantly differentiated between different types of social interactions. 

Multivoxel pattern analysis was performed in which a classifier was trained to differentiate between qualitatively different types of dyadic interactions. Above-chance classification of interactions was observed in 'interaction selective' pSTS-I and extrastriate body area (EBA), but not in other regions of interest (i.e. face-selective STS and mentalizing-selective temporo-parietal junction). A dyadic information effect was not observed in the pSTS-I, but instead was shown in the EBA; that is, classification of dyadic interactions did not fully generalise to averaged responses to the isolated interactors, indicating that dyadic representations in the EBA contain unique information that cannot be recovered from the interactors presented in isolation. These findings complement previous observations for congruent grouping of human bodies and objects in the broader lateral occipital temporal cortex area. 
   Highlights  
  
pSTS and EBA classify between different dynamic interactions. 
  
EBA is sensitive to (uniquely) dyadic interaction information. 
  
These findings support previous evidence for grouping of interacting people/objects in LOTC. 
  
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (38608 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Social interactions are ubiquitous, yet little research has investigated visual perceptual responses to these common social scenarios, relative to individual-person perception ( ). Interestingly, recent behavioural evidence demonstrates that visual responses to two human individuals that are positioned to imply an interaction evoke different responses than when not positioned in this manner. These effects are demonstrated most strikingly by the findings of  : In this study, subjects viewed pairs of briefly presented (30 ms) human bodies or control objects (i.e. chairs), that either faced   towards   or   away   from each other, in either upright or inverted orientation, and were instructed to respond to the stimulus category they saw (i.e. bodies or chairs). Greater recognition accuracy was shown for upright than inverted dyads when an interaction was implied by the two bodies facing towards each other, but crucially, not when facing away from each other. Similarly, visual search facilitation is shown for full body dyads that are positioned to   face towards   – rather than   away   from – each other ( ), while facing direction effects are shown to modulate the evaluation of facial emotion of a target face (i.e. the perceived emotional expression of a target face is modulated by the emotion of a simultaneously presented non-target face, but only when positioned to   face towards   the target;  ). 

Together, these behavioural findings demonstrate that interacting individuals are not merely perceived as separate individuals, but as an   interactive dyad  . Indeed, similar   non-linear   neural responses have been observed recently – that is,   that responses to dyadic interaction stimuli are not the same as a linear combination of responses to the isolated elements of an interaction  . Specifically,   demonstrated evidence of non-linear responses to human-object interaction stimuli in the posterior temporal cortex; the authors used a pattern classification approach to test whether responses to images of human-object interactions (e.g. a person pushing a shopping cart) are distinct from   the mean-averaged response   to the constituent parts of the interaction (i.e. the averaged response to an isolated human and isolated cart); it was found that voxel patterns for human-object interactions in the posterior superior temporal sulcus (pSTS) and lateral occipital cortex (LOC) were statistically distinct from the averaged patterns evoked by isolated ‘interaction parts’. These findings suggest that these regions are sensitive to   unique   interactive information that is accessed only through holistic processing of interactions, and not through part-wise analysis (i.e. processing of constituent ‘interaction parts’ in isolation). 

Interestingly, this response in the pSTS complements previous findings that this region plays an important role in the visual processing of dynamic social interactions; for example, greater pSTS responses are shown for interacting point-light human dyads relative to two non-interacting figures, as well as for similar stimuli depicted by moving geometric shapes that do not contain body information ( ;  ). This region also differentiates between types of interactions performed by live-action human stimuli ( ), and is sensitive to ‘interactive’ motion cues such as the movement contingency between two interacting human figures ( ), or the degree of correlated motion between interacting animate geometric shapes ( ;  ). These findings implicate the pSTS as a region that may be optimized for processing social interaction information. 

The main aim of the present study was to determine whether pSTS encodes dynamic human interactions between two individuals in a non-linear fashion, using a similar approach to  . We herein adopt the phrase ‘  dyadic information effect  ’ rather than ‘non-linear’ effect, to emphasize a   sensitivity to unique information that is only present in dyadic interactions and not the averaged responses evoked by each interactor, presented in isolation  . Specifically, we used support vector machine (SVM) classification to test whether voxel-pattern responses to dyadic stimuli in the pSTS were statistically differentiable from   averaged response patterns   of isolated interactors. Additionally, it was predicted that significantly differentiable responses to   different types   of dyadic interaction would be observed in the pSTS, replicating previous findings (e.g.  ;  ). Responses were also tested in 3 other functionally localized regions of interest (ROIs) that are selective for social information that likely contributes to social interaction processing, and therefore might also plausibly show the hypothesized effects: Extrastriate body area (EBA), mentalizing-selective temporo-parietal junction (TPJ-M), and face-selective STS (STS-F). 


## Material & methods 
  
### Participants 
  
21 right-handed adults (mean age = 23.40 years; SD = 3.74; range = 18–35; 12 females) participated in the study. Participants gave informed consent and received monetary compensation for taking part. Ethical procedures were approved by the Bangor University psychology ethics board. 


### Stimuli 
  
Stimuli consisted of 4 s (s) video clips that were taken from custom footage of paired actors engaging in semi-improvised interactions. Actors were instructed to improvise these scenarios while enacting scripted ‘  action-gestures  ’; for example, for a given arguing scenario, one actor might be instructed to   point angrily   at the other person while the other   shook their fists   in frustration. Therefore, each interaction depicted two individuals performing a given pair of complementary action-gestures that they were encouraged to enact in a natural, authentic way (see supplementary materials A for example videos). An initial set of   dyad stimuli   were created (along with a separate set of   alone stimuli  , as described below; see   for examples of both dyad and alone stimuli). Dyad stimuli depicted two actors engaging in one of 3   interactive scenarios  :   Arguing   (i.e. both actors engaging in an angry/frustrated confrontation),   celebrating   (i.e. both actors celebrating together, excitedly), and   laughing   (i.e. both actors were laughing together, or at each other). These specific scenarios were chosen for the ‘tonal consistency’ of actions performed by a given pair of interactors, such that the intentions, emotions, and valence information conveyed by both individuals in a given scenario were always similar (e.g. angry/frustrated) rather than contrasting (e.g. angry/sad). This ensured that successful classification of the different scenarios was not driven by systematic differences in intentional, emotional, or valence content   between   interactors. Therefore, these scenarios represented three interactive scenarios that were intended to be easily distinguishable.   
a. Example video frames from the dyad versions of the three interaction scenarios. Each row represents one of three unique female-male interactor pairs. b. Two example alone stimuli (created from a given dyad stimulus). 
  Fig. 1   

Within each interaction scenario (e.g. arguing), 4 exemplar videos were created, each using a unique pair of action-gestures, such that each video showed the two individuals performing a complementary pair of action-gestures (e.g. while arguing, interactor A accusatorily points at interactor B who is shaking their hands in frustration). Importantly, no gestures were ‘reused’ in any of the other action-gesture pairings (i.e. a total of 8 action gestures were used across the 4 exemplar videos for each scenario). Similarly, 3 different female-male   interactor pairs   enacted these scenarios, yielding a total of 36 dyad stimuli: 3 interaction scenarios (arguing, celebrating, laughing) x 4 unique action-gesture pairings x 3 interactor pairs. The final stimuli were chosen from a wider set of stimuli based on the highest ‘interactive-ness’ and ‘naturalness’ ratings from a pilot study (N = 10; see supplementary materials A). 

For these stimuli, the average horizontal distance between actors was closely matched – the visual angle between the centre of each actor's torso was approximately 4.80°, and actor height ranged between 3.73 and 4.26°. As dynamic facial information is known to activate the STS (e.g.  ), the presence of facial information was controlled such that classification could not be attributed to different facial expressions. Accordingly, these stimuli did not contain high spatial frequency face information, but body information was preserved. To achieve this, a circle-shaped Gaussian blur mask was placed on each of the actors' heads for each video frame. This preserved the overall shape of the head, preventing the potentially eerie appearance of headless interacting bodies. 

To test neural responses to the same interactive information – but without specifically   dyadic information   (i.e. information available from two interactors presented simultaneously) – a separate set of 72   alone stimuli   were created by removing either individual from each of the 36 dyad stimuli (see  b for examples of two alone stimuli). It is important to note that although these stimuli depicted an isolated interactor by themselves, they still conveyed interactive information (e.g. communicative gesturing towards an implied interactor). Two horizontally-flipped variants of these 108 unique stimuli (36 dyad ​+ ​72 alone stimuli) resulted in a final set of 216 stimuli. 


### Design & procedure 
  
A rapid event-related design was used, and each run was optimized using optseq2 (  http://surfer.nmr.mgh.harvard.edu/optseq  ), based on differentiating 6 conditions (i.e. both dyad and alone variants of the arguing, celebrating, and laughing interaction scenarios), with an inter-stimulus interval range between 0 and 10s (along with 8s fixation at the beginning of each run, and 16 s at the end to capture most of the haemodynamic response). The 6 designs with the highest detection sensitivity were selected to determine event timings for runs. 

Inside the scanner, participants viewed stimuli that were presented centrally on the screen within a 9.17 × 5.11° rectangular space. 6 runs were completed, each lasted exactly 7 minutes and contained 8 stimuli for each dyad version and 16 stimuli for each alone version of each of the 3 scenarios, resulting in 72 experimental stimuli per run. Three important stimulus ordering considerations are also noted here: Firstly, left and right horizontal presentations of each stimulus were balanced within the design, such that any resulting effects could not be attributed to low-level confounds in the horizontal position of interactors (i.e. left and right horizontally-flipped variants of the stimuli appeared equally often); secondly, that any given pair of alone stimuli (i.e. that originated from the same dyad stimulus) were always presented in the same run as each other so that classification of alone stimuli did not contain additional between-run variance that was not present for the dyad stimuli; thirdly, to minimize repetition effects (i.e. seeing the exact same action-gestures from a given dyad stimulus and the corresponding pair of alone stimuli), alone stimuli that appeared in any given run were always from dyad stimuli that were allocated to a different run. 

In addition to the stimuli already described, nine additional catch stimuli were presented (three dyad stimuli, and six alone stimuli) but were not later analysed. These trials contained a ‘frame-freeze’ in which 12 consecutive video frames (duration = 500 ms) were randomly removed from the video and replaced with one repeated frame for that period, creating the impression of a momentary video pause. Participants were instructed to simply watch the videos and to give a button-press response whenever a frame-freeze was detected, and to refrain from making explicit judgements about the interactors. 


### Localizer tasks & ROI creation 
  
Participants completed several localizer tasks in a separate scanning session, on a separate day (see supplementary materials B for full description of these tasks). Briefly explained, three different video tasks were used to localize brain regions that are sensitive to different types of social information: 1) A point-light figure social interaction task similar to that used previously ( ;  ) was used to localize interaction-selective pSTS (pSTS-I) regions of interest (ROI) with the interaction > scrambled interaction contrast (i.e. two intact human figures interacting vs. spatially scrambled versions of the same stimuli in which body and interactive information was disrupted). 2) A dynamic body and face localizer that was adapted from stimuli used previously ( ) – this served to localize body-selective EBA and face-selective STS cortex (i.e. STS-F), with the bodies > objects, and faces > objects contrasts, respectively. 3) A free-viewing animated film (‘Partly Cloudy’; Pixar Animation Studios:   https://www.pixar.com/partly-cloudy  ) identical to that used previously ( ) was used to localize mentalizing-selective TPJ-M with the mentalizing > pain contrast (i.e. mentalizing > pain time-points). 

These tasks allowed for the localization of 4 bilateral subject-specific ROIs (i.e. pSTS-I, EBA, STS-F, & TPJ-M; see supplementary materials C for a visualization of these ROIs). These ROIs were created with a group-constrained definition procedure (e.g.  ) as follows. For a given subject and contrast (e.g. interaction > scrambled interaction, for the pSTS-I), a 5 mm-radius ‘search sphere’ was created by running a whole-brain analysis for N-1 group subjects (i.e. with the ‘current’ subject excluded) and centring the sphere at the peak voxel (i.e. highest t-value) in the designated region. This relatively small sphere was chosen to ensure subject's ROIs did not deviate too far from a given designated anatomical region (e.g. pSTS). To determine the position of the final ROI, a whole-brain analysis for the current subject (for the same contrast) was run, and resulting activation was constrained to the search sphere. A 7 mm-radius sphere was then centred at the peak voxel in this search region; this ROI sphere size was chosen as an ideal compromise between capturing a relatively large number of voxels that would benefit classification performance (e.g.  ), and ensuring minimal overlap between neighbouring STS ROIs. 

All ROIs contained 179 voxels, with the exception of two subjects that had small regions of overlap between the right pSTS-I and right TPJ-M, and a further two subjects with similar overlap between the right pSTS-I and right STS-F. Across these four subjects, a mean overlap of 18 voxels (range: 12–24) was found. To ensure independence of ROI voxels within each of these four subjects, overlapping voxels were removed and ROIs were recreated (respective final ROI sizes for these four subjects were: 167, 161, 161, 155 voxels; all other ROIs for these subjects contained 179 voxels). 


### MRI parameters, pre-processing, & GLM estimation 
  
Scanning was performed with a Philips 3T scanner at Bangor University. Functional images were acquired with the following parameters: T2*-weighted gradient-echo single-shot EPI pulse sequence; TR ​= ​2000 ​ms, TE ​= ​30 ​ms, flip angle ​= ​83°, FOV(mm) ​= ​240 ​× ​240 x 108, acquisition matrix ​= ​80 ​× ​78 (reconstruction matrix ​= ​80); 36 contiguous axial slices were acquired, with a reconstructed voxel size of 3 mm . Four dummy scans were discarded prior to image acquisition for each run. Structural images were obtained with the following parameters: T1-weighted image acquisition using a gradient echo, multi-shot turbo field echo pulse sequence, with a five echo average; TR = 12 ms, average TE = 3.4 ms, in 1.7 ms steps, total acquisition time = 136s, FA = 8°, FOV = 240 × 240, acquisition matrix = 240 × 224 (reconstruction matrix = 240); 128 contiguous axial slices, acquired voxel size (mm) = 1.0 × 1.07 x 2.0 (reconstructed voxel size = 1 mm ). 

Pre-processing was performed with SPM12 (fil.ion.ucl.ac.uk/spm/software/spm12). This entailed slice-timing correction, re-alignment (and re-slicing), co-registration, segmentation, normalization, and smoothing. All default parameters were used except for a 6 mm FWHM Gaussian smoothing kernel. General linear model (GLM) estimation was performed in SPM12 on participants’ normalized images. For the main task, whole-brain beta maps were generated on a run-wise basis with events estimated as 6   classification conditions   – both dyad and alone variants of the arguing, celebrating, and laughing stimuli. One further set of maps were created where each event was modelled separately, to allow for stimulus-wise analyses (see supplementary materials D). 


### SVM classification analyses 
  
Leave-one-run-out linear support vector machine (SVM) classification was implemented with CoSMoMVPA ( ). Briefly explained, for a given subject, an SVM classifier was trained on ROI voxels (i.e. beta values) for the conditions of interest (e.g. dyad variants of the arguing, celebrating, and laughing conditions) in all but one run of data – with the ‘left-out’ run of data used to independently test classification performance on. This was iterated 6 times with each run serving as the left-out test run, and classification accuracy was averaged across iterations. These values were then entered into group level   t  -tests. All reported tests were significant at the corrected Bonferroni threshold (α) unless otherwise stated. A different threshold was calculated separately for each set of analyses (i.e. based on 8, 8, & 4 comparisons for dyad, alone, and cross-classification analyses, respectively), as stated in each sub-section in the results. All   t  -test   p-  values are one-tailed. 

This approach was almost identical for both ‘standard’ classification (e.g. between the three dyad conditions, or between the three alone conditions) and   cross-classification   analyses except that the allocation of training and test conditions differed; that is, for cross-classification, the classifier was trained on the three dyad conditions, but   tested   on the three alone conditions. Significant cross-classification demonstrates that the patterns underlying the two sets of conditions are similar to each other, and therefore are largely driven by the same information. However, we reasoned that if a region showed significantly greater dyad classification than cross-classification (i.e. between dyad and alone conditions), this would indicate sensitivity to dyadic information that could not be ‘recovered’ from the individual interactors presented in isolation (i.e. averaged responses to alone stimuli). As explained previously (see section  ) several stimulus ordering constraints were imposed within each run, and importantly, alone stimuli from a given dyad stimulus were always presented in a different run to minimize repetition effects. Notably, this likely resulted in a   more conservative   estimation of the dyadic information effect due to greater similarity between stimuli in test and train data splits for cross-classification, than for ‘standard’ classification (see supplementary materials E for further details). 



## Results 
  
### SVM classification analyses 
  
For each of the 8 functionally localized ROIs, a series of analyses were performed in which a linear SVM classifier was trained and tested on different variants of the 3 interaction scenarios (i.e. arguing, celebrating, and laughing). One-sample   t  -tests were used to determine whether classification accuracy was above chance level (i.e. 100% / 3 categories = 33.3% chance accuracy; Bonferroni corrected α = 0.006). 

Significant above-chance classification of the three interaction scenarios of dyad stimuli (see  ) was observed in the right pSTS-I (Classification accuracy (%):   M   = 41.39,   SD   = 9.10;   t   (19) = 3.96,   p   < .001) and both the right EBA (  M   = 49.38,   SD   = 12.19;   t   (17) = 5.59,   p   < .001) and left EBA (  M   = 50.88,   SD   = 13.00;   t   (18) = 5.88,   p   < .001), and at an uncorrected threshold in the left pSTS-I (  M   = 38.60,   SD   = 10.55;   t   (18) = 2.17,   p   = .022). None of the 4 other ROIs – bilateral STS-F and TPJ-M – showed above-chance classification of the dyad stimuli (all   ps   > .100; see  ; see supplementary materials F for full statistics).   
A bar chart showing classification accuracy values for dyad, alone, and cross-classification analyses for bilateral pSTS-I and EBA ROIs. Dashed line represents chance-level accuracy (33.3%). *** ​= ​  p   ​≤ ​.001; ** ​= ​  p   ​≤ ​.010; * ​= ​  p   ​≤ ​.05; +=   p = .  073. Error bars are SEM. 
  Fig. 2     
A bar chart showing classification accuracy values for dyad and alone classification for bilateral STS-F and TPJ-M ROIs. Dashed line represents chance-level accuracy (33.3%). No results were significant. Error bars are SEM. 
  Fig. 3   

It is possible that significant classification of dyad stimuli in the bilateral pSTS-I and EBA does not completely rely on inherently dyadic information, and may also encode information conveyed by isolated individuals (e.g. interactive gestures directed towards an implied – but physically absent – interaction partner). To test if this was true, another classification analysis (Bonferroni corrected α = 0.006) was run to see if these regions could differentiate the three interaction scenarios for the alone stimuli (see  ,  ). It is worth reiterating that the   same overall information   was present as in the dyad classification analysis (i.e. same scenarios, actors, & gestures). Above-chance classification was shown in right pSTS-I (  M   = 43.33,   SD   = 12.57;   t   (19) = 3.56,   p   = .001) but only marginally in left pSTS-I (  M   = 37.43,   SD   = 12.81;   t   (18) = 1.39,   p   = .090). Both right EBA (  M   = 46.30,   SD   = 7.86;   t   (17) = 7.00,   p   < .001), and left EBA (  M   = 46.49,   SD   = 6.73;   t   (18) = 8.52,   p   < .001) also showed significant classification. As for dyad classification, bilateral STS-F and TPJ-M ROIs did not show above-chance classification (all   ps   > .088), and therefore, these regions were excluded from further analyses. 

Together, these two classification analyses demonstrate interaction sensitive responses in the right pSTS-I and bilateral EBA regions, and to a marginal extent in the left pSTS-I; specifically, these regions were able to differentiate between the three different interaction scenarios, both when observing an intact dyad and when observing the same constituent interactors presented in isolation. However, although these regions are sensitive to both modes of presentation, this does not mean that the underlying information driving classification in both dyadic and alone scenarios is the same (e.g. information about the spatial-relations between interactors may contribute to classification of the dyad stimuli, but not the alone stimuli). Indeed, if voxel pattern classification in any region does not fully generalise from dyad stimuli to the alone stimuli, this would suggest that there is information encoded by these regions during dyadic interaction perception that cannot be recovered by the same information presented in the alone stimuli. 

Next, a cross-classification analysis was implemented (Bonferroni corrected α = 0.013) whereby an SVM classifier was trained to discriminate responses to the three interaction scenarios with the dyad stimuli, but performance was tested on responses to the alone stimuli. Significant cross-classification was shown for all 4 ROIs (right pSTS-I:   M   = 41.39,   SD   = 8.92;   t   (19) = 4.04,   p   < .001; left pSTS-I:   M   = 40.64,   SD   = 9.63;   t   (18) = 3.31,   p   = .002; right EBA:   M   = 43.21,   SD   = 7.75;   t   (17) = 5.40,   p   < .001; left EBA:   M   = 46.20,   SD   = 11.27;   t   (18) = 4.97,   p   < .001), demonstrating that these regions encode similar information in both the dyad and alone stimuli. 

To test for the main hypothesis (i.e. a dyadic information effect) paired   t  -tests were then performed (Bonferroni corrected α = 0.013) between dyad classification accuracy scores and cross-classification accuracy scores. No difference was observed for either the right pSTS-I (  t   (19) = 0.00,   p   = .500) or left pSTS-I (  t   (18) = −0.73,   p   = .763), showing no dyadic information effect, indicating that the main hypothesis was not supported. However, significantly greater accuracy for dyad classification than cross-classification was shown in the right EBA at an uncorrected level (  t   (17) = 2.07,   p   = .027). A similar, although weaker, marginal effect was also shown in the left EBA (  t   (18) = 1.52,   p   = .073). Therefore, evidence suggestive of a dyadic information effect was shown in the bilateral EBA only. 

To determine whether regions outside the functionally defined ROIs demonstrated a dyadic information effect, whole-brain searchlight analyses ( ) were performed (see supplementary materials G for a full description of searchlight methods and results). Peak classification accuracies (i.e. for dyad and alone classification separately, and also for cross-classification) were observed in the bilateral lateral occipito-temporal cortex (LOTC) and pSTS, along with weaker responses in other areas. However, no dyadic information effects were observed in the LOTC/EBA for this analysis (or in any other brain region), further demonstrating the subtle nature of the effect in the ROI analysis. 


### Reliability of the dyadic information effect in EBA 
  
Due to the marginal nature of these results in the EBA, several follow up tests were performed to determine the reliability of this effect. First, Cohen's   d   effect-sizes were calculated for both the right and left EBA. A medium effect-size was found for the right EBA (  d   = 0.60), and a small-to-medium effect was shown in the left EBA (  d   = 0.38). 

To ensure that these effects were not spuriously driven by the ‘direction’ of cross-classification training and testing roles, cross-classification was performed again, but with the training and testing roles reversed. That is, the classifier was now trained on the   alone   stimuli and tested on the   dyad   stimuli. Both right EBA (  M   = 43.83, SD = 7.60;   t   (17) = 5.86,   p   < .001) and left EBA (  M   = 46.20, SD = 10.32;   t   (17) = 5.43,   p   < .001) showed significant cross-classification. Crucially, dyadic information effects were replicated; greater accuracy for dyad classification than cross-classification was again shown in the right EBA (  t   (17) = 2.03,   p   = .029;   d   = 0.55) and marginally in the left EBA (  t   (18) = 1.41,   p   = .088;   d   = 0.40). 

One further test was performed to determine how reliable these effects were across different ROI sizes (i.e. in addition to the original 7 mm radius ROIs, 5, 6, 8, 9, 10, 11, & 12 mm radius ROIs were created). Consistent with the dyadic information effect in the in the original right EBA ROI, greater accuracy for dyad classification than cross-classification was shown across all ROI sizes, but was most pronounced in larger ROIs (i.e.   ps   < .05 for 8, 9, 11, & 12 mm radii; see supplementary materials H). By contrast, in the left EBA, the dyadic information trend was only shown for smaller ROI sizes (i.e. 5 mm radius:   p   < .05; 6 and 7 mm radii: marginal   ps   ≤ .073); indeed, these hemispheric differences appear to be consistent with larger regions of body selectivity in the right than left EBA as previously reported ( ). 


### Results summary 
  
In summary, although right pSTS-I – and marginally, left pSTS-I – differentiated between the three interaction scenarios, no evidence for specific   dyadic information   encoding was observed in these regions. Instead, this effect was observed in the right EBA at an uncorrected threshold (the data for this analysis are available to download; see supplementary materials I). Follow-up analyses demonstrated that this effect was reliable and interpretable, and is further supported by similar (although weaker) effects in left EBA. Control analyses revealed that these effects are not accounted for by low-level differences in stimulus motion energy between conditions (see supplementary materials J). Additionally, exploratory representational similarity analyses were also performed to further characterize EBA responses to dyad and alone stimuli (see supplementary materials D). 



## Discussion 
  
### Overview of results 
  
The present study aimed to determine whether the pSTS – or any other posterior temporal lobe region – showed sensitivity to   unique   dyadic information in visually observed interactive scenarios that is not present for isolated individual interactors. Two main findings were shown: 1) EBA – but not pSTS – showed evidence consistent with the encoding of unique dyadic information; 2) pSTS (and EBA) classified between three interaction scenarios (i.e. arguing, celebrating, & laughing) replicating similar differentiation of types of interactions between abstract moving shapes ( ;  ). 


### Interaction classification in the pSTS & EBA 
  
Specifically, which type of information might drive differentiation of interaction scenarios in the pSTS and EBA? The pSTS plays an important role in biological motion perception (e.g.  ;  ;  ), and is strongly responsive to movement contingencies between interacting figures (e.g.  ), as well as dynamic cues that imply interactive behaviour between animate moving shapes ( ;  ). Similarly, the pSTS is also sensitive to the intentional contents of actions ( ;  ;  ). It therefore seems plausible that classification in the pSTS is driven by differential intentional content between interaction scenarios that is extracted from different dynamic contingencies between interactors. 

Additionally, the EBA also classified between interaction scenarios. A direct interpretation of this result is that body posture information contributes strongly to the differentiation of these three scenarios. EBA is shown to be sensitive to dynamic postural information (i.e. continuous sequences of body postures that form coherent actions) and is suggested to encode body-based actions ( ). In the current study, distinctively different sequences of coherent body postures – or action-gestures – may have driven classification of interaction scenarios. Although distinct action-gestures were used within each interactive scenario, these tended to be relatively similar to each other (e.g. arguing gestures usually depicted short, sharp movements, while laughing gestures typically contained convulsive torso movements). Therefore, it seems possible that classification of interaction scenarios in the EBA was likely the result of similar action-gestures   within   each scenario, that were markedly different   across   the three scenarios. 


### No dyadic information effect in the pSTS 
  
Despite the pSTS classifying interactive scenarios, the main prediction was not supported; no   dyadic information effect   was observed for the pSTS. This contrasts with the findings of   that showed an analogous effect in the pSTS for static depictions of human-object (inter)actions compared to the averaged responses to isolated objects and humans. One possible explanation for this concerns STS sensitivity to implied biological motion in static images ( ;  ); static human-object interactions might imply greater biological motion or more effortful movement that is not ‘recoverable’ from isolated human and objects; for example, an image of a person pushing a cart implies greater movement than the same body pose and cart presented separately, by virtue of greater physical effort required to move the cart, along with the corresponding impression that the cart is moving. Additionally, pSTS sensitivity to causal contingencies (e.g. a billiard ball hitting another, causing a transfer in motion;  ) suggests the strong influence of physical contact in human-object interactions that was not present in the isolated stimuli. By contrast, the current study used dynamic stimuli that contained biological motion information but no physical contact, and as such, the dyad and alone stimuli were closely matched for these two sources of information that might have driven responses to the stimuli used by  . 

Although no dyadic information effect was found in the pSTS, it is important to note that interactive information was still conveyed in the alone stimuli (e.g. communicative gesturing to an unseen interactive partner was strongly implied). Therefore, successful classification of the alone stimuli does not necessarily reflect that pSTS responses are non-interactive. Indeed, in the context of the sorts of gestural interactions used in the current study, it is possible that classification of the alone and dyad stimuli relied on the same cues (i.e. communicative gestures). Similarly, the current data supports the possibility that representations of interactions in this region may encode the presence of two interactors in a linear fashion (i.e. dyad = the average of the two individuals). Alternatively, it is possible that the pSTS responses to both dyad and alone stimuli are driven by interactive gestures ‘directed’ at another individual, regardless of whether the other individual is present or not. 


### Dyadic information processing in the EBA 
  
Although not observed for the pSTS, a dyadic information effect was shown for the right EBA and to a lesser extent, the left EBA. Although not predicted, this does fit with previous findings observed in the wider LOTC area. Specifically,   observed differentiable responses to human-object interactions than averaged responses to humans and objects in object-selective LOTC (i.e. LOC – in close proximity to EBA); however, this trend did not quite reach significance in the EBA, likely due to weaker responses to object stimuli, suggesting that the currently observed EBA responses could be specific to human body information. Recent evidence also shows that object-selective LOTC is sensitive to ‘regular’ spatial configurations of objects that imply a congruent scene (e.g. different responses are shown for scenes that depict a sofa positioned in front of a television, rather than behind it;  ). Similarly, object-selective LOTC is sensitive to spatial configurations of objects that imply an action (e.g. a pitcher tilted towards an empty cup), relative to configurations that do not ( ). 

Broadly, these findings might suggest a converging role for configural processing of   distinct   objects and people in the LOTC. In relation to the present findings, it is conceivable that LOTC – and here the EBA specifically – performs similar configural processing or grouping based on the action-, body-, and movement information conveyed by interactors. If true, to what extent does   dynamic   information contribute to this effect? In contrast to previous work investigating LOTC grouping responses for static stimuli ( ;  ;  ), the current study used dynamic stimuli. Although the EBA is highly sensitive to static pose information, and may process body movements as a series of static ‘snapshots’ ( ;  ) body (and face) responses are shown to generalise across static and dynamic depictions in broad regions of the posterior temporal cortex ( ). Similarly, representations in the LOTC generalise across dynamic and static depictions of actions and are invariant to other low-level features such as movement direction, or the specific hand used to perform an action ( ;  ). 

In line with these findings, it is likely that dyadic representations of (inter)actions in the EBA generalise across static-dynamic depictions. While dynamic information may not be necessary to encode such scenarios, it may, potentially, allow for more elaborate encoding of body-based actions than similar, static depictions. Additionally, other spatial cues (e.g. interpersonal distance, physical contact, and facing direction), and temporal cues (e.g. movement contingencies and correlated motion) may also contribute to dyadic encoding in the EBA, and further research may directly clarify which cues contribute most prominently. 

It is also worth briefly considering the extent to which dyadic information processing is present for other types of interaction, for example, interactions depicted by moving geometric shapes that do not contain body information. These types of stimuli are known to drive responses in LOTC, ostensibly due to the presence of simple actions such as pushing and pulling movements ( ). As mentioned previously, the wider LOTC area shows some sensitivity to spatial-temporal relations between interacting or scene entities, and therefore cortex in close proximity to (and overlapping with) EBA might plausibly encode dyadic information for these abstract scenarios. 

The present stimuli consisted of interactions between individuals that did not involve physical contact, a potentially powerful interaction cue that is worthy of further investigation; indeed, stronger dyadic information effects might be predicted for contact-based interactions (e.g. two individuals shaking hands), by virtue of categorical differences in physical contact (i.e. presence of physical contact in dyadic interactions vs. absence of physical contact in ‘alone’ variants of these stimuli). 


### Conclusion 
  
In summary, the present results show that both EBA and pSTS differentiate between different types of social interactions. Crucially, representations of dyadic social interactions in the EBA are sensitive to information beyond that which is encoded by the simple average of two separate interactors presented in isolation. This so-called   dyadic information effect   suggests that the EBA is sensitive to unique interactive information that is present only when two individuals interact simultaneously. These findings complement previously observed sensitivity in the wider LOTC area to spatial configurations of objects or bodies that support the processing of holistic, congruent scenarios. 



## Author contributions 
  
J.W & K.K: study design, data-collection, analysis, writing, and editing. 


## Conflicts of interest 
  
None declared. 


## Funding 
  
This work has received funding from the   under the   (ERC starting grant: Becoming Social). 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-42'>
<h2>42. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/26644594/' target='_blank'>26644594</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> The shaping of social perception by stimulus and knowledge cues to human animacy</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Philos Trans R Soc Lond B Biol Sci</p>
<p><strong>Publication Year:</strong> 2016</p>
<p><strong>DOI:</strong> 10.1098/rstb.2015.0075</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4685521/' target='_blank'>4685521</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study with healthy adult participants (final N=23; mean age 26.4, right-handed, neurologically healthy), using a task that probes social perception/action observation (viewing agents interacting with objects and rating smoothness/liking). Whole-brain analyses were performed and reported (voxel-wise thresholds, cluster correction; whole-brain contrasts for main effects and interactions are described). The study is not a review/meta-analysis, does not focus on clinical populations, and does not report only ROI results. All inclusion criteria (fMRI during social-related task, healthy adults 18–60, whole-brain results) are met and no exclusion criteria apply.</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Although robots are becoming an ever-growing presence in society, we do not hold the same expectations for robots as we do for humans, nor do we treat them the same. As such, the ability to recognize cues to human animacy is fundamental for guiding social interactions. We review literature that demonstrates cortical networks associated with person perception, action observation and mentalizing are sensitive to human animacy information. In addition, we show that most prior research has explored stimulus properties of artificial agents (humanness of appearance or motion), with less investigation into knowledge cues (whether an agent is believed to have human or artificial origins). Therefore, currently little is known about the relationship between stimulus and knowledge cues to human animacy in terms of cognitive and brain mechanisms. Using fMRI, an elaborate belief manipulation, and human and robot avatars, we found that knowledge cues to human animacy modulate engagement of person perception and mentalizing networks, while stimulus cues to human animacy had less impact on social brain networks. These findings demonstrate that self–other similarities are not only grounded in physical features but are also shaped by prior knowledge. More broadly, as artificial agents fulfil increasingly social roles, a challenge for roboticists will be to manage the impact of pre-conceived beliefs while optimizing human-like design. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (49446 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Detection and recognition of other agents is a necessary ability across species. It is an integral pre-requisite for social interaction: one must accurately identify others in order to appropriately interact with them. For instance, one would not expect a robot to offer the same opportunities for social interaction as a human. Considering the predicted rise of artificial agents in society performing tasks alongside humans in hospitals, care homes and schools [ ], it will become increasingly important to distinguish between animate agents (e.g. humans) and inanimate agents (e.g. robots). Robots can act in the world by moving and achieving goals, but they are not sentient or intentional. Indeed, a key factor for classifying other agents is the perception of animacy—the presence of life in others. The distinct way that robots and humans look and move as well as what we know about their origins offer important cues to animacy [ ]. As such, a key question for social cognition and social neuroscience research pertains to understanding the cognitive and neurobiological mechanisms that enable us to recognize animacy in other agents [ ]. 

### The neuroscience of social perception and cognition 
  
The neuroscience of social cognition is concerned with how the brain manages social interactions with others [ ]. Several distinct brain circuits have been identified that process elements of our social worlds, three of which are of particular relevance to the current study ( ). Person perception research has shown how sensory systems are sensitive to the presence of conspecifics in the environment [ ]. For instance, patches of cortex in the ventral visual stream including fusiform and occipitotemporal gyri respond preferentially to images of social stimuli (faces and bodies) compared to non-social stimuli (houses and cars) [ , ]. Accumulating evidence suggests the ventral visual stream contributes to understanding identity through processing physical appearance, such as facial features, body shape and posture [ , ].
   
Social brain circuits. mPFC, medial prefrontal cortex; TP, temporal poles; Prec., precuneus; IFG, inferior frontal gyrus; IPL, inferior parietal lobule; TPJ, temporoparietal junction; pSTS, posterior superior temporal sulcus; FG, fusiform gyrus; OT, occipitotemporal cortex. The mirror neuron system and pSTS form the key nodes of the action observation network. 
  

Another form of social perception involves observing others moving through the environment and interacting with objects. Brain regions responding to the observation of others in action include posterior temporal gyri, inferior parietal lobule and inferior frontal gyrus [ – ]. The frontal and parietal responses are consistent with research into the mirror neuron system discovered in monkeys, which shows similar responses to performed and observed actions [ ]. One dominant theory argues that this frontoparietal network enables action understanding through simulation by mapping observed actions onto the observer's own motor system [ ]. 

Simply coding the physical characteristics of other agents and their movements would not, however, be sufficient to understand the meaning of their actions. It is also necessary to make inferences about information one cannot see, such as others' beliefs, desires, attitudes and traits [ ]. A third strand of social cognition research—mentalizing—aims to delineate the cognitive and brain systems integral to representing such mental states of others [ ]. Brain circuits spanning the medial prefrontal cortex (mPFC), temporoparietal junction (TPJ), temporal poles and precuneus are consistently engaged when inferring and evaluating mental states and are collectively known as the theory of mind network [ , ]. The ability to draw inferences about underlying intentions helps us to predict what another individual may do next and helps to regulate social interactions [ , ]. Together, the studies highlighted in this section have identified discrete brain circuits that subserve aspects of social perception and interaction. It is less clear, however, how social information is organized beyond a social–non-social distinction. 


### The ‘like-me’ hypothesis 
  
One dominant model in social cognition states that understanding the similarity between self and other is a basic principle of social cognition and that humans have developed to seek out self–other equivalence [ , ]. This account, known as the ‘like-me’ hypothesis, further proposes that actions performed by oneself and another are represented in common cognitive codes [ ]. At the core of the ‘like-me’ hypothesis is the proposal that cognitive and brain mechanisms have been shaped to show sensitivity to information that is physically or cognitively similar to one's own makeup. This view is consistent with the biological imperative to detect similar others as a foundation for successful navigation of the world [ ]. 

One approach to test predictions that follow from the ‘like-me’ hypothesis has been to vary cues to human animacy. In such studies, the idea is that the more human-like an agent is perceived, in terms of physical appearance and intentionality, the more it is considered to be ‘like me’. These studies have fallen into two main camps based on the type of cues to human animacy under investigation. One camp has manipulated stimulus features, such as what an agent looks like or how it moves. The second camp has manipulated knowledge cues to animacy, such as whether an observer believes an agent to be human or not. Both cue types are of clear relevance to the study of social perception. Humans move in a particular way, for instance using a minimum jerk trajectory, and have a particular form (i.e. head above a torso with limbs). Such distinctive physical features can be diagnostic of a human presence. Likewise, knowledge cues also matter for interpreting human animacy. If you know the gorilla across the street is actually a man in a costume, your perception of the social environment would be markedly different from if you were not aware of this fact. In the following, we review behavioural and brain-imaging studies that have manipulated stimulus cues and knowledge cues to human animacy. Instead of an exhaustive review of all studies exploring animacy detection, our focus is on brain systems that index the distinction between human and non-human agents. 


### Stimulus cues to human animacy 
  
The majority of research into cues influencing animacy perception has focused on stimulus cues to human animacy, such as what an agent looks like and how it moves. These can be considered ‘bottom-up’ cues that are determined by the visual appearance of the form and motion of an agent. Many studies have investigated responses along the ventral visual stream to depictions of human compared to non-human stimuli, such as other animals or inanimate objects [ , ]. Less research in the domain of person perception has varied cues to human animacy by comparing human to less human or robotic agents [ , ]. Gobbini   et al  . [ ] showed similar engagement of core face perception areas—fusiform face area (FFA), occipital face area (OFA) and posterior superior temporal sulcus—when observing human and artificial, robotic faces. In addition, core face and body processing regions also respond to cartoon and schematic depictions of faces and bodies [ , ]. Thus, the ventral visual stream appears to be indifferent to animacy cues that are based on physical form and responds to real faces and bodies as well as face- and body-like forms. 

In the domain of action perception, where agents are moving in the world and sometimes interacting with objects, results are mixed. The superior temporal sulcus has been shown to respond to biological motion, even in the absence of a clear human form [ , ]. Many studies have also compared the observation of actions performed by humans and robots. A common result is more engagement of sensorimotor brain regions collectively termed the action observation network (AON) and facilitated behavioural responses when the agent is more human than not [ , ]. For example, observing human form and motion increased motor priming in an imitation task [ , ]. In addition, right premotor cortex is engaged more during the observation of reaching actions performed by a human hand compared to a robotic claw [ ]. These results are consistent with a self-similarity bias and more AON engagement when an observed agent is more human. 

On further inspection of the action perception literature, however, several studies show indifference in the AON to degrees of stimulus-driven humanness or even a preference for non-human stimuli. For instance, Gazzola   et al  . [ ] failed to find any difference in brain responses when participants viewed actions performed by a human or robotic hand. Likewise, Ramsey & Hamilton [ ] found that the left anterior intraparietal sulcus, a core AON node, responded in a similar manner when participants observed a geometric shape or a human hand perform goal-directed actions. Moreover, some studies show an even greater response in the AON when perceiving non-human compared to human visual cues [ , ]. In two experiments, Cross and co-workers show greater engagement when watching rigid robotic movement compared to natural free-flowing dance moves that are more consistent with a human's motor repertoire [ ]. This robust AON engagement was seen when participants observed a human actor dancing and when observing a robot toy animated to move in a similar manner. Therefore, the AON was shown to be more sensitive to rigid, non-human-like movement irrespective of animacy cues based on physical form. Finally, Saygin & Stadler [ ] found that middle temporal gyrus and intraparietal sulcus are more sensitive to an android (a robot dressed as a human) than a clearly presented human or robot actor. Thus, the role of the AON in response to varying stimulus cues to human animacy remains somewhat unclear. 

Stimulus cues can also drive mental state reasoning and engagement of the person knowledge or theory of mind network. Heider & Simmel [ ] showed that when people observe simple shapes moving around as if they are interacting, they ascribe human-like mental states to these shapes. Using the same stimuli, Castelli   et al  . [ ] demonstrated that these stimuli also engage brain regions associated with mental state reasoning and social cognition (see also [ ]). Social context can also lead to mental state reasoning if stimuli are arranged in a manner that makes a moving object look like a social agent (such as an ice skater) rather than an inanimate object (like a spinning top [ ]). Finally, the same movie footage of social interactions engages person knowledge networks more if real video footage is viewed rather than modified versions that have been made to appear ‘cartoonish’ [ ]. Together, this work suggests that stimulus cues alone can provide an input to human-like mental state and animacy judgements. 


### Knowledge cues to human animacy 
  
Knowledge cues to animacy are based on beliefs about an agent's animate origins and can be task instructed or task independent [ ]. These can be considered ‘top-down’ cues that are driven by prior information about the stimulus, rather than by the visible form and motion cues. The impact of knowledge cues can be seen most clearly when visually identical stimuli are encountered across different conditions, which vary knowledge about the agent's humanness. Thus, any differences in cognitive or brain function are cued by information that is independent to the stimulus. 

A growing body of behavioural evidence supports the notion that beliefs about humanness influence social perception and interaction [ – ]. For example, Liepelt & Brass [ ] used an automatic imitation task and found that participants showed stronger evidence of motor priming when movements were thought to be made by a human rather than a wooden hand. Using simplified moving dot stimuli, Stanley   et al  . [ , ] showed increased behavioural interference together with reports of stimuli appearing more human-like when participants believed the stimuli originated from real human movement compared to computer-generated movement. Finally, using a manipulation where participants were required to coordinate their actions with a physically present humanoid robot, Stenzel   et al  . [ ] found that participants were more likely to represent the robot's action if they believed that the robot's behaviour was based on a biologically inspired neural network than when it was based on a computer program. 

Neuroimaging research has also varied knowledge cues to human animacy. Seminal fMRI studies of theory of mind used the same stimuli for both ‘human’ and ‘computer’ conditions, and varied participant instructions. The instruction ‘you are playing with a human’ gave rise to robust activation in the person knowledge network [ , ]. That is, the identical stimulus increasingly activated social brain regions when participants believed it originated in another person, not a computer. 


### Combined stimulus and knowledge cues to human animacy 
  
Few studies have directly compared stimulus and knowledge cues to human animacy. Press   et al  . [ ] showed that stimulus cues to animacy override knowledge cues when imitating hand actions. By contrast, Stanley   et al  . [ ] showed that knowledge of how a moving dot was made (human versus computer-generated) dominated perception of animacy compared to its motion properties. Klapper   et al  . [ ] showed that both types of cue influence imitation of hand actions. Moreover, fMRI results from the study by Klapper and co-workers showed that right TPJ was engaged more during an automatic imitation task when both stimulus   and   knowledge cues to human animacy were present than when only one or neither cue to human animacy was present [ ]. This result supports the view that right TPJ may be particularly sensitive to controlling interactions with human agents [ , ]. 

A neuroimaging study by Stanley   et al  . [ ] manipulated both types of cue by investigating passive observation of point-light animations. Point-light stimuli typically consist of a sequence of moving dots, representing several joints on an actor's body, which give the appearance of human biological motion [ ]. This study found that knowledge of human animacy engaged mPFC more than knowledge that the stimuli were computer-generated. By contrast, human-like movement did not engage social brain circuits more than less-human movement. While emerging evidence suggests instances when both stimulus and knowledge cues influence social perception and cognition, the conditions and parameters that lead to these biases remain largely unknown. 


### Summary and the current study 
  
Evidence suggests widespread cortical engagement of distinct social brain circuits for detecting and recognizing aspects of human animacy during social interactions. Stimulus and knowledge cues to human animacy engage person perception, action observation and mental state reasoning networks. The picture to date remains far from clear, but there appears to be some kernel of truth to the suggestion that a mechanism of self-similarity or ‘like me’ may operate across these studies. Many questions remain unanswered, however. A growing number of studies show indifferent or opposite brain or behavioural responses to those consistent with a theory based on self-bias. Moreover, few neuroimaging studies have directly compared stimulus and knowledge cues to human animacy in the same experiment to tease apart their relative contributions to detection and recognition of other humans. Indeed, only one other study to date has investigated action perception in this manner and this study did not present visible human features, such as faces or body parts, but instead used point-light displays of simple actions [ ]. Hence, it remains unclear how perception of action is influenced by cues to human animacy, particularly when physical form cues are visible. 

The current study, therefore, directly compares stimulus and knowledge cues to human animacy during the observation of agents interacting with objects. Face and body cues are manipulated as well as beliefs about the origins of such actions. By doing so, we are able to investigate which cues to animacy dominate perception of action as well as how these cues engage social brain circuits. To support the ‘like-me’ hypothesis, we would expect greater engagement of brain regions implicated in action observation [ , ], mentalizing [ , , ] and person perception [ , ] when stimulus or knowledge cues to human animacy (or both) are present. However, as a number of recent studies suggest [ , – ], we might also find that parts of the social brain are not solely tuned to preferentially respond to cues that are ‘like me’. Thus, the current study will provide novel insights into aspects of the social brain that are more or less responsive to features of an agent that are ‘like me’ through careful manipulation of stimulus and knowledge cues to human animacy. 



## Material and methods 
  
### Participants 
  
Twenty-nine physically and neurologically healthy young adults were recruited from the fMRI Database of the Max Planck Institute for Human Cognitive and Brain Sciences (Leipzig, Germany). All were monetarily compensated for their involvement and provided written informed consent in line with procedures set forth by the local ethics board. Six participants were excluded from the final analyses due to not believing the cover story (see   Behavioural Procedure and Task  ). The final sample included 23 participants (14 women, nine men;   M   = 26.41 years, s.d. = 3.02 years) who believed the cover story. All participants were native German speakers and right handed as measured by the Edinburgh Handedness Inventory [ ]. 


### Stimuli 
  
Stimuli were created using P  three-dimensional animation software (SmithMicro Software Inc, Santa Cruz, CA, USA) and featured 10 object-directed actions ( ). Each video lasted 5 s. To create the stimuli, a human actor was first filmed performing each action, and these videos served as a model for creating the Poser videos. Each action was mapped onto two different avatars: a human male and a custom-designed robot ( ). Each action was ‘filmed’ from the waist upwards and from three different angles: centre, off centre and from the side (see right panel of   a  ). These procedures yielded 60 videos in total (10 different actions × 2 different agents × 3 different viewing angles).
   
Details of experimental materials and design. (  a  )(i) Eight of the 10 actions featured in the stimuli set (the remaining two, ‘toss ball’ and ‘hammer nail’ are seen in (  a  )(ii) and in (  b  )). (  a  )(ii) The three viewing angles each action was ‘filmed’ from, to create a larger, richer stimulus set. (  b  ) The 2 × 2 factorial design that enabled investigation of bottom-up features (whether the agent looked like a human or robot; rows of design) as well as top-down features (whether participants were told the videos were created using human motion capture or computer animation; columns of design). 
  


### Belief manipulation 
  
In order to manipulate knowledge cues to human animacy, participants were told the current study was commissioned by a major German film studio for the purpose of examining how the human brain processes two cutting-edge animation techniques: human motion capture and computer-generated keyframe animation. Before taking part in the experiment, participants watched a 10-min custom-made and professionally produced ‘documentary’ that explained human motion capture and computer keyframe animation techniques in detail (see also [ ]). Specifically, participants learned that human motion capture involves recording real human movement via sensors that are attached to the body, whereas computer-generated keyframe animation involves a computer algorithm that fills in intermediate frames of a movement between predefined start and end positions. To further induce believability, the Poser stimuli used in the actual experiment were briefly seen in several parts of the cover story documentary to reinforce the idea that both kinds of animation could lead to the types of stimuli observed in the present study. In reality, however, all stimuli used in the real experiment were made with computer keyframe animation (the technique used by P  software), which closely approximates real biological motion. After watching the documentary, participants were asked whether they had understood how both techniques were used to animate avatars, and whether they had any questions about the techniques before the experiment started. 


### Behavioural procedure and task 
  
Participants' task in the scanner was to carefully observe 240 video stimuli during one functional run (each of 60 videos was repeated four times in total during the experiment). The videos were blocked into groups of five (with each group of five videos featuring either the human or the robot avatar), and participants observed a total of 48 blocks of five videos containing equal numbers of each agent form/belief pairing. Before each block of five videos was played, a cueing screen appeared for 2 s that specified that the following videos were made either with motion capture or computer keyframe animation (  b  ). The order of instruction screens and the individual actions that made up each series of five videos was pseudo-randomly assigned. 

After each video, one of two questions appeared which participants were required to answer: either (i) how much did you   like   the video you just saw? or (ii) how   smooth   did you find the movement in the previous video? These questions were chosen for several reasons. First, we wanted to determine how stimulus and knowledge cues to human animacy influence perception of the stimuli at a behavioural level. Second, two questions were chosen so that participants could not anticipate the exact question they would be asked, which required them to maintain attention to the stimuli. Participants made their ratings on a 1–8 scale via a fibre-optic scanner compatible button box. Following scanning, participants completed a debriefing survey where they were explicitly asked whether they noticed anything of note about the stimuli, as well as what they believed the true goal of the study was. The six participants (of the original sample of 29 participants) who raised suspicions the stimuli seemed to be the same and only the instructions changed were excluded from the final sample. Upon completing this survey, all participants were told the true nature of the study and compensated for their time. 


### MRI acquisition 
  
Functional neuroimaging was acquired using a Bruker 3 Tesla Medspec 20/100 whole-body MR scanning system, equipped with a standard birdcage head coil. Functional images were acquired continuously with a single-shot gradient echo-planar imaging sequence with the following parameters: echo time (TE) = 30 ms, flip angle = 90°, repetition time (TR) = 2000 ms, acquisition bandwidth 100 kHz. Twenty-four axial slices allowing for full-brain coverage were acquired in ascending order (pixel matrix = 64 × 64; FOV = 24 cm, resulting in an in-plane resolution of 3.75 × 3.75 mm , slice thickness = 4 mm, interslice gap = 1 mm). Slices were oriented parallel to the bicommissural plane (AC-PC line). The first two volumes of each functional run were discarded to allow for longitudinal magnetization to approach equilibrium. An additional 813–830 volumes of axial images were collected. Geometric distortions were characterized by a B0 field map scan (consisting of a gradient echo readout (32 echoes, inter-echo time 0.64 ms) with a standard two-dimensional phase encoding). The B0 field was obtained by a linear fit to the unwarped phases of all odd echoes. Following the functional run and field map scan, 24 two-dimensional anatomical images (256 × 256 pixel matrix, T1-weighted MDEFT sequence) were obtained for normalization purposes. In addition, for each participant, a sagittal T1-weighted high-resolution anatomical scan was recorded in a separate session. The anatomical images were used to align the functional data slices with a three-dimensional stereotaxic coordinate reference system. 


### Behavioural data analysis 
  
Behavioural responses to the smoothness and liking questions asked during the imaging task were combined to form a single dependent variable and were analysed with a 2 (Agent Form: human, robot) × 2 (Belief Manipulation: human motion capture, computer-generated animation) repeated measures ANOVA. 


### Imaging data analysis 
  
Data were realigned and unwarped in SPM8 (Wellcome Department of Imaging Neuroscience, London, UK) and normalized to the Montreal Neurological Institute (MNI) template with a resolution of 3 × 3 × 3 mm. Slice timing correction was performed after realignment. Functional data were normalized to individual participants' T1 anatomical scans with a resolution of 3 mm . All images were then spatially smoothed (8 mm). A design matrix was fitted for each participant, with each type of video (Human with Motion Capture instruction, Human with Computer Animation instruction, Robot with Motion Capture instruction and Robot with Computer Animation instruction), the belief manipulation instruction screen and the question/response period modelled as a boxcar function convolved with the standard haemodynamic response function. The imaging analyses were designed to achieve the following three primary objectives: 

#### Main effect of stimulus cues 
  
First, we evaluated the main effect of visual cues to the socialness of an observed agent. To achieve this, we compared observation of actions performed by the human avatar to the robot avatar (human > robot), as well as the inverse (robot > human). 


#### Main effect of knowledge cues 
  
We next assessed the main effect of our belief manipulation. We evaluated brain regions more engaged when videos were believed to have a human origin (motion capture > computer animation), or when videos were believed to be computer-generated (computer animation > motion capture). 


#### Interaction between stimulus and knowledge cues 
  
The third set of contrasts examined the interactions between agent form and belief cues. The aim of these interaction analyses was to determine the extent to which brain regions associated with the action observation, mentalizing or person perception networks are sensitive to specific pairings of stimulus-driven and knowledge-based cues to human animacy. The first interaction contrast interrogated brain regions more engaged when viewing congruent agent/belief pairings more than incongruent pairings. An example of a congruent pairing would be a human agent paired with motion capture belief or a robotic agent paired with computer-generated belief, whereas incongruent pairings would feature a human agent paired with computer animation belief or the robotic agent paired with motion capture belief. The inverse interaction examined brain regions more engaged when viewing the incongruent agent/belief pairings compared to the congruent pairings. 

All neuroimaging analyses were evaluated at the whole-brain level with a voxel-wise threshold of   p   < 0.005 uncorrected and   k   = 10 voxels [ ].   lists all regions that meet this threshold. To most clearly illustrate all fMRI findings,   t  -images are visualized on a participant-averaged high-resolution anatomical scan. Parameter estimates (beta values) were extracted and plotted for visualization purposes only for the two interaction analyses. Anatomical localization of all activations was assigned based on consultation of the Anatomy Toolbox in SPM [ , ].
   
Main effects and interaction from whole-brain analyses. MNI coordinates of peaks of relative activation within regions responding to the main effects of agent, collapsed across instruction (a: observing a human compared to a robot perform an action; and b: observing a robot compared to a human perform an action), the main effects of belief manipulation, collapsed across agent (c: observing actions said to be made by human motion capture compared to computer-generated animation; and d: observing actions said to be made by computer-generated animation compared to human motion capture) and the interactions between agent form and belief manipulation (e: observation of congruent agent/belief pairings; and f: observation of incongruent agent/belief pairings). Results were calculated at a voxel-level threshold of   p   < 0.005,   k   = 10 voxels. Up to three local maxima are listed when a cluster has multiple peaks more than 8 mm apart. Entries in bold denote activations significant at the false discovery rate cluster-corrected level of   p   < 0.05. HF, human form; RF, robot form; MCB, motion capture belief; CGB, computer-generated belief. 
  




## Results 
  
### Behavioural data 
  
During scanning, participants rated each video on how smooth they found the movement or how much they enjoyed watching it. Due to an error in the MATLAB code, it was not possible to separate ratings of liking and smoothness for the main experiment. However, a follow-up behavioural study was performed with 30 naive participants who performed the identical task with the same stimuli. These data showed that across all 120 stimuli/instruction pairings, ratings of liking and smoothness correlated at   r   = 0.53,   p   < 0.001. As prior work suggests that both questions tap into the same psychological construct (i.e. we tend to like movements more that are smooth [ ], and participants' ratings of movement smoothness and liking strongly correlate in other experimental settings [ ]), we considered it valuable to examine behavioural responses as a single combined variable. A repeated measures ANOVA revealed that participants rated movements they thought to be generated by human motion capture as significantly smoother and more pleasing to watch than videos they believed to be generated by computer animation,   F   = 21.28,   p   < 0.001 ( ). No main effect of agent (  p   = 0.39) emerged, nor was any interaction between belief and agent manifest in the data (  p   = 0.79). These data suggest that beliefs influence our dependent measure more than an agent's form.
   
Behavioural data from fMRI task. Plots illustrate mean ratings reported by participants to questions interrogating how smooth participants found the movements or how much they enjoyed watching them. A main effect of belief was manifest, such that participants found those action videos they believed to originate from human motion capture techniques to be smoother and more enjoyable to watch than videos they believed to originate from computer-generated animation. No other main effects or interactions were observed. 
  


### Functional imaging data 
  
#### Main effects of stimulus cues 
  
The first imaging analyses investigated the extent to which visual cues to human animacy influence action perception. No suprathreshold clusters emerged from the human > robot form contrast. The inverse contrast (robot > human form) revealed engagement of bilateral ventral temporal and occipital cortices, which survived correction for multiple comparisons (  p   < 0.005,   FWE  -corrected), as well as   engagement of portions   of the left superior temporal gyrus and hippocampus (  b   and   a  ). Similar to findings reported by Cross   et al  . [ ], this result suggests greater high- and low-level visual engagement when observing a robotic agent execute actions.
   
Main effects of agent form (stimulus) and belief manipulation (knowledge). Panel (  a  ) illustrates brain regions more engaged when participants watched actions performed by a robotic avatar compared to a human avatar. Panel (  b  ) shows brain regions more engaged when participants watched videos they believed to originate from human motion capture compared to computer animation. Full details of these findings are presented in  . STG, superior temporal gyrus; FG, fusiform gyrus; IOG, inferior occipital gyrus; SPL, superior parietal lobule. 
  


#### Main effect of knowledge cues 
  
The next set of contrasts evaluated the impact of belief or knowledge cues to human animacy on action perception. The first contrast (human motion capture > computer keyframe animation belief) revealed activity within the right inferior occipital and fusiform gyri. While these brain regions did not survive correction for multiple comparisons, it is nonetheless of interest to note that the cluster located within the right inferior occipital gyrus closely corresponds to functional localizations of the OFA (less than 6 mm away [ ]). Moreover, the peak of the cluster in fusiform gyrus is 14 mm away from an average peak location of this region when functionally localized, as reported by Spiridon   et al  . [ ]. It should be noted, however, that the fusiform cluster identified in the present study is more anterior to most reports of the FFA. Clusters also emerged in the left precuneus, as well as the left superior parietal lobule also emerged from this contrast (  c   and   b  ). The response in the precuneus corresponds closely to responses typically found with a theory of mind localizer task based on comparing beliefs to physical stories [ ]. The inverse contrast (computer keyframe animation > human motion capture) did not reveal any suprathreshold activations. 


#### Interaction between stimulus and knowledge cues 
  
The next set of analyses investigated the extent to which brain regions associated with social perception are influenced by the interaction of stimulus and knowledge cues to human animacy. The first interaction examined congruent pairings of agent and belief compared to incongruent pairings ((human form + motion capture belief) and (robot form + computer animation belief) > (human form + computer animation belief) and (robot form + motion capture belief)). Three uncorrected clusters emerged along the midline cingulate cortex, including middle and posterior cingulate cortices (  e   and electronic supplementary material, figure A). The parameter estimate plots reveal evidence for crossover interactions for the two middle cingulate activations, while the interaction within posterior cingulate cortex appears to be driven most by a stronger response to the human agent being paired with motion capture instructions compared to computer animation instructions. 

The inverse interaction evaluated brain regions more engaged when observing incongruent compared to congruent form and belief pairings ((human form + computer animation belief) and (robot form + motion capture belief) > (human form + motion capture belief) and (robot form + computer animation belief)). This contrast revealed two uncorrected clusters: one in the right inferior frontal gyrus, and a second in the cerebellum (  f   and electronic supplementary material, figure B). For this interaction, it is of note that the interaction present within these two brain regions is driven by different stimuli (see parameter estimates in electronic supplementary material, figure B). Specifically, robotic agents paired with motion capture instructions seem to drive the cerebellar region most strongly, while the human agents paired with computer animation instructions drive the inferior frontal gyrus region most. 




## Discussion 
  
Prior research has revealed that many different cues to human animacy engage brain networks associated with social cognition, while less is known about the relationship between these cues. In the present study, we used video stimuli featuring kinematically identical actions performed by a human or robotic agent and an elaborate belief manipulation to test the extent to which stimulus and knowledge cues to human animacy influence perception. Behaviourally, participants reported actions believed to originate from human motion capture to be smoother and more enjoyable to watch than those believed to have computer animation origins, while differences in agent form did not affect ratings. The neuroimaging findings echoed this pattern, with knowledge cues to human animacy showing subtle influence (at a liberal threshold) on brain circuits implicated in social cognition. 

We failed to find evidence that visual cues to human animacy more strongly engage the action observation, person perception or theory of mind networks than visual cues to a robotic agent, as might have been predicted. In contrast, we found a robust, cluster-corrected area of activation spanning ventral temporal and occipital cortices when participants observed actions performed by a robotic compared to human-like agent. These findings raise questions about the role played by stimulus cues to human animacy, while also highlighting the influence of knowledge cues on social perception when perceiving identical agents and actions. Together, they provide new insights into the supporting neural architecture and behavioural consequences of social perception. 

### Belief about humanness influences perception, as shown by brain and behavioural responses 
  
While some prior studies have failed to find evidence that belief about the human origins of a stimulus can impact perception [ ], a growing body of evidence supports the notion that beliefs about humanness influence the way we perceive and imitate other agents [ – , ]. Our results are consistent with these findings as participants were more likely to report actions supposedly originating from real human movements as smoother and more pleasing to watch (questions that tap into how natural or human-like an agent or action appears [ ]). Our findings also fail to demonstrate that differences in agent form influence these ratings, which further suggests that knowledge cues can dominate stimulus cues in explicit evaluation of social features of an observed action [ ]. A challenge for future behavioural research will be to systematically investigate how knowledge cues to animacy impact different facets of social cognition. To date, for example, perceptual and imitative processes have been studied separately, and the relationship between these key aspects of social cognition and knowledge cues to human animacy remains unexplored. 

At the neural level, our findings provide some evidence that actions paired with a human- compared to computer-generated belief lead to greater engagement of brain regions associated with person perception and theory of mind. Specifically, portions of the right inferior occipital gyrus and fusiform gyrus responded more to the same stimuli when they were paired with human motion capture instructions. Both regions are located in close proximity to patches of cortex that are face selective including the OFA [ ] and fusiform face [ ] and body areas [ ]. It is of note that these two brain regions associated with processing the human face were modulated in this instance by social knowledge, and not differences in stimulus-driven features. 

Also important is the emergence of a cluster within the right precuneus from this same contrast. The precuneus is consistently implicated in theory-of-mind tasks and is believed to play a role in explicit belief processing [ , ]. If these results were to be replicated by future studies, they would suggest that parts of the social brain network involved in perceiving others' physical features and reasoning about others' minds are engaged when viewing agents whose actions are believed to have human origins. Revisiting the study by Stanley   et al  . [ ], these researchers varied the motion parameters of point-light actions (ranging from veridical displays of the original action to completely scrambled versions of each action), and, as in the current study, they also varied instructions (human- or computer-generated). For the main effect of instructions (human > computer), and similar to the present study, Stanley and co-workers reported greater engagement of brain regions associated with mentalizing. Consistent with Stanley and co-workers' interpretation of this finding [ ], we propose that based on believing that an agent is more human in nature, greater demands are placed on extracting relevant cues to support and evaluate this belief, changing the observer's perception of the social scene. In other words, it seems plausible that visual inputs are matched against a human template more in the human- than computer-belief condition. This process engages theory of mind and person perception in combination. This interpretation, however, remains speculative at this stage and will require further research to test it thoroughly. 


### Revisiting stimulus cues to human animacy and the action observation network's role in social perception 
  
In contrast to a number of previous studies [ , , , ], we failed to find behavioural or brain-based evidence that stimulus cues to human animacy enhance action perception relative to non-human stimulus cues. Instead, we contribute further support, which survives correction for multiple comparisons, to a growing body of evidence that suggests that non-human stimulus cues can lead to the same or even an enhanced engagement of high- and low-level visual areas and the AON [ , – ]. Specifically, we add to the evidence that social brain circuits including the AON are frequently indifferent to stimulus cues to human animacy. 

Although visually salient differences between the human and robot avatar are apparent, the AON did not respond to this difference in the present study. An exploratory analysis of each stimulus form compared independently to an implicit baseline revealed that observing the human or robot agent in isolation resulted in widespread, robust engagement of bilateral AON, fusiform and occipitotemporal brain regions. The results of these simple contrasts help to rule out the possibility that the lack of findings in the human > robot contrast are due to a peculiarity of the human stimuli not engaging such brain networks on their own. The present findings could possibly be due to the fact that both agents executed the identical goal-directed actions (cf. [ , ]) or because the robot and human forms shared some features (i.e. a head atop a torso with two arms). Even though the human and robot forms were generated with the same CGI package, one potential reason the AON might have failed to discriminate between the agents might be because the human form was slightly less human than a video of a real person would be. Another possibility for why we found greater engagement of brain regions associated with person perception when observing a robot compared to a human could be that these brain regions are engaged to assimilate the robotic agent with a more familiar and predictable human template. A similar idea was discussed by Cross   et al  . [ ] in light of finding more robust AON engagement when observing robotic compared to human-like actions. Recent work [ ] lends tentative support to the idea that greater engagement of occipitotemporal brain regions when observing unfamiliar visual stimuli (such as the robotic actions in [ ] and the robotic agents in the current study) might indeed be due to differences in predictability, as outlined by a predictive coding model of action perception [ ]. 

Regardless of the reason for the absence of a difference in AON engagement observed between human and non-human stimulus cues in our study, the current findings suggest that the importance of a human-like form to social perception may have been overstated. Other factors such as top-down beliefs [ , ] and bottom-up kinematic information [ ] also shape social cognition when perceiving and interacting with others [ , ]. Our data help to redress the balance of how much weight the AON assigns to self–other similarities on a form-based, visual level. Future research investigating perception of human animacy may explore which social brain mechanisms are specifically tuned to respond to the extent to which a stimulus is perceived as being ‘like me’, and what other complementary mechanisms might be at play [ , ]. Returning to the ‘like-me’ account of social cognition, the current findings contribute to this view by demonstrating that social brain circuits may be tuned to detect human animacy based on knowledge cues that signal an agent to be ‘like me’. 

While we fail to find behavioural or imaging evidence demonstrating that visual cues to humanness influence social perception, it should be noted that exploratory further analysis of the human > robot form contrast (evaluated at   p   < 0.01,   k   = 10 voxels) revealed activity within the right temporoparietal junction, centred on coordinates   x   = 51,   y   = −37,   z   = 27. While this finding provides weak evidence that brain structures implicated in social cognition [ ] might indeed be more engaged when observing human compared to robotic agents, we are reluctant to interpret this finding further due to the lack of statistical strength. The clearer message to emerge from the main effects of the present study is that top-down belief cues to human animacy shape social perception to a stronger degree than bottom-up visual form cues to human animacy, with stimuli paired with human beliefs associated with engagement of brain regions implicated in person perception and theory of mind. 


### Interactions between stimulus and knowledge cues to human animacy 
  
The design of the present study enabled us to address how stimulus and knowledge cues to human animacy interact during action perception. Findings from the contrast comparing congruent with incongruent pairings of stimulus and knowledge cues failed to show modulation of the action observation, person perception or mentalizing networks. Instead, we report engagement of three uncorrected clusters spanning the middle and posterior cingulate cortex. However, as this finding was not predicted, we are reluctant to interpret it further. The result from the incongruent pairings interaction revealed an uncorrected cluster within the right inferior frontal gyrus located in a similar coordinate space to recent meta-analyses of the AON [ , ]. One simple interpretation of this finding, consistent with a rich literature on executive control, is that viewing incongruent pairings of agent form and humanness belief requires greater attentional control than when pairings are congruent [ ]. Alternatively, it is possible that increased engagement of this sensorimotor brain region when viewing incongruent stimulus and knowledge pairings relates to increased demands on motor simulation mechanisms to reconcile human and artificial features of an observed agent. In order to evaluate this necessarily speculative interpretation, further research is required to replicate and more fully delineate how stimulus and knowledge cues to human animacy interact. If we take a step back and attempt to construct a broader view of how the current study's findings fit in to the wider literature on the biological substrates of social perception and social cognition, given that some findings do support the ‘like-me’ hypothesis [ – ], while others do not [ – ], and the fact that not all reported results survive correction for multiple comparisons, replication of these findings will be important for future progress towards understanding how we perceive animacy in other agents. 


### Multiple routes to socialness and considerations for social artificial agent design 
  
The theoretical implications of the current study and research reviewed in this paper extend beyond the laboratory and serve to inform disciplines in addition to social cognition and neuroscience, including robotics. Over the past decade, individuals working to develop socially interactive artificial agents, including robots and avatars, are taking an increased interest in social cognition and social neuroscience research that examines the impact of ‘like-me’-ness on how we perceive and interact with such agents [ – ]. An ongoing goal for robotics designers has been to maximize the similarity of artificial agents to humans, in terms of appearance and movement (while perhaps attempting to circumnavigate the uncanny valley), in an attempt to make particular artificial agents as ‘like me’ as possible [ ]. However, findings from the current study and considerations raised by related work suggest that how an agent is perceived as being ‘like me’ can take many forms and is not only dictated by how convincingly a robot looks or moves like a human. Pre-conceived beliefs about robots will impact their reception in the workplace, schools, care homes and other social settings, and will undeniably shape how effective human–robot interactions will be. Thus, human knowledge about and attitudes towards robots will need to be optimized as much as a robot's physical form and motion parameters. As such, roboticists and computer animators stand to benefit from further dialogue and collaboration with researchers investigating mechanisms of social perception and their consequences for social interaction. 



## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-43'>
<h2>43. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/25885446/' target='_blank'>25885446</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Dual Logic and Cerebral Coordinates for Reciprocal Interaction in Eye Contact</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2015</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0121791</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4401735/' target='_blank'>4401735</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Meets all inclusion criteria: 3T fMRI data were acquired during social tasks (dyadic eye-contact tasks A and B), involving healthy adult participants (19 pairs, ages 18–33; informed consent and IRB approved). Analyses report whole-brain preprocessing, group GLM and paired t-tests registered to MNI152, cluster results and atlas labels (CCRI masks), and group-level ICA projecting ICs onto whole-brain CCRI—i.e., whole-brain results rather than ROI-only analyses. Not a review/meta-analysis and no clinical/psychiatric sample. Although partial occipital signal loss is noted, the study reports whole-brain results and uses standard atlas labeling, so it satisfies the review’s requirements.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
In order to scientifically study the human brain’s response to face-to-face social interaction, the scientific method itself needs to be reconsidered so that both quantitative observation and symbolic reasoning can be adapted to the situation where the observer is also observed. In light of the recent development of dyadic fMRI which can directly observe dyadic brain interacting in one MRI scanner, this paper aims to establish a new form of logic, dual logic, which provides a theoretical platform for deductive reasoning in a complementary dual system with emergence mechanism. Applying the dual logic in the dfMRI experimental design and data analysis, the exogenous and endogenous dual systems in the BOLD responses can be identified; the non-reciprocal responses in the dual system can be suppressed; a cerebral coordinate for reciprocal interaction can be generated. Elucidated by dual logic deductions, the cerebral coordinate for reciprocal interaction suggests: the exogenous and endogenous systems consist of the empathy network and the mentalization network respectively; the default-mode network emerges from the resting state to activation in the endogenous system during reciprocal interaction; the cingulate plays an essential role in the emergence from the exogenous system to the endogenous system. Overall, the dual logic deductions are supported by the dfMRI experimental results and are consistent with current literature. Both the theoretical framework and experimental method set the stage to formally apply the scientific method in studying complex social interaction. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (53468 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
In order to scientifically study the human brain’s response to face-to-face social interaction, the scientific method itself may need to be improved, so that both quantitative observation and symbolic reasoning can be adapted to the situation where the observer is also observed. 

Directly detecting two interacting brain responses is only now possible with the recent development of dyadic fMRI (dfMRI) [ ]. Although EEG [ , ] and MEG [ ] have been used for dyadic data acquisition, they are limited by their coarse spatial resolution. Also, MRI “hyperscan” (scanning a dyad from two different scanners) [ ] or fMRI with recorded video for social stimulation [ ] have also been utilized in the past to indirectly observe dyadic interaction. However, the video and audio links compromise some of the reciprocity between the dyad. The newly developed dfMRI has largely removed the instrumental limitations, and provides sufficient spatial and temporal resolution for directly measuring dyadic BOLD hemodynamic activation during face-to-face social interaction. 

Given the fact that the observers are also observed in the dfMRI experiment, most existing syllogistic logic seems insufficient in providing a deductive reasoning framework for the analysis and synthesis of dfMRI data. To systematically address one of the essential issues in social interaction studies—the entwinement between reciprocal and non-reciprocal response [ ]—a dual logic derived from abstract algebraic logic is established to provide a logical framework in which an interacting brain can be formulated by a dual system [ ]. Within the dual logic framework, a propositional model was created for distinguishing reciprocal and non-reciprocal brain responses during eye contact in the dfMRI experiment. Based on this model, dual logic deductions can analytically suppress the non-reciprocity and yield the dual systems for reciprocal interaction. 

Social neuroscience has accumulated a large amount of fMRI observations [ ], including many empirical data on eye gazing [ ]. However, in the study of social interaction [ – ], explicitly distinguishing between reciprocal and non-reciprocal components in their entwined BOLD responses has been elusive. By applying dual logic deduction in a dfMRI experiment, a data-driven dual systems [ ] for reciprocal interaction during eye contact can be derived. This dual system can subserve cerebral coordinate for reciprocal interaction (CCRI), and could have broad applications in general dyadic data analysis for filtering out non-reciprocal responses. An example of CCRI used in computing reciprocal coupling modes during eye contact is provided here. 

Given the vast context of the topic, the main focus of this paper is limited to dual logic, the CCRI, and an example of an application of the CCRI. The goal is to demonstrate that logical deduction can elucidate the dfMRI data and extracts deterministic aspects of the experimental results. The detailed dyadic interaction analysis is beyond the scope of this work. 


## Theory 
  
During social interaction such as eye contact, brain responses can be classified by a dual system: the exogenous system and the endogenous system. By definition, the exogenous system directly responds to any exteroceptive stimulus; the endogenous system can only be activated by interoceptive stimulus. The dual logic is proposed for deductive reasoning in these dual systems during the eye contact in the dfMRI experiment. 

In order to observe reciprocity in eye contact, the dfMRI experiment was designed as follows: Two subjects are laid on their sides, facing each other as in  . The relative positions of their eyes and faces are locked in position as shown in   to create a “laboratory eye contact” scenario. Two functional tasks are performed as shown in  . During the tasks, the two subjects are verbally instructed to open and close their eyes either simultaneously in task A, or alternately in task B. 
   The outline of the dfMRI eye contact experiments.  
The (a) illustrates the dual-head coil and the dyadic placement in a commercial MRI scanner; the (b) is a 3D rendering of a dyadic anatomical data set, which illustrates the physical stimuli and BOLD responses in the experiments; the (c) depicts the temporal courses of dyadic stimuli: eye opening and/or closing in the task A and B. 
  
To analytically distinguish reciprocal and non-reciprocal responses in the dual system in the eye contact experiment where only binary states of task (eyes open/closed) and response (activation on/off) are of concern, the dual logic is constructed as an extension of Boolean logic. Such a construct in abstract algebraic logic is detailed in Appendix A, where the binary logic   and     are for the exogenous and endogenous system respectively, and non-binary logic operations are defined for emergence from the exogenous system to the endogenous system. 

Within the dual logic framework, a brain in the dfMRI experiments in   can be formulated by a stimulus-response model shown in  , in which every stimulus and response are decomposed into two states for the purpose of distinguishing reciprocity and non-reciprocity. 
   A block diagram describes the exogenous-endogenous dual systems and their stimuli-responses model.  
The exteroceptive stimulus σ consists of   p   and   q   states for “seeing eyes only” and “seeing face without eyes”. The arising interoceptive stimuli π and θ are the dual pairs of   p   and   q  . The BOLD response Ω consists of exogenous response Ω  and endogenous response Ω . The exogenous Ω  can be further decomposed to two states   x   and   y   for “reciprocal responses and non-reciprocal responses; the endogenous Ω  can also decomposed to two states ξ and ψ which are the dual pairs of   x   and   y  . 
  
### Stimulus states 
  
In the experiment shown in  , reciprocity only exists when the dyad’s eyes meet. Thus, when a subject looks at his/her partner, the exteroceptive stimulus, “I see a face”, can be decomposed into: “I see eyes only, with either a direct or averted gaze” (  p  ), and “I see a face without eyes” (  q  ). Here,   p   and   q   are the state variables in the logic   for the two dichotomous states of the exteroceptive stimulus. Their logic values are binary “1” or “0,” corresponding to “true” or “false” of the propositions   p   and   q  . Such bi-state exteroceptive stimuli can be expressed by the matrix σ for algebraic logic operation. The functionality of the σ is the disjunction of first and second row of the matrix,
 
The   p   and   q   represent the exteroceptive stimuli of “seeing” a face. Their corresponding interoceptive stimuli π and θ can be described by the propositions “I mentalize eyes only” and “I mentalize a face without eyes” respectively [ ], which represent “mentalizing face”. Notice that in this eye contact experiment scenario, “seeing” and “mentalizing” not only are two independent processes but also can coexist. To fully capture such orthogonality and to avoid any degeneracy in algebraic logic expression, the logic values of π and θ are adapted to binary “  i  ” or “0”, corresponding to “true” or “false” of the variables π and θ in the logic  . Here, “  i  ” is the imaginary unit of the complex number. 


### Response states 
  
The cerebral response measured by BOLD effect (Ω) is modeled by the exogenous and endogenous dual systems. The exogenous response (Ω ) is activated by the exteroceptive stimulus (  p  ,   q  ); the endogenous response (Ω ) is activated by the interoceptive stimulus (π, θ). For the same reasons in describing stimulus, the response variables Ω  and Ω  are also depicted by logic   and   respectively. In order to untwine the reciprocal and non-reciprocal responses during eye contact, the Ω  can be further decomposed into two salient states: the exogenous reciprocal state (  x  ) that is only mediated by simultaneous mutual eye contact (  p  ), and the exogenous non-reciprocal state (  y  ) that can be induced by either   p   or   q  . Here   x   and   y   are the state variables in  , with truth-values “1” or “0” which correspond to ON or OFF of the exogenous activations regardless of their magnitudes. The Ω  can also be further decomposed into two states: the endogenous reciprocal state (ξ) and the endogenous non-reciprocal state (ψ). Here ξ and ψ are the logic variables in  , with truth-values “  i  ” or “0” which correspond to ON or OFF of the endogenous activations regardless of their magnitudes. 

In the binary logic   and   sets, if both the reciprocal and non-reciprocal states share a common cerebral region within either the exogenous or endogenous system, such overlapping can be easily expressed as   x   ∨   y   or ξ ∨ ψ. However, if overlapping occurs between the exogenous and endogenous system, Ω  and Ω , the truth-value may become complex 1+  i  , and quinary logic may be needed, (see Appendix A). Given that the concerns of this experiment are only binary in nature, i.e. opening/closing eyes or activation/non-activation, the   -   logic sets seem to be mostly sufficient, except in depicting the transition between the dual systems, which is detailed in the later sections and Appendix A. 


### Axioms 
  
At the state level, to establish the logical connection between the stimulus states (  p  ,   q  ; π, θ) and the response states (  x  ,   y  ; ξ, ψ), three axioms are postulated based on self-evident truth-tables and the duality principle from De Morgan logic: 

#### Axiom 1 
  
The exteroceptive stimulus   p  , with either direct or averted gazing [ ], is logically related to the disjunction of the exogenous reciprocal response (  x  ) and the non-reciprocal response (  y  ) by the logical connective of “material equivalence”, 


#### Axiom 2 
  
The exteroceptive stimulus   q   is logically related to the exogenous non-reciprocal response (  y  ) in “material equivalence”, 


#### Axiom 3 
  
The exogenous states (  p  ,   q  ;   x  ,   y  ) and endogenous states (π, θ; ξ, ψ) are dual pairs in the logic   and  , and they obey the duality principle in De Morgan logic. Since the dual pairs for ↔ and ∨ are ⊕ (exclusive disjunction) and ∧ (conjunction) respectively, the relations between the interoceptive stimuli and their responses in endogenous system become,
 
Although this axiom is a theoretical conjecture, it is supported by some computational and experimental evidence [ , ]. More importantly, the logical predictions based on these axioms are in agreement with the experimental data in this study, as well as current literature. The derivations of the three axioms are detailed in Appendix B. Based on these three axioms, all causal stimulus-response relations in this study can be logically deduced, as shown in  . 
   The dual logic.      


### The stimulus and response states in the original tasks 
  
To describe the stimulus in task A, substituting its two temporal stages (see and not-see) illustrated in   into its dichotomous states   p   and   q   in  , the stimulus matrices for both left and right subjects are:
 
For the task A’s cerebral response Ω , although its endogenous states are elusive, its exogenous reciprocal states (  x  ) are likely entwined with its exogenous non-reciprocal states (  y  ). The symbolic expressions for such entwinements in the exogenous system are explicitly described in  , where the response (Ω  = 1) can be the results of either (  x   = 0,   y   = 1), or (  x   = 1,   y   = 0), or (  x   = 1,   y   = 1). To suppress the non-reciprocal state   y   in the Ω , an additional task B is introduced, whose stimulus matrices for both left and right subject can also be derived from   and   as:
 
Due to the lack of eye contact, the cerebral response in task B (Ω  = 1) is the result of the only non-reciprocal response (  x   = 0,   y   = 1), as shown in  . Although neither task A nor B can result in an explicit reciprocal response, the collation (defined in Appendix A) between the states in task A and B can yield the desired states. Note that the functionality   f  (σ) defined in   for the four stimulus matrices in the   and   are the unit regressors in the task A and B ( ). 
   Truth table for BOLD responses in task A, B, A-B, and B-A.      

### The composite stimuli for reciprocal interaction 
  
Because only the proposition “I see eyes only” can induce reciprocity, the goal would be to generate a stimulus matrix that contains   p   only. Applying collation operation to the left subject, between σ (L) in   and σ (L) in  , will generate two composite stimuli:
 
In both σ (L) and σ (L), the non-reciprocal state   q   is removed (  q  ≡0). For the stimulus σ (L),   p   = (0 1) and   q   = (0 0) describe that subjects periodically see their partner’s eyes but not the rest of the face. Based on  , the functionality of stimulus σ (L) becomes   f  (σ (L)) =   p  . Moreover, the fact that all the truth-values in σ (L) remain real numbers after collation suggests that σ (L) is still a Boolean matrix in logic  , and is still an exteroceptive stimulus that stimulates the exogenous system. 

The result for σ (L) is much more significant and less intuitive. Referring to Appendix A, after being subjected to the collation operation,   p   has truth-value -1 which means “inconsistent” in the three-valued logic. Such inconsistency or “error” in the real Boolean logic   can be transformed to another self-consistent imaginary Boolean logic   by “-1 =   i  *  i  ” mapping in algebraic logic. The σ (L) clearly becomes two interoceptive stimulus matrices that contain stimuli π and θ, whose propositions are “I mentalize eyes” and “I mentalize a face without eyes.” Because the first and second imaginary matrices describe π = (0   i  ) and θ = (0   i  ) respectively, the functionality of task σ (L) then becomes   f  (σ (L)) = π∧θ. Thus, the collation operations in   and “-1 =   i  *  i  ” mapping convert the exteroceptive stimuli σ (L) and σ (L) into one exteroceptive stimulus σ (L) and one interoceptive stimulus σ (L). Most significantly, the σ (L) becomes the cause for emergence of the endogenous response due to inconsistency in the exogenous response. 

As a side note, the collations of the stimulus matrices for the right-side subject group yield different composite stimuli than those from the left-side subject group in   due to the phase difference in the stimulus time courses in  :
 
Unlike the left-side composite stimuli, σ (R) is not a pure exteroceptive stimulus, and σ (R) is not a pure interoceptive stimulus. Therefore their responses are mixtures of the exogenous and endogenous systems. This is because the initial phase in a complex number time series bears significant information. Meanwhile, since time-invariant feature in a dual system could be a more complicated issue beyond the scope of this study, no time shift in σ (R) to match the σ (R)’s phase is performed here. Fortunately, the BOLD responses that are statistically derived from the left-side group by mixed-effects analysis should apply to the right-side subject group in a standard brain space. Thus, in all the later text the σ  and σ  represent only σ (L) and σ (L) in this study. 


### The responses to the composite stimuli 
  
The logical deductions of the stimulus-response transformations (σ-Ω) for the composite stimuli (σ  and σ ) are listed in   as A-B and B-A, and their derivations are detailed in Appendix C. Based on the transformations, the cerebral responses for the composite stimuli are expressed in truth-table in   as Ω  =   x  ∧¬  y   and Ω  = ¬(ξ∧ψ)∧¬ψ. Notice that Ω  is only composed of the exogenous states, while Ω  is only composed of the endogenous states. Thus, the dual logic deduction results explicitly formulates that the exteroceptive stimulus σ  causes the exogenous response Ω  and the interoceptive stimulus σ  causes the endogenous responses Ω . 

According to  , the exogenous system activation (Ω  = 1) is the result of a reciprocal state (  x   = 1,   y   = 0), where the non-reciprocal   y  -state is suppressed. However, the endogenous system activation (Ω  =   i  ) is a superposition of both the reciprocal state (ξ =   i  , ψ = 0) and a default state (ξ = 0, ψ = 0), albeit the non-reciprocal ψ-state suppression. Note that the default state is neither reciprocal nor non-reciprocal. It is an intrinsic system embedded in the endogenous system, activated when the endogenous system emerges during dyad’s reciprocal interaction. With logical rigor and determinism, the Ω  and Ω  mark the cerebral regions where reciprocity occurs during eye contact, which can subserve a cerebral coordinate for reciprocal interaction (CCRI). 



## Methods 
  
### Participants 
  
The Princeton University institutional review board specially approved this study (IRB #4946). All participants gave informed and written consent based on the approved IRB. A total of 19 pairs (38 individuals) of subjects were enrolled in the dfMRI experiment. Most of the participants were university students. Their average, standard deviation, maximum, and minimum age were 22, 5, 33, and 18 years old. The numbers of pairs for female-female, male-female, male-male were 11, 4, and 4. There were 12 females and 7 males on the left side, and 14 females and 5 males on the right side. Prior to the scans, each participant took a behavioral test called “Inclusion of Other in the Self Scale” (IOS) [ ], for evaluating the closeness between the partners. The average scores for the left and right side subjects were 4.89 and 4.95 with standard deviations 1.45 and 1.39, which indicates the balanced intimacy level between left and right side subject groups. The IOS scale was 1 to 7 (7 for being the closest). 


### Experimental procedures 
  
All subjects were instructed to be natural and calm as much as possible while maintaining spontaneous facial expression during scanning. In task A, when they heard the verbal instruction “close”, the dyad should close their eyes simultaneously; when they heard the instruction “open”, the dyad should open their eyes simultaneously and make eye contact with either a direct gaze or an averted gaze according to their comfort. In task B, when they heard the instruction “one”, the right-side subject should switch to eyes open and the left-side subject should switch to eyes closed. When they heard the instruction “two”, the right-side subject should switch to eyes closed and the left-side subject should switch to eyes opened. All verbal instructions were delivered through headphones. 


### Data acquisition 
  
All functional, anatomical, and field mapping images were acquired on a 3T Siemens Magnetom Skyra MRI scanner (Siemens, Erlangen, Germany) using a custom-made dual-head coil [ ]. The functional protocol was a gradient-echo EPI. Its spatial parameters were voxel size ~4mm×4mm×4mm, FOV 500mm×254mm, slice thickness 4mm, 32 transverse slices, and slice order interleaved. Its temporal parameters were TR 2000ms, TE 30ms, echo spacing 0.52ms, 200 repetition volumes. Its 4D sampling matrix was 128×64×32×200. The field mapping protocol was a double echo gradient-echo sequence with TE1 4.92ms, TE2 7.38ms, TR 1230ms, echo spacing 0.58ms, flip angle 60, and the spatial sampling region identical to the EPI. The anatomical protocol was a 3D MPRAGE with voxel size 2mm×2mm×2mm, 96 coronal slices per slab, FOV 500mmx250mm, and 3D sampling matrix 256x128x96. In every dfMRI experiment, in addition to the task A and B described in  , a functional baseline data was also collected, in which the dyad were closing their eyes during entire scan session. 

The factory-specified homogeneous static magnetic field region for the Skyra is an ellipsoid with three axes: 50cmx50cmx45cm. When two medium-sized subjects are positioned as in  , both of their brains are just able to fit in the ellipsoid, so that dyadic anatomical images can fully capture both brains as shown in  . However, because the EPI sequence is more sensitive to field inhomogeneity, the functional images often miss part of the occipital lobe, see Supporting Information ( ). Given that the main focus of this study is to identify social brain, such as empathy or mentalization networks, excluding the occipital lobe here bears minimal consequences for now. 


### Data post-processing for the CCRI 
  
The BOLD responses for the task A and B (Ω  and Ω ) were calculated by group analysis of general-linear-model (GLM) regression. The exogenous and endogenous systems (Ω  and Ω ) were estimated by paired t-test comparison. Both were implemented by the software package FSL (Oxford University, UK) [ ]. The CCRI was the binary masks of the Ω  and Ω . 

In the preprocessing, each of the dyadic 4D functional data sets from the task A and B was first split into two monadic data sets for separating the left and right subjects. Then all of the monadic 4D data sets were put through motion correction, slice time correction, and brain extraction, as well as spatial smoothing with HMFW 8mm and temporal high pass filtering with a cut-off period of 60s. Each of the dyadic 3D anatomical and field mapping data sets was also split to two monadic data sets for separating the left and right subjects. Then all monadic 3D data sets were put through bias field correction and brain extraction. Note that during each data split, the sampling volume and coordinate information in the header of each monadic data file were reset in order to properly register to the standard MNI152 [ ] template. Meanwhile, since the brain orientations in dyadic data are different from the orientation of the MNI152 template, to avoid rotating all the functional data sets to adapt to the MNI152 template, the MNI152 template was rotated -90° for the left subject registration and 90° for the right subjects registration. The inversed rotation matrices and the new center offset were included in the file header so that the rotated standard images retained an accurate atlas label reading from the Harvard-Oxford Atlas [ ]. The registration contained three steps: First, the “weighted registration” function in FSL was used to initially register the functional data to the bias-corrected magnitude images in field mapping in six degrees of freedom (DOF), with the mask that 25% of the posterior part of image was masked out to avoid signal drops in the occipital lobes and to maintain that the frontal, temporal, and parietal lobes were accurately registered to the MNI152 standard brain. Second, the initially registered images were then registered to high-resolution anatomical images with 12 DOF. Third, the high-resolution images were registered to the standard MNI152 template with 12 DOF. 

After data preprocessing, Group GLM analysis was performed on the preprocessed monadic data sets from both task A and B. The hemodynamic response functions (HRF) were the block waveforms in   convolved by the first three eigen-components in the linear optimal basis set [ ]. The group average GLM for Ω  and Ω  were shown in Fig   and  . The paired t-test comparison for Ω  and Ω  were shown in  – . The activation labeling was based on the “Harvard-Oxford cortical structural atlas” and the “Harvard-Oxford subcortical structural atlas,” which are built-in features of FSL. In the end, the masks of Ω  and Ω  (1 for activation, 0 for no activation) became the CCRI. The atlas labels of Ω  and Ω  became the coordinate ticks in the CCRI, where exogenous and endogenous labels are indexed by real and imaginary numbers respectively, as shown in Fig   and  . 
   The group average GLM results for all left-side subjects.  
The (a) is the BOLD response in the task A, Ω ; the (b) is the BOLD response in the task B, Ω ; the (c) is the probabilistic atlas label distributions for the activations in both the task A and the task B. Note that the abbreviations of the labels’ names in this study are defined here. 
     The reciprocal BOLD responses due to eye contact.  
The (a) is the exogenous responses in which Ω  = 1 when (  x   = 1,   y   = 0); the (b) is the endogenous responses in which Ω  = 1 when (ξ = 1, ψ = 0) and (ξ = 0, ψ = 0). Here the (c) and (d) are the three orthogonal sections of the (a) and (b) respectively; the (e) and (f) are the probabilistic atlas label distributions for the exogenous-endogenous dual system, where the exogenous labels are indexed by real number, and the endogenous labels are indexed by imaginary number. 
  

### An example for applying the CCRI 
  
During eye contact, brain synchronization induced by reciprocal interaction can be decomposed into multiple coupling modes. Each mode represents a different interactive mechanism between dyadic brains. One way to estimate such coupling modes is to apply the independent component analysis (ICA) to the dyadic data from the task A. (Because only task A has eye contact.) The results of ICA are a set of independent components (IC) in which both reciprocal and non-reciprocal responses are entwined. By projecting the IC onto the CCRI, the non-reciprocal responses should be filtered out, and the reciprocal responses in each IC remain. 

The 19 dyadic data sets from the task A were processed in following three steps: First, since FSL can only handle monadic data, in order to assign labels to a dyadic IC with FSL, the dyadic data was first split and preprocessed, then the left and right monadic data were registered to the rotated left and right MNI152 standard templates respectively by using the same procedure as in the group GLM, then merged to form a registered dyadic data set. Second, group level tensor-ICA for all 19 registered dyadic data sets was computed by FSL/melodic and yielded 35 ICs.   selectively displays one of the 35 ICs. Third, in order to project the ICs onto the CCRI, each dyadic IC was split into two monadic data sets again. The split ICs for the left and right subjects were separately multiplied by the properly oriented CCRI first, and then processed for atlas labeling. The activated labels for the right subjects were indexed as a vertical axis. The activated labels for the left subjects were indexed as a horizontal axis. In this way, each coupling mode can be quantified by a matrix based on the labels in the CCRI, as shown in  . 
   One of the dyadic brain-to-brain coupling modes.  
The (a) is one of the independent components derived from the 19 data sets in the task A by group-level ICA. The (b) is the 2D matrix representation of the coupling mode after the IC is projected onto the CCRI. Note that each axis has real and imaginary regions that correspond the exogenous and endogenous labels respectively. All complex numbers and their corresponding labels are listed in the Fig   and  . Here the vertical axis is for right subjects and the horizontal axis is for left subjects. The (c) and (d) are the temporal course and the frequency response of the synchronized process that represented by this IC. 
  


## Results 
  
First of all, applying GLM on the baseline data (dyads closed eyes in entire scan) with the regressors in  , no BOLD activation was observed in dyads, which suggests that neither non-visual stimuli nor physiological coupling contribute to the BOLD responses in the task A and B. 

### The exogenous and endogenous systems Ω  and Ω 
  
The BOLD responses for the original tasks A and B, Ω  and Ω  respectively, are the group averages of GLM with the data from all the left subjects, as shown in Fig   and  , where the inference threshold is Z>2.3 and p-value<0.05. Note that no voxels exhibiting negative BOLD responses were observed in the Ω  and Ω . (Here the right-side subject group analysis is ignored because the logical deduction in   suggests that its paired t-test comparisons between Ω  and Ω  may not yield pure exogenous or pure endogenous response due to their regressors’ phase.) The probabilistic atlas label [ ] distributions for the activated brain regions in the MNI152 standard template [ ] are listed in  , in which the probability of each label is the average probability over the conjunction of the label’s mask (probability>15%) and activation maps (Z>2.3). The selected labels are grouped in six regions: the subcortex, the limbic lobe, the insula/operculum, the frontal lobe, the parietal lobe, and the temporal lobe. All abbreviations of the names of the labels are in  . Due to field inhomogeneity artifacts in the partial occipital lobe, all occipital labels are removed in this list. 

The BOLD responses of the exogenous and endogenous system for reciprocal interaction in eye contact, Ω  and Ω , were estimated by a paired t-test comparison between Ω  and Ω  in a group analysis. Both the exogenous system Ω  and the endogenous system Ω  are shown in Fig   and  , and their cross-section views in Fig   and  . Although the t-test threshold for generating Ω  and Ω  is lowered to Z>1.96 and p-value<0.05 for scoping finer differences, the inference threshold remains Z>2.3 and p-value<0.05 in clustering Ω  and Ω  to identify the dual system. The probabilistic atlas label distributions for Ω  and Ω  in the MNI152 standard template are listed in Fig   and   respectively, where the probability of each label is the average probability over the conjunction of the label’s mask (probability>15%) and the activation maps. Note that, to distinguish the dual systems, the labels in   are indexed by real numbers, and the labels in   are indexed by imaginary numbers. In a cluster analysis, three clusters are identified in Ω ; and seven clusters are identified in Ω . The names, vicinities, voxel sizes, maximal Z-scores, and MNI152 coordinates of the clusters are listed in  . Here, cluster size > 64 voxel, given that the spatial smoothing filter is 8×8. 
   The organization of the exogenous-endogenous system.      
Elucidated by the logical deductions in  , here Ω  is the data-driven exogenous system that responds to reciprocal exteroceptive stimulus   p  ; and Ω  is the data-driven endogenous system that are the responses to both reciprocal interoceptive stimulus π and emergence of the default state during eye contact. The binary masks of the Ω  and Ω  define the data-driven CCRI. 


### An example of using the CCRI to compute dyadic coupling modes 
  
The probabilistic ICA analysis (FSL/melodic) was applied on the dyadic (not split) data sets from the task A. With the mixture-modeling threshold set to 0.8, the group level ICA for all 19 paired data sets yielded a total of 35 ICs. 22 of the ICs had temporal courses that corresponded to the regressor of task A in   and had resonance peaks at 0.025Hz in their frequency response, as in Fig   and  , which indicated that these ICs were in synchrony with eyes opening and closing. Of the 22 eye-contact-related ICs, 14 of them had single and robust resonance peaks, while the other eight had multiple frequency modulations either due to motions or related to ventricles. Of the 14 robust eye-contact-related ICs, four of them were monadic (only activated on one side of subjects), and ten of them were dyadic. These ten dyadic ICs were selected as the exploratory coupling modes. Projecting these ten ICs onto the CCRI resulted in the coupling modes that are in dual system forms and likely contain only the reciprocal responses and default state activations. Here, only one of the ten coupling modes was chosen to demonstrate the application of the CCRI. The complete dyadic coupling mode analysis will be the subject of on-going research due to its extensive contents. 

IC #29 was chosen to briefly exemplify the application of the CCRI.   is the original IC #29. After both the left- and the right-side subjects’ activation maps were projected onto the CCRI, the left-subjects’ labels were distributed on both the endogenous (PCN/PAC, FMC/FP, PRG/POG) and the exogenous (CAU, PRG/POG, SGa). The right-subjects’ labels were distributed on both the endogenous system (PCN/PAC/CGp, FMC/FP) and the exogenous system (CGa/PAC, SMC/F1, T1a/T1p/T2a), as shown in  . This mode seems to illustrate the medial frontoparietal activation in social cognition articulated in the Ref. (8), in which the endogenous (FMC—PCN) between the left-subjects and the right-subjects are synchronized. In addition,   seems to also suggest that this endogenous coupling may be mediated by their exogenous coupling between the left-subjects and right-subjects. The temporal course of this process and its prominent 0.025Hz peak in its frequency response in Fig   and   indicate that this brain-to-brain synchronization occurs when the pairs have eye contact. 



## Discussion 
  
### The dual logic for the dual systems 
  
By expanding Boolean logic, the dual logic can symbolically formulate dual systems with an emergence mechanism. It introduces two original fundamental concepts: First, although it has been elaborated in literature that dual processes operate in significantly different ways in social cognition [ , ], such differences have not been rigorously formulated at the level of formal logic. Here, given the dual system model in  , as well as the binary nature of tasks (eyes open/closed) and responses (ON/OFF) in the experiments in  , the logical connectives between stimuli and responses in the exogenous and endogenous dual systems can be explicitly defined: The exogenous process operates with material equivalence (↔); the endogenous process operates with exclusive disjunction (⊕). Based on this definition, the exogenous process behaves as that of “if and only if a stimulus occurs, then a response is activated”; the endogenous process behaves as that of “if and only if a stimulus is unexpected, then a response is activated”. These are the precise characterizations for the “thermostat” aspect of the relation between the reflexive and reflective systems [ ]. The formal logic description of this relation is the duality principle in which ↔ and (⊕) are a dual pair that are bonded by De Morgan’s law. In the dual logic model for the experiment in  , the “↔” operation in the exogenous system is manifested in the first and second axioms; the “⊕” operation in the endogenous system is manifested in the third axiom. The first and second axioms are self-evident, which are detailed in Appendix B. The third axiom is a conjecture based on both a heuristic “thermostat” description of the dual system and the duality principle. It also seems to be consistent with recent evidence that suggests that ⊕ might be a slower and rule-based way of human brain function [ , ]. 

The second original concept is the use of complex binary numbers as logical truth-values for the dual system: (1, 0) for the exogenous system and (  i  , 0) for the endogenous system. At the fundamental algebraic logic level, the complex truth-value enables formulating emergence in dual systems. As detailed in Appendix A, the logic   and   are two closed binary logic sets for dual systems without concerning the transition process details between dual systems. However, if one has to logically formulate such a transition between the exogenous and endogenous system, binary logic may become inadequate. First, to formulate a basic process of comparison between expectation and proprioception, a three-value logic operation, collation, is defined in Appendix A. Its three truth-values are 1, 0, and -1 for true, false, and inconsistent. Comparing a proprioception to expectation in the exogenous system, if the result of collation is either 1 or 0, then the impact of the proprioception remains in the exogenous system; if collation yields -1, the inconsistency in the exogenous system triggers emergence of the endogenous response. Second, to avoid the degeneracy in describing that brain regions can be shared by the dual systems, the logical truth-value in the endogenous system should be orthogonal to its peer in the exogenous system. In algebraic logic, this can be achieved by a simple mapping -1 =   i  *  i   in a five-value logic, see appendix A. Thus, emergency can be formulated in two steps: collation and -1 =   i  *  i   mapping. 

In this specific experimental situation in which dyads are locked in eye contact and isolated from other mutual or environmental stimuli, given that the tasks (eye open/close) and responses (ON/OFF) are binary, the three axioms in Eqs ( – ) establish the foundation for dual logic deduction. Based on the axioms, the exogenous and endogenous systems can be identified, the non-reciprocal responses can be suppressed, and the existence and emergence of the default state in the endogenous system can be predicted, all by deductive approach. 


### The dual systems per the dual logic 
  
Conceptually, the exogenous-endogenous dual systems can be distinguished by their stimuli being either exteroceptive or interoceptive. Logically, the dual systems operate with different logic connectives that are either material equivalence or exclusive disjunction. In any case, they may slightly deviate from the traditional automatic-controlled dual system in social psychology [ – ]. Their functionality resembles that of the reflexive-reflective dual systems [ ]. Their organization is close to the data-driven externally-focused and the internally-focused dual system framed in cognitive neuroscience [ ]. 

The dual system responses Ω  and Ω  in   and   not only are consistent with the original neural correlates of the externally-focused and internally-focused dual processes [ ], but they also provide more complete brain organizations for the dual system. For the exogenous system where Ω  = 1 if and only if (  x   = 1,   y   = 0), not only does Ω  confirm lateral frontoparietal activation [ ], but it also identifies the regions that largely overlap with the mirror neuron system (F3o, SGa) [ ], imitation circuitry (T1p, mirror neuron) [ ], and the social empathy network (INS, CGa, imitation circuitry) [ ], as well as some afferent and efferent subcortex and motor cortices. For the endogenous system where Ω  = 1 if (ξ = 1, ψ = 0) or (ξ = 0, ψ = 0), not only does Ω  confirm the medial frontoparietal activation (FMC and CGp/PCN) [ ], but it also adds the left AG and FOC to the mix. This activation pattern resembles the DMN [ ], except for its left hemisphere dominant lateral asymmetry. Given that the DMN is usually in resting-state and its function seems to be self-referential (ξ = 0) [ ], its activation may offer evidence for the superposition of the reciprocal social state (ξ = 1, ψ = 0) and the default state (ξ = 0, ψ = 0), which is predicted in  . 

Such dual systems seem to be only activated in face-to-face reciprocal eye-contact. In a separate experiment, described in the Supporting Information ( ), gazing to the eyes in a pre-recorded face video did not prompt the same dual system activations, most likely due to lack of reciprocity. In that case, there is no lateral frontoparietal activation, especially no insular activation, in the exogenous system (A-B); and no medial frontoparietal activation in the endogenous system (B-A)—the DMN remains in resting-state. So it is fair to say that dfMRI can reveal some social brain behaviors that other methods cannot. The fundamental difference between the dfMRI and other methods is that it can capture the unfiltered reciprocity. 


### Emergence mechanism 
  
Although there could be many pathways between the exogenous and endogenous systems, the most obvious transition between the dual systems seems to happen at the cingulate. According to some influential theories, the anterior cingulate (CGa) may be engaged in monitoring conflicts with expectations [ ]; the posterior cingulate (CGp) may be engaged in regulating the balance between internally and externally directed cognition [ ] and in retrieving autobiographical memories [ ]; the cingulate and paracingulate may be responsible for agent recognition in the social domain (“me” and “not me”) [ ]. From an emergence point of view, these previous observations and theories could be nicely explained by the dual system and dual logic. Based on the data-driven CCRI, as shown in  , CGa and PAC are in the exogenous system while CGp and PAC are in the endogenous system. The logical description of the emergence from the exogenous to endogenous system has two steps: the collation that compares proprioception with expectation, and the -1 =   i  *  i   mapping that transcends exogenous inconsistency to the endogenous response. Apparently the collation operation seems to be the logical expression of monitoring conflict, so it should occur in CGa. From the truth table of the collation shown in Appendix A, if the proprioception is the same as the expectations, then the collation results are false (0), which indicates that no conflict is detected and no action is needed. If there is no expectation but proprioception is positive, then the collation result is true (1), the truth-value remains a real number, which suggests an exogenous activation. Most interestingly, if there is an expectation but no proprioception, then collation yields inconsistency (-1), which means conflict or error. Such inconsistency in the exogenous system prompts emergence of the endogenous system by the -1 =   i  *  i   mapping. Given the function of the CGp in regulating the balance between exogenous and endogenous, this mapping likely occurs in the CGp. Overall, during eye contact, saccade of the partner presents constant unexpected proprioception, which results in continuous inconsistency from collation and “-1 =   i  *  i  ” mapping. Such dynamic monitoring conflict and balancing the dual systems constantly recruit the CGa and CGp, and make the cingulate an agent-specific emergence site. 



## Conclusions 
  
The dual logic is proposed for explicitly formulating the dual systems and emergence mechanism between the dual systems. It’s one of the few initial attempts to use the closed logic system to analyze agent-specific observations, especially when the observer is also being observed. It offers a deterministic approach to complement the existing common statistical approaches in neuroimaging analysis. By applying the dual logic in the dfMRI experiment design and analysis, the data-driven exogenous and endogenous systems that delineate the dual logic deduction provide a generic CCRI in which the exogenous and endogenous system consist of mainly the empathy network and mentalization network respectively. Moreover, the logical interpretation of the data-driven endogenous activations elucidates the intrinsic and social characteristics of the DMN; the logical formulation of the transition between the exogenous and endogenous system elicit the role of CG in agent recognition in the social domain. Overall, the dual logic deductions are supported by the dfMRI experimental results and are consistent with current literature. Both the theoretical framework and experimental method set a stage to formally apply the scientific method in studying complex social interaction. 


## Appendices 
  
### A. Construct of a dual system with abstract algebraic logic 
  
In the well-established abstract algebraic logic approach [ ], a logic problem can be transformed to algebraic forms, and resolved with algebra, and transformed back to a logic solution. Given the dual system model in  , as well as the binary tasks (eyes open/closed) and responses (ON/OFF), the binary Boolean logic is mostly sufficient to formulate the dfMRI experiment in this study. Here the definition of the original Boolean logic is given as:
 
Here   wff   means well-formed formula. The truth-values are 1 for true and 0 for false. Although a two-value logic can have a total of 2  logic operations, all of them can be composed by a minimum set of operations ⊕, ∧, and ¬. The   can be transformed to the Boolean algebra
 
Here, the   Alg   is the transformation from logic to algebra. The   F  (  x  ) is the algebraic expression over variables   x  , and   x   has binary values 0 or 1. The logic operations ⊕, ∧, and ¬ coincide with the arithmetic operation +, *, and 1+x, meaning they have the same truth-table operation respectively. Note that addition (+) is performed modulo 2 here. As shown in  , the Br is a subset of a three-valued algebra
 
Here   x   has ternary values 1, 0, and -1. The arithmetic operation subtraction (-) is also performed modulo 2. Its corresponding logic operation (with the same truth-table operation,  ) is defined as collation with symbol ⊖. The logical meaning of 1 is true, 0 is false, and -1 is inconsistent. The practical explanation of the collation (  β   ⊖   α  ) can be described as α being the expectation value, β being the proprioception value. If the proprioception matches the expectations (either α = β = 0 or α = β = 1), then no action is needed (  β   ⊖   α   = 0). However, if the proprioception comes as unexpected (α = 0, β = 1), then the proprioception will prompt action to address the unexpected (  β   ⊖   α   = 1). More interestingly, if the expectation is there but the proprioception is not (α = 1, β = 0), then no proprioception can prompt action to address the unexpected, which results in inconsistency or “error” (  β   ⊖   α   = −1). 
   The transformation between the algebra and the logic.       Collation & Subtraction.      
Meanwhile,   also suggests that the algebra Cr is a subset of a five-valued algebra
 
Here   x   becomes a complex number that has quinary values 1, -1, i,-i, and 0. Note that binary algebra has 2  operations, ternary algebra has 3  operations, and quinary algebra has 5  operations. 

As illustrated in  , applying subtraction (-) over Br area (the 2-by-2 area at the upper left corner in  ) can yield -1. Its corresponding logic explanation is that applying the collation operation will generate an inconsistency in Boolean logic. However, in the algebra D, -1 can be mapped to   i  *  i   with the arithmetic multiplication operation. Given the entire algebra D (∀D), there should be existence of a subset algebra Bi (∃Bi),
 
Here   i  ⊙  i   =   i*i  , the imaginary unit self rotates 2π in the complex plane. If the corresponding logic to the algebra Bi is  , then a subset of   that is bonded with   by the duality principle can be constructed by
 
Here the superscript + represents dual. The   is constructed from the   based on the duality principle. Thus, inconsistency in the logic   prompts emergency of a consistent logic  . 

To avoid confusion, please note that the reason for using ⊕ to define base operation in   is because its logic operation and algebraic operation have the same truth-table. However, when the   is used to model the exogenous system for the experiment, its operation is defined as ↔ in the axiom 1 and 2, in which ↔ can be simply expressed as ¬⊕ in the  . For the similar reason, ↔ is used to define the base operation in   because it is the dual of ⊕. When the   is used to model the endogenous system for the experiment, its operation is defined as ⊕ in the axiom 3, in which ⊕ can simply expressed as ¬↔ in the  . 


### B. Derivation of the dual logic’s three axioms 
  
To determine whether the logical connectives in the first and second axioms are “material equivalence” (↔), and whether the connectives in the third axiom are “exclusive disjunction” (⊕), the truth-table method is employed to avoid ambiguity of the English language. The complete derivation process is shown in  : First off, assuming that all truth-values in the “connective” columns are unknown, then using the exhaustive method determines their values based on self-evidence and the duality principle. Once the truth-tables are completed, the connectives can be uniquely determined. 
   The truth table for the premises.      
The first axiom in   is basic stimulus-response logic for eye-contact in the exogenous system. Generally, it is not only self-evident but also well articulated that seeing other’s eyes (direct or averted gaze) will prompt either social interaction or emotional responses [ ]. In order to use a truth-table to fully describe this event under the experimental condition in   within the frame of the dual system model in  , the “seeing eyes” is expressed as the exteroceptive stimulus (  p  ) and its cerebral responses are expressed as reciprocal   x  -state and non-reciprocal   y  -state. Please note that “seeing eyes” (  p  ) in the first axiom and “seeing face without eyes” (  q  ) in the second axiom are two independent logic variables. They act like two orthogonal axes in describing the task “seeing face”. Thus, when discussing   p   and its responses, none of the responses due to   q   should be any concern. This is important for avoiding confusion in the self-evident explanations. 

The connective between   p   and (  x  ,   y  ) can be derived from the truth-table based on the following self-evidence: In the case that observers cannot see their partners’ eyes, obviously there is neither reciprocal nor non-reciprocal exogenous responses due to exteroceptive stimulus by eye contact. For the proposition that describes this statement, “If   p   = 0, then neither   x   nor   y   can be activated (  x   = 0,   y   = 0)”, its truth-value is true or “1”. For the proposition that contradicts this statement, “If   p   = 0, then there will be activation due to either (  x   = 1,   y   = 0), (  x   = 0,   y   = 1), or (  x   = 1,   y   = 1)”, its truth-value is false or “0”. In the case that the observers can see their partners’ eyes, thus, the exteroceptive stimulus can cause either reciprocal, or non-reciprocal, or both exogenous responses. For the proposition that contradicts this statement “if (  p   = 1), then neither   x   nor   y   can be activated (  x   = 0,   y   = 0)”, its truth-value is “0”. For the proposition that describes this statement, “if (  p   = 1), then there will be activation due to either (  x   = 1,   y   = 0), (  x   = 0,   y   = 1), or (  x   = 1,   y   = 1)”, its truth-value is “1”. A connective with such a truth table is called “material equivalence”, and its formal symbol is ↔. 

With the same argument, the connective in the second axiom in   can be attributed to “material equivalence” (↔) as well. The third axiom in   is basic stimulus-response logic for eye-contact in the endogenous system. Based on the definition in   in Appendix A, the duality principle dictates that all the logic variables and connectives in the endogenous system are simply the dual pairs of the variables and connectives in the exogenous system. 


### C. Deduction for the four transformations 
  
The four stimulus-response transformations in   are the propositional logic descriptions for two original tasks (task A and B) and their two composite tasks (A-B and B-A). Transformation A can be deduced from the first and second axioms:
 
Here, given the stimulus σ  whose functionality f(σ ) =   p  ∨  q  , as shown in the  , the response is inferred as Ω  =   x  ∨  y  , which is entwined reciprocal and non-reciprocal states. Transformation B is a trivial case, since it is equivalent to the second axiom. Given stimulus σ  whose functionality f(σ ) =   q   based on  , the response is inferred as Ω  =   y  . 

The collation operations in the task space in   transform the two exteroceptive tasks σ  and σ  into one exteroceptive task σ  and one interoceptive task σ , where the functionality of σ  becomes   f  (σ ) = (  p  ∨  q  )¬∧  q  , and the functionality of σ  becomes f(σ ) = π∧θ. Note that by definition, the   p   and   q   are dichotomous and independent in stimulus space. Therefore, the   f  (σ ) can be logically simplified to “  p  ” within the stimulus space, which is also consistent with the σ ’s bi-state matrix expression in  . However, due to the first axiom, the relation between tasks (  p  ,   q  ) and their responses (  x  ,   y  ) is not one-to-one mapping, and the operations in the stimulus space and the operations in the response space are not homomorphic. Thus, during the process of deduction from stimulus space to response space, the logical operation steps embedded in the functionality expression of the stimulus (premise) should remain without simplification. The transformation A-B can be deduced from the first and second axiom:
 
So, given the composite stimulus σ  whose functionality   f  (σ  ) =   p   (now it can be expressed in its simplified form after deduction), the response is inferred as exogenous Ω  =   x   ∧ ¬   y  . 

The transformation B-A needs to be deduced in two steps: The first is to show that it yields no exogenous response. The second is to establish the emergence of endogenous response. The exogenous part of the transformation B-A is:
 
Logically speaking, the composite stimulus σ  does not yield any exogenous response. As shown in the  , based on the rule “-1 =   i  *  i  ” in complex numbers, the transformation B-A formulates an emergence of the interoceptive stimulus σ  whose functionality f(σ ) = π∧θ. The endogenous part of transformation B-A can be deduced from the third axiom:
 
Given the composite stimulus σ , the endogenous response is inferred to be Ω  = ¬(ξ∧ψ)∧¬ψ. Since the ⊕ logic is somewhat counterintuitive, the detailed deduction of   by truth-table is provided in   in which ζ = ξ∧ψ. Note that ¬ζ∧¬ψ is the only solution for maintaining conjunction logic. 
   Deduction for the transformation in endogenous system.      


## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-44'>
<h2>44. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/25946306/' target='_blank'>25946306</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Reading a Suspenseful Literary Text Activates Brain Areas Related to Social Cognition and Predictive Inference</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2015</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0124550</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4422438/' target='_blank'>4422438</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This fMRI study acquired whole-brain functional imaging while healthy adult participants (N=23, ages 19–32) performed a task involving reading a literary text and providing suspense ratings. The experimental manipulation and analyses explicitly probe social-cognitive processes (mentalizing/theory-of-mind) and predictive inference: reported activations include medial frontal cortex and temporo-parietal junction—key social cognition regions. Whole-brain GLM results are reported with cluster-level FWE correction (and a separate ROI analysis for the amygdala); the study is not an ROI-only report, nor a review/meta-analysis, and participants were healthy. Therefore it meets all inclusion criteria for fMRI studies of social-related processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Stories can elicit powerful emotions. A key emotional response to narrative plots (e.g., novels, movies, etc.) is suspense. Suspense appears to build on basic aspects of human cognition such as processes of expectation, anticipation, and prediction. However, the neural processes underlying emotional experiences of suspense have not been previously investigated. We acquired functional magnetic resonance imaging (fMRI) data while participants read a suspenseful literary text (E.T.A. Hoffmann's “The Sandman”) subdivided into short text passages. Individual ratings of experienced suspense obtained after each text passage were found to be related to activation in the medial frontal cortex, bilateral frontal regions (along the inferior frontal sulcus), lateral premotor cortex, as well as posterior temporal and temporo-parietal areas. The results indicate that the emotional experience of suspense depends on brain areas associated with social cognition and predictive inference. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (41594 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
   
I could a tale unfold whose lightest word 

Would harrow up thy soul, freeze thy young blood, 

Make thy two eyes, like stars, start from their spheres, 

Thy knotted and combined locks to part 

And each particular hair to stand on end, 

Like quills upon the fretful porpentine. 
  
William Shakespeare,   Hamlet   (1.5.15–20) 
 
Spoken or written words can evoke powerful emotional responses. A prime example of this are stories. For millennia, generations of humans around the world have been moved, fascinated and entertained by stories, and oral traditions of storytelling may be as old as human language itself. Stories—factual or fictional—are omnipresent in human culture: Apart from their artfully refined role in literature (e.g., in novels, short stories, and many forms of poetry and drama), stories are told in a variety of other contexts, and the appeal of movies, songs, speeches, jokes, newspaper articles—and perhaps even scientific papers—often depends on their capacity “to tell a good story”. The human ability to understand, tell, and enjoy stories involves a multitude of cognitive and affective mechanisms including perception, attention, memory, reasoning, simulation of actions, emotion, and, naturally, language. Investigating story processing with modern neuroimaging methods can therefore provide insights into the neural signature of these mechanisms. 

Various neuroimaging studies have begun to tap into the brain mechanisms associated with story processing (for meta-analyses of story and text comprehension studies see [ ,  ]). Most of these studies focus on cognitive aspects of story processing, investigating, for example, neural activations in response to coherent narratives as opposed to unrelated sentences or words [ – ], comparing neural responses to written and auditory text presentations [ ], or probing memory encoding during story processing [ ]. 

Neuroscientific research on emotional responses to stories, however, is scarce, and only a few studies have specifically investigated the neuroaffective processes underlying story processing. An fMRI study by Wallentin et al. [ ] found that the emotional intensity experienced during auditory presentation of a story correlates with heart rate variability, activation of temporal cortices, the thalamus, as well as the amygdala, and that passages associated with positive valence are related to orbitofrontal cortex activations. Investigating emotional valence for short narratives, Altmann et al. [ ] showed that negative story valence is associated with increased activation of theory-of-mind-related brain regions (such as the medial frontal cortex and the temporo-parietal junction). More recently, Hsu et al. [ ,  ,  ,  ] provided fMRI evidence for the fiction feeling hypothesis [ ] stating that narratives with emotional content (in contrast to stories with neutral content) invite readers to empathize to a stronger degree with the protagonists, thus engaging the affective empathy network of the brain. These studies provide first evidence that investigating emotions evoked by narrative plots can offer new insights into neuroaffective brain processes. 

One component of emotional experience that is particularly relevant to story processing is suspense. Suspense is experienced in a huge variety of different contexts ranging from everyday life situations, sports, or gambling to different forms of media entertainment (e.g., film, television, literature, or music). Accordingly, suspense has been discussed by scholars from different disciplines such as literary science, film studies, or media psychology (for introductions, see [ – ]). Creating “the force that draws us through a narrative” [ ], suspense is the predominant emotional response elicited by many types of literary genres (e.g., thrillers, detective stories, spy novels, etc.), and the broad popularity of these genres illustrates the power of suspense to attract audiences and excite emotional responses. Suspense in narrative plots is closely intertwined with processes of prediction and anticipation which are triggered by explicit or implicit questions in the minds of the audience [ ], and which arise from the uncertainty regarding the outcome of the plot (cf. [ ,  ]). Plots of suspenseful novels or movies, for example, often involve conflicts and obstacles that the protagonists have to overcome, making the audience ponder over possible solutions to these conflicts and anticipate their eventual resolution. Predictive inferences during story processing have been found to be related to activation in inferior frontal and posterior temporal regions [ – ], and more generally, action and event prediction have been proposed to be supported by motor-related regions of the brain, in particular the lateral premotor cortex [ ]. Apart from adding to research on affective mechanisms involved in story processing, investigating neural responses to suspenseful narrative plots thus also promises insights into the brain structures associated with predictive inference. Moreover, suspense is closely related to processes of immersion, transportation, or absorption in media reception, such as reading [ ,  ,  ] or computer games [ ], which can be explained by the neurocognitive poetics model of literary reading [ ,  ]. 

At the text level, a suspense discourse organization involves an initiating event or situation, i.e., an event which potentially leads to significant consequences (either good or bad) for one of the characters in the narrative. The structural-affect theory of stories by Brewer and Lichtenstein [ ] states that the event structure must also contain the outcome of the initiating event, allowing to resolve the reader’s suspense. According to the model by Jacobs, the core affect systems “FEAR”, “ANGER”, or “CARE” described in Panksepp’s emotion theory [ ] are likely to be involved in this suspense building process, e.g., when a reader experiences suspense through vicarious fear, because a protagonist is in danger (especially when this danger is only known to the reader), which is mediated by processes of empathy and sympathy. Findings by Altmann et al. [ ] provided initial support for this assumption, indicating that short stories with negative content induce more affective empathy with the described characters in readers than neutral stories, as evidenced by increased brain activity in theory-of-mind and empathy-related areas (i.e., the medial frontal cortex, superior temporal sulcus, and temporo-parietal junction). Hsu et al. [ ] directly tested the model’s assumption and found that immersion (which at the experiential level is related to suspense; [ ]) is associated with activation of the mid-cingulate cortex and is higher for fear-inducing text passages describing protagonists’ pain or personal distress than for neutral passages. 

Although suspense can be measured at both the subjective-experiential (through questionnaires) and more objective behavioral and physiological levels, such as facial expressions, heart rate, or skin temperature [ ], at present, there are no neuroimaging results speaking directly to the issue of suspense in literary reading contexts. 

In the current study, we investigated the neural correlates of suspense experienced by readers during their first reading of a literary text. To this end, we acquired fMRI data while participants read a narrative (E.T.A. Hoffmann's “The Sandman”) subdivided into short text segments. After each segment, participants rated the level of suspense they had experienced while reading the segment. We then identified brain areas in which activation was related to the level of subjectively experienced suspense. Due to the dearth of previous research on neural correlates of subjectively experienced suspense, it was difficult to make specific predictions about brain regions involved in the experience of suspense. However, we were particularly interested in neuroaffective responses to suspenseful text segments. Previous fMRI research from the music domain has found ratings of musical tension—the musical “equivalent” of narrative suspense (cf. [ ,  ])—to be associated with activity changes in the lateral orbitofrontal cortex and the amygdala [ ]. Similarly, the violation, anticipation, and fulfillment of musical expectancies that mediate feelings of tension have been associated with amygdala [ ] as well as dorsal and ventral striatum activations [ ]. We expected suspense to be related to increased activity in similar brain structures associated with affective processing. In addition, based on the results reported by Altmann et al. [ ] and Hsu et al. [ ,  ], we explored whether suspense is related to activation in areas associated with theory-of-mind processing and mentalizing, i.e., the medial frontal cortex and the temporo-parietal junction [ – ]. Furthermore, based on the connection between suspense and predictive processes discussed above, we expected suspense to correlate with activation in brain areas associated with prediction (e.g., lateral premotor cortex). 


## Methods 
  
### Participants 
  
Right-handed German native speakers who were unfamiliar with the story and who enjoyed reading literature (according to self-reports) were recruited as participants for the experiment. Data from 23 participants (12 female, age range: 19–32 years,   M   = 24.1,   SD   = 3.9) were included in the analysis. Data from five additional participants were excluded because they did not finish reading within scanning time (four participants) or answered fewer than two of five control questions that were asked after the experiment correctly (one participant). All participants gave written consent and were compensated with 15 euros or course credit. The study was approved by the ethics committee of the Department for Educational Sciences and Psychology of the Freie Universität Berlin and was conducted in accordance with the Declaration of Helsinki. 


### Stimuli 
  
The narrative “Der Sandmann” (“The Sandman”) by E.T.A. Hoffmann was used as stimulus material. A prominent example of a Romantic narrative devoted to the darker sides of emotional life, the story relates events in the life of the student Nathaniel who—traumatized by the early death of his father—is haunted since childhood by the mysterious Sandman. The story was chosen because of its suspenseful character and uncanny atmosphere (famously discussed in Sigmund Freud's essay”The Uncanny”; [ ]). Importantly, the story features text passages inducing high as well as low suspense (as determined in a preceding pilot rating study), thus ensuring sufficient variability in the suspense ratings to use them as parametric regressor in the fMRI data analysis (see  ). The story was presented in German. To make it suitable for the experiment, the text was shortened (from 12,232 to 6,859 words) and some words that are now out of use and hence unfamiliar were replaced by more common ones to guarantee that participants comprehended the text. Special care was taken to ensure that the shortening of the text did not modify the plot or make the story less comprehensible. For the presentation in the MRI scanner, the story was partitioned into 65 segments of approximately equal length (  M   = 105.5 words per segment;   SD   = 26.1 words). Segmentation was done in such a way that the level of suspense varied across text segments but remained relatively constant within one text segment (  shows the segmented text used in the study). 


### Experimental procedure 
  
Participants read the story, segment by segment, while functional imaging data were recorded. The text was presented on a screen above participants' head via a magnet-compatible projection mirror system (the text was shown in a black font against a gray background). To make the reading experience as natural as possible, reading time was self-paced, i.e., participants decided how long each text segment was presented by pressing a button whenever they wanted to proceed (however, to avoid fatigue, scanning was stopped after a maximum of 60 minutes, and four participants who had not finished reading within this time were excluded from the analysis). After each text segment, participants rated how much suspense they had experienced during the preceding segment on a 10-point scale (ranging from “not suspenseful” to “very suspenseful”) using two buttons of an MRI-compatible response box. The rating screen was presented with a temporal jitter of 1.0–4.2 seconds after participants had finished reading the text segment. At the initial presentation of each rating screen, a random rating value was selected that had to be adjusted according to the experienced suspense using the two buttons (the initial random rating value was chosen to de-correlate the level of experienced suspense from the button presses during the rating). Using a third button, participants confirmed the rating and proceeded to the next text segment (the same button was used to proceed from the text segment to the rating; see  ). Participants were explicitly instructed to rate the suspense they subjectively experienced (not the suspense they thought the segment was supposed to evoke). To become familiar with the experimental task, participants completed a short practice trial (with a different text) before the actual experiment. Due to the self-paced reading times, the scanning duration varied between 28:05 and 53:52 min across participants (  M   = 42:55 min;   SD   = 7:33 min). 
   One trial of the experiment: a segment of the text was presented, followed by a rating screen on which the suspense experienced while reading the text segment was selected on a 10-point scale using two buttons (for moving the selected point on the rating scale to the left or right).  
Timing was self-paced, i.e., participants pressed a button in order to proceed to the next text segment / rating screen. A total of 65 text segments was presented during the experiment. 
  
To assess whether participants had read the text attentively, five multiple-choice control questions were asked after the experiment (in order not to influence the natural reading process, participants were not informed about this before the experiment). We also assessed participants' general reading habits (e.g., how many books they usually read per year, and what type of literature genres). We moreover acquired heart rate and respiration rate of the participants; however, due to technical failure, the heart and respiration data of some participants were not usable, and we therefore could not include them as control regressors in our fMRI analysis. 


### Image acquisition 
  
MRI data were acquired at the Dahlem Institute for Neuroimaging of Emotion at the Freie Universität Berlin using a 3 Tesla Siemens Magnetom TrioTim MRI scanner (Siemens AG, Erlangen, Germany). Before functional scanning, a high-resolution (1x1x1 mm) T1-weighted anatomical reference image was obtained using a rapid acquisition gradient echo (MP-RAGE) sequence. For the acquisition of functional data, a continuous echo planar imaging (EPI) sequence was used (37 slices; slice thickness: 3 mm; interslice gap: 0.6 mm; echo time: 30 ms; repetition time: 2 s; flip angle: 70°; 64x64 voxel matrix; field of view: 192x192 mm) with slice acquisition interleaved within the TR interval. To reduce susceptibility-induced image distortions and signal losses in areas such as the orbitofrontal cortex and the temporal lobes, the acquisition window was tilted at an angle of 30° to the intercommissural (AC-PC) line [ ,  ]. 


### Image processing and statistical analysis 
  
Data were analyzed using Matlab (MathWorks, Natick, USA) and SPM8 (Wellcome Trust Centre for Neuroimaging, London, UK). Prior to the statistical analysis of the data, functional images were realigned using a 6-parameter rigid body transformation, co-registered to the anatomical reference image, normalized to standard Montreal Neurological Institute (MNI) stereotaxic space using a 12-parameter affine transformation, and spatially smoothed with a Gaussian kernel of 6 mm full-width at half-maximum. Low-frequency noise and signal drifts were removed using a high-pass filter with a cut-off frequency of 1/256 Hz. We deliberately opted for this comparatively low cut-off frequency to avoid filtering out parts of the signal of interest (because readers' experience of suspense changes relatively slowly). Serial correlations between scans were accounted for using an autoregressive AR(1) model. 

A standard general linear model (GLM) approach was used for statistical analysis. Potential confounding factors were added as control variables to the model. The control variables included were “action”, “imageability”, arousal, valence, and average sentence length of each text segment. To determine the amount of action described in the text segments we acquired additional ratings from a different group of participants (  N   = 20, 13 female, age range: 20–33 years,   M   = 23.5,   SD   = 3.8) asking how eventful each segment was experienced during reading (ratings were given on a 7-point scale). The Berlin Affective Word List (BAWL-R; [ ]) was used to estimate imageability, arousal, and valence based on values of single words which were then averaged over all words from one text segment. Average sentence length (in words) of each text segment was added to control effects of working memory, assuming that longer sentences generally impose higher demands on working memory. Thus, the model included the following regressors: reading periods were modeled as block regressor; control variables (action, imageability, arousal, valence, and average sentence length) and individual suspense ratings were modeled as a parametric modulator [ ,  ] of the reading periods (suspense ratings were orthogonalized to the control variables); rating periods were modeled as block regressor; estimates of the motion correction parameters obtained during the realignment were added as regressors of no interest. All regressors (except for the motion correction parameters) were convolved with the standard hemodynamic response function, and model parameters were estimated using the restricted maximum likelihood approach implemented in SPM8. After model estimation, whole-brain statistical parametric maps (SPMs) were calculated for the contrasts   reading > rating   (assuming that it would be associated with typical activations of the reading network, this contrast mainly served as a sanity check of the data) and the parametric regressor   suspense   (and its inverse—  suspense  ). To obtain group level results, the contrast images of individual participants were entered into a second-level random effects analysis. To account for differences in reading times as well as in the general experienced suspensefulness of the text, total reading times and average suspense ratings of each participant over the complete text were added as control regressors into the second-level model. Activations with a   p-  value smaller than. 05 corrected for family-wise errors (FWE) at the cluster level (with a cluster-forming threshold of   p   <. 005) were considered significant (FWE-corrected cluster extent threshold: 210 voxels). Because this cluster thresholding procedure may miss smaller activation clusters, in particular activations in the amygdala which we expected to be related to suspense (see  ), we also performed a region of interest analysis in the left and right amygdala. The region of interest was defined using the probability maps of the amygdala as implemented in the SPM anatomy toolbox [ ,  ]; a statistical threshold of   p   <. 05 (FWE-corrected) was used for the region of interest analysis. 



## Results 
  
### Behavioral data 
  
 shows average suspense ratings for the story. Pearson's product-moment correlation coefficients between individual suspense profiles, averaged over all possible pairs of participants, revealed a moderate inter-participant agreement (  r   =. 31,   p   <. 05; because Pearson's correlation coefficients are not additive, a Fisher z-transformation was applied before averaging over correlation coefficients and the resulting z-value was then converted back into a correlation coefficient). Average reading time for one text segment was 29.98 s (  SD   = 12.04 s). No correlation between reading speed and suspense ratings (averaged over participants) was observed (  r   =. 08,   p   =. 55). Moreover, suspense ratings did not correlate with the lengths of the text segments (  r   = –.04,   p   =. 74). Correlation coefficients between suspense ratings and the control measures (i.e., action, imageability, arousal, valence, and sentence length) are reported in  . 
   Average suspense ratings (  N   = 23) and standard errors for each segment of the text.    

### Functional MRI data 
  
Comparing reading periods with rating periods (  reading > rating  ,  ) revealed bilateral activations in visual cortices, the entire superior temporal sulcus (with left hemispheric dominance), and anterior hippocampus (cornu ammonis). Moreover, left-hemispheric activations were observed in the precentral gyrus and fusiform gyrus. 
   Statistical parametric maps (  p   <. 05, cluster-level FWE-corrected, shown in neurological convention) for (A) the contrast   reading > rating   and (B) the parametric   suspense   regressor capturing participants' experience of suspense during reading.    
The suspense regressor (reflecting participants' individual experience of suspense) showed a medial frontal activation cluster, as well as in each hemisphere a lateral frontal and a posterior temporal cluster of activation ( ). More specifically, the lateral frontal activation clusters extended anteriorly along the IFS into the inferior frontal gyrus (IFG), and posterior-superiorly into the precentral sulcus and precentral gyrus (lateral premotor cortex). The temporal clusters covered the posterior part of the superior temporal sulcus (STS), extending into the temporo-parietal junction (TPJ). These temporal and temporo-parietal activations were more pronounced in the left than in the right hemisphere. No negative correlations with suspense were observed, and none of the analyses showed activity changes in the amygdala, nor the orbitofrontal cortex. For a complete list of activations see  . Significant activations for the parametric control regressors (action, imageability, arousal, valence, and sentence length) are reported in   and  . 
   GLM analysis: anatomical locations, peak MNI coordinates, T-values, and cluster sizes (number of voxels) of significant clusters for the   reading > rating   contrast and the parametric   suspense   regressor.        
The region of interest analysis for the suspense regressor in the left and right amygdala did not yield any significant activations. 


### Psychophysiological interactions (PPI) 
  
To investigate whether there is a relationship between suspense ratings and the functional connectivity patterns of brain areas associated with suspense, we also performed a   post hoc   PPI analysis [ ]. For this, we used the upper and lower quartiles of individual suspense ratings to dichotomize suspense ratings into high and low values which were used to test the interaction of suspense with the functional connectivity of voxels around the maxima of the five activation clusters reported above (i.e., left posterior STS, right IFS, left IFG, MFC, and right TPJ; for exact locations, see peak MNI coordinates of  ). The contrast high vs. low suspense was multiplied with the eigenvariate of the voxels within a sphere with the radius 3 mm around the peak activation voxel of each cluster to obtain the interaction term. We expected psychophysiological interactions of the regions related to suspense with limbic/paralimbic regions implicated in emotion (such as the amygdala and the orbitofrontal cortex, see  ). For the left IFG region, the PPI analysis showed significant activations in cerebellar and occipital regions as well as the posterior inferior temporal gyrus and premotor cortex. Moreover, suspense significantly modulated the functional connectivity between the MFC and bilateral occipital areas as well as parietal areas including the postcentral gyrus (see   and  ). For the other seed regions (left posterior STS, right IFS, and left TPJ), the PPI analysis did not yield significant results. 
   PPI analysis: anatomical locations, peak MNI coordinates, T-values, and cluster sizes (number of voxels) of brain areas in which suspense (high vs. low) significantly modulated the functional connectivity to the seed region.        


## Discussion 
  
In the present study, we investigated the neural correlates of suspense evoked by a literary text. For this, we acquired functional imaging data while participants read a suspenseful story subdivided into short text passages. After each text passage, a rating of subjectively experienced suspense was obtained. Suspense ratings correlated with blood oxygen level-dependent (BOLD) signal intensity in the medial frontal cortex, bilateral frontal regions along the inferior frontal sulcus (extending into the inferior frontal gyrus and premotor cortex) as well as posterior temporal and temporo-parietal regions bilaterally. 

Comparing reading periods with rating periods yielded activations in the left (and to a lesser degree right) superior temporal sulcus. Activation of these areas has previously been associated with semantic processing of written and spoken language in general (see [ ], for an overview) and story processing in particular [ ,  ]. Reading also activated the left fusiform gyrus or what has been termed the “visual word form area” which has previously been ascribed a specialized role in the processing of written words [ ,  ]. As could be expected, reading of the story thus evoked typical brain activations of a left-lateralized language and reading network. Moreover, reading was associated with increased activation in visual cortices, possibly reflecting the higher visual input during reading periods compared with rating periods. 

Suspense—as subjectively experienced by individual participants—was related to bilateral clusters of activation in the medial and dorsolateral prefrontal cortex, in particular the inferior frontal sulcus, the inferior frontal gyrus, and the precentral gyrus (lateral premotor cortex), as well as posterior temporal areas extending into the TPJ. Activations of posterior temporal regions, in particular the TPJ, have previously been related to social cognitive tasks such as perspective taking [ ] or theory-of-mind processing [ ,  ]. A meta-analysis investigating neural correlates of social cognition associated the TPJ with the inference of other people's goals and actions [ ], and TPJ activations have been repeatedly observed for story processing (e.g., [ ]; for a meta-analysis, see [ ]). Likewise, the medial frontal cortex, which also showed activation related to suspense, has been discussed as a key area associated with social cognition and theory-of-mind [ ]. For example, a study comparing theory-of-mind processing in cartoon tasks and story tasks found overlapping activity for both tasks in the medial frontal cortex [ ], coinciding with the activation found in the present study. Similarly, a study by Steinbeis and Koelsch [ ] reports medial frontal cortex activation when participants believed they were listening to music written by a composer as opposed to computer-generated music, underlining the role of the MFC in theory-of-mind processing and mental state attribution. As hypothesized in the aforementioned neurocognitive poetics model of literary reading [ ,  ], and supported by Hsu et al. [ ], activation of temporo-parietal and medial frontal areas could thus be due to readers adopting the perspective and inferring the mental states of the main characters of the story during emotionally engaging and suspenseful text segments. Suspenseful parts of a narrative plot (in particular the suspenseful text segments of the current experiment) often involve situations in which a main character of the story is facing situations of potential danger or threat. Following Zillmann's definition “that the experience of suspense in dramatic presentations derives characteristically from the respondent's acute, fearful apprehension about deplorable events that threaten liked protagonists” ([ ], p. 140), activation of the TPJ and MFC may reflect these fearful anticipations of upcoming events that depend on the ability to infer the mental states, goals, and actions of characters of the story. This is in line with connectivity studies indicating that the MFC (in particular its dorsal parts) and its connectivity with the TPJ are associated with the understanding of others' mental states [ ] (however, note that we did not find such a connectivity in our PPI analysis). Furthermore, suspense has been proposed to build on a disparity between the knowledge of a character and the knowledge of the reader or viewer (most notably discussed by Alfred Hitchcock [ ]; see also [ ]). This disparity of knowledge is often based on theory-of-mind processing (e.g., knowing that the characters don't know what one oneself knows) and could therefore account for the activation of theory-of-mind-related brain areas during suspenseful texts (however, this is rather speculative because the disparity of knowledge between characters and readers appears to be less relevant for building suspense in the specific text used in the present experiment). 

The posterior temporal activations associated with suspense (particularly the ones in the left hemisphere) also suggest that neural activity in lower-level language areas is influenced by suspense, as these areas have been associated with the cognitive processing of written words and texts, e.g., word recognition [ ,  ,  ], acoustic-phonetic processing [ ], mapping of orthographic to phonological representations [ ], and the integration of semantic information [ ]. However, whether suspense directly modulates lower-level language areas or whether suspenseful text segments tend to covary with linguistic features that could influence neural activation in lower-level language areas remains to be investigated more closely (see  ). 

In addition to the TPJ and MFC activations, suspense was associated with bilateral activations in inferior frontal regions extending into lateral premotor cortex in the precentral gyrus. The activation of premotor areas during the experience of suspense suggests a connection between suspense and neural processes of prediction and anticipation. As described previously, premotor cortex activations (particularly in ventrolateral parts) have consistently been reported for tasks involving action and event prediction (for reviews, see [ ,  ]), which is corroborated by studies showing that predictive processing of sequential information is impaired in patients with premotor lesions [ ], and that ventrolateral premotor activations are associated with the processing of biological as well as abstract non-biological stimulus sequences [ ]. Our results point to a possible role of the premotor cortex in predictive processes concerning upcoming events in a suspenseful narrative plot, thus supporting the conjecture that the premotor cortex is involved in general aspects of event prediction (regardless of whether these predictions require motor control or planning; see [ ]). Moreover, predictive inferences in the context of story processing have been associated with inferior frontal and posterior temporal activation: In a study by Jin et al. [ ], short “mini-stories” provoking predictive inferences (compared with non-predictive counterparts) were related to left IFG activations, and Virtue et al. [ ] found story passages that required active inferences (based on previous information given in the story) to be associated with activation in the right posterior STG and bilateral IFG. The inferior frontal and posterior temporal activations observed for suspense could therefore reflect predictive processes associated with inferences about the unfolding of events of the story. The involvement of predictive processes during suspenseful text segments could also provide an alternative explanation to the TPJ and MFC activations discussed above: Decety and Lamm [ ] argue that TPJ activations are not specific to theory-of-mind processing but reflect more domain-general mechanisms “involved in generating, testing, and correcting internal predictions about external sensory events” ([ ], p. 583), and similarly, MFC activations have been implicated in predictive inferences during text comprehension [ ,  ,  ,  ]. 

The close link between suspense and prediction is particularly interesting in light of Bayesian accounts of brain functioning such as predictive coding and free energy [ ,  ]. From the perspective of these theories—which postulate that perception, action, learning, and emotion [ ] are essentially based on the minimization of prediction errors, surprise, and uncertainty—suspense can be viewed as the emotional component reflecting this urge for uncertainty reduction. Novels, movies, television series and various other forms of media entertainment appear to take advantage of this fundamental principle of human cognition, thus accounting for their general appeal and popularity. However, apart from reflecting an urge for uncertainty reduction, suspense may involve other (neuro-)cognitive mechanisms. From a biological perspective, uncertainty should be associated with negative emotion (because an organism that is able to make accurate predictions about its environment should have an evolutionary advantage over organisms that are unable to make such predictions), and suspense should therefore primarily be experienced as negative (and only the resolution of suspense should have a positive valence). Yet, suspense—in particular in forms of media entertainment such as film, music, or literature—is often experienced as positive, and the emotional “thrill” associated with suspense experiences may be enjoyed for its own sake (especially when the context in which suspense is elicited is devoid of potentially negative real-life consequences, as in literature, film, or music; cf. [ ,  ]). This indicates that, apart from uncertainty, other factors may also play a role in suspense and determine whether it is experienced as positive or negative (for a more detailed discussion of this point, see [ ]). 

The bilateral activation clusters of the inferior frontal sulcus included the so-called inferior frontal junction (IFJ, cf. [ ,  ]). Located at the intersection of premotor, language, and memory areas, activations in this area have previously been reported in experiments involving cognitive control, task switching, or updating processes [ – ]. For example, a meta-analysis by Derrfuss et al. [ ] reports activation of the IFJ in experimental paradigms requiring the updating of task representations (e.g., task-switching paradigms, Stroop tasks, or n-back tasks). With regard to language processing, left inferior frontal regions have been associated with semantic encoding [ ,  ], semantic working memory [ ], semantic retrieval [ ,  ], or selection of information from semantic memory [ ]. On a more speculative note, the frontal activation clusters observed for suspense may therefore reflect the recruitment of cognitive control structures during suspenseful text segments, i.e., during passages when the reader's interest about the unfolding of events of the story is highest. Being “captured” by the story during episodes of high suspense may lead to the engagement of top-down control mechanisms that rely on the IFJ and that may optimize semantic processing of the content of the story. This is in line with dynamic causal modeling (DCM) studies showing that IFG regions coordinate temporal and parietal regions associated with lower-level language processing [ ,  ,  ]. 

The brain activations related to participants' experience of suspense partially overlap with brain activations associated with the emotional intensity of a story reported in the study by Wallentin et al. [ ]. Both suspense and emotional intensity appear to be related to bilateral inferior frontal and (posterior) temporal activations. However, there were also differences in activation patterns between the two studies: for emotional intensity, Wallentin et al. [ ] report activations of the right amygdala as well as the thalamus which we did not find for suspense; conversely, the medial frontal activations related to suspense were not found in the study by Wallentin et al. [ ]. Apart from differences between the concepts investigated (i.e., suspense vs. emotional intensity), the different activations may be due to other differences between the two studies. Whereas the study by Wallentin et al. [ ] relied on auditory presentation of the story, the present study made use of a self-paced reading paradigm. Moreover, the present study used individual suspense ratings acquired while participants read the story in the fMRI scanner, which came at the cost of repeatedly interrupting the story to collect the ratings, which may have impeded participants' full immersion into the fictional world of the story (see also  ). Last, the participants of the study by Wallentin et al. [ ] were familiar with the plot of the study, whereas they did not know the plot in the present study. 

### Limitations and outlook 
  
We also had expected suspense to be related to neural activity in limbic brain structures associated with emotional processing such as the amygdala or the striatum. This hypothesis was not confirmed. One aspect of our experiment that may have compromised the evocation of strong emotional responses was that participants had to shortly interrupt reading after each text segment to give the suspense ratings, which may have disrupted the immersive reading experience usually associated with natural reading of suspenseful texts. We had deliberately opted for these online suspense ratings to capture the suspense experience of each individual participant as accurately as possible (alternative methods of acquiring suspense ratings after participants have read the complete text—and hence without interrupting the reading process—or of using average suspense ratings of a different group of participants might have reflected individual suspense experiences during reading less accurately, thus decreasing the sensitivity of the statistical analysis). However, it remains to be investigated whether uninterrupted reading of a suspenseful text engages limbic brain structures associated with emotional processing. Using “stronger” stimulus material—for example, suspenseful movie scenes—may further facilitate the measurement of neural substrates of emotional responses related to suspense. 

Moreover, it may be objected that lower-level stimulus features may have confounded the brain activations observed for suspense. We accounted for possible confounds by including action, imageability, arousal, valence, and average sentence length of each text segment as control variables in the model. However, when investigating a high-level concept like suspense in a relatively naturalistic setting using a real text, controlling all possible low-level stimulus properties is unfeasible, and the possibility that results are influenced by these stimulus features can never be entirely excluded. For example, the IFG activations observed for suspenseful text segments could also be interpreted as reflecting effects of syntactic processing (cf. [ ]). We did not include syntactic complexity as a control variable because there is no straightforward measure quantifying syntactic complexity in natural language texts. However, increased syntactic processing during suspenseful text segments seems unlikely because the relationship between syntactic complexity and suspense in the text of the present experiment is rather negative, i.e., suspenseful text segments tended to feature more simple sentences (often a concatenation of simple main clauses with few embedded sentences) than less suspenseful segments. Nevertheless, controlling as many confounding variables as possible in future neuroimaging studies on suspense is highly desirable. This includes physiological parameters such as heart or respiration rate. 

Finally, we used only one text as experimental stimulus. Whether the results reported here generalize to other texts and domains (e.g., film) remains to be clarified by future research. 



## Conclusion 
  
Suspense is an important component of the emotional experience evoked by narrative plots (e.g., in literature, film, etc.). To our knowledge, this is the first study exploring the neural correlates of suspense during the reading of a literary text. Recording functional imaging data while participants read a suspenseful piece of literature, we found that individual ratings of suspense were related to activity in the medial frontal cortex, posterior temporal and temporo-parietal regions, as well as the dorsolateral prefrontal cortex along the inferior frontal sulcus including the IFG and premotor cortex. Our results indicate that text passages that are experienced as suspenseful engage brain areas associated with mentalizing, predictive inference, and possibly cognitive control. 


## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
</div>

<footer>
    <p>Generated by Qualitative Review Tool for Meta-Analysis Pipeline</p>
</footer>
</body>
</html>
