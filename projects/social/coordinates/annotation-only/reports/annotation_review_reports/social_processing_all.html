<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>social_processing_all review report</title>
  <style>
    :root {
      --bg: #f7f6f2;
      --panel: #ffffff;
      --ink: #1d2730;
      --line: #d8dde3;
    }
    body { margin: 0; padding: 1.25rem; font-family: "IBM Plex Sans", "Segoe UI", sans-serif; background: var(--bg); color: var(--ink); }
    header { background: var(--panel); border: 1px solid var(--line); border-radius: 10px; padding: 1rem; margin-bottom: 1rem; }
    .top-nav { position: sticky; top: 0; z-index: 10; display: flex; flex-wrap: wrap; gap: 0.5rem; background: #eef3f2; border: 1px solid var(--line); border-radius: 10px; padding: 0.6rem; margin-bottom: 1rem; }
    .top-nav a { display: inline-block; padding: 0.35rem 0.6rem; border: 1px solid var(--line); border-radius: 999px; background: #fff; text-decoration: none; font-size: 0.9rem; color: #0e4f85; }
    section { margin-bottom: 1rem; }
    .bucket > summary, .doc-card > summary, .inner-accordion > summary { cursor: pointer; }
    .doc-card { background: var(--panel); border: 1px solid var(--line); border-radius: 10px; padding: 0.85rem; margin-bottom: 0.85rem; }
    .table-wrap, .table-html { overflow-x: auto; }
    .inner-accordion { margin-top: 0.6rem; border-top: 1px dashed var(--line); padding-top: 0.4rem; }
    .paper-text { white-space: pre-wrap; max-height: 26rem; overflow-y: auto; background: #fbfcfe; border: 1px solid var(--line); border-radius: 8px; padding: 0.6rem; font-size: 0.88rem; line-height: 1.35; }
    table { width: 100%; border-collapse: collapse; font-size: 0.9rem; }
    th, td { border: 1px solid var(--line); padding: 0.45rem; vertical-align: top; text-align: left; }
    th { background: #edf2f5; }
    .decision-cell, .confusion-cell { text-align: center; vertical-align: middle; }
    .decision-pill, .confusion-pill {
      display: inline-flex;
      align-items: center;
      justify-content: center;
      min-width: 1.55rem;
      padding: 0.12rem 0.45rem;
      border-radius: 999px;
      font-weight: 700;
      font-size: 0.82rem;
      border: 1px solid transparent;
    }
    .decision-include { background: #e9f8ef; color: #1f7a3d; border-color: #b7e4c6; }
    .decision-exclude { background: #fdecec; color: #9b1c1c; border-color: #f6caca; }
    .decision-none { background: #f2f4f7; color: #5b6775; border-color: #dde3ea; }
    .confusion-good { background: #e9f8ef; color: #166534; border-color: #b7e4c6; }
    .confusion-bad { background: #fdecec; color: #991b1b; border-color: #f6caca; }
    .confusion-na { background: #f2f4f7; color: #5b6775; border-color: #dde3ea; }
    a { color: #0e4f85; }
  </style>
</head>
<body>
  <header>
    <a id="top"></a>
    <h1>social_processing_all report</h1>
    <p>Manual benchmark is sliced to the auto PMID universe from <code>outputs/nimads_annotation.json</code>. Analysis-level row is evaluated only on manual analyses with an assigned auto match (truth positives are accepted fuzzy matches only).</p>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Level</th>
            <th>TP</th>
            <th>FP</th>
            <th>FN</th>
            <th>Precision</th>
            <th>Recall</th>
            <th>F1</th>
            <th>Manual Positives</th>
            <th>Predicted Positives</th>
            <th>Universe</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Document bucket overlap</td>
            <td>122</td>
            <td>11</td>
            <td>1</td>
            <td>0.917</td>
            <td>0.992</td>
            <td>0.953</td>
            <td>123</td>
            <td>133</td>
            <td>134</td>
          </tr>
          <tr>
            <td>Study inclusion</td>
            <td>133</td>
            <td>0</td>
            <td>1</td>
            <td>1.000</td>
            <td>0.993</td>
            <td>0.996</td>
            <td>134</td>
            <td>133</td>
            <td>134</td>
          </tr>
          <tr>
            <td>Analysis inclusion (matched manual universe; accepted=positive)</td>
            <td>407</td>
            <td>51</td>
            <td>15</td>
            <td>0.889</td>
            <td>0.964</td>
            <td>0.925</td>
            <td>422</td>
            <td>458</td>
            <td>475</td>
          </tr>
        </tbody>
      </table>
    </div>
  </header>
  <nav class="top-nav">
    <a href="#bucket-correct">Correct (122)</a>
    <a href="#bucket-false-positive">False Positive (11)</a>
    <a href="#bucket-false-negative">False Negative (1)</a>
    <a href="#missing-manual">Missing PMIDs (0)</a>
    <a href="#top">Top</a>
  </nav>
  <section id="bucket-correct"><details class="bucket"><summary><h2>Correct (122)</h2></summary><p><strong>Match status totals:</strong> accepted=420 | uncertain=11 | unmatched=42</p>
<details class="doc-card">
  <summary><strong>PMID 29079809</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29079809/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29079809_analysis_0</td><td>clusters genetic &gt; non-genetic</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Movie-viewing ISC contrasts directly probe social cognition: subjects watched a moral dilemma between sisters and ISC differences reflect synchronized social-cognitive processing (mentalizing, moral evaluation). This fits Social Processing (broad social perception and response).</td></tr>
<tr><td>29079809_analysis_1</td><td>clusters non-genetic &gt; genetic</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The non-genetic&gt;genetic ISC clusters (occipital visual areas) arise from the same movie social paradigm; the analysis is part of the social-processing experiment comparing kinship contexts and thus falls under broad Social Processing.</td></tr>
<tr><td>29079809_analysis_2</td><td>moral dilemma decision task</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The moral-dilemma decision GLM localizes brain regions engaged when subjects choose between saving sister, friend, or strangers — a classic social-cognitive task probing moral/social decision-making, satisfying broad Social Processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29079809_1</td><td>clusters genetic&gt;non-genetic; self</td><td>29079809_analysis_0</td><td>clusters genetic &gt; non-genetic</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29079809_2</td><td>clusters non-genetic&gt;genetic; self</td><td>29079809_analysis_1</td><td>clusters non-genetic &gt; genetic</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29079809_3</td><td>moral dilemma decision task; self</td><td>29079809_analysis_2</td><td>moral dilemma decision task</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  <details class="inner-accordion"><summary>PMC full text available (PMCID 5660240)</summary><p><strong>Title:</strong> Differential inter-subject correlation of brain activity when kinship is a variable in moral dilemma</p><details><summary>Abstract</summary><pre class="paper-text">Previous behavioural studies have shown that humans act more altruistically towards kin. Whether and how knowledge of genetic relatedness translates into differential neurocognitive evaluation of observed social interactions has remained an open question. Here, we investigated how the human brain is engaged when viewing a moral dilemma between genetic vs. non-genetic sisters. During functional magnetic resonance imaging, a movie was shown, depicting refusal of organ donation between two sisters, with subjects guided to believe the sisters were related either genetically or by adoption. Although 90% of the subjects self-reported that genetic relationship was not relevant, their brain activity told a different story. Comparing correlations of brain activity across all subject pairs between the two viewing conditions, we found significantly stronger inter-subject correlations in insula, cingulate, medial and lateral prefrontal, superior temporal, and superior parietal cortices, when the subjects believed that the sisters were genetically related. Cognitive functions previously associated with these areas include moral and emotional conflict regulation, decision making, and mentalizing, suggesting more similar engagement of such functions when observing refusal of altruism from a genetic sister. Our results show that mere knowledge of a genetic relationship between interacting persons robustly modulates social cognition of the perceiver.</pre></details><details><summary>Body</summary><pre class="paper-text">## Introduction 
  
Evaluating and predicting social interactions of others is an integral part of social cognition, one of the most fundamental of human cognitive functions. Indeed, the evolution of social cognition may best explain why humans have a more developed neocortex than other species . So far, social cognition has been predominantly studied with stimuli depicting interactions between strangers, however, most of the significant interactions evaluated in daily life are between one’s family members, friends, and acquaintances 

More importantly, most of our social interactions (and social effort) is directed to a very small number of familiar individuals, 60% of our social effort is directed to just 15 close friends and family . There is also considerable experimental and observational evidence for a “kinship premium” in our interactions with others, especially when those interactions involve altruistic behaviour . We are more likely to help our genetic relatives compared to unrelated individuals, and to do so implicitly, without conscious elaboration . In a trolley dilemma , subjects have to decide if they would push a handle to set a trolley to another track so that instead of killing five people when left without intervention, it will kill a single person on an alternative track. If only strangers are considered, the study subjects favoured the survival of the five over one life; however, their judgement changed if the single person was genetically related to the subject. 

On the other hand it has been shown, that subjects judged incest to be equally morally wrong for a sibling, irrespective of whether this was a genetic, adoptive or step sibling . In these studies, rather co-residence with the sibling in the family, irrespective of genetic status, was the most relevant factor in decisions about the moral reprehensibility of incest. 

These and many other studies, have shown differences in multiple aspects of moral perception/processing, evaluation, judgement and decision making at the behavioural level when processing information about kin vs. non-kin. However, much less is known about the neuronal underpinnings of these effects. Recently, Wlodarski and Dunbar  have shown that different brain regions are active when subjects judge moral dilemmas about kin vs. friends. They found the sensorimotor cortex, ventromedial prefrontal cortex and posterior cingulate cortex to be more strongly activated when the subjects processed social information about their friends than about their kin. These differences imply that the brain processes kinship information differently than information on unrelated individuals. 

We explored this further by comparing subjects’ brain responses to a moral dilemma involving a pair of genetic versus adoptive (  i  .  e  ., unrelated) sisters. During functional magnetic resonance imaging (fMRI) the subjects viewed the same movie involving two sisters, but one group was primed with the information that they were genetic sisters and the other group with the information that they were sisters by adoption. The case of sisters related genetically vs. by adoption is especially suitable for testing whether knowledge of genetic relationship influences perception of a moral dilemma between kin given that there is no potential for shared genetic interest in future generations for adopted siblings . Note, however, that the current study examined perception of a kin relationship that subjects were seeing in a movie, while in Wlodarski and Dunbars  analysis the subjects answered questions about their own kin members and friends. 

In the present study, we utilized inter-subject correlation (ISC) of brain hemodynamic activity as a model-free analysis approach that makes it possible to use movies as ecologically valid stimuli during fMRI. Due to improvements in fMRI acquisition methods and data analysis algorithms , it has become possible to study specific aspects of social cognition between subjects using ecologically valid fMRI paradigms. The ecological validity is particularly important when studying moral dilemmas in order to engage the subjects and make the dilemma as credible and perceptible as possible in order to get authentic reactions. To investigate the degree of similarity in how individual brains respond to the common movie stimulus, the brains of individual subjects are aligned and ISC between the hemodynamic activity time courses for each voxel are calculated across all subject pairs. ISC can be interpreted as reflecting synchronized neural activity and thus similarity of cerebral information processing across individuals . It has been shown that when viewing a feature film during brain scanning, both “higher-order” prefrontal cortical as well as basic sensory cortex regions become synchronized across subjects . Further, ISC may not only reflect mutual neuronal responses, but could provide the basis of inducing a specific common mind set, e.g. built by context information or perspective taking as well as predicting the actions of others . 

The model-free approach of ISC does not require any a priori, pre-designed modeling of the fMRI signal to carry out the analysis and thus provides a powerful tool to investigate neuronal mechanisms as the correlations are exclusively based on similarities between the subjects’ brain activities when they react to the various aspects of the complex movie . At the same time, ISC has been shown to reliably detect involved brain regions in complex experimental setups almost as sensitively as a model-based analysis . 

In study 1, we asked whether people discriminate behaviourally between relatives with genetic vs. non-genetic backgrounds: In an implicit association test (IAT ) the subjects’ reaction time when associating the words “sister” and “adopted sister” to positive or negative connoted adjectives was measured. Further, after watching the movie, the subjects were asked whether genetic vs. non-genetic relationship status mattered to them in the moral dilemma that they observed. 

In study 2, we tested how the subjects perceived moral dilemmas involving genetically related vs. unrelated individuals during fMRI. In a first task, the subjects watched the movie depicting the moral dilemma between two sisters after being primed that they were either genetically related sisters or sisters related only by adoption. Should knowledge of genetic relationship matter, we expect to see differences in the behavioural tests (IAT; questionnaires) as well as the neuronal mechanisms: we predict that brain regions known to be involved in processing of mentalizing , conflict resolution , emotion regulation , and moral dilemmas  would be activated differently under the two viewing conditions. 

Second, following the hypothesis that moral processing is the most relevant factor to distinguish between watching the movie when believing the sisters to be genetic or adopted (i.e., non-genetic), each subject underwent a moral decision task during fMRI scanning to evaluate specifically which brain areas are associated with the perception and processing of moral dilemmas during movie-watching. In this task the subjects had to decide whom to save from a dangerous area and had different choices including their own sister, best friend, and strangers, an experimental design similar to the classical moral trolley dilemma. Again, if the genetic relationship had an effect on the viewers, as has previously been shown behaviourally , we hypothesize that the subjects will show kinship preference by saving their sister over others and that similar brain areas are engaged both in the decision task and when watching the movie believing that the sisters are genetic. 


## Results 
  
### Study 1: Implicit association test (IAT) 
  
To examine if a possible general implicit bias against adopted sisters (that potentially modulates brain functions during movie viewing) underlies the subjects’ perception of the movie, we asked 30 subjects in a behavioural experiment to undergo an IAT . In this test, reaction times during assignment of positive and negative connoted words to the categories of sister and adopted sister showed that there is no such implicit bias: Out of 30 subjects, nine favoured a genetic sister, 13 a non-genetic sister, and eight had no preference (one sampled t-test t = −0.9564 p = 0.3468). The TOST procedure  indicated that the ratings of emotional closeness were significantly similar (observed effect size (d = −0.17) was significantly within the equivalent bounds of d = −0.68 and d = 0.68; t(29) = 2.77, p = 0.005). 


### Study 2: Inter-subject correlation (ISC) of fMRI during movie watching 
  
#### Inter-subject correlation (ISC) across all conditions 
  
During fMRI scanning the subjects watched a movie depicting a moral dilemma between two sisters, either believing the sisters are genetic sisters or that the younger sister was adopted at birth. In a first step, the overall ISC (22) of hemodynamic activity of an independent set of 30 subjects was calculated during first viewing of the movie (Fig.  ). Significant ISC was observed extensively in occipital lobes, posterior parietal areas, and temporal cortices. In the frontal cortex, areas in the lateral inferior frontal gyrus (IFG), lateral middle frontal gyrus (MFG), dorsolateral prefrontal cortex (DLPFC), dorsomedial prefrontal cortex (DMPFC) and ventromedial prefrontal cortex (VMPFC) showed ISC between all subjects. The location of all brain areas were defined using anatomical brain atlases as specifically the Harvard-Oxford Cortical Structural Atlas and the Juelich Histological Atlas.   
Inter-subject correlation (ISC) of all 30 subjects during the first viewing of the movie. On top row are shown lateral and on bottom row medial surfaces of left and right cerebral hemispheres. Red-yellow colours indicate areas of significant ISC during movie watching (FDR q &lt; 0.05). Abbreviations: ACC = anterior cingulate cortex, ANG = angular gyrus, CAL = calcarine gyrus, DLPFC = dorsolateral prefrontal cortex, DMPFC = dorsomedial prefrontal cortex, IFG = inferior frontal gyrus, IOG = inferior occipital gyrus, MFG = middle frontal gyrus, MOG = middle occipital gyrus, MTG = middle temporal gyrus, PCC = posterior cingulate cortex, SOG = superior occipital gyrus, SPL = superior parietal lobe, STS/STG = superior temporal sulcus and gyrus, VMPFC = ventromedial prefrontal cortex, a = anterior, d = dorsal, p = posterior, v = ventral. 
  


#### Differences in ISC between conditions 
  
In a second step, the ISC of all subjects (N = 30) were contrasted between the genetic vs. non-genetic relationship viewing conditions. As each participant watched the movie in the genetic and in the non-genetic condition on two different scanning days in a counterbalanced order, this is a within-subject design. There were robust differences between the two conditions in the ISC of hemodynamic activity of the subjects, despite 90% of the subjects self-reporting that it did not matter to them whether the sisters were related genetically or not. When the subjects watched the movie believing that they were seeing genetically related sisters, the ISC was significantly stronger in the superior temporal sulcus and gyrus (STS/STG), VMPFC, DLPFC, anterior cingulate cortex (ACC) and posterior cingulate cortex (PCC), IFG, insula, cuneus, precuneus, and superior parietal lobule (SPL) (Fig.  , Table  ).   
Differential ISC between the conditions of an assumed genetic and non-genetic sisters and BOLD time series from two exemplary single voxels. (  A  ) Significant differences in brain activity when all subjects watched the movie thinking that the sisters were genetically vs. non-genetically related (FDR q &lt; 0.05, t = 2.1447, for consistent illustration purposes, the figures shows t-values from 3 to 9 and −3 to −9) (N = 30, within subject design). Red-yellow colours indicate areas of significantly higher ISC when the subjects watched the movie as depicting genetically related, as compared to non-genetically related, sisters. Blue colour indicates areas showing significantly higher ISC in the reverse contrast. Abbreviations: ACC = anterior cingulate cortex, CAL = calcarine gyrus, DLPFC = dorsolateral prefrontal cortex, IFG = inferior frontal gyrus, IOG = inferior occipital gyrus, MOG = middle occipital gyrus, PCC = posterior cingulate cortex, SPL = superior parietal lobe, STS/STG = superior temporal sulcus and gyrus, VMPFC = ventromedial prefrontal cortex, a = anterior, d = dorsal, p = posterior, v = ventral. (  B  ) Across subjects averaged BOLD time series of two voxels, one in the area VMPFC that showed significantly higher ISC when the subjects were viewing the sisters as genetic and one time series of a voxel in area V1 (primary visual cortex) that did not show significant between-condition ISC differences. The red line plots the group mean BOLD in the genetic sisters condition and the blue line plots the group mean BOLD in non-genetic sisters condition over the whole length of the movie. Red and blue shades indicate the 25  and 75  percentile of the variance. 
    
Clusters size, peak coordinates and t value of all clusters of Experiment 1 (movie watching task). 
  

When the subjects thought that the sisters were non-genetic, higher ISC was observed mainly in the occipital cortex. Importantly, the movie stimulus was identical in both viewing conditions. 

To illustrate blood oxygenation level dependent (BOLD) time series of specific voxels, in Fig.  , the panel B shows the time series of two exemplary voxels, over the whole length of the movie, from: i) VMPFC that showed higher ISC when the subjects viewed the sisters as genetic and ii) from a voxel in the area V1 (primary visual cortex), which is an early sensory brain area that did not show any between condition differences in ISC. 

Self-ratings of emotional valence and arousal obtained after the scans were not significantly different between the conditions (Valence: r = 0.0075, p = 0.3458, Arousal: r = −0.0189, p = 0.6081) (Fig.  ). Further, the mean ISC of eye-movements (eISC) over time windows showed no significant difference between the groups of participants believing in genetic or non-genetic sisters (p = 0.3918) (see Fig.  ). Likewise, no significant difference could be found in the heart and breathing rate comparing the conditions of assumed genetic versus non-genetic sisters (with bootstrap over 5000 permutations, breathing rate: t-value = 0.430, p = 0.335: heart rate: t-value = −1.12, p = 0.129) (see Fig.  ).   
Experienced emotional valence and arousal as well as physiological parameters when perceiving the sisters in the movie as genetic vs. non-genetic. (  A  ) Shown are dynamic self-ratings of emotional valence and arousal over the whole time course of the movie obtained during re-viewing of the movie after the fMRI sessions when the sisters were viewed as genetically related (red) or non-genetic (blue). The ratings were highly similar and there were no time periods where significant between-condition differences could have been observed. Note that half of the subjects (N = 2 × 15) rated experienced arousal and the rest rated experienced valence after the first fMRI session followed by rating the other emotional dimension after the second fMRI session. Plotted are means for all subjects in the red line for assumed genetic sisters and the blue line for non-genetic sisters condition. Red and blue dashed lines show the 25  and 75  percentile of the variance. (  B  ) Eye gaze behavior (N = 29) in the movies when the sisters were perceived as either genetic (right) or non-genetic (left) shown as a violin plot with the red cross depicting the means and green squares the medians. There were no significant differences between the conditions. (  C  ) Breathing and heart rates (N = 30) when the sisters were perceived as either genetic (red) or non-genetic (blue). There were no significant differences between the conditions. Red line plots the condition with assumed genetic sisters and the blue line non-genetic sisters. Red and blue shade show the 25  and 75  percentile of the variance. 
  



### Comparison with the moral dilemma decision experiment 
  
To further examine which neurocognitive processes might be involved, we studied whether the brain areas showing higher ISC in the genetic condition overlap with those engaged during a modified moral dilemma task  analysed with general linear modelling (GLM) (Fig.  , Tables   and  ). Naturally, it should be kept in mind that while ISC and GLM analyses of brain hemodynamic activity can yield converging results , this is not necessarily the case, as high ISC can be observed also when the BOLD signals are small.   
Having to decide in a simulation between saving one’s sister, friend, and others from crisis regions elicited significant brain activity in the VMPFC, ACC, precuneus, DLPFC, IFG, insula, TPJ and MTG. These activations of subjects (N = 30) were obtained by contrasting the decision phases (from the point of revealing the individuals involved until the decision signaled by the subject’s button press) against non-decision phases (subjects watching the background story depicting the two crisis regions and how the subjects only have resources to save individuals from one of the crisis regions) (FDR q &lt; 0.05, t = 2.0384, for consistent illustration purposes, the figures shows t-values from 3 to 9) Left-lateralized motor and supplementary motor are probably explained by the button press that the subjects performed to announce their decision. Abbreviations: ACC = anterior cingulate cortex, DLPFC = dorsolateral prefrontal cortex, IFG = inferior frontal gyrus, IOG = inferior occipital gyrus, ITG = inferior temporal gyrus, MC = motor cortex, MFC = medial frontal cortex, MOG = middle occipital gyrus, MTG = middle temporal gyrus, PCC = posterior cingulate cortex. SMA = supplementary motor area, SPL = superior parietal lobe, TPJ = temporo-parietal junction,VMPFC = ventromedial prefrontal cortex, a = anterior, d = dorsal, p = posterior, v = ventral. 
    
Clusters size, peak coordinates and t value of all clusters of and Experiment 2 (moral dilemma decision task). 
  

When the same subjects who watched the movie had to decide between saving their sister, best friend, vs. stranger(s), in various combinations, from a crisis region, 93% of the subjects showed a clear kin preference by choosing their sister (even when associated with some strangers) rather than their best female friend (chi-squared test ×  = 43.4 p &lt; 4 × 10 ). Further, as can be seen in Fig.   the VMPFC, ACC, IFG, MTG, SPL, PCC, precuneus, DLPFC, and anterior insula were consistently involved in both making choices of whom to prefer in a morally dilemmatic situation and when observing the moral dilemma between a genetic vs. non-genetic sister. Importantly, ratings of emotional closeness were not significantly different for the subjects’ sisters and their best friends with an average of 9.28 (sisters) and 8.80 (friends) on a 1–10 scale (Wilcoxon signed rank test = 0.12, t-test, t = 1.64 p = 0.11). The TOST procedure  indicated that the ratings of emotional closeness were significantly similar (observed effect size (d = 0.33) was significantly within the equivalent bounds of d = −0.68 and d = 0.68, or in raw scores: −1.07 and 1.07, t(29) = −1.92, p = 0.032).   
Activity during moral dilemma decision making as disclosed by GLM analysis (red) and the ISC when the subjects believed in a genetic relationship between the sisters in the movie (blue), along with the overlap of these two maps (violet), as well as the more strict overlap with a conjunction test (yellow);  , (FDR q &lt; 0.05, t = 2.0384 for GLM and t = 2.1447 for ISC). Abbreviations: ACC = anterior cingulate cortex, DLPFC = dorsolateral prefrontal cortex, IFG = inferior frontal gyrus, MFC = medial frontal cortex, MOG = middle occipital gyrus, MTG = midddle temporal gyrus, PCC = posterior cingulate cortex. SPL = superior parietal lobe, VMPFC = ventromedial prefrontal cortex, a = anterior, d = dorsal, p = posterior, v = ventral. 
  

As measured with an independent group of subjects outside the scanner, reaction times for the moral-dilemma decision were significantly longer in the case of a decision between a group comprised of their friend and four strangers on one side and their sister alone on the other side as in the case that only comprised strangers (on both sides) (paired Wilcoxon rank sum test p = 0.0011973). 



## Discussion 
  
In the present study, we investigated whether refusing altruism from a sister is perceived differently when the viewers think that the sisters are genetically related vs. when they think that one of the sisters has been adopted at young age. The results of the IAT in study 1 suggest that the subjects do not show an implicit bias against adoptive sisters compared to genetic sisters in general. Also, when explicitly asked if the relationship (as genetic or adopted) would matter in the decision of an organ donation, most subjects (90%) report that this knowledge would not affect the decision. Further, heart rate and breathing rate exhibited no significant differences between the two conditions, and self-reported emotional valence and arousal was likewise similar between the conditions (Fig.  ), suggesting that there were no robust differences in experienced emotions between the conditions. 

In contrast, the ISC of the hemodynamic brain activity show a different picture: robust differences were observed in patterns of brain activity due to the mere knowledge of the genetic relationship between the sisters in the movie. Specifically, there were multiple brain regions showing significantly higher ISC when the subjects thought that they are seeing a young girl refusing to donate her organ to save her genetic, as opposed to non-genetic, sister (Fig.  ). These areas included VMPFC, DLPFC, ACC, PCC, insula, precuneus, and SPL. While we would caution against drawing conclusions of specific cognitive functions involved on the basis of observed differences in brain activity, these brain regions have been previously shown to be associated with moral and emotional conflict regulation , decision making , mentalizing , and perspective taking , thus tentatively suggesting more uniform engagement of such neurocognitive functions when observing the dilemma of organ donation between genetic sisters. 

In the reverse contrast (i.e. when the subjects thought the sisters were non-genetic), higher ISC was observed in brain areas in the occipital cortex, conventionally associated mainly with visual perception . One possible explanation could potentially be that in the case of a non-genetic relationship between the sisters, the processing of complex social conflict associated with the moral dilemma is less demanding, and therefore leaves room for the subjects to focus on the visual aspects of the movie. However, eye-movements were not significantly different between the two viewing conditions, suggesting that differences in attention to movie events did not explain the observed robust differences in ISC. 

To specifically test for the possibility that the differences in ISC between the conditions reflected differences in moral evaluation, we compared the areas showing differences in ISC with areas activated when the subjects engaged in a separate moral-decision making control task. In this control task, the subjects had to make choices about saving people (including their sister, best friend, and strangers, in various combinations) from disaster. As each subject made only one decision that contrasted saving the friend over strangers and one decision of saving the friend over the own sister plus four strangers (as well as four decisions that contrasts the sister to groups of others), the statistical power in this experimental design was unfortunately not sufficient to differentiate directly between brain responses during decisions to save the sister vs. the friend. Rather, the results should be viewed as localization of brain regions involved in making moral decisions, yet also modulated by differences in, e.g., executive control, readiness for action, and attention, between the passive perception of the story and active decision making. However, significantly longer reaction times suggested increased difficulty when having to choose between a sister and the friend together with four strangers while areas in the VMPFC, DLPFC, ACC, PCC, precuneus, IFG, MTG, SPL and anterior insula were consistently involved in both making choices of whom to prefer in a morally dilemmatic situation and when observing the moral dilemma between a genetic vs. non-genetic sister (Fig.  ). This overlap in engaged brain regions suggests that processing of moral dilemmas took place during movie watching when the sisters were understood to be genetically related. It is significant that the brain regions flagged up in this analysis are those known to be involved in processing moral dilemmas and mentalizing. The DLPFC has been reported to play a role in overcoming a primary moral judgment in favour of greater welfare  and in cortical emotional processing , while the MTG has been implicated in attributing mental states as well as ingroup/outgroup distinctions , the ACC has been reported to be engaged in resolving conflicts , and the SPL, precuneus, and PCC have been implicated in mentalizing and perspective taking . Further, the VMPFC has been associated with viewing moral conflicts, making moral decisions, attributing mental states to self and others, adopting another person’s perspective, and evaluating their beliefs . 

Thus, the differences in ISC between the conditions appear to have arisen due to the knowledge about the sisters’ relationship influencing cognitive evaluation of the moral dilemma depicted in the movie. The contrast to the behavioural results assessed in study 1, where we find that behavioural decisions were not influenced by knowledge of the relationship, is particularly interesting since it suggests that differential processing is taking place under the surface. 

There could be at least two possible explanations for these findings. First, the study subjects might have purposely been hiding their “real” honest opinions as they might have not been willing to reveal these to the researchers, presumably because of social pressure against discriminating between genetic and adoptive siblings. However, the IAT is an implicit test for biases (it uses differences in reaction times for associations of a specific term with positively and negatively connoted words), so subjects are not aware of their performance on this task. Further, they do not know the exact measures which are used to calculate the IAT score, thus making it difficult to engineer potential biases; hence, it is very difficult, even impossible, to manipulate an IAT response in a desired direction . Thus, while a conscious manipulation of reported opinions would be possible in the open-format questionnaire (when asked if the relationship of the sisters matters in the situation of organ donation), it is very unlikely in the IAT. However, Liberman   et al  .  showed that, when judging incest reprehensibility, the coresidence of siblings is a stronger factor than the assumed relationship status and in when the two parameters are in conflict, the time spent in coresidence outweighs the belief of kin relation. As in this study the subjects were told that the apparent adoption took place as the younger sister was a newborn (implying coresidence of the sisters in both the genetic and the adoption case), we suggest, in accordance with Liberman   et al  ., that the factor of coresidence was given greater account than the kin relationship and thus the subjects’ explicit answers in the questionnaire could probably be seen/taken as truthful i.e. reporting authentic, honest thoughts. 

A second possible explanation for our findings is that, as the results of the implicit testing show, the study subjects indeed did not show any biases behaviourally and still pursued different ways of considering the case of a relationship by genes or by adoption, with resulting differences in brain activity patterns. These results show that an event that is behaviourally counter-intuitive (e.g. refusing to help a sister to prolong her life) needs different and potentially more intensive mental processing when the sisters are related genetically compared to adoptive sisters. As the differences in the brain activity patterns between the genetic and the adopted condition particularly comprise areas known to be involved in processing moral dilemmas and mentalizing as the VMPFC, DLPFC, ACC, PCC, precuneus, IFG, MTG, SPL, and anterior insula, we suggest that the study subjects’ expectations of morality are more strongly violated when close genetic relatives refuse to help each other than when unrelated individuals behave this way, despite their close social relation (adoption). 

Notwithstanding these points, we wish to caution the reader to keep in mind the caveats associated with reverse inference  (although see ). Specifically, even as we are suggesting that an activation observed in a certain region is indicative of a specific cognitive process based on results of previous research documented in the literature, it is possible that the activation of that region in the present study was due to some other cognitive process. This is because in general any given brain region is involved in multiple cognitive functions, thus making it difficult to infer with certainty the cognitive functions involved in a task based on brain regions that are activated. 

An alternative possibility is that the different measures operate at different levels of cognition: The null result in the IAT could be relying on a more basic level of attention to the social knowledge, whereas the questionnaire requires high level explicit cognition and the ISC during movie perception reflects some intermediate level of cognition. Had we thought to include them, other behavioural tests might have revealed more detail and background information on the subjects. Finally, it is always possible that something other than moral considerations could underlie the differences in brain patterns that we found, although, given the brain areas that show differences, this is unlikely. 

In summary, we observed robust differences in brain activity when subjects viewed a movie depicting refusal to donate an organ to a genetic vs. non-genetic sister. These differences in brain activity were observed despite the subjects self-reporting that the relational status of the sisters did not make any difference to them. Areas of increased synchrony in the case of genetic sisters overlapped with those activated in a separate moral dilemma decision task. Taken together, our results suggest that the precuneus, MTG, insula, SPL, and the VMPFC, along with the associated cognitive processes (i.e., moral and emotional conflict regulation), decision making, mentalizing and perspective taking are synchronized across subjects more robustly when they are viewing refusal of altruism from genetic as opposed to non-genetic, kin. Overall, these findings are fundamentally important for understanding social cognition, a pivotal ability that makes us human and, among other things, enables the existence of societies. Our findings point out that the perceived relationship of interacting persons robustly modulates how the brains of spectators process third-party interactions. This is highly significant given that majority of research to date on social cognition has been on strangers, whereas most of our social interactions take place between family members, friends, and acquaintances. 


## Material and Methods 
  
### Subjects 
  
We studied 33 healthy female subjects  (19–39 years, mean age of 26 years, one left-handed, laterality index of right handed 84.5%). None of the subjects reported any history of neurological or psychiatric disorders. When asked, all subjects reported either normal vision or corrected to normal vision by contact lenses. Three subjects were excluded due to discomfort in the scanner, so that the final analysis included 30 subjects. 27 of them were native Finnish speakers and three were native Russian speakers. All subjects were sufficiently proficient in English to follow the dialogue in the movie without subtitles. The experimental protocols were approved by the research ethics committee of the Aalto University and the study was carried out with their permission (Lausunto 9 2013 Sosiaalisen kognition aivomekanismit, 8.10.2013) and in accordance with the guidelines of the declaration of Helsinki . Written informed consent was obtained from each subject prior to participation. 


### Stimuli and Procedure 
  
The study consisted of two experiments. In the first experiment, the feature film   My Sister’s Keeper”   (dir. Nick Cassavetes, 2009, Curmudgeon Films), edited to 23 minutes and 44 s, (of which 14 min 17 s (60%) portray the theme of refusal of the organ donation),with the main story line retained, was shown to the subjects during fMRI. This shortened version of the movie focuses on the moral dilemma of the protagonist Anna to donate one of her kidneys to her sister Kate, who is fatally ill from cancer. In the course of the movie, Anna refuses to donate and Kate dies. The reason for Anna refusing to donate the kidney was not revealed to the subjects until after the experiment. The movie was shown to the subjects in the scanner four times in two separate scanning sessions on two different days. For each viewing of the movie the instructions were varied regarding the information about the sister’s relationship and the perspective to take in this viewing (Fig.  ). Each subject thus watched the movie assuming that the sisters were genetic sisters or that the younger sister Anna had been adopted as a newborn. In addition each subject was asked to take either the perspective of the potential donor (Anna) or the perspective of the potential recipient (Kate) on separate viewings (and both under the condition of a genetic or non-genetic relation background). The order of the different viewing conditions was counterbalanced between the subjects.   
Experimental procedure and ISC analysis in the movie watching task. (  A  ) Every subject watched the movie four times, in a 2 × 2 design assuming that the movie characters are either genetic sisters or not genetically related and taking the perspective of the to-be-donor sister Anna or the to-be-recipient sister Kate. The order of all the conditions were counter-balanced. (  B  ) Time series from each voxel from all the fMRI recordings are compared across subjects in pairwise correlations to obtain the mean inter-subject-correlation (ISC). 
  

In the second experiment, each subject carried out a moral-dilemma decision task during fMRI in order to localize brain regions that are related to moral decision making. For this purpose, a modified version of the classical trolley dilemma , was shown to the subjects. Each subject had to choose between rescuing different individuals, including unknown individuals, their sister and a best female friend. A presentation showing text and pictures told a story about civil unrest in a fictive distant country. This country had two parts: one part very dangerous and the other much less dangerous. Different people are in both parts of the country. Subjects were also told that as they were very rich and owned an airplane, they could go there and rescue some of the people. However, due to the circumstances in the country they had to decide which group of people to rescue. The two choices were always a group of five individuals on one side and a single person on the other. In seven runs the identity of the involved individual(s) was varied using the real names of the subject’s sister and best female friend. The 7 runs were: 1. All persons are unknown; 2. Sister is with four others in the dangerous part of the country, the single person is unknown; 3. Five persons are in the dangerous part of the country, the single person is the sister; 4. Five persons are in the dangerous part of the country, the single person is the friend; 5. Sister is with four others in the dangerous part of the country, the single person is the friend; 6. Friend is with four others in the dangerous part of the country, the single person is the sister; 7. Sister is with four others in the less dangerous part of the country, the single person is unknown. Responses in the moral dilemma decision task were recorded with a button press on a LUMItouch keypad (Photon Control Inc.8363, Canada). For the all questions, it was calculated with which percentage the sister was chosen over the friend and the stranger(s); statistical significance was tested with a Chi  test. 


### fMRI acquisition 
  
Before each scan the subjects were informed about the scanning procedures and asked to avoid bodily movements during the scans. All stimuli were presented to the subject with the Presentation software (Neurobehavioral Systems Inc., Albany, CA, USA), synchronizing the onset of the stimuli with the beginning of the functional scans. The movie was back-projected on a semitransparent screen using a data projector (PT-DZ8700/DZ110X Series, Panasonic, Osaka, Japan). The subjects viewed the screen at 33–35 cm viewing distance   via   a mirror located above their eyes. The audio track of the movie was played to the subjects with a Sensimetrics S14 audio system (Sensimetrics Corporation Malden, USA). The intensity of the auditory stimulation was individually adjusted to be loud enough to be heard over the scanner noise. The brain-imaging data were acquired with a 3T Siemens MAGNETOM Skyra (Siemens Healthcare, Erlangen, Germany), at the Advanced Magnetic Imaging center, Aalto University, using a standard 20-channel receiving head-neck coil. Anatomical images were acquired using a T1-weighted MPRAGE pulse sequence (TR 2530 ms, TE 3.3 ms, TI 1100 ms, flip angle 7°, 256 × 256 matrix, 176 sagittal slices, 1-mm3 resolution). Whole-brain functional data were acquired with T2*-weighted EPI sequence sensitive to the BOLD contrast (TR 2000 ms, TE 30 ms, flip angle 90, 64 × 64 matrix, 35 axial slices, slice thickness 4 mm, 3 × 3 mm in plane resolution). 

A total of 712 whole-brain EPI volumes were thus acquired for each movie viewing. The number of whole-brain EPI volumes for the moral dilemma decision task varied individually depending on the decision made by each subject (median 267 whole-brain EPI volumes). Heart pulse and respiration were monitored with the Biopac system (Biopac Systems Inc., Isla Vista, California, USA) during fMRI. Instantaneous values of heart rate and breathing rate were estimated with Drifter software package  (  http://becs.aalto.fi/en/research/bayes/drifter/  ). 


### fMRI preprocessing 
  
Standard fMRI preprocessing steps were applied using the FSL software (  www.fmrib.ox.ac.uk  ) and custom MATLAB code (available at   https://version.aalto.fi/gitlab/BML/bramila/  ). Briefly, EPI images were corrected for head motion using MCFLIRT. 

Then they were coregistered to the Montreal Neurological Institute 152 2 mm template in a two-step registration procedure using FLIRT: from EPI to subject’s anatomical image after brain extraction (9 degrees of freedom) and from anatomical to standard template (12 degrees of freedom). Further, spatial smoothing was applied with a Gaussian kernel of 6 mm full width at half maximum. High pass temporal filter at a cut-off frequency of 0.01 Hz was used to remove scanner drift. To further control for motion and physiological artefacts, BOLD time series were cleaned using 24 motion-related regressors, signal from deep white matter, ventricles and cerebral spinal fluid locations (see ) for details, cerebral spinal fluid mask from SPM8 file csf.nii, white matter and ventricles masks from Harvard Oxford atlas included with FSL). As a measure of quality control we computed framewise displacement to quantify instantaneous head motion. Out of all the 120 runs (30 subjects, 4 sessions each), 97.5% of the runs (117 runs) had 90% of time points (640 volumes) with framewise displacement under the 0.5 mm threshold suggested in . For the remaining three runs, the number of time points under 0.5 mm were 639 (89.7%), 633 (88.9%), 489 (68.7%), i.e. only one session had a considerable amount of head motion. While head motion is a concern in connectivity studies as it can increase spurious BOLD time series correlations that are affected by the same amount of instantaneous head motion, with across-brain time series correlation, head motion is expected to reduce the SNR. However, to make sure that head motion similarity did not explain any group difference, we computed the same permutation test for the ISC also for average framewise displacement by estimating the similarity of two subjects as the distance between their average framewise displacement value. We found that similarity in average head motion was not different between the two viewing conditions (t-value = 0.255; p = 0.398 obtained with 5000 permutations). 


### Inter-subject correlation (ISC) analysis of brain activity during movie watching 
  
To investigate how similar the brain activity was across subjects in the different experimental conditions, we performed inter-subject correlation (ISC) using the isc-toolbox (  https://www.nitrc.org/projects/isc-toolbox/  ) . For each voxel the toolbox computes a similarity matrix between subject pairs and within same subject in all conditions, with the conditions being: (i) shared assumption that the movie’s sisters are genetically related, (ii) shared assumption that the younger sister was adopted, (iii) shared perspective of the to-be-organ-donor, and (iv) shared perspective of the to-be-organ-recipient. The total size of the similarity matrix is then 120 × 120 (4 conditions × 30 subjects) with each subject having two viewings for the genetic and two viewings for the non-genetic condition. The comparison between the conditions of the sisters to be perceived as either genetic sisters or non-genetic sisters results thus in a total of 1740 pairs per condition, as the similarity of BOLD time series during the two viewings (in either the genetic or the non-genetic condition) of each subject is compared with the two respective viewings of the other N-1 subjects. As the order of subjects does not matter, the final number of pairs in same conditions will be 2*2*(N-1)*N/2 = 1740 with N = 30. Each value of the correlation matrix is a result of the correlation between the BOLD time series of the pair of subjects considered for the selected voxel. We computed differences between experimental conditions by first transforming the correlation values into z-scores with the Fisher Z transform and then computing t-values and corresponding p-values using a permutation based approach . 

The Fisher-Z transformed correlations of the two perspectives were pooled for either the genetic or the non-genetic sisterhood. 

Correction for the multiple comparison was performed with Benjamini-Hochberg false discovery rate (BH-FDR) correction at a q &lt; 0.05, corresponding to a t-value threshold of 2.133. For visualization purposes, all results were also cluster corrected by removing any significant cluster smaller than 4 × 4 × 4 voxels. Summary tables were generated with an increased t-value threshold of 3. For the conjunction or “intersection–union test”  the p values of the ISC and GLM results are pulled together by considering the maximum p-value at each voxel. Then, multiple comparisons correction is performed with the Benjamini-Hochberg false discovery rate procedure with an FDR threshold equal to q &lt; 0.05. 

Unthresholded statistical parametric maps can be found in neurovault:   http://neurovault.org/collections/WGSQZWPH/  . 

#### Perspective taking 
  
In the movie-viewing experiment, in addition to having the subjects to watch the movie in the conditions of sisters related by birth or by adoption, we had altogether four runs, so that on two of the runs the subjects were asked to view the movie from the perspective of the sister who was expected to donate the organ, and on two of the runs from the perspective of the to-be-recipient sister. Thus, there was one run wherein the subjects viewed the movie from the perspective of the to-be- donor thinking that the sisters were genetic, one run wherein the subjects viewed the movie from the perspective of the to-be- donor thinking that the sisters were non-genetic, one run wherein the subjects viewed the movie from the perspective of the to-be- recipient thinking that the sisters were genetic, and one run wherein the subjects viewed the movie from the perspective of the to-be- recipient thinking that the sisters were non-genetic. 

As the results of this task open up a completely other aspect of the experiment with various results to discuss, which go beyond the scope and the space limitation of this article, they will be reported separately elsewhere. These conditions are mentioned here for reasons of describing the experimental procedures thoroughly so that it would be possible for others to replicate the study should they wish to do so. 



### General linear model analysis of the fMRI data acquired during the control task 
  
A moral dilemma decision task was performed by all subjects to localize regions involved in moral processing. The moral dilemma decision task was analyzed with a general linear model approach using the SPM12 software (  www.fil.ion.ucl.ac.uk/spm  ). To distinguish between moments of decision in the moral dilemma and the simple perception of the presentation, we created a temporal model of the occurrence of decision moments during the experiment. The decision regressor included time points from the revelation of the identity of involved individuals to the moment of decision indicated by button press. The activity during these time points was compared to the activity in all other time points of the task, including telling the background story of the moral dilemma in the presentation. Regressors were convolved with canonical hemodynamic response function to account for hemodynamic lag. From the preprocessed input data (see above) low-frequency signal drifts were removed by high-pass filtering (cutoff 128 s). First, individual contrast images were generated for the main effects of the regressors, then first level analyses were subjected to second-level analyses in MATLAB using one-sample   t  -test to test which brain areas showed significant activations in decision vs. no decision moments in a one-sample   t  -test over subjects. Statistical threshold was set at   p   &lt; 0.05 (cluster-corrected using the threshold free cluster enhancement approach implemented by FSL randomize with 5000 permutations). 


### Recording of eye-movements 
  
Eye movements were recorded during fMRI scanning from all subjects with an EyeLink 1000 eye tracker (SR Research, Mississauga, Ontario, Canada; sampling rate 1000 Hz, spatial accuracy better than 0.5°, with a 0.01° resolution in the pupil-tracking mode). Due to technical problems, 4 subjects had to be excluded from the final data analysis (with the rejection criteria of blinks maximum 10% of the duration of the scan and majority of blinks and saccades less than 1 second in duration). In addition, a part of recordings from some additional subjects had to de discarded due to the same criteria mentioned above, resulting in 61 recorded files with sufficient quality, with 35 files remaining in the genetic condition and 26 remaining files for the non-genetic condition. Prior to the experiment the eye tracker was calibrated once with a nine-point calibration. 

Saccade detection was performed using a velocity threshold of 30°/s and an acceleration threshold of 4000°/s2. Because the experiment was relatively long and no intermediate drift correction was performed, we retrospectively corrected the mean effect of the drift. We first calculated the mean of all fixation locations over the entire experiment for each subject, and then rigidly shifted the fixation distributions so that the mean fixation location coincided with the grand mean fixation location over all subjects. 


### Eye-movement analysis 
  
Subject-wise gaze fixation distributions were compared across the genetic vs. non-genetic conditions in the movie viewing task. Individual heat maps were generated by modelling each fixation as a Gaussian function using a Gaussian kernel with a standard deviation of 1degree of visual angle and a radius of 3 standard deviations. The heat maps were generated in time windows of 2 seconds corresponding to the TR used in the fMRI measurements. Spatial similarities between each pair of heat maps across the eye-tracking sessions were calculated using Pearson’s product-moment correlation coefficient (inter-subject correlation of eye gaze, eyeISC ). In the end a similarity matrix was obtained with correlations between each pair for each of the 712 time windows. 

First, the mean eISC scores over all 712 time windows were examined. These mean scores were acquired by extracting the mean of Fisher’s Z-transformed correlation scores and then transforming these mean values back to the correlation scale before the statistical analysis. The statistical significance of the group differences was analysed by contrasting pairs in which both subjects assumed a genetic relationship with pairs in which both subjects assumed the younger sister to be adopted. Non-parametric permutation tests with a total of 100000 permutations were used to avoid making assumptions about the data distribution. In this procedure the data were mixed randomly to change groupings and differences in the resulting new randomised groups were used to form an estimated distribution of the data. A comparison of how many of the permuted random partitions into groups build a more extreme group mean difference that the one observed with the original grouping yielded the final p-values. 


### Behavioral Measurements and Self-reports 
  
#### Valence and Arousal measurements 
  
The subjects self-reported emotions they had experienced during movie viewing. This was carried out after the fMRI experiment by viewing the movie again (Full procedures have been described in an earlier publication ). Two aspects of emotional experience were rated: emotional valence (positive-negative scale) and arousal which were acquired on separate runs. While watching the movie in the middle of the screen, the subjects could move a small cursor on the right side of the screen up and down on a scale using the computer mouse to report their current state of valence or arousal using a web tool   https://version.aalto.fi/gitlab/eglerean/dynamicannotations  . The self-ratings were collected at 5 Hz sampling rate. 


#### Behavioral questionnaires 
  
The subjects were asked after the first fMRI session five short freeform questions about their perception of the movie, specifically about how easy it was to take one or the other perspective, and whether they would have donated their kidney if in place of the movie protagonist. After the second fMRI session all subjects were debriefed by showing them the ending of the original movie, where it is revealed that the sick sister had wished for the healthy sister to refuse donating her kidney. Afterwards they were asked if seeing the real ending changed their opinion on the roles of the two movie protagonists. 

As an additional self-report measure, the subjects’ disposition for catching emotions from others was assessed with two emotional empathy questionnaires: Hatfield’s Emotional Contagion Scale  and the BIS/BAS scale . Every subject also filled in a questionnaire quantifying their social network , including their emotional closeness to their sister and best friend. The names of the sister and best friend were obtained from this questionnaire for the moral dilemma task. 



### Analysis of behavioral measurements 
  
#### Valence and arousal measurements 
  
To test whether dynamic valence and arousal were different between the genetic and non-genetic condition, we first computed inter-subject similarity matrices using valence and arousal rating time-series. These were compared against a similarity matrix for the experimental conditions of the viewing preceding the valence/arousal rating, i.e. the model tests for the case where individuals are more similar within the same condition (genetic or non-genetic), but dissimilar between conditions. Tests were performed using Mantel test with 5000 permutations. We also performed a test to see if subjects who were rating arousal and valence for the genetic condition had a stronger group similarity than subjects who rated arousal and valence for the non-genetic condition. Tests were performed using permutation based t-tests. As dynamic ratings can also be different in specific time points, we also performed a permutation-based t-test on valence and arousal values at each time point corrected for multiple comparisons across time. 


#### Heart rate and breathing rate analysis 
  
Differences between experimental conditions were computed in the same way as in the ISC analysis: Correlation values were first transformed into z-scores with the Fisher Z’s transform and then a permutation based approach was used to compute t-values and corresponding p-values . Correction for the multiple comparisons was performed with Benjamini-Hochberg false discovery rate (BH-FDR) correction at a q &lt; 0.05, corresponding to a t-value threshold of 2.133. 



### Behavioral measurements with a new group of subjects 
  
Subsequent to the fMRI experiments a new group of 30 subjects (all female, and having a sister, 18–33 years, mean age 25.5 years, right handed) were recruited for two further behavioral measurements. The subjects first performed an implicit association test (IAT). The IAT measures attitudes and beliefs that might not be consciously self-recognized by the subject or attitudes that the subjects are unwilling to report. By asking the subjects to sort, as quickly as possible, positively and negatively connoted words into categories, the IAT can measure the reaction times of the association process between the categories and the evaluations (e.g., good, bad). It has been shown in previous studies that making a response is easier and thus faster if the category is matching the implicit evaluation the subject bears in mind . In this study the two categories were “genetic sister” (sisko) and “adopted sister” (adoptiosisko). The two categories were paired in different randomized runs with positive or negative words, thus the experiment comprised separate runs asking the subjects to either match the positive words with the category “genetic sister” and negative words with the category “adopted sister” or vice versa to match positive words with the category “adopted sister” and negative words with the category “genetic sister”. The order in which the runs are presented counter-balanced across subjects and categories switched their localization on the screen in different runs to be on the left or right side of the screen to the same extent. Subjects were asked to press a key with either the right or the left hand and thus assign the evaluation word to one category on either the left or right hand side of the computer screen. With the experiment going on, the number of trials in this part of the IAT is increased in order to minimize the effects of practice. The IAT score is based on how long it takes a person to sort the words with the condition associating positive words and genetic (and negative and adopted) in contrast to negative words and genetic (and positive words and adopted). If an implicit preference exist for one of the categories subjects would be faster to match positive words to that category relative to the reverse. Data were analysed using Matlab. Similarity between subjects’ scores were examined TOST testing . As a second task, reaction times for the moral decision task were measured with the same group of subjects that underwent the IAT. As a difference to the decision task performed during fMRI scanning the order of the decisions was randomized (with easy decision including only strangers and difficult decisions including the sister on one side and the friend on the other). Reaction times were measured as the time between the onset of the slide revealing the identity of the involved individuals and the button press of the subject that related her decision. 


### Data availability 
  
The data that support the findings of this study are available on request from the corresponding author MBT. The data are not publicly available due to a prohibition by the Finnish law: Juridical restrictions set by the Finnish law prevent public access to the collected data, be it anonymized or non-anonymized, when data are recorded from human individuals. As the consent given by the subjects only applies to the specific study reported in our manuscript, no portion of the data collected could be used or released for use by third parties.</pre></details></details>
  <details class="inner-accordion"><summary>Coordinate-relevant source tables (2)</summary><details class="inner-accordion"><summary>Table 1 (Tab1) - Clusters size, peak coordinates and t value of all clusters of Experiment 1 (movie watching task).</summary><div class="table-html"><table-wrap id="Tab1" position="float" orientation="portrait"><label>Table 1</label><caption><p>Clusters size, peak coordinates and t value of all clusters of Experiment 1 (movie watching task).</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="1" rowspan="1">Cluster Label: movie watching task</th><th colspan="1" rowspan="1">Cluster extent (voxels)</th><th colspan="1" rowspan="1">x MNI (mm)</th><th colspan="1" rowspan="1">y MNI (mm)</th><th colspan="1" rowspan="1">z MNI (mm)</th><th colspan="1" rowspan="1">Peak value (T-value)</th></tr></thead><tbody><tr><td colspan="6" rowspan="1">
<bold>clusters genetic &gt; non-genetic</bold>
</td></tr><tr><td colspan="1" rowspan="1">Superior parietal lobule (R)</td><td colspan="1" rowspan="1">8794</td><td colspan="1" rowspan="1">8</td><td colspan="1" rowspan="1">−86</td><td colspan="1" rowspan="1">44</td><td colspan="1" rowspan="1">14.6272</td></tr><tr><td colspan="1" rowspan="1">Ventromedial prefrontal cortex (R)</td><td colspan="1" rowspan="1">4099</td><td colspan="1" rowspan="1">0</td><td colspan="1" rowspan="1">54</td><td colspan="1" rowspan="1">−8</td><td colspan="1" rowspan="1">8.3312</td></tr><tr><td colspan="1" rowspan="1">Superior temporal gyrus (L)</td><td colspan="1" rowspan="1">2182</td><td colspan="1" rowspan="1">−42</td><td colspan="1" rowspan="1">−26</td><td colspan="1" rowspan="1">6</td><td colspan="1" rowspan="1">16.974</td></tr><tr><td colspan="1" rowspan="1">Superior temporal gyrus (R)</td><td colspan="1" rowspan="1">1138</td><td colspan="1" rowspan="1">62</td><td colspan="1" rowspan="1">−26</td><td colspan="1" rowspan="1">4</td><td colspan="1" rowspan="1">13.0493</td></tr><tr><td colspan="1" rowspan="1">Putamen (R)</td><td colspan="1" rowspan="1">616</td><td colspan="1" rowspan="1">18</td><td colspan="1" rowspan="1">16</td><td colspan="1" rowspan="1">−10</td><td colspan="1" rowspan="1">7.2211</td></tr><tr><td colspan="1" rowspan="1">Insula (L)</td><td colspan="1" rowspan="1">266</td><td colspan="1" rowspan="1">−40</td><td colspan="1" rowspan="1">18</td><td colspan="1" rowspan="1">−10</td><td colspan="1" rowspan="1">6.9642</td></tr><tr><td colspan="1" rowspan="1">Inferior temporal gyrus (R)</td><td colspan="1" rowspan="1">145</td><td colspan="1" rowspan="1">52</td><td colspan="1" rowspan="1">−46</td><td colspan="1" rowspan="1">−30</td><td colspan="1" rowspan="1">7.432</td></tr><tr><td colspan="1" rowspan="1">Middle temporal gyrus (R)</td><td colspan="1" rowspan="1">110</td><td colspan="1" rowspan="1">66</td><td colspan="1" rowspan="1">−4</td><td colspan="1" rowspan="1">−16</td><td colspan="1" rowspan="1">10.4489</td></tr><tr><td colspan="1" rowspan="1">Inferior frontal gyrus (L)</td><td colspan="1" rowspan="1">89</td><td colspan="1" rowspan="1">−36</td><td colspan="1" rowspan="1">34</td><td colspan="1" rowspan="1">20</td><td colspan="1" rowspan="1">5.3232</td></tr><tr><td colspan="1" rowspan="1">Superior frontal gyrus (R)</td><td colspan="1" rowspan="1">89</td><td colspan="1" rowspan="1">8</td><td colspan="1" rowspan="1">62</td><td colspan="1" rowspan="1">26</td><td colspan="1" rowspan="1">6.2544</td></tr><tr><td colspan="1" rowspan="1">Inferior parietal lobule (L)</td><td colspan="1" rowspan="1">86</td><td colspan="1" rowspan="1">−52</td><td colspan="1" rowspan="1">−60</td><td colspan="1" rowspan="1">48</td><td colspan="1" rowspan="1">5.0215</td></tr><tr><td colspan="1" rowspan="1">Postcentral gyrus (R)</td><td colspan="1" rowspan="1">81</td><td colspan="1" rowspan="1">56</td><td colspan="1" rowspan="1">−6</td><td colspan="1" rowspan="1">38</td><td colspan="1" rowspan="1">7.0252</td></tr><tr><td colspan="1" rowspan="1">Superior parietal lobule (L)</td><td colspan="1" rowspan="1">73</td><td colspan="1" rowspan="1">−14</td><td colspan="1" rowspan="1">−58</td><td colspan="1" rowspan="1">72</td><td colspan="1" rowspan="1">7.4174</td></tr><tr><td colspan="6" rowspan="1">
<bold>clusters non-genetic &gt; genetic</bold>
</td></tr><tr><td colspan="1" rowspan="1">Inferior occipital gyrus (R)</td><td colspan="1" rowspan="1">1938</td><td colspan="1" rowspan="1">40</td><td colspan="1" rowspan="1">−66</td><td colspan="1" rowspan="1">−8</td><td colspan="1" rowspan="1">−12.3679</td></tr><tr><td colspan="1" rowspan="1">Middle occipital gyrus (L)</td><td colspan="1" rowspan="1">604</td><td colspan="1" rowspan="1">−32</td><td colspan="1" rowspan="1">−84</td><td colspan="1" rowspan="1">4</td><td colspan="1" rowspan="1">−9.7755</td></tr><tr><td colspan="1" rowspan="1">Cerebellar crus II (R)</td><td colspan="1" rowspan="1">318</td><td colspan="1" rowspan="1">30</td><td colspan="1" rowspan="1">−86</td><td colspan="1" rowspan="1">−32</td><td colspan="1" rowspan="1">−7.3011</td></tr><tr><td colspan="1" rowspan="1">Temporal pole (middle) (R)</td><td colspan="1" rowspan="1">171</td><td colspan="1" rowspan="1">38</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">−34</td><td colspan="1" rowspan="1">−6.6407</td></tr><tr><td colspan="1" rowspan="1">Inferior temporal gyrus (L)</td><td colspan="1" rowspan="1">165</td><td colspan="1" rowspan="1">−54</td><td colspan="1" rowspan="1">−64</td><td colspan="1" rowspan="1">−4</td><td colspan="1" rowspan="1">−8.2858</td></tr><tr><td colspan="1" rowspan="1">Angular gyrus (L)</td><td colspan="1" rowspan="1">147</td><td colspan="1" rowspan="1">−42</td><td colspan="1" rowspan="1">−54</td><td colspan="1" rowspan="1">28</td><td colspan="1" rowspan="1">−5.5752</td></tr><tr><td colspan="1" rowspan="1">Superior temporal gyrus (R)</td><td colspan="1" rowspan="1">95</td><td colspan="1" rowspan="1">64</td><td colspan="1" rowspan="1">−28</td><td colspan="1" rowspan="1">20</td><td colspan="1" rowspan="1">−8.3381</td></tr><tr><td colspan="1" rowspan="1">Inferior frontal gyrus (R)</td><td colspan="1" rowspan="1">94</td><td colspan="1" rowspan="1">52</td><td colspan="1" rowspan="1">20</td><td colspan="1" rowspan="1">16</td><td colspan="1" rowspan="1">−5.7279</td></tr><tr><td colspan="1" rowspan="1">Superior temporal gyrus (R)</td><td colspan="1" rowspan="1">87</td><td colspan="1" rowspan="1">64</td><td colspan="1" rowspan="1">0</td><td colspan="1" rowspan="1">−4</td><td colspan="1" rowspan="1">−9.6944</td></tr><tr><td colspan="1" rowspan="1">Precentral gyrus (L)</td><td colspan="1" rowspan="1">86</td><td colspan="1" rowspan="1">−44</td><td colspan="1" rowspan="1">10</td><td colspan="1" rowspan="1">52</td><td colspan="1" rowspan="1">−6.1405</td></tr><tr><td colspan="1" rowspan="1">Superior frontal gyrus (L)</td><td colspan="1" rowspan="1">86</td><td colspan="1" rowspan="1">−8</td><td colspan="1" rowspan="1">20</td><td colspan="1" rowspan="1">60</td><td colspan="1" rowspan="1">−7.8522</td></tr></tbody></table></table-wrap>
</div></details><details class="inner-accordion"><summary>Table 2 (Tab2) - Clusters size, peak coordinates and t value of all clusters of and Experiment 2 (moral dilemma decision task).</summary><div class="table-html"><table-wrap id="Tab2" position="float" orientation="portrait"><label>Table 2</label><caption><p>Clusters size, peak coordinates and t value of all clusters of and Experiment 2 (moral dilemma decision task).</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="1" rowspan="1">Cluster Label: moral dilemma decision task</th><th colspan="1" rowspan="1">Cluster extent (voxels)</th><th colspan="1" rowspan="1">x MNI (mm)</th><th colspan="1" rowspan="1">y MNI (mm)</th><th colspan="1" rowspan="1">z MNI (mm)</th><th colspan="1" rowspan="1">Peak value (T-value)</th></tr></thead><tbody><tr><td colspan="1" rowspan="1">Cerebellar lobule VI (R)</td><td colspan="1" rowspan="1">10417</td><td colspan="1" rowspan="1">20</td><td colspan="1" rowspan="1">−54</td><td colspan="1" rowspan="1">−30</td><td colspan="1" rowspan="1">10.1921</td></tr><tr><td colspan="1" rowspan="1">Superior frontal gyrus (L)</td><td colspan="1" rowspan="1">3631</td><td colspan="1" rowspan="1">−8</td><td colspan="1" rowspan="1">10</td><td colspan="1" rowspan="1">48</td><td colspan="1" rowspan="1">8.4473</td></tr><tr><td colspan="1" rowspan="1">Precentral gyrus (L)</td><td colspan="1" rowspan="1">2476</td><td colspan="1" rowspan="1">−34</td><td colspan="1" rowspan="1">−18</td><td colspan="1" rowspan="1">58</td><td colspan="1" rowspan="1">7.2107</td></tr><tr><td colspan="1" rowspan="1">Inferior frontal gyrus (L)</td><td colspan="1" rowspan="1">1207</td><td colspan="1" rowspan="1">−52</td><td colspan="1" rowspan="1">12</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">6.3788</td></tr><tr><td colspan="1" rowspan="1">Superior parietal lobule (L)</td><td colspan="1" rowspan="1">815</td><td colspan="1" rowspan="1">−28</td><td colspan="1" rowspan="1">−56</td><td colspan="1" rowspan="1">48</td><td colspan="1" rowspan="1">6.0945</td></tr><tr><td colspan="1" rowspan="1">Amygdala (L)</td><td colspan="1" rowspan="1">720</td><td colspan="1" rowspan="1">−14</td><td colspan="1" rowspan="1">−12</td><td colspan="1" rowspan="1">−12</td><td colspan="1" rowspan="1">6.2453</td></tr><tr><td colspan="1" rowspan="1">Putamen (R)</td><td colspan="1" rowspan="1">257</td><td colspan="1" rowspan="1">24</td><td colspan="1" rowspan="1">10</td><td colspan="1" rowspan="1">8</td><td colspan="1" rowspan="1">5.4598</td></tr><tr><td colspan="1" rowspan="1">Superior parietal lobule (R)</td><td colspan="1" rowspan="1">199</td><td colspan="1" rowspan="1">26</td><td colspan="1" rowspan="1">−62</td><td colspan="1" rowspan="1">54</td><td colspan="1" rowspan="1">4.8181</td></tr><tr><td colspan="1" rowspan="1">Angular gyrus (L)</td><td colspan="1" rowspan="1">156</td><td colspan="1" rowspan="1">−48</td><td colspan="1" rowspan="1">−52</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">4.9727</td></tr><tr><td colspan="1" rowspan="1">Insula (R)</td><td colspan="1" rowspan="1">128</td><td colspan="1" rowspan="1">40</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">0</td><td colspan="1" rowspan="1">5.3664</td></tr><tr><td colspan="1" rowspan="1">Middle temporal gyrus (L)</td><td colspan="1" rowspan="1">123</td><td colspan="1" rowspan="1">−62</td><td colspan="1" rowspan="1">−24</td><td colspan="1" rowspan="1">−12</td><td colspan="1" rowspan="1">4.7632</td></tr><tr><td colspan="1" rowspan="1">Temporal pole (middle) (L)</td><td colspan="1" rowspan="1">77</td><td colspan="1" rowspan="1">−56</td><td colspan="1" rowspan="1">8</td><td colspan="1" rowspan="1">−24</td><td colspan="1" rowspan="1">5.4375</td></tr></tbody></table></table-wrap>
</div></details></details>
</details>


<details class="doc-card">
  <summary><strong>PMID 29330483</strong> | Pred included: 12 | Manual included (accepted matches only): 10 | Correct overlaps: 10 | Match statuses: accepted=10, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29330483/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29330483_analysis_0</td><td>Female &gt; Male Pictures</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Participants viewed erotic pictures of other people (male vs. female), which involves perceiving and responding to social stimuli (bodies, faces, interpersonal sexual context). This contrast measures social-related neural processing across groups (gendered social cues), meeting the broad Social Processing construct.</td></tr>
<tr><td>29330483_analysis_1</td><td>Male &gt; Female Pictures</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Male&gt;female picture contrast involves perception of social stimuli (other people’s bodies/faces) and differential social processing; it fits the Social Processing construct.</td></tr>
<tr><td>29330483_analysis_2</td><td>Female &gt; Male Pictures</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Female&gt;male picture contrast in bisexual women examines neural responses to social stimuli (others’ bodies/faces) and is therefore within Social Processing.</td></tr>
<tr><td>29330483_analysis_3</td><td>Male &gt; Female Pictures</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Male&gt;female picture contrast in bisexual women involves social stimulus processing (perception of other people), placing it in Social Processing.</td></tr>
<tr><td>29330483_analysis_4</td><td>Female &gt; Male Pictures</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Female&gt;male picture contrast in homosexual women examines perception and neural responses to other people (preferred-sex vs non-preferred), which is social in nature and falls under Social Processing.</td></tr>
<tr><td>29330483_analysis_5</td><td>Male &gt; Female Pictures</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Male&gt;female picture contrast in homosexual women entails processing social stimuli (other people), thus meeting Social Processing inclusion criteria.</td></tr>
<tr><td>29330483_analysis_6</td><td>Heterosexual Women: Female &gt; Male Videos</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Female&gt;male video contrast involves viewing other people in socially meaningful (sexual) contexts, with auditory and visual social cues; this reflects broad Social Processing.</td></tr>
<tr><td>29330483_analysis_7</td><td>Heterosexual Women: Male &gt; Female Videos</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Male&gt;female video contrast taps processing of social stimuli (actors’ behaviors/vocalizations) and thus qualifies as Social Processing.</td></tr>
<tr><td>29330483_analysis_8</td><td>Bisexual Women: Female &gt; Male Videos</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Female&gt;male video contrast in bisexual women entails social-cognitive processing of others (visual and auditory cues), fitting Social Processing.</td></tr>
<tr><td>29330483_analysis_9</td><td>Bisexual Women: Male &gt; Female Videos</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Male&gt;female video contrast engages processing of social stimuli (other people’s bodies/actions/vocalizations), so it falls under Social Processing.</td></tr>
<tr><td>29330483_analysis_10</td><td>Homosexual Women: Female &gt; Male Videos</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Female&gt;male video contrast in homosexual women involves social stimulus processing (actors’ actions and vocalizations) and therefore fits Social Processing.</td></tr>
<tr><td>29330483_analysis_11</td><td>Homosexual Women: Male &gt; Female Videos</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Male&gt;female video contrast examines responses to social stimuli (other people’s actions/vocalizations) and so qualifies under Social Processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29330483_1</td><td>(Bisexual Women) Female &gt; Male Pictures; self</td><td>29330483_analysis_2</td><td>Female &gt; Male Pictures</td><td>0.721</td><td>0.923</td><td>0.863</td><td>accepted</td><td>high_coord_match</td></tr><tr><td>29330483_10</td><td>(Homosexual Women) Male &gt; Female Videos; self</td><td>29330483_analysis_11</td><td>Homosexual Women: Male &gt; Female Videos</td><td>0.961</td><td>1.000</td><td>0.988</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29330483_2</td><td>(Bisexual Women) Female &gt; Male Videos; self</td><td>29330483_analysis_8</td><td>Bisexual Women: Female &gt; Male Videos</td><td>0.959</td><td>1.000</td><td>0.988</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29330483_3</td><td>(Bisexual Women) Male &gt; Female Pictures; self</td><td>29330483_analysis_3</td><td>Male &gt; Female Pictures</td><td>0.721</td><td>1.000</td><td>0.916</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29330483_4</td><td>(Bisexual Women) Male &gt; Female Videos; self</td><td>29330483_analysis_9</td><td>Bisexual Women: Male &gt; Female Videos</td><td>0.959</td><td>1.000</td><td>0.988</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29330483_5</td><td>(Heterosexual Women) Female &gt; Male Pictures; self</td><td>29330483_analysis_0</td><td>Female &gt; Male Pictures</td><td>0.677</td><td>1.000</td><td>0.903</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29330483_6</td><td>(Heterosexual Women) Female &gt; Male Videos; self</td><td>29330483_analysis_6</td><td>Heterosexual Women: Female &gt; Male Videos</td><td>0.963</td><td>1.000</td><td>0.989</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29330483_7</td><td>(Heterosexual Women) Male &gt; Female Videos; self</td><td>29330483_analysis_7</td><td>Heterosexual Women: Male &gt; Female Videos</td><td>0.963</td><td>1.000</td><td>0.989</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29330483_8</td><td>(Homosexual Women) Female &gt; Male Pictures; self</td><td>29330483_analysis_4</td><td>Female &gt; Male Pictures</td><td>0.698</td><td>1.000</td><td>0.910</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29330483_9</td><td>(Homosexual Women) Female &gt; Male Videos; self</td><td>29330483_analysis_10</td><td>Homosexual Women: Female &gt; Male Videos</td><td>0.961</td><td>1.000</td><td>0.988</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  <details class="inner-accordion"><summary>PMC full text available (PMCID 5766543)</summary><p><strong>Title:</strong> Neural Correlates of Sexual Orientation in Heterosexual, Bisexual, and Homosexual Women</p><details><summary>Abstract</summary><pre class="paper-text">We used fMRI to investigate neural correlates of responses to erotic pictures and videos in heterosexual (N = 26), bisexual (N = 26), and homosexual (N = 24) women, ages 25–50. We focused on the ventral striatum, an area of the brain associated with desire, extending previous findings from the sexual psychophysiology literature in which homosexual women had greater category specificity (relative to heterosexual and bisexual women) in their responses to male and female erotic stimuli. We found that homosexual women’s subjective and neural responses reflected greater bias towards female stimuli, compared with bisexual and heterosexual women, whose responses did not significantly differ. These patterns were also suggested by whole brain analyses, with homosexual women showing category-specific activations of greater extents in visual and auditory processing areas. Bisexual women tended to show more mixed patterns, with activations more responsive to female stimuli in sensory processing areas, and activations more responsive to male stimuli in areas associated with social cognition.</pre></details><details><summary>Body</summary><pre class="paper-text">## Introduction 
  
Studies using physiological measures have found that women tend to have non-specific patterns of genital arousal . That is, in contrast to men, women tend to show similar degrees of arousal to erotic stimuli depicting either sex. For example, heterosexual women have generally shown equivalent arousal to both erotic stimuli featuring men and erotic stimuli featuring women. This has been repeatedly demonstrated with vaginal photoplethysmography . This pattern has also been found using less direct measures such as looking time , pupil dilation , and fMRI . Notably, homosexual women’s arousal patterns are more category-specific than heterosexual women’s, although less so than men’s . 

The fact that women’s sexual arousal patterns are less category-specific than men’s has been interpreted as a potential contributor to gender differences in “erotic plasticity” , which Baumeister has defined as “the extent to which sex drive is shaped by social, cultural, and situational factors.” 

Baumeister offered three lines of evidence when he initially proposed that women may have greater erotic plasticity compared with men: (1) women show larger effects of social and cultural factors on sexual attitudes, desire, and behavior; (2) sexual attitude-behavior consistency is lower in women than in men; (3) individual women exhibit more variation in sexual behavior across time than men. Women’s less specific arousal patterns may also contribute to their increased “sexual fluidity” , which Diamond has defined as an individual’s “capacity for situation-dependent flexibility in sexual responsiveness, which allows individuals to experience changes in same-sex or other-sex desire across both short-term and long-term time periods” . 

One might hypothesize that arousal patterns of bisexual women should be similar to the non-specific arousal patterns of heterosexual women; however, studies of women’s arousal patterns have mostly neglected to include bisexual women. Heterosexual women’s arousal does not appear to favor erotic stimuli of either sex, and thus may be considered to reflect a bisexual pattern. (We do not mean to imply that heterosexual women are confused or in denial about their “real preferences”; rather, the findings in need of explanation are why heterosexual women show non-heterosexual arousal patterns in the laboratory). The implication of women’s non-specific arousal patterns for their sexual orientations is difficult to interpret. Most women, like most men, behave and identify heterosexually . However, men are more likely than women to identify as completely heterosexual or completely homosexual, and women are more likely than men to identify as bisexual or “mostly heterosexual” . 

If arousal patterns are similar between heterosexual and bisexual women, the question remains what distinguishes the two groups. One possibility, supported by some research, is that bisexual women tend to have greater sexual motivation, which may increase the likelihood of exploring a capacity for attraction to both sexes . Or, bisexual women may be more aware than heterosexual women of their non-specific arousal , which could partially contribute to bisexual sexual motivation. Alternatively, bisexual women may be more likely than heterosexual women to interpret their non-specific arousal states in sexual or romantic terms. 

It is also possible that bisexual women’s arousal patterns differ from those observed in heterosexual women. Consistent with this possibility, recent studies suggest that women with bisexual interests tend to be more aroused by female than by male erotic stimuli . Perhaps for some women with female-biased arousal patterns, this bias can motivate non-heterosexual feelings, behavior, and identity. 

Interpretations of non-specific arousal patterns in women are further complicated by the fact that female genital arousal exhibits relatively low correlations with subjectively reported sexual arousal, in contrast to the high correlations observed in men . Discrepancies between existing genital and subjective measures indicate that some women may report substantial subjective arousal without substantial genital arousal, and vice versa. It has also been suggested that non-specific arousal patterns may not indicate affective responses to erotic stimuli, but may instead reflect a kind of protective preparatory response . 

Neuroimaging assessments may shed light on the neural systems that are involved in responding to a given paradigm. Functional magnetic resonance imaging (fMRI) is a neuroimaging approach that allows for the indirect assessment of brain activity by tracking ratios of oxygenated and deoxygenated blood a proxy for neural firing. When used in the context of presenting erotic stimuli, this non-invasive neural measure could provide a converging line of evidence for interpreting the genital and subjective arousal findings described above. In this study, we used fMRI to specifically focused on the “reward system” in order to address the question: to what extent is there an affective significance to findings from the literature on women’s sexual orientation and genital arousal? 

The part of the “reward system” that we focused on is the ventral striatum, a dopamine-sensitive area of the brain that is a reliable measure of reward-related processing–and in particular, wanting and “incentive motivation” –including with respect to sexual orientation . Most neuroimaging studies of sexual response have focused on men , but the ventral striatum has also been found to reliably activate in studies of women’s responses to erotic stimuli . However, until now, no studies have measured neural responses to erotic stimuli in bisexual women. 

The present investigation primarily focused on two hypotheses: (1) Homosexual women may show greater category-specificity than non-homosexual women in brain activity, as suggested by the genital arousal literature; (2) Bisexual women may show larger biases towards female stimuli, compared with heterosexual women. We tested these hypotheses with respect to subjective and neural responses to erotic pictures and erotic videos. We used two different kinds of erotic stimuli because of their potentially non-overlapping strengths and weaknesses. Erotic pictures may be particularly well-suited for assessing the initial appraisal of sexual stimuli, but their brevity may not reflect the kinds of experiences that drive sexuality in the real world. Erotic videos may allow for the measurement of more intense states, but their extended duration may also provide opportunities for self-regulatory efforts to modify erotic responses. 


## Method 
  
### Participants 
  
Participants were 26 heterosexual women, 26 bisexual women, and 24 homosexual women, recruited from a variety of publicly-posted and online advertisements seeking (paid) volunteers for a neuroimaging study of sexual orientation and arousal. Bisexual women were required to have had at least two previous sexual partners and one romantic partner (of three months or greater duration) of each sex. Homosexual and heterosexual participants all met these criteria with respect to their respective preferred sexes. 

After responding to advertisements, participants were screened for inclusion using online questionnaires. Participants provided information about sexual orientation, sexual interests, and personality, in addition to answering screening questions relevant to medical eligibility for fMRI research. Participants were required to be right handed, non-claustrophobic, free from ferromagnetic implants, and not currently taking psychiatric medications. Participants were informed of the risks and nature of the study and agreed to participate in all portions of the research. This study was approved by the Institutional Review Board of Northwestern University and carried out in accordance with its guidelines. Informed consent was obtained from each participant for every portion of the study in which they participated. 

Participants’ sexual orientation was assessed using self-reported identities (i.e. “Homosexual”/“Gay”, “Bisexual”/“Bi”, “Heterosexual”/“Straight”), as well as with a modified Kinsey score, which asked participants about their sexual fantasies throughout adulthood as well as in the past year. The scale ranged from 0 to 6, with 0 corresponding to an exclusively heterosexual orientation and 6 corresponding to an exclusively homosexual orientation. Responses to questions about adulthood and about the past year were averaged to create a Kinsey score for each participant. The average Kinsey score was 0.8 for heterosexual women (  SD   = 0.7,   range   = 0–2), 2.63 for bisexual women (  SD   = 0.7,   range   = 2–4.5), and 5.2 for homosexual women (  SD   = 0.68,   range   = 4–6). 

Participants’ ages ranged from 21 to 46 years old. Mean ages were 29.7 for heterosexual women (  SD   = 5.86,   range   = 25–46), 30.27 for bisexual women (  SD   = 6.41,   range   = 21–48), and 29 for homosexual women (  SD   = 3.12,   range   = 25–38). The sample of 76 participants was racially and ethnically diverse, with 23 non-Caucasian participants including two Latina participants, ten African-American participants, four Asian-American participants, and seven participants who identified otherwise or who identified as multiethnic/multiracial. Groups did not significantly differ either with respect to age (  F  (2,73) = 0.348,   p   = 0.708) or ethnicity (c (2, N = 76) = 2.94, p = 0.23). We also confirmed that ethnicity did not significantly impact responses to the erotic stimuli. 


### Stimuli and Procedure 
  
Subjects experienced two experimental paradigms in the scanner: first erotic pictures were shown (over a period of ~21 minutes), and then erotic videos were shown (over a period of ~19 minutes) after a brief rest period. Picture stimuli were shown before video stimuli for all participants in an attempt to promote stimulus engagement. That is, it was assumed that potentially less intense stimuli might be better presented earlier in the experimental session while attentional resources are highest. Further, there was concern that first showing more intense stimuli would reduce engagement with subsequent stimuli. As such, pictures and videos stimuli were not counterbalanced with respect to each other. 

Participants watched stimuli while laying down with a combination of earplugs (to minimize scanner noise) and over-ear headphones (for video sound and communication with experimenters). Images were displayed via projector onto a wall, which was made viewable to participants via an angled mirror placed above the eyes. 

#### Erotic pictures paradigm 
  
The present study employed a subset of the picture stimuli used in Safron   et al  .  and Sylva   et al  . . Pictures depicted a nude man, a nude woman, or a same-sex couple (i.e., either two men or two women) engaged in explicit sexual contact. Erotic stimuli featuring both individual nudes and same-sex pairs engaging in explicit sexual interaction is common in research on sexual arousal and sexual orientation , which is not the case when stimuli featuring male-female couples is presented. However, erotic stimuli featuring explicit sexual activity in same-sex couples tends to be substantially more arousing compared with pictures of single nudes . Such stimuli are similar to pictures of nude individuals, in the sense that only men or women, but not both, are depicted in a given picture. Thus, sexual arousal induced by them is relatively unambiguous in terms of the gender to which participants are responding. 

In each of two 10.5-minute runs (ordering counterbalanced), participants viewed 40 erotic pictures featuring male models and 40 erotic pictures featuring female models. Each picture was shown for 3.5 seconds, followed by a variable-duration fixation cross presented for either 1.5, 6.5, or 11.5 seconds. Variable-duration baselines were utilized for superior deconvolution of the BOLD signal in a rapid event-related design for fMRI (in which evoked signals are never allowed to return to baseline levels). During the presentation of each picture, participants used buttons held in their right hands to rate that image on a scale of −2 to +2 (respectively: “strongly disliked,” “disliked,” “liked,” “strongly liked”), with no option of 0 for neutral ratings. Neutral options for ratings were not provided for the sake of consistency with previous research using the same stimuli. Note: Subjective ratings of pictures were lost for some participants due to a button-box equipment error. 


#### Erotic videos paradigm 
  
Following picture assessment, participants were shown six video clips depicting individual masturbating men and six video clips depicting individual masturbating women. Depicted individuals appeared sexually aroused but did not reach orgasm. To estimate baseline responses, six natural landscape videos were shown. 

In each of two 9.25-minute runs (ordering counterbalanced), videos were presented for 15 seconds each, followed by a 15-second distraction task requiring participants to indicate via button-press when a number in a series decreased by an interval other than seven. This task was intended to facilitate a return to emotional and physiological baseline. 15-second stimulus presentations were chosen as a desirable stimulation period in an fMRI block design, which can potentially be more sensitive than event-related designs . 

After leaving the scanner, participants viewed the videos once more and provided ratings of each clip. Videos were rated using a 5-point scale for degree of sexual appeal, ranging from “not at all” (0) to “very much” (4), with a midpoint of “somewhat” (2).’ 



### fMRI signal extraction methods 
  
#### Image acquisition 
  
A Siemens Trio 3 T magnet and 12-channel RF head coil were used to collect T2*-weighted gradient-recalled EPI images from the whole brain (32 3-mm slices with a 0.99-mm interslice gap; TR = 2500 ms; TE = 20 ms; flip angle = 80°; FOV = 200 × 220 mm, 120 × 128 acquisition matrix). Slices were taken along the plane connecting the anterior and posterior commissures, with a 1.72 mm × 1.72 mm × 3.99 mm resolution, with more refined axial dimensions intended to produce less distortion and signal dropout in sub-cortical areas, although possibly at the expense of signal-to-noise ratio. During each picture run, 250 whole-brain volumes were collected, and during each video run, 220 whole-brain volumes were collected, with the first four volumes discarded to account for initial magnetization effects. For anatomical localization, a structural MRI scan consisting of T1-weighted images was conducted after the testing runs (160 1-mm axial slices; TR = 2.1 ms; TE = 4.38 ms; flip angle = 15°; FOV = 220 mm; 256 × 192 matrix). 


#### Image pre-processing 
  
Image pre-processing and analysis was performed using SPM 12b (Wellcome Trust Centre for Neuroimaging, London, UK), and implemented in Matlab v 8.1.604 (The MathWorks Inc., MA, USA). 

Functional (EPI) volumes were first corrected for slice timing. Each participant’s volumes were then registered to the mean slice, after which the registered volumes were resliced, used to create a mean resliced image, and then co-registered to the structural (T1) image. All EPI images, including the mean resliced image, as well as the structural (T1) scans were then spatially normalized to Montreal Neurological Institute (MNI) space, and re-sampled to 3 × 3 × 3 mm (27 mm ) resolution. Normalized functional images were then smoothed to an 8 mm full-width-at-half-maximum Gaussian kernel. 


#### Signal to noise ratio and head coverage exclusions 
  
To exclude participants with poor signal due to either head motion or scanner conditions, average signal-to-noise ratio (SNR) over time was calculated for each subject (after preprocessing, using a mask that included only voxels with appreciable EPI signal). The SNR ratio for each voxel (mean divided by standard deviation) was averaged across all voxels in the brain . Participants whose picture data SNR was less than one standard deviation below the mean were excluded from picture analyses. Similarly, participants whose video data SNR was less than one standard deviation below the mean were excluded from video analyses. 

Based on these criteria, fourteen participants (five heterosexual, five bisexual, and four homosexual) were excluded from fMRI and subjective picture analyses, and sixteen participants (six heterosexual, six bisexual, and four homosexual) were excluded from fMRI and subjective video analyses. After exclusions were performed for SNR, we included a total of twenty-one heterosexual women, twenty-one bisexual women, and twenty homosexual women in fMRI picture analyses. Video analyses after SNR exclusion included eighteen heterosexual women, eighteen bisexual women, and twenty homosexual women. To check the validity of our SNR criterion, head motion plots were visually inspected for all participants (Parrish,   et al  . ). Excluded participants had highly variable head positions as compared to included participants. An additional validity-check was performed using evoked responses to erotic pictures minus a fixation-cross baseline. Excluded participants had substantially reduced activity in visual cortices as compared to included participants. 

An additional thirty-two participants (twelve heterosexual, twelve bisexual, and eight homosexual) were excluded from subjective picture rating analyses due to insufficient subjective data resulting from a button-box equipment error. Five participants (three bisexual and two homosexual) were excluded from subjective video analyses for the same reason. Thus, after exclusions were performed for insufficient subjective data, we included a total of nine heterosexual women, nine bisexual women, and twelve homosexual women in subjective picture analyses, and twenty heterosexual women, seventeen bisexual women, and eighteen homosexual women in subjective video analyses. 

For whole-brain analyses, mean functional scans were individually examined to identify participants with substantial cutoffs in head coverage. As a result, one heterosexual female who had substantial frontal lobe cutoff was excluded from whole-brain analyses in addition to those participants excluded for SNR. 


#### First-level analyses 
  
For both the video and picture assessments, a standard general linear model (GLM)  was used in identifying hemodynamic changes for each participant, and a high-pass filter (cutoff 128 s) was used to remove low-frequency temporal noise. 

Estimated average activity was calculated for each participant’s separate responses to male pictures, female pictures, male videos, and female videos (contrasted with fixation cross for pictures and neutral nature scenes for videos). These estimates were used for region of interest analyses. For whole-brain analyses, estimated average activity was also calculated for each participant’s response to male compared with female pictures and videos. For both the picture and video assessments, each participant’s responses to each stimulus contrast of interest were concatenated within stimulus type, using data from both the 1  and 2  runs. 

Ventral striatum region of interest analyses. An a priori region of interest (ROI) analysis was performed on the ventral striatum—centered on the nucleus accumbens—as this was the area most likely to indicate desire. The ventral striatum and hypothalamus are the only two areas that have been shown to be specifically associated with sexual (as opposed to general) arousal . We focused on the ventral striatum because it likely has higher validity for reflecting sexual incentive value compared with the hypothalamus, which contains a variety of nuclei with heterogeneous functions (including sexual arousal) that would be difficult to disambiguate with the limited spatial resolution of 3 T fMRI. 

The ventral striatum ROI mask used in the present study was drawn on an MNI template brain using the WFU PickAtlas toolbox for SPM 8 . It was anatomically defined as a dilated intersection of the ventral anterior caudate and putamen. The resulting ventral striatum ROI is shown in Fig.  .   
Mask used as the ventral striatum (VS) ROI, drawn using an average brain in the WFU PickAtlas toolbox for SPM 8. MNI coordinates displayed: x = 0, y = 17, z = −8. 
  

Estimates of average ventral striatum activity for each participant were extracted using the MarsBar toolbox for SPM8 . Extracted ventral striatum ROI data were analyzed using JMP Pro v11 (SAS Institute, Cary, NC). 



### Planned contrasts and within-group tests 
  
We constructed separate dependent variables for each combination of stimulus type (i.e. picture or video) and response type (i.e., subjective or ventral striatum activation) by subtracting response to female stimuli from response to male stimuli. That is, we constructed dependent variables for 1) subjective response to pictures, 2) subjective response to videos, 3) ventral striatum activation to pictures, and 4) ventral striatum responses to videos, each of which reflected responses to male stimuli minus responses to female stimuli. We refer to this as the Male-Female contrast. 

Because there were three groups (i.e., heterosexual, homosexual, and bisexual women), two orthogonal between-groups contrasts were constructed to examine what we believe to be the most interesting pair of independent questions based on previous literature . The first question was whether homosexual women differed from the other two groups in their Male-Female contrasts. The second question was whether bisexual women differed from heterosexual women in their Male-Female contrasts. The use of orthogonal planned contrasts allowed us to test these hypotheses with maximum statistical power while simultaneously minimizing the number of overall comparisons. 

Within-group t-tests were also performed separately in each group in order to characterize relative responding to male and female stimuli. 


### Whole-brain analyses 
  
Finally, we examined overall patterns of differential activation in response to male compared with female erotic stimuli across the entire brain. If bisexual and heterosexual women have less specific arousal patterns, then they are likely to exhibit less extensive differential activity between male and female stimuli compared with the activity patterns expected for homosexual women. 

Tests of average group responses to stimulus conditions were performed using one-sample contrasts. Each group (heterosexual women, bisexual women, and homosexual women) was tested individually for clusters of greater activity for male stimuli compared with female stimuli, and female stimuli compared with male stimuli, using a corrected statistical threshold (p &lt; 0.05 FWE). 

For these analyses, cluster reports were generated in SPM. Peak activations and cluster extents (extent threshold k = 5) were visually examined as overlays on slice and render maps. Neuroanatomical descriptions were determined based on agreement between two trained investigators, and checked against designations from the WFU Atlas (Maldjian   et al  ., 2003). 


### Data availability statement 
  
The datasets generated and analyzed during the current study are available from the corresponding author on request. 



## Results 
  
### Between-group planned contrasts 
  
As previously described, planned comparisons for the ventral striatum ROI were conducted via multiple regression using two orthogonal between-groups contrasts: one comparing homosexual women with heterosexual and bisexual women, and one comparing heterosexual with bisexual women. Separate analyses were conducted for each of the Male-Female contrasts (i.e., responses to female stimuli subtracted from responses to male stimuli). Results are presented in Table  .    
Planned contrasts comparing women of different orientation groups. 
  
*Significant p-value &lt; 0.05. **Signifcant p-value &lt; 0.01. 

***Significant p-value &lt; 0.001. 
    
Within-group male – female (male minus female) stimuli difference scores for subjective ratings and ventral striatum (VS) responses, by sexual orientation. Difference scores are defined as a participant’s average response to stimuli depicting males minus average response to stimuli depicting females. Points represent individual participants. Horizontal bars indicate group means and 95% confidence intervals of the means. Horizontal lines at 0 indicate no difference between ratings to erotic stimuli depicting each sex. (  a  ) Difference scores for subjective ratings of picture stimuli. (b) Difference scores for VS activation evoked by picture stimuli. (c) Difference scores for subjective ratings of video stimuli. (d) Difference scores for VS activation evoked by video stimuli. ***p &lt; 0.001, **p &lt; 0.01, *p &lt; 0.05. 
  

#### Homosexual versus non-homosexual women 
  
Subjective ratings. Compared with non-homosexual women, homosexual women had significantly more negative (i.e., gynephilic) Male-Female contrasts for both pictures (p = 0.015) and videos (p &lt; 0.001). That is, homosexual women showed a greater preference for pictures and videos of females relative to males, compared with both bisexual and heterosexual women. 

Ventral striatum activation patterns. Homosexual women had significantly more female-biased ventral striatum responses compared to non-homosexual women for pictures (p = 0.002), but not videos. 


#### Bisexual versus heterosexual women 
  
We compared heterosexual and bisexual women’s subjective and ventral striatum responses to erotic pictures and videos, and observed only one significant difference: for video stimuli, bisexual women had significantly more female-preferring subjective responses than did heterosexual women (p = 0.026). 



### Within-group tests comparing responses to male and female erotic stimuli 
  
Figure   (showing the distribution of Male-Female contrasts for the three groups) shows that heterosexual women exhibited a non-significant trend (p = 0.079) towards favoring female erotic pictures compared with male erotic pictures, and had no differentiation between stimulus sex for other tests. Bisexual women also did not subjectively differentiate among stimulus types based on sex, although they did exhibit (non-significant) marginal female-favoring ventral striatum scores for picture (p = 0.063) and video (p = 0.054) stimuli. Homosexual women, in contrast to heterosexual and bisexual women, showed clear favoring of female stimuli as assessed by subjective liking of pictures (p &lt; 0.001), appeal ratings of videos (p &lt; 0.001), as well as in ventral striatum responses to pictures (p = 0.003) and non-significantly for ventral striatum responses to videos (p = 0.073). Note that these results are presented descriptively. Inferences about differences among the three groups depend on the tests presented in Table  . 


### Whole brain tests comparing responses to male and female erotic stimuli 
  
Note: Activation patterns are described in greater detail in the discussion, with interpretations of possible functional significances. 

#### Picture stimuli 
  
Comparing activation to female versus male erotic pictures, heterosexual women exhibited relatively greater activity for female pictures in occipital (i.e., visual) and occipitotemporal cortices, with no brain areas showing significantly greater activation for male pictures (Fig.  ; Table  ). Bisexual women also showed greater activity in visual cortices for female relative to male pictures, but they showed greater activity for male pictures in other areas including supramarginal and angular gyri, as well as the posterior cingulate. Homosexual women exhibited significant activations for female compared with male pictures in visual cortex, parietal lobes, and parahippocampal cortex, but with no brain areas showing significantly greater activation for male pictures.   
Differential brain activations towards male and female pictures in heterosexual, bisexual, and homosexual women. Whole brain activations are shown for the male picture minus female picture contrasts (with brain activation evoked by viewing neutral stimuli subtracted from activations toward the erotic pictures). Height threshold is set at p &lt; 0.05 FWE with a cluster threshold of k = 5. Axial slice 31, sagittal slice 50, and coronal slice 38 are shown for all groups. 
    
Differential whole-brain activations in response to male vs. female pictures. 
  


#### Video stimuli 
  
When viewing female compared with male erotic videos (Fig.  ; Table  ), all groups showed activity in bilateral superior temporal cortices, likely indicating an auditory confound in which more extensive and substantial vocalizations were present in female erotic videos . However, this effect appeared to vary by sexual orientation, with homosexual women showing the most extensive and robust evoked activity (peak T = 14.22) compared with heterosexual (peak T = 11.71) and bisexual women (peak T = 8.83). In the opposite direction of greater responses to male compared with female erotic videos, heterosexual and bisexual (but not homosexual) women exhibited activations in occipital cortices. While all groups had greater activity towards male videos in (anterior) superior parietal cortices, these activations appeared to be more extensive and robust in bisexual women (peak T = 11.55) compared with heterosexual (peak T = 7.64) and homosexual women (peak T = 7.99).   
Differential brain activations between male and female videos in heterosexual, bisexual, and homosexual women. Whole brain activations are shown for the male video minus female video contrasts (with brain activation evoked by viewing neutral stimuli subtracted from activation toward the erotic videos). Height threshold is set at p &lt; 0.05 FWE with a cluster threshold of k = 5. Axial slice 37, sagittal slice 61, and coronal slice 38 are shown for all groups. 
    
Differential whole-brain activations in response to male vs. female videos. 
  




## Discussion 
  
In this fMRI study of female sexual orientation—the first to include bisexual women—we extended several key findings from the sexual psychophysiology literature . Using the ventral striatum as a neural measure of incentive motivation, we demonstrated that homosexual women have greater gender bias in their responses to male and female erotic stimuli. 

### Main findings: subjective and ventral striatum responses to male and female erotic stimuli 
  
Direct comparisons of bisexual and heterosexual women revealed no significant differences, with the exception of bisexual women having more gynephilic subjective responses to erotic videos. However, bisexual and heterosexual women did not differ with respect to their ventral striatum responses toward these stimuli. When contrasted to bisexual and heterosexual women, homosexual women showed distinctly greater bias toward female stimuli in both their subjective responses to videos and pictures, and also in their ventral striatum responses to pictures. In sum, our planned contrast findings are consistent with the genital arousal literature in which more category-specific responses were observed in homosexual women . 

Another set of tests, comparing male vs. female stimuli within each group, revealed that neither bisexual nor heterosexual women were significantly biased toward stimuli depicting males or stimuli depicting females. This was true both in ventral striatum response and in subjective arousal, for both picture and video stimuli. Homosexual women, however, were uniquely gynephilic (i.e., female-preferring), with significantly greater responses to female stimuli for subjective responses to pictures, subjective responses to videos, and ventral striatum responses to pictures. This gynephilic bias in homosexual women was consistent with our direct comparisons and previous literature. 

Our findings are only partially consistent with observations from the genital arousal literature in which homosexual and bisexual women both had gynephilic responses, but where heterosexual women had non-specific responses . We found significant biases in ventral striatum responses toward female stimuli among homosexual women, but with more indifferent patterns among heterosexual and bisexual women. However, with one exception—bisexual women showing more gynephilic subjective responses to erotic videos than did heterosexual women, in a direct comparison—heterosexual and bisexual women’s patterns of results did not differ significantly. 

Our a priori tests in the ventral striatum allowed us to explore whether women of different sexual orientations also exhibited different degrees of incentive motivation toward male and female erotic stimuli. But fMRI also provides the ability to look at activation patterns across the entire brain, potentially allowing for a more detailed characterization of the neural systems involved. Below we review activation patterns for each group in viewing male compared with female erotic stimuli, along with some reverse inferences as to their functional significance. 


### Whole brain responses to erotic pictures 
  
For heterosexual women viewing erotic pictures, activity was greater for female relative to male stimuli bilaterally in lateral occipital cortices, likely indicative of visual attention , as well as in right-lateralized fusiform cortex, potentially suggesting face or body processing .   In no brain areas did heterosexual women have significantly greater activation for male relative to female erotic pictures  . Rather, they seemed to have a somewhat gynephilic pattern of visual attention, consistent with results from eye-tracking and looking-time studies in which heterosexual women attended to erotic characteristics of female pictures . 

Bisexual women showed more activity in response to female (relative to male) erotic pictures throughout the visual system, including fusiform cortex, which (as described above) is often associated with perception of faces and bodies . Patterns were similar to those observed in heterosexual women (and presumably with similar functional significances), but with larger spatial extents of activation. Although bisexual and heterosexual women were not directly contrasted, this more extensive visual activation could be taken as support for somewhat greater gynephilic interest on the part of bisexual women, consistent with ventral striatum activation patterns. 

For bisexual women viewing erotic pictures, activity was greater for male relative to female stimuli in posterior midcingulate and right retrosplenial cingulate cortices, potentially suggesting greater perceptual salience and emotional memory for male erotic stimuli . Additional male-biased activations were identified bilaterally in supramarginal and angular gyri, indicating processes relating to mental imagery, or possibly mentalizing . 

Thus, in contrast to heterosexual participants, bisexual women showed greater activity towards male (relative to female) erotic pictures in affect-related brain areas. In this way, it seems that it would be overly simplistic to say that bisexual women are similar to heterosexual women, but with the addition of gynephilic interest. Rather,   bisexual women seem to have greater responses to both male and female erotic stimuli, depending on the brain area being considered  . Patterns of greater overall responsiveness are consistent with suggestions that bisexual women may be distinguished by having overall greater degrees of sexual motivation relative to heterosexual women . 

It is also notable that bisexual women uniquely showed greater activations to male stimuli in areas of the brain implicated in higher-order cognition, including mentalizing. Speculatively, these activations could be related to more complex processing of sexual motivation in bisexual women . To the degree that these activation patterns in bisexual women actually specifically reflect social cognition, the question remains open as to why this may be more likely to be observed in bisexual but not heterosexual or homosexual women. 

For homosexual women viewing erotic pictures, greater activations for female (relative to male) stimuli extended throughout the visual system, with additional clusters in occipitotemporal cortices. Clusters in the right inferior precuneus may have indicated mental imagery , and clusters in posterior parahippocampal cortex may have indicated either memory encoding or retrieval .   For homosexual women, no brain areas had significantly greater activation for male relative to female erotic pictures. Thus, homosexual women were the only group that exhibited an overall pattern of differential brain activity (between male and female sexual stimuli) greater only for pictures depicting their preferred gender  . 


### Whole brain responses to erotic videos 
  
For heterosexual women viewing erotic videos, activity was greater for female relative to male stimuli in bilateral superior temporal cortices likely indicating an auditory confound deriving from more extensive and substantial vocalizations being present in female erotic videos . Activity was greater for male relative to female videos in posterior occipital cortex, likely indicating enhanced visual attention . Further clusters (greater for male compared with female videos) in the inferolateral postcentral gyrus and parietal somatosensory association areas may have indicated awareness of bodily sensations, possibly related to sexual imagery . 

For bisexual women viewing erotic videos, activations were greater for female (relative to male) stimuli in superior temporal cortices, likely indicating the same auditory-related activity present in heterosexual women. Bisexual women’s brain activity was greater for male (relative to female) erotic videos in occipital cortex, likely indicating visual attention . Male-biased activations in somatosensory cortices may have indicated processing of bodily sensations , and further activations in bilateral superior parietal lobules, premotor and supplementary motor cortices, and right supramarginal gyrus may have indicated mental imagery or possibly mirroring with the actors shown in the videos . 

Similar to the findings for erotic pictures,   bisexual women were unique in the degree to which male videos produced activations in brain areas associated with more abstract (and possibly complex) processing  . Again, the significance of this pattern remains unclear. 

For homosexual women viewing female relative to male erotic videos, activity in superior temporal cortices likely indicated the same auditory-related processing observed in heterosexual and bisexual women, albeit more robustly and extensively, consistent with enhanced attention to emotionally salient stimulus features. When viewing male relative to female erotic videos, activations in the right somatosensory cortex may have indicated processing of bodily sensations , which may have been either positive or negative in valence. Thus, while emotionally associated brain areas did not exhibit differential activations for videos,   homosexual women’s particularly strong engagement of auditory cortices for female stimuli provided yet further evidence of uniquely gender-biased responding, relative to heterosexual and bisexual women  . 


### Comparisons with previous findings 
  
Few studies have investigated the category-specificity of brain activity in non-heterosexual women. Ponseti   et al  .  found that both heterosexual and homosexual women showed gender-specific patterns of brain activity in multiple areas, including the ventral striatum. Sylva   et al  .  also found some evidence for category-specific responding in women, although not in the ventral striatum, and without specifically testing whether or not heterosexual or homosexual women differed in their responses. 

The patterns observed Ponseti   et al  .  stand in contrast to the present investigation in which homosexual women tended to be the only group showing strongly category-specific responses to erotic stimuli. One possible interpretations for their findings of category-specific responses in all women was the unusual nature of the stimuli (i.e., close-up images of male and female genitalia, isolated from interpersonal contextual factors) . As suggested by Chivers (2017) , it may be the case that sex and gender cues can produce specific responses in heterosexual women, but that these are usually trumped by contextual factors in driving arousal responses in women. The stimuli utilized in the present study contained contextual factors (e.g. body posture, facial expression) that are more typical of those found in the genital arousal literature. 

However, it should be noted that the present study did not find support for greater category-specificity in homosexual women across all stimulus conditions. Rather, planned contrasts in the ventral striatum only revealed significant group differences between homosexual and non-homosexual women for erotic pictures. There were no significant differences in ventral striatum response between homosexual and non-homosexual women for erotic videos (even though subjective evaluations of those stimuli did significantly differ across the groups). 

This pattern of differing results for pictures versus videos may be related to differences in how individuals respond to these stimuli, limitations of our video paradigm, or both. While erotic videos may theoretically allow for the assessment of qualitatively different states of sexual response, it may be the case that incentive motivation is greatest when stimuli are first presented, but then diminishes with longer stimulus presentations . Additionally, erotic pictures may have been more effective at driving ventral striatum responses due to factors such as unpredictably varied presentation times of preferred stimuli contributing to larger magnitude reward-prediction errors . 


### Limitations 
  
One limitation of nearly all studies of erotic responses in women—including this one—is a failure to control for hormonal conditions or contraceptive usage. By default, it can generally be assumed that most women were not measured within the ovulatory window, when responses to erotic stimuli might be greatest . Additionally, a number of women may have been using hormonal contraceptives. Measuring women’s responses outside of the fertile phase of their cycles—or while they were using hormonal contraceptives —may have yielded a restricted range of arousal responses. However, the specificity of erotic responding has not been shown to be influenced by menstrual cycle in previous studies of genital arousal . 

Another source of potential limitations may have been the nature of the stimuli used. Though our stimuli were pilot-tested and rated by individuals of different sexual orientations in order to confirm that they would appeal to a broad participant sample, it is never possible to ensure that common stimuli will evoke the responses intended. This may be especially true for something as emotionally salient and individual as sexual arousal. Thus, it is possible that category specificity patterns could appear to be different if stimuli better reflected participants’ subjective preferences. This is a limitation of many studies of sexual responding, although data gleaned from more individualized stimulus sets are difficult to interpret. 

One more aspect of the stimuli that is difficult to control for is sensory details that are inherently different between male and female stimuli. Differences in actors’ vocalizations (for videos), actors’ body positions (for both videos and pictures), and actors’ body motions (in the videos) were present (on average) between male and female stimuli. These features are difficult to control for and could conceivably lead to differences in both subjective and neural responding when viewing male vs. female stimuli, especially in more primary sensory areas of the brain such as visual and auditory cortices. However, such differences may also serve to reinforce the gendered nature of the stimuli and improve their correspondence with real-world experiences and real-world arousal. 



## Conclusions 
  
Though the neural data presented here align with previously-observed patterns in women’s genital and subjective arousal, much remains unknown about the relationship between arousal patterns, orientation, and the development of sexual motivation towards particular sexes in women. Our study supports past findings indicating that women tend not to have strongly category-specific responses to erotic stimuli, with homosexual women showing somewhat greater specificity than heterosexual and bisexual women. Future research should explore the extent to which women’s non-specific sexual response contributes to erotic plasticity (i.e., change with context) and sexual fluidity (i.e., change over time) .</pre></details></details>
  <details class="inner-accordion"><summary>Coordinate-relevant source tables (2)</summary><details class="inner-accordion"><summary>Table 2 (Tab2) - Differential whole-brain activations in response to male vs. female pictures.</summary><div class="table-html"><table-wrap id="Tab2" position="float" orientation="portrait"><label>Table 2</label><caption><p>Differential whole-brain activations in response to male vs. female pictures.</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="1" rowspan="1">R/L</th><th colspan="1" rowspan="1">Region</th><th colspan="1" rowspan="1">BA</th><th colspan="1" rowspan="1">MNI</th><th colspan="1" rowspan="1">voxels</th><th colspan="1" rowspan="1">peak T</th></tr></thead><tbody><tr><td colspan="6" rowspan="1">
<italic toggle="yes">Heterosexual Women</italic>
</td></tr><tr><td colspan="6" rowspan="1">    Female &gt; Male Pictures</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">lingual gyrus, inferolateral occipital</td><td colspan="1" rowspan="1">18, 19</td><td colspan="1" rowspan="1">(−33 −76 −10)</td><td colspan="1" rowspan="1">21</td><td colspan="1" rowspan="1">8.01</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">fusiform gyrus</td><td colspan="1" rowspan="1">37</td><td colspan="1" rowspan="1">(30 −67 −7)</td><td colspan="1" rowspan="1">26</td><td colspan="1" rowspan="1">7.81</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">inferolateral occipital, fusiform gyrus</td><td colspan="1" rowspan="1">19, 37</td><td colspan="1" rowspan="1">(42 −70 −16)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.78</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">fusiform gyrus</td><td colspan="1" rowspan="1">37</td><td colspan="1" rowspan="1">(30 −58 −10)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.59</td></tr><tr><td colspan="6" rowspan="1">    Male &gt; Female Pictures: no differential activations</td></tr><tr><td colspan="6" rowspan="1">
<italic toggle="yes">Bisexual Women</italic>
</td></tr><tr><td colspan="6" rowspan="1">    Female &gt; Male Pictures</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">inferior occipital cortex, middle occipital gyrus, lingual gyrus</td><td colspan="1" rowspan="1">18, 19</td><td colspan="1" rowspan="1">(36 −70 −10)</td><td colspan="1" rowspan="1">86</td><td colspan="1" rowspan="1">10.68</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">19</td><td colspan="1" rowspan="1">(48 −64 −10)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.96</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">fusiform gyrus</td><td colspan="1" rowspan="1">37</td><td colspan="1" rowspan="1">(33 −55 −13)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.15</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">inferolateral occipital, middle occipital gyrus</td><td colspan="1" rowspan="1">19, 18</td><td colspan="1" rowspan="1">(−39 −85 −7)</td><td colspan="1" rowspan="1">138</td><td colspan="1" rowspan="1">9.07</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">18, 19</td><td colspan="1" rowspan="1">(−30 −88 5)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">8.47</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">inferior occipital gyrus, primary visual cortex, lingual gyrus</td><td colspan="1" rowspan="1">18, 17</td><td colspan="1" rowspan="1">(−24 −94 −4)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">8.06</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">occipital cortex, middle occipital gyrus</td><td colspan="1" rowspan="1">19</td><td colspan="1" rowspan="1">(30 −79 17)</td><td colspan="1" rowspan="1">43</td><td colspan="1" rowspan="1">9.03</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">occipital cortex, middle occipital gyrus</td><td colspan="1" rowspan="1">19</td><td colspan="1" rowspan="1">(30 −82 26)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.38</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">inferior occipital cortex, lingual gyrus</td><td colspan="1" rowspan="1">18</td><td colspan="1" rowspan="1">(−24 −85 −13)</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">8.22</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">primary visual cortex, cuneus</td><td colspan="1" rowspan="1">17</td><td colspan="1" rowspan="1">(15 −100 −4)</td><td colspan="1" rowspan="1">12</td><td colspan="1" rowspan="1">8.09</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">18</td><td colspan="1" rowspan="1">(42 −82 −1)</td><td colspan="1" rowspan="1">27</td><td colspan="1" rowspan="1">8.05</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">18</td><td colspan="1" rowspan="1">(27 −85 2)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.62</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">18</td><td colspan="1" rowspan="1">(33 −91 8)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">6.86</td></tr><tr><td colspan="2" rowspan="1">    Male &gt; Female Pictures</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1" /></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">angular gyrus, supramarginal gyrus</td><td colspan="1" rowspan="1">39, 40</td><td colspan="1" rowspan="1">(−51 −64 41)</td><td colspan="1" rowspan="1">21</td><td colspan="1" rowspan="1">9.37</td></tr><tr><td colspan="1" rowspan="1">      R/L</td><td colspan="1" rowspan="1">posterior cingulate</td><td colspan="1" rowspan="1">23</td><td colspan="1" rowspan="1">(0 −22 35)</td><td colspan="1" rowspan="1">10</td><td colspan="1" rowspan="1">8.23</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">angular gyrus</td><td colspan="1" rowspan="1">39</td><td colspan="1" rowspan="1">(48 −61 35)</td><td colspan="1" rowspan="1">27</td><td colspan="1" rowspan="1">7.94</td></tr><tr><td colspan="1" rowspan="1">       R</td><td colspan="1" rowspan="1">supramarginal gyrus</td><td colspan="1" rowspan="1">40</td><td colspan="1" rowspan="1">(51 −61 44)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.75</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">retrosplenial cingulate</td><td colspan="1" rowspan="1">30</td><td colspan="1" rowspan="1">(15 −52 29)</td><td colspan="1" rowspan="1">6</td><td colspan="1" rowspan="1">7.68</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">supramarginal gyrus</td><td colspan="1" rowspan="1">40</td><td colspan="1" rowspan="1">(57 −49 35)</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">7.38</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">supramarginal gyrus</td><td colspan="1" rowspan="1">40</td><td colspan="1" rowspan="1">(−36 −61 44)</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">7.08</td></tr><tr><td colspan="6" rowspan="1">
<italic toggle="yes">Homosexual Women</italic>
</td></tr><tr><td colspan="6" rowspan="1">    Female &gt; Male Pictures</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">19</td><td colspan="1" rowspan="1">(−27 −82 14)</td><td colspan="1" rowspan="1">139</td><td colspan="1" rowspan="1">10.01</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">18, 19</td><td colspan="1" rowspan="1">(−33 −88 −1)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">8.99</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">middle occipital gyrus, primary visual cortex</td><td colspan="1" rowspan="1">18, 17</td><td colspan="1" rowspan="1">(−18 −97 2)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">8.57</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">19</td><td colspan="1" rowspan="1">(33 −79 14)</td><td colspan="1" rowspan="1">89</td><td colspan="1" rowspan="1">9.83</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">inferior lateral occipital cortex</td><td colspan="1" rowspan="1">19</td><td colspan="1" rowspan="1">(42 −85 2)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">8.19</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">19</td><td colspan="1" rowspan="1">(33 −70 8)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.78</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">fusiform gyrus, posterior paraphippocampal gyrus</td><td colspan="1" rowspan="1">37</td><td colspan="1" rowspan="1">(33 −52 −10)</td><td colspan="1" rowspan="1">36</td><td colspan="1" rowspan="1">9.56</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">fusiform gyrus, middle occipital gyrus</td><td colspan="1" rowspan="1">18</td><td colspan="1" rowspan="1">(33 −70 −13)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">8.03</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">primary visual cortex</td><td colspan="1" rowspan="1">17</td><td colspan="1" rowspan="1">(18 −94 −1)</td><td colspan="1" rowspan="1">11</td><td colspan="1" rowspan="1">8.56</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">fusiform gyrus, lingual gyrus, posterior parahippocampal gyrus</td><td colspan="1" rowspan="1">37</td><td colspan="1" rowspan="1">(−33 −61 −7)</td><td colspan="1" rowspan="1">26</td><td colspan="1" rowspan="1">8.45</td></tr><tr><td colspan="1" rowspan="1">       L</td><td colspan="1" rowspan="1">fusiform gyrus</td><td colspan="1" rowspan="1">37</td><td colspan="1" rowspan="1">(−39 −61 −13)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.62</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">precuneus, occipitoparietal</td><td colspan="1" rowspan="1">7</td><td colspan="1" rowspan="1">(24 −73 41)</td><td colspan="1" rowspan="1">6</td><td colspan="1" rowspan="1">7.18</td></tr><tr><td colspan="6" rowspan="1">    Male &gt; Female Pictures: no differential activations</td></tr></tbody></table></table-wrap></div></details><details class="inner-accordion"><summary>Table 3 (Tab3) - Differential whole-brain activations in response to male vs. female videos.</summary><div class="table-html"><table-wrap id="Tab3" position="float" orientation="portrait"><label>Table 3</label><caption><p>Differential whole-brain activations in response to male vs. female videos.</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="1" rowspan="1">R/L</th><th colspan="1" rowspan="1">Region</th><th colspan="1" rowspan="1">BA</th><th colspan="1" rowspan="1">MNI</th><th colspan="1" rowspan="1">voxels</th><th colspan="1" rowspan="1">peak T</th></tr></thead><tbody><tr><td colspan="6" rowspan="1">
<italic toggle="yes">Heterosexual Women</italic>
</td></tr><tr><td colspan="6" rowspan="1">    Female &gt; Male Videos</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">superior temporal gyrus, primary and secondary auditory cortex</td><td colspan="1" rowspan="1">22, 41, 42</td><td colspan="1" rowspan="1">(−57 −25 8)</td><td colspan="1" rowspan="1">124</td><td colspan="1" rowspan="1">11.71</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">superior temporal gyrus, primary and secondary auditory cortex</td><td colspan="1" rowspan="1">22, 41, 42</td><td colspan="1" rowspan="1">(−42 −31 11)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">10.15</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">superior temporal gyrus</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">(−66 −28 8)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">8.99</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">superior temporal gyrus, primary and secondary auditory cortex</td><td colspan="1" rowspan="1">22, 41, 42</td><td colspan="1" rowspan="1">(54 −16 −1)</td><td colspan="1" rowspan="1">48</td><td colspan="1" rowspan="1">10.42</td></tr><tr><td colspan="6" rowspan="1">    Male &gt; Female Videos</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">primary visual cortex, lingual gyrus</td><td colspan="1" rowspan="1">17, 18</td><td colspan="1" rowspan="1">(−9 −82 2)</td><td colspan="1" rowspan="1">30</td><td colspan="1" rowspan="1">10.14</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">inferolateral postcentral gyrus</td><td colspan="1" rowspan="1">3</td><td colspan="1" rowspan="1">(60 −16 29)</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">7.94</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">superior parietal lobule</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">(33 −49 62)</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">7.64</td></tr><tr><td colspan="6" rowspan="1">
<italic toggle="yes">Bisexual Women</italic>
</td></tr><tr><td colspan="6" rowspan="1">    Female &gt; Male Videos</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">superior temporal, primary and secondary auditory cortex</td><td colspan="1" rowspan="1">22, 41, 42</td><td colspan="1" rowspan="1">(−54 −10 5)</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">8.83</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">superior temporal gyrus</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">(63 −25 2)</td><td colspan="1" rowspan="1">8</td><td colspan="1" rowspan="1">7.26</td></tr><tr><td colspan="6" rowspan="1">    Male &gt; Female Videos</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">superior parietal lobule, extending into supramarginal gyrus</td><td colspan="1" rowspan="1">7, 5, 40</td><td colspan="1" rowspan="1">(36 −46 59)</td><td colspan="1" rowspan="1">211</td><td colspan="1" rowspan="1">11.55</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">postcentral gyrus</td><td colspan="1" rowspan="1">3, 1, 2</td><td colspan="1" rowspan="1">(36 −37 53)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">11.27</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">postcentral sulcus</td><td colspan="1" rowspan="1">1, 2</td><td colspan="1" rowspan="1">(33 −31 41)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">9.51</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">postcentral gyrus, postcentral sulcus</td><td colspan="1" rowspan="1">3, 1, 2</td><td colspan="1" rowspan="1">(−36 −37 56)</td><td colspan="1" rowspan="1">25</td><td colspan="1" rowspan="1">8.45</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">superior parietal lobule</td><td colspan="1" rowspan="1">5, 7</td><td colspan="1" rowspan="1">(−33 −49 59)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.55</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">supplementary motor area</td><td colspan="1" rowspan="1">6</td><td colspan="1" rowspan="1">(30 −10 59)</td><td colspan="1" rowspan="1">12</td><td colspan="1" rowspan="1">8.14</td></tr><tr><td colspan="1" rowspan="1">       L</td><td colspan="1" rowspan="1">supplementary motor area</td><td colspan="1" rowspan="1">6</td><td colspan="1" rowspan="1">(−24 −13 62)</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">7.73</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">cuneus</td><td colspan="1" rowspan="1">17</td><td colspan="1" rowspan="1">(−9 −82 2)</td><td colspan="1" rowspan="1">9</td><td colspan="1" rowspan="1">7.6</td></tr><tr><td colspan="6" rowspan="1">
<italic toggle="yes">Homosexual Women</italic>
</td></tr><tr><td colspan="6" rowspan="1">    Female &gt; Male Videos</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">superior temporal gyrus</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">(51 −10 2)</td><td colspan="1" rowspan="1">578</td><td colspan="1" rowspan="1">14.22</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">primary and secondary auditory cortex, superior temporal gyrus</td><td colspan="1" rowspan="1">41 42, 22</td><td colspan="1" rowspan="1">(54 −19 5)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">13.91</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">superior temporal gyrus</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">(60 −1 −4)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">13.26</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">superior temporal gyrus</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">(−63 −19 2)</td><td colspan="1" rowspan="1">247</td><td colspan="1" rowspan="1">12.7</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">primary and secondary auditory cortex</td><td colspan="1" rowspan="1">41, 42</td><td colspan="1" rowspan="1">(−45 −25 8)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">11.97</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">superior temporal gyrus</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">(−66 −28 5)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">10.99</td></tr><tr><td colspan="6" rowspan="1">     Male &gt; Female Videos</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">postcentral gyrus</td><td colspan="1" rowspan="1">3</td><td colspan="1" rowspan="1">(33 −34 47)</td><td colspan="1" rowspan="1">7</td><td colspan="1" rowspan="1">7.99</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">postcentral sulcus</td><td colspan="1" rowspan="1">2</td><td colspan="1" rowspan="1">(42 −28 41)</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">7.76</td></tr></tbody></table></table-wrap></div></details></details>
</details>


<details class="doc-card">
  <summary><strong>PMID 29890323</strong> | Pred included: 6 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29890323/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29890323_analysis_0</td><td>emotional &gt; neutral video clips</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast compares emotional vs neutral autobiographical videos requiring participants to perceive, interpret and respond to social-emotional cues—directly measuring broad social processing (empathy, mentalising).</td></tr>
<tr><td>29890323_analysis_1</td><td>neutral &gt; emotional video clips</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The neutral&gt;emotional contrast still involves processing of social stimuli (videos of people) and comparisons of social-emotional engagement, relevant to social processing.</td></tr>
<tr><td>29890323_analysis_2</td><td>Positively related to Z-EA scores</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Modulation of BOLD by intra-individual empathic accuracy directly indexes social cognitive processing required for understanding others—core social processing.</td></tr>
<tr><td>29890323_analysis_3</td><td>Negatively related to Z-EA scores</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Negative modulation by EA still pertains to social cognitive processing (regions whose activity inversely relates to accuracy), so it remains within social processing domain.</td></tr>
<tr><td>29890323_analysis_4</td><td>Positive correlation with participants&#x27; emotional intensity ratings</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Temporal correlation between BOLD and participants&#x27; continuous ratings of targets&#x27; emotional intensity probes dynamic social processing of others&#x27; affect—central to social processing.</td></tr>
<tr><td>29890323_analysis_5</td><td>Negative correlation with participants&#x27; emotional intensity ratings</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Negative correlations between BOLD and participants&#x27; ratings still concern social-emotional processing of others and therefore fall under social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29890323_1</td><td>emotional &gt; neutral video clips; others</td><td>29890323_analysis_0</td><td>emotional &gt; neutral video clips</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29890323_2</td><td>neutral &gt; emotional video clips; others</td><td>29890323_analysis_1</td><td>neutral &gt; emotional video clips</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  <details class="inner-accordion"><summary>PMC full text available (PMCID 6057276)</summary><p><strong>Title:</strong> Tracking emotions in the brain – Revisiting the Empathic Accuracy Task</p><details><summary>Abstract</summary><pre class="paper-text">Many empathy tasks lack ecological validity due to their use of simplistic stimuli and static analytical approaches. Empathic accuracy tasks overcome these limitations by using autobiographical emotional video clips. Usually, a single measure of empathic accuracy is computed by correlating the participants&#x27; continuous ratings of the narrator&#x27;s emotional state with the narrator&#x27;s own ratings. 

In this study, we validated a modified empathic accuracy task. A valence-independent rating of the narrator&#x27;s emotional intensity was added to provide comparability between videos portraying different primary emotions and to explore changes in neural activity related to variations in emotional intensity over time. We also added a new neutral control condition to investigate general emotional processing. In the scanner, 34 healthy participants watched 6 video clips of people talking about an autobiographical event (2 sad, 2 happy and 2 neutral clips) while continuously rating the narrator&#x27;s emotional intensity. 

Fluctuation in perceived emotional intensity correlated with activity in brain regions previously implicated in cognitive empathy (bilateral superior temporal sulcus, temporoparietal junction, and temporal pole) and affective empathy (right anterior insula and inferior frontal gyrus). When emotional video clips were compared to neutral video clips, we observed higher activity in similar brain regions. Empathic accuracy, on the other hand, was only positively related to activation in regions that have been implicated in cognitive empathy. 

Our modified empathic accuracy task provides a new method for studying the underlying components and dynamic processes involved in empathy. While the task elicited both cognitive and affective empathy, successful tracking of others&#x27; emotions relied predominantly on the cognitive components of empathy. The fMRI data analysis techniques developed here may prove valuable in characterising the neural basis of empathic difficulties observed across a range of psychiatric conditions. 
   Highlights  
  
Activity in affective and cognitive empathy related regions during emotional videos. 
  
Activity in similar regions related to changes in perceived emotional intensity. 
  
Only regions implicated in cognitive empathy were associated with empathic accuracy. 
  
No difference between video clips that did and did not elicit affect sharing. 
  
Empathic accuracy related to self-rated perspective-taking but not empathic concern.</pre></details><details><summary>Body</summary><pre class="paper-text">## Introduction 
  
Empathy, has been defined as “an emotional response [… which] is similar to one&#x27;s perception […] and understanding […] of the stimulus emotion, with recognition that the source of the emotion is not one&#x27;s own.” ( , page 150). Empathy is crucial for successful social interaction as it allows the individual to predict others&#x27; actions, emotions and intentions ( ). Deficits in empathic processing have been reported in psychiatric disorders such as autism spectrum disorder (ASD), schizophrenia, borderline personality disorder and bipolar disorder ( ). Identifying the neural substrates of empathy in healthy populations is important for understanding conditions that are characterised by empathic difficulties. In neuroscience, the concept of empathy is considered to include separate affective (sharing others&#x27; emotion) and cognitive (understanding others&#x27; emotion) components (for example,  ;  ). Previous research has identified distinct clusters of brain regions involved in affective empathy: medial/anterior cingulate cortex (MCC, ACC), anterior insula (AI) ( ;  ), and supplementary motor area (SMA) ( ). Within the broader domain of social cognition, cognitive empathy overlaps with the affective component of Theory of Mind (ToM) or mentalising, namely the capacity to infer other people&#x27;s thoughts, emotions and intentions without necessarily sharing them ( ). A recent meta-analysis of 144 fMRI studies using ToM tasks ( ) identified the medial prefrontal cortex (mPFC), medial orbitofrontal cortex (mOFC), ACC, precuneus, temporal pole (TP), posterior superior temporal gyrus (pSTS) and temporoparietal junction (TPJ) and inferior frontal gyrus (IFG) as key regions for mentalising. 

However, prior research on the neural mechanisms of empathy has often lacked ecological validity. Studies have often used simplistic stimuli that differ greatly from the complex cues that individuals have to process in real-life situations ( ,  ). Moreover, most studies focus on empathy for pain, while only a few studies have evaluated other emotions (e.g. disgust, happiness, sadness;  ;  ). In addition, empathy has mostly been operationalised as a static trait ( ). However, in the real world empathy fluctuates dynamically ( ). These fluctuations can happen spontaneously because of changes in internal state or in response to shifts in external circumstances, such the emotional intensity and expressivity of others. 

In the current study, we addressed these limitations of previous research by modifying an existing paradigm, the Empathic Accuracy Task (EAT;  ), that incorporates more naturalistic stimuli and reflects the dynamic nature of empathy. Participants (perceivers) watch video clips in which another person (target) describes an emotional autobiographical event. Perceivers continuously rate the target&#x27;s emotion while watching the clips (via button pressing). The EAT measures how   accurately   the perceiver infers changes in the target&#x27;s emotional states by correlating the perceiver&#x27;s ratings with the target&#x27;s ratings of their own emotions (see   for a detailed description).   found that empathic accuracy was associated with higher activation in both affective (i.e. inferior parietal lobule (IPL)) and cognitive (i.e. mPFC) empathy networks. In a recent study of adolescents, empathic accuracy related positively to activation in cognitive empathy or mentalising regions (mPFC, TPJ, STS) and negatively to activation in regions implicated in affective empathy (IPL, ACC, AI;  ). 

In the current study, new video clips were created and the EAT was modified in the following important ways: First, video clips depicted discrete primary emotions (happy, sad, angry, frightened) and participants rated changes in the targets&#x27; emotional intensity (instead of valence) to ensure comparability across different emotions and higher construct validity. Second, we introduced well-matched neutral video clips that acted as a control condition. In this condition, targets described their bedroom. This control condition allowed us to examine the neural correlates of emotion processing irrespective of empathic accuracy. Third, as empathy is a dynamic process, perceivers need to be able to continuously identify changes in the intensity of the target&#x27;s emotional state. We therefore utilised an analysis approach that tracked changes in the target&#x27;s emotional intensity throughout each video clip, in addition to deriving a single index of empathic accuracy (averaged across the clip). Fourth, we included ratings from participants regarding how they felt after watching each video to gain a better understanding of how the neural correlates of EA are influenced by cognitive and affective empathy. Finally, to validate the EAT, we related task performance to self-reported trait empathy and IQ as well as acquiring a normative data set with participants who completed the EAT outside of the scanner. 

The aim of this study was to validate a modified version of the Empathic Accuracy Task, using a staged analysis approach which replicates analyses presented previously in the literature, but which also included additional comparisons. First, we contrasted the blood-oxygen-level dependent (BOLD) responses to emotional and neutral clips to explore correlates of complex and multi-sensory emotional processing during extended clips rather than single emotional images. Second, we validated our emotional intensity rating scale by analysing the neural correlates of intra-individual variations in empathic accuracy. Third, we explored neural correlations with variations in perceived emotional intensity over time, thus capitalising on the availability of continuous ratings throughout each video clip. 

Given the results of prior neuroimaging studies of empathy and mentalising, we had the following hypotheses:   
At the group level, increased BOLD responses would be observed in brain regions previously linked to empathy and mentalising when participants watched targets describe emotional versus neutral events. 
  
There would be positive correlations between intra-individual variations in empathic accuracy and BOLD responses in these regions. 
  
We predicted positive correlations between fluctuations in perceived emotional intensity and BOLD responses in these regions during emotional video clips. 
  


## Methods 
  
### Participants 
  
#### fMRI study 
  
Forty-seven healthy participants aged between 20 and 30 years, fluent in English and with no history of neurological illness, took part in the study. Six participants were excluded from the analysis due to current or recurrent episodes of mental illness as assessed by the Mini International Neuropsychiatric Interview ( ). Five further participants were excluded because of excessive head movement or poor task performance (&lt;2 SD in empathic accuracy (EA) scores) and two participants had incomplete questionnaire data. The final dataset included 34 subjects (19 females, mean age: 24.0 years, SD: 2.7 years). The study received ethical approval from the Camberwell - St. Giles NHS Research Ethics Committee (14/LO/0477) and the University of Southampton Ethics Committee. 


#### Normative data collection 
  
To create a normative data set for the EAT and to validate the stimuli used in the fMRI task, an additional 73 healthy participants completed the EAT outside the MRI scanner. The same inclusion criteria as described above were applied. After excluding 13 participants due to current or recurrent episodes of mental illness, the final dataset included 60 healthy participants (36 females, mean age: 25.2 years, SD: 2.9 years). This aspect of the study was approved by the University of Southampton Ethics Committee. 



### Tasks and stimuli 
  
#### Video acquisition 
  
Eleven native English-speaking students from the University of Southampton acted as targets (8 females, mean age: 20.1 years, SD: 1.64 years). Before filming they were asked to recall a specific autobiographical event (happy, sad, angry or frightened), in which they remembered feeling a strong emotion. Each target wrote a short summary of each event and rated its overall emotional intensity on a 9-point scale (from 1, ‘no emotion’ to 9, ‘very strong emotion’). For the emotional stimuli, only events with a rating of 5 or above were filmed. Each target provided one video clip for each emotion and one clip in which they described their bedroom (neutral condition). An adapted emotion elicitation strategy, which involved imagining being in the situation, was used before filming to reinstate the affective states the targets had felt during the events ( ). They were advised to refrain from making specific reference to their affective state (e.g. happy) but were allowed to use generic descriptions (e.g. upset) or descriptions of bodily symptoms (e.g. shaking). All targets were filmed from the shoulders upwards, in front of a black background, for standardisation purposes. Each clip lasted between 83 and 140 s (mean = 100.3, SD = 15.2). After filming each clip, targets watched the video and continuously rated their emotional intensity using the same 9-point scale as above. Ratings were made by using arrow keys on the keyboard to move a coloured square on the scale (this shifted by one point per button press). Starting point for all ratings was “1”. 

For the fMRI study, the 6 video clips that were selected (one happy, one sad and one neutral video, featuring one female and one male target) were those which received high EA and target expressiveness scores in a pilot study with 13 participants (7 male, mean age: 21.54 years, SD: 2.37 years). A description of the target&#x27;s gender, the emotional condition, the clip length and the target&#x27;s rating of emotional intensity experienced during each clip is presented in  . For pre-training and volume adjustment, one additional sad, one neutral and two happy clips were added (depicting different targets from the main experiment). For the data collection outside the MRI scanner, 27 expressive video clips were selected (7 happy clips, 7 sad clips, 3 angry clips, 3 frightened clips and 7 neutral clips) as well as two happy clips and one sad clip for pre-training purposes. The task and instructions for filming stimuli are available on request.   
Video clips displayed in order of presentation during the Empathic Accuracy Task with target&#x27;s gender, emotional condition and length of the video clip and targets&#x27; average ratings of their own emotional intensity. 
  Table 1   


#### Empathic accuracy task (EAT) 
  
Participants were instructed to continuously rate the perceived emotional intensity of the target ( , top) using the same 9-point scale as above (from 1, ‘no emotion’ to 9, ‘very strong emotion’). In the fMRI study, participants used a button box to provide ratings. In the non-imaging study, participants used the computer&#x27;s arrow keys. The default rating at the start of each video clip was no emotion (i.e. rating of 1). Following each clip, participants were asked: (1) which emotion the target felt most strongly (cognitive empathy: options of “happy”, “angry”, “surprised”, “sad”, “frightened” and “no emotion”); and (2) which emotion they themselves felt most strongly (i.e., affective empathy: same response options as above).   
 Schematic representation of the Empathic Accuracy task and continuous rating scale data.   Top: example of a video clip and rating scale in the Empathic Accuracy Task. The target&#x27;s identity has been disguised in this image. Bottom: Illustration of fluctuations in the   target&#x27;s   emotional intensity, as rated by the target (blue) and an example participant&#x27;s ratings (green). An Empathic Accuracy (EA) score was computed by correlating the participant&#x27;s ratings and the target&#x27;s ratings for each video clip. 
  Fig. 1   


#### Interpersonal reactivity index 
  
The Interpersonal Reactivity Index (IRI) is a widely-used self-report questionnaire that measures dispositional empathy using four subscales: fantasy (FS), empathic concern (EC), perspective taking (PT) and personal distress (PD;  ). 


#### Wechsler abbreviated scale of intelligence, Second Edition 
  
The Wechsler Abbreviated Scale of Intelligence, Second Edition (WASI-II;  ) is a widely-used and reliable test of general intelligence. 



### Procedure 
  
#### fMRI study 
  
The EAT was part of the testing protocol of the English and Romanian Adoptees&#x27; Brain Imaging Study (for further details, see  ). Participants gave written informed consent to participate in the study. All participants completed the MINI and WASI-II, and an online survey, which included the IRI. Participants received pre-training on the fMRI tasks prior to the scan, during which they were familiarised with the EAT and the scanning environment. After observing the experimenter demonstrating how to rate one happy clip, participants rated two clips (one sad, one happy) themselves, while lying in a mock scanner. In the actual EAT experiment, participants watched and rated the 6 video clips in a fixed order ( ). The task took approximately 12 min. Participants were reimbursed for around 6 h of their time with a £100 Amazon voucher. 


#### Normative data collection 
  
For the non-scanning study, participants gave written consent to participate. For pre-training, participants first watched the experimenter rate one happy clip before rating two practice video clips themselves. They then watched and rated 27 video clips in randomised presentation order, in a quiet testing room. This lasted approximately 40 min. Participants also completed an online survey, which included the IRI. Participants were reimbursed for their time with a £15 Amazon voucher. 



### Behavioural data analysis 
  
Participants&#x27; and targets&#x27; ratings were analysed using Matlab 8.2.0 (The MathWorks Inc., Natick, Massachusetts, United States) and SPSS (Version 22, IBM Corp., Armonk, New York, United States). All ratings were separated into 2 s bins and one time-weighted average rating was calculated for each bin. We then tested for correlations between the participants&#x27; and targets&#x27; ratings ( , bottom). The resulting Pearson&#x27;s correlation coefficient for each video clip and each participant is referred to as the EA score. As expected, the variance of the ratings was low for neutral clips. EA scores were therefore only calculated for emotional video clips. EA scores were then r-to-Z transformed to allow comparison between correlation coefficients ( ,  ). 

#### Behavioural analysis of fMRI sample 
  
Paired t-tests examined whether Z-transformed EA scores, affective and cognitive empathy scores differed between happy and sad video clips. Moreover, paired t-tests were performed to test for differences in the average ratings of the target&#x27;s emotional intensity between emotional and neutral as well as happy and sad video clips. A paired   t  -test was also used to test whether Z-EA scores differed between video clips that elicited “affect sharing” (participants reported feeling the same emotion as the target) compared to those that did not (participants reported a different emotion or no emotion). In addition, Pearson correlations were conducted to test for relationships between mean Z-EA scores, the IRI subscales and IQ. 


#### Behavioural analysis of normative data sample 
  
To examine whether the video clips presented in the fMRI study induced Z-EA scores comparable to those in the non-scanning sessions, two Pearson correlations were performed within the normative data sample. Considering happy and sad video clips separately, we examined the correlation between Z-EA scores based on the two video clips presented in the scanner and Z-EA scores based on all seven video clips from the respective emotional category. Moreover, intra-individual standard deviations were calculated based on (1) the four emotional video clips presented in the scanner and (2) all 20 emotional video clips. These were then compared with a paired   t  -test. 



### fMRI data acquisition 
  
Functional images were acquired on a General Electric MR750 3.0 T MR scanner with a 12-channel head coil. A T2*-weighted gradient echo, echo-planar imaging sequence was used, which covered 41 axial slices and recorded 347 vol acquired sequentially, descending (TR/TE 2000/30 ms, flip angle 75°, 64 × 64 matrix, 3 mm thick, field of view (FoV) = 247 mm). To facilitate fMRI data registration and normalisation, we also acquired a T1-weighted Magnetization Prepared Rapid Gradient Echo MPRAGE image (TR/TE 7312/3.02 ms, flip angle 11°, 256 × 256 matrix, 1.2 mm thick, 196 sagittal slices, FoV = 270 mm). 


### fMRI data analysis 
  
We used SPM12 for pre-processing and subject-level (first level) analyses (Wellcome Department of Cognitive Neurology, Institute for Neurology, London, UK). FSL was utilised for cerebrospinal fluid (CSF) regression and statistical nonparametric permutation inference at the group level (second level) with “randomise” ( ; FMRIB Analysis Research, Oxford Centre for Functional MRI of the Brain, Oxford, UK). 

#### Preprocessing 
  
After reorientation, the EPI files were first slice-time corrected (middle slice as reference). Images were then realigned to the first image and subsequently to the time series mean. The mean EPI image was co-registered to the T1-weighted image to allow for normalisation. The structural files were segmented and the resulting grey matter, white matter and CSF files were used to create a common group-specific template using group-wise DARTEL registration ( ). This template was then employed to normalise the functional EPI files to MNI space. This step simultaneously resampled volumes (1.5 mm isotropic) and applied spatial smoothing (Gaussian FWHM kernel of 8 mm). Finally, for each participant, the time course signal of a CSF mask (top 5% from DARTEL CSF component) was extracted in native space. 


#### Emotional vs neutral video clips 
  
At the first level of analysis, each participant&#x27;s pre-processed data were modelled as a block design using a general linear model framework. We included 3 separate regressors (happy, sad, neutral) encoding the predicted BOLD response associated with video presentation, formed by convolution of the canonical haemodynamic response function (HRF) with boxcars delimiting the video presentation. 

We identified regional estimates of BOLD response associated with watching and rating the video clips. Separate parameter estimates for mean response during the emotional (happy and sad) and neutral category compared to the implicit baseline were produced. At the group level, in a random-effects model, paired t-tests were performed to identify clusters that were differentially activated when watching emotional video clips compared to neutral clips. Moreover, happy and sad clips were compared using paired t-tests. 


#### Intra-individual variation in empathic accuracy 
  
In accordance with  , Z-EA scores for each participant and each video clip were added as parametric modulators at the first level of analysis. On the group level, one sample t-tests were performed, to test whether the BOLD response during emotional video clips was modulated by intra-individual variations in Z-EA scores. 


#### Correlation with emotional intensity ratings 
  
We examined how the BOLD time series correlated with the participant&#x27;s ratings of the target&#x27;s emotional intensity. Scans were split and a model was fitted to each emotional video clip in turn. The continuous ratings of the target&#x27;s emotional intensity for each 2 s bin as rated by the participant were entered as regressors of interest. At the group level, one-sample t-tests assessed whether the relationship between BOLD response and changes in the emotional intensity ratings was significantly observed in any brain region across the group. 


#### Exploratory analysis: impact of affect sharing 
  
To examine differences in BOLD response for video clips that induced affect sharing compared to those that did not, we conducted an exploratory post-hoc analysis. We included the 20 participants who showed affect sharing in response to some, but not all video clips in order to be able to create 3 separate conditions in the first level in a block design (shared, non-shared, neutral). For each participant, emotional videos that induced affect sharing (participants reported to have the same emotion as the target) were included in the shared condition, while emotional videos that did not elicit affect sharing (participants reported to have a different emotion than the target or no emotion) were modelled in the non-shared condition. Separate parameter estimates for mean response during affect shared, non-shared and neutral video clip presentation compared to the implicit baseline were calculated. At the group level, paired t-tests were performed to identify clusters that were differentially activated when watching video clips that induced affect sharing compared to non-shared clips. 


#### Movement, scanner drifts and multiple comparisons correction 
  
As well as the regressors described above, all analyses included seven movement parameters (six standard parameters as well as volume-to-volume movement) as nuisance regressors. For each volume-to-volume movement exceeding 1 mm, an additional regressor was included marking the location of that volume and those immediately adjacent (for a summary of volume-to-volume movement see  ). The CSF regressor was also included as a nuisance regressor. To control for task-related hand movement artefacts, button presses were included as condition of no interest. To investigate the effect of controlling for button presses, we additionally repeated all analyses without including this condition. Moreover, we compared button presses during emotional video clips with button presses during neutral video clips as separate conditions to ensure that activity relating to emotion processing was not partialled out. 

Data were high pass filtered with a threshold of 209 s, which corresponds to twice the length of the longest video clip, to control for scanner drifts. 

Results reported are based on Family-Wise Error (FWE) corrected threshold-free cluster enhancement (TFCE:   p   &lt; 0.05 ( )). For each significant cluster, the peak activations with a minimum inter-peak distance of 20 voxels are reported to account for the wide-spanning clusters found in our analyses. 




## Results 
  
### Behavioural data 
  
#### Behavioural analysis of the fMRI sample 
  
On average, participants had high EA scores (mean   r   = .75, mean intra-individual standard deviation (iSD) = .35, range = .13 to .97). Fisher&#x27;s Z-transformed (Z-)EA scores were slightly, but significantly, lower for sad video clips (mean Z-EA = 0.97, SD = 0.21) than happy ones (mean Z-EA = 1.16, SD = 0.19;   t   (33) = 5.17,   p   &lt; .001). As expected, participants&#x27; average ratings of the target&#x27;s emotional intensity were higher for emotional than for neutral video clips (mean emotional = 5.18, mean neutral = 1.75,   t   (33) = 15.29,   p   &lt; .001), with higher ratings for sad compared to happy ones (mean sad = 5.49, mean happy = 4.87,   t   (33) = 3.02,   p   &lt; .01). 

On average, participants correctly inferred the target&#x27;s emotion in 90.4% of clips (emotion identification, SD = 15.1%), with no difference between happy and sad clips (  t   (33) = −0.33,   p   = .74). They also reported experiencing the same emotion as the target for the majority of the emotional video clips (affect sharing, mean = 72.8%, SD = 28.5%), with a higher degree concordance for sad (mean = 79.4%, SD = 32.8%) compared to happy clips (mean = 66.2%, SD = 31.9%;   t   (33) = 2.5,   p   &lt; .05). 13 participants shared the target&#x27;s emotion in every emotional video clip while one participant did not show affect sharing in any of the clips. For the remaining 20 participants who showed a mix of affect sharing and non-sharing, Z-EA scores did not differ for videos that elicited affect sharing (mean Z-EA = 1.09, SD = .24) compared to those that did not (mean Z-EA = 1.06, SD = .33,   t   (19) = .36,   p   = .72). 

Additionally, we found a positive correlation between participants&#x27; mean Z-EA scores and IRI perspective-taking (  r   = .48,   p   &lt; .01). No significant correlations were found between mean Z-EA scores and the other IRI subscales or estimated IQ (all   ps   &gt; .09). 

Note that while we used Pearson&#x27;s product-moment correlation, alternative methods for assessing agreement are available such as the intraclass correlation coefficient. EA scores derived using this measure were highly correlated (r = 0.89) with Pearson&#x27;s correlations. We chose the latter for two reasons. First, we were able to confirm our findings after partialling out dependency over time of the ratings (data not shown) and second, we wished to maintain compatibility with previous studies using similar tasks that also based estimates of inter-rater agreement on Pearson&#x27;s correlations. 


#### Behavioural analysis of the normative data sample 
  
The analysis showed that the mean Z-EA scores for the video clips presented in the fMRI study were strongly positively correlated with Z-EA scores for the seven clips presented in the normative data study (happy:   r   = .82,   p   &lt; .001; sad:   r   = .77,   p   &lt; .001). Furthermore, the intra-individual standard deviation of the four emotional video clips presented in the scanner (mean iSD = .36) did not differ from the individual standard deviation across all 20 emotional video clips presented outside the scanner (mean iSD = .39,   t   (59) = −1.64,   p   = .11). 



### fMRI data 
  
#### Emotional vs. neutral video clips 
  
Group-level analysis revealed a higher BOLD response during emotional compared to neutral clips in a large cluster spanning multiple regions, with peak activations in bilateral occipital poles and inferior lateral occipital cortex ( a,  ). The cluster included bilateral posterior and anterior superior temporal cortex (STC), as well as bilateral temporal pole (TP), bilateral planum temporale and bilateral posterior temporoparietal junction (pTPJ). Higher activation was also seen in right inferior frontal gyrus (IFG; including pars triangularis and opercularis), with the cluster extending into right anterior insular cortex (AI) and right putamen. A second cluster showed higher activation in supplementary motor area (SMA). While participants were watching neutral compared to emotional video clips, activation was higher in left superior lateral occipital cortex, left posterior cingulate cortex (PCC) and left precuneus. Significant activation was similar, albeit more widespread, when not controlling for button presses (see  ). Moreover, when analysing the button press condition separately for emotional and neutral video clips, no brain regions showed significant differences between both button press conditions.   
 Neural substrates of changes in empathy.   a) Significant brain activations when viewing emotional video clips compared to neutral ones. b) Regions significantly positively (red) and negatively (blue) modulated by variations in empathic accuracy (Z-EA scores). c) top: Brain areas significantly positively correlated over time with the participants&#x27; ratings of the target&#x27;s emotional intensity. bottom: BOLD response (after first level regression) of significant clusters (blue) and participant&#x27;s ratings of the target&#x27;s emotional intensity (green) of one exemplary participant. Key: STC - superior temporal cortex, TP - temporal pole, TPJ - temporoparietal junction, IFG - inferior frontal gyrus, SMA - supplementary motor area, aMCC - anterior midcingulate cortex. 
  Fig. 2     
Significant clusters and their peak activations for the contrasts emotional &gt; neutral video clips and neutral &gt; emotional video clips (threshold-free cluster enhancement   p   &lt; 0.05). 
  Table 2   

To explore differences between the different emotion conditions, we also directly compared happy and sad video clips. Activation in the bilateral STC was higher during happy compared to sad clips, while the right paracingulate gyrus and right precuneus showed higher activation during sad video clips (see   and  ). 


#### Intra-individual variation in empathic accuracy 
  
Participants&#x27; intra-individual variations in Z-EA scores were positively related to activation in clusters spanning the bilateral STC, planum temporale, TP and pTPJ, left hippocampus and left amygdala. Activity in the bilateral inferior lateral occipital cortex and fusiform cortex was also positively related to Z-EA scores ( b,  ). Activation in the bilateral paracingulate gyrus and right frontal pole as well as the right middle frontal gyrus was significantly negatively modulated by Z-EA scores.   
Significant clusters and their peak activations for the modulation of BOLD-response by intra-individual variation of Z-EA scores (threshold-free cluster enhancement   p   &lt; 0.05). 
  Table 3   


#### Correlation with emotional intensity ratings 
  
While watching emotional video clips, participants&#x27; fluctuations in ratings of the targets&#x27; emotional intensity were positively correlated over time with changes in BOLD response in multiple brain regions ( c,  ). Associations were found in multiple clusters including bilateral posterior STC, bilateral TP, bilateral IFG (including pars triangularis and opercularis), bilateral SMA, bilateral middle and superior frontal cortices, right anterior midcingulate cortex (aMCC), right AI, bilateral amygdala, bilateral putamen as well as pTPJ and right temporal occipital and anterior temporal fusiform cortex. Emotional intensity ratings and BOLD-response were negatively correlated in the in the bilateral superior lateral occipital cortex, PCC, and precuneus.   shows a binarised overlay of significant clusters in the different analyses.   
Binarised overlay of activations related to a) emotional compared to neutral video clips, b) variation positively related to empathic accuracy and c) positive correlation with emotional intensity. 
  Fig. 3     
Significant clusters and their peak activations for the correlation between BOLD-response and the participants&#x27; ratings of the target&#x27;s emotional intensity (threshold-free cluster enhancement   p   &lt; 0.05). 
  Table 4   


#### Exploratory analysis: impact of affect sharing 
  
For emotional video clips, there were no significant differences in BOLD response between clips that elicited, versus those that did not elicit, affect sharing (i.e. participants reported experiencing the same emotion as the target after providing their continuous ratings). 




## Discussion 
  
We used a modified version of the EAT to study neural substrates of empathic accuracy and to gain a better understanding of its underlying components. We demonstrated that fluctuations in participants&#x27; perceived emotional intensity ratings are correlated with activation in a network of brain regions previously implicated in empathy and broader aspects of social cognition (i.e., mentalising). More specifically, consistent with our first hypothesis, we observed increased activation in brain regions associated with empathy and mentalising when participants watched emotional compared to neutral clips. Supporting our second hypothesis, we found a positive correlation between intra-individual variations in empathic accuracy and the temporal lobe, “mentalising” regions of the same network. Confirming our third hypothesis, we found a correlation between fluctuations in ratings of the targets&#x27; perceived emotional intensity over time and activity in these same regions. This network of brain regions appears not only to have a general role in emotion and empathic processing but is also sensitive to   variations   in the intensity of others&#x27; emotions. 

The superior temporal sulcus (STS), temporoparietal junction (TPJ), and temporal pole (TP) have consistently been associated with mentalising ( ). In our study, these areas were more active with higher EA, i.e. when participants were more accurate at tracking the target&#x27;s emotion. Beyond this, we could also show these regions are sensitive to fluctuations in perceived emotional intensity of others. The STS is thought to facilitate mentalising by interpreting social aspects of observed biological motion ( ,  ) and the region has been implicated in EA ( ,  ). The TPJ is involved in inferring other people&#x27;s temporary mental states ( ) while the TP&#x27;s role in mentalising is thought to involve the integration of multimodal information and recollection of social scripts ( ;  ). Combined, these brain regions are involved in distinct emotional and cognitive processes that are required to perform our modified EAT: they are integral for the successful tracking of others&#x27; emotional intensity and correlate positively with intra-individual variations in EA. 

The anterior insula (AI), anterior midcingulate cortex (aMCC), inferior frontal gyrus (IFG) and supplementary motor area (SMA) have previously been implicated in empathy tasks and are associated with the affect sharing component of empathy (or affective empathy) ( ). Together these regions are implicated in the emotional processing of the modified EAT stimuli. Most importantly, we could show for the first time that their activity tracks the perceived emotional intensity of others. However, activity in these brain regions was not sensitive to changes in EA and thus seems more tied to the subjective perception of other&#x27;s feelings. 

This suggests it is the time-series variation in activation in the temporal lobe regions (STS, TPJ, TP) that might be informative for accurately tracking other people&#x27;s emotions, while activation in the frontal regions (AI, ACC, IFG, SMA) represents a different emotion processing component that does not vary with changes in EA ( ). This is consistent with previous studies on EA, which showed either no correlation between EA and activity in the above frontal regions ( ) or, in the case of adolescents, a negative correlation between EA and ACC and AI activation ( ). Furthermore, we could not replicate an association between EA and activity in the inferior parietal lobe, a region implicated in motor imitation and previously interpreted as an affective processing component of EA ( ). Taken together, these findings provide evidence that EA is more closely related to the concept of cognitive empathy and mentalising than affective empathy and emotion sharing. The role of EA in cognitive but not affective empathy is further supported by the positive correlation between EA scores and the perspective-taking scale of a well-established self-report measure of empathy (the IRI) but not with other more affective subscales such as empathic concern. Moreover, participants&#x27; average EA scores did not differ between videos where they shared the same emotion as the target compared to those were they did not, which again suggests that emotion sharing is neither necessary for, nor facilitates, EA. 

Even if EA does only relate to cognitive but not affective empathy, the EAT as a task successfully elicited affective empathy in most of our participants – they reported sharing the target&#x27;s emotion in 73% of the emotional video clips. However, there were no significant differences in brain activity when rating videos where participants shared the same emotion compared to videos where they did not. This further supports our hypothesis that the higher activation in aMCC, AI, SMA and IFG during emotional clips is associated with more basal, empathy-independent aspects of emotion processing. 

Higher activation of the bilateral STS could also be seen during happy compared to sad video clips, while the right paracingulate gyrus was more highly activated during sad video clips. This is in line with our behavioural findings of, on average, higher EA scores during happy video clips, which suggest more successful tracking and mentalising of the target&#x27;s emotion, while sad video clips induced higher rates of affect sharing among participants. The paracingulate gyrus has previously been implicated in affective empathy ( ). 

During the modified EAT, participants rated fluctuations in emotional intensity rather than valence as this allowed a comparable rating scale across different distinct emotions. Furthermore, previous literature suggests distinct neural correlates for processing emotional intensity and valence ( ), with the amygdala being associated with intensity and the orbitofrontal cortex with valence. In agreement with this, we found that bilateral activation of amygdala but not the orbitofrontal cortex covaried with the emotional intensity of the targets. Unexpectedly activation in the precuneus – a region implicated in self-referential processing ( ) – was stronger during neutral versus emotional clips and correlated negatively with emotional intensity ratings. The precuneus is associated with visual-spatial imagery ( ,  ) and is a component of the default mode network ( ). Higher activation during the neutral videos in which participants described their bedroom, might be explained by higher visual-spatial imagery and an increased tendency for mind-wandering during these less engaging parts of the task ( ). 

Empathy is a complex and dynamic process, which requires multiple higher order functions ( ) such as emotion recognition, multimodal sensory integration, self-other distinction and continuous processing of valence and intensity information. Compared to other commonly used empathy tasks, the modified EAT used a more naturalistic setting to examine which brain regions track fluctuations over time in perceived emotional intensity of others and intra-individual variations in empathic accuracy. Previous studies in the empathy and mentalising literature have largely focused on simplistic stimuli (e.g. static images of hands in painful situations). Compared to these earlier studies, we found that regions that have been separately implicated in mentalising and empathy were all involved in performing the modified EAT. However, only brain regions previously associated with mentalising were found to covary with EA, while regions previously implicated in classic affective empathy paradigms were positively correlated with the emotional intensity of others but were not sensitive to changes in EA. In this more naturalistic and complex task, it seems that an interplay between brain networks associated with mentalising and empathy enables the accurate tracking of other&#x27;s emotions. Furthermore, these regions were sensitive to fluctuations in perceived emotional intensity of others, which serves as a potential mechanism for successful communication between these networks to achieve empathic accuracy. 

A possible limitation of our study was the lower number of emotional video clips in comparison to previous studies on EA ( ,  ). This study was conducted within the framework of a larger project, and thus the scanning time was limited. However, we showed that our chosen video clips led to very similar EA scores relative to those obtained with the larger dataset of 27 video clips in the norm sample. More importantly, the intra-individual variation across videos was also comparable to that seen for the full set of video clips. 

The study had a number of strengths. The original EAT ( ) represented an important advance in empathy research, as it was the first task to utilise naturalistic stimuli and assess EA in an fMRI context. In this modified EAT, the stimuli used for fMRI purposes had been validated in a separate behavioural study. Moreover, we added a neutral control condition, which allowed us to identify brain regions that are generally more active during emotional video clips irrespective of empathic accuracy. Future studies could employ this paradigm to study psychiatric populations with empathy deficits (e.g., adolescents with Conduct Disorder;  ). By additionally taking the neutral control condition into account, one could examine whether emotional clips were ‘neutral-like’ in those with low EA scores. For future studies, it would be worth considering incorporating neutral videos with varying topics other than bedroom descriptions to ensure continued engagement throughout the task (see   for possible examples). Furthermore, we introduced the measurement of emotional intensity rather than valence, which is more closely related to the concept of empathy. This also made the video clips of different emotions comparable and allowed a more fine-grained analysis of changes over time in activation related to the emotional intensity of others. Together, we propose that the three analysis techniques used in this study, should be employed in conjunction to allow a comprehensive study of empathic accuracy and its different components. 

In conclusion, we provide the first evidence that the modified EAT is a suitable paradigm for studying empathy and its underlying components. We show that, while the modified EAT successfully induces both affective and cognitive empathy, EA relies more on cognitive empathy than affect sharing. The neutral control condition and the valence-independent rating scale represent valuable additions to the task. The fMRI data analysis techniques developed and described here may prove valuable in characterising differences between healthy participants and participants with psychiatric conditions associated with empathy deficits. 


## Funding 
  
This work was funded by a project grant from the   to ESB, MM and GF (MR/K022474/1). 


## Declaration of interest 
  
We do not have any financial, institutional or other relationships that might lead to a conflict of interest.</pre></details></details>
  <details class="inner-accordion"><summary>Coordinate-relevant source tables (3)</summary><details class="inner-accordion"><summary>Table 2 (tbl2) - Significant clusters and their peak activations for the contrasts emotional &gt; neutral video clips and neutral &gt; emotional video clips (threshold-free cluster enhancement pFWE &lt; 0.05).</summary><div class="table-html"><table-wrap id="tbl2" position="float" orientation="portrait"><label>Table 2</label><caption><p>Significant clusters and their peak activations for the contrasts emotional &gt; neutral video clips and neutral &gt; emotional video clips (threshold-free cluster enhancement <italic toggle="yes">p</italic><sub>FWE</sub> &lt; 0.05).</p></caption><alt-text id="alttext0035">Table 2</alt-text><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" colspan="1">Cluster</th><th rowspan="2" colspan="1">Anatomical region</th><th rowspan="2" colspan="1">Hemisphere</th><th rowspan="2" colspan="1">Cluster size</th><th colspan="3" rowspan="1">MNI coordinates [mm]<hr /></th><th rowspan="2" colspan="1">Peak-level <italic toggle="yes">t</italic></th></tr><tr><th colspan="1" rowspan="1">x</th><th colspan="1" rowspan="1">y</th><th colspan="1" rowspan="1">z</th></tr></thead><tbody><tr><td colspan="8" align="left" rowspan="1"><bold>emotional &gt; neutral video clips</bold><hr /></td></tr><tr><td rowspan="11" align="left" colspan="1">1</td><td align="left" colspan="1" rowspan="1">Occipital Pole</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">9901</td><td align="left" colspan="1" rowspan="1">20</td><td align="left" colspan="1" rowspan="1">−94</td><td align="left" colspan="1" rowspan="1">−2</td><td align="left" colspan="1" rowspan="1">7.33</td></tr><tr><td align="left" colspan="1" rowspan="1">Inferior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−32</td><td align="left" colspan="1" rowspan="1">−90</td><td align="left" colspan="1" rowspan="1">−6</td><td align="left" colspan="1" rowspan="1">6.86</td></tr><tr><td align="left" colspan="1" rowspan="1">Anterior Superior Temporal Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">52</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">−18</td><td align="left" colspan="1" rowspan="1">6.21</td></tr><tr><td align="left" colspan="1" rowspan="1">Occipital Pole</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−16</td><td align="left" colspan="1" rowspan="1">−94</td><td align="left" colspan="1" rowspan="1">12</td><td align="left" colspan="1" rowspan="1">5.94</td></tr><tr><td align="left" colspan="1" rowspan="1">Inferior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">40</td><td align="left" colspan="1" rowspan="1">−70</td><td align="left" colspan="1" rowspan="1">−4</td><td align="left" colspan="1" rowspan="1">5.1</td></tr><tr><td align="left" colspan="1" rowspan="1">Posterior Superior Temporal Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">56</td><td align="left" colspan="1" rowspan="1">−28</td><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">4.57</td></tr><tr><td align="left" colspan="1" rowspan="1">Insular Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">28</td><td align="left" colspan="1" rowspan="1">16</td><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">4.39</td></tr><tr><td align="left" colspan="1" rowspan="1">Temporal Occipital Fusiform Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">40</td><td align="left" colspan="1" rowspan="1">−50</td><td align="left" colspan="1" rowspan="1">−16</td><td align="left" colspan="1" rowspan="1">4.15</td></tr><tr><td align="left" colspan="1" rowspan="1">Frontal Operculum Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">48</td><td align="left" colspan="1" rowspan="1">16</td><td align="left" colspan="1" rowspan="1">0</td><td align="left" colspan="1" rowspan="1">4.02</td></tr><tr><td align="left" colspan="1" rowspan="1">Occipital Fusiform Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−36</td><td align="left" colspan="1" rowspan="1">−70</td><td align="left" colspan="1" rowspan="1">−16</td><td align="left" colspan="1" rowspan="1">4.01</td></tr><tr><td align="left" colspan="1" rowspan="1">Occipital Pole</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−10</td><td align="left" colspan="1" rowspan="1">−100</td><td align="left" colspan="1" rowspan="1">−14</td><td align="left" colspan="1" rowspan="1">3.44</td></tr><tr><td rowspan="4" align="left" colspan="1">2</td><td align="left" colspan="1" rowspan="1">Anterior Superior Temporal Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">2243</td><td align="left" colspan="1" rowspan="1">−52</td><td align="left" colspan="1" rowspan="1">−6</td><td align="left" colspan="1" rowspan="1">−14</td><td align="left" colspan="1" rowspan="1">5.32</td></tr><tr><td align="left" colspan="1" rowspan="1">Posterior Supramarginal Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−56</td><td align="left" colspan="1" rowspan="1">−44</td><td align="left" colspan="1" rowspan="1">14</td><td align="left" colspan="1" rowspan="1">4.45</td></tr><tr><td align="left" colspan="1" rowspan="1">Middle Temporal Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−44</td><td align="left" colspan="1" rowspan="1">−32</td><td align="left" colspan="1" rowspan="1">−2</td><td align="left" colspan="1" rowspan="1">3.85</td></tr><tr><td align="left" colspan="1" rowspan="1">Planum Temporale</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−60</td><td align="left" colspan="1" rowspan="1">−20</td><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">3.48</td></tr><tr><td align="left" colspan="1" rowspan="1">3</td><td align="left" colspan="1" rowspan="1">Supplementary Motor Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">250</td><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">60</td><td align="left" colspan="1" rowspan="1">5.04</td></tr><tr><td align="left" colspan="1" rowspan="1">4<hr /></td><td align="left" colspan="1" rowspan="1">Temporal Pole<hr /></td><td align="left" colspan="1" rowspan="1">L<hr /></td><td align="left" colspan="1" rowspan="1">6<hr /></td><td align="left" colspan="1" rowspan="1">−46<hr /></td><td align="left" colspan="1" rowspan="1">18<hr /></td><td align="left" colspan="1" rowspan="1">−26<hr /></td><td align="left" colspan="1" rowspan="1">3.53<hr /></td></tr><tr><td colspan="8" align="left" rowspan="1"><bold>neutral &gt; emotional video clips</bold><hr /></td></tr><tr><td align="left" colspan="1" rowspan="1">1</td><td align="left" colspan="1" rowspan="1">Superior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">1014</td><td align="left" colspan="1" rowspan="1">−34</td><td align="left" colspan="1" rowspan="1">−80</td><td align="left" colspan="1" rowspan="1">40</td><td align="left" colspan="1" rowspan="1">6.59</td></tr><tr><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">Superior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−44</td><td align="left" colspan="1" rowspan="1">−84</td><td align="left" colspan="1" rowspan="1">22</td><td align="left" colspan="1" rowspan="1">5.86</td></tr><tr><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">Posterior Cingulate Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">207</td><td align="left" colspan="1" rowspan="1">−4</td><td align="left" colspan="1" rowspan="1">−38</td><td align="left" colspan="1" rowspan="1">40</td><td align="left" colspan="1" rowspan="1">8.99</td></tr><tr><td align="left" colspan="1" rowspan="1">3</td><td align="left" colspan="1" rowspan="1">Precuneus Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">86</td><td align="left" colspan="1" rowspan="1">−14</td><td align="left" colspan="1" rowspan="1">−60</td><td align="left" colspan="1" rowspan="1">14</td><td align="left" colspan="1" rowspan="1">6.2</td></tr><tr><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">Superior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">54</td><td align="left" colspan="1" rowspan="1">36</td><td align="left" colspan="1" rowspan="1">−76</td><td align="left" colspan="1" rowspan="1">42</td><td align="left" colspan="1" rowspan="1">5.32</td></tr><tr><td align="left" colspan="1" rowspan="1">5</td><td align="left" colspan="1" rowspan="1">Lingual Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">34</td><td align="left" colspan="1" rowspan="1">−38</td><td align="left" colspan="1" rowspan="1">−10</td><td align="left" colspan="1" rowspan="1">5.49</td></tr><tr><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">Planum Temporale</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">30</td><td align="left" colspan="1" rowspan="1">−30</td><td align="left" colspan="1" rowspan="1">−20</td><td align="left" colspan="1" rowspan="1">5.46</td></tr></tbody></table></table-wrap></div></details><details class="inner-accordion"><summary>Table 3 (tbl3) - Significant clusters and their peak activations for the modulation of BOLD-response by intra-individual variation of Z-EA scores (threshold-free cluster enhancement pFWE &lt; 0.05).</summary><div class="table-html"><table-wrap id="tbl3" position="float" orientation="portrait"><label>Table 3</label><caption><p>Significant clusters and their peak activations for the modulation of BOLD-response by intra-individual variation of Z-EA scores (threshold-free cluster enhancement <italic toggle="yes">p</italic><sub>FWE</sub> &lt; 0.05).</p></caption><alt-text id="alttext0040">Table 3</alt-text><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" colspan="1">Cluster</th><th rowspan="2" colspan="1">Anatomical region</th><th rowspan="2" colspan="1">Hemisphere</th><th rowspan="2" colspan="1">Cluster size</th><th colspan="3" rowspan="1">MNI coordinates [mm]<hr /></th><th rowspan="2" colspan="1">Peak-level <italic toggle="yes">t</italic></th></tr><tr><th colspan="1" rowspan="1">x</th><th colspan="1" rowspan="1">y</th><th colspan="1" rowspan="1">z</th></tr></thead><tbody><tr><td colspan="8" align="left" rowspan="1"><bold>Positively related to Z-EA scores</bold><hr /></td></tr><tr><td rowspan="7" align="left" colspan="1">1</td><td align="left" colspan="1" rowspan="1">Posterior Superior Temporal Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">9036</td><td align="left" colspan="1" rowspan="1">−62</td><td align="left" colspan="1" rowspan="1">−26</td><td align="left" colspan="1" rowspan="1">10</td><td align="left" colspan="1" rowspan="1">9.88</td></tr><tr><td align="left" colspan="1" rowspan="1">Planum Temporale</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−38</td><td align="left" colspan="1" rowspan="1">−34</td><td align="left" colspan="1" rowspan="1">14</td><td align="left" colspan="1" rowspan="1">9.17</td></tr><tr><td align="left" colspan="1" rowspan="1">Temporal Pole</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−54</td><td align="left" colspan="1" rowspan="1">−2</td><td align="left" colspan="1" rowspan="1">−2</td><td align="left" colspan="1" rowspan="1">7.02</td></tr><tr><td align="left" colspan="1" rowspan="1">Hippocampus</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−20</td><td align="left" colspan="1" rowspan="1">−14</td><td align="left" colspan="1" rowspan="1">−20</td><td align="left" colspan="1" rowspan="1">6.50</td></tr><tr><td align="left" colspan="1" rowspan="1">Inferior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−44</td><td align="left" colspan="1" rowspan="1">−72</td><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">6.03</td></tr><tr><td align="left" colspan="1" rowspan="1">Posterior Temporal Fusiform Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−38</td><td align="left" colspan="1" rowspan="1">−42</td><td align="left" colspan="1" rowspan="1">−26</td><td align="left" colspan="1" rowspan="1">4.67</td></tr><tr><td align="left" colspan="1" rowspan="1">Occipital Fusiform Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−20</td><td align="left" colspan="1" rowspan="1">−90</td><td align="left" colspan="1" rowspan="1">−18</td><td align="left" colspan="1" rowspan="1">4.61</td></tr><tr><td rowspan="2" align="left" colspan="1">2</td><td align="left" colspan="1" rowspan="1">Planum Temporale</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">2421</td><td align="left" colspan="1" rowspan="1">64</td><td align="left" colspan="1" rowspan="1">−16</td><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">7.37</td></tr><tr><td align="left" colspan="1" rowspan="1">Planum Temporale</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">34</td><td align="left" colspan="1" rowspan="1">−28</td><td align="left" colspan="1" rowspan="1">14</td><td align="left" colspan="1" rowspan="1">4.93</td></tr><tr><td rowspan="2" align="left" colspan="1">3<hr /></td><td align="left" colspan="1" rowspan="1">Inferior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">2315</td><td align="left" colspan="1" rowspan="1">46</td><td align="left" colspan="1" rowspan="1">−66</td><td align="left" colspan="1" rowspan="1">0</td><td align="left" colspan="1" rowspan="1">7.80</td></tr><tr><td align="left" colspan="1" rowspan="1">Occipital Fusiform Cortex<hr /></td><td align="left" colspan="1" rowspan="1">R<hr /></td><td colspan="1" rowspan="1"><hr /></td><td align="left" colspan="1" rowspan="1">22<hr /></td><td align="left" colspan="1" rowspan="1">−88<hr /></td><td align="left" colspan="1" rowspan="1">−8<hr /></td><td align="left" colspan="1" rowspan="1">5.37<hr /></td></tr><tr><td colspan="8" align="left" rowspan="1"><bold>Negatively related to Z-EA scores</bold><hr /></td></tr><tr><td rowspan="3" align="left" colspan="1">1</td><td align="left" colspan="1" rowspan="1">Paracingulate Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">275</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">22</td><td align="left" colspan="1" rowspan="1">48</td><td align="left" colspan="1" rowspan="1">4.11</td></tr><tr><td align="left" colspan="1" rowspan="1">Frontal Pole</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">10</td><td align="left" colspan="1" rowspan="1">62</td><td align="left" colspan="1" rowspan="1">36</td><td align="left" colspan="1" rowspan="1">4.01</td></tr><tr><td align="left" colspan="1" rowspan="1">Paracingulate Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−6</td><td align="left" colspan="1" rowspan="1">44</td><td align="left" colspan="1" rowspan="1">30</td><td align="left" colspan="1" rowspan="1">3.81</td></tr><tr><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">Middle Frontal Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">31</td><td align="left" colspan="1" rowspan="1">36</td><td align="left" colspan="1" rowspan="1">14</td><td align="left" colspan="1" rowspan="1">32</td><td align="left" colspan="1" rowspan="1">4.42</td></tr></tbody></table></table-wrap></div></details><details class="inner-accordion"><summary>Table 4 (tbl4) - Significant clusters and their peak activations for the correlation between BOLD-response and the participants&#x27; ratings of the target&#x27;s emotional intensity (threshold-free cluster enhancement pFWE &lt; 0.05).</summary><div class="table-html"><table-wrap id="tbl4" position="float" orientation="portrait"><label>Table 4</label><caption><p>Significant clusters and their peak activations for the correlation between BOLD-response and the participants' ratings of the target's emotional intensity (threshold-free cluster enhancement <italic toggle="yes">p</italic><sub>FWE</sub> &lt; 0.05).</p></caption><alt-text id="alttext0045">Table 4</alt-text><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" colspan="1">Cluster</th><th rowspan="2" colspan="1">Anatomical region</th><th rowspan="2" colspan="1">Hemisphere</th><th rowspan="2" colspan="1">Cluster size</th><th colspan="3" rowspan="1">MNI coordinates [mm]<hr /></th><th rowspan="2" colspan="1">Peak-level <italic toggle="yes">t</italic></th></tr><tr><th colspan="1" rowspan="1">x</th><th colspan="1" rowspan="1">y</th><th colspan="1" rowspan="1">z</th></tr></thead><tbody><tr><td colspan="8" align="left" rowspan="1"><bold>Positive correlation with participants' emotional intensity ratings</bold><hr /></td></tr><tr><td rowspan="17" align="left" colspan="1">1</td><td align="left" colspan="1" rowspan="1">Posterior Superior Temporal Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">24492</td><td align="left" colspan="1" rowspan="1">58</td><td align="left" colspan="1" rowspan="1">−16</td><td align="left" colspan="1" rowspan="1">0</td><td align="left" colspan="1" rowspan="1">9.56</td></tr><tr><td align="left" colspan="1" rowspan="1">Posterior Middle Frontal Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">62</td><td align="left" colspan="1" rowspan="1">−36</td><td align="left" colspan="1" rowspan="1">0</td><td align="left" colspan="1" rowspan="1">8.26</td></tr><tr><td align="left" colspan="1" rowspan="1">Temporal Pole</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">58</td><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">−16</td><td align="left" colspan="1" rowspan="1">8.19</td></tr><tr><td align="left" colspan="1" rowspan="1">Planum Temporale</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−64</td><td align="left" colspan="1" rowspan="1">−14</td><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">8.05</td></tr><tr><td align="left" colspan="1" rowspan="1">Putamen</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">26</td><td align="left" colspan="1" rowspan="1">−92</td><td align="left" colspan="1" rowspan="1">−6</td><td align="left" colspan="1" rowspan="1">7.4</td></tr><tr><td align="left" colspan="1" rowspan="1">Temporal Pole</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−56</td><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">−10</td><td align="left" colspan="1" rowspan="1">7.04</td></tr><tr><td align="left" colspan="1" rowspan="1">Middle Frontal Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">48</td><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">38</td><td align="left" colspan="1" rowspan="1">6.92</td></tr><tr><td align="left" colspan="1" rowspan="1">Middle Temporal Gyrus, temporooccipital part</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">46</td><td align="left" colspan="1" rowspan="1">−56</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">6.49</td></tr><tr><td align="left" colspan="1" rowspan="1">Temporal Occipital Fusiform Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">40</td><td align="left" colspan="1" rowspan="1">−46</td><td align="left" colspan="1" rowspan="1">−16</td><td align="left" colspan="1" rowspan="1">6.06</td></tr><tr><td align="left" colspan="1" rowspan="1">Temporal Occipital Fusiform Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−46</td><td align="left" colspan="1" rowspan="1">−64</td><td align="left" colspan="1" rowspan="1">−28</td><td align="left" colspan="1" rowspan="1">5.7</td></tr><tr><td align="left" colspan="1" rowspan="1">Insular Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">38</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">−20</td><td align="left" colspan="1" rowspan="1">5.49</td></tr><tr><td align="left" colspan="1" rowspan="1">Middle Temporal Gyrus, temporooccipital part</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−64</td><td align="left" colspan="1" rowspan="1">−44</td><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">5.31</td></tr><tr><td align="left" colspan="1" rowspan="1">Inferior Frontal Gyrus, pars triangularis</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">56</td><td align="left" colspan="1" rowspan="1">28</td><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">5.04</td></tr><tr><td align="left" colspan="1" rowspan="1">Temporal Pole</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−44</td><td align="left" colspan="1" rowspan="1">20</td><td align="left" colspan="1" rowspan="1">−26</td><td align="left" colspan="1" rowspan="1">4.93</td></tr><tr><td align="left" colspan="1" rowspan="1">Occipital Fusiform Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−30</td><td align="left" colspan="1" rowspan="1">−82</td><td align="left" colspan="1" rowspan="1">−18</td><td align="left" colspan="1" rowspan="1">4.87</td></tr><tr><td align="left" colspan="1" rowspan="1">Planum Temporale</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−40</td><td align="left" colspan="1" rowspan="1">−36</td><td align="left" colspan="1" rowspan="1">10</td><td align="left" colspan="1" rowspan="1">4.84</td></tr><tr><td align="left" colspan="1" rowspan="1">Amygdala</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−18</td><td align="left" colspan="1" rowspan="1">−6</td><td align="left" colspan="1" rowspan="1">−14</td><td align="left" colspan="1" rowspan="1">4.78</td></tr><tr><td rowspan="2" align="left" colspan="1">2</td><td align="left" colspan="1" rowspan="1">Supplementary Motor Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">1735</td><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">66</td><td align="left" colspan="1" rowspan="1">6.85</td></tr><tr><td align="left" colspan="1" rowspan="1">Anterior Midcingulate Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">14</td><td align="left" colspan="1" rowspan="1">38</td><td align="left" colspan="1" rowspan="1">3.74</td></tr><tr><td rowspan="2" align="left" colspan="1">3</td><td align="left" colspan="1" rowspan="1">Precentral Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">1714</td><td align="left" colspan="1" rowspan="1">−40</td><td align="left" colspan="1" rowspan="1">−8</td><td align="left" colspan="1" rowspan="1">56</td><td align="left" colspan="1" rowspan="1">5.64</td></tr><tr><td align="left" colspan="1" rowspan="1">Superior Frontal Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−24</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">72</td><td align="left" colspan="1" rowspan="1">4.96</td></tr><tr><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">Postcentral Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">206</td><td align="left" colspan="1" rowspan="1">−48</td><td align="left" colspan="1" rowspan="1">−26</td><td align="left" colspan="1" rowspan="1">40</td><td align="left" colspan="1" rowspan="1">4.05</td></tr><tr><td align="left" colspan="1" rowspan="1">5<hr /></td><td align="left" colspan="1" rowspan="1">Putamen<hr /></td><td align="left" colspan="1" rowspan="1">R<hr /></td><td align="left" colspan="1" rowspan="1">173<hr /></td><td align="left" colspan="1" rowspan="1">18<hr /></td><td align="left" colspan="1" rowspan="1">10<hr /></td><td align="left" colspan="1" rowspan="1">6<hr /></td><td align="left" colspan="1" rowspan="1">4.67<hr /></td></tr><tr><td colspan="8" align="left" rowspan="1"><bold>Negative correlation with participants' emotional intensity ratings</bold><hr /></td></tr><tr><td rowspan="7" align="left" colspan="1">1</td><td align="left" colspan="1" rowspan="1">Cuneus Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">10193</td><td align="left" colspan="1" rowspan="1">10</td><td align="left" colspan="1" rowspan="1">−86</td><td align="left" colspan="1" rowspan="1">24</td><td align="left" colspan="1" rowspan="1">6.42</td></tr><tr><td align="left" colspan="1" rowspan="1">Posterior Cingulate Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">−34</td><td align="left" colspan="1" rowspan="1">38</td><td align="left" colspan="1" rowspan="1">5.48</td></tr><tr><td align="left" colspan="1" rowspan="1">Precuneus Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−4</td><td align="left" colspan="1" rowspan="1">−66</td><td align="left" colspan="1" rowspan="1">16</td><td align="left" colspan="1" rowspan="1">5.3</td></tr><tr><td align="left" colspan="1" rowspan="1">Superior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">38</td><td align="left" colspan="1" rowspan="1">−74</td><td align="left" colspan="1" rowspan="1">22</td><td align="left" colspan="1" rowspan="1">5.25</td></tr><tr><td align="left" colspan="1" rowspan="1">Precuneus Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−12</td><td align="left" colspan="1" rowspan="1">−58</td><td align="left" colspan="1" rowspan="1">34</td><td align="left" colspan="1" rowspan="1">4.82</td></tr><tr><td align="left" colspan="1" rowspan="1">Lingual Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">26</td><td align="left" colspan="1" rowspan="1">−52</td><td align="left" colspan="1" rowspan="1">−4</td><td align="left" colspan="1" rowspan="1">4.66</td></tr><tr><td align="left" colspan="1" rowspan="1">Superior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">44</td><td align="left" colspan="1" rowspan="1">−64</td><td align="left" colspan="1" rowspan="1">46</td><td align="left" colspan="1" rowspan="1">3.99</td></tr><tr><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">Superior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">466</td><td align="left" colspan="1" rowspan="1">−38</td><td align="left" colspan="1" rowspan="1">−70</td><td align="left" colspan="1" rowspan="1">32</td><td align="left" colspan="1" rowspan="1">4.69</td></tr><tr><td align="left" colspan="1" rowspan="1">3</td><td align="left" colspan="1" rowspan="1">Temporal Occipital Fusiform Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">121</td><td align="left" colspan="1" rowspan="1">−24</td><td align="left" colspan="1" rowspan="1">−56</td><td align="left" colspan="1" rowspan="1">−12</td><td align="left" colspan="1" rowspan="1">3.23</td></tr><tr><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">Superior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">32</td><td align="left" colspan="1" rowspan="1">−50</td><td align="left" colspan="1" rowspan="1">−74</td><td align="left" colspan="1" rowspan="1">26</td><td align="left" colspan="1" rowspan="1">3.77</td></tr></tbody></table></table-wrap></div></details></details>
</details>


<details class="doc-card">
  <summary><strong>PMID 30349467</strong> | Pred included: 8 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=1, unmatched=3</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/30349467/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Activations: Leading &gt; Following (Followers only); others, Activations: Leading &gt; Following (Whole-group); others, Deactivations: Following &gt; Leading (Whole-group); others</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>30349467_analysis_0</td><td>Leaders only (n = 11)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Leaders-only analysis involves a two-person joint-action task (leading vs following) which is inherently social—participants interact, interpret partner cues, and coordinate actions. This meets the Social Processing definition and inclusion I1.</td></tr>
<tr><td>30349467_analysis_1</td><td>Followers only (n = 10)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Followers-only analysis also uses the two-person joint-action task; following requires interpreting partner cues and coordinating behavior, satisfying Social Processing I1.</td></tr>
<tr><td>30349467_analysis_2</td><td>Whole-group (n = 18)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Whole-group Leading vs Following contrast examines interactive joint action and role-based social behavior; this is squarely within Social Processing I1.</td></tr>
<tr><td>30349467_analysis_3</td><td>Leaders only (n = 11)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Leaders-only (repeat of subgroup contrast) examines the social joint-action role of leading; it involves interacting with a partner and social coordination, meeting Social Processing I1.</td></tr>
<tr><td>30349467_analysis_4</td><td>Followers only (n = 10)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Followers-only contrast probes interactive following behavior (interpreting partner cues), which is social processing by definition and meets Social Processing I1.</td></tr>
<tr><td>30349467_analysis_5</td><td>Activation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Whole-brain regression of Leading&gt;Following with leader skill examines how social interactive role expertise modulates social interaction-related activations—fits Social Processing I1.</td></tr>
<tr><td>30349467_analysis_6</td><td>Deactivation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Leader-skill deactivation analysis is part of the social joint-action regression set and still pertains to how role expertise modulates social interaction-related activation patterns, meeting Social Processing I1.</td></tr>
<tr><td>30349467_analysis_7</td><td>Leading versus following correlated with skill as a follower.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Regression of Leading&gt;Following with follower skill examines how expertise at following modulates social-interaction-related activations (mentalizing/action perception), satisfying Social Processing I1.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>30349467_1</td><td>Activations: Leading &gt; Following (Followers only); others</td><td>30349467_analysis_7</td><td>Leading versus following correlated with skill as a follower.</td><td>0.491</td><td>0.000</td><td>0.147</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>30349467_2</td><td>Activations: Leading &gt; Following (Leaders only); others</td><td>30349467_analysis_3</td><td>Leaders only (n = 11)</td><td>0.382</td><td>1.000</td><td>0.815</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>30349467_3</td><td>Activations: Leading &gt; Following (Whole-group); others</td><td>30349467_analysis_2</td><td>Whole-group (n = 18)</td><td>0.364</td><td>0.583</td><td>0.517</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>30349467_4</td><td>Deactivations: Following &gt; Leading (Followers only); others</td><td>30349467_analysis_4</td><td>Followers only (n = 10)</td><td>0.405</td><td>0.800</td><td>0.682</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>30349467_5</td><td>Deactivations: Following &gt; Leading (Whole-group); others</td><td>30349467_analysis_6</td><td>Deactivation</td><td>0.400</td><td>0.000</td><td>0.120</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>30349467_6</td><td>[Leading &gt; Rest] and [Following &gt; Rest] (followers only); others</td><td>30349467_analysis_1</td><td>Followers only (n = 10)</td><td>0.380</td><td>1.000</td><td>0.814</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>30349467_7</td><td>[Leading &gt; Rest] and [Following &gt; Rest] (leaders only); others</td><td>30349467_analysis_0</td><td>Leaders only (n = 11)</td><td>0.347</td><td>1.000</td><td>0.804</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  <details class="inner-accordion"><summary>PMC full text available (PMCID 6186800)</summary><p><strong>Title:</strong> Role-Specific Brain Activations in Leaders and Followers During Joint Action</p><details><summary>Abstract</summary><pre class="paper-text">Much of social interaction in human life requires that individuals perform different roles during joint actions, the most basic distinction being that between a leader and a follower. A number of neuroimaging studies have examined the brain networks for leading and following, but none have examined what effect prior expertise at these roles has on brain activations during joint motor tasks. Couple dancers (e.g., dancers of Tango, Salsa, and swing) are an ideal population in which examine such effects, since leaders and followers of partnered dances have similar overall levels of motor expertise at dancing, but can differ strikingly in their role-specific skill sets. To explore role-specific expertise effects on brain activations for the first time, we recruited nine skilled leaders and nine skilled followers of couple dances for a functional magnetic resonance imaging study. We employed a two-person scanning arrangement that allowed a more naturalistic interaction between two individuals. The dancers interacted physically with an experimenter standing next to the bore of the magnet so as to permit bimanual partnered movements. Together, they alternated between leading and following the joint movements. The results demonstrated that the brain activations during the acts of leading and following were enhanced by prior expertise at being a leader or follower, and that activity in task-specific brain areas tended to be positively correlated with the level of expertise at the corresponding role. These findings provide preliminary evidence that training at one role of a joint motor task can selectively enhance role-related brain activations.</pre></details><details><summary>Body</summary><pre class="paper-text">## Introduction 
  
Much joint action between two people involves the contrastive roles of leader and follower ( ). For example, when two people move a sofa, the front person is often the one who navigates the joint movement as well as the one who determines the speed at which the two people move, while the back person responds to these movement-cues and attempts to coordinate his/her actions with the front person. However, the experimental literature that examines joint action in the lab does not give consideration to individual differences, for example the fact that people may be predisposed toward being a leader or follower based on their personality traits or life experiences ( ). In typical studies of joint action, people are randomly assigned to being a leader or follower (or both) of a joint task without assessing individual differences in task expertise that may exist between them. This applies to studies of both experts ( ;  ) and non-experts ( ;  ;  ;  ). This may be problematic since many studies demonstrate that expertise has an effect on behavioral performance and brain activations across many domains ( ;  ;  ). 

An interesting solution to this problem is to examine couple dancers, such as Tango dancers, since such people engage in extensive training to develop expertise at one specific role in the dance, thereby making the assessment of leading/following experience on joint action quite feasible. Leaders and followers of a couple dance have similar overall levels of motor expertise at dancing, but they can differ strikingly in their role-specific skill sets, such that dancers of one role are often unable to dance the opposite role. This applies not merely to the movement patterns themselves, but to the   coordination   skills required for leading (e.g., force conveyance) and following (e.g., responsiveness to force cues). While previous neuroimaging studies have looked separately at the topics of leading/following and expertise, the current study–which is a follow-up analysis to a previously published study from our lab ( )–represents a first attempt at examining   role-specific expertise   at leading and following, doing so using trained leaders and followers of couple dances. The principal aim of the study is to identify role-specific brain activations, namely leading-related activations in trained leaders compared to non-leaders, and following-related activations in trained followers compared to non-followers. 

Previous studies of leading and following have tended to emphasize the networks for leading, more so than those for following. For example, studies of interactive imitation have compared the initiation and imitation of visual actions within the same group of participants, and have highlighted an initiation network involved in self-monitoring, willed action, and decision making ( ;  ;  ;  ). Studies of auditory-entrainment tasks, such as finger tapping, have studied expert leaders or individuals who spontaneously emerge as leaders with in the context of the study, and have similarly identified a network involved in decision making, movement initiation, and self-processing ( ;  ;  ). These studies have provided either no results or inconsistent findings regarding following or expert followers. In a previous publication from our lab ( ), we characterized the networks for leading and following during a joint-action task with physical interaction, using the same dancer participants as those employed in the present study. In accordance with the previous literature, we found that leading showed a motor- and self-oriented profile, engaging areas associated with motor planning, spatial navigation, sequencing, action monitoring, and error correction. In contrast, following showed a far more sensory- and externally oriented profile, revealing areas involved in somatosensation, proprioception, motion tracking, social cognition, and outcome monitoring. However, while that study compared the act of leading with the act of following, it did not assess the influence of prior expertise at being a leader or follower on the brain activations. That was the major objective of the current follow-up analysis, namely to examine role-specific expertise. 

It is well-established that expertise can influence both the structure and function of the brain. There is now a vast literature devoted to various forms of motor, perceptual, and cognitive expertise (reviewed in  ). A general finding of such studies is that brain activations and gray matter volume are enhanced in experts, as compared to non-experts, in areas that process the skills that underlie a person’s domain of expertise ( ;  ;  ). For example, with regard to perceptual tasks, trained musicians and other auditory experts show enhanced effects in auditory cortex ( ,  ;  ;  ), while visual experts show effects in visual cortex ( ,  ;  ). In the motor domain, effects are found in cortical and subcortical motor and premotor areas involved in motor execution, control, planning, and representation ( ;  ). Motor experts, such as athletes, dancers, and musicians, additionally demonstrate changes in perceptual and cognitive areas associated with their trained skills ( ). For example, sensorimotor coupling is enhanced in musicians and athletes ( ;  ). In addition, activations in the action-observation network [including premotor cortex (PMC), superior parietal lobule (SPL), and inferior parietal lobule (IPL)] are enhanced when dancers view specific dance patterns that they are expert in ( ), or when athletes view sports actions that they are expert in ( ), as compared to when the same people view dances or sports movements that they are not trained in.   suggested that this effect was due to motor training, rather than the associated perceptual training. Expertise, in addition to producing enhancements in processing, has also been linked to decreases in the overall number of activated foci in neuroimaging studies, especially in attentional and cognitive-control networks, suggesting an enhancement in automaticity of processing for the trained skill ( ;  ). The “two stage expertise hypothesis” ( ;  ) suggests that short-term training leads to enhancements of brain activations for the trained skill, while long-term training and skill mastering lead instead to decreases or reorganizations in brain activations. 

While previous neuroimaging studies have looked at leading/following and expertise in isolation, no study thus far has combined the two issues, which is the principal objective of the present study. As mentioned above, couple dancers are an ideal cohort for exploring role-specific expertise in leading and following, since they spend many years developing expertise at typically just one of the two roles of the dance. As a result, expert leaders are usually unskilled followers, and vice versa, while both groups have comparable levels of overall motor expertise at the dance. More specifically, leader expertise during couple dancing requires the generation of a motor plan for both the self and the partner, and the efficient conveyance of signals to the partner, while follower expertise requires the tracking of information coming from the leader and its interpretation to construct either an identical or complementary movement pattern in real time. 

In order to assess the effect of role expertise on brain activations during an ecologically valid joint-action task, we carried out an exploratory follow-up analysis to our previous publication that looked at leading and following ( ) in order to examine the effects of role-specific expertise on brain activations. In the previous study, skilled leaders and followers of couple dances performed both a leading and following task in a magnetic resonance imaging (MRI) scanner in interaction with an experimenter standing next to the bore of the magnet. The participant and experimenter were in physical contact at their hands, and alternated between being the leader and follower of joint improvised bimanual movements. The principal aim of the study was to compare brain activity during the acts of leading and following. The current study follows up on those results using the same dataset in order to examine the effects of individual differences on the brain activations, in particular an individual’s expertise at a given role of the dance. The aim was to look for role-specific brain activations, in other words leading-related activations in trained leaders compared to non-leaders (i.e., followers), and following-related activations in trained followers compared to non-followers (i.e., leaders). Based on the literature cited above demonstrating that experts show enhancements in task-specific brain areas compared to non-experts when performing the same tasks, we predicted that leaders, as compared with non-leaders, would show an enhancement of leading-related activations when leading (only), and likewise that followers, as compared with non-followers, would show an enhancement of following-related activations when following (only). Given that we were not able to effectively rule out the influence of gender on dance role in our design, the results need to be viewed as exploratory. 


## Materials and Methods 
  
### Participants 
  
Eighteen participants (nine of each gender) took part in this study after giving their written informed consent in accordance with the Hamilton Integrated Research Ethics Board, who approved the study (St. Joseph’s Healthcare, R. P. #12-3777). They received monetary compensation for their participation. None of them had a past history of neurological or psychiatric disease. An inclusion criterion for the study was that participants have at least 2 years of experience at one or more kinds of couple dances involving leading and following (e.g., Argentine Tango, Salsa, Swing, and Ballroom). Male participants (40.7 ± 14.9 years old) had a mean dance experience of 8.7 ± 7.2 years, principally as leaders, although one male had significant experience as a follower as well. Female participants (40.2 ± 12.3 years old) had a mean dance experience of 5.6 ± 2.9 years, principally as followers, although two females had significant experience as leaders as well. 

On the day of the experiment, participants reported their ability to lead or follow a couple dance using a scale from 0 to 100, where 0 corresponds to no expertise at leading or following, and 100 corresponds to a very high level of expertise at leading or following. Each person did separate ratings for leading and following skill, with results shown in   Figure   . We explained to participants that these scales emphasized the ability to transmit/receive information while dancing with a partner, rather than the ability to perform complex or stylistic movements. Males reported a mean leading ability of 69.8 ± 17.7 (one male was at 35 and the rest ranged from 60 to 90). Likewise, females reported a mean following ability of 77.2 ± 8.3 (ranging from 70 to 90). With regards to the complementary skill, males reported a mean following ability of 33.7 ± 21.6; the male with significant following experience reported his following ability at 78, while all the others males rated it at between 8 and 50. Females reported a mean leading ability of 28.9 ± 25.2; both females with significant leading experience reported their leading ability at 70, while all other females rated themselves at between 5 and 40. Correlations between leading ability, following ability, years of experience at dancing, and age showed that leading ability, but not following ability, correlated with the number of years of experience (  Table   ). Anecdotal evidence suggests that leading skill requires a greater amount of time and effort to achieve than does following skill, which may explain the exclusive correlation of leading skill with years of experience. Since leading and following ability were not anti-correlated in the analysis, participants designated as “leaders” in this study were comprised of all the participants who were primarily trained as leaders for at least 2 years (i.e., all the of males) plus the two participants who, although primarily trained as followers, had significant leading experience and a strong leading ability (two females). Those designated as “followers” were comprised of all the participants who were primarily trained as followers for at least 2 years (i.e., all of the females) plus one participant who, although primarily trained as leader, had significant following experience and a strong following ability (one male). Thus, three participants belonged in both groups. This division was used in only the first set of analyses (see below). 
  
Self-report scales for skills as a leader and follower of couple dances. The   x  -axis shows the self-rating scale for leader skill (left panel) and follower skill (right panel) for couple dancing, where 100 is the highest rating. The   y  -axis of each graph shows the number of participants, from the pool of 18, who rated themselves at the various levels of skill for each role. Female participants are color-coded red and males are color-coded blue, both here and in   Figures  ,   . Participants designated as “leaders” in this study were comprised of all the males plus the two females with strong leading ability, while those designated as “followers” were comprised of all the females plus the male with strong following ability. Leaders are color coded as purple here and in   Figures  –  , whereas followers are color coded as pink here and in   Figures  –   (not to be confused with the color coding of gender). 
    
Correlation between age, years of couple-dance experience, and self-reported leading and following skill. 
    

### Procedure 
  
While the participant was lying supine in the MRI scanner, an experimenter (LASC) stood next to the bore of the scanner in order to have physical contact with the participant’s two hands. The participant’s forearms were fastened to the side of their body such that only their wrists, hands and fingers were able to move. Participants’ hands (palms up) were always below the experimenter’s hands (palms down), so that the participants’ hands could not be passively moved. The experimenter had significant experience both as a follower and a leader of couple dances. Together, the participant and experimenter performed highly controlled joint hand movements in all three planes of motion, alternating between leading and following the joint movement during different task-epochs of the scan. The movement patterns were improvised, rather than pre-learned, in order to maintain an ongoing requirement for motor planning during leading and a comparably heightened sense of responsiveness during following. No external cuing of tempo or rhythm was done with a metronome or with music. Participants performed all conditions with their eyes closed, and were instructed about which task to perform by means of pre-recorded verbal cues delivered through MRI-compatible headphones. Each condition was performed in a random order six times in blocks of 28 s. 

Complete methods and details concerning fMRI acquisition and image analysis, including participant training, are described in  . Briefly, the functional MRI imaging parameters were 2000 ms TR, 35 ms TE, 90° flip angle, 39 axial slices, 4 mm slice thickness, 0 mm gap, 3.75 × 3.75 mm in-plane resolution, 64 × 64 matrix, and 240 mm field of view. An automatic shimming procedure was performed before each scan to minimize inhomogeneities in the static magnetic field. For each of the three functional scans, 216 volumes–corresponding to 12 epochs of 28 s task + 8 s rest–were collected over 7’12”, resulting in a total of 648 volumes. Two magnetic field maps (5 ms then 8 ms TE) with the same imaging parameters as the fMRI were acquired in order to unwarp the data. Unwarping was performed with the relaxation method of “anatabacus”, a plugin in BrainVoyager, in order to correct for non-rigid deformations. In addition, the head-motion parameters were included as nuisance regressors in the analysis. Functional and structural images were processed using BrainVoyager QX 2.8. Coordinate tables were computed using NeuroElf. 


### Analysis 
  
We first performed qualitative analyses on three groups to assess if there were any differences between being a leader and being a follower. Specifically, we carried out three random-effects analyses for the bidirectional contrast “Leading versus Following” (1) for the whole group of 18 participants, (2) for the 11 leaders only, and (3) for the 10 followers only. These were performed at a two-tailed statistical threshold of   p   &lt; 0.005 uncorrected with a cluster-level correction of   k   = 28 voxels determined with Alphasim (family-wise error   p   &lt; 0.05) in NeuroElf. The conjunction of [Leading &gt; Rest] ∩ [Following &gt; Rest] was also performed on these three groups in order to serve as a reference for the general network of brain areas activated by the movement tasks, irrespective of role. It was performed at a two-tailed statistical threshold of   p   &lt; 0.005 uncorrected with a cluster-level correction of   k   = 49 voxels determined with Alphasim. 

Since qualitative differences were found (see Results section), we tested further for the effect of role by performing whole-brain regression analyses on the full group of participants (  n   = 18). We chose to perform statistical regression analyses instead of a direct statistical comparison between leaders and followers for two reasons. First, we consider role expertise to be a continuous trait, rather than a dichotomous one. Dancers can belong to both groups if they are trained at both leading and following. Thus a binary distinction would have led to a “male versus female” contrast, rather than a “leader versus follower” contrast. Second, the number of participants in each group was small (  n   = 10 and 11 for leaders and followers, respectively), whereas the regression involved the full group of 18 participants. Because of the small number of participants in the analysis and because of the small number of female leaders and male followers in the cohort, we consider this an exploratory study. Future studies will need to examine larger numbers of participants who have both leading and following skills, although such dual training tends to be limited to professional teachers of a dance. 

For the whole-brain regression analyses, the self-reported values of leading and following skill were used as covariates in two separate analyses to regress the betas values of the contrast “Leading versus Following”. These regressions were also performed at a two-tailed statistical threshold of   p   &lt; 0.005 uncorrected with a cluster-level correction of   k   = 25 voxels, determined with Alphasim. However, this threshold led to null results, and so we reported the activation at a less stringent threshold of   p   &lt; 0.025 uncorrected with a cluster-level correction of k = 46 voxels, determined with Alphasim. We note that these results should be interpreted with caution and need to be replicated in future analyses. In order to examine the influence of gender, the mean beta value of each activated cluster was extracted for each participant and regressed against his/her corresponding leading or following skill. 



## Results 
  
In order to identify the basic sensorimotor network involved in performing our joint bimanual tasks, we carried out the conjunction of [Leading &gt; Rest] ∩ [Following &gt; Rest], with results shown in   Figure    and Talairach coordinates reported in   Table   . This shared network between leading and following consisted of a widespread sensorimotor cortical (primary motor and somatosensory cortex) and subcortical (thalamus and cerebellum) network, as well as the supplementary motor area (SMA), midcingulate cortex (MCC), SPL, inferior frontal gyrus (IFG), IPL (including the secondary somatosensory cortex [SII] and extending to the insula), and inferior temporal gyrus (ITG), extending to the middle temporal gyrus (MTG). Except for the ITG, which was present in leaders only, this network was found in both leaders and followers. 
  
Shared network for leading and following. The figure shows the results of the conjunction [Leading &gt; Rest] ∩ [Following &gt; Rest] in leaders only (left panel) and followers only (right panel),   p   &lt; 0.005 uncorrected (  k   = 49 voxels). With the exception of the inferior temporal gyrus, the activated network is similar in both followers and leaders. CB, cerebellum; IFG, inferior frontal gyrus; IPL, inferior parietal lobule; ITG, inferior temporal gyrus; MCC, middle cingulate cortex; SMA, supplementary motor area; SMC, sensorimotor cortex; SPL, superior parietal lobule; and Th., thalamus. 
    
The shared network for leading and following. 
    
We next wanted to explore our question of interest, namely whether there was evidence for role-specific activations, in other words activations found only in skilled individuals while performing the role they are trained in. This would reveal whether leaders and followers engage different brain resources during leading and following. As shown in   Figure    and   Table   , we first qualitatively compared three types of analyses of the “Leading &gt; Following” contrast (cyan clusters) and “Following &gt; Leading” contrast (yellow clusters): the whole group of 18 participants; only the leaders (a subset of 11 participants); and only the followers (a subset of 10 participants). Overall, the leaders-only analysis showed basically the same network for leading as the whole group, but no brain areas for following. Likewise, the followers-only analysis showed basically the same network for following as the whole group, but only the dorsolateral prefrontal cortex (DLPFC) for leading (Note that only role-specific activations are labeled in the   Figure   ). 
  
Role-specific brain activations. The figure shows an analysis of the bidirectional “Leading versus Following” contrast in three groupings: the whole group of 18 participants; only the leaders (a subset of 11 participants); and only the followers (a subset of 10 participants). Contrasts are performed at   p   &lt; 0.005 uncorrected (  k   = 28 voxels). The top panel is the midsagittal view, the lower left panel is the left hemisphere, and the lower right panel is the right hemisphere. Each panel is set up as a triad, with the whole group at the top and the restricted analyses of leaders-only and followers-only below that. Cyan clusters and outlines reflect the contrast of “Leading &gt; Following”, whereas yellow clusters and outlines reflect the reverse contrast of “Following &gt; Leading”. In order to facilitate the visualization of role-specific activations, we use colored outlines to represent whole-group activations that are missing in either the leaders-only or the followers-only analyses. More specifically, cyan outlines are regions of whole-group activation that are present in the leaders-only analysis, but not the followers-only analysis, while yellow outlines are regions of whole-group activation that present in the followers-only analysis, but not the leaders-only analysis. The leaders-only analysis shows the same network for leading as the whole group, but no brain areas for following. The followers-only analysis shows the same network for following as the whole group, but only the cerebellum and dorsolateral prefrontal cortex for leading. Only role-specific activations are labeled in this figure. Leading network: CMA: cingulate motor area; PMC, premotor cortex; SMA, supplementary motor area; and SPL, superior parietal lobule. Following network: PCC, posterior cingulate cortex and TPJ, temporo-parietal junction. 
    
Leading versus following in the whole group, the leader-only group, and the follower-only group. 
    
Regarding the leading task, role-specific activations that were found exclusively in skilled leaders (cyan activations in   Figure    in both the leaders-only and whole-group brains that correspond with the cyan outlines in the followers-only brain) were observed in the SMA and cingulate motor area (CMA; top panel), SPL (right and left hemispheres in the lower panels), and PMC(left hemisphere). In addition, while leading, leaders showed a more extended premotor activation than the whole-group, especially in the right hemisphere (  Table   ). 

Regarding the following task, role-specific activations that were found exclusively in skilled followers (yellow activations in   Figure    in both the followers-only and whole-group brains that correspond with the yellow outlines in the leaders-only brain) were observed in the posterior cingulate cortex (PCC; top panel), temporo-parietal junction (TPJ; right and left hemispheres in the lower panels), and parahippocampal cortex (PHC, not shown). In addition, while following, followers showed activity in the posterior superior temporal sulcus (pSTS) that was not present in the whole group (  Table   ). To summarize, the networks associated with leading and following seemed to be more strongly engaged by experts at the corresponding role than non-experts at that role. 

We followed up on these qualitative analyses with whole-brain regressions in which the self-reported expertise at being a leader or follower (see   Figure    above) was used as the covariate for the contrast of leading versus following. Activations for these analyses were only found at a more lenient threshold, but are still reported since they are consistent with both our hypotheses and the qualitative analyses reported above. However, the results should be interpreted with caution.   Figure    shows the regressions with leader skill, and   Figure    shows the regressions with follower skill. The regions where activations during the leading task correlated with leader skill included the SMA, pre-SMA, dorsal PMC (dPMC), superior temporal gyrus (STG), and insula (  Figure    top panel,   Table   ). The regions where activations during the following task correlated with follower skill include the PCC, TPJ, pSTS, and mPFC (  Figure    top panel,   Table   ). For each cluster, the coefficient of determination (  R  ) of the regression of the mean beta value against leader and follower skill is shown in   Tables  ,   , respectively. 
  
Regression of brain activation with leader skill in the whole group of participants. The top panel of this figure shows brain activity that correlates with the contrasts “Leading &gt; Following” (cyan activations) and “Following &gt; Leading” (yellow activations). Contrasts are performed at   p   &lt; 0.02 uncorrected (  k   = 25 voxels). Brain areas for “Leading &gt; Following” that correlate with leader skill include the dorsal premotor cortex (dPMC), insula (Ins.), superior temporal gyrus (STG), and supplementary motor area (SMA). Almost no areas for the contrast “Following &gt; Leading” correlate with leader skill (see   Table   ). The lower plots show mean beta values extracted from the SMA, dPMC, posterior insula and STG against leader skill, where female participants are shown with red dots and male participants with blue dots. Activity for leading increased with increasing leader skill, and this seems to be independent of gender. 
    
Regression of brain activation with the follower skill in the whole group of participants. The top panel of this figure shows brain activity that correlates with the contrasts “Leading &gt; Following” (cyan activations) and “Following &gt; Leading” (yellow activations). Contrasts are performed at   p   &lt; 0.02 uncorrected (  k   = 25 voxels). Brain areas for “Following &gt; Leading” that correlate with follower skill include the medial prefrontal cortex (mPFC), posterior parietal cortex (PCC), posterior superior temporal sulcus (pSTS), and temporo-parietal junction (TPJ). No areas appeared for the contrast “Leading &gt; Following” correlate with follower skill (see   Table   ). The lower plots show mean beta values extracted from the TPJ, PCC, mPFC, and pSTS against follower skill, where female participants are shown with red dots and male participants with blue dots. Activity for following increased with increasing follower skill, and this seems to be independent of gender. 
    
Leading versus following correlated with skill as a leader. 
      
Leading versus following correlated with skill as a follower. 
    
Examples of how the mean beta value in these regions covaries with leader and follower skill are shown in the bottom panels of   Figures  ,   , respectively. The results provide some evidence that activity in these regions might depend on the level of expertise. However, they in no way rule out a gender effect, either alone or in interaction with expertise, and so the results have to be seen as preliminary. In the dPMC and STG (  Figure   , bottom panels), activity for the contrast of “Leading &gt; Following” increased with leader skill, but a male with low leader skill had a low activity, whereas females with high leader skill had a high activity. Other areas that correlated with leader skill had the same trend (not shown). Similarly, in the mPFC and TPJ (  Figure   , bottom panels), activity for the contrast “Leading &gt; Following” decreased with follower skill (that is, “Following &gt; Leading” activity increased with follower skill), but a male with high follower skill had a low activity, similar to females with high follower skill. Other areas that correlated with follower skill had the same trend (not shown). Future studies will be needed to fully exclude the influence of gender on the expertise effects observed here. Hence, the current study must be seen as a pilot study that gives a first glimpse at role-specific expertise effects without being able to effectively factor out the influence of gender. 


## Discussion 
  
This current exploratory study examined for the first time the effect of expertise at the coordinative skills involved in leading and following on brain activations during a joint-action task in a realistic setting. Its results provide support for the existence of role-specific brain activations during joint actions. In particular, we observed that leading-related activations were enhanced in leaders compared to followers when both groups performed the leading task, and that following-related activations were enhanced in followers compared to leaders when both groups performed the following task. Additionally, we showed that leading-related brain regions in the whole group of participants tended to correlate with expertise at being a leader, whereas following-related brain regions tended to correlate with expertise at being a follower. Another way of conceptualizing these results is that the skilled leaders hardly engaged any areas during following that were not already engaged during leading; likewise, the skilled followers hardly engaged any areas during leading that were not already engaged during following. This might explain the null results found in some previous studies when comparing following with leading ( ). These results suggest that expertise at one role of a joint-action task can enhance brain activations for the trained role compared to the untrained role. Hence, not only do the results support the existing literature on expertise effects for motor tasks, but they extend it for the first time to the contrastive roles of leader and follower in joint actions. 

The major finding of the initial qualitative analysis (  Figure   ) was that the brain networks that we observed for leading and following in the whole group seemed to be mainly supported by prior experience at being a leader or follower. In particular, skilled followers strongly engaged the mentalizing and social networks (PCC, TPJ, and STS) while following, which is consistent with a view of following as a process of adapting to one’s partner or as inferring knowledge from one’s partner ( ;  ;  ;  ;  ;  ). In contrast, skilled leaders strongly engaged networks for motor control and planning (SMA, CMA, PMC, and cerebellum) and for spatial navigation and exploration (SPL) while leading, which is consistent with the requirements of the leading role ( ;  ;  ;  ;  ). Interestingly, both skilled leaders and skilled followers activated the DLPFC during leading, which implies that self-initiation and action selection ( ;  ;  ) are probably the most important characteristics of leading, regardless of expertise. 

By performing whole-brain regressions with leading or following skill, we treated being a leader or follower as a continuous trait, rather than a dichotomous one. Although we did not find any activity using our   a priori   threshold, the activations observed at a more lenient threshold were consistent with both our hypotheses and the qualitative results, and are thus reported as exploratory findings. We observed that distinct brain areas tended to correlate with the level of self-reported expertise at being a leader or a follower, respectively. The areas that correlated with follower skill were principally components of the following network, such as the mPFC, PCC, TPJ, and pSTS. Thus, the more that someone is trained at following, the more that s/he will recruit brain regions of the mentalizing and social networks, which might indicate more attention to, or more efficient processing of, social stimuli (i.e., cues coming from the leader) and the mental states of others (i.e., their intentions and action plans). Another characteristic of followers is their ability to track their partner’s movements or other signaling cues so as to produce either imitative or complementary movements. Along these lines, the pSTS has been specifically implicated in the multisensory perception of biological motion ( ;  ), indicating that a trained follower might be specialized in analyzing information coming from the partner’s movement, not least haptic information emanating from body contact ( ). 

In contrast to this profile for following, the areas that tended to correlate with leader skill were mainly part of the leading network, including premotor areas (pre-SMA, SMA, and PMC). Other areas that tended to correlate with leader skill were the insula and STG. This network is quite similar to the one shown to be activated by motor experts in the meta-analysis of  . In addition, all of the areas associated with leader skill in the present study have been previously shown to be involved in improvisation ( ). Since leading requires the ability to improvise movements, we can assume that the better a person is at leading, the better s/he can improvise a motor plan for both the self and the partner, and thus the more s/he recruits premotor areas and the STG. However, it has also been shown that improvisational expertise (in musicians, for example) is related to a deactivation in the DLPFC, TPJ, IFG, and insula ( ;  ), which has been interpreted as indicating an automation of cognitive processing and a greater focus on internal processes during improvisation ( ). The absence of deactivations in these regions in our study can potentially be explained by the fact that our use of a joint task may have precluded the adoption of an internal focus by the participants when leading. Indeed, a study of joint improvisation also found an activation increase in the DLPFC, pre-SMA, and STG ( ), which is quite similar to a situation of improvising with a dance partner when leading. 

Overall, the study integrates two issues in the cognitive neuroscience of motor performance, first the contrast between leading and following, and second the influence of individual differences in motor expertise on brain activations. As mentioned in the Introduction, many experimental studies of joint action randomly assign people to being a leader or follower of a joint task ( ;  ;  ;  ;  ). However, in Western dance culture, people are generally assigned these roles based on their gender, with men tending to be assigned the role of leader in couple dances. Thus, in contrast to a study of piano duetting ( ), for example, people come to a dance study like ours with years of experience at just one role of the joint task. This provides us with the unique ability to examine individual differences in joint action based not on random factors but on role-specific training. Previous studies of expertise processing have demonstrated enhanced brain activations in experts compared to non-experts ( ,  ;  ,  ;  ;  ;  ;  ;  ;  ;  ). However, this has often has been investigated using non-motor tasks, even in motor experts like professional ballet dancers ( ). We have instead probed this using a motor task, with the added benefit of doing this using a joint-action task. The integration of these two issues is that we were able to examine the contrast between leading and following–as per studies of joint action–but to incorporate the factor of prior motor experience, as per studies of expertise processing. The results revealed a clear overlap between these two issues, such that the brain activations during the acts of leading and following were enhanced by prior expertise at being a leader or follower, and that activity in task-specific brain areas tended to be positively correlated with the level of expertise at the corresponding role. In other words, we were able to demonstrate   role-specific enhancements   in brain activation. 

### Limitations 
  
Given that this study was a first attempt to examine the effect of role expertise on brain activations during joint action, we are aware that it has a number of significant limitations. First, we were limited in our ability to measure behavioral performance during task production in the scanner due to an absence of MRI-compatible technologies such as motion capture at our imaging center. Thus, we cannot determine if the differences between leaders and followers seen in the study are due to trait-related differences in activation or behavioral differences as well. The joint-action task performed in this study was quite simple and involved very small hand movements. Hence, it did not require any type of specialized skill, which would foster similar performance in the two groups. In addition, the experimenter was the sole interaction partner for all of the participants in the study and was thus a controlled factor in the interaction. However, the absence of a technology like motion capture means that we are unable to rule out behavioral differences between participants as a source of the results. Further research taking advantage of MRI-compatible technologies will be required to explore this issue. 

Second, the qualitative analyses showed an interesting pattern that was confirmed by the whole-group regression at a more lenient threshold, but not at a standard threshold. Hence, the effects seem to be small. Although the observed activations at the less stringent threshold were consistent with our expectations based on previous studies, the results of this study should be taken with caution and need to be replicated, preferentially with a larger cohort and a wider spread of skill levels. In addition, the skill levels that were used to regress the brain data were self-report data. They might thus have been subject to self-report biases and inaccuracies. However, no objective measure of leadership and/or followership skills exists in the literature. Given the preliminary results of this study, it would be worthwhile to develop such measures in future. Such measures could be used to see if the results of the present study could be replicated based on people’s role expertise in some other motor skill outside of dancing, or even on people’s natural predispositions to be a leader or follower, as related to personality traits and life experiences, rather than the specialized skill of dance training. 

Finally, and importantly, we are unable to rule out gender as a factor in determining the role-specific effects in our study, and hence the results need to be seen as quite preliminary. While the leader and follower groups were not exclusively of one gender, they did have a majority of one gender. Given the evidence for gender effects on a diversity of perceptual, cognitive, and motor tasks ( ;  ;  ;  ;  ), further studies will be required to assess a gender contribution to our results with trained couple dancers. Given the paucity of female leaders and male followers in the world of couple dancing, perhaps the only approach that will be able to address the limitations of the current study is a training study. A study that crosses gender with role during a several-month training program of leading or following for some joint-action task could permit a disentangling of the relative effects of gender and expertise. If female leaders and male followers showed the same role-specific effects as in the current study, this would argue against a gender interpretation in favor of expertise   per se  . Such a study could also reveal potential gender effects as well. 



## Conclusion 
  
This study is the first to look at the influence of prior individual training at being a leader or follower on the brain activations occurring during the acts of leading and following, thereby assessing the effect of role expertise during naturalistic joint action. Our major finding was that leaders and followers do not seem approach leading and following in the same way at the neural level, with leaders engaging more brain resources during leading, and followers during following, thus reflecting role-specific activations. Additionally, we showed that activity in leading-related brain regions tended to correlate with expertise at being a leader, and likewise that activity in following-related brain regions tended to correlate with expertise at being a follower. These findings highlight the fact that the acts of leading and following might be skill-specific, and thus that prior experience at these roles should be assessed when studying leading and following during joint action. However, given our inability to disentangle gender from dance role, the current results must be seen as preliminary. A training study that crosses gender with role will probably be required to truly distinguish dance role from gender. 


## Author Contributions 
  
LC ran the experiment and analyzed the data. LC and SB conceived the experiment, analyzed the results, and wrote the manuscript. 


## Conflict of Interest Statement 
  
The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</pre></details></details>
  <details class="inner-accordion"><summary>Coordinate-relevant source tables (4)</summary><details class="inner-accordion"><summary>Table 2 (T2) - The shared network for leading and following.</summary><div class="table-html"><table-wrap id="T2" position="float" orientation="portrait"><label>Table 2</label><caption><p>The shared network for leading and following.</p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="center" colspan="5" rowspan="1">Leaders only (<italic toggle="yes">n</italic> = 11)</th><th valign="top" align="center" colspan="5" rowspan="1">Followers only (<italic toggle="yes">n</italic> = 10)</th></tr><tr><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" colspan="5" rowspan="1"><hr /></th><th valign="top" align="left" colspan="5" rowspan="1"><hr /></th></tr><tr><th valign="top" align="left" rowspan="1" colspan="1">Area</th><th valign="top" align="left" rowspan="1" colspan="1">BA</th><th valign="top" align="left" rowspan="1" colspan="1">Hemisphere</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">k</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Max</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">k</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Max</th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">SMC</td><td valign="top" align="left" rowspan="1" colspan="1">1,3,4,5,6,40</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">33</td><td valign="top" align="center" rowspan="1" colspan="1">-40</td><td valign="top" align="center" rowspan="1" colspan="1">58</td><td valign="top" align="center" rowspan="1" colspan="1">1356</td><td valign="top" align="center" rowspan="1" colspan="1">17.01</td><td valign="top" align="center" rowspan="1" colspan="1">30</td><td valign="top" align="center" rowspan="1" colspan="1">-37</td><td valign="top" align="center" rowspan="1" colspan="1">61</td><td valign="top" align="center" rowspan="1" colspan="1">1149</td><td valign="top" align="center" rowspan="1" colspan="1">16.54</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">SMC</td><td valign="top" align="left" rowspan="1" colspan="1">2,3,4,5,6,40</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-39</td><td valign="top" align="center" rowspan="1" colspan="1">-43</td><td valign="top" align="center" rowspan="1" colspan="1">52</td><td valign="top" align="center" rowspan="1" colspan="1">1419</td><td valign="top" align="center" rowspan="1" colspan="1">17.67</td><td valign="top" align="center" rowspan="1" colspan="1">-39</td><td valign="top" align="center" rowspan="1" colspan="1">-37</td><td valign="top" align="center" rowspan="1" colspan="1">55</td><td valign="top" align="center" rowspan="1" colspan="1">1135</td><td valign="top" align="center" rowspan="1" colspan="1">18.19</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">IFG</td><td valign="top" align="left" rowspan="1" colspan="1">6,13,44</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">54</td><td valign="top" align="center" rowspan="1" colspan="1">2</td><td valign="top" align="center" rowspan="1" colspan="1">19</td><td valign="top" align="center" rowspan="1" colspan="1">174</td><td valign="top" align="center" rowspan="1" colspan="1">5.86</td><td valign="top" align="center" rowspan="1" colspan="1">54</td><td valign="top" align="center" rowspan="1" colspan="1">8</td><td valign="top" align="center" rowspan="1" colspan="1">7</td><td valign="top" align="center" rowspan="1" colspan="1">108</td><td valign="top" align="center" rowspan="1" colspan="1">8.05</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">SMA/MCC</td><td valign="top" align="left" rowspan="1" colspan="1">6, 24, 31</td><td valign="top" align="left" rowspan="1" colspan="1">RH/LH</td><td valign="top" align="center" rowspan="1" colspan="1">3</td><td valign="top" align="center" rowspan="1" colspan="1">-13</td><td valign="top" align="center" rowspan="1" colspan="1">52</td><td valign="top" align="center" rowspan="1" colspan="1">610</td><td valign="top" align="center" rowspan="1" colspan="1">14.68</td><td valign="top" align="center" rowspan="1" colspan="1">0</td><td valign="top" align="center" rowspan="1" colspan="1">-22</td><td valign="top" align="center" rowspan="1" colspan="1">49</td><td valign="top" align="center" rowspan="1" colspan="1">683</td><td valign="top" align="center" rowspan="1" colspan="1">12.14</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">IPL/SII</td><td valign="top" align="left" rowspan="1" colspan="1">13,40,41</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">48</td><td valign="top" align="center" rowspan="1" colspan="1">-28</td><td valign="top" align="center" rowspan="1" colspan="1">25</td><td valign="top" align="center" rowspan="1" colspan="1">294</td><td valign="top" align="center" rowspan="1" colspan="1">7.26</td><td valign="top" align="center" rowspan="1" colspan="1">45</td><td valign="top" align="center" rowspan="1" colspan="1">-34</td><td valign="top" align="center" rowspan="1" colspan="1">31</td><td valign="top" align="center" rowspan="1" colspan="1">108</td><td valign="top" align="center" rowspan="1" colspan="1">6.82</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">IPL/SII</td><td valign="top" align="left" rowspan="1" colspan="1">13, 22,40</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-51</td><td valign="top" align="center" rowspan="1" colspan="1">-28</td><td valign="top" align="center" rowspan="1" colspan="1">19</td><td valign="top" align="center" rowspan="1" colspan="1">240</td><td valign="top" align="center" rowspan="1" colspan="1">9.52</td><td valign="top" align="center" rowspan="1" colspan="1">-48</td><td valign="top" align="center" rowspan="1" colspan="1">-34</td><td valign="top" align="center" rowspan="1" colspan="1">19</td><td valign="top" align="center" rowspan="1" colspan="1">314</td><td valign="top" align="center" rowspan="1" colspan="1">9.36</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">SPL</td><td valign="top" align="left" rowspan="1" colspan="1">7</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">24</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">58</td><td valign="top" align="center" rowspan="1" colspan="1">197</td><td valign="top" align="center" rowspan="1" colspan="1">7.06</td><td valign="top" align="center" rowspan="1" colspan="1">24</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">55</td><td valign="top" align="center" rowspan="1" colspan="1">166</td><td valign="top" align="center" rowspan="1" colspan="1">6.52</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">SPL</td><td valign="top" align="left" rowspan="1" colspan="1">7</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-24</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">58</td><td valign="top" align="center" rowspan="1" colspan="1">453</td><td valign="top" align="center" rowspan="1" colspan="1">10.52</td><td valign="top" align="center" rowspan="1" colspan="1">-27</td><td valign="top" align="center" rowspan="1" colspan="1">-55</td><td valign="top" align="center" rowspan="1" colspan="1">58</td><td valign="top" align="center" rowspan="1" colspan="1">268</td><td valign="top" align="center" rowspan="1" colspan="1">9.76</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">ITG</td><td valign="top" align="left" rowspan="1" colspan="1">37</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">51</td><td valign="top" align="center" rowspan="1" colspan="1">-58</td><td valign="top" align="center" rowspan="1" colspan="1">-8</td><td valign="top" align="center" rowspan="1" colspan="1">117</td><td valign="top" align="center" rowspan="1" colspan="1">6.45</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">ITG</td><td valign="top" align="left" rowspan="1" colspan="1">19, 37</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-48</td><td valign="top" align="center" rowspan="1" colspan="1">-58</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">93</td><td valign="top" align="center" rowspan="1" colspan="1">6.30</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Thalamus</td><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">15</td><td valign="top" align="center" rowspan="1" colspan="1">-25</td><td valign="top" align="center" rowspan="1" colspan="1">10</td><td valign="top" align="center" rowspan="1" colspan="1">105</td><td valign="top" align="center" rowspan="1" colspan="1">7.03</td><td valign="top" align="center" rowspan="1" colspan="1">0</td><td valign="top" align="center" rowspan="1" colspan="1">-16</td><td valign="top" align="center" rowspan="1" colspan="1">16</td><td valign="top" align="center" rowspan="1" colspan="1">49</td><td valign="top" align="center" rowspan="1" colspan="1">6.73</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Thalamus</td><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-15</td><td valign="top" align="center" rowspan="1" colspan="1">-19</td><td valign="top" align="center" rowspan="1" colspan="1">10</td><td valign="top" align="center" rowspan="1" colspan="1">139</td><td valign="top" align="center" rowspan="1" colspan="1">7.41</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Cerebellum</td><td valign="top" align="left" rowspan="1" colspan="1">Vermis</td><td valign="top" align="left" rowspan="1" colspan="1">RH/LH</td><td valign="top" align="center" rowspan="1" colspan="1">-3</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">-17</td><td valign="top" align="center" rowspan="1" colspan="1">308</td><td valign="top" align="center" rowspan="1" colspan="1">10.74</td><td valign="top" align="center" rowspan="1" colspan="1">3</td><td valign="top" align="center" rowspan="1" colspan="1">-58</td><td valign="top" align="center" rowspan="1" colspan="1">-14</td><td valign="top" align="center" rowspan="1" colspan="1">163</td><td valign="top" align="center" rowspan="1" colspan="1">7.72</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Cerebellum</td><td valign="top" align="left" rowspan="1" colspan="1">Culmen/Declive</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">15</td><td valign="top" align="center" rowspan="1" colspan="1">-49</td><td valign="top" align="center" rowspan="1" colspan="1">-17</td><td valign="top" align="center" rowspan="1" colspan="1">164</td><td valign="top" align="center" rowspan="1" colspan="1">9.53</td><td valign="top" align="center" rowspan="1" colspan="1">12</td><td valign="top" align="center" rowspan="1" colspan="1">-46</td><td valign="top" align="center" rowspan="1" colspan="1">-17</td><td valign="top" align="center" rowspan="1" colspan="1">104</td><td valign="top" align="center" rowspan="1" colspan="1">6.19</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Cerebellum</td><td valign="top" align="left" rowspan="1" colspan="1">Culmen/Declive</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-21</td><td valign="top" align="center" rowspan="1" colspan="1">-49</td><td valign="top" align="center" rowspan="1" colspan="1">-20</td><td valign="top" align="center" rowspan="1" colspan="1">140</td><td valign="top" align="center" rowspan="1" colspan="1">10.20</td><td valign="top" align="center" rowspan="1" colspan="1">-15</td><td valign="top" align="center" rowspan="1" colspan="1">-52</td><td valign="top" align="center" rowspan="1" colspan="1">-17</td><td valign="top" align="center" rowspan="1" colspan="1">144</td><td valign="top" align="center" rowspan="1" colspan="1">8.87</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Cerebellum</td><td valign="top" align="left" rowspan="1" colspan="1">Tuber/Declive</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">42</td><td valign="top" align="center" rowspan="1" colspan="1">-58</td><td valign="top" align="center" rowspan="1" colspan="1">-23</td><td valign="top" align="center" rowspan="1" colspan="1">94</td><td valign="top" align="center" rowspan="1" colspan="1">7.03</td><td valign="top" align="center" rowspan="1" colspan="1">45</td><td valign="top" align="center" rowspan="1" colspan="1">-58</td><td valign="top" align="center" rowspan="1" colspan="1">-20</td><td valign="top" align="center" rowspan="1" colspan="1">156</td><td valign="top" align="center" rowspan="1" colspan="1">7.86</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /></tr></tbody></table><table-wrap-foot><attrib><italic toggle="yes">Talairach coordinates for the conjunction of Leading and Following compared to rest (<italic toggle="yes">p</italic> &gt; 0.005 uncorrected, <italic toggle="yes">k</italic> = 49 voxels). IFG, inferior frontal gyrus; IPL, inferior parietal lobule; ITG, inferior temporal gyrus; SII, secondary somatosensory cortex; SMA, supplementary motor area; SMC, sensorimotor cortex; and SPL, superior parietal lobule.</italic></attrib></table-wrap-foot></table-wrap></div></details><details class="inner-accordion"><summary>Table 3 (T3) - Leading versus following in the whole group, the leader-only group, and the follower-only group.</summary><div class="table-html"><table-wrap id="T3" position="float" orientation="portrait"><label>Table 3</label><caption><p>Leading versus following in the whole group, the leader-only group, and the follower-only group.</p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="center" colspan="5" rowspan="1">Whole-group (<italic toggle="yes">n</italic> = 18)</th><th valign="top" align="center" colspan="5" rowspan="1">Leaders only (<italic toggle="yes">n</italic> = 11)</th><th valign="top" align="center" colspan="5" rowspan="1">Followers only (<italic toggle="yes">n</italic> = 10)</th></tr><tr><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" colspan="5" rowspan="1"><hr /></th><th valign="top" align="left" colspan="5" rowspan="1"><hr /></th><th valign="top" align="left" colspan="5" rowspan="1"><hr /></th></tr><tr><th valign="top" align="left" rowspan="1" colspan="1">Area</th><th valign="top" align="center" rowspan="1" colspan="1">BA</th><th valign="top" align="left" rowspan="1" colspan="1">Hemisphere</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">k</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Max</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">k</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Max</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">k</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Max</th></tr></thead><tbody><tr><td valign="top" align="left" colspan="2" rowspan="1"><bold>Activations: Leading &gt; Following</bold></td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   pre-SMA</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="left" rowspan="1" colspan="1">RH/LH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">3</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">58</td><td valign="top" align="center" rowspan="1" colspan="1">29</td><td valign="top" align="center" rowspan="1" colspan="1">5.24</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   SMA</td><td valign="top" align="center" rowspan="1" colspan="1">4,6</td><td valign="top" align="left" rowspan="1" colspan="1">RH/LH</td><td valign="top" align="center" rowspan="1" colspan="1">-4</td><td valign="top" align="center" rowspan="1" colspan="1">-4</td><td valign="top" align="center" rowspan="1" colspan="1">59</td><td valign="top" align="center" rowspan="1" colspan="1">81</td><td valign="top" align="center" rowspan="1" colspan="1">5.97</td><td valign="top" align="center" rowspan="1" colspan="1">-3</td><td valign="top" align="center" rowspan="1" colspan="1">-13</td><td valign="top" align="center" rowspan="1" colspan="1">64</td><td valign="top" align="center" rowspan="1" colspan="1">109</td><td valign="top" align="center" rowspan="1" colspan="1">6.28</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   CMA</td><td valign="top" align="center" rowspan="1" colspan="1">24</td><td valign="top" align="left" rowspan="1" colspan="1">RH/LH</td><td valign="top" align="center" rowspan="1" colspan="1">-6</td><td valign="top" align="center" rowspan="1" colspan="1">8</td><td valign="top" align="center" rowspan="1" colspan="1">37</td><td valign="top" align="center" rowspan="1" colspan="1">47</td><td valign="top" align="center" rowspan="1" colspan="1">4.84</td><td valign="top" align="center" rowspan="1" colspan="1">0</td><td valign="top" align="center" rowspan="1" colspan="1">2</td><td valign="top" align="center" rowspan="1" colspan="1">40</td><td valign="top" align="center" rowspan="1" colspan="1">85</td><td valign="top" align="center" rowspan="1" colspan="1">8.41</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   PMC</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">21</td><td valign="top" align="center" rowspan="1" colspan="1">-4</td><td valign="top" align="center" rowspan="1" colspan="1">55</td><td valign="top" align="center" rowspan="1" colspan="1">145</td><td valign="top" align="center" rowspan="1" colspan="1">8.01</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   PMC</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-26</td><td valign="top" align="center" rowspan="1" colspan="1">-13</td><td valign="top" align="center" rowspan="1" colspan="1">54</td><td valign="top" align="center" rowspan="1" colspan="1">51</td><td valign="top" align="center" rowspan="1" colspan="1">4.36</td><td valign="top" align="center" rowspan="1" colspan="1">-30</td><td valign="top" align="center" rowspan="1" colspan="1">-16</td><td valign="top" align="center" rowspan="1" colspan="1">64</td><td valign="top" align="center" rowspan="1" colspan="1">32</td><td valign="top" align="center" rowspan="1" colspan="1">5.71</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   DLPFC</td><td valign="top" align="center" rowspan="1" colspan="1">8,9</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-40</td><td valign="top" align="center" rowspan="1" colspan="1">29</td><td valign="top" align="center" rowspan="1" colspan="1">38</td><td valign="top" align="center" rowspan="1" colspan="1">98</td><td valign="top" align="center" rowspan="1" colspan="1">7.35</td><td valign="top" align="center" rowspan="1" colspan="1">-48</td><td valign="top" align="center" rowspan="1" colspan="1">32</td><td valign="top" align="center" rowspan="1" colspan="1">31</td><td valign="top" align="center" rowspan="1" colspan="1">46</td><td valign="top" align="center" rowspan="1" colspan="1">5.84</td><td valign="top" align="center" rowspan="1" colspan="1">-39</td><td valign="top" align="center" rowspan="1" colspan="1">44</td><td valign="top" align="center" rowspan="1" colspan="1">34</td><td valign="top" align="center" rowspan="1" colspan="1">76</td><td valign="top" align="center" rowspan="1" colspan="1">7.08</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   DLPFC</td><td valign="top" align="center" rowspan="1" colspan="1">9</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">-36</td><td valign="top" align="center" rowspan="1" colspan="1">23</td><td valign="top" align="center" rowspan="1" colspan="1">25</td><td valign="top" align="center" rowspan="1" colspan="1">30</td><td valign="top" align="center" rowspan="1" colspan="1">6.91</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   SPL</td><td valign="top" align="center" rowspan="1" colspan="1">7</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="center" rowspan="1" colspan="1">-73</td><td valign="top" align="center" rowspan="1" colspan="1">42</td><td valign="top" align="center" rowspan="1" colspan="1">70</td><td valign="top" align="center" rowspan="1" colspan="1">6.39</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="center" rowspan="1" colspan="1">-73</td><td valign="top" align="center" rowspan="1" colspan="1">49</td><td valign="top" align="center" rowspan="1" colspan="1">47</td><td valign="top" align="center" rowspan="1" colspan="1">7.56</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   SPL</td><td valign="top" align="center" rowspan="1" colspan="1">7</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-16</td><td valign="top" align="center" rowspan="1" colspan="1">-73</td><td valign="top" align="center" rowspan="1" colspan="1">36</td><td valign="top" align="center" rowspan="1" colspan="1">84</td><td valign="top" align="center" rowspan="1" colspan="1">5.44</td><td valign="top" align="center" rowspan="1" colspan="1">-18</td><td valign="top" align="center" rowspan="1" colspan="1">-79</td><td valign="top" align="center" rowspan="1" colspan="1">43</td><td valign="top" align="center" rowspan="1" colspan="1">48</td><td valign="top" align="center" rowspan="1" colspan="1">6.34</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   Cerebellum</td><td valign="top" align="center" rowspan="1" colspan="1">Tuber</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">47</td><td valign="top" align="center" rowspan="1" colspan="1">-65</td><td valign="top" align="center" rowspan="1" colspan="1">-17</td><td valign="top" align="center" rowspan="1" colspan="1">37</td><td valign="top" align="center" rowspan="1" colspan="1">5.00</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" colspan="2" rowspan="1"><bold>Deactivations: Following &gt; Leading</bold></td><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   PCC</td><td valign="top" align="center" rowspan="1" colspan="1">7,31</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">3</td><td valign="top" align="center" rowspan="1" colspan="1">-54</td><td valign="top" align="center" rowspan="1" colspan="1">23</td><td valign="top" align="center" rowspan="1" colspan="1">129</td><td valign="top" align="center" rowspan="1" colspan="1">-5.36</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">3</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">31</td><td valign="top" align="center" rowspan="1" colspan="1">92</td><td valign="top" align="center" rowspan="1" colspan="1">-11.12</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   TPJ</td><td valign="top" align="center" rowspan="1" colspan="1">39,40</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">45</td><td valign="top" align="center" rowspan="1" colspan="1">-59</td><td valign="top" align="center" rowspan="1" colspan="1">25</td><td valign="top" align="center" rowspan="1" colspan="1">28</td><td valign="top" align="center" rowspan="1" colspan="1">-5.33</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">48</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">31</td><td valign="top" align="center" rowspan="1" colspan="1">89</td><td valign="top" align="center" rowspan="1" colspan="1">-8.86</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   TPJ</td><td valign="top" align="center" rowspan="1" colspan="1">39,40</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-53</td><td valign="top" align="center" rowspan="1" colspan="1">-63</td><td valign="top" align="center" rowspan="1" colspan="1">23</td><td valign="top" align="center" rowspan="1" colspan="1">105</td><td valign="top" align="center" rowspan="1" colspan="1">-5.70</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   STS</td><td valign="top" align="center" rowspan="1" colspan="1">19,39</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">48</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">16</td><td valign="top" align="center" rowspan="1" colspan="1">92</td><td valign="top" align="center" rowspan="1" colspan="1">-10.18</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   STS</td><td valign="top" align="center" rowspan="1" colspan="1">37,39</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">-51</td><td valign="top" align="center" rowspan="1" colspan="1">-52</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">66</td><td valign="top" align="center" rowspan="1" colspan="1">-5.94</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   aSTG</td><td valign="top" align="center" rowspan="1" colspan="1">13,22</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">57</td><td valign="top" align="center" rowspan="1" colspan="1">-16</td><td valign="top" align="center" rowspan="1" colspan="1">-2</td><td valign="top" align="center" rowspan="1" colspan="1">72</td><td valign="top" align="center" rowspan="1" colspan="1">-9.70</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   Temporal pole</td><td valign="top" align="center" rowspan="1" colspan="1">38</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">-48</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">-23</td><td valign="top" align="center" rowspan="1" colspan="1">30</td><td valign="top" align="center" rowspan="1" colspan="1">-8.09</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   PHC</td><td valign="top" align="center" rowspan="1" colspan="1">30,36</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">17</td><td valign="top" align="center" rowspan="1" colspan="1">-33</td><td valign="top" align="center" rowspan="1" colspan="1">0</td><td valign="top" align="center" rowspan="1" colspan="1">39</td><td valign="top" align="center" rowspan="1" colspan="1">-4.72</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">42</td><td valign="top" align="center" rowspan="1" colspan="1">-40</td><td valign="top" align="center" rowspan="1" colspan="1">1</td><td valign="top" align="center" rowspan="1" colspan="1">28</td><td valign="top" align="center" rowspan="1" colspan="1">-6.13</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   PHC</td><td valign="top" align="center" rowspan="1" colspan="1">28</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-21</td><td valign="top" align="center" rowspan="1" colspan="1">-16</td><td valign="top" align="center" rowspan="1" colspan="1">-6</td><td valign="top" align="center" rowspan="1" colspan="1">103</td><td valign="top" align="center" rowspan="1" colspan="1">-5.76</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">-30</td><td valign="top" align="center" rowspan="1" colspan="1">-22</td><td valign="top" align="center" rowspan="1" colspan="1">-11</td><td valign="top" align="center" rowspan="1" colspan="1">67</td><td valign="top" align="center" rowspan="1" colspan="1">-7.52</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   Thalamus</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">21</td><td valign="top" align="center" rowspan="1" colspan="1">-25</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">59</td><td valign="top" align="center" rowspan="1" colspan="1">-6.72</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /></tr></tbody></table><table-wrap-foot><attrib><italic toggle="yes">Talairach coordinates for the contrast “Leading versus Following” in the whole group, leaders only, and followers only (<italic toggle="yes">p</italic> &gt; 0.005 uncorrected, <italic toggle="yes">k</italic> = 28 voxels). aSTG, anterior superior temporal gyrus; CMA, cingulate motor area; DLPFC, dorsolateral prefrontal cortex; PCC, posterior cingulate cortex; PHC, parahippocampal cortex; PMC, premotor cortex; SMA, supplementary motor area; SPL, superior parietal lobule; STS, superior temporal sulcus; and TPJ, temporo-parietal junction.</italic></attrib></table-wrap-foot></table-wrap></div></details><details class="inner-accordion"><summary>Table 4 (T4) - Leading versus following correlated with skill as a leader.</summary><div class="table-html"><table-wrap id="T4" position="float" orientation="portrait"><label>Table 4</label><caption><p>Leading versus following correlated with skill as a leader.</p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><thead><tr><td valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1">Area</th><th valign="top" align="center" rowspan="1" colspan="1">BA</th><th valign="top" align="left" rowspan="1" colspan="1">Hemisphere</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">k</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Max</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">R</italic><sup>2</sup></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Activation</bold></td><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">pre-SMA</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="center" rowspan="1" colspan="1">8</td><td valign="top" align="center" rowspan="1" colspan="1">58</td><td valign="top" align="center" rowspan="1" colspan="1">55</td><td valign="top" align="center" rowspan="1" colspan="1">0.73</td><td valign="top" align="center" rowspan="1" colspan="1">0.37</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">SMA</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">12</td><td valign="top" align="center" rowspan="1" colspan="1">-7</td><td valign="top" align="center" rowspan="1" colspan="1">55</td><td valign="top" align="center" rowspan="1" colspan="1">184</td><td valign="top" align="center" rowspan="1" colspan="1">0.81</td><td valign="top" align="center" rowspan="1" colspan="1">0.46</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">dPMC</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">36</td><td valign="top" align="center" rowspan="1" colspan="1">-1</td><td valign="top" align="center" rowspan="1" colspan="1">37</td><td valign="top" align="center" rowspan="1" colspan="1">46</td><td valign="top" align="center" rowspan="1" colspan="1">0.66</td><td valign="top" align="center" rowspan="1" colspan="1">0.49</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">Insula</td><td valign="top" align="center" rowspan="1" colspan="1">13</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">33</td><td valign="top" align="center" rowspan="1" colspan="1">-25</td><td valign="top" align="center" rowspan="1" colspan="1">28</td><td valign="top" align="center" rowspan="1" colspan="1">101</td><td valign="top" align="center" rowspan="1" colspan="1">0.71</td><td valign="top" align="center" rowspan="1" colspan="1">0.50</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">STG</td><td valign="top" align="center" rowspan="1" colspan="1">41,22</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">54</td><td valign="top" align="center" rowspan="1" colspan="1">-28</td><td valign="top" align="center" rowspan="1" colspan="1">10</td><td valign="top" align="center" rowspan="1" colspan="1">62</td><td valign="top" align="center" rowspan="1" colspan="1">0.66</td><td valign="top" align="center" rowspan="1" colspan="1">0.48</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Deactivation</bold></td><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">Cingulate</td><td valign="top" align="center" rowspan="1" colspan="1">13,13</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-21</td><td valign="top" align="center" rowspan="1" colspan="1">-34</td><td valign="top" align="center" rowspan="1" colspan="1">28</td><td valign="top" align="center" rowspan="1" colspan="1">87</td><td valign="top" align="center" rowspan="1" colspan="1">-0.74</td><td valign="top" align="center" rowspan="1" colspan="1">0.37</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">Lingual</td><td valign="top" align="center" rowspan="1" colspan="1">19</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-33</td><td valign="top" align="center" rowspan="1" colspan="1">-58</td><td valign="top" align="center" rowspan="1" colspan="1">-2</td><td valign="top" align="center" rowspan="1" colspan="1">46</td><td valign="top" align="center" rowspan="1" colspan="1">-0.72</td><td valign="top" align="center" rowspan="1" colspan="1">0.30</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /></tr></tbody></table><table-wrap-foot><attrib><italic toggle="yes">Talairach coordinates for the contrast “Leading versus Following” in the whole group correlated with the covariate “leader skill” (<italic toggle="yes">p</italic> &gt; 0.025 uncorrected, <italic toggle="yes">k</italic> = 46 voxels). <italic toggle="yes">R</italic><sup>2</sup> is the coefficient of determination of the regression of the cluster’s mean beta value against leader skill. dPMC, dorsal premotor cortex; SMA, supplementary motor area; and STG, superior temporal cortex.</italic></attrib></table-wrap-foot></table-wrap></div></details><details class="inner-accordion"><summary>Table 5 (T5) - Leading versus following correlated with skill as a follower.</summary><div class="table-html"><table-wrap id="T5" position="float" orientation="portrait"><label>Table 5</label><caption><p>Leading versus following correlated with skill as a follower.</p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><thead><tr><td valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1">Area</th><th valign="top" align="center" rowspan="1" colspan="1">BA</th><th valign="top" align="left" rowspan="1" colspan="1">Hemisphere</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">k</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Max</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">R</italic><sup>2</sup></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Activation</bold></td><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Deactivation</bold></td><td valign="top" align="left" rowspan="1" colspan="1">PCC</td><td valign="top" align="center" rowspan="1" colspan="1">7,31</td><td valign="top" align="left" rowspan="1" colspan="1">RH/LH</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="center" rowspan="1" colspan="1">-55</td><td valign="top" align="center" rowspan="1" colspan="1">37</td><td valign="top" align="center" rowspan="1" colspan="1">78</td><td valign="top" align="center" rowspan="1" colspan="1">-0.75</td><td valign="top" align="center" rowspan="1" colspan="1">0.30</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">mPFC</td><td valign="top" align="center" rowspan="1" colspan="1">9,10</td><td valign="top" align="left" rowspan="1" colspan="1">RH/LH</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="center" rowspan="1" colspan="1">47</td><td valign="top" align="center" rowspan="1" colspan="1">22</td><td valign="top" align="center" rowspan="1" colspan="1">64</td><td valign="top" align="center" rowspan="1" colspan="1">-0.73</td><td valign="top" align="center" rowspan="1" colspan="1">0.27</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">pSTS</td><td valign="top" align="center" rowspan="1" colspan="1">19,39</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">42</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">13</td><td valign="top" align="center" rowspan="1" colspan="1">90</td><td valign="top" align="center" rowspan="1" colspan="1">-0.75</td><td valign="top" align="center" rowspan="1" colspan="1">0.61</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">TPJ</td><td valign="top" align="center" rowspan="1" colspan="1">39,40</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">48</td><td valign="top" align="center" rowspan="1" colspan="1">-52</td><td valign="top" align="center" rowspan="1" colspan="1">43</td><td valign="top" align="center" rowspan="1" colspan="1">72</td><td valign="top" align="center" rowspan="1" colspan="1">-0.72</td><td valign="top" align="center" rowspan="1" colspan="1">0.48</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /></tr></tbody></table><table-wrap-foot><attrib><italic toggle="yes">Talairach coordinates for the contrast “Leading versus Following” in the whole group correlated with the covariate “follower skill” (<italic toggle="yes">p</italic> &gt; 0.025 uncorrected, <italic toggle="yes">k</italic> = 46 voxels). <italic toggle="yes">R</italic><sup>2</sup> is the coefficient of determination of the regression of the cluster’s mean beta value against follower skill. mPFC, medial prefrontal cortex; PCC, posterior cingulate cortex; pSTS, superior temporal sulcus; and TPJ, temporo-parietal junction.</italic></attrib></table-wrap-foot></table-wrap></div></details></details>
</details>


<details class="doc-card">
  <summary><strong>PMID 31056647</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/31056647/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>31056647_analysis_0</td><td>Emotional support group &gt; no support group</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast comes from a cyberball social exclusion task and tests how emotional (touch) support modulates neural responses to exclusion (reduced right AI). This directly measures social processing.</td></tr>
<tr><td>31056647_analysis_1</td><td>Appraisal support group &gt; no support group</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast derives from the cyberball exclusion task with appraisal (informational) support and probes changes in neural responses (TPJ) to a social manipulation, therefore measuring social processing.</td></tr>
<tr><td>31056647_analysis_2</td><td>Appraisal support group &gt; no support group</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast (exclusion run2 &gt; run1 after appraisal support) assesses neural responses (increased subACC) to a social exclusion manipulation following social support, thus measuring social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>31056647_1</td><td>appraisal support group &gt; no support group (run 1 &gt; run 2); affiliation</td><td>31056647_analysis_1</td><td>Appraisal support group &gt; no support group</td><td>0.840</td><td>1.000</td><td>0.952</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>31056647_2</td><td>appraisal support group &gt; no support group (run 2 &gt; run 1); affiliation</td><td>31056647_analysis_2</td><td>Appraisal support group &gt; no support group</td><td>0.840</td><td>1.000</td><td>0.952</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>31056647_3</td><td>emotional support group &gt; no support group (run 1 &gt; run 2); affiliation</td><td>31056647_analysis_0</td><td>Emotional support group &gt; no support group</td><td>0.840</td><td>1.000</td><td>0.952</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  <details class="inner-accordion"><summary>PMC full text available (PMCID 6688450)</summary><p><strong>Title:</strong> Social support modulates the neural correlates underlying social exclusion</p><details><summary>Abstract</summary><pre class="paper-text">Ostracism threatens the human need for social interactions, with negative consequences on cognition, affect and behavior. Understanding the mechanisms that can alleviate these consequences has therefore become an important research agenda. In this study, we used behavioral and fMRI measures to advance our understanding how social support can buffer the negative effects of social exclusion. We focused on two different types of support from a friend: emotional support, conveyed by gentle touch and appraisal support, implemented as informative text messages. Seventy-one female participants underwent fMRI scanning while playing a virtual ball-tossing game in the course of which they were excluded. Two consecutive runs of the game were separated according to the participant’s experimental condition (appraisal support, emotional support and no support). Results showed that the experience of social exclusion is modulated by the type of support received. Specifically, emotional support decreased negative emotions and anterior insula activity, while appraisal support increased negative emotions, with concomitant increase of subgenual anterior cingulate cortex and decrease of temporal-parietal junction activity. These divergent effects of social support point to the necessity to characterize whether and under which conditions it represents an effective and positive resource to alleviate the negative consequences of social exclusion.</pre></details><details><summary>Body</summary><pre class="paper-text">## Introduction 
  
The aim of the present study was to investigate how different types of social support reduce negative feelings associated with social exclusion and its activation at the neural level. Human beings have a fundamental need to interact with each other. Ostracism (social exclusion) threatens this need and has various effects on cognition, affect and behavior ( ). It is often associated with experiences of pain, often called social pain, defined as ‘the distressing experience arising from the perception of actual or potential psychological distance from close others or a social group’ ( ;  ).   refers to it as one of the most painful and emotionally unpleasant conditions that the individual can live with, as it bears the risk of damaging his ability to relate to other individuals. Experimental neuroscientific research over the past decades has extensively focused on the understanding of ostracism’s neurophysiological underpinnings. Mainly investigated via computer-controlled ball-tossing games (the cyberball game, see   for review), the experience of exclusion from the game (social exclusion) usually results in feelings of unpleasantness and discomfort, with concomitant recruitment of a network of brain areas associated with the processing of negative affect, such as the dorsal anterior cingulate cortex (dACC), the subgenual anterior cingulate cortex (subACC) ( ;  ;  ;  ) and the anterior insula (AI) ( ). It is currently a matter of debate if the fingerprint of social exclusion resembles the negative experience associated with pain of physical nature ( ;  ). For example, the experiences of social exclusion and physical pain reflect many common psychological and biological characteristics: from the use of similar words (‘I feel hurt’) ( ), the involvement of overlapping neurochemical ( ;  ) and neural systems ( ), to comparable inflammatory responses and genetic regulation ( ;  ;  ). These commonalities may stem from similar adaptive evolutionary functions ( ). As physical damage to an organism threatens its survival, and the presence of pain lead to protective responses via unpleasant and distressing psychological states, feelings of pain and discomfort after separation from the individual’s social group may serve as protective factors preventing such separation. Consequently, social pain may have promoted safety in a similar manner as physical pain; when a ‘socially painful’ event has occurred, it may drive the individual to repair the social relationship or to seek new ones ( ). However, behaviors that are adaptive when an individual experiences acute pain, e.g. avoiding activities that increase pain, when pain becomes chronic may develop into patterns of behavior that are maladaptive and impair long-term health ( ). Similarly, social pain responses that are situationally appropriate, e.g. feeling angry or avoiding a group after being rejected, may lead to less-effective coping and long-term social isolation, when they become a chronic issue ( ). Given the negative and serious long-term consequences of pain exposure, it is mandatory therefore to understand and promote factors that facilitate the remission or prevent the initiation of such psychological and behavioral effects. In that regard, positive aspects of one’s social world (social support) may improve coping responses and overall well-being. For example, according to  , p. 11), social support is configured as an ‘exchange of resources between two individuals, perceived by the one who provides it - or by those who receive it - as something aimed at increasing the well-being of the recipient’.   describes it in terms of perceived and real, useful and/or significant supplies provided by the community, social networks and trustworthy partners associated to the well-being of the subject.   identifies different types of social support:   `  emotional support’ is associated with sharing life experiences and involves the provision of empathy, love, trust and care; `instrumental support’ involves behaviors that directly help people in need using tangible help (like tangible services and economic benefits); `informational support’ involves the provision of advice, suggestions and information that a person can use to address problems; and finally `appraisal support’ involves the provision of information that is useful for evaluation purposes: constructive feedback, affirmation and social comparison. Several empirical studies ( ;  ;  ) have examined the function of social support on the perception of physical pain, demonstrating a remarkable correlation between social support and the reduction of physical pain experience. Meaningful social connections have also been shown to serve a protective role in reducing neural, physiological and neuroendocrine responses to pain and stress including heart rate, blood pressure and cardiovascular and neuroendocrine responses ( ;  ). Given the strong commonalities between physical and social pain, it is not surprising that the interest on the effects of social support on physical pain has been extended to stressors of social nature, with similar results reported. In particular, psychosocial stress caused by social evaluation ( ) has been observed to be reduced by social support ( ). Interestingly, different types of social supports (verbal support, physical contact) have been associated to different reactions in women ( ), suggesting that not all types of social support are effective in reducing the physiological responses to social stress. In spite of the rich scientific literature on social support and psychological stress upon social evaluation, only few studies have directly examined the effects of social support on the feeling of social pain caused by, for example, social exclusion or ostracism. Similarly, to psychological stress, these studies suggest that the presence of a friend ( ), supportive emotional texts ( ) or gentle slow touch ( ) are able to reduce the negative feelings caused by social exclusion. On the neural level, self-reported supportive daily life interactions have been shown to diminish neuroendocrine stress responses and to correlate with decreased activity in the dACC following ostracism ( ). Similarly,   observed that supportive emotional text leads to reduced AI and enhanced theory of mind (ToM) network activity ( ;  ;  ;  ) during social exclusion. 

To date, however, a single study examining how different types of social support modulates feelings of social pain and how this is represented at the neural level has not been performed yet. Our study aimed, for the first time, at disclosing the role of different support strategies in modulating the behavioral and neural correlates involved in social exclusion. Specifically, we used two different types of support: emotional physical support (emotional support), which we implemented as gentle touch, and informational/appraisal support (appraisal support), which we implemented as informative text messages allowing to better understand the situation. In line with the previous literature, we hypothesized feelings of social pain, induced via exclusion from a virtual ball-tossing game, to be reduced after experiencing social support. Furthermore, we hypothesized such behavior to be associated with reduced activity of the neural network involved during the experience of social exclusion. Finally, we expect different neurophysiological effects depending on the type of social support experienced. In particular, we expected the emotional support group to show modulatory effect in the affective network (e.g. AI, ACC) while the appraisal support group to additionally modulate the ToM network ( ) 


## METHODS 
  
### Participants 
  
In total, 81 Italian female volunteers (age, 21.67 ± 2.29 years) with no history of neurological or psychiatric disorders (assessed with semi-structured interviews conducted by a psychologist) were recruited among undergraduate students at the University of Turin. We chose to include females only, as gender differences on social exclusion are well-documented (see  ;  ). All participants were right-handed according to the Edinburgh Handedness Inventory ( ). Female friends of a similar age as the participants were invited to participate in the experiment, and instructed to act as confederates. Subjects were randomly assigned to one of the three groups: appraisal support group (N = 26), emotional support group (N = 26) and no support group (N = 29). Ten participants were excluded from the study because of excessive movement or lack of compliance during the functional Magnetic Resonance Imaging (fMRI) session, leaving the final sample for the three groups as follows: appraisal support group (N = 23), emotional support group (N = 23) and no support group (N = 25). All participants signed the information
consent after the experimental procedures have been described to them. The study was approved by the Bioethics Committee of the University of Turin. 


### Social pain task 
  
In order to create in the fMRI environment the uncomfortable situation in which participants could experience social exclusion, we used a modified version of the well-known `cyberball game’ ( ), which has been widely used in the literature ( ;  ;  ;  ;  ). Our version was developed by  , who replaced the animated cartoons of the cyberball game by videos showing schematic virtual representations of real people tossing the ball to each other. The task was composed of 10 blocks with two experimental conditions: `social inclusion’ and `social exclusion’. In each block the ball-tossing game included a total of 12 passes, distributed between three players (including the participant). In the five blocks inducing the experience of social inclusion, the participant received at least one third of the total passes, while in the five blocks inducing social exclusion, the participant received less than one third of the total passages (see   for a detailed description of the stimuli preparation and procedure). Once the participant received the ball, she had to decide to whom to throw it back by pressing with her index (left player) or middle (right player) finger on an Magnetic Resonance Imaging (MRI) compatible button box. The presentation of the blocks was equal for all the participants with a pseudorandomized order: the first three and the last two blocks belonged to the inclusion condition, while the five blocks placed in the central position of the task belonged to the exclusion condition. Each ball-tossing game had an average duration of 33.5 s (range, 30–40 s). At the end of each game, the participant was asked to answer the question ‘How are your emotions?’ in order to report the valence and intensity of the emotions experienced during the game on a Likert scale with nine discrete values (from −4 = very negative on 0 to +4 = very positive) displayed for 4 s. The answer was given by using the same button box used to throw the ball (see  ). Of crucial relevance, this sequence of 10 blocks was performed twice, in two separate fMRI runs. In between the runs, emotional or appraisal support was provided by the participant’s friend in the two experimental groups, while no support was provided in the control group. 
  
 Exemplar trial for the social pain task.   In each trial, participants played the game with other two virtual players. During the game, once they receive the ball, they have to decide to whom to throw it back (as illustrated by the two arrows) by pressing the left or right key on the pad. In the inclusion condition, participants received the ball at least one third of the total tosses. In the exclusion condition, participants received the ball less than one third of the total tosses. Immediately after the game, they were asked to answer the question ‘How are your emotions?’ on a 9-point Likert scale, displayed for 4 s. Interstimulus interval was randomly jittered between 1 and 3 s. Arrows in the inclusion condition are inserted only for descriptive purposes and not displayed during the game. 
  

### Social support manipulation 
  
Two experimental groups of social support have been defined: emotional and appraisal. In the emotional support group  ,   each confederate (the female friend) was instructed to gently touch the hand of the participant, with the aim of comforting her. The characteristic of this group was the administration of support only through physical contact, without the use of verbal or expressive linguistic expressions. No specific constraints on how to deliver the touch was given to the confederates. Rather, they should hold, caress and tenderly squeeze her friend’s hand as she would normally do when trying to comfort her. 

In the appraisal support group, social support was given by the participant’s friend through text messages delivered and displayed on the back-projection screen in the scanner. In particular, the participants were told that the phrases they read on the monitor were written and sent directly by their friend from a PC situated in another room, where she could follow the game. Each participant saw 10 pre-prepared phrases meant to give additional information in order to help the understanding of the experience of social exclusion (for example: ‘I think that these two players are actually friends’ or ‘I think that when the experiment will end, we’ll see them go away together’). Importantly, the content of the text was never aimed to comfort the subject but rather to give information allowing the reappraisal of the situation, and it was always emotionally neutral. 

Finally, in order to tease apart the effect of the repetition of the task (adaptation, fatigue, etc.), the control group did the social exclusion task twice but without receiving any kind of support in between. We chose such control condition because the mere presence of a friend, even without delivering any social support, could have affected the following experience of social exclusion ( ). All conditions of social support lasted for 3 min and were delivered between runs 1 and 2 of the cyberball game, while the subject was resting inside the scanner. For the no support group, the same interval was kept between runs 1 and 2, and the subject asked to wait still for the next run to start. 


### Procedure 
  
Each participant, previously randomly assigned to one of three groups, and her friend (except for the no support group in which participants came alone) were received in the fMRI room of the hospital and informed about the study. Specifically, participants were told that they would be connected via Internet to two other players, located in another room of the hospital. After the general information, each confederate was accommodated in the adjacent room for observing through a monitor what happens to her friend during the game. Here she was instructed on what she had to do for the different support conditions. For all participants, after the verbal instruction about the cyberball game, a training session was performed outside of the scanner to ensure that participants understood the game. A second short practice session was administered in the scanner to familiarize the participants with the response recording system. The cyberball game was programmed using Cogent toolbox (2000), running on Matlab 2007 (Mathworks, Cherborn, MA, USA). Inside the scanner, the stimuli were presented via a head coil-mounted display system (Resonance Technology, Inc.). The fMRI session was composed of three phases performed on the same day (see  ): (i) social pain task run 1: each participant was scanned while engaging in the virtual cyberball game, as described above; (ii) social support: each experimental group received social support (e.g. emotional or appraisal), while the control group did not receive any kind of support. During this section, no fMRI scanning was performed. (iii) Social pain task run 2: each participant was scanned for the second time while engaging in the virtual cyberball task, as described above. After the fMRI session, each participant answered a brief interview aimed at investigating the believability of the manipulation. In particular, we asked indirect questions such as: ‘What do you think about the players? How was the game for you? Do you have any comments?’ None of the participants expressed doubts about the veracity of the situation. 
  
 Timeline of the fMRI session.   Each fMRI session was divided into three phases performed on the same day: (i) social pain task run 1, (ii) social support (emotional, appraisal, no support), (iii) social pain task run 2. Social support was either emotional or appraisal for a duration of 3 min. In the case of the no support group, a 3 min break between the two runs was carried out. 
  

### MRI data acquisition 
  
The MRI data were acquired using a 3.0 T MRI Scanner (Philips Ingenia) with a 32-channel array head coil. The study was performed at the Center of Brain Imaging 3 T-NIT, at the Hospital Città della Salute e della Scienza in Turin, Italy. Echo-Planar Image (EPI) sequence [TR/TE, 2000/30 ms; 33 slices, matrix size, 64 × 64; interslice gap, 0.5 mm; field of view (FOV), 230 × 230 mm ; flip angle, 90 degrees; slices aligned to the AC-PC line, 230 volumes/run] for functional images was applied. A total of 226 volumes per subject per run were collected. The first four volumes of each run were discarded to allow the equilibration of T1 saturation effects. T1-weighted sequence MP-RAGE (TR, 8.1 ms; TI, 900 ms; TE, 3.7 ms; voxel size, 1 × 1 × 1 mm ) for structural images of the whole brain was used. 
  
Contrasts of interest 
  
Significant voxels are reported threshold of   P   ≤ 0.05 FWE corrected for small volumes.Peak activity coordinates are given in MNI space. Significant value for   P   &lt; 0.001 uncorrected. 
  

### Data analysis 
  
#### Behavioral analysis 
  
Emotional ratings given by the participants after each round of the cyberball game were analysed in order to investigate differences in the emotional experience between exclusion and inclusion trials and between the first and second run, i.e. before and after receiving social support. We conducted a repeated-measures ANOVA with two within-subjects factors, condition (inclusion, exclusion), time (runs 1 and 2), and one between-subject factor, group (emotional support, appraisal support, no support). Ratings of the exclusion condition were multiplied by −1 in order to carry the same direction as the inclusion ratings, allowing to test the three-way interaction. Statistical analyses were performed with IBM SPSS Statistics version 24. 


#### fMRI data analysis 
  
The MRI data were analysed using Statistical Parametric Mapping 12 (SPM12, Wellcome Department of Cognitive Neurology, London, UK) run on Matlab 2007 (Mathworks, Cherborn, MA, USA). All functional images have been pre-processed following this order: spatially realigned to the first volume, co-registered to the mean image, segmented in cerebrospinal fluid tissues, gray matter and white matter, then normalized to the Montreal Neurological Institute (MNI) space and finally smoothed at the first level with an 8 mm full-width half-maximum Gaussian Kernel, with an additional 6 mm at the second level. Low-frequency drifts, high-pass temporal filtering with a cut-off of 128 s was used. After preprocessing, a General Linear Model ( ) for statistical analysis was used for both functional runs. Regressors of interest were convolved with a canonical hemodynamic response function. For each participant’s first level analysis, six regressors were computed: social inclusion (I), social exclusion (I), emotion rating (I), social inclusion (II), social exclusion (II) and emotion rating (II). In addition, six parametric regressors of no interest were added to the design matrix to correct residual effects of head motion. At the second level, four contrasts of interest from the first-level analyses were fed into a flexible factorial design aiming at investigating the effect of social support on social exclusion, using a random effects analysis ( ). Linear contrast of the repeated-measures ANOVA with the within-subject factors, condition (exclusion, inclusion), time (runs 1 and 2), and the between-subject factor, group (emotional support, appraisal support, no support), were used to assess the interaction between the factors group and time. Given the main research question of our paper, only results for the exclusion condition are reported. We performed whole brain analyses with an initial threshold of   P   &lt; 0.001 uncorrected and reports clusters that survived Family-Wise Error (FWE) correction for small volumes (SVC) at   P   &lt; 0.05. For the SVC, we created two binary masks encompassing, first, the affective network specifically detected in social exclusion paradigms, and second, a network associated to representing other minds and intentions (ToM). Both masks are based on the most recent published meta-analyses on social exclusion and ToM, respectively. More specifically, the first mask included coordinates derived from two meta-analyses on social exclusion published by   and  . In spite of repeated attempts, it was, however, not possible to receive the original maps from both authors. Therefore, spheres of 10 mm radius centered on the reported main activation loci were generated and combined into one mask with the toolbox MarsBaR ( ). The second mask was provided as an image-based mask by ( ), based on their meta-analysis on ToM tasks (see   for more details). Given we did not expect the involvement of the ToM network for the emotional support group, only the first (affective) mask was used to investigate differences in activations between this group and the no support group. To investigate differences in activations between the appraisal support and no support groups and the emotional support and appraisal support groups, both the affective and the ToM masks were used. The MRIcron software package ( ;  ) was used for anatomical and cytoarchitectonic display and interpretation. 


#### Brain–behavior correlation analyses 
  
Pearson correlation analyses between brain activity and behavioral ratings were performed with IBM SPSS Statistics version 24. In particular, the difference in activity (∆) between the first and second run of social exclusion in the regions showing significant statistical difference (see  ) was correlated with the difference in emotional ratings between the two runs (run 1 minus run 2). Activity in these regions was extracted with REX (  http://web.mit.edu/swg/rex/rex.pdf  ). Correlations were performed for each group separately and corrected for the number of ROIs used in each group. 




## RESULTS 
  
### Behavioral results 
  
The ANOVA revealed a significant interaction effect time*condition*group [  F   = 3.39,   P   = 0.040, partial Eta squared = 0.091]. All the other effects and interactions were not significant (  F   &lt; .103) . Post hoc pairwise comparisons were used in order to characterize the effect of the triple interaction. In particular, in the emotional support group, a significant difference between exclusion run 1   vs   run 2 was observed, defined by a reduction of unpleasantness ratings during the second run (  M   = 5.57, SE = 1.91,   P   = 0.005). In the appraisal support group  ,   a significant difference between exclusion run 1   vs   run 2 was also observed, but with an opposite pattern, namely an increase of unpleasant emotions in the second run (  M   = −3.93, SE = 1.91,   P   = 0.044). The no support group did not show any significant difference between runs 1 and 2 for both conditions (see  ). Finally, the differences between the inclusion and exclusion runs (Δ inclusion, Δ exclusion) were entered in a one-way ANOVA to assess whether the groups significantly differed. The analysis revealed a significant difference between the groups in the Δ exclusion only (  F   = 6.22,   P   = 0.003). Post hoc multiple comparisons were used in order to characterize the effect. In particular, we observed a significant difference both between the emotional support group and the no support group (  M   = 0.564, SE = 0.265,   P   = 0.037) and the emotional support group and the appraisal support group (  M   = 0.949, SE = 0.270,   P   = 0.001). 
  
 Behavioral results.   Mean and confidence intervals (95%) divided by group, condition and run. Significant differences are marked with an asterisk (  P   &lt; 0.05, based on post hoc pairwise comparisons) 
  

### fMRI results 
  
  Emotional support group vs. No support group.   

 Emotional support (social exclusion run 1 &gt; social exclusion run 2) &gt; no support (social exclusion run 1 &gt; social exclusion run 2).  

The analysis revealed significantly reduced activation in the right AI (rAI, x = 33, y = 27, z = −8) for the emotional support group compared to the no support group ( ;  ) for the second run compared to the first run of social exclusion . 
  
 FMRI results.   Differences in the neural activation between the emotional support group vs. the no support group for the contrast: social exclusion run 1   &gt;   social exclusion run 2. The bar plots represent contrast estimates and 90% confidence intervals in the right AI. For illustrative purposes, statistical maps are displayed with a threshold of   P   &lt; 0.001 uncorrected and superimposed on a standard T1 template. 
  
 Emotional support (social exclusion run 2 &gt; social exclusion run 1) &gt; No support (social exclusion run 2 &gt; social exclusion run 1).  

No suprathreshold voxels were observed for the reverse contrast. 

  Appraisal support group vs. no support group.   

 Appraisal support (social exclusion run 1 &gt; social exclusion run 2) &gt; No support (social exclusion run 1 &gt; social exclusion run 2).  

The analysis revealed significantly reduced activation in the right temporal parietal junction (rTPJ, x = 46, y = −47, z = 27) for the appraisal support group compared to the no support group ( ;  ) for the second compared to the first run of social exclusion. A more liberal threshold of   P   &lt; 0.001 revealed reduced activation also in the left temporal parietal junction (lTPJ, x = −48, y = −53, z = 34). 
  
 FMRI results.   Differences in the neural activation between the appraisal support group   vs   the no support group for the contrast: social exclusion run 1 &gt; social exclusion run 2. The bar plots represent contrast estimates and 90% confidence intervals in the right TPJ. For illustrative purposes, statistical maps are displayed with a threshold of   P   &lt; 0.001 uncorrected and superimposed on a standard T1 template. 
  
 Appraisal support (social exclusion run 2 &gt; social exclusion run 1) &gt; No support (social exclusion run 2 &gt; social exclusion run 1).  

The analysis revealed significantly increased activation in the subACC (x = −5; y = 32, z = −5) for the appraisal support group compared to the no support group ( .  ) for the second compared to the first run of social exclusion. A more liberal threshold of   P   &lt; 0.001 revealed reduced activation also in the ventromedial prefrontal cortex (vmPFC) (2, y = 37, z = −8). 
  
 FMRI results.   Differences in the neural activation between the appraisal support group   vs   the no support group for the contrast: social exclusion run 2 &gt; social exclusion run 1. The bar plots represent contrast estimates and 90% confidence intervals in the subACC. For illustrative purposes, statistical maps are displayed with a threshold of   P   &lt; 0.001 uncorrected and superimposed on a standard T1 template. 
    
 Correlation results.   Scatterplot of the correlation between the difference in subACC activity between exclusion runs 1 and 2 (∆ subACC) and the difference in unpleasantness ratings between exclusion runs 1 and 2. 
  
  Emotional support group vs. Appraisal support group.   

No suprathreshold voxels were observed in any of the possible combinations. 


### Brain-behavior correlation analyses 
  
The following correlations were performed: (i) for the emotional support group, correlation between ∆ activity in rAI and ∆ unpleasantness ratings and (ii) for the appraisal support group, correlation between ∆ activity in rTPJ, subACC and ∆ unpleasantness ratings. The correlation analyses revealed a significant positive relationship between ∆ subACC and ∆ unpleasantness ratings in the appraisal support group (r(23) = 0.443,   P   &lt; 0.017 one tailed, corrected for the number of correlations performed). This means that in the appraisal support group, the increase of subACC activity observed in the second run of exclusion was associated to increased unpleasantness feelings in the second run ( ). All the other correlations were not significant. 



## DISCUSSION 
  
In the present study, we investigated the effects of different types of social support (emotional and appraisal) on the behavioral and neural correlates of the experience of social exclusion. Seventy-one female participants were scanned twice while playing the cyberball game. Between the two runs of the game, different types of support were delivered by a female friend. At the behavioral level, we observed that, compared to the control group (no support), the sample that received emotional support in the form of gentle touch, reported reduced feeling of unpleasantness during exclusion trials between the first and second run of the game, i.e. after they had received the emotional support. Our results are in line with the findings of  , which showed reduced reported distress associated to ostracism, after being touched with optimal speed (3 cm/s) to induce positive feelings and thereby promoting interpersonal touch and affiliative behavior ( ). By adding these results, our study was able to show for the first time that the experience of emotional support is associated, at the neural level, to a reduction of activity in right AI, a brain area involved in the processing of negative affect during social exclusion and self- and other-directed aversive experiences ( ;  ;  ). The effects of emotional social support on the experience of social pain resemble the findings reported on pain of physical nature ( ;  ). In particular, during the administration of painful stimuli, married women who held the hand of their partners indicated a lower value of perceived pain. The subjective experience was correlated with reduced activation of the brain areas involved in pain processing, including the AI ( ). Moreover, imagined social support, provided through the visualization of images portraying of loved ones, was also able to modify the neural activation of the insula ( ;  ) and reduce the feeling of distress upon physical pain. The similar effect of emotional support on social and physical pain suggests overlapping regulatory mechanisms, possibly associated to the activity of the μ-opioid system and its analgesic properties ( ). 

The more informative type of support yielded instead different results. At the behavioral level, participants reported increased feelings of unpleasantness after receiving information about the other two participants. The subjective experience was accompanied by a reduced activation in the right TPJ, an area included in the ToM network ( ;  ;  ) and involved in incongruency detection and self-other distinction ( ;  ;  ). TPJ is considered a central structure implicated in the representation of mental states of others ( ). A recent study has associated the function of this brain region to the update of the internal models of the situation in order to generate appropriate actions to the social contexts ( ). This function is particularly important when faced with unexpected stimuli that demand attention reorienting and model updates. The findings of the present study suggest that the information received during the support possibly allowed the participants to interpret what was happening during the first run of the game. Indeed, the participants that received information (e.g. ‘the two players are friends’ or ‘there is understanding between them’) leading to a better understating of the social situation, showed an increase of unpleasant emotions (possibly anger) and possibly a reduced need to understand what was happening, indicated by reduced activity in TPJ. To corroborate this hypothesis, we observed increased recruitment of the subACC after receiving the appraisal support. Furthermore, the increased activity in subACC was positively correlated with the increased negative feelings reported during the second run. Interestingly, the subACC is a region involved in affective processes but not in physical pain ( ). Several social pain studies have indicated an increase in activity in the subACC during the negative experience of social exclusion ( ;  ;  ).   indicated the possibility that greater responsivity in the subACC during peer rejection could reflect an inability to properly regulate emotions evocated by negative events. In line with this literature, some studies have shown that this area is more responsive to negative emotional stimuli among depressed patients and correlates to the severity of depressive symptoms ( ;  ). Notably and differently from subACC, the increased negative affect did not result in a concomitant increase of AI activity, suggesting that the effects of ostracism on affective pain-related brain areas were not modulated by this type of support received. These findings point to a different role of these two areas in emotional processing during social exclusion, possible link to affective saliency and the need of emotion regulation. Our results are partially in line with the findings by  , who reported different reactions depending on the type of social support (verbal or physical contact) received. In particular, they observed that only physical contact was effective in reducing the symptoms of distress associated to negative social evaluation, while verbal support did not show any different from the no support condition. In our case, though, the appraisal support group showed increased negative feelings and concomitant neural response. It is possible to speculate that the negative reaction observed after appraisal support could have adaptive functions for the person experiencing it, in that it may drive the individual to seek for new relationship, when the actual ones are dysfunctional ( ). 

In conclusion, our study provides the first neuroimaging evidences that experiences of social support can modulate regions of the brain recruited during social pain and possibly responsible for coding the negative valence and intensity of emotion experience. Furthermore, for the first time, we showed that this effect may be different depending on the type of support received. Social support is a very complex phenomenon in which various factors can influence how it is effective for the receiver (e.g. who is providing it, in which form, etc.). It has been shown that it does not always result in a reduction of the negative experiences associated to social stress ( ) and social pain. Instead, as observed in our study, it can also increase the negative emotional experience, which can still be functional for the individual in the short term. Therefore, it is very important to understand under which conditions (contextual, personal, modality, etc.) social support can represent an effective and positive resource to alleviate the negative consequences of social exclusion. Importantly, our findings are restricted to a female sample; therefore not generalizable to the entire population. Future studied are needed to extend these findings to samples representative of the general population such as male participants and different age groups ( ) and to explore alternative types of social support (e.g. instrumental, informational). 


## Supplementary Material</pre></details></details>
  <details class="inner-accordion"><summary>Coordinate-relevant source tables (1)</summary><details class="inner-accordion"><summary>Table 1 (TB1) - Contrasts of interest</summary><div class="table-html"><table-wrap id="TB1" orientation="portrait" position="float"><label>Table 1</label><caption><p>Contrasts of interest</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /></colgroup><thead><tr><th rowspan="1" colspan="1" /><th colspan="3" align="left" rowspan="1">
<bold>MNI coordinates</bold>
</th><th align="left" rowspan="1" colspan="1">
<bold><italic toggle="yes">Z</italic>-score</bold>
</th><th align="left" rowspan="1" colspan="1">
<bold><italic toggle="yes">T</italic>-value</bold>
</th><th align="center" rowspan="1" colspan="1">
<bold><italic toggle="yes">P</italic>-value</bold>
</th></tr><tr><th align="left" rowspan="1" colspan="1">
<bold>Anatomical region</bold>
</th><th align="left" rowspan="1" colspan="1">
<italic toggle="yes">X</italic>
</th><th align="left" rowspan="1" colspan="1">
<italic toggle="yes">Y</italic>
</th><th align="left" rowspan="1" colspan="1">
<italic toggle="yes">Z</italic>
</th><th rowspan="1" colspan="1" /><th rowspan="1" colspan="1" /><th align="center" rowspan="1" colspan="1">
<italic toggle="yes">FWE corrected</italic>
</th></tr></thead><tbody><tr><td align="left" colspan="7" rowspan="1">
<bold><italic toggle="yes">Emotional support group &gt; no support group</italic></bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic toggle="yes">Exclusion run 1 &gt; exclusion run 2</italic>
</td><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /></tr><tr><td align="left" rowspan="1" colspan="1">Right AI</td><td align="left" rowspan="1" colspan="1">33</td><td align="left" rowspan="1" colspan="1">27</td><td align="left" rowspan="1" colspan="1">−8</td><td align="left" rowspan="1" colspan="1">3.29</td><td align="left" rowspan="1" colspan="1">3.35</td><td align="left" rowspan="1" colspan="1">.052</td></tr><tr><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /></tr><tr><td align="left" colspan="7" rowspan="1">
<bold><italic toggle="yes">Appraisal support group &gt; no support group</italic></bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic toggle="yes">Exclusion run 1 &gt; exclusion run 2</italic>
</td><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /></tr><tr><td align="left" rowspan="1" colspan="1">rTPJ</td><td align="left" rowspan="1" colspan="1">46</td><td align="left" rowspan="1" colspan="1">−47</td><td align="left" rowspan="1" colspan="1">27</td><td align="left" rowspan="1" colspan="1">3.42</td><td align="left" rowspan="1" colspan="1">3.48</td><td align="left" rowspan="1" colspan="1">.046</td></tr><tr><td align="left" rowspan="1" colspan="1">lTPJ</td><td align="left" rowspan="1" colspan="1">−48</td><td align="left" rowspan="1" colspan="1">−53</td><td align="left" rowspan="1" colspan="1">34</td><td align="left" rowspan="1" colspan="1">3.22</td><td align="left" rowspan="1" colspan="1">3.27</td><td align="left" rowspan="1" colspan="1">.001<sup>*</sup></td></tr><tr><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /></tr><tr><td align="left" rowspan="1" colspan="1">
<bold><italic toggle="yes">Appraisal support group &gt; no support group</italic></bold>
</td><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /></tr><tr><td align="left" rowspan="1" colspan="1">
<italic toggle="yes">Exclusion run 2 &gt; exclusion run 1</italic>
</td><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /></tr><tr><td align="left" rowspan="1" colspan="1">Left subACC</td><td align="left" rowspan="1" colspan="1">−5</td><td align="left" rowspan="1" colspan="1">32</td><td align="left" rowspan="1" colspan="1">−5</td><td align="left" rowspan="1" colspan="1">3.34</td><td align="left" rowspan="1" colspan="1">3.39</td><td align="left" rowspan="1" colspan="1">.046</td></tr><tr><td align="left" rowspan="1" colspan="1">Right vmPFC</td><td align="left" rowspan="1" colspan="1">2</td><td align="left" rowspan="1" colspan="1">37</td><td align="left" rowspan="1" colspan="1">−8</td><td align="left" rowspan="1" colspan="1">2.99</td><td align="left" rowspan="1" colspan="1">3.03</td><td align="left" rowspan="1" colspan="1">.001<sup>*</sup></td></tr></tbody></table><table-wrap-foot><p>Significant voxels are reported threshold of <italic toggle="yes">P</italic> ≤ 0.05 FWE corrected for small volumes.Peak activity coordinates are given in MNI space.<sup>*</sup>Significant value for <italic toggle="yes">P</italic> &lt; 0.001 uncorrected.</p></table-wrap-foot></table-wrap></div></details></details>
</details>


<details class="doc-card">
  <summary><strong>PMID 31142792</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/31142792/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>31142792_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast (increased responses to faces before treatment) arises from participants viewing faces and reflects social-relevant processing (implicit bias, salience of disfigurement). Neural effects include fusiform (face processing) and right IFG and relate to social evaluation, satisfying that the analysis measures social processing.</td></tr>
<tr><td>31142792_analysis_1</td><td>Decreased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast (decreased responses to faces before treatment) concerns neural responses while viewing socially salient faces and implicates regions (anterior cingulate/medial PFC) tied to social cognition and empathy, indicating the analysis measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>31142792_1</td><td>before treatment &gt; after treatment (decreased activation); self</td><td>31142792_analysis_1</td><td>Decreased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing.</td><td>0.414</td><td>1.000</td><td>0.824</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>31142792_2</td><td>before treatment &gt; after treatment (increased activation); self</td><td>31142792_analysis_0</td><td>analysis_0</td><td>0.149</td><td>1.000</td><td>0.745</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  <details class="inner-accordion"><summary>PMC full text available (PMCID 6541618)</summary><p><strong>Title:</strong> Behavioural and Neural Responses to Facial Disfigurement</p><details><summary>Abstract</summary><pre class="paper-text">Faces are among the most salient and relevant visual and social stimuli that humans encounter. Attractive faces are associated with positive character traits and social skills and automatically evoke larger neural responses than faces of average attractiveness in ventral occipito-temporal cortical areas. Little is known about the behavioral and neural responses to disfigured faces. In two experiments, we tested the hypotheses that people harbor a disfigured is bad bias and that ventral visual neural responses, known to be amplified to attractive faces, represent an attentional effect to facial salience rather than to their rewarding properties. In our behavioral study (N = 79), we confirmed the existence of an implicit ‘  disfigured is bad  ’ bias. In our functional MRI experiment (N = 31), neural responses to photographs of disfigured faces before treatment evoked greater neural responses within ventral occipito-temporal cortex and diminished responses within anterior cingulate cortex. The occipito-temporal activity supports the hypothesis that these areas are sensitive to attentional, rather than reward properties of faces. The relative deactivation in anterior cingulate cortex, informed by our behavioral study, may reflect suppressed empathy and social cognition and indicate evidence of a possible neural mechanism underlying dehumanization.</pre></details><details><summary>Body</summary><pre class="paper-text">## Introduction 
  
Physical appearance has a profound impact on a person’s life. Beautiful people are preferred and enjoy many advantages compared to average-looking people . While conceptually orthogonal, the correlation of attractiveness and positive character traits indicates the prevalence of a ‘beautiful is good’ stereotype . This stereotype might be innate . Attractive people are seen as more trustworthy, socially competent, dominant, better adjusted, more capable in school and work, and also receive greater rewards and lesser punishments than their average looking peers . Adults and children ascribe desirable personality traits to attractive faces of adults and children and discriminate against unattractive faces even if they are friends and family members . Attractiveness and trustworthiness judgments are consistent across cultures  and are made extremely quickly . Longer exposure to a face does not attenuate these biases and instead only consolidates people’s confidence in a judgement already made . Attractiveness also highly influences visual exploration of faces . 

In this study we examine a corollary to the ‘beautiful is good’ stereotype, that an automatic ‘disfigured is bad’ stereotype also exists. People with facial disfigurement are stigmatized and are often targets of discrimination. Looking at disfigured faces makes observers feel less happy, less in control, less dominant, and more aroused . People with facial disfigurements are not only perceived as less attractive and less likely to be selected as romantic partners, they are also thought of as having unfavourable personality traits (e.g., lack of emotional stability, conscientiousness), internal attributes (e.g., unhappiness, lower intelligence), social qualities (e.g., untrustworthiness, unpopularity)  and are treated poorly in social interactions . In popular culture, facial disfigurement is often used to distinguish good and evil characters . Well known examples of disfigured villains are Scar in the   Lion King   (large facial scar over left eye), Freddy Krueger in   Nightmare on Elm Street   (3rd degree burns and exposed tissue), the   James Bond   villains Le Chiffre (facial scar over left eye), Emilio Largo (missing eye), Ernst Stavro Blofeld (large scar over right eye covering most of his right side of the face), and Alec Trevelyan (facial burn scars), Elle Driver in   Kill Bill   (missing eye), Two Face in the   Batman   Universe (acid scars covering the left side of his head), Hopper in   A Bug’s Life   (scar covering right eye), and the Duchess from   Alice in a Wonderland   (Macrocephaly). This ‘disfigurement is bad’ stereotype is only partially explained by lower attractiveness of disfigured faces . 

Attractiveness of faces –and therefore attribution of a’beauty is good’ stereotype- is highly correlated with typicality or statistical averageness of faces . In addition to being statistical averages of groups, attractive faces are also symmetric . Both facial symmetry and averageness are considered markers of physical health and influence peoples’ choices of partners . Disfigured faces are neither typical nor average, and are usually not symmetric. They often deviate substantially from the norm. If proximity to the norm predicts positive social attributions, being ‘different’ could lead to negative evaluations. Disfigured faces might be linked to unfavourable personality traits, internal attributes, and social qualities because they are less typical and deviate from the population average. The association of disfigurement with negative attributes probably drives stigmatization and discrimination of disfigured people in social, academic, and professional contexts . The stigmatization and discrimination of disfigured people likely contributes to low self-esteem  and long term mental health concerns similar to other stigmatized groups that are subject to dehumanization . Dehumanization deprives a person or a group of people of positive human qualities and has been shown for several stigmatized groups such as homeless people and drug addicts . Dehumanization is used as a propaganda tool in political conflicts . The strongest predictors of dehumanization are hypothesized to be perceived competence and warmth . Faces rated lowest on both competence and warmth most robustly evoke dehumanization - including feelings of disgust and lack of empathy . 

Neuroimaging studies show that seeing attractive faces evokes brain responses in reward, emotion, and visual areas compared to seeing faces of average attractiveness . Attractive faces produce activations in areas associated with reward, like the nucleus accumbens , and orbitofrontal cortex . Moreover, attractiveness correlates with increased activations in areas associated with emotion, empathy, and social cognition like the anterior cingulate cortex and medio-prefrontal cortex  the latter being particularly active in tasks in which people are not making explicit attractiveness judgements . Different regions of the prefrontal cortex are selectively responsive to either attractive or unattractive faces  which is consistent with findings that ventral medio-prefrontal cortex processes stimulus value attributes in coordination with higher order visual areas like fusiform gyri and semantic processing areas (posterior superior temporal sulcus) . Orbital frontal  and medial prefrontal cortices  seem to process both aesthetic and moral values and may represent the biological link between these two kinds of evaluation . 

Left and right amygdala seem to be sensitive to both attractive  and unattractive faces . These non-linear effects for extremes at either end of the attractiveness spectrum suggest that amygdala activation reflects sensitivity to valence intensity rather than positive or negative valence per se . In line with the valence processing hypothesis for the functional role of amygdala, increased activation in the amygdala (bilaterally) is linked to untrustworthiness of faces . A meta-analysis of brain activations to attractiveness and trustworthiness suggests that activation of amygdala and adjacent nucleus accumbens is driven by extremes and atypicality . There is some tentative evidence that face typicality can also account for the activations in medio-prefrontal and anterior cingulate cortex . The authors note that the brain networks activated in response to extremes of attractiveness and trustworthiness are remarkably similar to brain networks that process positive and negative emotions . 

In addition to increased brain activations in reward and emotion areas, attractive faces also evoke larger neural responses in selective visual processing areas within ventral occipito-temporal cortex (such as the fusiform face area) as compared to faces of average attractiveness . These areas remain sensitive to facial attractiveness even when subjects are engaged in tasks in which attractiveness judgements are not queried explicitly. These observations have previously been interpreted as evidence that these areas also process rewards. While a reward response is one possible explanation for this amplified neural response to attractive faces, it is also possible that this reflects sensitivity to the saliency of attractive faces . If this alternate hypothesis is true, other salient features, such as disfigurement, should lead to similarly amplified neural responses in visual processing areas. 

Viewing faces of stigmatized groups fails to activate brain regions associated with empathy and social cognition . Krendl and colleagues reported increased activation in anterior insula and amygdala which correlated with self-reported disgust in response to viewing faces of stigmatized groups . The lack of activation in empathy and social cognition regions of the brain is postulated to be a neural correlate of dehumanization . 

Appearance clearly affects how people are viewed and treated by others. The same mechanisms that benefit attractive people in social interaction, put unattractive people at an unfair disadvantage. The effects of discriminating against people with facial disfigurement seem to extend beyond the specific effects of lower overall attractiveness and may tie in more with the pattern of results that have been shown with stigmatized groups. 

The goal of the present study was to test the behavioural and brain responses to facial disfigurement and investigate whether surgical treatment mitigates these responses. In two experiments, we used a set of photograph pairs of patients with different types of facial disfigurements before and after surgical treatment of the disfigurement. In experiment one we tested if people harbour implicit biases against disfigured faces and if such implicit biases were different from consciously aware self-reported explicit biases. In a follow up functional MRI (fMRI) study, we tested differential automatic brain responses to the same picture pairs when naïve participants were engaged in an unrelated cover task. We hypothesized that people have negative biases against faces with disfigurement. For the neural responses to facial disfigurement we tested competing hypotheses: visual cortices respond to rewards per se, or visual cortices respond to salience. In addition, we expected disfigured faces to show selective responses in emotion and valence areas such as anterior insulae and amygdalae and anterior cingulate and lateral or medial prefrontal areas in line with the research reviewed above. 


## Results and Discussion 
  
The behavioural experiment (N = 79, see method section for details) consisted of an implicit association test  (IAT) and an explicit bias questionnaire (EBQ) to test the hypothesis that people have a negative bias for disfigured faces. For the IAT, we used a stimulus set of photographs of real patients taken before and after treatment for disfigurement. The EBQ consisted of 11 questions which query conscious biases against people with facial disfigurements (see   https://osf.io/ca2u9/   for all items and data). We found no indication of an explicit bias. However, we did find that non-disfigured faces were preferred in the IAT (see Fig.  ). This bias was particularly robust for men, consistent with previous findings . Prior exposure to disfigured faces did not modulate the implicit bias of individuals.   
Female respondents demonstrate significantly less, although still strong, implicit preference for non-disfigured faces than male respondents. Male respondents show a moderate explicit preference for non-disfigured faces while women show no explicit preference. Error bars indicate 95% confidence intervals. 
  

We used the same set of photographs of people before and after surgical treatment that we used in the IAT in the fMRI study (N = 31). Participants viewed these photographs and engaged in a gender judgement task. We measured neural responses to facial disfigurement to test competing hypotheses of reward versus salience in visual areas like fusiform face area. If these visual areas respond to rewards, then non-disfigured faces compared to disfigured faces would show increased activity in visual areas linked to face processing. If these visual areas respond to salience, then we should find the opposite results; disfigured faces compared to non-disfigured faces should show increased activity in these areas. Because people with facial disfigurement are likely treated as an outgroup , neural patterns in response to disfigurement should be similar to previous findings investigating other stigmatized groups . We predicted decreased activation in areas linked to social cognition such as medio-prefrontal cortex and anterior cingulate cortex, as well as increased activations in areas linked to disgust and negative emotion like anterior insula and amygdala. 

We found that images of people with facial disfigurement, as compared to images of the same faces after surgical treatment, evoked greater neural responses within ventral occipito-temporal cortex, particularly bilateral fusiform gyri (see Fig.  ), and right inferior frontal cortex. This observation confirms the hypothesis that face processing and adjacent areas respond automatically to the salience of faces, rather than their attractiveness or rewarding properties per se.   
Increased activations (red yellow) and deactivations (blue-green) in response to faces before treatment. Results were corrected for multiple comparisons by familywise error correction at p &lt; 0.05 with Monte Carlo permutation testing in SnPM with a combined cluster-voxel threshold (cluster defining threshold p &lt; 0.001, T &gt; 3.3852). 
  

In addition to increased responses in visual areas, we found decreases in neural response amplitude to disfigured faces in the medial anterior cingulate gyrus extending towards medial prefrontal cortex (see Figs   and  ), as well as in a region stretching from right cuneus to the right calcarine gyrus and right lingual gyrus. This finding is similar to previous observations of neural responses to other stigmatized outgroups such as drug addicts and homeless people  and could reflect suppression empathy and mentalizing or increased demands in cognitive control, e.g. inhibition of staring at the area of lesion or inhibition of inappropriate social behaviour like obvious avoidance. Both possible hypotheses are not mutually exclusive and could be linked to the increased activation in the left inferior frontal gyrus - a region linked to cognitive control.   
Increased activations (red yellow) and deactivations (blue-green) in response to faces before treatment. Results were corrected for multiple comparisons by familywise error correction at p &lt; 0.05 with Monte Carlo permutation testing in SnPM with a combined cluster-voxel threshold (cluster defining threshold p &lt; 0.001, T &gt; 3.3852). 
  

In previous studies, increased amygdala activation has been reported to both positive and negative valence of faces . Moreover, studies investigating the brain responses to extreme outgroups like homeless people and drug addicts find activations in anterior insula where it is typically interpreted as a disgust response . We did not find statistically significant activations in amygdala and anterior insula. It is possible that this lack of effect is because of our smaller stimulus sample or that the difference between before and after stimulus pairs is not large enough to produce statistically significant results in this before-after contrast of the same face. 

In sum, we found that people have implicit negative biases against faces that are disfigured, without being aware of harbouring such biases. Disfigured faces evoke greater neural responses in ventral occipito-temporal and right inferior frontal regions as compared to non-disfigured faces. This finding refutes the hypothesis that attractiveness and reward per se drives automatic ventral cortical responses and instead confirms the idea that ventral occipito-temporal regions are sensitive to the salience of faces. 

Moreover, disfigured faces evoke lower neural responses in the anterior cingulate and medio-prefrontal cortex, as well as some visual areas. This result is similar to previously reported neural responses to stigmatized outgroups like homeless people and drug addicts . In agreement with this research, we speculate that the de-activation of these brain areas upon seeing disfigured faces as opposed to the same faces after surgical treatment possibly reflects an inhibition of empathy and mentalizing or inhibition of socially inappropriate behaviour. The medial anterior cingulate gyrus and the adjacent medial prefrontal cortex are core areas of the theory of mind and empathy networks  and are crucial for inferring other’s beliefs, feelings, and mental states. Together with previous behavioural research showing a clear association of negative personality traits and our findings of an implicit bias against disfigured faces, we take these response patterns as neural evidence for stigmatization. Future research should investigate if the de-activation of anterior cingulate cortex represents a consistent neural marker for dehumanization of people with disfigured faces or if it reflects social adaptive behaviour to people who deviate from the norm. 

The emphasis of attractiveness, its association with positive attributes and robustness of these associations across cultures  highlights the pervasive effect of attractiveness in social interaction. People who fall towards the lower end of the attractiveness spectrum are disadvantaged or even subject to discrimination and social isolation as in the case of facial disfigurement. Encouragingly, our findings suggest that surgical treatment of disfigurement mitigates the negative effects of disfigurement. Our findings highlight the importance of recognizing that we implicitly and automatically regard flawed faces as flawed people and that corrective surgery confers social and psychological benefits to people with facial disfigurement. Alternative prevention strategies against discrimination of disfigured people and effective support for people with facial conditions should be explored. 


## Methods 
  
### Implicit association test (IAT) and explicit bias questionnaire (EBQ) 
  
#### Participants 
  
80 participants were recruited via an online recruiting system for psychology experiments at the University of Pennsylvania (55 female, 25 male, mean age = 23 years, SD = 6.4, range 18–56). The sample size was determined based on estimates suggested by a meta-analysis on attitudes towards individuals with disabilities as measured by an IAT . Prior to participation, participants were informed that the task was about categorising faces and words but were naïve to the fact that some of those faces might be disfigured. Participation was voluntary, and participants received money as compensation. Study procedures were approved by the Institutional Review Board (IRB) at the University of Pennsylvania (Protocol #806447). IRB approval was in accordance with the International Conference on Harmonization and the Belmont report. All participants gave written informed consent. 

One participant was excluded from the data analysis for the IAT because more than 10% of the total test trials were unreasonably fast (&lt;300 ms). After data exclusion, the data of 79 participants went into the final analysis (55 female, mean age = 23 years, SD = 6.4, range 18–56). 


#### Procedure 
  
Task order between the IAT and the EBQ was counterbalanced so that half of the participants completed the IAT first, and half of the participants completed the EBQ first. Participants were seated in a testing room, in front of a testing laptop. After having been briefed on the order of the tasks, participants gave written informed consent. The entire experiment took about 30 minutes. 

The IAT  was designed using E-Prime software and was modelled after the IATs from   Project Implicit   (  https://implicit.harvard.edu  ). A total of 16 words were used for the IAT: 8 were positive words (attractive, happy, approachable, friendly, adore, lovely, spectacular, excellent), and 8 were negative words (ugly, evil, sickening, rotten, disaster, disgust, pain, despise). 

Participants completed the EBQ as a survey on Qualtrics. Questions were modelled after the Project Implicit and Changing Faces explicit questionnaires . The questionnaire included 11 questions asking about participants’ prior exposure to and conscious biases against people with facial disfigurement. Participants responded on a scale ranging from 1 to 7 (see   https://osf.io/ca2u9/   for details). 


#### Pictures 
  
Images consisted of photographs of patients with facial disfigurements before and after corrective surgery. These photos were collected from craniofacial and dental surgery atlases and compilations of plastic surgery results. The disfigured faces were photos of the individuals before treatment that were affected by one of the following disfigurements: carcinoma, hyperpigmentation, birthmark, scar or small wound, facial paralysis, isolated weight loss, bone disfigurement, or facial trauma. The non-disfigured faces were photographs of the same individuals after treatment (see   https://osf.io/ca2u9/   for all stimulus pairs). Pre-treatment and post-treatment photographs were cropped (to show only faces, with some hair and neck) and colour-corrected to match in size and coloring . The stimulus set consisted of 28 faces, of which 22 were female and 6 were male. 16 of the faces were oriented frontally, 10 were oriented in a three-quarters portrait view, and 2 were profiles (see   https://osf.io/ca2u9/  ). 


#### Implicit association test and explicit bias measure results 
  
Explicit scores range from −3 to +3, with zero indicating no relative preference for non-disfigured vs. disfigured faces. Positive scores indicate a preference for non-disfigured faces, and negative scores indicate a preference for disfigured faces. We found a significant implicit preference for non-disfigured faces (mean difference score = 0.90; SD = 0.58; min = −0.26; max = 2.00;   t   = 13.80; 95% CI = 0.77 to 1.03; p &lt; 0.001; Cohen’s   d   = 1.55). This effect was particularly strong for male respondents (see Table   for details, see Fig.  ). Participants showed no significant explicit preference for non-disfigured vs. disfigured faces (mean explicit score = 0.01; SD = 0.51; min = −1.50; max = 1.08.168;   t   = 0.17; 95% CI = −0.11 to 0.12; p = 0.866; Cohen’s   d =   0.02). Prior exposure had no effect on bias for either the IAT or the EBQ. There was a small to moderate correlation between implicit and explicit scores that was, however, not statistically significant (Pearson’s correlation coefficient, r = 0.22; p = 0.052) making it difficult to draw conclusions as to whether people are aware of their biases.   
Implicit preferences for non-disfigured vs. disfigured faces for all participants by gender. 
  
IAT D scores range from −2 to +2, with zero indicating no relative preference for non-disfigured vs. disfigured faces. Positive scores indicate an implicit preference for non-disfigured faces while negative scores indicate an implicit preference for disfigured faces. D scores were interpreted according to specific, conservative break points based on Cohen’s   d  : ±0.15 (‘slight’ bias), 0.35 (‘moderate’ bias), 0.65 (‘strong’ bias). 

Cohen’s   d   is a standardized effect size, interpreted as   d   of 0.2 = small effect,   d   of 0.5 = medium effect, and   d   ≥ 0.8 = large effect. 
  



### FMRI experiment 
  
#### Participants 
  
We recruited 34 healthy right-handed college students from University of Pennsylvania (24 females, 10 males). Age of participants ranged from 18–35 years. Participants had normal or corrected to normal vision and no prior history of psychiatric or neurological disease. Before participation in the study, each individual gave informed consent approved by the IRB at the University of Pennsylvania (Protocol #806447) in accordance with the International Conference on Harmonization and the Belmont report. 

The data of three participants was excluded from the final analysis. One dataset was excluded because of technical failure which stopped the stimulus presentation halfway through the experiment. Two other datasets were excluded because of synchronization problems between experimenter laptop and the scanner triggers. The data of 31 participants entered the final analysis (22 females, 9 males). 

The EBQ for the participants in the fMRI experiment showed that about half of the participants have a close friend or family member with either a facial disfigurement or a disability. Exposure to people with facial disfigurement was normally distributed in the sample, and most participants reported no to slight preference for non-disfigured over disfigured people (22/28 data entries, 5 missing values). 


#### Procedure and stimulus presentation 
  
The experiment consisted of one session. Participants were presented with 28 pictures of faces in randomized order and were asked to decide whether the displayed face was male or female. Half of the presented pictures were photographs of patients before treatment, and half after treatment. The pictures were identical to the ones used in the behavioural experiment (IAT, see above). Stimuli were presented using E-prime software by projecting them onto a screen using a projector outside the MR scanner room, which could be seen by participants through a mirror mounted over the head coil. Each picture was presented for 6 seconds. Responses were recorded with a 2-button response device. After the experiment, a high-resolution anatomical scan (~7 min) was conducted. After the scanning session, participants were taken out of the scanner and completed the EBQ for disfigurement on a testing computer outside the scanner room. This test was identical to the EBQ in the online sample reported above. 


#### fMRI data acquisition and pre-processing 
  
Images of blood-oxygen level dependent (BOLD) changes were acquired with a 3 T Siemens Magnetom Prisma scanner (Erlangen, Germany) with a 64-channel head coil. We used cushions to minimize participants’ head movement. We used two localizing scans and auto-alignment. Functional images were acquired using a standard BOLD sequence (TR: 2000 ms, TE: 30 ms, flip angle: 60 degrees, voxel size: 2.0 × 2.0 × 2.0 mm, 81 slices). High resolution (0.8 × 0.8 × 0.8 mm) structural (anatomical) images were acquired using an SPC T1 GRAPPA sequence . Data were pre-processed using the Matlab toolbox SPM12 (  http://www.fil.ion.ucl.ac.uk/spm  ). Images were motion corrected and registered to the first image of the scanning block. The mean of the motion-corrected images was co-registered with the individual participants’ anatomical scan. The anatomical and functional scans were spatially normalized to the standard MNI template. Finally, all data were spatially smoothed using an isotropic 8 mm full width at half maximum (FWHM) Gaussian kernel. 


#### fMRI data analysis 
  
At the single-subject level, statistical analysis was performed using a general linear model. The motion estimates of the motion correction algorithm were modelled as regressors of no interest to account for head motion. We performed a whole-brain group analysis by directly contrasting the mean activations per condition in a non-parametric design with SnPM (  https://warwick.ac.uk/fac/sci/statistics/staff/academic-research/nichols/software/snpm  ). Results were corrected for multiple comparisons with a combined voxel-cluster level threshold by familywise error correction at p &lt; 0.05 with Monte Carlo permutation testing. 

In addition to the whole brain group analysis, we performed an item-wise region of interest control analysis to test if the effects in the group analysis are driven by specific items. The two clusters were defined by the group contrasts in the whole brain analysis and consisted of one area comprising of the two large occipital activation clusters, and one comprising the (de-)activation cluster in the anterior cingulate cortex. Mean values for these two regions were extracted for each subject and item. The mean values were normalised with the individual subject’s mean activation in this area to create relative difference scores per subject and item. The data for the item-wise analysis were analysed with linear mixed effect models in RStudio. We built one base model for each dependent variable (occipital cluster activation, anterior cingulate cluster activation) that included condition (pre or post surgery picture) as a predictor and subject and item as random factors with random intercepts. We tested for both random factors whether including random slopes for the condition would improve the model fit and tested interactions with gender and EBQ responses with the best base model (see   https://osf.io/ca2u9/   for details). 


#### FMRI sample results 
  
Participants performed at ceiling for the gender judgment task. 

An ANOVA analysis of the reaction time data in the gender judgement task in the scanner revealed no differences in reaction times between before and after treatment pictures (F  = 0.56, p = 0.45, see Fig.  ) and no differences for item (F  = 1.26, p = 0.17) and no interaction between item and face type (F  = 1.06, p = 0.38).   
Reaction times for gender judgement task per item split by face type. Error bars display 95% confidence intervals. 
  

We found increased activations in temporo-occipital regions encompassing bilateral middle occipital and fusiform gyrus, left inferior occipital gyrus, as well as right inferior temporal and right inferior frontal gyrus (Fig.  ; see Table   for details). An area in the medial anterior cingulate cortex and an area in the right calcarine gyrus showed significant decrease in activation in response to faces before surgery (Fig.  ; see Table   for details). All clusters statistically significant at p &lt; 0.05 FWE at the cluster level corrected by Monte Carlo permutation testing (cluster forming threshold p &lt; 0.001 per voxel).   
Increased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing. 
    
Decreased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing. 
  

The ROI analysis controlling for random effects of items and subjects confirmed the results of the whole brain analysis (see Figs   and  , see   https://osf.io/ca2u9/   for analysis code and full statistical details). Whether the picture of a person was presented from before or after surgery had a significant effect on the BOLD activation level in the anterior cingulate cluster (β = −0.15, s.e. = 0.05, t = −2.95), as well as the occipital cortex (β = 0.17, s.e. = 0.03, t = 5.31). Neither gender of the participant, any of the EBQ measures (see Tables   and   for descriptive statistics), or the gender of the depicted person was found to be related to BOLD activation level differences.   
Itemwise mean activation in the occipital cortex. Stimulus items that do not follow the general activation pattern are Item 2, 7, 12, 25, and 28. 
    
Itemwise mean activation in the anterior cingulate cortex. Stimulus items that do not follow the general activation pattern are Item 1, 25, and 28. 
    
Summary of the EBQ responses I. 
    
Summary of the EBQ responses II. 
  



 ## Data Availability

The datasets generated and analysed during the current study will be made available without restriction on Open Science Framework (DOI 10.17605/OSF.IO/CA2U9) upon acceptance of the article for publication, https://osf.io/ca2u9/. https://osf.io/ca2u9/</pre></details></details>
  <details class="inner-accordion"><summary>Coordinate-relevant source tables (2)</summary><details class="inner-accordion"><summary>Table 2 (Tab2) - Increased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing.</summary><div class="table-html"><table-wrap id="Tab2" position="float" orientation="portrait"><label>Table 2</label><caption><p>Increased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing.</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="1" rowspan="1">Location</th><th colspan="1" rowspan="1">k</th><th colspan="1" rowspan="1">T-max</th><th colspan="1" rowspan="1">x</th><th colspan="1" rowspan="1">y</th><th colspan="1" rowspan="1">z</th></tr></thead><tbody><tr><td colspan="1" rowspan="1">left lateral occipital gyrus/BA 18</td><td colspan="1" rowspan="1">3442</td><td colspan="1" rowspan="1">8.08</td><td colspan="1" rowspan="1">−28</td><td colspan="1" rowspan="1">−98</td><td colspan="1" rowspan="1">8</td></tr><tr><td colspan="1" rowspan="1">right lateral occipital gyrus/BA 18</td><td colspan="1" rowspan="1">2377</td><td colspan="1" rowspan="1">6.98</td><td colspan="1" rowspan="1">34</td><td colspan="1" rowspan="1">−90</td><td colspan="1" rowspan="1">2</td></tr><tr><td colspan="1" rowspan="1">right inferior frontal gyrus/BA 44</td><td colspan="1" rowspan="1">230</td><td colspan="1" rowspan="1">5.02</td><td colspan="1" rowspan="1">42</td><td colspan="1" rowspan="1">8</td><td colspan="1" rowspan="1">26</td></tr></tbody></table></table-wrap></div></details><details class="inner-accordion"><summary>Table 3 (Tab3) - Decreased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing.</summary><div class="table-html"><table-wrap id="Tab3" position="float" orientation="portrait"><label>Table 3</label><caption><p>Decreased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing.</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="1" rowspan="1">Location</th><th colspan="1" rowspan="1">k</th><th colspan="1" rowspan="1">T-max</th><th colspan="1" rowspan="1">x</th><th colspan="1" rowspan="1">y</th><th colspan="1" rowspan="1">z</th></tr></thead><tbody><tr><td colspan="1" rowspan="1">left and right anterior cingulate cortex/BA 24</td><td colspan="1" rowspan="1">765</td><td colspan="1" rowspan="1">4.92</td><td colspan="1" rowspan="1">−2</td><td colspan="1" rowspan="1">36</td><td colspan="1" rowspan="1">10</td></tr><tr><td colspan="1" rowspan="1">right calcarine gyrus/BA 18</td><td colspan="1" rowspan="1">247</td><td colspan="1" rowspan="1">4.10</td><td colspan="1" rowspan="1">6</td><td colspan="1" rowspan="1">−88</td><td colspan="1" rowspan="1">12</td></tr></tbody></table></table-wrap></div></details></details>
</details>


<details class="doc-card">
  <summary><strong>PMID 14568477</strong> | Pred included: 4 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/14568477/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>14568477_analysis_0</td><td>Internal &gt; external</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast Internal &gt; External examines attributional decisions about social events (self-responsibility vs other/situational responsibility). This directly measures broad social processing involved in interpreting social information and making social judgments.</td></tr>
<tr><td>14568477_analysis_1</td><td>External &gt; internal</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>External &gt; Internal examines attributions to others or situations for social events, which is clearly a social processing judgment about causal responsibility in interpersonal contexts.</td></tr>
<tr><td>14568477_analysis_2</td><td>Self-serving bias</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The self-serving bias contrast combines internal attributions for positive events and external attributions for negative events — a social-cognitive bias in interpreting interpersonal events — and thus indexes social processing.</td></tr>
<tr><td>14568477_analysis_3</td><td>Non-self-serving bias</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The non-self-serving bias contrast (internal negative, external positive) examines social-cognitive attribution patterns in interpersonal scenarios and therefore measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>14568477_1</td><td>External &gt; internal; others</td><td>14568477_analysis_1</td><td>External &gt; internal</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>14568477_2</td><td>Internal &gt; external; others</td><td>14568477_analysis_0</td><td>Internal &gt; external</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>14568477_3</td><td>Non-self-serving bias &gt; Self-serving bias; others</td><td>14568477_analysis_3</td><td>Non-self-serving bias</td><td>0.677</td><td>1.000</td><td>0.903</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>14568477_4</td><td>Self-serving bias &gt; Non-self-serving bias; others</td><td>14568477_analysis_2</td><td>Self-serving bias</td><td>0.586</td><td>1.000</td><td>0.876</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 14980212</strong> | Pred included: 4 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/14980212/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>14980212_analysis_0</td><td>Affective-Neutral Faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast Affective &gt; Neutral compares faces of cooperators and defectors (socially learned moral status) to neutral faces during an interactive social task. This directly measures social processing (perceiving, interpreting, and responding to social information).</td></tr>
<tr><td>14980212_analysis_1</td><td>Cooperator-Neutral Faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Cooperator &gt; Neutral contrasts faces of socially learned cooperators with neutral faces; this probes social perception, evaluation, and learned social value, meeting social processing criteria.</td></tr>
<tr><td>14980212_analysis_2</td><td>Defector-Neutral Faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Defector &gt; Neutral contrasts faces of learned defectors (cheaters) vs neutral faces; this assesses social evaluative processing of others within an interactive social context.</td></tr>
<tr><td>14980212_analysis_3</td><td>Cerebral Foci of Activation for Intentional versus Nonintentional Cooperator Faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The Intentional &gt; Nonintentional Cooperator contrast examines how attribution of intentionality modulates responses to cooperative faces — a core social processing manipulation (social inference, evaluation).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>14980212_1</td><td>Affective &gt; Neutral faces; socialcommunication</td><td>14980212_analysis_0</td><td>Affective-Neutral Faces</td><td>0.917</td><td>1.000</td><td>0.975</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>14980212_2</td><td>Cooperator &gt; Neutral faces; socialcommunication</td><td>14980212_analysis_1</td><td>Cooperator-Neutral Faces</td><td>0.920</td><td>1.000</td><td>0.976</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>14980212_3</td><td>Defector &gt; Neutral faces; socialcommunication</td><td>14980212_analysis_2</td><td>Defector-Neutral Faces</td><td>0.913</td><td>1.000</td><td>0.974</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 15006683</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/15006683/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>15006683_analysis_0</td><td>Relational vs. alone segment</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares relational (interactive) movie segments to alone segments and rest, directly probing social processing (perception and interpretation of social interactions). The task is explicitly social and the reported activations (dorsomedial PFC, precuneus, STS, IFG, fusiform) reflect social-cognitive processing beyond rest.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>15006683_1</td><td>Relational &gt; alone; others</td><td>15006683_analysis_0</td><td>Relational vs. alone segment</td><td>0.739</td><td>1.000</td><td>0.922</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 15488424</strong> | Pred included: 4 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/15488424/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>15488424_analysis_0</td><td>Cooperation versus independent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast Cooperation vs Independent involves an explicit social interaction (cooperating with another person) and measures social processing (monitoring others&#x27; actions, joint goal pursuit).</td></tr>
<tr><td>15488424_analysis_1</td><td>Competition versus independent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast Competition vs Independent involves explicit social interaction (competing against another) and measures social processing, including monitoring and predicting the opponent.</td></tr>
<tr><td>15488424_analysis_2</td><td>Cooperation versus competition</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Cooperation vs Competition directly contrasts two social interaction states; both are social tasks and the contrast measures social processing differences between them.</td></tr>
<tr><td>15488424_analysis_3</td><td>Competition versus cooperation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Competition vs Cooperation contrasts two social interaction conditions and measures social processing related to competitive stance and associated mentalizing/executive processes.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>15488424_1</td><td>Competition versus cooperation; affiliation</td><td>15488424_analysis_3</td><td>Competition versus cooperation</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>15488424_2</td><td>Competition versus independent; affiliation</td><td>15488424_analysis_1</td><td>Competition versus independent</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>15488424_3</td><td>Cooperation versus competition; affiliation</td><td>15488424_analysis_2</td><td>Cooperation versus competition</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>15488424_4</td><td>Cooperation versus independent; affiliation</td><td>15488424_analysis_0</td><td>Cooperation versus independent</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 15528097</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=4</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/15528097/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Embarrassment &gt; Neutral; socialcommunication, Embarrassment &gt; guilt; socialcommunication, Guilt &gt; Embarrassment; socialcommunication, Guilt &gt; Neutral; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>15528097_analysis_0</td><td>Brain regions commonly activated by guilt and embarrassment conditions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task required reading first-person sentences describing social situations and making evaluative judgments about guilt and embarrassment — clearly a social-related task probing social cognition and Theory of Mind. The contrasts (guilt vs neutral; embarrassment vs neutral) directly measure social processing related to self-conscious emotions.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>15528097_1</td><td>Embarrassment &gt; Neutral; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>15528097_2</td><td>Embarrassment &gt; guilt; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>15528097_3</td><td>G &gt; N masked E &gt; N; socialcommunication</td><td>15528097_analysis_0</td><td>Brain regions commonly activated by guilt and embarrassment conditions</td><td>0.275</td><td>1.000</td><td>0.783</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>15528097_4</td><td>Guilt &gt; Embarrassment; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>15528097_5</td><td>Guilt &gt; Neutral; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 15808992</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/15808992/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>15808992_analysis_0</td><td>self-other contrast</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The self–other morph discrimination is explicitly a social task: participants judge identity (self vs familiar other) of faces, engaging social perception and self/other representations. This directly measures social processing related constructs (self/other perception, social cognition).</td></tr>
<tr><td>15808992_analysis_1</td><td>other-self contrast</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The other–self contrast involves processing of familiar others versus self and engages social cognition (processing socially relevant, familiar faces). This meets the Social Processing inclusion criterion.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>15808992_1</td><td>Other - Self; socialcommunication</td><td>15808992_analysis_1</td><td>other-self contrast</td><td>0.645</td><td>1.000</td><td>0.894</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>15808992_2</td><td>Self - Other; socialcommunication</td><td>15808992_analysis_0</td><td>self-other contrast</td><td>0.645</td><td>1.000</td><td>0.894</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 16035037</strong> | Pred included: 5 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/16035037/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>16035037_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task contrasts viewing unknown (distracter) faces vs scrambled baseline—this is a social-related face perception task assessing social processing of faces.</td></tr>
<tr><td>16035037_analysis_1</td><td>familiar minus distracter contrast</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Familiar vs distracter contrast is a social task comparing personally familiar (fraternity brother) to unfamiliar faces, thus assessing social processing.</td></tr>
<tr><td>16035037_analysis_2</td><td>Local maxima of CBF change during self minus distracter contrast corrected at P = 0.001 and cluster at P = 0.05</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Self vs distracter contrast is a social task (self-face recognition vs unfamiliar faces) and assesses social cognitive processing related to self/other distinctions.</td></tr>
<tr><td>16035037_analysis_3</td><td>Local Maxima of CBF change during familiar minus self contrast</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Familiar &gt; Self contrast is a social task comparing personally familiar faces to self, thus engaging social processing systems.</td></tr>
<tr><td>16035037_analysis_4</td><td>CBF change during self minus familiar contrast</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Self &gt; Familiar contrast is a social-related task directly assessing self vs other face-processing and broader social cognitive processes.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>16035037_1</td><td>distracter &gt; null; socialcommunication</td><td>16035037_analysis_0</td><td>analysis_0</td><td>0.148</td><td>1.000</td><td>0.744</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16035037_2</td><td>familiar face &gt; distracter; socialcommunication</td><td>16035037_analysis_1</td><td>familiar minus distracter contrast</td><td>0.667</td><td>1.000</td><td>0.900</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>16035037_3</td><td>familiar face &gt; self face; socialcommunication</td><td>16035037_analysis_3</td><td>Local Maxima of CBF change during familiar minus self contrast</td><td>0.370</td><td>1.000</td><td>0.811</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16035037_4</td><td>self face &gt; distracter; socialcommunication</td><td>16035037_analysis_2</td><td>Local maxima of CBF change during self minus distracter contrast corrected at P = 0.001 and cluster at P = 0.05</td><td>0.312</td><td>1.000</td><td>0.794</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16035037_5</td><td>self face &gt; famililar face; socialcommunication</td><td>16035037_analysis_4</td><td>CBF change during self minus familiar contrast</td><td>0.444</td><td>1.000</td><td>0.833</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 16055351</strong> | Pred included: 7 | Manual included (accepted matches only): 7 | Correct overlaps: 7 | Match statuses: accepted=7, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/16055351/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>16055351_analysis_0</td><td>Anger vs. Neutral (AN + NA) vs. (NN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast compares angry vs. neutral prosody in voices (AN+NA vs NN). This is a social-related task assessing processing of emotional social cues in voices, meeting Social Processing inclusion I1.</td></tr>
<tr><td>16055351_analysis_1</td><td>Anger to-be-attended vs. Neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast isolates anger prosody when it is to-be-attended vs. neutral — a social-related task assessing processing of emotional social cues in voices. Meets Social Processing I1.</td></tr>
<tr><td>16055351_analysis_2</td><td>Anger to-be-ignored vs. Neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast examines anger prosody presented to-be-ignored vs neutral — the task still involves processing social-emotional vocal cues, so it meets Social Processing I1.</td></tr>
<tr><td>16055351_analysis_3</td><td>Anger to-be-attended vs. to-be-ignored</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast directly compares anger prosody when to-be-attended vs to-be-ignored — a manipulation of socially relevant vocal emotion and attention, meeting Social Processing I1.</td></tr>
<tr><td>16055351_analysis_4</td><td>Anger to-be-ignored vs. to-be-attended</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast (anger to-be-ignored vs to-be-attended) still concerns processing of emotional prosody in voices; the task is social in nature and meets Social Processing I1.</td></tr>
<tr><td>16055351_analysis_5</td><td>Spatial attention towards right vs. left ear</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Spatial attention to right vs left ear was manipulated within a task using social stimuli (voices, emotional prosody). Although the contrast is spatial attention, the task context is social communication, so it meets Social Processing I1.</td></tr>
<tr><td>16055351_analysis_6</td><td>Spatial attention towards left vs. right ear</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Spatial attention to left vs right ear contrast was performed in the context of a voice-based task with emotional prosody; the overall study assesses social processing and this contrast is part of that. Meets Social Processing I1.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>16055351_1</td><td>Anger &gt; Neutral (AN + NA) &gt; (NN); socialcommunication</td><td>16055351_analysis_0</td><td>Anger vs. Neutral (AN + NA) vs. (NN)</td><td>0.882</td><td>0.889</td><td>0.887</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>16055351_2</td><td>Anger to be attended &gt; to be ignored; socialcommunication</td><td>16055351_analysis_3</td><td>Anger to-be-attended vs. to-be-ignored</td><td>0.838</td><td>0.800</td><td>0.811</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>16055351_3</td><td>Anger to-be-attended &gt; Neutral; socialcommunication</td><td>16055351_analysis_1</td><td>Anger to-be-attended vs. Neutral</td><td>0.935</td><td>1.000</td><td>0.981</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>16055351_4</td><td>Anger to-be-ignored &gt; Neutral; socialcommunication</td><td>16055351_analysis_2</td><td>Anger to-be-ignored vs. Neutral</td><td>0.933</td><td>1.000</td><td>0.980</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>16055351_5</td><td>anger to be ignored &gt; to be attended; socialcommunication</td><td>16055351_analysis_4</td><td>Anger to-be-ignored vs. to-be-attended</td><td>0.838</td><td>1.000</td><td>0.951</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>16055351_6</td><td>spatial attention to left ear &gt; right ear; socialcommunication</td><td>16055351_analysis_6</td><td>Spatial attention towards left vs. right ear</td><td>0.847</td><td>0.889</td><td>0.876</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>16055351_7</td><td>spatial attention to right ear&gt; left ear; socialcommunication</td><td>16055351_analysis_5</td><td>Spatial attention towards right vs. left ear</td><td>0.847</td><td>1.000</td><td>0.954</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 16122944</strong> | Pred included: 5 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/16122944/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>16122944_analysis_0</td><td>‘ToM’ - ‘Physical 1’</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast (‘ToM’ − ‘Physical 1’) probes social cognitive processes (theory of mind) using cartoon stories requiring inference about others’ intentions; thus it measures social processing broadly.</td></tr>
<tr><td>16122944_analysis_1</td><td>‘Empathy’ - ‘Physical 2’</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The (‘Empathy’ − ‘Physical 2’) contrast probes social cognitive processing of others’ emotions (empathy) using cartoon narratives, thus measuring social processing.</td></tr>
<tr><td>16122944_analysis_2</td><td>Conjuction analysis</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The conjunction identifies areas commonly active for ToM and empathy; both conditions are social tasks, so the conjunction reflects broad social processing.</td></tr>
<tr><td>16122944_analysis_3</td><td>(‘ToM’ - ‘Physical 1’) - (‘Empathy’ - ‘Physical 2’)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The interaction (‘ToM’ − ‘Physical 1’) − (‘Empathy’ − ‘Physical 2’) identifies regions more engaged by ToM than empathy; both are social cognitive operations, so this contrast remains within broad social processing.</td></tr>
<tr><td>16122944_analysis_4</td><td>(‘Empathy’ - ‘Physical 2’) - (‘ToM’ - ‘Physical 1’)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The interaction (‘Empathy’ − ‘Physical 2’) − (‘ToM’ − ‘Physical 1’) isolates empathy-specific activations (amygdala, cingulate, mPFC); empathy is a social process, so this reflects social processing broadly.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>16122944_1</td><td>(Empathy - Physical 2) - (ToM - Physical 1); others</td><td>16122944_analysis_4</td><td>(‘Empathy’ - ‘Physical 2’) - (‘ToM’ - ‘Physical 1’)</td><td>0.915</td><td>1.000</td><td>0.974</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>16122944_2</td><td>(ToM - Physical 1) - (Empathy - Physical 2); others</td><td>16122944_analysis_3</td><td>(‘ToM’ - ‘Physical 1’) - (‘Empathy’ - ‘Physical 2’)</td><td>0.915</td><td>1.000</td><td>0.974</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>16122944_3</td><td>Conjunction Analysis; others</td><td>16122944_analysis_2</td><td>Conjuction analysis</td><td>0.974</td><td>1.000</td><td>0.992</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>16122944_4</td><td>Empathy - Physical 2; others</td><td>16122944_analysis_1</td><td>‘Empathy’ - ‘Physical 2’</td><td>0.909</td><td>1.000</td><td>0.973</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>16122944_5</td><td>ToM - Physical 1; others</td><td>16122944_analysis_0</td><td>‘ToM’ - ‘Physical 1’</td><td>0.889</td><td>1.000</td><td>0.967</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 16171833</strong> | Pred included: 6 | Manual included (accepted matches only): 6 | Correct overlaps: 6 | Match statuses: accepted=6, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/16171833/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>16171833_analysis_0</td><td>a) Common activations of social interaction (SOC &gt; ARB)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast SOC&gt;ARB directly tests perception of socially relevant facial expressions versus arbitrary movements, a canonical social-processing manipulation. It therefore measures social processing broadly (perception and interpretation of social cues).</td></tr>
<tr><td>16171833_analysis_1</td><td>b) Common activations of arbitrary facial movements (ARB &gt; SOC)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast ARB&gt;SOC examines neural responses to facial movements lacking social meaning versus socially relevant expressions; this still probes social processing by contrasting social/non-social face cues.</td></tr>
<tr><td>16171833_analysis_2</td><td>c) Common activations of self-involvement (ME &gt; OTHER)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast ME&gt;OTHER manipulates self-involvement (being gazed at) versus observing others, clearly a social manipulation assessing how social context affects neural responses.</td></tr>
<tr><td>16171833_analysis_3</td><td>d) Common activations of other-related activity (OTHER &gt; ME)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>OTHER&gt;ME contrasts observing others-directed behavior versus being addressed oneself, a social task probing processing of social scenes and perspective-taking, thus indexing social processing broadly.</td></tr>
<tr><td>16171833_analysis_4</td><td>e) Common activations of the statistical interaction SOC × ME</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The interaction SOC×ME isolates neural processes when socially relevant expressions are self-directed versus other-directed, a social-processing interaction combining self-involvement and communicative content.</td></tr>
<tr><td>16171833_analysis_5</td><td>f) Common activations of the statistical interaction SOC × OTHER</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>SOC×OTHER isolates processing of socially relevant expressions when directed to someone else, a social-processing contrast probing how social cues are represented in a third-person context.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>16171833_1</td><td>ARB &gt; SOC; socialcommunication</td><td>16171833_analysis_1</td><td>b) Common activations of arbitrary facial movements (ARB &gt; SOC)</td><td>0.250</td><td>1.000</td><td>0.775</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16171833_2</td><td>ME &gt; OTHER; socialcommunication</td><td>16171833_analysis_2</td><td>c) Common activations of self-involvement (ME &gt; OTHER)</td><td>0.312</td><td>1.000</td><td>0.794</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16171833_3</td><td>OTHER &gt; ME; socialcommunication</td><td>16171833_analysis_3</td><td>d) Common activations of other-related activity (OTHER &gt; ME)</td><td>0.286</td><td>1.000</td><td>0.786</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16171833_4</td><td>SOC &gt; ARB; socialcommunication</td><td>16171833_analysis_0</td><td>a) Common activations of social interaction (SOC &gt; ARB)</td><td>0.281</td><td>1.000</td><td>0.784</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16171833_5</td><td>SOC x ME&gt;Other; socialcommunication</td><td>16171833_analysis_4</td><td>e) Common activations of the statistical interaction SOC × ME</td><td>0.245</td><td>1.000</td><td>0.773</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16171833_6</td><td>SOC x OTHER&gt; ME; socialcommunication</td><td>16171833_analysis_5</td><td>f) Common activations of the statistical interaction SOC × OTHER</td><td>0.250</td><td>1.000</td><td>0.775</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 16406606</strong> | Pred included: 2 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/16406606/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>16406606_analysis_0</td><td>Active conditions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task required subjects to judge whether visual cursor movement was feedback from their own movement (self) or not (other). This directly involves perception/understanding of self vs other, which falls under broad Social Processing constructs per I1.</td></tr>
<tr><td>16406606_analysis_1</td><td>Passive conditions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>As in the active condition, subjects judged ownership of visual feedback (self vs non-self) during passive movement; this involves perception/understanding of self and other and therefore falls under Social Processing per I1.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>16406606_1</td><td>Active conditions &gt; passive conditions; others</td><td>16406606_analysis_1</td><td>Passive conditions</td><td>0.643</td><td>1.000</td><td>0.893</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 16759672</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/16759672/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> faces associated with nice behaviors &gt; faces associated with neutral behaviors; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>16759672_analysis_0</td><td>Areas showing significantly greater activity for faces associated with behaviors than for novel faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast compares faces associated with learned social behaviors vs novel faces, directly assessing spontaneous retrieval of person knowledge and engagement of social-cognitive systems (APC, STS). Measures social processing.</td></tr>
<tr><td>16759672_analysis_1</td><td>Faces associated with disgusting behaviors greater than faces associated with aggressive behaviors</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast differentiates faces based on learned social/emotional behaviors (disgusting vs aggressive), probing social-cognitive and affective processing systems; thus measures social processing.</td></tr>
<tr><td>16759672_analysis_2</td><td>Faces associated with aggressive behaviors greater than faces associated with disgusting behaviors</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast (aggressive &gt; disgusting) examines socially relevant trait information bound to faces, engaging social-cognitive processing; therefore included.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>16759672_1</td><td>face associated with behavior &gt; novel faces; socialcommunication</td><td>16759672_analysis_0</td><td>Areas showing significantly greater activity for faces associated with behaviors than for novel faces</td><td>0.583</td><td>1.000</td><td>0.875</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>16759672_2</td><td>faces associated with aggressive behaviors &gt; faces associated with disgusting behaviors; socialcommunication</td><td>16759672_analysis_2</td><td>Faces associated with aggressive behaviors greater than faces associated with disgusting behaviors</td><td>0.930</td><td>1.000</td><td>0.979</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>16759672_3</td><td>faces associated with disgusting behaviors &gt; faces associated with aggressive behaviors; socialcommunication</td><td>16759672_analysis_1</td><td>Faces associated with disgusting behaviors greater than faces associated with aggressive behaviors</td><td>0.930</td><td>0.944</td><td>0.940</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>16759672_4</td><td>faces associated with nice behaviors &gt; faces associated with neutral behaviors; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 17071110</strong> | Pred included: 3 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=2, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/17071110/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Retaliation interaction with low CU &gt; High CU; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>17071110_analysis_0</td><td>Receiving aversive stimuli; parametric modulation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The condition involves a social interactive task (competitive reaction-time paradigm) where subjects observe an opponent adjusting aversive stimulus intensity and anticipate punishment. This clearly measures social processing (perceiving, interpreting, and responding to social information).</td></tr>
<tr><td>17071110_analysis_1</td><td>Retaliation; parametric modulation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Retaliation involves explicit social interaction (deciding punishment to an opponent) and engages processing of social information and decisions in an interpersonal context, meeting broad social processing criteria.</td></tr>
<tr><td>17071110_analysis_2</td><td>Conjunction; retaliation and watching the opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The conjunction combines retaliation and watching the opponent—both are social-interactive conditions requiring perception, interpretation, and response to social information, meeting broad social processing criteria.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>17071110_1</td><td>Retaliation &gt; Watching opponent; socialcommunication</td><td>17071110_analysis_1</td><td>Retaliation; parametric modulation</td><td>0.554</td><td>0.750</td><td>0.691</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>17071110_2</td><td>Retaliation interaction with low CU &gt; High CU; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>17071110_3</td><td>Watching opponent &gt; Retaliation; socialcommunication</td><td>17071110_analysis_0</td><td>Receiving aversive stimuli; parametric modulation</td><td>0.375</td><td>0.842</td><td>0.702</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>17071110_4</td><td>Watching opponent &gt; Retaliation (conjunction); socialcommunication</td><td>17071110_analysis_2</td><td>Conjunction; retaliation and watching the opponent</td><td>0.484</td><td>0.900</td><td>0.775</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 17408704</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/17408704/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>17408704_analysis_0</td><td>EMO</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The EMO analysis is an explicit emotion recognition task using faces, which is a canonical social processing task (perceiving and interpreting others&#x27; emotions). It directly measures social processing.</td></tr>
<tr><td>17408704_analysis_1</td><td>AGE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The AGE analysis uses faces and assesses implicit emotional processing (age discrimination on faces). Although the task focuses on age, it still involves social face processing and measures social perception.</td></tr>
<tr><td>17408704_analysis_2</td><td>EMO-AGE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The EMO-AGE contrast directly assesses differences in social/emotional face processing between explicit and implicit tasks, thus indexing social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>17408704_1</td><td>explicit (emotion) &gt; baseline; socialcommunication</td><td>17408704_analysis_0</td><td>EMO</td><td>0.188</td><td>1.000</td><td>0.756</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>17408704_2</td><td>explicit (emotion) &gt; implicit (age); socialcommunication</td><td>17408704_analysis_2</td><td>EMO-AGE</td><td>0.286</td><td>1.000</td><td>0.786</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>17408704_3</td><td>implicit (age) &gt; baseline; socialcommunication</td><td>17408704_analysis_1</td><td>AGE</td><td>0.214</td><td>1.000</td><td>0.764</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 17627852</strong> | Pred included: 4 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/17627852/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>17627852_analysis_0</td><td>Communication—control</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Communication vs Control contrast measures communicative speech directed at another person (video actor) and involves social interaction processes; meets inclusion criterion for social-related tasks.</td></tr>
<tr><td>17627852_analysis_1</td><td>Description—control</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Description vs Control contrast requires observing and verbally describing another person&#x27;s actions and situation, engaging social perceptual and interpretive processes.</td></tr>
<tr><td>17627852_analysis_2</td><td>Communication— description</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Communication vs Description contrast isolates behavioral/social aspects of communicative speech production and explicitly targets social interaction processes, satisfying the social processing criterion.</td></tr>
<tr><td>17627852_analysis_3</td><td>Familiar communication – unfamiliar communication</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Familiar Communication vs Unfamiliar Communication contrast directly manipulates the social variable of familiarity and examines how social processing differs with a known vs unknown target, clearly a social task.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>17627852_1</td><td>Communication &gt; Description; socialcommunication</td><td>17627852_analysis_2</td><td>Communication— description</td><td>0.943</td><td>0.714</td><td>0.783</td><td>accepted</td><td>coord_count_mismatch</td></tr><tr><td>17627852_2</td><td>Communication &gt; control; socialcommunication</td><td>17627852_analysis_0</td><td>Communication—control</td><td>0.909</td><td>1.000</td><td>0.973</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>17627852_3</td><td>Description &gt; control; socialcommunication</td><td>17627852_analysis_1</td><td>Description—control</td><td>0.900</td><td>1.000</td><td>0.970</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>17627852_4</td><td>Familiar communication &gt; unfamiliar communication; socialcommunication</td><td>17627852_analysis_3</td><td>Familiar communication – unfamiliar communication</td><td>0.980</td><td>1.000</td><td>0.994</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18486491</strong> | Pred included: 4 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18486491/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18486491_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Analysis derives from the PD vs. Gamble contrast and identifies a network active during social interaction (Prisoner’s Dilemma), directly measuring social processing.</td></tr>
<tr><td>18486491_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This table/analysis pertains to the social interactive task (PD) and its neural correlates, so it measures social processing.</td></tr>
<tr><td>18486491_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This analysis correlates behavioral discrimination (cooperation difference) with BOLD differences for in-group vs out-group—direct measure of social processing.</td></tr>
<tr><td>18486491_analysis_3</td><td>DMPFC connectivity with in-group - DMPFC connectivity with out-group</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This analysis compares DMPFC functional connectivity between in-group and out-group interactions—directly addressing social neural processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18486491_1</td><td>PD – Gamble; affiliation</td><td>18486491_analysis_0</td><td>analysis_0</td><td>0.190</td><td>1.000</td><td>0.757</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18501639</strong> | Pred included: 15 | Manual included (accepted matches only): 8 | Correct overlaps: 8 | Match statuses: accepted=8, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18501639/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18501639_analysis_0</td><td>Main effect [(Sf + Sn)–(Ff + Fn) masked by Sf–Ff and Sn–Fn]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Contrast compares self vs friend across face and name recognition — a social-related task addressing self/other social processing across modalities.</td></tr>
<tr><td>18501639_analysis_1</td><td>Face (simple effect) [Sf–Ff]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Face-specific self &gt; friend contrast examines social processing during face recognition, a social task.</td></tr>
<tr><td>18501639_analysis_2</td><td>Name (simple effect) [Sn–Fn]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Name-based self &gt; friend contrast probes social processing for person-identifying stimuli (written names).</td></tr>
<tr><td>18501639_analysis_3</td><td>Face specific (interaction) [(Sf–Ff)–(Sn–Fn) masked by Sf–Ff]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Interaction isolating face-specific self effects examines social processing specific to faces (a social domain).</td></tr>
<tr><td>18501639_analysis_4</td><td>Name specific (interaction) [(Sn–Fn)–(Sf–Ff) masked by Sn–Fn]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Interaction isolating name-specific self effects probes social processing for name stimuli (social identity cues).</td></tr>
<tr><td>18501639_analysis_5</td><td>Main effect [(Ff + Fn)–(Sf + Sn) masked by Ff–Sf and Fn–Sn]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Friend &gt; Self (across face and name) contrast examines social processing related to familiar others, a social task.</td></tr>
<tr><td>18501639_analysis_6</td><td>Face (simple effect) [Ff–Sf]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Face-based Friend &gt; Self contrast taps social processing during face recognition of a familiar person.</td></tr>
<tr><td>18501639_analysis_7</td><td>Name (simple effect) [Fn–Sn]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Name-based Friend &gt; Self contrast involves social processing of person identity via names.</td></tr>
<tr><td>18501639_analysis_8</td><td>Face specific (interaction) [(Ff–Sf)–(Fn–Sn) masked by Ff–Sf]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Interaction isolating face-specific friend effects examines social processing related to familiar others in face modality.</td></tr>
<tr><td>18501639_analysis_9</td><td>Name specific (interaction) [(Fn–Sn)–(Ff–Sf) masked by Fn–Sn]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Name-specific friend interaction probes social processing for familiar others in the name modality.</td></tr>
<tr><td>18501639_analysis_10</td><td>Main effect [(Sf + Ff + Sn + Fn)–2(Cf + Cn) masked by Sf–Cf, Ff–Cf, Sn–Cn, and Fn–Cn]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Familiarity contrast (self+friend vs unfamiliar) directly probes social processing related to person familiarity across modalities.</td></tr>
<tr><td>18501639_analysis_11</td><td>Face (simple effect) [Sf + Ff–2Cf masked by Sf–Cf, and Ff–Cf]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Face-based familiarity (self+friend &gt; control) examines social processing of familiar faces versus unfamiliar faces.</td></tr>
<tr><td>18501639_analysis_12</td><td>Name (simple effect) [Sn + Fn–2Cn masked by Sn–Cn, and Fn–Cn]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Name-based familiarity contrast probes social processing of familiar vs unfamiliar names across modalities.</td></tr>
<tr><td>18501639_analysis_13</td><td>Face specific (interaction) [(Sf + Ff–2Cf)–(Sn + Fn–2Cn) masked by Sf + Ff–2Cf]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Face-specific familiarity interaction examines modality-specific social processing for familiar faces vs names.</td></tr>
<tr><td>18501639_analysis_14</td><td>Name specific (interaction) [(Sn + Fn–2Cn)–(Sf + Ff–2Cf) masked by Sn + Fn–2Cn]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Name-specific familiarity interaction probes social processing for names (non-facial modality) and familiar vs unfamiliar persons.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18501639_1</td><td>Face (simple effect) [Ff–Sf]; socialcommunication</td><td>18501639_analysis_6</td><td>Face (simple effect) [Ff–Sf]</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18501639_2</td><td>Face (simple effect) [Sf+Ff–2Cf masked by Sf–Cf, and Ff–Cf]; socialcommunication</td><td>18501639_analysis_11</td><td>Face (simple effect) [Sf + Ff–2Cf masked by Sf–Cf, and Ff–Cf]</td><td>0.983</td><td>1.000</td><td>0.995</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18501639_3</td><td>Face (simple effect) [Sf–Ff]; socialcommunication</td><td>18501639_analysis_1</td><td>Face (simple effect) [Sf–Ff]</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18501639_4</td><td>Face specific (interaction) [(Sf+Ff–2Cf)–(Sn+Fn–2Cn) masked by Sf+Ff–2Cf]; socialcommunication</td><td>18501639_analysis_13</td><td>Face specific (interaction) [(Sf + Ff–2Cf)–(Sn + Fn–2Cn) masked by Sf + Ff–2Cf]</td><td>0.961</td><td>1.000</td><td>0.988</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18501639_5</td><td>Face specific (interaction) [(Sf–Ff)–(Sn–Fn) masked by Sf–Ff]; socialcommunication</td><td>18501639_analysis_3</td><td>Face specific (interaction) [(Sf–Ff)–(Sn–Fn) masked by Sf–Ff]</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18501639_6</td><td>Main effect [(Ff+Fn)–(Sf+Sn) masked by Ff–Sf and Fn–Sn]; socialcommunication</td><td>18501639_analysis_5</td><td>Main effect [(Ff + Fn)–(Sf + Sn) masked by Ff–Sf and Fn–Sn]</td><td>0.965</td><td>1.000</td><td>0.989</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18501639_7</td><td>Main effect [(Sf+Ff+Sn+Fn)–2(Cf+Cn) masked by Sf–Cf, Ff–Cf, Sn–Cn, and Fn–Cn]; socialcommunication</td><td>18501639_analysis_10</td><td>Main effect [(Sf + Ff + Sn + Fn)–2(Cf + Cn) masked by Sf–Cf, Ff–Cf, Sn–Cn, and Fn–Cn]</td><td>0.951</td><td>0.667</td><td>0.752</td><td>accepted</td><td></td></tr><tr><td>18501639_8</td><td>Name (simple effect) [Sn+Fn–2Cn masked by Sn–Cn, and Fn–Cn]; socialcommunication</td><td>18501639_analysis_12</td><td>Name (simple effect) [Sn + Fn–2Cn masked by Sn–Cn, and Fn–Cn]</td><td>0.983</td><td>1.000</td><td>0.995</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18514546</strong> | Pred included: 6 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18514546/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18514546_analysis_0</td><td>SELF versus high-level baseline</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The SELF vs high-level baseline contrast is an empathy-related social task probing emotional perspective taking (self-focused), which clearly measures social processing across interpersonal contexts.</td></tr>
<tr><td>18514546_analysis_1</td><td>OTHER versus high-level baseline</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The OTHER vs high-level baseline contrast is an empathy-related social task (attribution of emotion to others) and thus measures social processing.</td></tr>
<tr><td>18514546_analysis_2</td><td>Correlations between mirror neuron activation in the SELF/OTHER task and individual empathy scores (BEES)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The correlations examine neural activation related to empathy (mirror neuron regions) and dispositional empathic scores across tasks—this addresses social processing broadly.</td></tr>
<tr><td>18514546_analysis_3</td><td>Interaction (SELF_f – B_f) – (SELF_m – B_m)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This interaction tests gender differences in SELF-related activation (SELF_f – B_f) – (SELF_m – B_m), probing social-empathic processing and gender modulation—therefore social processing is measured.</td></tr>
<tr><td>18514546_analysis_4</td><td>Interaction (SELF_m – B_m) – (SELF_f – B_f)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This interaction reverses the gender comparison for SELF-related activation (SELF_m – B_m) – (SELF_f – B_f) and still probes social-empathic processing; social processing is measured.</td></tr>
<tr><td>18514546_analysis_5</td><td>Interaction (OTHER_f – B_f) – (OTHER_m – B_m)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This interaction tests gender differences for the OTHER task (OTHER_f – B_f) – (OTHER_m – B_m), which probes social-empathic processing of others&#x27; emotions and thus measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18514546_1</td><td>Other &gt; high-level baseline; socialcommunication</td><td>18514546_analysis_1</td><td>OTHER versus high-level baseline</td><td>0.881</td><td>1.000</td><td>0.964</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18514546_2</td><td>Self &gt; high-level baseline; socialcommunication</td><td>18514546_analysis_0</td><td>SELF versus high-level baseline</td><td>0.877</td><td>1.000</td><td>0.963</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18537114</strong> | Pred included: 2 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18537114/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18537114_analysis_0</td><td>P</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This analysis (Pavlovian water reward task) is a non-social Pavlovian conditioning task using thirsty subjects and water delivery; it does not involve social stimuli or interactions. Does not meet inclusion criteria for social processing.</td></tr>
<tr><td>18537114_analysis_1</td><td>S</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The Social task is explicitly a social motor response learning paradigm involving animated other agents, social inclusion/exclusion, and learning about social inclusion as reinforcement—this directly measures social processing.</td></tr>
<tr><td>18537114_analysis_2</td><td>Brain activation in Pavlovian compared with social task</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This analysis compares Pavlovian and Social tasks and identifies regions with stronger TD signals in the Social task (e.g., frontal operculum, dAC), thereby measuring social processing differences.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18537114_1</td><td>Pavlovian &gt; with social task; affiliation</td><td>18537114_analysis_2</td><td>Brain activation in Pavlovian compared with social task</td><td>0.651</td><td>1.000</td><td>0.895</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18633788</strong> | Pred included: 16 | Manual included (accepted matches only): 13 | Correct overlaps: 13 | Match statuses: accepted=13, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18633788/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18633788_analysis_0</td><td>Stories &gt; Rest</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Stories present and interpret social rules (social-exchange, precautionary, descriptive); this contrast (Stories &gt; Rest) examines brain activity during interpretation of social-rule stories, so it measures social processing.</td></tr>
<tr><td>18633788_analysis_1</td><td>Rest &gt; Stories</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast is the inverse of the story-based condition from the same social-rule task; although it reflects deactivations, it is derived from a social cognitive paradigm and thus pertains to social processing.</td></tr>
<tr><td>18633788_analysis_2</td><td>Cards&gt;Rest</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Card responses require subjects to evaluate potential violations of social rules (including social-exchange and precautionary rules), so this contrast measures social processing during decision-making.</td></tr>
<tr><td>18633788_analysis_3</td><td>Rest&gt;Cards</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Rest &gt; Cards is part of the same social-rule decision-making paradigm; although it reflects relative deactivations, the underlying task is social, so the contrast is linked to social processing.</td></tr>
<tr><td>18633788_analysis_4</td><td>Stories: Social Contracts &gt; Precautions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast specifically compares social-exchange (social contract) story interpretation to precaution stories; it directly probes social processing related to social-exchange reasoning.</td></tr>
<tr><td>18633788_analysis_5</td><td>Stories: Social Contracts &gt; Descriptives</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Stories contrasting social contracts versus descriptive rules probe social-exchange-specific interpretive processing and therefore social processing.</td></tr>
<tr><td>18633788_analysis_6</td><td>Cards: Social Contracts &gt; Precautions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Card-phase contrast for social contracts versus precautions targets decision-making about social-rule violations (cheater detection), reflecting social processing during choices.</td></tr>
<tr><td>18633788_analysis_7</td><td>Cards: Social Contracts &gt; Descriptives</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Card-phase social-contract vs descriptive contrast examines decision processes about potential violations of social rules and is part of the social-processing task.</td></tr>
<tr><td>18633788_analysis_8</td><td>Stories: Precautions &gt; Social Contracts</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast probes interpretation of precautionary versus social-exchange stories; precautionary stories are social in that they concern people’s actions and safety, so it is linked to social processing.</td></tr>
<tr><td>18633788_analysis_9</td><td>Stories: Precautions &gt; Descriptives</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Precautionary stories concern people’s behavior in hazardous contexts and thus fall under social processing; this contrast examines those interpretive processes relative to descriptive stories.</td></tr>
<tr><td>18633788_analysis_10</td><td>Cards: Precautions &gt; Social Contracts</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Card-based precaution vs social contract contrast involves evaluating others’ actions with respect to rules (danger vs cheating) and thus pertains to social processing during decision-making.</td></tr>
<tr><td>18633788_analysis_11</td><td>Cards: Precautions &gt; Descriptives</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Cards contrast (Precautions &gt; Descriptives) examines decision processes about rule violations concerning people’s safety—part of social processing in the task context.</td></tr>
<tr><td>18633788_analysis_12</td><td>Stories: Descriptives &gt; Social Contracts</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Descriptive stories concern people’s habits/preferences and are part of the social-rule story set; this contrast (Descriptives &gt; Social Contracts) involves social content and thus social processing.</td></tr>
<tr><td>18633788_analysis_13</td><td>Stories: Descriptives &gt; Precautions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Descriptive vs precautionary story contrast engages processing of social-content stories about people’s traits/hazards and thus relates to social processing.</td></tr>
<tr><td>18633788_analysis_14</td><td>Cards: Descriptives &gt; Social Contracts</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Card-based Descriptives &gt; Social Contracts contrast examines decision processes about others’ behaviors and rule violations; this is embedded in the social-rule task and pertains to social processing.</td></tr>
<tr><td>18633788_analysis_15</td><td>Cards: Descriptives &gt; Precautions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Cards contrast (Descriptives &gt; Precautions) evaluates others’ behaviors against descriptive vs precautionary rules and is part of the social-rule decision-making paradigm, so it is relevant to social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18633788_1</td><td>Cards &gt; Rest; others</td><td>18633788_analysis_2</td><td>Cards&gt;Rest</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633788_10</td><td>Stories: Precautions &gt; Descriptives; others</td><td>18633788_analysis_9</td><td>Stories: Precautions &gt; Descriptives</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633788_11</td><td>Stories: Precautions &gt; Social Contracts; others</td><td>18633788_analysis_8</td><td>Stories: Precautions &gt; Social Contracts</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633788_12</td><td>Stories: Social Contracts &gt; Descriptives; others</td><td>18633788_analysis_5</td><td>Stories: Social Contracts &gt; Descriptives</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633788_13</td><td>Stories: Social Contracts &gt; Precautions; others</td><td>18633788_analysis_4</td><td>Stories: Social Contracts &gt; Precautions</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633788_2</td><td>Cards: Descriptives &gt; Precautions; others</td><td>18633788_analysis_15</td><td>Cards: Descriptives &gt; Precautions</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633788_3</td><td>Cards: Descriptives &gt; Social Contracts; others</td><td>18633788_analysis_14</td><td>Cards: Descriptives &gt; Social Contracts</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633788_4</td><td>Cards: Precautions &gt; Descriptives; others</td><td>18633788_analysis_11</td><td>Cards: Precautions &gt; Descriptives</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633788_5</td><td>Cards: Precautions &gt; Social Contracts; others</td><td>18633788_analysis_10</td><td>Cards: Precautions &gt; Social Contracts</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633788_6</td><td>Rest &gt; Cards; others</td><td>18633788_analysis_3</td><td>Rest&gt;Cards</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633788_7</td><td>Rest &gt; Stories; others</td><td>18633788_analysis_1</td><td>Rest &gt; Stories</td><td>1.000</td><td>0.950</td><td>0.965</td><td>accepted</td><td>high_coord_match</td></tr><tr><td>18633788_8</td><td>Stories &gt; Rest; others</td><td>18633788_analysis_0</td><td>Stories &gt; Rest</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633788_9</td><td>Stories: Descriptives &gt; Precautions; others</td><td>18633788_analysis_13</td><td>Stories: Descriptives &gt; Precautions</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18633834</strong> | Pred included: 6 | Manual included (accepted matches only): 6 | Correct overlaps: 6 | Match statuses: accepted=6, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18633834/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18633834_analysis_0</td><td>STEP1
F+STEP2 - REST</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast STEP1+STEP2 vs REST presents footstep sounds conveying social information (one vs two walkers) and measures brain responses to socially relevant auditory scenes; thus it assesses general social processing.</td></tr>
<tr><td>18633834_analysis_1</td><td>NOISE1
F+NOISE2 - REST</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast NOISE1+NOISE2 vs REST is part of the experimental manipulation controlling auditory stimuli; although noise is non-social, it is used within a social-processing experiment and the contrast characterizes auditory processing in the social task context.</td></tr>
<tr><td>18633834_analysis_2</td><td>(STEP2 - NOISE2) - (STEP1 - NOISE1)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast (STEP2 - NOISE2) - (STEP1 - NOISE1) is explicitly designed to isolate social differences between two-person vs one-person walking after noise subtraction, targeting social-processing differences between conditions.</td></tr>
<tr><td>18633834_analysis_3</td><td>STEP1 - NOISE1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>STEP1 - NOISE1 isolates brain responses to single-person footstep sounds versus matched noise, directly measuring social auditory processing of an individual agent.</td></tr>
<tr><td>18633834_analysis_4</td><td>STEP2 - NOISE2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>STEP2 - NOISE2 isolates neural responses to two-person footstep sounds versus matched noise, directly assessing processing of a social scene involving multiple agents.</td></tr>
<tr><td>18633834_analysis_5</td><td>STEP2 - STEP1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast STEP2 - STEP1 compares two-person vs one-person footstep sounds, directly addressing social complexity and processing differences between group vs single-agent auditory scenes.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18633834_1</td><td>(STEP2 - NOISE2) - (STEP1 - NOISE1); socialcommunication</td><td>18633834_analysis_2</td><td>(STEP2 - NOISE2) - (STEP1 - NOISE1)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633834_2</td><td>NOISE1 + NOISE2 - REST; socialcommunication</td><td>18633834_analysis_1</td><td>NOISE1
F+NOISE2 - REST</td><td>0.955</td><td>1.000</td><td>0.986</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633834_3</td><td>STEP1 + STEP2 - REST; socialcommunication</td><td>18633834_analysis_0</td><td>STEP1
F+STEP2 - REST</td><td>0.950</td><td>1.000</td><td>0.985</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633834_4</td><td>STEP1 - NOISE1; socialcommunication</td><td>18633834_analysis_3</td><td>STEP1 - NOISE1</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633834_5</td><td>STEP1 - STEP1; socialcommunication</td><td>18633834_analysis_5</td><td>STEP2 - STEP1</td><td>0.923</td><td>1.000</td><td>0.977</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633834_6</td><td>STEP2 - NOISE2; socialcommunication</td><td>18633834_analysis_4</td><td>STEP2 - NOISE2</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18633846</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18633846/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18633846_analysis_0</td><td>Main effect of type of observed action</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast directly compares observation of social interactions versus individual actions, which is a canonical social-processing task engaging interpretation of others&#x27; behavior and social cues (dMPFC, IFG, pSTS). This matches Social Processing inclusion criteria.</td></tr>
<tr><td>18633846_analysis_1</td><td>Main effect of gaze</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The main effect of gaze isolates a core social cue (gaze present vs masked). Gaze is central to social information processing and modulates interpretation of others&#x27; actions, meeting Social Processing criteria.</td></tr>
<tr><td>18633846_analysis_2</td><td>Interaction</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The interaction tests how gaze availability modulates neural responses to social versus individual actions (i.e., how social inference is computed), directly indexing social processing (dMPFC modulation argues for inferential social processing).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18633846_1</td><td>Interaction [( Individual gaze + Social No-gaze) - (Individual No-gaze + Social gaze)];socialcommunication</td><td>18633846_analysis_2</td><td>Interaction</td><td>0.227</td><td>1.000</td><td>0.768</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>18633846_2</td><td>[( Social gaze + Individual gaze) - ( Social No-gaze + Individual No-gaze)]; socialcommunication</td><td>18633846_analysis_1</td><td>Main effect of gaze</td><td>0.149</td><td>1.000</td><td>0.745</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>18633846_3</td><td>[(Individual gaze + Social No-gaze) - (Individual No-gaze + Social Gaze); socialcommunication</td><td>18633846_analysis_0</td><td>Main effect of type of observed action</td><td>0.183</td><td>1.000</td><td>0.755</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18633856</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18633856/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18633856_analysis_0</td><td>Angry&gt;Happy</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task requires participants to view approaching characters making emotional facial expressions (happy vs angry) and to interpret social intentions (affiliation vs threat). This directly engages broad social processing (perception, interpretation, and response to social cues).</td></tr>
<tr><td>18633856_analysis_1</td><td>Happy&gt;Angry</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Happy&gt;Angry contrast still involves social stimuli (approach, facial expression) and measures social processing of affiliative versus threatening cues; it therefore indexes broad social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18633856_1</td><td>Angry &gt; Happy; affiliation</td><td>18633856_analysis_0</td><td>Angry&gt;Happy</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633856_2</td><td>Happy &gt; Angry; affiliation</td><td>18633856_analysis_1</td><td>Happy&gt;Angry</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18783371</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18783371/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> interaction between observed (hand and foot) and group (Compatible and Incompatible) &gt; baseline during Action Observation task; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18783371_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The study explicitly investigates the mirror system in the context of social cognition and uses action observation of other agents (hand and foot actions) and sensorimotor training to probe mechanisms relevant to social processing. The Observation Task involves perceiving others’ actions and the paper frames results in terms of social cognition, satisfying the inclusion criterion for Social Processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18783371_1</td><td>interaction between observed (hand and foot) and group (Compatible and Incompatible) &gt; baseline during Action Observation task; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>18783371_2</td><td>observation of both hands and feet &gt; baseline and action execution (hands and feet) &gt; baseline (conjunction analysis); socialcommunication</td><td>18783371_analysis_0</td><td>analysis_0</td><td>0.126</td><td>1.000</td><td>0.738</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 19048432</strong> | Pred included: 4 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/19048432/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Interaction between feedback condition and variance in pupil size (positive &gt; negative); socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>19048432_analysis_0</td><td>Main effect of viewing eyes</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involved viewing eye stimuli and dynamic pupillary interaction between observer and observed, directly probing social information processing and social salience. Analysis measures social processing of cues (eyes, pupillary coherence).</td></tr>
<tr><td>19048432_analysis_1</td><td>Main effect of change in observed and observer&#x27;s pupil size</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>ROI/main-effect analysis examines neural responses to dynamic pupillary signals in a social context (eyes), thus measuring social processing.</td></tr>
<tr><td>19048432_analysis_2</td><td>Region of interest analysis</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Interaction and contrasts in the reported analyses concern dynamic social signals (eyes/pupils) and their neural processing, fitting broad social processing.</td></tr>
<tr><td>19048432_analysis_3</td><td>Interaction between feedback condition and variance in pupil size</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Interaction analysis directly examines neural responses to coherent vs. incoherent social autonomic signals (eyes/pupils), reflecting social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>19048432_1</td><td>Interaction between feedback condition and variance in pupil size (positive &gt; negative); socialcommunication</td><td>19048432_analysis_3</td><td>Interaction between feedback condition and variance in pupil size</td><td>0.855</td><td>0.125</td><td>0.344</td><td>unmatched</td><td>coord_count_mismatch, low_coord_high_name, low_total_score</td></tr><tr><td>19048432_2</td><td>Main effect of change in observed and observer’s pupil size; socialcommunication</td><td>19048432_analysis_1</td><td>Main effect of change in observed and observer&#x27;s pupil size</td><td>0.983</td><td>1.000</td><td>0.995</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>19048432_3</td><td>Main effect of viewing eyes; socialcommunication</td><td>19048432_analysis_0</td><td>Main effect of viewing eyes</td><td>1.000</td><td>0.833</td><td>0.883</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 19107754</strong> | Pred included: 6 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/19107754/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>19107754_analysis_0</td><td>Individualism (IND) &gt; Collectivism (COL)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast is a group difference (IND &gt; COL) during self-judgment tasks; the tasks are social in nature (self-construal, self vs contextual social contexts). Therefore it measures social processing broadly.</td></tr>
<tr><td>19107754_analysis_1</td><td>Collectivism (COL) &gt; Individualism (IND)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast is a group difference (COL &gt; IND) during self-judgment tasks; the tasks are socially relevant (self-construal and social context), so it measures social processing.</td></tr>
<tr><td>19107754_analysis_2</td><td>General &gt; Contextual</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>General &gt; Contextual contrast stems from a self-related social task (self-construal judgments) and thus falls within social processing.</td></tr>
<tr><td>19107754_analysis_3</td><td>Contextual &gt; General</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contextual &gt; General contrast involves self-judgments embedded in social context (e.g., ‘when talking to your mother’), so it probes social processing.</td></tr>
<tr><td>19107754_analysis_4</td><td>fMRI results of interaction contrast [(INDgeneral + COLcontextual) - (INDcontextual + COLgeneral)]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The interaction contrast compares self-judgment types across self-construal styles (individualism vs collectivism) and directly addresses social representations of self, thus falls under social processing.</td></tr>
<tr><td>19107754_analysis_5</td><td>fMRI results of whole-brain correlation analysis of self-judgment contrast image [contextual-general] with self-construal style index [COL score-IND score]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The whole-brain correlation examines contextual vs general self-judgments in relation to self-construal style, probing social aspects of self-representation; therefore it measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>19107754_1</td><td>Collectivism &gt; Individualism; self</td><td>19107754_analysis_1</td><td>Collectivism (COL) &gt; Individualism (IND)</td><td>0.824</td><td>1.000</td><td>0.947</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>19107754_2</td><td>Contextual &gt; General; self</td><td>19107754_analysis_3</td><td>Contextual &gt; General</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>19107754_3</td><td>General &gt; Contextual; self</td><td>19107754_analysis_2</td><td>General &gt; Contextual</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>19107754_4</td><td>Individualism &gt; Collectivism; self</td><td>19107754_analysis_0</td><td>Individualism (IND) &gt; Collectivism (COL)</td><td>0.824</td><td>1.000</td><td>0.947</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>19107754_5</td><td>Self Judgement ( Contextual &gt; General) &gt; Self-Construal Style Index ( Collectivism &gt; Individualism); self</td><td>19107754_analysis_5</td><td>fMRI results of whole-brain correlation analysis of self-judgment contrast image [contextual-general] with self-construal style index [COL score-IND score]</td><td>0.538</td><td>1.000</td><td>0.862</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 19347874</strong> | Pred included: 5 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/19347874/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Coorelation -- attachment avoidance with brain responses to masked sad faces; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>19347874_analysis_0</td><td>Brain regions exhibiting significantly increased activation in response to masked sad faces compared to neutral faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task presents facial emotional expressions (social stimuli) and measures neural responses; thus this analysis assesses social processing broadly.</td></tr>
<tr><td>19347874_analysis_1</td><td>Brain regions exhibiting significantly increased activation in response to masked happy faces compared to neutral faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Masked happy vs neutral faces contrast uses social stimuli (faces) and measures social information processing.</td></tr>
<tr><td>19347874_analysis_2</td><td>Table III. Negative correlations of attachment avoidance with brain responses to masked sad faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This analysis correlates attachment avoidance with neural responses to masked sad faces, directly addressing social information processing differences.</td></tr>
<tr><td>19347874_analysis_3</td><td>Positive correlations</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>This analysis correlates attachment avoidance with brain responses to masked happy faces, thus probing social processing mechanisms.</td></tr>
<tr><td>19347874_analysis_4</td><td>Negative correlations</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Negative correlations of attachment avoidance with brain responses to masked happy faces still probe social processing and individual differences in social-emotional response.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>19347874_1</td><td>Coorelation -- attachment avoidance with brain responses to masked sad faces; socialcommunication</td><td>19347874_analysis_3</td><td>Positive correlations</td><td>0.227</td><td>0.500</td><td>0.418</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>19347874_2</td><td>Masked sad faces &gt; neutral faces; socialcommunication</td><td>19347874_analysis_0</td><td>Brain regions exhibiting significantly increased activation in response to masked sad faces compared to neutral faces</td><td>0.416</td><td>1.000</td><td>0.825</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>19347874_3</td><td>Negative coorelation -- attachment avoidance with brain responsed to masked sad faces; socialcommunication</td><td>19347874_analysis_2</td><td>Table III. Negative correlations of attachment avoidance with brain responses to masked sad faces</td><td>0.890</td><td>0.857</td><td>0.867</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>19347874_4</td><td>masked happy faces &gt; neutral faces; socialcommunication</td><td>19347874_analysis_1</td><td>Brain regions exhibiting significantly increased activation in response to masked happy faces compared to neutral faces</td><td>0.431</td><td>1.000</td><td>0.829</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 19439183</strong> | Pred included: 10 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/19439183/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>19439183_analysis_0</td><td>Pain &gt; no pain</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast Pain &gt; No Pain was derived from an event-related fMRI task that manipulated perception of others in painful vs non-painful situations within a social-context experiment. This is a social-related task probing neural responses to others&#x27; pain and thus measures social processing.</td></tr>
<tr><td>19439183_analysis_1</td><td>No pain &gt; pain</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>No Pain &gt; Pain is derived from the same task with social stimuli (presence/absence of others). Even inverse contrasts come from a social perception task and thus belong under broad social processing.</td></tr>
<tr><td>19439183_analysis_2</td><td>Self + Other &gt; Self</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Self+Other &gt; Self directly tests the effect of the presence of another individual (social context) on neural responses. This is a social-related manipulation and thus meets social processing.</td></tr>
<tr><td>19439183_analysis_3</td><td>Self &gt; Self + Other</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The Self &gt; Self+Other contrast is part of the same social-context design and hence falls under broad social processing (manipulation of social presence/agency).</td></tr>
<tr><td>19439183_analysis_4</td><td>PCO &gt; PCS</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The PPI contrast PCO &gt; PCS tests task-dependent connectivity modulated by whether pain was caused by another person versus by accident (agency/social context). This probes social-contextual modulation of neural circuits and thus is social processing.</td></tr>
<tr><td>19439183_analysis_5</td><td>PCS &gt; PCO</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>PCS &gt; PCO PPI tests connectivity when pain was caused by accident (self) versus intentionally by another; this contrast arises from a social-context task and therefore falls under social processing.</td></tr>
<tr><td>19439183_analysis_6</td><td>Emotion contagion score (during PCS trials)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This correlation links individual differences in emotional contagion (a social trait) to brain responses during the task (here labelled as during PCS trials). The analysis evaluates social susceptibility within a social-context experiment, satisfying social processing.</td></tr>
<tr><td>19439183_analysis_7</td><td>Pain ratings (during PCS trials)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This analysis correlates participants&#x27; pain ratings with brain responses (during PCS trials per label) in a social-context empathy task, linking subjective perception of others’ pain to neural activity and therefore fits social processing.</td></tr>
<tr><td>19439183_analysis_8</td><td>Emotion contagion score (during PCO trials)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This correlation links emotional contagion scores with brain responses during PCO trials (others-caused pain). It evaluates trait-level social susceptibility within an intentional-harm social context, and thus is a social-processing analysis.</td></tr>
<tr><td>19439183_analysis_9</td><td>Pain ratings (during PCO trials)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This analysis correlates subjective pain ratings during PCO trials (others-inflicted pain) with brain responses, linking subjective perception of others&#x27; suffering to neural activity — a social processing measure.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>19439183_1</td><td>Pain &gt; no pain; others</td><td>19439183_analysis_0</td><td>Pain &gt; no pain</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>19439183_2</td><td>Self + Other &gt; Self; others</td><td>19439183_analysis_2</td><td>Self + Other &gt; Self</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 19733672</strong> | Pred included: 6 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/19733672/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>19733672_analysis_0</td><td>Movie scenes theory of mind (ToM) &gt; movie scenes physical inference (PI)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast (movie scenes ToM &gt; PI) uses MASC naturalistic social videos to probe theory-of-mind/mentalizing during dynamic social scenes, which directly measures broad social processing.</td></tr>
<tr><td>19733672_analysis_1</td><td>Silent answer theory of mind (ToM) &gt; silent answer physical inference (PI)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Silent-answer ToM &gt; PI probes explicit mental-state reasoning in the social MASC task, clearly measuring broad social processing.</td></tr>
<tr><td>19733672_analysis_2</td><td>MC answer theory of mind (ToM) &gt; MC answer physical inference (PI)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>MC-answer ToM &gt; PI assesses explicit mental-state reasoning with overt responses in social contexts, directly indexing broad social processing.</td></tr>
<tr><td>19733672_analysis_3</td><td>IC 1 (rank 8 within all 80 components)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>IC1 (T-PICA) is a task-related network during ToM that includes STS, TPJ, temporal poles, PCC/precuneus and occipito-temporal/FFA — a canonical social-cognitive network, indexing broad social processing.</td></tr>
<tr><td>19733672_analysis_4</td><td>IC 2 (rank 13 within all 80 components)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>IC2 (T-PICA) comprises STS, temporal poles, IFG and precuneus and is task-related during ToM, reflecting a distributed social-cognitive network and broad social processing.</td></tr>
<tr><td>19733672_analysis_5</td><td>IC 3 (rank 19 within all 80 components)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>IC3 (T-PICA) is a ToM-related component including dmPFC and precuneus and is implicated in mental-state attribution, indexing broad social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>19733672_1</td><td>MC answer theory of mind (ToM)NMC answer physical inference (PI); others</td><td>19733672_analysis_2</td><td>MC answer theory of mind (ToM) &gt; MC answer physical inference (PI)</td><td>0.969</td><td>1.000</td><td>0.991</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>19733672_2</td><td>Movie scenes theory of mind (ToM) &gt; movie scenes physical inference (PI); others</td><td>19733672_analysis_0</td><td>Movie scenes theory of mind (ToM) &gt; movie scenes physical inference (PI)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>19733672_3</td><td>Silent answer theory of mind (ToM) &gt; silent answer physical inference (PI); others</td><td>19733672_analysis_1</td><td>Silent answer theory of mind (ToM) &gt; silent answer physical inference (PI)</td><td>1.000</td><td>0.800</td><td>0.860</td><td>accepted</td><td>high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 19944083</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/19944083/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>19944083_analysis_0</td><td>Emotional &gt; neutral stimuli</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast Emotional &gt; Neutral uses socially relevant stimuli (drawings of people in emotional vs neutral situations) probing empathy and social cognition. This meets inclusion criterion I1 (social-related task; measures social processing).</td></tr>
<tr><td>19944083_analysis_1</td><td>Neutral &gt; emotional stimuli</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Neutral &gt; Emotional uses the same social stimuli set (people in scenes) and therefore still indexes social processing (differences in response to social content). Meets I1.</td></tr>
<tr><td>19944083_analysis_2</td><td>Social relation &gt; single person</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast Social relation (two persons) &gt; Single person explicitly probes social interaction/relations and engages social cognitive processes (mentalizing, STS/mPFC activations). Meets I1.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>19944083_1</td><td>Emotional &gt; neutral stimuli; self</td><td>19944083_analysis_0</td><td>Emotional &gt; neutral stimuli</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>19944083_2</td><td>Neutral &gt; emotional stimuli; self</td><td>19944083_analysis_1</td><td>Neutral &gt; emotional stimuli</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>19944083_3</td><td>Social relation &gt; single person; self</td><td>19944083_analysis_2</td><td>Social relation &gt; single person</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 20045478</strong> | Pred included: 4 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/20045478/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>20045478_analysis_0</td><td>Self &gt; syllables</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast compares self-referential trait judgments (social cognition about the self) to a non-social control (syllables). Task is social-related (self/other trait judgments), so it measures social processing broadly.</td></tr>
<tr><td>20045478_analysis_1</td><td>Other &gt; syllables</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast compares trait judgments about a close friend to a non-social control; clearly involves social processing (perception/understanding of others and social cognition).</td></tr>
<tr><td>20045478_analysis_2</td><td>Self &gt; other</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Self &gt; other contrast directly compares two social conditions (self versus friend trait judgments), probing social processing related to self/other evaluation.</td></tr>
<tr><td>20045478_analysis_3</td><td>Other &gt; self</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Other &gt; self contrast examines neural activity for friend-relative to self trait judgments, a social task involving understanding others; fits broad social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>20045478_1</td><td>Other &gt; self; others</td><td>20045478_analysis_3</td><td>Other &gt; self</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>20045478_2</td><td>Other &gt; syllables; others</td><td>20045478_analysis_1</td><td>Other &gt; syllables</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>20045478_3</td><td>Self &gt; other; self</td><td>20045478_analysis_2</td><td>Self &gt; other</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>20045478_4</td><td>Self &gt; syllables; self</td><td>20045478_analysis_0</td><td>Self &gt; syllables</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 20056152</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/20056152/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>20056152_analysis_0</td><td>Places &gt; bodies</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is a social joint-attention paradigm requiring attribution of what another person sees (the avatar&#x27;s gaze toward occluded body/place images). The contrasts (Places &gt; Bodies) are derived from this social task and index social processing related to representing others&#x27; mental content.</td></tr>
<tr><td>20056152_analysis_1</td><td>Bodies &gt; places</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Bodies &gt; Places contrast is derived from the same joint-attention/theory-of-mind task and indexes social processing related to attributing content to another&#x27;s mind (seeing a body vs a place).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>20056152_1</td><td>Bodies &gt; Places; socialcommunication</td><td>20056152_analysis_1</td><td>Bodies &gt; places</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>20056152_2</td><td>Places &gt; Bodies; socialcommunication</td><td>20056152_analysis_0</td><td>Places &gt; bodies</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 20096792</strong> | Pred included: 4 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/20096792/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>20096792_analysis_0</td><td>Live&gt;Recorded</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Experiment 1 Live&gt;Recorded contrasts a live, contingent social interaction with recorded playback, directly measuring neural correlates of social interaction and social processing (social cognition, reward, attention).</td></tr>
<tr><td>20096792_analysis_1</td><td>Recorded &gt;Live</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Recorded&gt;Live arises from the same social interaction paradigm (recorded vs live) and thus reflects contrasts within a social-processing task, even if the peak activations are motor regions.</td></tr>
<tr><td>20096792_analysis_2</td><td>JA&gt;SA</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Experiment 2 Joint Attention&gt;Solo Attention directly manipulates a core social interaction component (joint attention), measuring social cognitive processing during live interaction.</td></tr>
<tr><td>20096792_analysis_3</td><td>SA&gt;JA</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Solo&gt;Joint Attention is part of the same social interaction task and reflects contrasts in social processing (differences when the partner is present but not coordinating attention).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>20096792_1</td><td>Live &gt; Recorded; socialcommunication</td><td>20096792_analysis_0</td><td>Live&gt;Recorded</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>20096792_2</td><td>Recorded &gt; Live; socialcommunication</td><td>20096792_analysis_1</td><td>Recorded &gt;Live</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>20096792_3</td><td>JA &gt; SA; socialcommunication</td><td>20096792_analysis_2</td><td>JA&gt;SA</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 20119878</strong> | Pred included: 4 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/20119878/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>20119878_analysis_0</td><td>Neural regions active to warmth expectancy violation social targets</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast examines neural responses to warmth expectancy violations when viewing pictures of social targets after dispositional attributions — a clearly social task probing social perception and learning. This directly measures social processing.</td></tr>
<tr><td>20119878_analysis_1</td><td>Neural regions active to warmth expectancy consistent social targets</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast examines neural responses when social targets are consistent with warmth expectancies; it is a social task probing social perception and expectancy, so it measures social processing.</td></tr>
<tr><td>20119878_analysis_2</td><td>Neural regions active to competence expectancy violation social targets</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast captures neural responses to competence expectancy violations when viewing social targets — a social task that assesses person perception and social learning, therefore measuring social processing.</td></tr>
<tr><td>20119878_analysis_3</td><td>Neural regions active to competence expectancy consistent social targets</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast examines competence expectancy consistency for social targets — a social perception and learning task that measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>20119878_1</td><td>competence expectancy violation &gt; consistant competence expectency; others</td><td>20119878_analysis_2</td><td>Neural regions active to competence expectancy violation social targets</td><td>0.540</td><td>1.000</td><td>0.862</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>20119878_2</td><td>consistant competence expectency &gt; competence expectancy violation; others</td><td>20119878_analysis_3</td><td>Neural regions active to competence expectancy consistent social targets</td><td>0.507</td><td>1.000</td><td>0.852</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>20119878_3</td><td>consistent warmth expectancy &gt;  warm expectancy violation; others</td><td>20119878_analysis_1</td><td>Neural regions active to warmth expectancy consistent social targets</td><td>0.468</td><td>1.000</td><td>0.840</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>20119878_4</td><td>warm expectancy violation  &gt;  consistent warmth expectancy; others</td><td>20119878_analysis_0</td><td>Neural regions active to warmth expectancy violation social targets</td><td>0.504</td><td>1.000</td><td>0.851</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 20188182</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=6</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/20188182/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> loved one &gt; self; affiliation, loved one &gt; stranger; affiliation, self &gt; loved one; self, self &gt; stranger; self, stranger &gt; loved one; others, stranger &gt; self; others</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>20188182_analysis_0</td><td>Brain regions showing a significant effect of pain.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis reports the main effect of painful vs. neutral stimuli within an empathy-for-pain paradigm that manipulates perspective (Self, Loved-one, Stranger). The task is explicitly social (empathy, perspective-taking, relationships) and the contrast indexes social processing related to perceiving others in pain and associated affective responses. Thus it meets I1 (social-related task) and I2 (measures social processing).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>20188182_1</td><td>loved one &gt; self; affiliation</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>20188182_2</td><td>loved one &gt; stranger; affiliation</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>20188182_3</td><td>pain &gt; no pain; others</td><td>20188182_analysis_0</td><td>Brain regions showing a significant effect of pain.</td><td>0.369</td><td>1.000</td><td>0.811</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>20188182_4</td><td>self &gt; loved one; self</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>20188182_5</td><td>self &gt; stranger; self</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>20188182_6</td><td>stranger &gt; loved one; others</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>20188182_7</td><td>stranger &gt; self; others</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 20188190</strong> | Pred included: 7 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/20188190/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>20188190_analysis_0</td><td>Preference</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The Preference task explicitly asks subjects to judge whether they like a presented face (social preference). This is a social-related task probing social information processing and thus meets I1.</td></tr>
<tr><td>20188190_analysis_1</td><td>Gender</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The Gender (control) task involves face perception and social information (identifying another person&#x27;s gender), therefore it is a social-related task and meets I1.</td></tr>
<tr><td>20188190_analysis_2</td><td>Preference &gt; Gender</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Preference&gt;Gender contrast isolates neural processes of social preference (liking others) and therefore measures social processing (I1).</td></tr>
<tr><td>20188190_analysis_3</td><td>Gender &gt; Preference</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Gender&gt;Preference contrast still concerns social stimuli (faces) and differences in processing of social information (greater activity for Gender), so it remains within social processing.</td></tr>
<tr><td>20188190_analysis_4</td><td>aMFC</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The aMFC PPI analysis examines task-dependent functional coupling during the social preference task (Preference vs Gender), addressing network mechanisms of social processing and meeting I1.</td></tr>
<tr><td>20188190_analysis_5</td><td>vMFC</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The vMFC PPI analysis tests task-dependent coupling during social preference, directly concerning social processing and meeting I1.</td></tr>
<tr><td>20188190_analysis_6</td><td>PCC</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The PCC PPI analysis examines network interactions during the social preference task, addressing mechanisms of social processing and meeting I1.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>20188190_1</td><td>Gender &gt; Preference; socialcommunication</td><td>20188190_analysis_3</td><td>Gender &gt; Preference</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>20188190_2</td><td>Preference &gt; Gender; socialcommunication</td><td>20188190_analysis_2</td><td>Preference &gt; Gender</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 21249224</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/21249224/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>21249224_analysis_0</td><td>Brain areas showing increased activity in response to the social interaction condition.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast compares observation of social interactions (SI) versus non-social movements (NSI) using point-light displays; this directly measures broad social processing (perception and interpretation of social intentions). Matches inclusion criteria: social-related task and measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>21249224_1</td><td>social interactions &gt; nonsocial interactions; others</td><td>21249224_analysis_0</td><td>Brain areas showing increased activity in response to the social interaction condition.</td><td>0.397</td><td>1.000</td><td>0.819</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 21320516</strong> | Pred included: 2 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/21320516/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>21320516_analysis_0</td><td>Female and male</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves processing humorous cartoons, social cognition, emotion perception, and mentalizing; authors explicitly discuss social aspects of humor and report TPJ/ToM and ACC involvement, so this is a social-processing task.</td></tr>
<tr><td>21320516_analysis_1</td><td>Female and male</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Parametric modulation relates subjective funniness to brain activation during processing of humorous cartoons—a social-cognitive, affective task involving appraisal and mentalizing; authors frame humor as social and report joint activations in social-cognition regions.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>21320516_1</td><td>cartoons &gt; neutral pictures; socialcommunication</td><td>21320516_analysis_0</td><td>Female and male</td><td>0.238</td><td>1.000</td><td>0.771</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 21600991</strong> | Pred included: 2 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/21600991/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>21600991_analysis_0</td><td>Activations in the retrieval of social context</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Contrast directly isolates retrieval of social context ((rSS+rSO) - (rNS+rNO)); task involved collaborative social interaction and recognition of words learned in social vs solitary contexts, so this measures broad social processing.</td></tr>
<tr><td>21600991_analysis_1</td><td>Activations in the retrieval of self-generation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast isolates self-generation retrieval ((rSS+rNS) - (rSO+rNO)); self-generation in a social experimental context still falls under social processing broadly (self vs other generation within social interaction), so it is included as social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>21600991_1</td><td>Retrieval of social context &gt; Retrieval of self-generation; socialcommunication</td><td>21600991_analysis_1</td><td>Activations in the retrieval of self-generation</td><td>0.724</td><td>1.000</td><td>0.917</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 21703352</strong> | Pred included: 3 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/21703352/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>21703352_analysis_0</td><td>Neural regions engaged during decisions to accept Costly-Donation relative to Noncostly-Reward trials.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast examines prosocial (costly donation to family) versus self-reward decisions, a social task probing social motives, mentalizing and self-control during interpersonal decisions. This directly measures social processing involved in understanding and responding to others (family).</td></tr>
<tr><td>21703352_analysis_1</td><td>Neural regions associated with family obligation preferences during decisions to accept Costly-Donation versus Noncostly-Reward trials.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This analysis links individual differences in family-obligation preferences to neural recruitment during prosocial family decisions — a social construct assessing how people perceive/act toward others (family), thus measuring social processing.</td></tr>
<tr><td>21703352_analysis_2</td><td>Neural regions associated with the ventral striatum during decisions to accept Costly-Donation relative to Noncostly-Reward trials that correlated positively with participants&#x27; family obligation preferences.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>PPI examines functional coupling between reward (ventral striatum) and self-control/mentalizing regions during prosocial family decisions and how this varies with family-obligation — a social-processing question about interpersonal decision mechanisms.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>21703352_1</td><td>Costly-Donation relative to Noncostly-Reward (accept); others</td><td>21703352_analysis_0</td><td>Neural regions engaged during decisions to accept Costly-Donation relative to Noncostly-Reward trials.</td><td>0.594</td><td>1.000</td><td>0.878</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>21703352_2</td><td>Costly-Donation versus Noncostly-Reward (Family obligtations); others</td><td>21703352_analysis_1</td><td>Neural regions associated with family obligation preferences during decisions to accept Costly-Donation versus Noncostly-Reward trials.</td><td>0.439</td><td>1.000</td><td>0.832</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 21955370</strong> | Pred included: 4 | Manual included (accepted matches only): 3 | Correct overlaps: 2 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/21955370/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>21955370_analysis_0</td><td>I(H + M) &gt; C(H + M)</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Contrast I(H+M) &gt; C(H+M) isolates Stroop (incongruent vs congruent) executive/inhibition effects across both opponent types. Although performed in a social-competition context, this contrast does not specifically measure social processing or distinguish human vs. machine interaction (does not isolate ToM or other social processes).</td></tr>
<tr><td>21955370_analysis_1</td><td>C(H + M) &gt; I(H + M)</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Contrast C(H+M) &gt; I(H+M) isolates Congruent &gt; Incongruent Stroop (control &gt; Stroop) and does not measure social processing specifically; it collapses across opponent types.</td></tr>
<tr><td>21955370_analysis_2</td><td>H(I + C) &gt; M(I + C)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast H(I+C) &gt; M(I+C) directly compares human vs. machine competition and therefore isolates social processing related to human–human interaction (ToM/social context). The task explicitly manipulates social competitor type and instructions encourage mentalizing in the Human condition.</td></tr>
<tr><td>21955370_analysis_3</td><td>M(I + C) &gt; H(I + C)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Contrast M(I+C) &gt; H(I+C) is a direct social manipulation contrast (machine vs human opponent). Even though the paper reports no suprathreshold activation for this direction, the contrast is designed to measure social-processing differences between opponent types.</td></tr>
<tr><td>21955370_analysis_4</td><td>[H(I &gt; C)] &gt; [M(I &gt; C)]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Interaction [H(I&gt;C)] &gt; [M(I&gt;C)] isolates executive (Stroop) activity that is specifically modulated by human (vs machine) competition — directly indexing social-processing modulation (ToM in a competitive context).</td></tr>
<tr><td>21955370_analysis_5</td><td>[M(I &gt; C)] &gt; [H(I &gt; C)]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Interaction [M(I&gt;C)] &gt; [H(I&gt;C)] is a social-context contrast (machine vs human modulation of Stroop). Even though no suprathreshold voxels were reported, the contrast is designed to detect social-processing differences and thus counts as a social-processing analysis.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>21955370_1</td><td>H(I + C) &gt; M(I + C); affiliation</td><td>21955370_analysis_2</td><td>H(I + C) &gt; M(I + C)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>21955370_2</td><td>I(H + M) &gt; C(H + M); affiliation</td><td>21955370_analysis_0</td><td>I(H + M) &gt; C(H + M)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>21955370_3</td><td>[H(I &gt; C)] &gt; [M(I &gt; C)]; affiliation</td><td>21955370_analysis_4</td><td>[H(I &gt; C)] &gt; [M(I &gt; C)]</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 22019860</strong> | Pred included: 2 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/22019860/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> observation of biological motion displays &gt; scrambled displays; others</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>22019860_analysis_0</td><td>A: brain regions exhibiting activation during observation of biological motion displays, as compared with scrambled displays</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast (canonical point-light walker vs scrambled) probes perception of others’ biological motion, a social-related task; it measures social processing broadly (perception/understanding of others).</td></tr>
<tr><td>22019860_analysis_1</td><td>B: brain regions showing functional connectivity with the left cerebellar lobule Crus I in the seed-voxel regression analysis</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>The functional connectivity analysis examines regions engaged during biological motion perception (left Crus I seed), which is a social-related process (perception of others), so it reflects social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>22019860_1</td><td>Observation of biological motion displays &gt; observation of scrambled displays; others</td><td>22019860_analysis_0</td><td>A: brain regions exhibiting activation during observation of biological motion displays, as compared with scrambled displays</td><td>0.647</td><td>1.000</td><td>0.894</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>22019860_2</td><td>observation of biological motion displays &gt; scrambled displays; others</td><td>22019860_analysis_1</td><td>B: brain regions showing functional connectivity with the left cerebellar lobule Crus I in the seed-voxel regression analysis</td><td>0.182</td><td>0.076</td><td>0.107</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 22174872</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/22174872/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>22174872_analysis_0</td><td>Subtraction of neutral form emotional trials.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast of emotional (all emotions) vs neutral trials measures emotional prosody comprehension, a social-related task requiring perception and interpretation of others&#x27; vocal emotional cues. This meets the criteria for Social Processing as it assesses social cue perception and understanding.</td></tr>
<tr><td>22174872_analysis_1</td><td>Subtraction of simple from complex emotion trials.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The complex&gt;simple emotion contrast probes additional socio-cognitive processing (mPFC, premotor, insula, somatosensory regions) required to interpret complex/social emotions, clearly indexing social processing.</td></tr>
<tr><td>22174872_analysis_2</td><td>Subtraction of simple from complex emotion trials (controlled for pitch).</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Controlling for pitch, the complex&gt;simple (pitch-controlled) contrast still reveals mPFC, premotor and insula activations linked to socio-cognitive processing of complex emotions, consistent with Social Processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>22174872_1</td><td>Complex emotion trials &gt; Simple emotion trials</td><td>22174872_analysis_1</td><td>Subtraction of simple from complex emotion trials.</td><td>0.458</td><td>1.000</td><td>0.838</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>22174872_2</td><td>Complex emotion trials &gt; Simple emotion trials (controlling for pitch)</td><td>22174872_analysis_2</td><td>Subtraction of simple from complex emotion trials (controlled for pitch).</td><td>0.601</td><td>1.000</td><td>0.880</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>22174872_3</td><td>Emotional trials &gt; Neutral Trials</td><td>22174872_analysis_0</td><td>Subtraction of neutral form emotional trials.</td><td>0.410</td><td>1.000</td><td>0.823</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 22726841</strong> | Pred included: 3 | Manual included (accepted matches only): 5 | Correct overlaps: 3 | Match statuses: accepted=5, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/22726841/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>22726841_analysis_0</td><td>Simulated-other&#x27;s reward prediction error</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This analysis indexes learning and prediction about another person&#x27;s decision-making (simulated-other&#x27;s reward prediction error); it directly involves social cognition/simulation. Matches inclusion I1 (social-related task).</td></tr>
<tr><td>22726841_analysis_1</td><td>Simulated-other&#x27;s action prediction error</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This analysis indexes the simulated-other&#x27;s action prediction error (sAPE) based on observing another&#x27;s choices, a core social-cognitive process (learning about others&#x27; behavior). Matches I1 (social-related task).</td></tr>
<tr><td>22726841_analysis_2</td><td>Reward probability</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This analysis concerns the subject&#x27;s reward probability in the Other task (decision based on simulation of another), which occurs within a social simulation context (predicting another&#x27;s choices). Thus it is a social-related analysis (I1).</td></tr>
<tr><td>22726841_analysis_3</td><td>Reward prediction error</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>This analysis indexes the subject&#x27;s own reward prediction error in the Control task, which is a nonsocial reinforcement-learning condition used as a reference; it does not involve social or other-directed processing, so it does not satisfy the social-related inclusion I1.</td></tr>
<tr><td>22726841_analysis_4</td><td>Reward probability</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>This analysis indexes the subject&#x27;s reward probability in the Control (nonsocial) task, which does not involve social processing of others and thus fails the social-related I1 for this construct.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>22726841_1</td><td>Reward Prediction Error (control) &gt; Reward probability (other); affiliation</td><td>22726841_analysis_3</td><td>Reward prediction error</td><td>0.541</td><td>1.000</td><td>0.862</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>22726841_2</td><td>Reward probability (other) &gt;  Reward Prediction Error (control); affiliation</td><td>22726841_analysis_4</td><td>Reward probability</td><td>0.450</td><td>1.000</td><td>0.835</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>22726841_3</td><td>Reward probability (other) &gt; Reward Prediction Error (other); affiliation</td><td>22726841_analysis_2</td><td>Reward probability</td><td>0.462</td><td>1.000</td><td>0.838</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>22726841_4</td><td>Simulated-other’s action prediction error &gt; Simulated-other’s reward prediction error; affiliation</td><td>22726841_analysis_1</td><td>Simulated-other&#x27;s action prediction error</td><td>0.635</td><td>1.000</td><td>0.890</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>22726841_5</td><td>Simulated-other’s reward prediction error &gt; Simulated-other’s action prediction error; affiliation</td><td>22726841_analysis_0</td><td>Simulated-other&#x27;s reward prediction error</td><td>0.635</td><td>1.000</td><td>0.890</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 22841755</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/22841755/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>22841755_analysis_0</td><td>Power motive</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The power-motive analysis uses social movie clips (power-related interactions) and regressions of BOLD responses on social-motive individual differences, so it targets social processing broadly.</td></tr>
<tr><td>22841755_analysis_1</td><td>Affiliation motive</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The affiliation-motive analysis uses love/affiliation movie clips and regresses BOLD responses on affiliation motive scores, directly addressing social processing related to bonding/attachment.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>22841755_1</td><td>affiliation &gt; power; affiliation</td><td>22841755_analysis_1</td><td>Affiliation motive</td><td>0.757</td><td>1.000</td><td>0.927</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>22841755_2</td><td>power &gt; affiliation; affiliation</td><td>22841755_analysis_0</td><td>Power motive</td><td>0.516</td><td>1.000</td><td>0.855</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23063451</strong> | Pred included: 7 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23063451/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23063451_analysis_0</td><td>Self &gt; Other</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast Self &gt; Other examines perspective-taking (self vs other) in an empathy task using painful vs neutral stimuli; this is a social-related task measuring social processing of self/other perspectives.</td></tr>
<tr><td>23063451_analysis_1</td><td>Other &gt; Self</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Other &gt; Self contrast probes adopting a third-person perspective (mentalizing/empathy) and therefore measures social processing.</td></tr>
<tr><td>23063451_analysis_2</td><td>OtherGood &gt; OtherBad performer</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>OtherGood &gt; OtherBad compares successful vs unsuccessful third-person perspective taking in an empathy task; this is a social processing measure.</td></tr>
<tr><td>23063451_analysis_3</td><td>OtherBad &gt; OtherGood performer</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>OtherBad &gt; OtherGood contrasts unsuccessful &gt; successful third-person perspective taking in an empathy paradigm—this is social processing relevant.</td></tr>
<tr><td>23063451_analysis_4</td><td>SelfGood &gt; SelfBad performer</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>SelfGood &gt; SelfBad contrasts successful vs unsuccessful self-perspective taking within an empathy paradigm, which is social processing (self/other distinction component).</td></tr>
<tr><td>23063451_analysis_5</td><td>SelfBad &gt; SelfGood performer</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>SelfBad &gt; SelfGood examines unsuccessful vs successful first-person perspective taking — a social processing contrast concerning self/other distinction and empathy.</td></tr>
<tr><td>23063451_analysis_6</td><td>analysis_6</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Analysis 6 is unspecified but belongs to the same study investigating perspective taking and empathy; as such it likely probes social processes — include by default given study context.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23063451_1</td><td>Conjunction of Other and Self; others</td><td>23063451_analysis_6</td><td>analysis_6</td><td>0.170</td><td>1.000</td><td>0.751</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>23063451_2</td><td>Other &gt; Self; others</td><td>23063451_analysis_1</td><td>Other &gt; Self</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23063451_3</td><td>Self &gt; Other; self</td><td>23063451_analysis_0</td><td>Self &gt; Other</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23221019</strong> | Pred included: 5 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=2</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23221019/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Conjunction of all Conditions &gt; Fixation Baseline; socialcommunication, Load x Goal &gt; Fixation Baseline; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23221019_analysis_0</td><td>Conjunction of all conditions versus fixation baseline</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>The task is action observation with goal manipulations (what/how/why) and a load manipulation to probe automaticity of social-cognitive systems (mirror neuron and mentalizing systems). This directly measures social processing broadly (perception and interpretation of others’ actions and mental states).</td></tr>
<tr><td>23221019_analysis_1</td><td>Conjunction of low-load/how-goal condition &gt; low-load/observe-goal condition and high-load/how-goal condition &gt; high-load/observe-goal condition</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast compares goal-directed action understanding (how) against passive observation across loads, directly targeting social-cognitive processing involved in action understanding and thus qualifies as broad social processing.</td></tr>
<tr><td>23221019_analysis_2</td><td>Modulation by load for any of the four goals</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This analysis tests modulation by cognitive load across goals for systems implicated in social cognition (mirror neuron and mentalizing systems), addressing automaticity of social processing and thus falls under broad social processing.</td></tr>
<tr><td>23221019_analysis_3</td><td>Low-load/why-goal condition compared with high-load/why-goal condition, low-load/how-goal condition, and high-load/how-goal condition combined</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The low-load/why-goal &gt; other-conditions contrast isolates mentalizing (inferring others’ motives) under sufficient cognitive resources — a prototypical social-cognitive process and thus broad social processing.</td></tr>
<tr><td>23221019_analysis_4</td><td>Load-by-goal interaction</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>The load-by-goal interaction evaluates how cognitive resources and task goals shape activity in mirror and mentalizing systems during social perception — a central social-processing question.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23221019_1</td><td>Conjunction of all Conditions &gt; Fixation Baseline; socialcommunication</td><td>23221019_analysis_0</td><td>Conjunction of all conditions versus fixation baseline</td><td>0.932</td><td>0.200</td><td>0.420</td><td>unmatched</td><td>coord_count_mismatch, low_coord_high_name, low_total_score</td></tr><tr><td>23221019_2</td><td>Conjunction of low-load/how-goal condition &gt; low-load/observe-goal condition and high-load/how-goal condition &gt; high-load/observe-goal condition; socialcommunication</td><td>23221019_analysis_1</td><td>Conjunction of low-load/how-goal condition &gt; low-load/observe-goal condition and high-load/how-goal condition &gt; high-load/observe-goal condition</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23221019_3</td><td>Load x Goal &gt; Fixation Baseline; socialcommunication</td><td>23221019_analysis_4</td><td>Load-by-goal interaction</td><td>0.545</td><td>0.429</td><td>0.464</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>23221019_4</td><td>Low-load/why-goal condition compared with high-load/why-goal condition, low-load/how-goal condition, and high-load/how-goal condition combined; socialcommunication</td><td>23221019_analysis_3</td><td>Low-load/why-goal condition compared with high-load/why-goal condition, low-load/how-goal condition, and high-load/how-goal condition combined</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23221019_5</td><td>Modulation by load for any of the four goals; socialcommunication</td><td>23221019_analysis_2</td><td>Modulation by load for any of the four goals</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23298748</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23298748/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23298748_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task explicitly manipulates sociality (trustworthiness judgments of faces) and measures social working memory; this directly assesses social processing.</td></tr>
<tr><td>23298748_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Same experiment/contrast manipulates social vs. nonsocial information (trustworthiness vs. spatial location) and assesses social processing in the social condition.</td></tr>
<tr><td>23298748_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This analysis is part of the same study manipulating social information (trustworthiness) and thus measures social processing broadly.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23298748_1</td><td>interaction between sociality and working memory load; socialcommunication</td><td>23298748_analysis_2</td><td>analysis_2</td><td>0.127</td><td>1.000</td><td>0.738</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>23298748_2</td><td>sociality &gt; working memory load; socialcommunication</td><td>23298748_analysis_0</td><td>analysis_0</td><td>0.146</td><td>1.000</td><td>0.744</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>23298748_3</td><td>working memory load &gt; sociality; socialcommunication</td><td>23298748_analysis_1</td><td>analysis_1</td><td>0.195</td><td>1.000</td><td>0.759</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23378834</strong> | Pred included: 10 | Manual included (accepted matches only): 12 | Correct overlaps: 7 | Match statuses: accepted=12, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23378834/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23378834_analysis_0</td><td>FAMOUS FACES vs. BASELINE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Contrast examines famous faces vs baseline — a social/person-related face memory task assessing social processing (person identification, memory).</td></tr>
<tr><td>23378834_analysis_1</td><td>FAMILIAR FACES vs. BASELINE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Contrast examines personally familiar faces vs baseline; clearly a social-related task involving person knowledge and social processing.</td></tr>
<tr><td>23378834_analysis_2</td><td>FAMOUS ∩ FAMILIAR FACES</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Conjunction of famous and familiar faces identifies overlapping person-memory related activations — a social processing result.</td></tr>
<tr><td>23378834_analysis_3</td><td>Faces &gt; Landmarks</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Faces vs landmarks contrast engages face-processing and person-related networks — a social processing task.</td></tr>
<tr><td>23378834_analysis_4</td><td>Landmarks &gt; Faces</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Landmarks &gt; faces emphasizes non-social, scene-related processing; not a social-related task.</td></tr>
<tr><td>23378834_analysis_5</td><td>Famous faces &gt; Novel faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Famous &gt; Novel faces contrast taps person memory and social knowledge — a social processing task.</td></tr>
<tr><td>23378834_analysis_6</td><td>Novel faces &gt; Famous faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Novel &gt; Famous faces examines face perception and novelty detection within a social/person domain — a social processing-relevant contrast.</td></tr>
<tr><td>23378834_analysis_7</td><td>Novel faces &gt; Novel landmarks</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Novel faces vs novel landmarks is a face-specific contrast probing social/person perception — a social processing task.</td></tr>
<tr><td>23378834_analysis_8</td><td>Novel landmarks &gt; Novel faces</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Novel landmarks &gt; novel faces emphasizes non-social scene/place processing rather than social tasks.</td></tr>
<tr><td>23378834_analysis_9</td><td>Famous faces &gt; Novel landmarks</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Famous faces &gt; novel landmarks contrasts person-related stimuli with non-social scenes and probes social/person processing.</td></tr>
<tr><td>23378834_analysis_10</td><td>Novel landmarks &gt; Famous faces</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Novel landmarks &gt; famous faces emphasizes scene/place processing and is not a social/person-specific task.</td></tr>
<tr><td>23378834_analysis_11</td><td>Famous landmarks &gt; Novel landmarks</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Famous landmarks &gt; novel landmarks is a non-social, place/scene contrast; not a social processing task.</td></tr>
<tr><td>23378834_analysis_12</td><td>Novel landmarks &gt; Famous landmarks</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Novel landmarks &gt; famous landmarks is a place/scene contrast unrelated to social/person processing.</td></tr>
<tr><td>23378834_analysis_13</td><td>Familiar faces &gt; Novel faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Familiar (friends) &gt; novel faces directly probes social/person knowledge and social processing (friend recognition, social closeness judgments).</td></tr>
<tr><td>23378834_analysis_14</td><td>Famous ∩ Familiar faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Conjunction of famous and familiar faces highlights shared person-memory activations — a social processing outcome.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23378834_1</td><td>Faces &gt; Landmarks; socialcommunication</td><td>23378834_analysis_3</td><td>Faces &gt; Landmarks</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_10</td><td>Novel landmarks &gt; Famous faces; socialcommunication</td><td>23378834_analysis_10</td><td>Novel landmarks &gt; Famous faces</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_11</td><td>Novel landmarks &gt; Famous landmarks; socialcommunication</td><td>23378834_analysis_12</td><td>Novel landmarks &gt; Famous landmarks</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_12</td><td>Novel landmarks &gt; Novel faces; socialcommunication</td><td>23378834_analysis_8</td><td>Novel landmarks &gt; Novel faces</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_2</td><td>Familiar faces &gt; Novel faces; socialcommunication</td><td>23378834_analysis_13</td><td>Familiar faces &gt; Novel faces</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_3</td><td>Famous faces &gt; Novel faces; socialcommunication</td><td>23378834_analysis_5</td><td>Famous faces &gt; Novel faces</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_4</td><td>Famous faces &gt; Novel landmarks; socialcommunication</td><td>23378834_analysis_9</td><td>Famous faces &gt; Novel landmarks</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_5</td><td>Famous landmarks &gt; Novel landmarks; socialcommunication</td><td>23378834_analysis_11</td><td>Famous landmarks &gt; Novel landmarks</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_6</td><td>Famous ∩ Familiar faces; socialcommunication</td><td>23378834_analysis_14</td><td>Famous ∩ Familiar faces</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_7</td><td>Landmarks &gt; Faces; socialcommunication</td><td>23378834_analysis_4</td><td>Landmarks &gt; Faces</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_8</td><td>Novel faces &gt; Famous faces; socialcommunication</td><td>23378834_analysis_6</td><td>Novel faces &gt; Famous faces</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_9</td><td>Novel faces &gt; Novel landmarks; socialcommunication</td><td>23378834_analysis_7</td><td>Novel faces &gt; Novel landmarks</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23599165</strong> | Pred included: 8 | Manual included (accepted matches only): 7 | Correct overlaps: 7 | Match statuses: accepted=7, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23599165/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23599165_analysis_0</td><td>Yes (Match + Unrequited) &gt; No (Rejection + Disinterest)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast compares neural responses to receiving ‘yes’ (interest) vs ‘no’ (rejection/disinterest) in a real-world social interaction paradigm (speed-dating). This directly measures social processing (perception, interpretation, and response to social signals).</td></tr>
<tr><td>23599165_analysis_1</td><td>No (Rejection + Disinterest) &gt; Yes (Match + Unrequited)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This contrast (No &gt; Yes) captures neural responses to social rejection/disinterest versus interest, a core social processing measure.</td></tr>
<tr><td>23599165_analysis_2</td><td>Match &gt; Unrequited</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Match (mutual yes) versus Unrequited (partner yes but participant no) contrasts social reward and interpersonal outcomes—clearly social processing.</td></tr>
<tr><td>23599165_analysis_3</td><td>Rejection &gt; Disinterest</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Rejection &gt; Disinterest isolates neural correlates of being rejected by a desired partner versus mutual disinterest—central social processing.</td></tr>
<tr><td>23599165_analysis_4</td><td>Mismatched (Rejection + Unrequited) &gt; matched (Match + Disinterest)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Mismatched (participant and partner decisions differ) vs matched trials capture expectation violation in interpersonal interaction—core social processing.</td></tr>
<tr><td>23599165_analysis_5</td><td>Unsigned prediction errors from RL model</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Unsigned prediction errors from an RL model index trial-by-trial surprise about partners&#x27; decisions (learning from social feedback)—a social processing measure.</td></tr>
<tr><td>23599165_analysis_6</td><td>Partners who were given a yes &gt; those given a no</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Comparing partners the participant said yes to vs those said no to at face-presentation examines anticipation and social valuation—core social processing.</td></tr>
<tr><td>23599165_analysis_7</td><td>Partners who were given a no &gt; those given a yes</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast of partners given a no &gt; yes captures neural responses to viewing partners previously judged as undesirable—social processing about interpersonal evaluation.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23599165_1</td><td>Match &gt; Unrequited; socialcommunication</td><td>23599165_analysis_2</td><td>Match &gt; Unrequited</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23599165_2</td><td>Mismatched (Rejection + Unrequited) &gt; matched (Match + Disinterest); socialcommunication</td><td>23599165_analysis_4</td><td>Mismatched (Rejection + Unrequited) &gt; matched (Match + Disinterest)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23599165_3</td><td>Partners who were given a no &gt; those given a yes; socialcommunication</td><td>23599165_analysis_7</td><td>Partners who were given a no &gt; those given a yes</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23599165_4</td><td>Partners who were given a yes &gt; those given a no; socialcommunication</td><td>23599165_analysis_6</td><td>Partners who were given a yes &gt; those given a no</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23599165_5</td><td>Rejection &gt; Disinterest; socialcommunication</td><td>23599165_analysis_3</td><td>Rejection &gt; Disinterest</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23599165_6</td><td>Unsigned prediction errors from RL model; socialcommunication</td><td>23599165_analysis_5</td><td>Unsigned prediction errors from RL model</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23599165_7</td><td>Yes (Match + Unrequited) &gt; No (Rejection + Disinterest); socialcommunication</td><td>23599165_analysis_0</td><td>Yes (Match + Unrequited) &gt; No (Rejection + Disinterest)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23667619</strong> | Pred included: 4 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23667619/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23667619_analysis_0</td><td>CSL&gt;TIC</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast CSL&gt;TIC compares complex social (joy/taunt) versus tickling laughter and explicitly probes processing of social information in vocal signals; tasks involve social categorization and implicit/explicit social evaluation, so this contrast measures social processing.</td></tr>
<tr><td>23667619_analysis_1</td><td>TIC&gt;CSL</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast TIC&gt;CSL contrasts tickling (reflex-like) versus complex social laughter and probes differences in processing socially relevant vocalizations; tasks involve social stimuli and categorization/counting, so the analysis measures social processing.</td></tr>
<tr><td>23667619_analysis_2</td><td>CAT&gt;COU</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast CAT&gt;COU contrasts explicit laughter-type categorization versus an implicit bout-counting task, manipulating attention to social information and thus indexing social processing.</td></tr>
<tr><td>23667619_analysis_3</td><td>HAP&lt;sub&gt;CAT&lt;/sub&gt; ∩ TAU&lt;sub&gt;CAT&lt;/sub&gt; ∩ TIC&lt;sub&gt;CAT&lt;/sub&gt; ∩ HAP&lt;sub&gt;COU&lt;/sub&gt; ∩ TAU&lt;sub&gt;COU&lt;/sub&gt; ∩ TIC&lt;sub&gt;COU&lt;/sub&gt;</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This conjunction identifies regions commonly activated across all laughter types and tasks (auditory cortex, IFG, SMA) and thus reflects core processing of socially relevant vocal signals — i.e., social processing broadly construed.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23667619_1</td><td>CAT &gt; COU; socialcommunication</td><td>23667619_analysis_2</td><td>CAT&gt;COU</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23667619_2</td><td>CSL &gt; TIC; socialcommunication</td><td>23667619_analysis_0</td><td>CSL&gt;TIC</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23667619_3</td><td>TIC &gt; CSL; socialcommunication</td><td>23667619_analysis_1</td><td>TIC&gt;CSL</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23684882</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=3</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23684882/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> [(S-IMIO &gt; NS-IMIO) &gt; (S-CTO &gt; NS-CTO)] &gt; [(S-IMIE &gt; NS-IMIE) &gt; (S-CTE &gt; NS- CTE)]; socialcommunication, [(S-IMIO &gt; S-CTO) + (S-IMIE &gt; S-CTE)] &gt; [(NS-IMIO &gt; NS-CTO) + (NS-IMIE &gt; NS-CTE)]; socialcommunication, [S (IMIO + CTO + IMIE + CTE) &gt; NS (IMIO + CTO + IMIE + CTE)]; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23684882_analysis_0</td><td>(IMI_O &gt; CT_O) ∩ (IMI_E &gt; CT_E)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast isolates imitation vs control across observation and execution of gestures (IMI&gt;CT in both phases). This is a social-related task involving perception and processing of communicative and non-communicative gestures and examines networks (MNS, pSTS, medial frontal areas) implicated in social cognition. Thus it measures broad Social Processing.</td></tr>
<tr><td>23684882_analysis_1</td><td>(S-IMI_O &gt; NS-IMI_O) &gt; (S-CT_O &gt; NS-CT_O)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This interaction specifically contrasts social versus non-social gestures during imitation versus control in the observation phase, directly addressing recognition and processing of communicative (social) gestures and associated social-cognitive mechanisms.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23684882_1</td><td>(IMIO &gt; CTO) ∩ (IMIE &gt; CTE); socialcommunication</td><td>23684882_analysis_0</td><td>(IMI_O &gt; CT_O) ∩ (IMI_E &gt; CT_E)</td><td>0.931</td><td>0.950</td><td>0.944</td><td>accepted</td><td>high_coord_match</td></tr><tr><td>23684882_2</td><td>(S-IMIO&gt;NS-IMIO) &gt; (S-CTO &gt; NS-CTO); socialcommunication</td><td>23684882_analysis_1</td><td>(S-IMI_O &gt; NS-IMI_O) &gt; (S-CT_O &gt; NS-CT_O)</td><td>0.949</td><td>1.000</td><td>0.985</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23684882_3</td><td>[(S-IMIO &gt; NS-IMIO) &gt; (S-CTO &gt; NS-CTO)] &gt; [(S-IMIE &gt; NS-IMIE) &gt; (S-CTE &gt; NS- CTE)]; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>23684882_4</td><td>[(S-IMIO &gt; S-CTO) + (S-IMIE &gt; S-CTE)] &gt; [(NS-IMIO &gt; NS-CTO) + (NS-IMIE &gt; NS-CTE)]; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>23684882_5</td><td>[S (IMIO + CTO + IMIE + CTE) &gt; NS (IMIO + CTO + IMIE + CTE)]; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23722983</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23722983/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23722983_analysis_0</td><td>Intention effect</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The intention effect examines interns&#x27; intentions to recommend ideas — a social task involving planning social communication and influence. This maps onto broad social processing (perceiving, interpreting, and responding to social information).</td></tr>
<tr><td>23722983_analysis_1</td><td>Salesperson effect</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The salesperson effect indexes interns&#x27; success at persuading producers — a social-influence task involving social cognition and interaction, fitting broad social processing.</td></tr>
<tr><td>23722983_analysis_2</td><td>Buzz effect</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The buzz effect identifies neural responses predicting which ideas spread across people — inherently social processing (valuation and mentalizing in a social propagation context).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23722983_1</td><td>Buzz effect; socialcommunication</td><td>23722983_analysis_2</td><td>Buzz effect</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23722983_2</td><td>Intention effect; socialcommunication</td><td>23722983_analysis_0</td><td>Intention effect</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23722983_3</td><td>Salesperson effect; socialcommunication</td><td>23722983_analysis_1</td><td>Salesperson effect</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23813661</strong> | Pred included: 5 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23813661/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23813661_analysis_0</td><td>Regions more responsive to meaningful than scrambled videos</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast compares meaningful dyadic social interaction videos vs scrambled controls; task required participants to evaluate naturalness of social scenes, so the analysis measures social processing broadly.</td></tr>
<tr><td>23813661_analysis_1</td><td>1. Contingent &gt; Mirrored</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast (Contingent &gt; Mirrored) isolates processing of dyadic social contingency — a social task measuring perception and interpretation of social interactions, thus indexing social processing.</td></tr>
<tr><td>23813661_analysis_2</td><td>2. Mirrored &gt; Contingent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast (Mirrored &gt; Contingent) still addresses processing of dyadic social stimuli (here symmetry/noncontingency) and participants&#x27; social judgments of naturalness, so it falls under social processing.</td></tr>
<tr><td>23813661_analysis_3</td><td>1. Rigid &gt; Smooth</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast (Rigid &gt; Smooth) addresses processing of kinematic properties of dyadic social stimuli and participants&#x27; social-evaluative judgments (naturalness), so it measures social processing broadly.</td></tr>
<tr><td>23813661_analysis_4</td><td>2. Interaction: (Contingent &gt; Mirrored) &gt; (Smooth &gt; Rigid)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Interaction contrast [(Contingent&gt;Mirrored) for Smooth&gt;Rigid] examines combined effects of contingency and fluency on perception of dyadic social interactions — a social processing measure.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23813661_1</td><td>(Contingent &gt; Mirrored) &gt; (Smooth &gt; Rigid); others</td><td>23813661_analysis_4</td><td>2. Interaction: (Contingent &gt; Mirrored) &gt; (Smooth &gt; Rigid)</td><td>0.840</td><td>1.000</td><td>0.952</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23813661_2</td><td>Contingent &gt; Mirrored; others</td><td>23813661_analysis_1</td><td>1. Contingent &gt; Mirrored</td><td>0.933</td><td>1.000</td><td>0.980</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23813661_3</td><td>Mirrored &gt; Contingent; others</td><td>23813661_analysis_2</td><td>2. Mirrored &gt; Contingent</td><td>0.933</td><td>1.000</td><td>0.980</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23813661_4</td><td>Rigid &gt; Smooth; others</td><td>23813661_analysis_3</td><td>1. Rigid &gt; Smooth</td><td>0.903</td><td>1.000</td><td>0.971</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23813661_5</td><td>meaningful videos &gt; scrambled videos; others</td><td>23813661_analysis_0</td><td>Regions more responsive to meaningful than scrambled videos</td><td>0.589</td><td>1.000</td><td>0.877</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24243619</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24243619/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24243619_analysis_0</td><td>Main effects of social judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast isolates neural correlates of explicit social trait judgments (trustworthiness and attractiveness) versus control conditions, directly measuring social processing across participants.</td></tr>
<tr><td>24243619_analysis_1</td><td>Overlapping effects during social and emotional judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This conjunction includes social trait judgments (TR, AT) together with emotional judgments (HA) contrasted to AG, thus clearly engaging social processing of vocal cues.</td></tr>
<tr><td>24243619_analysis_2</td><td>Overlapping effects during social and cognitive judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This conjunction includes social trait judgments (TR, AT) and age judgments (AG) contrasted to happiness (HA), indexing social and trait-processing of vocal stimuli and thus social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24243619_1</td><td>[(TR−AG)∩(AT−AG)∩(HA−AG)]; socialcommunication</td><td>24243619_analysis_1</td><td>Overlapping effects during social and emotional judgments</td><td>0.291</td><td>1.000</td><td>0.787</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>24243619_2</td><td>[(TR−HA)∩(AT−HA)∩(AG−HA)]; socialcommunication</td><td>24243619_analysis_2</td><td>Overlapping effects during social and cognitive judgments</td><td>0.330</td><td>1.000</td><td>0.799</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>24243619_3</td><td>[(TR−HA)∩(AT−HA)∩(TR−AG)∩(AT−AG)]; socialcommunication</td><td>24243619_analysis_0</td><td>Main effects of social judgments</td><td>0.256</td><td>1.000</td><td>0.777</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24294841</strong> | Pred included: 8 | Manual included (accepted matches only): 7 | Correct overlaps: 7 | Match statuses: accepted=7, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24294841/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24294841_analysis_0</td><td>Main effect (ES + TS + SRS) - (EN + TN + SRN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast tests the main effect of emotional (sad vs neutral) context across all three social conditions (empathy, ToM, self-reference). The task explicitly involves social cognition (inferring internal states of pictured people), satisfying social processing.</td></tr>
<tr><td>24294841_analysis_1</td><td>Empathy ES-EN</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast (Empathy: sad vs neutral) isolates social cognitive processing of others’ emotions (imagining what the main character feels), directly measuring social processing.</td></tr>
<tr><td>24294841_analysis_2</td><td>ToM TS-TN</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast (ToM: sad vs neutral) involves social cognitive processes (inferring what would make another feel better), so it measures social processing.</td></tr>
<tr><td>24294841_analysis_3</td><td>Self-reference SRS-SRN</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Self-reference sad vs neutral isolates social-cognitive processes in a first-person perspective within a social task (imagining oneself in another’s situation), so it is social processing relevant.</td></tr>
<tr><td>24294841_analysis_4</td><td>Empathy &gt; ToM(ES + EN)-(TS + TN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This contrast compares Empathy vs ToM across emotions and directly probes different kinds of social cognition (inferring feelings vs reasoning about how to help), so it clearly measures social processing.</td></tr>
<tr><td>24294841_analysis_5</td><td>ToM &gt; Empathy(TS + TN)-(ES + EN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>ToM &gt; Empathy directly probes social cognitive processes (higher-order reasoning about another’s state vs empathic feeling), so it measures social processing.</td></tr>
<tr><td>24294841_analysis_6</td><td>Empathy &gt; Self-reference(ES + EN)-(SRS + SRN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Empathy &gt; Self-reference contrasts other-focused social inference (imagining another’s feelings) against self-focused perspective, so it probes social processing and self–other differentiation.</td></tr>
<tr><td>24294841_analysis_7</td><td>Self-reference &gt; Empathy(SRS + SRN)-(ES + EN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Self-reference &gt; Empathy isolates self-focused social-cognitive processing (imagining oneself in another’s situation compared to inferring another’s feelings), so it is clearly social processing relevant.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24294841_1</td><td>Empathy &gt; Self-reference; others</td><td>24294841_analysis_6</td><td>Empathy &gt; Self-reference(ES + EN)-(SRS + SRN)</td><td>0.727</td><td>1.000</td><td>0.918</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24294841_2</td><td>Empathy ES–EN; others</td><td>24294841_analysis_1</td><td>Empathy ES-EN</td><td>0.923</td><td>0.833</td><td>0.860</td><td>accepted</td><td>high_coord_match</td></tr><tr><td>24294841_3</td><td>Main effect (ES + TS + SRS) – (EN + TN + SRN); others</td><td>24294841_analysis_0</td><td>Main effect (ES + TS + SRS) - (EN + TN + SRN)</td><td>0.978</td><td>1.000</td><td>0.993</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24294841_4</td><td>Self-reference &gt;  Empathy; self</td><td>24294841_analysis_7</td><td>Self-reference &gt; Empathy(SRS + SRN)-(ES + EN)</td><td>0.720</td><td>1.000</td><td>0.916</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24294841_5</td><td>Self-reference SRS–SRN; self</td><td>24294841_analysis_3</td><td>Self-reference SRS-SRN</td><td>0.955</td><td>1.000</td><td>0.986</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24294841_6</td><td>ToM &gt; Empathy; others</td><td>24294841_analysis_5</td><td>ToM &gt; Empathy(TS + TN)-(ES + EN)</td><td>0.642</td><td>1.000</td><td>0.892</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24294841_7</td><td>ToM TS–TN; others</td><td>24294841_analysis_2</td><td>ToM TS-TN</td><td>0.889</td><td>0.857</td><td>0.867</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24294906</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24294906/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24294906_analysis_0</td><td>Main effect of social value orientation on decision-making</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis examines neural differences between prosocial and proself participants during one-shot prisoner’s dilemma decisions, focusing on social cognition (medial PFC, TPJ, precuneus) and how dispositional trust and SVO shape cooperative behavior. This is a social-related task and the contrast measures social processing (mentalizing, trust, cooperation).</td></tr>
<tr><td>24294906_analysis_1</td><td>Interaction effect between dispositional trust and social value orientation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This analysis tests the interaction between dispositional trust and SVO on neural activation in social cognition regions (TPJ, medial frontal cortex, precuneus). It directly measures social processing related to trust and cooperation.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24294906_1</td><td>Interaction effect between dispositional trust and social value orientation; others</td><td>24294906_analysis_1</td><td>Interaction effect between dispositional trust and social value orientation</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24294906_2</td><td>Main effect of social value orientation on decision-making; others</td><td>24294906_analysis_0</td><td>Main effect of social value orientation on decision-making</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24414614</strong> | Pred included: 7 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24414614/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24414614_analysis_0</td><td>Imitating</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Imitating is an online social interaction task requiring perception, interpretation and response to another person’s actions (role switching between model and imitator). This directly measures social processing (social interaction, action understanding, anticipation).</td></tr>
<tr><td>24414614_analysis_1</td><td>Being imitated</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Being imitated is an interactive social condition requiring interpretation of another’s behavior and role dynamics, thus measuring social processing.</td></tr>
<tr><td>24414614_analysis_2</td><td>Observation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Observation of hand gestures is a social perception task (perceiving another’s actions) and forms the baseline social processing condition in this study.</td></tr>
<tr><td>24414614_analysis_3</td><td>Imitating-IFG</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>PPI for Imitating-IFG examines changes in functional connectivity of mirror system during an online social interaction; this directly assesses social processing integration between action and mentalizing systems.</td></tr>
<tr><td>24414614_analysis_4</td><td>Being imitated-IFG</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>PPI for Being imitated-IFG examines functional coupling during an interactive social condition (being imitated), thus measuring social processing integration between mirror and mentalizing systems.</td></tr>
<tr><td>24414614_analysis_5</td><td>Imitating-IPL*</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>PPI for Imitating-IPL tests connectivity of a mirror-system node during imitation in an interactive social task, directly assessing social processing.</td></tr>
<tr><td>24414614_analysis_6</td><td>Being imitated-IPL</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>PPI for Being imitated-IPL examines functional coupling during an interactive social condition (being imitated), directly assessing social processing between mirror and mentalizing systems.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24414614_1</td><td>being imitated &gt; rest; socialcommunication</td><td>24414614_analysis_1</td><td>Being imitated</td><td>0.800</td><td>1.000</td><td>0.940</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24414614_2</td><td>imitating &gt; rest; socialcommunication</td><td>24414614_analysis_0</td><td>Imitating</td><td>0.720</td><td>1.000</td><td>0.916</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24414614_3</td><td>observation &gt; rest; socialcommunication</td><td>24414614_analysis_2</td><td>Observation</td><td>0.759</td><td>1.000</td><td>0.928</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24462962</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24462962/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24462962_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis examines face perception (faces &gt; houses) and links fusiform gyrus activation to quantitative social-cognition measures (EQ, SRS, SAT). This is clearly a social-related task and measures social processing broadly (face processing, empathy, social responsiveness).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24462962_1</td><td>house + faces; socialcommunication</td><td>24462962_analysis_0</td><td>analysis_0</td><td>0.182</td><td>1.000</td><td>0.755</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24583253</strong> | Pred included: 5 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24583253/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24583253_analysis_0</td><td>Decrease in activity with the increase in group size</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast examines neural responses to witnessing an emergency modulated by number of bystanders. This is a social task assessing how social context (group size) influences processing of social scenes and action preparation. Meets I1 (social-related task).</td></tr>
<tr><td>24583253_analysis_1</td><td>Increase in activity with the increase in group size</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This analysis examines increases in activity with group size during observation of social scenes (bystander presence), a social processing manipulation. Meets I1.</td></tr>
<tr><td>24583253_analysis_2</td><td>Control &gt; bystander.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Control &gt; bystander contrast tests responses to social scenes (presence vs absence of bystanders) and visual complexity; it still involves social stimuli and context, satisfying I1.</td></tr>
<tr><td>24583253_analysis_3</td><td>Falling &gt; standing</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Falling &gt; standing contrasts responses to another&#x27;s emergency vs neutral action; this is a social task probing processing of others in distress and therefore meets I1 for social processing.</td></tr>
<tr><td>24583253_analysis_4</td><td>Standing &gt; falling</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Standing &gt; falling contrasts responses to the person standing versus falling, manipulating social content and perception of others; qualifies as social processing under I1.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24583253_1</td><td>control &gt; bystander; others</td><td>24583253_analysis_2</td><td>Control &gt; bystander.</td><td>0.974</td><td>1.000</td><td>0.992</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24583253_2</td><td>falling &gt; standing; others</td><td>24583253_analysis_3</td><td>Falling &gt; standing</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24583253_3</td><td>standing &gt;  falling; others</td><td>24583253_analysis_4</td><td>Standing &gt; falling</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24726338</strong> | Pred included: 6 | Manual included (accepted matches only): 6 | Correct overlaps: 6 | Match statuses: accepted=6, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24726338/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24726338_analysis_0</td><td>Self &gt; other</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Localizer task contrasts self vs other trait judgments (social cognitive task involving self/other), so it is a social processing task measuring social cognition broadly.</td></tr>
<tr><td>24726338_analysis_1</td><td>Other &gt; self</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Localizer contrasts include other-judgment vs self, a social cognitive task involving reasoning about another person (President Obama).</td></tr>
<tr><td>24726338_analysis_2</td><td>Communication &gt; moral (collapsing across self/other)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast compares Communication &gt; Moral items from the main experiment, which involves social content and social task context (group/alone), so it falls under broad social processing.</td></tr>
<tr><td>24726338_analysis_3</td><td>Moral &gt; communication (collapsing across self/other)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Moral &gt; Communication contrast involves social-moral content and social decision-making context, so it qualifies as social processing.</td></tr>
<tr><td>24726338_analysis_4</td><td>Self &gt; other (collapsing across moral/communication)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Main-experiment Self &gt; Other contrast directly addresses self-referential processing in a social experimental context (first-person vs third-person statements during competitive tasks), meeting broad social processing criteria.</td></tr>
<tr><td>24726338_analysis_5</td><td>Other &gt; self (collapsing across moral/communication)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Other &gt; Self contrast in the main experiment involves processing of other-referential statements in a social/competitive context, so it qualifies as social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24726338_1</td><td>Communication &gt; moral (collapsing across self/other); others</td><td>24726338_analysis_2</td><td>Communication &gt; moral (collapsing across self/other)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24726338_2</td><td>Moral &gt; communication (collapsing across self/other); others</td><td>24726338_analysis_3</td><td>Moral &gt; communication (collapsing across self/other)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24726338_3</td><td>Other &gt; Self; others</td><td>24726338_analysis_1</td><td>Other &gt; self</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24726338_4</td><td>Other &gt; self (collapsing across moral/communication); others</td><td>24726338_analysis_5</td><td>Other &gt; self (collapsing across moral/communication)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24726338_5</td><td>Self &gt; other; self</td><td>24726338_analysis_0</td><td>Self &gt; other</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24726338_6</td><td>Self &gt; other (collapsing across moral/communication); self</td><td>24726338_analysis_4</td><td>Self &gt; other (collapsing across moral/communication)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24772075</strong> | Pred included: 7 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24772075/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24772075_analysis_0</td><td>MAIN EFFECT: FEEDBACK ONSET: SELF &gt; OTHER</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast examines neural responses to socially delivered feedback (self vs other) during a face-to-face interaction task—directly measures social processing.</td></tr>
<tr><td>24772075_analysis_1</td><td>MAIN EFFECT: FEEDBACK ONSET: OTHER &gt; SELF</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast examines neural responses to social feedback about the other person versus self—clearly a social processing contrast.</td></tr>
<tr><td>24772075_analysis_2</td><td>INTERACTION: FEEDBACK ONSET: (SELF &gt; OTHER) × (GERMAN &gt; CHINESE)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Interaction tests cultural modulation of social feedback processing (self vs other) — clearly within social processing domain.</td></tr>
<tr><td>24772075_analysis_3</td><td>WHOLE-BRAIN CORRELATION WITH OVERALL RELATIVE ABSOLUTE MEAN UPDATES IN THE CONTRAST FEEDBACK ONSET: SELF &gt; OTHER</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This analysis correlates whole-brain activity (self &gt; other) with behavioral updating (conformity) — directly addresses social feedback processing.</td></tr>
<tr><td>24772075_analysis_4</td><td>FEEDBACK RATING (TRIAL-BY-TRIAL CORRELATION): SELF &gt; OTHER</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Parametric correlation with feedback ratings for self isolates processing of socially delivered evaluative feedback (social reward); clearly social processing.</td></tr>
<tr><td>24772075_analysis_5</td><td>FEEDBACK DISCREPANCIES (POSITIVE TRIAL-BY-TRIAL CORRELATION): SELF AND OTHER</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Trial-by-trial correlation with feedback discrepancies (self and other) probes social comparison and mentalizing processes—core social processing.</td></tr>
<tr><td>24772075_analysis_6</td><td>FEEDBACK DISCREPANCIES (NEGATIVE TRIAL-BY-TRIAL CORRELATION): SELF AND OTHER</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Negative trial-by-trial correlations with feedback discrepancies (self and other) remain squarely within social feedback and comparison processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24772075_1</td><td>(SELF &gt; OTHER) × (GERMAN &gt; CHINESE); self</td><td>24772075_analysis_2</td><td>INTERACTION: FEEDBACK ONSET: (SELF &gt; OTHER) × (GERMAN &gt; CHINESE)</td><td>0.707</td><td>1.000</td><td>0.912</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24772075_2</td><td>OTHER &gt; SELF; others</td><td>24772075_analysis_1</td><td>MAIN EFFECT: FEEDBACK ONSET: OTHER &gt; SELF</td><td>0.453</td><td>1.000</td><td>0.836</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>24772075_3</td><td>SELF &gt; OTHER; self</td><td>24772075_analysis_0</td><td>MAIN EFFECT: FEEDBACK ONSET: SELF &gt; OTHER</td><td>0.453</td><td>1.000</td><td>0.836</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>24772075_4</td><td>SELF &gt; OTHER (CORRELATION); self</td><td>24772075_analysis_3</td><td>WHOLE-BRAIN CORRELATION WITH OVERALL RELATIVE ABSOLUTE MEAN UPDATES IN THE CONTRAST FEEDBACK ONSET: SELF &gt; OTHER</td><td>0.174</td><td>1.000</td><td>0.752</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24814646</strong> | Pred included: 5 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=2, unmatched=6</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24814646/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> A&amp;B; socialcommunication, p2&gt;n2; socialcommunication, D&amp;E; socialcommunication, a1&gt; n1; socialcommunication, a2&gt; n2; socialcommunication, p1&gt; n1; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24814646_analysis_0</td><td>fMRI contrasts on the basis of the neutral condition as baseline</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>The analysis contrasts affective (reactive–aggressive and social-positive) vs neutral interactions using first-person videos and explicit empathic instructions. This is a social-related task probing perception, interpretation, and response to social cues, so it measures broad Social Processing.</td></tr>
<tr><td>24814646_analysis_1</td><td>A</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This analysis (A) derives from the same first-person social interaction paradigm and contrasts affective vs neutral conditions; it therefore measures broad social processing.</td></tr>
<tr><td>24814646_analysis_2</td><td>B</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Analysis B uses contrasts from the first‑person social video task; it taps core social processing (perception, interpretation and responses to social interactions).</td></tr>
<tr><td>24814646_analysis_3</td><td>C</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Analysis C corresponds to contrasts from the same social-interaction fMRI paradigm and thus measures broad Social Processing networks engaged by the stimuli.</td></tr>
<tr><td>24814646_analysis_4</td><td>D</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Analysis D (final-phase contrasts) derives from the same first-person interactive video task and targets social processing (evaluation and response to interactions), so Social Processing applies.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24814646_1</td><td>A&amp;B; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>24814646_10</td><td>p2&gt;n2; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>24814646_2</td><td>D&amp;E; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>24814646_3</td><td>a1&gt; n1; socialcommunication</td><td>24814646_analysis_0</td><td>fMRI contrasts on the basis of the neutral condition as baseline</td><td>0.304</td><td>0.282</td><td>0.289</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>24814646_4</td><td>a1&gt;p1; socialcommunication</td><td>24814646_analysis_1</td><td>A</td><td>0.250</td><td>1.000</td><td>0.775</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>24814646_5</td><td>a2&gt; n2; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>24814646_6</td><td>a2&gt;p2; socialcommunication</td><td>24814646_analysis_3</td><td>C</td><td>0.069</td><td>1.000</td><td>0.721</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>24814646_7</td><td>p1&gt; n1; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>24814646_8</td><td>p1&gt;a1; socialcommunication</td><td>24814646_analysis_2</td><td>B</td><td>0.000</td><td>0.938</td><td>0.656</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>24814646_9</td><td>p2&gt;a2; socialcommunication</td><td>24814646_analysis_4</td><td>D</td><td>0.000</td><td>0.923</td><td>0.646</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24824165</strong> | Pred included: 2 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24824165/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24824165_analysis_0</td><td>Clusters of activation for (atypical-upright+atypical-inverted)-(typical-upright+typical-inverted) assessed by using all data</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast tests brain responses to typical vs. atypical (incongruent) dyadic social interactions using point-light displays while participants performed an unrelated task. This directly measures social processing (detection and interpretation of social interactions and violations of social expectations).</td></tr>
<tr><td>24824165_analysis_1</td><td>Table 2. Clusters of activation for (atypical-upright+atypical-inverted)-(typical-upright+typical-inverted) assessed by using two separate subsets of data</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Same contrast as analysis_0 (atypical vs typical dyadic point-light displays); it probes social processing of interactions and expectation violations, satisfying both inclusion criteria.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24824165_1</td><td>(atypical-upright 1 atypical-inverted) 2 (typical-upright 1 typical-inverted); others</td><td>24824165_analysis_1</td><td>Table 2. Clusters of activation for (atypical-upright+atypical-inverted)-(typical-upright+typical-inverted) assessed by using two separate subsets of data</td><td>0.594</td><td>1.000</td><td>0.878</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24825504</strong> | Pred included: 4 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24825504/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24825504_analysis_0</td><td>Brain areas activated in the conjunction triad ∩ self ∩ other.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The conjunction analysis tests common activity across triad, self, and other tasks — all are social-related mentalizing tasks (imagining social interactions, self-referential and other-referential processing). This contrast clearly measures general social processing and recruits core mentalizing regions (MPFC, PCC, TPJ).</td></tr>
<tr><td>24825504_analysis_1</td><td>Triad &gt; (Self &amp; Other)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast triad &gt; (self &amp; other) isolates neural activity specific to imagining triadic social interactions (self + other + object), a social processing task recruiting mirror and mentalizing systems.</td></tr>
<tr><td>24825504_analysis_2</td><td>Self &gt; (Other &amp; Triad)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Self &gt; (Other &amp; Triad) contrast specifically isolates self-referential processing, which is a core component of social processing and mentalizing, engaging MPFC/ACC.</td></tr>
<tr><td>24825504_analysis_3</td><td>Other &gt; (Self &amp; Triad)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Other &gt; (Self &amp; Triad) contrast isolates other-referential mentalizing (e.g., judgments about Angela Merkel) and engages core mentalizing regions (right TPJ, PCC), reflecting social processing about others.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24825504_1</td><td>Other &gt; (self &amp; triad); others</td><td>24825504_analysis_3</td><td>Other &gt; (Self &amp; Triad)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24825504_2</td><td>Self &gt; (other &amp; triad); self</td><td>24825504_analysis_2</td><td>Self &gt; (Other &amp; Triad)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24825504_3</td><td>Triad &gt; (self &amp; other); others</td><td>24825504_analysis_1</td><td>Triad &gt; (Self &amp; Other)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24825504_4</td><td>triad ∩ self ∩ other; others</td><td>24825504_analysis_0</td><td>Brain areas activated in the conjunction triad ∩ self ∩ other.</td><td>0.488</td><td>1.000</td><td>0.846</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24834034</strong> | Pred included: 5 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24834034/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24834034_analysis_0</td><td>FAIR &gt; UNFAIR</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast FAIR &gt; UNFAIR comes from an ultimatum game, a classic social-norm decision-making task involving evaluation of fairness in social exchanges. It directly measures social processing (perception/interpretation of social offers and norm enforcement).</td></tr>
<tr><td>24834034_analysis_1</td><td>FAIR &lt; UNFAIR</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The UNFAIR &gt; FAIR contrast probes neural responses to social norm violations in the ultimatum game, directly indexing social processing of others&#x27; offers and norm enforcement.</td></tr>
<tr><td>24834034_analysis_2</td><td>HUMAN &gt; COMPUTER</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>HUMAN &gt; COMPUTER directly contrasts social (human proposer) vs non-social (computer) conditions in the UG, clearly indexing social processing differences attributable to social interaction context.</td></tr>
<tr><td>24834034_analysis_3</td><td>HIGH(UNFAIR–FAIR) &gt; LOW(UNFAIR–FAIR)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The modulation contrast HIGH(UNFAIR–FAIR) &gt; LOW(UNFAIR–FAIR) examines how monetary incentives alter fairness-related social decision-making in the UG, a social processing measure.</td></tr>
<tr><td>24834034_analysis_4</td><td>HIGH(UNFAIR–FAIR) &gt; LOW(UNFAIR–FAIR) WITHIN HUMAN</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This is the same modulation contrast restricted to human proposers; it directly indexes social processing in interpersonal contexts (how incentives change norm enforcement with human partners).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24834034_1</td><td>FAIR &lt; UNFAIR; self</td><td>24834034_analysis_1</td><td>FAIR &lt; UNFAIR</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24834034_2</td><td>FAIR &gt; UNFAIR; self</td><td>24834034_analysis_0</td><td>FAIR &gt; UNFAIR</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24834034_3</td><td>HIGH(UNFAIR–FAIR) &gt; LOW(UNFAIR–FAIR); self</td><td>24834034_analysis_3</td><td>HIGH(UNFAIR–FAIR) &gt; LOW(UNFAIR–FAIR)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24834034_4</td><td>HIGH(UNFAIR–FAIR) &gt; LOW(UNFAIR–FAIR) WITHIN HUMAN; self</td><td>24834034_analysis_4</td><td>HIGH(UNFAIR–FAIR) &gt; LOW(UNFAIR–FAIR) WITHIN HUMAN</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24834034_5</td><td>HUMAN &gt; COMPUTER; self</td><td>24834034_analysis_2</td><td>HUMAN &gt; COMPUTER</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24842782</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24842782/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24842782_analysis_0</td><td>Angry &gt;neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast Angry &gt; Neutral uses socially relevant video of an opponent&#x27;s facial expression during a social interaction (Taylor Aggression Paradigm). This directly measures social processing (perception and response to social cues) across subjects.</td></tr>
<tr><td>24842782_analysis_1</td><td>Angry &gt;neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Angry &gt; Neutral (outcome or decision phase) involves processing socially relevant emotional expressions in an interactive context; thus it measures social processing.</td></tr>
<tr><td>24842782_analysis_2</td><td>Parametric modulation angry &gt;neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Parametric modulation of Angry &gt; Neutral with punishment selections links trial-by-trial social cue processing to social behavior in an interactive task, satisfying Social Processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24842782_1</td><td>Decision phase: Angry &gt; neutral; socialcommunication</td><td>24842782_analysis_1</td><td>Angry &gt;neutral</td><td>0.652</td><td>1.000</td><td>0.896</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24842782_2</td><td>Decision phase: Parametric modulation angry &gt; neutral; socialcommunication</td><td>24842782_analysis_2</td><td>Parametric modulation angry &gt;neutral</td><td>0.822</td><td>1.000</td><td>0.947</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24842782_3</td><td>Outcome phase: Angry &gt; neutral; socialcommunication</td><td>24842782_analysis_0</td><td>Angry &gt;neutral</td><td>0.667</td><td>1.000</td><td>0.900</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24936688</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24936688/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24936688_analysis_0</td><td>Status Type by Status Level interaction</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is impression formation of social targets (faces) paired with moral/financial status cues and the contrasts assess neural responses to social status — this is a social processing task measuring social cognition and evaluation.</td></tr>
<tr><td>24936688_analysis_1</td><td>Status Type main effect</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The main effect of Status Type compares responses to different social status dimensions (moral vs financial) during impression formation of faces — a social processing contrast measuring social cognition.</td></tr>
<tr><td>24936688_analysis_2</td><td>Status Level main effect</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The main effect of Status Level (Lower/Same/Higher) examines social-evaluative processing during impression formation of faces with status cues — a core social processing measure.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24936688_1</td><td>Status Level &gt; baseline; socialcommunication</td><td>24936688_analysis_2</td><td>Status Level main effect</td><td>0.723</td><td>1.000</td><td>0.917</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24936688_2</td><td>Status Type &gt; baseline; socialcommunication</td><td>24936688_analysis_1</td><td>Status Type main effect</td><td>0.711</td><td>1.000</td><td>0.913</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24936688_3</td><td>Status Type x Status Level &gt; baseline; socialcommunication</td><td>24936688_analysis_0</td><td>Status Type by Status Level interaction</td><td>0.763</td><td>1.000</td><td>0.929</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25118071</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25118071/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25118071_analysis_0</td><td>CV&gt;NV contrast</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The CV&gt;NV contrast contrasts social, empathy-inducing campaign videos with neutral driving videos and explicitly targets socio-cognitive and socio-emotional processing (empathy, mentalising). This meets both criteria: the task is social and the contrast measures social processing related to understanding others’ mental/emotional states.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25118071_1</td><td>CV &gt; NV; others</td><td>25118071_analysis_0</td><td>CV&gt;NV contrast</td><td>0.774</td><td>1.000</td><td>0.932</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25281889</strong> | Pred included: 12 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25281889/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25281889_analysis_0</td><td>HA&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves explicit labeling of briefly presented emotional facial expressions — a prototypical social-processing task requiring perception and interpretation of others&#x27; emotions. The contrast (happy&gt;neutral) measures social processing of facial emotion.</td></tr>
<tr><td>25281889_analysis_1</td><td>AN&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Angry&gt;neutral contrast is a social task requiring perception and interpretation of another person&#x27;s emotional expression; it measures social processing.</td></tr>
<tr><td>25281889_analysis_2</td><td>FE&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Fearful&gt;neutral contrast requires perceiving, interpreting, and labeling another person&#x27;s emotional expression; it is a social-processing measure.</td></tr>
<tr><td>25281889_analysis_3</td><td>HA&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This analysis examines correlations between neural responses to happy&gt;neutral and alexithymia during an emotion-labeling task — a social-processing investigation of individual differences in social cognition.</td></tr>
<tr><td>25281889_analysis_4</td><td>AN&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This analysis studies neural correlates of perceiving angry&gt;neutral faces as a function of alexithymia — directly addressing social processing mechanisms for others&#x27; emotions.</td></tr>
<tr><td>25281889_analysis_5</td><td>FE&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Analysis relates fearful&gt;neutral brain responses to alexithymia during an emotion labeling task — a social-processing assessment of perceiving others&#x27; emotions.</td></tr>
<tr><td>25281889_analysis_6</td><td>HA&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>TAS-20-DDF correlations with happy&gt;neutral reflect individual differences in social perception and labeling of facial emotion, thus a social-processing measure.</td></tr>
<tr><td>25281889_analysis_7</td><td>AN&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>TAS-20-DDF correlations with angry&gt;neutral probe how individual differences affect social processing of anger faces — a social-processing analysis.</td></tr>
<tr><td>25281889_analysis_8</td><td>FE&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>TAS-20-DDF correlations with fearful&gt;neutral examine social-processing differences in perceiving fearful faces linked to alexithymia.</td></tr>
<tr><td>25281889_analysis_9</td><td>HA&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>TSIA-DDF correlations with happy&gt;neutral probe observer-rated alexithymia effects on social perception of facial emotion — a social-processing analysis.</td></tr>
<tr><td>25281889_analysis_10</td><td>AN&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>TSIA-DDF correlations with angry&gt;neutral investigate how observer-rated alexithymia modulates social processing of angry faces — a social-processing measure.</td></tr>
<tr><td>25281889_analysis_11</td><td>FE&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>TSIA-DDF correlations with fearful&gt;neutral probe how observer-rated alexithymia affects social processing of fearful faces — clearly a social-processing analysis.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25281889_1</td><td>AN &gt; NE; socialcommunication</td><td>25281889_analysis_1</td><td>AN&gt;NE</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25281889_2</td><td>FE &gt; NE; socialcommunication</td><td>25281889_analysis_2</td><td>FE&gt;NE</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25281889_3</td><td>HA &gt; NE; socialcommunication</td><td>25281889_analysis_0</td><td>HA&gt;NE</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25315788</strong> | Pred included: 3 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25315788/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25315788_analysis_0</td><td>A. Univariate analysis: friend minus pc</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast friend minus PC directly probes social context and engages the mentalizing network; it measures social processing (dmPFC, TPJ, precuneus activations).</td></tr>
<tr><td>25315788_analysis_1</td><td>B. Searchlight-based MVPA: happy versus sad</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>MVPA (happy vs sad) is embedded in a social-communication experiment and examines encoding of socially-relevant affective message content, so it falls under social processing.</td></tr>
<tr><td>25315788_analysis_2</td><td>C. Searchlight-based MVCA: friend minus pc</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>MVCA explicitly tests sender-dependent gating of sensory information into social-cognitive regions (dmPFC) and therefore indexes social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25315788_1</td><td>univariate analysis: friend minus pc; others</td><td>25315788_analysis_0</td><td>A. Univariate analysis: friend minus pc</td><td>0.960</td><td>1.000</td><td>0.988</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25640962</strong> | Pred included: 5 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25640962/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> (IC &gt; NG ∩ ego &gt; allo) (conjunction analysis); socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25640962_analysis_0</td><td>IC&gt;NG</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task explicitly probes social processing: participants judged whether they felt addressed by videos manipulating co-speech gestures and actor orientation. The IC&gt;NG contrast measures neural responses to a social cue (gesture) within that social judgment task.</td></tr>
<tr><td>25640962_analysis_1</td><td>ego&gt;allo</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The ego&gt;allo contrast probes social self-involvement and addressment (actor orientation) during an explicit social judgment; it measures social processing related to engagement and self-involvement.</td></tr>
<tr><td>25640962_analysis_2</td><td>allo&gt;ego</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The allo&gt;ego contrast examines processing when the actor is allocentric (less addressing) within an explicit social task, thus indexing social processing related to communicative context and interpretation.</td></tr>
<tr><td>25640962_analysis_3</td><td>(IC-ego&gt;IC-allo)&gt;(NG-ego&gt;NG-allo)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This interaction ((IC-ego&gt;IC-allo)&gt;(NG-ego&gt;NG-allo)) directly targets how gesture and body orientation jointly influence the feeling of being addressed—clearly a social processing measure.</td></tr>
<tr><td>25640962_analysis_4</td><td>(IC-allo&gt;NG-allo)&gt;(IC-ego&gt;NG-ego)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This interaction ((IC-allo&gt;NG-allo)&gt;(IC-ego&gt;NG-ego)) evaluates how gesture effects differ by actor orientation within the social addressment judgment task—clearly social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25640962_1</td><td>(IC &gt; NG ∩ ego &gt; allo) (conjunction analysis); socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>25640962_2</td><td>(IC-allo&gt;NG-allo)&gt;(IC-ego&gt;NG-ego); socialcommunication</td><td>25640962_analysis_4</td><td>(IC-allo&gt;NG-allo)&gt;(IC-ego&gt;NG-ego)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25640962_3</td><td>(IC-ego&gt;IC-allo)&gt; (NG-ego&gt;NG-allo); socialcommunication</td><td>25640962_analysis_3</td><td>(IC-ego&gt;IC-allo)&gt;(NG-ego&gt;NG-allo)</td><td>1.000</td><td>0.800</td><td>0.860</td><td>accepted</td><td>high_coord_match</td></tr><tr><td>25640962_4</td><td>IC &gt; NG; socialcommunication</td><td>25640962_analysis_0</td><td>IC&gt;NG</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25640962_5</td><td>allo &gt; ego; socialcommunication</td><td>25640962_analysis_2</td><td>allo&gt;ego</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25640962_6</td><td>ego &gt; allo; socialcommunication</td><td>25640962_analysis_1</td><td>ego&gt;allo</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25697049</strong> | Pred included: 7 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25697049/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25697049_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The localizer and ROI table are part of a study on person perception and were used to identify face- and body-selective regions for subsequent social-dyad analyses; this is directly related to social processing.</td></tr>
<tr><td>25697049_analysis_1</td><td>Congruent Interactions &gt; Incongruent Interactions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Contrast compares congruent (meaningful) social interactions to incongruent dyads; it directly tests social scene processing and how social relations modulate perception.</td></tr>
<tr><td>25697049_analysis_2</td><td>Incongruent Interactions &gt; Congruent Interactions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast (incongruent &gt; congruent) examines social-scene incongruency effects on person perception, a social processing phenomenon.</td></tr>
<tr><td>25697049_analysis_3</td><td>Congruent Interactions &gt; Non-Interactions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Contrast compares congruent interactions (meaningful social scenes) to non-interactions; this directly tests social scene processing and its effect on person perception.</td></tr>
<tr><td>25697049_analysis_4</td><td>Non-Interactions &gt; Congruent Interactions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Non-interactions &gt; congruent interactions still concerns social scenes and how their relational properties modulate neural responses; thus it falls under social processing.</td></tr>
<tr><td>25697049_analysis_5</td><td>Incongruent Interactions &gt; Non-Interactions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Incongruent interactions &gt; non-interactions compares different types of social scenes and how social relations affect perception, fulfilling social processing inclusion.</td></tr>
<tr><td>25697049_analysis_6</td><td>Non-Interactions &gt; Incongruent Interactions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Non-interactions &gt; incongruent interactions compares social scene types and neural sensitivity to differing relational properties, so it pertains to social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25697049_1</td><td>Incongruent Interactions &gt; Congruent Interactions; others</td><td>25697049_analysis_2</td><td>Incongruent Interactions &gt; Congruent Interactions</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25697049_2</td><td>Incongruent Interactions &gt; Non-Interactions; others</td><td>25697049_analysis_5</td><td>Incongruent Interactions &gt; Non-Interactions</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25716010</strong> | Pred included: 11 | Manual included (accepted matches only): 10 | Correct overlaps: 10 | Match statuses: accepted=10, uncertain=1, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25716010/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25716010_analysis_0</td><td>A. Fear&gt;happy+neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast (Fear &gt; Happy+Neutral) examines perception of emotional crowds and group dynamics, which is a social task assessing social processing across emotions.</td></tr>
<tr><td>25716010_analysis_1</td><td>B. Fear+happy&gt;neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Fear+Happy &gt; Neutral examines processing of emotionally expressive crowds versus neutral, a social perceptual task assessing social processing.</td></tr>
<tr><td>25716010_analysis_2</td><td>C. Fear+neutral&gt;happy</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Fear+Neutral &gt; Happy contrasts social-emotional responses across conditions and is a social processing analysis of group emotion perception.</td></tr>
<tr><td>25716010_analysis_3</td><td>D. Happy&gt;fear+neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Happy &gt; Fear+Neutral examines social perception of positive crowd emotion versus others, a social processing task.</td></tr>
<tr><td>25716010_analysis_4</td><td>E. Neutral&gt;fear+happy</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Neutral &gt; Fear+Happy contrasts responses to neutral crowds versus emotional ones; still a social task involving group perception.</td></tr>
<tr><td>25716010_analysis_5</td><td>Main effect of dynamics.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Main effect of dynamics (interactive &gt; individual) directly probes sensitivity to social interactions and group dynamics — a core social processing measure.</td></tr>
<tr><td>25716010_analysis_6</td><td>A. Interactive fear&gt;individual fear</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Interactive fear &gt; individual fear assesses processing of socially salient panic-like interactions — clearly social processing.</td></tr>
<tr><td>25716010_analysis_7</td><td>B. Interactive fear&gt;individual fear+interactive happy&gt;individual happy</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The compound contrast (interactive fear&gt;individual fear + interactive happy&gt;individual happy) targets social interaction effects across emotions — a social processing measure.</td></tr>
<tr><td>25716010_analysis_8</td><td>C. Interactive fear&gt;individual fear+interactive neutral&gt;individual neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Interactive fear&gt;individual fear + interactive neutral&gt;individual neutral examines social interaction effects specifically for fear and neutral conditions — a social processing analysis.</td></tr>
<tr><td>25716010_analysis_9</td><td>D. Interactive fear&gt;individual fear+individual neutral&gt;interactive neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Interactive fear&gt;individual fear + individual neutral&gt;interactive neutral tests interaction-by-emotion effects — a social processing contrast focused on group behavior and emotion.</td></tr>
<tr><td>25716010_analysis_10</td><td>E. Interactive neutral&gt;individual neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Interactive neutral &gt; individual neutral compares social interaction effects even in neutral crowds, a social processing measure of group dynamics.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25716010_1</td><td>Fear +  happy &gt; neutral; socialcommunication</td><td>25716010_analysis_1</td><td>B. Fear+happy&gt;neutral</td><td>0.889</td><td>1.000</td><td>0.967</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25716010_10</td><td>Neutral &gt; fear +  happy; socialcommunication</td><td>25716010_analysis_4</td><td>E. Neutral&gt;fear+happy</td><td>0.889</td><td>1.000</td><td>0.967</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25716010_11</td><td>interactive &gt; individual; socialcommunication</td><td>25716010_analysis_5</td><td>Main effect of dynamics.</td><td>0.348</td><td>0.882</td><td>0.722</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>25716010_2</td><td>Fear + neutral &gt; happy; socialcommunication</td><td>25716010_analysis_2</td><td>C. Fear+neutral&gt;happy</td><td>0.889</td><td>1.000</td><td>0.967</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25716010_3</td><td>Fear &gt; happy +  neutral; socialcommunication</td><td>25716010_analysis_0</td><td>A. Fear&gt;happy+neutral</td><td>0.889</td><td>1.000</td><td>0.967</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25716010_4</td><td>Happy &gt; fear + neutral; socialcommunication</td><td>25716010_analysis_3</td><td>D. Happy&gt;fear+neutral</td><td>0.889</td><td>1.000</td><td>0.967</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25716010_5</td><td>Interactive fear &gt; individual fear; socialcommunication</td><td>25716010_analysis_6</td><td>A. Interactive fear&gt;individual fear</td><td>0.958</td><td>1.000</td><td>0.987</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25716010_6</td><td>Interactive fear &gt; individual fear +  individual neutral &gt; interactive neutral; socialcommunication</td><td>25716010_analysis_9</td><td>D. Interactive fear&gt;individual fear+individual neutral&gt;interactive neutral</td><td>0.968</td><td>1.000</td><td>0.990</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25716010_7</td><td>Interactive fear &gt; individual fear + interactive happy &gt; individual happy; socialcommunication</td><td>25716010_analysis_7</td><td>B. Interactive fear&gt;individual fear+interactive happy&gt;individual happy</td><td>0.966</td><td>1.000</td><td>0.990</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25716010_8</td><td>Interactive fear &gt; individual fear + interactive neutral &gt; individual neutral; socialcommunication</td><td>25716010_analysis_8</td><td>C. Interactive fear&gt;individual fear+interactive neutral&gt;individual neutral</td><td>0.968</td><td>1.000</td><td>0.990</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25716010_9</td><td>Interactive neutral &gt; individual neutral; socialcommunication</td><td>25716010_analysis_10</td><td>E. Interactive neutral&gt;individual neutral</td><td>0.964</td><td>1.000</td><td>0.989</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25729358</strong> | Pred included: 6 | Manual included (accepted matches only): 6 | Correct overlaps: 6 | Match statuses: accepted=6, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25729358/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25729358_analysis_0</td><td>simple deception and sophisticated deception trials vs. truth trials</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast (simple + sophisticated deception vs. truth) assesses intentional deceptive behavior in a strategic, interpersonal game—clearly a social processing task involving understanding and responding to social information.</td></tr>
<tr><td>25729358_analysis_1</td><td>Simple deception vs. truth</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Simple deception vs. truth investigates deliberate interpersonal deception in a game context, a social processing task.</td></tr>
<tr><td>25729358_analysis_2</td><td>Sophisticated deception vs. truth</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Sophisticated deception vs. truth examines strategic interpersonal behavior (telling truth with intent to deceive), a social processing task.</td></tr>
<tr><td>25729358_analysis_3</td><td>Sophisticated deception vs. simple deception</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast sophisticated vs. simple deception compares two interpersonal, strategic behaviors—both social processing phenomena.</td></tr>
<tr><td>25729358_analysis_4</td><td>Truth vs. simple and sophisticated deception</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Truth vs. deception contrasts genuine belief-to-belief interactions, assessing social decision-making and intention in interpersonal exchanges—central to social processing.</td></tr>
<tr><td>25729358_analysis_5</td><td>Parametric analysis modeling the incentive to deceive for simple deception trials</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The parametric analysis models incentive to deceive in an interpersonal game—this is a social processing manipulation of social incentives.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25729358_1</td><td>difference between sender and reciever payoff &gt; baseline; others</td><td>25729358_analysis_5</td><td>Parametric analysis modeling the incentive to deceive for simple deception trials</td><td>0.248</td><td>1.000</td><td>0.774</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>25729358_2</td><td>simple &amp; sophisticated deception &gt; truth; others</td><td>25729358_analysis_0</td><td>simple deception and sophisticated deception trials vs. truth trials</td><td>0.724</td><td>1.000</td><td>0.917</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25729358_3</td><td>simple deception &gt; truth; others</td><td>25729358_analysis_1</td><td>Simple deception vs. truth</td><td>0.920</td><td>1.000</td><td>0.976</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25729358_4</td><td>sophisticated deception &gt; simple deception; others</td><td>25729358_analysis_3</td><td>Sophisticated deception vs. simple deception</td><td>0.953</td><td>1.000</td><td>0.986</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25729358_5</td><td>sophisticated deception &gt; truth; others</td><td>25729358_analysis_2</td><td>Sophisticated deception vs. truth</td><td>0.938</td><td>1.000</td><td>0.981</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25729358_6</td><td>truth &gt; simple deception &amp; sophisticated deception; others</td><td>25729358_analysis_4</td><td>Truth vs. simple and sophisticated deception</td><td>0.830</td><td>1.000</td><td>0.949</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25929599</strong> | Pred included: 5 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25929599/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25929599_analysis_0</td><td>Incongruent &gt; Congruent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast Incongruent &gt; Congruent indexes regulation of automatic imitation (mimicry) in a task that includes facial stimuli and social-affective context; it directly measures social processing (perceiving and responding to social cues, action observation, and social interaction processes).</td></tr>
<tr><td>25929599_analysis_1</td><td>Happy (Incongruent &gt; Congruent) masked inclusively with Happy (Incongruent &gt; Congruent) &gt; Angry (Incongruent &gt; Congruent)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast isolates mimicry regulation specifically when happy faces are shown, a clear social-affective manipulation measuring social processing.</td></tr>
<tr><td>25929599_analysis_2</td><td>Angry (Incongruent &gt; Congruent) masked inclusively with Angry (Incongruent &gt; Congruent) &gt; Happy (Incongruent &gt; Congruent)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast isolates mimicry regulation when angry faces are shown; it is a social-affective manipulation and therefore measures social processing.</td></tr>
<tr><td>25929599_analysis_3</td><td>Out-group (Incongruent &gt; Congruent) masked inclusively with Out-group (Incongruent &gt; Congruent) &gt; In-group (Incongruent &gt; Congruent)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast targets mimicry regulation specifically for out-group faces (social group membership), directly probing social processing of intergroup cues and behavior.</td></tr>
<tr><td>25929599_analysis_4</td><td>In-group (Incongruent &gt; Congruent) masked inclusively with In-group (Incongruent &gt; Congruent) &gt; Out-group (Incongruent &gt; Congruent)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast isolates mimicry regulation for in-group faces and thus probes social processing tied to group membership and affiliative behavior.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25929599_1</td><td>Angry (Incongruent &gt; Congruent) masked inclusively with Angry (Incongruent &gt; Congruent) &gt; Happy (Incongruent &gt; Congruent); socialcommunication</td><td>25929599_analysis_2</td><td>Angry (Incongruent &gt; Congruent) masked inclusively with Angry (Incongruent &gt; Congruent) &gt; Happy (Incongruent &gt; Congruent)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25929599_2</td><td>Happy (Incongruent &gt; Congruent) masked inclusively with Happy (Incongruent &gt; Congruent) &gt; Angry (Incongruent &gt; Congruent); socialcommunication</td><td>25929599_analysis_1</td><td>Happy (Incongruent &gt; Congruent) masked inclusively with Happy (Incongruent &gt; Congruent) &gt; Angry (Incongruent &gt; Congruent)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25929599_3</td><td>In-group (Incongruent &gt; Congruent) masked inclusively with In-group (Incongruent &gt; Congruent) &gt; Out-group (Incongruent &gt; Congruent); socialcommunication</td><td>25929599_analysis_4</td><td>In-group (Incongruent &gt; Congruent) masked inclusively with In-group (Incongruent &gt; Congruent) &gt; Out-group (Incongruent &gt; Congruent)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25929599_4</td><td>Incongruent &gt; Congruent; socialcommunication</td><td>25929599_analysis_0</td><td>Incongruent &gt; Congruent</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25929599_5</td><td>Out-group (Incongruent &gt; Congruent) masked inclusively with Out-group (Incongruent &gt; Congruent) &gt; In-group (Incongruent &gt; Congruent);socialcommunication</td><td>25929599_analysis_3</td><td>Out-group (Incongruent &gt; Congruent) masked inclusively with Out-group (Incongruent &gt; Congruent) &gt; In-group (Incongruent &gt; Congruent)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25996424</strong> | Pred included: 6 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=1, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25996424/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25996424_analysis_0</td><td>Eye Contact &gt; Averted Gaze</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The contrast Eye Contact &gt; Averted Gaze examines perceiving social gaze relations between two people (observed eye contact), which is a social task and measures social processing of attentional relations and face/gaze cues.</td></tr>
<tr><td>25996424_analysis_1</td><td>Averted Gaze &gt; Eye Contact</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Averted Gaze &gt; Eye Contact examines social perceptual processing of gaze patterns between agents; it is a social task measuring social processing.</td></tr>
<tr><td>25996424_analysis_2</td><td>Congruent Gaze Cues &gt; Incongruent Gaze Cues</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Congruent &gt; Incongruent contrasts examine gaze-following and social attention, a social processing task measuring how social cues guide attention.</td></tr>
<tr><td>25996424_analysis_3</td><td>Incongruent Gaze Cues &gt; Congruent Gaze Cues</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Incongruent &gt; Congruent targets elicit increased attentional shifting in response to others&#x27; gaze — a social processing effect related to gaze following.</td></tr>
<tr><td>25996424_analysis_4</td><td>Eye Contact congruent &gt; Averted Gaze congruent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>EC congruent &gt; AG congruent tests how observed eye contact between others modulates processing of shared gaze to a target — clearly a social processing contrast.</td></tr>
<tr><td>25996424_analysis_5</td><td>Averted Gaze incongruent &gt; Averted Gaze congruent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Averted Gaze incongruent &gt; Averted Gaze congruent contrasts gaze congruency within the no-attentional-relation condition, addressing social attention/gaze-following processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25996424_1</td><td>averted gaze &gt; eye contact; socialcommunication</td><td>25996424_analysis_1</td><td>Averted Gaze &gt; Eye Contact</td><td>1.000</td><td>0.941</td><td>0.959</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>25996424_2</td><td>averted gaze x incongruent &gt; averted  gaze x congruent; socialcommunication</td><td>25996424_analysis_5</td><td>Averted Gaze incongruent &gt; Averted Gaze congruent</td><td>0.961</td><td>1.000</td><td>0.988</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25996424_3</td><td>congruent gaze cues &gt; incongruent gaze cues; socialcommunication</td><td>25996424_analysis_2</td><td>Congruent Gaze Cues &gt; Incongruent Gaze Cues</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25996424_4</td><td>eye contact &gt; averted gaze; socialcommunication</td><td>25996424_analysis_0</td><td>Eye Contact &gt; Averted Gaze</td><td>1.000</td><td>0.500</td><td>0.650</td><td>uncertain</td><td>coord_count_mismatch</td></tr><tr><td>25996424_5</td><td>eye contact x congruent &gt; averted gaze x congruent; socialcommunication</td><td>25996424_analysis_4</td><td>Eye Contact congruent &gt; Averted Gaze congruent</td><td>0.958</td><td>0.800</td><td>0.848</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>25996424_6</td><td>incongruent gaze cues &gt; congruent gaze cues; socialcommunication</td><td>25996424_analysis_3</td><td>Incongruent Gaze Cues &gt; Congruent Gaze Cues</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26235682</strong> | Pred included: 5 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26235682/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26235682_analysis_0</td><td>Positive vs. Neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast &#x27;Positive vs. Neutral&#x27; uses a social-reputation task (faces + evaluative comments) requiring subjects to imagine receiving social feedback and rate pleasantness. This is a social task that directly measures social processing (per Study Methods and behavioral aims).</td></tr>
<tr><td>26235682_analysis_1</td><td>Negative vs. Neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The &#x27;Negative vs. Neutral&#x27; contrast uses the same social-reputation task (faces + negative evaluative comments) and therefore measures social processing.</td></tr>
<tr><td>26235682_analysis_2</td><td>(Positive &gt; Neutral) inclusively masked with (Negative &gt; Neutral)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The conjunction mask [(Positive &gt; Neutral) ∩ (Negative &gt; Neutral)] examines areas commonly responsive to social evaluative feedback; this is clearly social processing.</td></tr>
<tr><td>26235682_analysis_3</td><td>(Positive vs. Neutral) vs. (Negative vs. Neutral)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast &#x27;(Positive vs. Neutral) vs. (Negative vs. Neutral)&#x27; isolates neural responses specific to positive social reputation; this is a social-processing contrast by design.</td></tr>
<tr><td>26235682_analysis_4</td><td>(Negative vs. Neutral) vs. (Positive vs. Neutral)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast &#x27;(Negative vs. Neutral) vs. (Positive vs. Neutral)&#x27; targets negative-specific responses to social evaluative feedback; it is a social-processing contrast.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26235682_1</td><td>(Positive &gt; Neutral) inclusively masked with (Negative &gt; Neutral); others</td><td>26235682_analysis_2</td><td>(Positive &gt; Neutral) inclusively masked with (Negative &gt; Neutral)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26235682_2</td><td>(Positive vs. Neutral) &gt; (Negative vs. Neutral); others</td><td>26235682_analysis_3</td><td>(Positive vs. Neutral) vs. (Negative vs. Neutral)</td><td>0.958</td><td>1.000</td><td>0.988</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26235682_3</td><td>Negative &gt; Neutral; others</td><td>26235682_analysis_1</td><td>Negative vs. Neutral</td><td>0.895</td><td>1.000</td><td>0.968</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26235682_4</td><td>Positive &gt; Neutral; others</td><td>26235682_analysis_0</td><td>Positive vs. Neutral</td><td>0.895</td><td>1.000</td><td>0.968</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26254589</strong> | Pred included: 6 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26254589/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26254589_analysis_0</td><td>EmpaToM: emotionally negative &gt; neutral video</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The EmpaToM contrasts directly probe social cognition (empathy, compassion, Theory of Mind). This meets inclusion criteria: a social-related task and measurement of social processing.</td></tr>
<tr><td>26254589_analysis_1</td><td>EmpaToM: ToM &gt; nonToM question</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The ToM vs non‑ToM question contrast probes social cognition (mentalizing), satisfying the social processing inclusion criteria.</td></tr>
<tr><td>26254589_analysis_2</td><td>EmpaToM: emotionally negative &gt; neutral video</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This Experiment 2 empathy contrast (emotionally negative &gt; neutral videos) measures social-affective processing (empathy/compassion) and thus meets the social processing criteria.</td></tr>
<tr><td>26254589_analysis_3</td><td>EmpaToM: ToM &gt; nonToM questions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This ToM &gt; nonToM questions contrast in Experiment 2 indexes social cognition (mentalizing), satisfying the social processing inclusion criteria.</td></tr>
<tr><td>26254589_analysis_4</td><td>EmpaToM: (emotional &gt; neutral video) &gt; (ToM &gt; nonToM questions)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The differential contrast (emotional&gt;neutral video) &gt; (ToM&gt;nonToM questions) contrasts social‑affective vs social‑cognitive processing—clearly within social processing.</td></tr>
<tr><td>26254589_analysis_5</td><td>EmpaToM: (ToM &gt; nonToM questions) &gt; (emotionally negative &gt; neutral video)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The reverse differential contrast (ToM&gt;Empathy) isolates social cognitive processing (mentalizing) versus social affect, and therefore meets social processing criteria.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26254589_1</td><td>EmpaToM: (ToM N nonToM questions) &gt; (emotionally negative N neutral video); others</td><td>26254589_analysis_5</td><td>EmpaToM: (ToM &gt; nonToM questions) &gt; (emotionally negative &gt; neutral video)</td><td>0.973</td><td>1.000</td><td>0.992</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26254589_2</td><td>EmpaToM: (emotional N neutral video) &gt; (ToM N nonToM questions); others</td><td>26254589_analysis_4</td><td>EmpaToM: (emotional &gt; neutral video) &gt; (ToM &gt; nonToM questions)</td><td>0.968</td><td>1.000</td><td>0.990</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26254589_3</td><td>EmpaToM: ToM &gt; nonToM questions; others</td><td>26254589_analysis_3</td><td>EmpaToM: ToM &gt; nonToM questions</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26254589_4</td><td>EmpaToM: emotionally negative &gt; neutral video; others</td><td>26254589_analysis_2</td><td>EmpaToM: emotionally negative &gt; neutral video</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26262561</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26262561/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26262561_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The study uses a gaze-following task with in-group/out-group political personages and examines neural activity related to social attention, perceived similarity, and ideological attitudes, directly measuring social processing. The main fMRI contrasts (incongruent&gt;congruent) and ROI/regression analyses probe social-cognitive modulation (FEF activity) by social variables (PS, SDO).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26262561_1</td><td>[incongruent &gt; congruent trials]; self</td><td>26262561_analysis_0</td><td>analysis_0</td><td>0.208</td><td>1.000</td><td>0.762</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26301900</strong> | Pred included: 2 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26301900/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26301900_analysis_0</td><td>ToM &gt; R</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The ToM &gt; R contrast uses a well-established Theory of Mind paradigm (animated triangles) that directly probes social processing and attribution of mental states. This meets both I1 (social-related task) and I2 (contrast measures social processing).</td></tr>
<tr><td>26301900_analysis_1</td><td>Bayesian analysis to evaluate the theory that the response in the mPFC is the same as the response in the right superior temporal gyrus during “ToM &gt; R” (volume of interest (VOI): mPFC-coordinates based on literature, right posterior superior temporal gyrus coordinates based on our sample (MNI: 54-48 16), radius 15 mm; mean and standard deviation (SD) represent the average BOLD-signal within a volume of interest).</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The Bayesian VOI analysis evaluates responses in mPFC versus right posterior STG specifically for the ToM &gt; R contrast, which probes social processing (Theory of Mind). Thus it measures social processing (meets I1 and I2).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26301900_1</td><td>ToM &gt; R; others</td><td>26301900_analysis_0</td><td>ToM &gt; R</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26323252</strong> | Pred included: 5 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=1, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26323252/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> ingroup members &gt; outgroup members; others</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26323252_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast is Pain vs Neutral from an empathy-for-pain paradigm; this measures social processes (perceiving others&#x27; pain, empathic responding).</td></tr>
<tr><td>26323252_analysis_1</td><td>Main effect of condition</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Main effect of condition (ingroup vs outgroup) comes from the same empathy task with experimentally-induced groups; this probes social processing of group membership and empathic responses.</td></tr>
<tr><td>26323252_analysis_2</td><td>Main effect of gender</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Main effect of gender in this empathy task indexes social-processing differences between male and female participants while perceiving others&#x27; pain; thus it is social processing-related.</td></tr>
<tr><td>26323252_analysis_3</td><td>Pain×condition</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Pain × Condition interaction tests how empathy-related neural responses differ for ingroup vs outgroup when viewing pain vs neutral — a core social processing question.</td></tr>
<tr><td>26323252_analysis_4</td><td>Pain×gender</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Pain × Gender interaction examines social-processing differences (how empathy for others&#x27; pain varies by observer gender) and therefore qualifies as social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26323252_1</td><td>ingroup members &gt; outgroup members; others</td><td>26323252_analysis_2</td><td>Main effect of gender</td><td>0.218</td><td>0.667</td><td>0.532</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>26323252_2</td><td>pain stimuli &gt; neutral stimuli; others</td><td>26323252_analysis_0</td><td>analysis_0</td><td>0.300</td><td>1.000</td><td>0.790</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>26323252_3</td><td>pain x condition &gt; pain x gender; others</td><td>26323252_analysis_3</td><td>Pain×condition</td><td>0.565</td><td>0.778</td><td>0.714</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26365506</strong> | Pred included: 1 | Manual included (accepted matches only): 2 | Correct overlaps: 1 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26365506/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26365506_analysis_0</td><td>Self-referential &gt; social</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>This contrast isolates self-referential &gt; social activity (self &gt; social). Although the experiment includes social stimuli, the contrast tests greater activation for self-related processing rather than measuring social processing per se. Thus it does not meet the requirement that the contrast measures social processing.</td></tr>
<tr><td>26365506_analysis_1</td><td>Social &gt; self-referential</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast isolates social &gt; self activity (social &gt; self). It directly measures social stimulus processing (pictures with humans) and therefore meets the criteria for Social Processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26365506_1</td><td>Self-referential &gt; social; self</td><td>26365506_analysis_0</td><td>Self-referential &gt; social</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26365506_2</td><td>Social &gt; self-referential; self</td><td>26365506_analysis_1</td><td>Social &gt; self-referential</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26417673</strong> | Pred included: 3 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=2</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26417673/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Disgust &gt; Neutral; socialcommunication, Out-group &gt; In-group; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26417673_analysis_0</td><td>Brain activation of the racial prejudice in disgust perception during the passive viewing task ((disgusted out-group-neutral out-group)-(disgusted in-group-neutral in-group))</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast examines racial bias in perception of disgusted faces ((disgusted out-group–neutral out-group)–(disgusted in-group–neutral in-group)) during a passive face-viewing task. This is a social task probing perception and interpretation of social cues (emotion and group membership), so it measures broad social processing.</td></tr>
<tr><td>26417673_analysis_1</td><td>Positive connectivity</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>This analysis reports positive task-dependent functional connectivity (insula with amygdala/fusiform) during out-group disgust perception. It concerns neural mechanisms engaged when processing social stimuli (faces, racial group cues and emotions), thus indexing social processing broadly.</td></tr>
<tr><td>26417673_analysis_2</td><td>Negative connectivity</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>This analysis reports negative task-dependent connectivity (insula–ACC) during biased disgust perception of out-group faces. It concerns regulation and processing of social-emotional responses to others’ faces, thereby indexing broad social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26417673_1</td><td>Disgust &gt; Neutral; socialcommunication</td><td>26417673_analysis_1</td><td>Positive connectivity</td><td>0.316</td><td>0.023</td><td>0.111</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>26417673_2</td><td>Disgusted out-group-neutral out-group &gt; Disgusted In-group-neutral in-group; socialcommunication</td><td>26417673_analysis_0</td><td>Brain activation of the racial prejudice in disgust perception during the passive viewing task ((disgusted out-group-neutral out-group)-(disgusted in-group-neutral in-group))</td><td>0.578</td><td>1.000</td><td>0.873</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26417673_3</td><td>Out-group &gt; In-group; socialcommunication</td><td>26417673_analysis_2</td><td>Negative connectivity</td><td>0.194</td><td>0.067</td><td>0.105</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26481048</strong> | Pred included: 4 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=2</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26481048/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Activation &gt; Deactivation; self, Deactivation &gt; Activation; self</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26481048_analysis_0</td><td>Compared to implicit baseline</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>This contrast examines activation for agentic and communal trait-word processing versus implicit baseline; the task is explicitly social (processing social trait content) and measures social processing broadly (mentalizing and social-cognitive networks).</td></tr>
<tr><td>26481048_analysis_1</td><td>Compared to fixation task</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>This contrast (agentic and communal blocks vs fixation baseline) evaluates processing of social trait words and associated social-cognitive networks, meeting the broad social processing construct.</td></tr>
<tr><td>26481048_analysis_2</td><td>Agency vs. Communion</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast (Agency &gt; Communion) compares two social-content conditions (agentic vs communal trait words) and probes social-cognitive processing tied to agency, thus falls under broad social processing.</td></tr>
<tr><td>26481048_analysis_3</td><td>Communion vs. Agency</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast (Communion &gt; Agency) directly tests processing differences for communal (affiliation-related) versus agentic trait words; it clearly measures broad social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26481048_1</td><td>Activation &gt; Deactivation; self</td><td>26481048_analysis_1</td><td>Compared to fixation task</td><td>0.400</td><td>0.127</td><td>0.209</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>26481048_2</td><td>Agency vs. Communion; self</td><td>26481048_analysis_2</td><td>Agency vs. Communion</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26481048_3</td><td>Communion vs. Agency; self</td><td>26481048_analysis_3</td><td>Communion vs. Agency</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26481048_4</td><td>Deactivation &gt; Activation; self</td><td>26481048_analysis_0</td><td>Compared to implicit baseline</td><td>0.167</td><td>0.571</td><td>0.450</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26505303</strong> | Pred included: 4 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26505303/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26505303_analysis_0</td><td>Words &gt; Faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast compares speech-containing trials (Words) to Faces-only controls within interactive communicative videos. Task probes comprehension of communicative interactions and recruits social cognition regions (e.g., right TPJ), so it measures social processing.</td></tr>
<tr><td>26505303_analysis_1</td><td>Request &gt; Naming</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Request &gt; Naming directly contrasts two communicative speech-act types in interactive social contexts; the task probes social processing of communicative intentions and action predictions.</td></tr>
<tr><td>26505303_analysis_2</td><td>Request &gt; Naming</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Duplicate Request &gt; Naming analysis similarly probes social processing of communicative actions and intentions in the interactive speech-act paradigm.</td></tr>
<tr><td>26505303_analysis_3</td><td>Naming &gt; Request</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Naming &gt; Request (even if not significant at FDR threshold) is part of the same speech-act manipulation probing social communicative processing (referential aspects of communication).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26505303_1</td><td>Request &gt; Naming; socialcommunication</td><td>26505303_analysis_1</td><td>Request &gt; Naming</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26505303_2</td><td>Words &gt; Faces; socialcommunication</td><td>26505303_analysis_0</td><td>Words &gt; Faces</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26567160</strong> | Pred included: 7 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26567160/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Trust &gt; Distrust; affiliation</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26567160_analysis_0</td><td>Attitude &gt; Age</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast (Attitude &gt; Age) tests control of interpersonal trust/distrust — clearly a social task measuring social processing of interpersonal attitudes.</td></tr>
<tr><td>26567160_analysis_1</td><td>Trust &gt; Age</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Trust &gt; Age directly tests deliberate control of interpersonal trust — a social processing task.</td></tr>
<tr><td>26567160_analysis_2</td><td>Distrust &gt; Age</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Distrust &gt; Age examines control of negative interpersonal attitudes — a social processing contrast.</td></tr>
<tr><td>26567160_analysis_3</td><td>Trust</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Individual-differences analysis links PrC activity with change in trust — directly about social attitude change and social processing.</td></tr>
<tr><td>26567160_analysis_4</td><td>Distrust</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Individual-differences analysis linking IFG activity to change in distrust addresses social attitude control and social processing.</td></tr>
<tr><td>26567160_analysis_5</td><td>Precuneus Connectivity-Positive</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>PrC connectivity analysis examines networks associated with changing trustworthiness evaluations — clearly social processing related.</td></tr>
<tr><td>26567160_analysis_6</td><td>IFG Connectivity-Negative</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>IFG connectivity-negative analysis tests networks associated with changing distrust — a social processing functional connectivity result.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26567160_1</td><td>Attitude &gt; Age; affiliation</td><td>26567160_analysis_0</td><td>Attitude &gt; Age</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26567160_2</td><td>Distrust &gt; Age; affiliation</td><td>26567160_analysis_2</td><td>Distrust &gt; Age</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26567160_3</td><td>Trust &gt; Age; affiliation</td><td>26567160_analysis_1</td><td>Trust &gt; Age</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26567160_4</td><td>Trust &gt; Distrust; affiliation</td><td>26567160_analysis_4</td><td>Distrust</td><td>0.667</td><td>0.000</td><td>0.200</td><td>unmatched</td><td>coord_count_mismatch, low_total_score, name_only_signal</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26803059</strong> | Pred included: 10 | Manual included (accepted matches only): 7 | Correct overlaps: 7 | Match statuses: accepted=7, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26803059/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26803059_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Study uses affective Theory of Mind (ToM) cartoon stories and emotional facial expressions (EFE) to probe social cognition; this analysis belongs to the overall set and is therefore measuring social processing.</td></tr>
<tr><td>26803059_analysis_1</td><td>EFE &gt; no EFE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>EFE &gt; no EFE contrast examines social cue (facial expression) effects during affective ToM—core social processing.</td></tr>
<tr><td>26803059_analysis_2</td><td>No EFE &gt; EFE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>No EFE &gt; EFE contrast examines brain regions more engaged when facial cues are absent during social inference—still social processing.</td></tr>
<tr><td>26803059_analysis_3</td><td>Correlation of differential activation EFE &gt; no EFE with RT reduction by EFE, P &lt; 0.001 (uncorrected); k = 10</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Correlation of differential activation (EFE&gt;no EFE) with RT reduction examines how social cues (faces) affect social-cognitive performance—falls under social processing.</td></tr>
<tr><td>26803059_analysis_4</td><td>Correlation of differential activation no EFE &gt; EFE with RT reduction by EFE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Correlation of no EFE &gt; EFE differential activation with RT reduction still investigates social inference processes (how absence of faces modulates processing).</td></tr>
<tr><td>26803059_analysis_5</td><td>Greater EFE effects with explicit demand of affective ToM judgments (EFE ToM - no EFE ToM) - (EFE no ToM - no EFE no ToM)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Interaction analysis tests how EFE effects depend on explicit affective ToM demand — a social-cognitive interaction, thus social processing.</td></tr>
<tr><td>26803059_analysis_6</td><td>Greater EFE effects with explicit demand of affective ToM judgments (EFE no ToM - no EFE no ToM) - (EFE ToM - no EFE ToM)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Complementary interaction contrast also addresses social inference with/without facial cues — part of social processing domain.</td></tr>
<tr><td>26803059_analysis_7</td><td>PPI</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>PPI tests connectivity between right basolateral amygdala and ToM network modulated by EFE—investigates network-level social processing.</td></tr>
<tr><td>26803059_analysis_8</td><td>Pos. correlation: affective ToM matching with consensus judgments and PPI effects</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Positive correlation between affective ToM matching and PPI effects links neural connectivity and accuracy in social inference—core social processing.</td></tr>
<tr><td>26803059_analysis_9</td><td>Neg. correlation: affective ToM matching with consensus judgments and PPI effects</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Negative correlation between matching and PPI effects still probes social inference performance and neural connectivity—part of social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26803059_1</td><td>(EFE ToM − no EFE ToM) − (EFE no ToM − no EFE no ToM); others</td><td>26803059_analysis_5</td><td>Greater EFE effects with explicit demand of affective ToM judgments (EFE ToM - no EFE ToM) - (EFE no ToM - no EFE no ToM)</td><td>0.575</td><td>0.900</td><td>0.802</td><td>accepted</td><td>high_coord_match</td></tr><tr><td>26803059_2</td><td>(EFE no ToM − no EFE no ToM) − (EFE ToM − no EFE ToM); others</td><td>26803059_analysis_6</td><td>Greater EFE effects with explicit demand of affective ToM judgments (EFE no ToM - no EFE no ToM) - (EFE ToM - no EFE ToM)</td><td>0.575</td><td>1.000</td><td>0.872</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26803059_3</td><td>3rdppA &gt; 1stppV; others</td><td>26803059_analysis_0</td><td>analysis_0</td><td>0.182</td><td>1.000</td><td>0.755</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>26803059_4</td><td>EFE &gt; no EFE; others</td><td>26803059_analysis_1</td><td>EFE &gt; no EFE</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26803059_5</td><td>EFE &gt; no EFE with RT reduction; others</td><td>26803059_analysis_3</td><td>Correlation of differential activation EFE &gt; no EFE with RT reduction by EFE, P &lt; 0.001 (uncorrected); k = 10</td><td>0.489</td><td>1.000</td><td>0.847</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>26803059_6</td><td>No EFE &gt; EFE; others</td><td>26803059_analysis_2</td><td>No EFE &gt; EFE</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26803059_7</td><td>no EFE &gt; EFE with RT reduction; others</td><td>26803059_analysis_4</td><td>Correlation of differential activation no EFE &gt; EFE with RT reduction by EFE</td><td>0.566</td><td>1.000</td><td>0.870</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26812250</strong> | Pred included: 11 | Manual included (accepted matches only): 11 | Correct overlaps: 11 | Match statuses: accepted=11, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26812250/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26812250_analysis_0</td><td>Negative vs. positive performance feedback.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The negative vs. positive feedback contrast is embedded in a social context (verbal performance feedback and financial loss) and probes affective responses to social feedback; therefore it assesses social-related processing at the level of social evaluation and emotion.</td></tr>
<tr><td>26812250_analysis_1</td><td>(A) Emotional empathic (EE) &gt; emotional unempathic (EN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>EE&gt;EN compares emotionally empathic vs unempathic verbal comments, directly probing social processing (empathy, social support) and its neural correlates.</td></tr>
<tr><td>26812250_analysis_2</td><td>(B) Unempathic (EN + CN) &gt; empathic (EE + CE)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>EN+CN &gt; EE+CE contrasts unempathic vs empathic comments overall, a direct social-processing contrast assessing reactions to different social responses.</td></tr>
<tr><td>26812250_analysis_3</td><td>(C) Cognitive unempathic (CN) &gt; cognitive empathic (CE)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>CN&gt;CE (cognitive unempathic &gt; cognitive empathic) contrasts different social responses (verbal indications of understanding vs lack thereof) and probes social processing.</td></tr>
<tr><td>26812250_analysis_4</td><td>(D) Empathic (EE + CE) &gt; high level baseline</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>EE+CE &gt; baseline contrasts empathic interventions during distress against a non-distress baseline and therefore probes social support processing and related social cognition.</td></tr>
<tr><td>26812250_analysis_5</td><td>(E) Emotional empathic (EE) &gt; high level baseline</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>EE &gt; baseline examines neural responses to emotionally empathic comments compared to a non-distress baseline, directly probing social/empathic processing.</td></tr>
<tr><td>26812250_analysis_6</td><td>(F) Cognitive empathic (CE) &gt; high level baseline</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>CE &gt; baseline contrasts cognitively empathic comments (paraphrasing/understanding) vs baseline; this probes social cognitive processes related to being understood and social support.</td></tr>
<tr><td>26812250_analysis_7</td><td>(A) Emotional (EE + EN) &gt; cognitive (CE + CN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>(EE+EN) &gt; (CE+CN) contrasts emotional versus cognitive interventions and probes differential social processing of two types of empathic communication.</td></tr>
<tr><td>26812250_analysis_8</td><td>(B) Emotional empathic (EE) &gt; cognitive empathic (CE)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>EE &gt; CE (emotionally empathic &gt; cognitively empathic) directly contrasts two social responses and probes social/empathic processing differences.</td></tr>
<tr><td>26812250_analysis_9</td><td>(C) Emotional unempathic (EN) &gt; cognitive unempathic (CN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>EN &gt; CN (emotional unempathic &gt; cognitive unempathic) contrasts different forms of unempathic social responses and probes social processing of negative interpersonal signals.</td></tr>
<tr><td>26812250_analysis_10</td><td>(D) Cognitive unempathic (CN) &gt; emotional unempathic (EN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>CN &gt; EN (cognitive unempathic &gt; emotional unempathic) contrasts different forms of unempathic social responses and probes social processing of these verbal signals.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26812250_1</td><td>Cognitive empathic (CE) &gt; high level baseline; others</td><td>26812250_analysis_6</td><td>(F) Cognitive empathic (CE) &gt; high level baseline</td><td>0.957</td><td>1.000</td><td>0.987</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26812250_10</td><td>Unempathic (EN + CN) &gt; empathic (EE + CE); others</td><td>26812250_analysis_2</td><td>(B) Unempathic (EN + CN) &gt; empathic (EE + CE)</td><td>0.953</td><td>1.000</td><td>0.986</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26812250_11</td><td>negative vs positive performance; others</td><td>26812250_analysis_0</td><td>Negative vs. positive performance feedback.</td><td>0.853</td><td>1.000</td><td>0.956</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26812250_2</td><td>Cognitive unempathic (CN) &gt; cognitive empathic (CE); others</td><td>26812250_analysis_3</td><td>(C) Cognitive unempathic (CN) &gt; cognitive empathic (CE)</td><td>0.962</td><td>1.000</td><td>0.989</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26812250_3</td><td>Cognitive unempathic (CN) &gt; emotional unempathic (EN); others</td><td>26812250_analysis_10</td><td>(D) Cognitive unempathic (CN) &gt; emotional unempathic (EN)</td><td>0.964</td><td>1.000</td><td>0.989</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26812250_4</td><td>Emotional (EE + EN) &gt; cognitive (CE + CN); others</td><td>26812250_analysis_7</td><td>(A) Emotional (EE + EN) &gt; cognitive (CE + CN)</td><td>0.953</td><td>1.000</td><td>0.986</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26812250_5</td><td>Emotional Empathic (EE) &gt; emotional unempathic (EN); others</td><td>26812250_analysis_1</td><td>(A) Emotional empathic (EE) &gt; emotional unempathic (EN)</td><td>0.962</td><td>1.000</td><td>0.989</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26812250_6</td><td>Emotional empathic (EE) &gt; cognitive empathic (CE); others</td><td>26812250_analysis_8</td><td>(B) Emotional empathic (EE) &gt; cognitive empathic (CE)</td><td>0.961</td><td>1.000</td><td>0.988</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26812250_7</td><td>Emotional empathic (EE) &gt; high level baseline; others</td><td>26812250_analysis_5</td><td>(E) Emotional empathic (EE) &gt; high level baseline</td><td>0.957</td><td>1.000</td><td>0.987</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26812250_8</td><td>Emotional unempathic (EN) &gt; cognitive unempathic (CN); others</td><td>26812250_analysis_9</td><td>(C) Emotional unempathic (EN) &gt; cognitive unempathic (CN)</td><td>0.964</td><td>1.000</td><td>0.989</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26812250_9</td><td>Empathic (EE + CE) &gt; high level baseline; others</td><td>26812250_analysis_4</td><td>(D) Empathic (EE + CE) &gt; high level baseline</td><td>0.952</td><td>1.000</td><td>0.986</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26892859</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26892859/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26892859_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task directly involves social evaluation (positive, neutral, negative videos) requiring perception and interpretation of social cues; the contrasts (positive&gt;neutral, negative&gt;neutral, conjunction) measure social processing across valences.</td></tr>
<tr><td>26892859_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Same experimental paradigm and contrasts as analysis_0 (positive/negative vs. neutral); all probe social processing of evaluative videos.</td></tr>
<tr><td>26892859_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This conjunction analysis (positive&gt;neutral &amp; negative&gt;neutral) identifies common social processing networks engaged by evaluative social stimuli, meeting social_processing_all criteria.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26892859_1</td><td>Negative &gt; neutral; affiliation</td><td>26892859_analysis_0</td><td>analysis_0</td><td>0.214</td><td>1.000</td><td>0.764</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>26892859_2</td><td>positive &gt; neutral; affiliation</td><td>26892859_analysis_1</td><td>analysis_1</td><td>0.143</td><td>1.000</td><td>0.743</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>26892859_3</td><td>positive &gt; neutral and negative &gt; neutral (conjunction analysis); affiliation</td><td>26892859_analysis_2</td><td>analysis_2</td><td>0.216</td><td>1.000</td><td>0.765</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26908320</strong> | Pred included: 5 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26908320/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Black &gt; White faces: A. Increased activation with more racial trust disparities; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26908320_analysis_0</td><td>A. Increased activation with more racial trust disparity</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves perceiving and evaluating faces and links neural responses to later social behavior (trustworthiness), meeting broad social processing criteria.</td></tr>
<tr><td>26908320_analysis_1</td><td>B. Increased connectivity with orbitofrontal cortex (18, 66, 0) with less racial trust disparity</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>PPI connectivity predicting racial trust disparity concerns social perception and subsequent social behavior, fitting broad social processing.</td></tr>
<tr><td>26908320_analysis_2</td><td>A. Increased activation with more differentiation disparity</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Analysis links neural responses during face perception to later racial differentiation disparity, a social perception process, meeting the broad social processing definition.</td></tr>
<tr><td>26908320_analysis_3</td><td>Increased activation with less differentiation disparity</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Analysis of neural activation predicting less differentiation disparity concerns social perception processes and later social-cognitive behavior—fits social processing.</td></tr>
<tr><td>26908320_analysis_4</td><td>B. Increased connectivity with dorsolateral prefrontal seed (24, 42, 21) with less differentiation disparity</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>PPI between dlPFC and cingulate predicting differentiation disparity reflects social perceptual and cognitive processes, fitting broad social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26908320_1</td><td>Black &gt; White faces: A. Increased activation with less differentiation disparity; socialcommunication</td><td>26908320_analysis_3</td><td>Increased activation with less differentiation disparity</td><td>0.824</td><td>1.000</td><td>0.947</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26908320_2</td><td>Black &gt; White faces: A. Increased activation with less racial trust disparities; socialcommunication</td><td>26908320_analysis_0</td><td>A. Increased activation with more racial trust disparity</td><td>0.770</td><td>0.750</td><td>0.756</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>26908320_3</td><td>Black &gt; White faces: A. Increased activation with more differentiation disparity; socialcommunication</td><td>26908320_analysis_2</td><td>A. Increased activation with more differentiation disparity</td><td>0.849</td><td>1.000</td><td>0.955</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26908320_4</td><td>Black &gt; White faces: A. Increased activation with more racial trust disparities; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>26908320_5</td><td>Black &gt; White faces: B. Increassed connectivity with dorsolateral prefrontal seed (24, 42, 21) with less differentiation disparity; socialcommunication</td><td>26908320_analysis_4</td><td>B. Increased connectivity with dorsolateral prefrontal seed (24, 42, 21) with less differentiation disparity</td><td>0.908</td><td>1.000</td><td>0.972</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26908320_6</td><td>Black &gt; White faces: B. Increased connectivity with orbitofrontal cortex (18, 66, 0) with less racial trust disparity; socialcommunication</td><td>26908320_analysis_1</td><td>B. Increased connectivity with orbitofrontal cortex (18, 66, 0) with less racial trust disparity</td><td>0.901</td><td>1.000</td><td>0.970</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 27039141</strong> | Pred included: 3 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=1, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/27039141/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Physical &gt; Meaning; others</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>27039141_analysis_0</td><td>A Meaning &gt; Physical</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Contrast &#x27;Meaning &gt; Physical&#x27; explicitly manipulates interpretive attitude to elicit social-cognitive processing (activations in mPFC and TPJ), so this analysis measures social processing related constructs (mentalizing/social cognition).</td></tr>
<tr><td>27039141_analysis_1</td><td>B Physical &gt; Meaning</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>The &#x27;Physical &gt; Meaning&#x27; contrast emphasizes perceptual and motor/object-processing regions (fusiform, precentral) and does not probe social or mentalizing processes; it does not meet the social-processing inclusion. </td></tr>
<tr><td>27039141_analysis_2</td><td>C Own &gt; Other (meaning related task)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast &#x27;Own &gt; Other&#x27; (within meaning task) elicits dmPFC, ACC, TPJ and precuneus—regions linked to social cognition, autobiographical memory and agency. This directly involves social processing (self-related social cognition).</td></tr>
<tr><td>27039141_analysis_3</td><td>D Own &gt; Other × Collective &gt; Individual (meaning related task)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The interaction (own&gt;other × collective&gt;individual) isolates neural responses related to socially embedded, collective self-relevant artifacts and implicates ACC, IFG, insula—regions linked to social salience and emotion—so it measures social processing. </td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>27039141_1</td><td>Meaning &gt; Physical; others</td><td>27039141_analysis_0</td><td>A Meaning &gt; Physical</td><td>0.947</td><td>0.500</td><td>0.634</td><td>uncertain</td><td>coord_count_mismatch</td></tr><tr><td>27039141_2</td><td>Own &gt; Other (meaning related task); others</td><td>27039141_analysis_2</td><td>C Own &gt; Other (meaning related task)</td><td>0.971</td><td>0.750</td><td>0.816</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>27039141_3</td><td>Own &gt; Other × Collective &gt; Individual (meaning related task); others</td><td>27039141_analysis_3</td><td>D Own &gt; Other × Collective &gt; Individual (meaning related task)</td><td>0.984</td><td>0.667</td><td>0.762</td><td>accepted</td><td>coord_count_mismatch</td></tr><tr><td>27039141_4</td><td>Physical &gt; Meaning; others</td><td>27039141_analysis_1</td><td>B Physical &gt; Meaning</td><td>0.947</td><td>0.333</td><td>0.518</td><td>unmatched</td><td>coord_count_mismatch, low_coord_high_name, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 27090501</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/27090501/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>27090501_analysis_0</td><td>Significant activation for the (toss - button press) high-frequency effect.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast isolates increased frequency of social interaction in a Cyberball ball-toss task (ball-toss high-frequency &gt; normal-frequency, contrasted with button-press), directly measuring social processing—enjoyment and neural responses to social inclusion/exchange (ventral striatum, precuneus). This meets I1 (social-related task) and measures Social Processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>27090501_1</td><td>Significant activation for the (toss – button press) high-frequency effect; others</td><td>27090501_analysis_0</td><td>Significant activation for the (toss - button press) high-frequency effect.</td><td>0.980</td><td>1.000</td><td>0.994</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 27095057</strong> | Pred included: 3 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/27095057/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Social-Look &gt; Social-Reg; self</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>27095057_analysis_0</td><td>Social-Reg &gt; Social-Look</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast Social-Reg &gt; Social-Look isolates effects of socially-induced cognitive emotion regulation delivered by a psychotherapist (video instruction). This is a clearly social task engaging social cognition and DMN nodes; the analysis directly measures social processing during regulation.</td></tr>
<tr><td>27095057_analysis_1</td><td>(Reg &gt; Look)_Social ∩ (Reg &gt; Look)_Self</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This conjunction identifies regions commonly engaged by Social-Reg and Self-Reg, capturing shared social/cognitive processes involved in regulation. Because one of the tasks is Social-Reg and the conjunction includes its social components, this analysis measures social processing.</td></tr>
<tr><td>27095057_analysis_2</td><td>Distinct areas recruited by Social-Reg</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>This analysis identifies areas specifically more engaged during Social-Reg than Self-Reg (dmPFC, precuneus, TPJ), i.e., social-cognitive and DMN regions. It therefore directly measures social processing unique to socially-induced regulation.</td></tr>
<tr><td>27095057_analysis_3</td><td>Distinct areas recruited by Self-Reg</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This analysis identifies regions preferentially engaged by Self-Reg (e.g., left IFG, inferior parietal cortex) in a self-initiated reappraisal task presented with written cues. The task is intrapersonal and not social in nature, so it does not meet the social-processing inclusion criteria.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>27095057_1</td><td>Social-Look &gt; Social-Reg; self</td><td>27095057_analysis_2</td><td>Distinct areas recruited by Social-Reg</td><td>0.484</td><td>0.000</td><td>0.145</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>27095057_2</td><td>Social-Reg &gt; Social-Look; self</td><td>27095057_analysis_0</td><td>Social-Reg &gt; Social-Look</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 27096431</strong> | Pred included: 14 | Manual included (accepted matches only): 8 | Correct overlaps: 8 | Match statuses: accepted=8, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/27096431/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>27096431_analysis_0</td><td>Aggressive reaction to provoking opponent &gt; non aggressive reaction to non-provoking opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast compares aggressive vs non-aggressive reactions within a social interaction paradigm (Taylor Aggression Paradigm) involving opponents; therefore it probes social processing (perception, interpretation and response to social provocation).</td></tr>
<tr><td>27096431_analysis_1</td><td>Non aggressive reaction to non-provoking opponent &gt; aggressive reaction to provoking opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Reverse contrast of analysis_0; still a social interaction contrast within the TAP, probing responses to others and social behavior.</td></tr>
<tr><td>27096431_analysis_2</td><td>Won &gt; lost</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Won &gt; lost is an outcome contrast within the TAP, a social interaction paradigm, and thus relates to social processing (responses to social outcomes).</td></tr>
<tr><td>27096431_analysis_3</td><td>Lost &gt; won</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Lost &gt; won is an outcome contrast within the TAP social interaction and thus involves social processing of negative outcomes and anticipated social feedback.</td></tr>
<tr><td>27096431_analysis_4</td><td>Won against the provoking opponent &gt; won against the non-provoking opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Contrast compares winning against provoking vs non‑provoking opponent — an explicitly social/opponent‑specific contrast in the TAP, engaging social processing.</td></tr>
<tr><td>27096431_analysis_5</td><td>Won against the non-provoking opponent &gt; won against the provoking opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Opponent-specific winning contrast (non-provoking &gt; provoking) within the TAP — involves social processing of interactions and outcomes.</td></tr>
<tr><td>27096431_analysis_6</td><td>Lost against the provoking opponent &gt; lost against the non-provoking opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Lost against provoking &gt; lost against non-provoking is an opponent-specific outcome contrast within a social interaction, engaging social processing.</td></tr>
<tr><td>27096431_analysis_7</td><td>Lost against the non-provoking opponent &gt; lost against the provoking opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Opponent-specific loss contrast (non‑provoking &gt; provoking) in the TAP; relates to social processing of outcomes and opponent behavior.</td></tr>
<tr><td>27096431_analysis_8</td><td>Retaliation independent of opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Retaliation independent of opponent probes decision-making about others within the TAP social interaction and thus indexes social processing.</td></tr>
<tr><td>27096431_analysis_9</td><td>Retaliation interacting with provoking opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Retaliation interacting with provoking opponent is an explicitly social/opponent‑specific decision contrast, directly probing social processing of provocation and response.</td></tr>
<tr><td>27096431_analysis_10</td><td>Retaliation interacting with non-provoking opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Retaliation interacting with non‑provoking opponent is a social decision contrast within the TAP and relates to social processing of interactions with a benign other.</td></tr>
<tr><td>27096431_analysis_11</td><td>Won</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>General &#x27;Won&#x27; outcome in the TAP is embedded in a social interaction and therefore engages social processing of outcomes and reward in an interpersonal context.</td></tr>
<tr><td>27096431_analysis_12</td><td>Won against provoking opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Won against provoking opponent is an opponent-specific outcome contrast in the TAP and clearly involves social processing (responses to an opponent).</td></tr>
<tr><td>27096431_analysis_13</td><td>Won against non-provoking opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Won against non‑provoking opponent is an opponent-specific TAP outcome and thus engages social processing in an interpersonal context.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>27096431_1</td><td>Aggressive reaction to provoking opponent &gt; non aggressive reaction to non-provoking opponent; others</td><td>27096431_analysis_0</td><td>Aggressive reaction to provoking opponent &gt; non aggressive reaction to non-provoking opponent</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27096431_2</td><td>Lost &gt; Won; others</td><td>27096431_analysis_3</td><td>Lost &gt; won</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27096431_3</td><td>Lost against the non-provoking opponent &gt; lost against the provoking opponent; others</td><td>27096431_analysis_7</td><td>Lost against the non-provoking opponent &gt; lost against the provoking opponent</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27096431_4</td><td>Non aggressive reaction to non-provoking opponent &gt; aggressive reaction to provoking opponent; others</td><td>27096431_analysis_1</td><td>Non aggressive reaction to non-provoking opponent &gt; aggressive reaction to provoking opponent</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27096431_5</td><td>Retaliation independent of opponent; others</td><td>27096431_analysis_8</td><td>Retaliation independent of opponent</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27096431_6</td><td>Retaliation interacting with non-provoking opponent; others</td><td>27096431_analysis_10</td><td>Retaliation interacting with non-provoking opponent</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27096431_7</td><td>Retaliation interacting with provoking opponent; others</td><td>27096431_analysis_9</td><td>Retaliation interacting with provoking opponent</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27096431_8</td><td>Won &gt; Lost; others</td><td>27096431_analysis_2</td><td>Won &gt; lost</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 27236373</strong> | Pred included: 9 | Manual included (accepted matches only): 6 | Correct overlaps: 6 | Match statuses: accepted=6, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/27236373/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>27236373_analysis_0</td><td>Time-point 2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast compares Social scenarios requiring contextual adjustment vs Physical scenarios without adjustment (SocAdj &gt; PhyConf). This directly targets social cognitive processing (Theory of Mind) and reproduces classical ToM localizer effects.</td></tr>
<tr><td>27236373_analysis_1</td><td>Response period</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Response-period contrast SocAdj &gt; PhyConf engages full ToM network during explicit social inference and context integration at response, indexing social processing.</td></tr>
<tr><td>27236373_analysis_2</td><td>Time-point 1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Time-point 1 contrast (Soc &gt; Phy) compares reading social vs physical scenario sentences that evoke intention inferences, engaging social processing.</td></tr>
<tr><td>27236373_analysis_3</td><td>Time-point 2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Time-point 2 Soc &gt; Phy compares social vs physical scenarios after context presentation and taps social cognitive processing (mental-state representation).</td></tr>
<tr><td>27236373_analysis_4</td><td>Response period</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Response-period Soc &gt; Phy reflects explicit social inference processing during decision making and engages ToM network, indexing social processing.</td></tr>
<tr><td>27236373_analysis_5</td><td>Time-point 2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Time-point 2 Adj &gt; Conf contrasts trials requiring contextual adjustment vs confirmation across social and physical scenarios. Although mixed, the contrast includes social trials and probes processes (context integration) relevant to social cognition in the REMICS task.</td></tr>
<tr><td>27236373_analysis_6</td><td>Response period</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Response-period Adj &gt; Conf isolates contextual adjustment-related processing at decision time across social and physical trials; because social trials are included and ToM processes are central to the study, this contrast is relevant to social processing.</td></tr>
<tr><td>27236373_analysis_7</td><td>SocAdj</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Condition SocAdj is explicitly social (mental-state inferences requiring contextual adjustment) and directly measures social cognition/processing.</td></tr>
<tr><td>27236373_analysis_8</td><td>SocConf</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>SocConf is a social condition (social scenarios with contextual confirmation) and involves representing others&#x27; mental states, thus indexing social processing.</td></tr>
<tr><td>27236373_analysis_9</td><td>PhyAdj</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>PhyAdj is a physical scenario condition (contextual adjustments for non-social events) and does not primarily probe social processing or mental-state attribution.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>27236373_1</td><td>Adj &gt; Conf, Response Period; others</td><td>27236373_analysis_6</td><td>Response period</td><td>0.714</td><td>1.000</td><td>0.914</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27236373_2</td><td>Soc &gt; Phy, Response Period; others</td><td>27236373_analysis_4</td><td>Response period</td><td>0.732</td><td>1.000</td><td>0.920</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27236373_3</td><td>Soc &gt; Phy, Time-Point 1; others</td><td>27236373_analysis_2</td><td>Time-point 1</td><td>0.686</td><td>1.000</td><td>0.906</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27236373_4</td><td>Soc &gt; Phy, Time-Point 2; others</td><td>27236373_analysis_3</td><td>Time-point 2</td><td>0.686</td><td>1.000</td><td>0.906</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27236373_5</td><td>SocAdj &gt; PhyConf, Response Period; others</td><td>27236373_analysis_1</td><td>Response period</td><td>0.625</td><td>1.000</td><td>0.887</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27236373_6</td><td>SocAdj &gt; PhyConf, Time-Point 2; others</td><td>27236373_analysis_0</td><td>Time-point 2</td><td>0.571</td><td>1.000</td><td>0.871</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 27375449</strong> | Pred included: 7 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/27375449/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>27375449_analysis_0</td><td>Angry &gt; Joyful session</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast compares angry vs joyful sessions while watching actors — a social-emotional task assessing processing of others; therefore it measures social processing broadly.</td></tr>
<tr><td>27375449_analysis_1</td><td>Grasping &gt; Faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Grasping vs faces involves social stimuli (actions and faces) and addresses social perception and processing of others&#x27; behavior.</td></tr>
<tr><td>27375449_analysis_2</td><td>Faces &gt; Grasping</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Faces &gt; Grasping isolates face perception and emotion processing, a core social processing task.</td></tr>
<tr><td>27375449_analysis_3</td><td>Interaction analysis between grasping and neutral grasping</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Interaction between grasping and neutral grasping across emotion runs probes how social context modulates perception of others&#x27; actions — a social processing analysis.</td></tr>
<tr><td>27375449_analysis_4</td><td>Angry &gt; Joyful run</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>ROI/PPI analysis contrasts Angry &gt; Joyful runs, examining network changes during social-emotional perception of others; this is a social processing analysis.</td></tr>
<tr><td>27375449_analysis_5</td><td>Angry grasping &gt; Joyful grasping</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Angry grasping vs joyful grasping isolates social-emotional modulation of observing others&#x27; actions, a social processing effect.</td></tr>
<tr><td>27375449_analysis_6</td><td>PPI: seed in the right Insula</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>PPI seed in right insula examines connectivity changes during social-emotional conditions (anger vs joy), reflecting social processing of others.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>27375449_1</td><td>Angry &gt; Joyful session; socialcommunication</td><td>27375449_analysis_0</td><td>Angry &gt; Joyful session</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27375449_2</td><td>Faces &gt; Grasping; socialcommunication</td><td>27375449_analysis_2</td><td>Faces &gt; Grasping</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27375449_3</td><td>Grasping &gt; Faces; socialcommunication</td><td>27375449_analysis_1</td><td>Grasping &gt; Faces</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27375449_4</td><td>Interaction analysis between grasping and neutral grasping; socialcommunication</td><td>27375449_analysis_3</td><td>Interaction analysis between grasping and neutral grasping</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 27477020</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/27477020/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>27477020_analysis_0</td><td>S-performance</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The S-performance contrast comes from an experiment explicitly about social interactions (cooperation vs competition) and how self and other estimates interact. It measures social processing at the level of self/other representations and their relational dynamics.</td></tr>
<tr><td>27477020_analysis_1</td><td>O-performance</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The O-performance contrast measures tracking of another person’s performance within cooperative and competitive social contexts and thus clearly engages social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>27477020_1</td><td>O-performance &gt; S - performance; others</td><td>27477020_analysis_1</td><td>O-performance</td><td>0.591</td><td>1.000</td><td>0.877</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27477020_2</td><td>S-performance &gt; O - performance; others</td><td>27477020_analysis_0</td><td>S-performance</td><td>0.591</td><td>1.000</td><td>0.877</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 27494142</strong> | Pred included: 6 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/27494142/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>27494142_analysis_0</td><td>CC-A</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast CC &gt; average(other outcomes) derives from a one-shot Prisoner’s Dilemma social interaction (mutual cooperation vs other social outcomes). This directly measures social processing (perception, interpretation and response in social interaction).</td></tr>
<tr><td>27494142_analysis_1</td><td>A-CC</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The A &gt; CC contrast is from the same PD social task and indexes neural responses to non-CC social outcomes; it therefore measures social processing.</td></tr>
<tr><td>27494142_analysis_2</td><td>Gain-Loss</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Gain &gt; Loss is computed across trials of the PD social task; it captures how social processing differs under gain vs loss context and therefore measures social processing.</td></tr>
<tr><td>27494142_analysis_3</td><td>Loss-Gain</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Loss &gt; Gain is derived from the Prisoner’s Dilemma social paradigm and indexes social processing differences under loss vs gain contexts, so it meets the social processing criterion.</td></tr>
<tr><td>27494142_analysis_4</td><td>(CC-A) Gain - (CC-A) Loss</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The interaction (cooperation-specific effect in Gain vs Loss) isolates how social cooperation representations differ by context; it directly probes social processing tied to cooperative outcomes.</td></tr>
<tr><td>27494142_analysis_5</td><td>(CC-A) Loss - (CC-A) Gain</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The reverse interaction ((CC–A)loss–(CC–A)gain) is still a social-task-derived contrast examining context-modulation of cooperation processing, thus indexing social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>27494142_1</td><td>(CC-A)Gain &gt; (CC-A)Loss; others</td><td>27494142_analysis_4</td><td>(CC-A) Gain - (CC-A) Loss</td><td>0.917</td><td>1.000</td><td>0.975</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27494142_2</td><td>A &gt; CC; others</td><td>27494142_analysis_1</td><td>A-CC</td><td>0.600</td><td>1.000</td><td>0.880</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27494142_3</td><td>CC &gt; A; others</td><td>27494142_analysis_0</td><td>CC-A</td><td>0.600</td><td>1.000</td><td>0.880</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27494142_4</td><td>Gain &gt; Loss; others</td><td>27494142_analysis_2</td><td>Gain-Loss</td><td>0.800</td><td>1.000</td><td>0.940</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 27568587</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/27568587/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> PAINFUL &gt; NON-PAINFUL and SELF PAINFUL &gt; NON-PAINFUL; others</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>27568587_analysis_0</td><td>Mentalizing with Dissimilar &gt; Similar person</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast examines mentalizing (Theory of Mind) with similar vs dissimilar others — a canonical social processing task involving perception, interpretation and reasoning about social information and relationships. This directly meets the Social Processing definition.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>27568587_1</td><td>DISSIMILAR &gt; SIMILAR; others</td><td>27568587_analysis_0</td><td>Mentalizing with Dissimilar &gt; Similar person</td><td>0.667</td><td>1.000</td><td>0.900</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27568587_2</td><td>PAINFUL &gt; NON-PAINFUL and SELF PAINFUL &gt; NON-PAINFUL; others</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 27622781</strong> | Pred included: 6 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/27622781/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>27622781_analysis_0</td><td>Working memory maintenance</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The working memory maintenance analysis includes both competition and no-competition conditions and reports activity in mentalizing/default-mode regions (mPFC, PCC/precuneus) related to social comparison and distraction. The task manipulates a social context (competition), so it measures social processing.</td></tr>
<tr><td>27622781_analysis_1</td><td>Effect of performance parametric modulator on no competition</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The performance parametric modulator in the no-competition condition still sits within the overall social task context (comparison across social vs nonsocial conditions) and measures neural responses related to task performance/attention; social processing is a primary focus of the study and contrasts include social context.</td></tr>
<tr><td>27622781_analysis_2</td><td>Effect of performance parametric modulator on competition</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The performance parametric modulator for the competition condition directly probes neural responses when participants believe they are competing, engaging social processing (mentalizing, social comparison) as reported in the paper.</td></tr>
<tr><td>27622781_analysis_3</td><td>Event‐Related Analysis at Feedback</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The event-related feedback analysis contrasts feedback processing with and without competition, directly tapping social processing (responses to social feedback, mentalizing) as discussed in the paper.</td></tr>
<tr><td>27622781_analysis_4</td><td>Competition&gt;No competition</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Competition &gt; No competition contrast at feedback isolates social processing elicited by competitive feedback (greater mPFC, PCC/precuneus, STS activity), directly measuring social processes.</td></tr>
<tr><td>27622781_analysis_5</td><td>No Competition&gt;Competition</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The No Competition &gt; Competition contrast examines feedback-related activity favoring the noncompetitive context; because the study centers on social effects of competition, this contrast still informs social processing differences between contexts.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>27622781_1</td><td>Competition &gt; No Competition; self</td><td>27622781_analysis_4</td><td>Competition&gt;No competition</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27622781_2</td><td>No Competition &gt; Competition; self</td><td>27622781_analysis_5</td><td>No Competition&gt;Competition</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 28477977</strong> | Pred included: 8 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/28477977/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>28477977_analysis_0</td><td>SELF minus OTHER [(SELF_No + SELF_Single + SELF_ Group) - (OTHER_No + OTHER_Single + OTHER_Group)] (Fig. 3)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The SELF vs OTHER contrast was derived from a social interactive task (telling jokes and hearing listener responses). It directly probes social processing (self-relevant vs other-relevant outcomes) and is part of the study’s social interaction framework.</td></tr>
<tr><td>28477977_analysis_1</td><td>Group minus No Laughter [(SELF_ Group - SELF_No) + (OTHER_ Group - OTHER_No)] (Supplemental Fig. S1)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Group vs No Laughter contrast indexes responses to social auditory feedback (laughter) during an interactive social task, and thus measures social processing.</td></tr>
<tr><td>28477977_analysis_2</td><td>Single minus No Laughter [(SELF_ Single - SELF_No) + (OTHER_Single - OTHER_No)]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Single vs No Laughter contrasts neural responses to an interpersonal social signal (single-person laughter) within the interactive task; this indexes social processing.</td></tr>
<tr><td>28477977_analysis_3</td><td>Group minus Single Laughter [(SELF_ Group - SELF_Single) + (OTHER_ Group - OTHER_Single)]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Group vs Single Laughter contrasts two types of social auditory feedback within the interactive social task, indexing social processing of differing social feedback magnitudes.</td></tr>
<tr><td>28477977_analysis_4</td><td>[(SELF_ Group - SELF_No) - (OTHER_Group - OTHER_No)] (Fig. 4)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The action-outcome contingency interaction explicitly addresses social interactive processing (how self-actions vs others’ actions influence reward-related responses), central to social processing.</td></tr>
<tr><td>28477977_analysis_5</td><td>[(SELF_ Single - SELF_No) - (OTHER_Single - OTHER_No)]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The Single-laughter action-outcome contingency interaction is a social-interaction contrast probing whether self-contingent single laughter modulates reward processing; it therefore indexes social processing.</td></tr>
<tr><td>28477977_analysis_6</td><td>Physio-physiological interaction (PPI) seeded on the right auditory cortex and mPFC.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The PPI between mPFC and right auditory cortex tests interactions among brain regions supporting self-relevance, auditory social feedback, and reward processing — a distributed social processing network.</td></tr>
<tr><td>28477977_analysis_7</td><td>Physio-physiological interaction (PPI) analysis in the left auditory cortex and mPFC.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The PPI between mPFC and left auditory cortex examines the network-level integration of self-relevance and auditory social feedback with reward processing, squarely within social processing constructs.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>28477977_1</td><td>SELFGroup−SELFNo &gt; OTHER Group–OTHERNo; socialcommunication</td><td>28477977_analysis_4</td><td>[(SELF_ Group - SELF_No) - (OTHER_Group - OTHER_No)] (Fig. 4)</td><td>0.485</td><td>1.000</td><td>0.845</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>28477977_2</td><td>group &gt; no laughter; socialcommunication</td><td>28477977_analysis_1</td><td>Group minus No Laughter [(SELF_ Group - SELF_No) + (OTHER_ Group - OTHER_No)] (Supplemental Fig. S1)</td><td>0.343</td><td>1.000</td><td>0.803</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>28477977_3</td><td>group &gt; single laughter; socialcommunication</td><td>28477977_analysis_3</td><td>Group minus Single Laughter [(SELF_ Group - SELF_Single) + (OTHER_ Group - OTHER_Single)]</td><td>0.406</td><td>1.000</td><td>0.822</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>28477977_4</td><td>self &gt; other; socialcommunication</td><td>28477977_analysis_0</td><td>SELF minus OTHER [(SELF_No + SELF_Single + SELF_ Group) - (OTHER_No + OTHER_Single + OTHER_Group)] (Fig. 3)</td><td>0.271</td><td>1.000</td><td>0.781</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>28477977_5</td><td>single &gt; no laughter; socialcommunication</td><td>28477977_analysis_2</td><td>Single minus No Laughter [(SELF_ Single - SELF_No) + (OTHER_Single - OTHER_No)]</td><td>0.450</td><td>1.000</td><td>0.835</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 28504911</strong> | Pred included: 5 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/28504911/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>28504911_analysis_0</td><td>Select &gt; content</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Select &gt; content contrast involves a social-related task: selecting articles engaged ROI sets including social-cognition regions (VMPFC, DMPFC, TPJ, PC, rSTS) and the authors state social considerations were engaged during selection. This meets I1 and the analysis measures social processing.</td></tr>
<tr><td>28504911_analysis_1</td><td>Share &gt; content</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Share &gt; content clearly probes social-related processing: deciding to share articles engages value, self-related, and social-cognition ROIs and is explicitly a social task. Meets I1.</td></tr>
<tr><td>28504911_analysis_2</td><td>Share &gt; select</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Share &gt; select isolates increased social-related processing when considering sharing versus personal reading; authors report greater activation across value, self, and social ROIs in sharing, so this contrast measures social processing. Meets I1.</td></tr>
<tr><td>28504911_analysis_3</td><td>Select</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Parametric modulation of Select trials by preference examines how social/self/value ROIs scale with selection likelihood; authors report social-cognition ROI involvement during selection, so this analysis measures social processing. Meets I1.</td></tr>
<tr><td>28504911_analysis_4</td><td>Share</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Parametric modulation of Share trials by preference directly probes social-related processes tied to willingness to transmit information; authors report scaling in value, self, and social ROIs for sharing, so this measures social processing. Meets I1.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>28504911_1</td><td>Select &gt; content; others</td><td>28504911_analysis_0</td><td>Select &gt; content</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>28504911_2</td><td>Share &gt; content; others</td><td>28504911_analysis_1</td><td>Share &gt; content</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>28504911_3</td><td>Share &gt; select; others</td><td>28504911_analysis_2</td><td>Share &gt; select</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 28905269</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/28905269/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>28905269_analysis_0</td><td>Regions with increased activation for monogamous men compared to non-monogamous men for the romantic &gt; neutral contrast</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast (romantic &gt; neutral) uses images of couples and probes responses to social/romantic stimuli and group differences in social-affiliative processing; thus it clearly measures social processing at the neural level.</td></tr>
<tr><td>28905269_analysis_1</td><td>Regions with increased activation for non-monogamous men compared to monogamous men for the romantic &gt; sexual contrast</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast (romantic &gt; sexual) examines differential neural processing of social/romantic versus sexual stimuli, reflecting broader social processing differences in non-monogamous men.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>28905269_1</td><td>monogamous men compared to nonmonogamous, romantic &gt; neutral contrast; self</td><td>28905269_analysis_0</td><td>Regions with increased activation for monogamous men compared to non-monogamous men for the romantic &gt; neutral contrast</td><td>0.723</td><td>1.000</td><td>0.917</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>28905269_2</td><td>monogamous men compared to nonmonogamous, romantic &gt; sexual contrast; self</td><td>28905269_analysis_1</td><td>Regions with increased activation for non-monogamous men compared to monogamous men for the romantic &gt; sexual contrast</td><td>0.688</td><td>1.000</td><td>0.906</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29039129</strong> | Pred included: 2 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29039129/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29039129_analysis_0</td><td>Incongruent vs. Congruent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The IAT contrast (&#x27;Incongruent vs. Congruent&#x27;) probes implicit attitudes about monogamy vs. adultery, which are social constructs involving perception, interpretation, and regulation of social information relevant to relationships. This meets the Social Processing definition and the inclusion criterion (task is social-related).</td></tr>
<tr><td>29039129_analysis_1</td><td>Congruent vs. Incongruent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The &#x27;Congruent vs. Incongruent&#x27; IAT contrast is derived from the same social task measuring implicit attitudes about monogamy/adultery and thus indexes social processing related to relationship judgments.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29039129_1</td><td>Incongruent &gt; Congruent; socialcommunication</td><td>29039129_analysis_0</td><td>Incongruent vs. Congruent</td><td>0.917</td><td>1.000</td><td>0.975</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29097704</strong> | Pred included: 14 | Manual included (accepted matches only): 8 | Correct overlaps: 8 | Match statuses: accepted=8, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29097704/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29097704_analysis_0</td><td>FT&gt;FA</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task required participants to judge whether point-light displays or human-like walkers were facing towards or away, which directly involves perceiving and interpreting social cues and potential for social interaction. The contrast FT&gt;FA measures differences in social processing related to movement direction.</td></tr>
<tr><td>29097704_analysis_1</td><td>FA&gt;FT</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>FA&gt;FT contrasts neural responses to movement direction (away vs towards) for PLD/HL, reflecting social cue interpretation and potential for social involvement.</td></tr>
<tr><td>29097704_analysis_2</td><td>HL&gt;PLD</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>HL&gt;PLD contrasts human-like video stimuli against point-light displays; both involve social perception and interpretation of others’ actions and social meaning.</td></tr>
<tr><td>29097704_analysis_3</td><td>PLD&gt;HL</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>PLD&gt;HL examines greater MNS/MS engagement for sparse biological motion versus human-like stimuli — a social-processing contrast probing how social cues are encoded.</td></tr>
<tr><td>29097704_analysis_4</td><td>STIMULUS*DIRECTION</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The STIMULUS*DIRECTION interaction tests how stimulus type and movement direction jointly modulate social-network activity (MNS/MS), directly measuring social processing.</td></tr>
<tr><td>29097704_analysis_5</td><td>POST-HOC ANALYSIS</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Post-hoc analyses further parse condition-specific social effects (e.g., which stimulus/direction combinations drive MNS/MS differences), thus directly addressing social processing.</td></tr>
<tr><td>29097704_analysis_6</td><td>FT_PLD&gt;HL</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>FT_PLD&gt;HL compares facing-towards PLD to HL, probing social cue processing when stimuli are interpreted as approaching — a social-processing contrast.</td></tr>
<tr><td>29097704_analysis_7</td><td>FT_HL&gt;PLD</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>FT_HL&gt;PLD contrasts HL vs PLD when facing toward the observer; this probes social processing of richer social cues in approaching human-like stimuli.</td></tr>
<tr><td>29097704_analysis_8</td><td>FA_PLD&gt;HL</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>FA_PLD&gt;HL compares PLD vs HL in the facing-away condition, testing how social processing differs when social involvement potential is reduced/ambiguous.</td></tr>
<tr><td>29097704_analysis_9</td><td>FA_HL&gt;PLD</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>FA_HL&gt;PLD contrasts human-like vs PLD when facing away; this tests social-processing differences linked to stimulus realism under reduced social involvement.</td></tr>
<tr><td>29097704_analysis_10</td><td>PLD_FT&gt;FA</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>PLD_FT&gt;FA contrasts PLD facing-toward vs away, probing how direction modulates processing of social cues in point-light stimuli.</td></tr>
<tr><td>29097704_analysis_11</td><td>PLD_FA&gt;FT</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>PLD_FA&gt;FT compares PLD away vs toward, examining social-processing modulation by direction for point-light stimuli (social involvement inference).</td></tr>
<tr><td>29097704_analysis_12</td><td>HL_FT&gt;FA</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>HL_FT&gt;FA contrasts HL approaching vs receding, testing social-processing sensitivity to movement direction for explicit human-like agents.</td></tr>
<tr><td>29097704_analysis_13</td><td>HL_FA&gt;FT</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>HL_FA&gt;FT contrasts HL away vs toward; tests social-processing differentials when human-like agents are oriented away, assessing perceived social involvement.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29097704_1</td><td>FA &gt; FT; others</td><td>29097704_analysis_1</td><td>FA&gt;FT</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29097704_2</td><td>FA_HL &gt; PLD; others</td><td>29097704_analysis_9</td><td>FA_HL&gt;PLD</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29097704_3</td><td>FA_PLD &gt; HL; others</td><td>29097704_analysis_8</td><td>FA_PLD&gt;HL</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29097704_4</td><td>HL &gt; PLD; others</td><td>29097704_analysis_2</td><td>HL&gt;PLD</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29097704_5</td><td>HL_FT &gt; FA; others</td><td>29097704_analysis_12</td><td>HL_FT&gt;FA</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29097704_6</td><td>PLD &gt; HL; others</td><td>29097704_analysis_3</td><td>PLD&gt;HL</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29097704_7</td><td>PLD_FA &gt; FT; others</td><td>29097704_analysis_11</td><td>PLD_FA&gt;FT</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29097704_8</td><td>Stimulus*Direction; others</td><td>29097704_analysis_4</td><td>STIMULUS*DIRECTION</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29221830</strong> | Pred included: 2 | Manual included (accepted matches only): 5 | Correct overlaps: 2 | Match statuses: accepted=5, uncertain=1, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29221830/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29221830_analysis_0</td><td>Collaborative &gt; Arbitrary</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast directly compares retrieval of collaboratively encoded labels versus arbitrarily learned labels. The collaborative condition is a social communicative encoding context and the reported fMRI effects (medial PFC, TPJ, precuneus) reflect social processing/mentalizing. This contrast therefore measures social processing.</td></tr>
<tr><td>29221830_analysis_1</td><td>Individual &gt; Arbitrary</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Individual &gt; Arbitrary contrasts self-generated versus arbitrary labels; both are non-collaborative encoding contexts. The contrast primarily reflects semantic vs hippocampal memory processes rather than social processing.</td></tr>
<tr><td>29221830_analysis_2</td><td>Collaborative &gt; Individual</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Collaborative &gt; Individual directly contrasts collaboratively encoded labels with individually encoded labels; the authors report increased activation in social cognition regions (medial PFC, right TPJ, precuneus). The contrast therefore measures social processing.</td></tr>
<tr><td>29221830_analysis_3</td><td>Arbitrary &gt; Individual</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TN</span></td><td></td><td>Arbitrary &gt; Individual highlights greater hippocampal and domain-general memory/effort-related activations for arbitrary associations. Both conditions are non-collaborative encoding contexts; the contrast does not target social processing.</td></tr>
<tr><td>29221830_analysis_4</td><td>Individual &gt; Collaborative</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Individual &gt; Collaborative isolates regions more active for individually encoded labels relative to collaboratively encoded ones; this does not measure social processing and instead reflects non-social differences (e.g., semantic retrieval, efficiency).</td></tr>
<tr><td>29221830_analysis_5</td><td>Arbitrary &gt; Collaborative</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Arbitrary &gt; Collaborative contrasts arbitrary (non-social) encoding against collaborative encoding; effects reflect hippocampal and memory-related activity for arbitrary labels rather than social processing, so it does not meet Social Processing criteria.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29221830_1</td><td>Arbitrary &gt; Collaborative; socialcommunication</td><td>29221830_analysis_5</td><td>Arbitrary &gt; Collaborative</td><td>1.000</td><td>0.946</td><td>0.962</td><td>accepted</td><td>high_coord_match</td></tr><tr><td>29221830_2</td><td>Arbitrary &gt; Individual; socialcommunication</td><td>29221830_analysis_3</td><td>Arbitrary &gt; Individual</td><td>1.000</td><td>0.617</td><td>0.732</td><td>uncertain</td><td>coord_count_mismatch</td></tr><tr><td>29221830_3</td><td>Collaborative &gt; Arbitrary; socialcommunication</td><td>29221830_analysis_0</td><td>Collaborative &gt; Arbitrary</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29221830_4</td><td>Collaborative &gt; Individual; socialcommunication</td><td>29221830_analysis_2</td><td>Collaborative &gt; Individual</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29221830_5</td><td>Individual &gt; Arbitrary; socialcommunication</td><td>29221830_analysis_1</td><td>Individual &gt; Arbitrary</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29221830_6</td><td>Individual &gt; Collaborative; socialcommunication</td><td>29221830_analysis_4</td><td>Individual &gt; Collaborative</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29324862</strong> | Pred included: 6 | Manual included (accepted matches only): 7 | Correct overlaps: 6 | Match statuses: accepted=7, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29324862/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29324862_analysis_0</td><td>Partnering.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast examines partnered vs non-partnered movements (Leading+Following+Mutual &gt; Solo+Alone). This directly probes social interaction and networks (pSTS, TPJ, mPFC) involved in perceiving and engaging with another person, so it measures broad social processing.</td></tr>
<tr><td>29324862_analysis_1</td><td>Leading &gt; Conjunction</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast isolates Leading-specific activations within a dyadic interaction. Leading is a social role in joint action and the analysis investigates brain systems supporting that social behavior (self-oriented social role), so it meets the social processing criterion.</td></tr>
<tr><td>29324862_analysis_2</td><td>Following &gt; Conjunction</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast isolates Following-specific activations within a dyadic interaction. Following is a social role and the analysis probes networks supporting interpersonal responsiveness to another’s actions (pSTS, S2, MT+/V5), so it measures social processing.</td></tr>
<tr><td>29324862_analysis_3</td><td>Mutual &gt; Conjunction</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Mutual-specific contrast isolates an egalitarian, reciprocal interaction and shows engagement of mentalizing and reward circuitry (mPFC, TPJ, PCC, nucleus accumbens), so it clearly measures broad social processing.</td></tr>
<tr><td>29324862_analysis_4</td><td>Improvisation</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>This contrast targets improvisation per se (Leading+Solo &gt; Mutual+Alone) across partnered and non-partnered conditions to isolate generative motor and working-memory networks; it is primarily about motor/cognitive processes rather than social interaction specifically, so it does not meet the social-processing inclusion criterion.</td></tr>
<tr><td>29324862_analysis_5</td><td>Self-initiation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The self-initiation contrast ([Leading+Solo+Mutual+Alone] &gt; Following) indexes self- versus externally-triggered action within a social interaction context (Following is an externally-driven social role). Because it directly examines self-driven action in social exchanges, it is relevant to social processing.</td></tr>
<tr><td>29324862_analysis_6</td><td>Joint improvisation.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This analysis (Joint improvisation / Leading &gt; Solo) compares partnered versus solo improvisation to find regions related to signalling intentions to a partner; it interrogates social aspects of joint improvisation and interpersonal coordination, thus meeting the social processing criterion.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29324862_1</td><td>Following &gt; Conjunction; others</td><td>29324862_analysis_2</td><td>Following &gt; Conjunction</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29324862_2</td><td>Leading + Following + Mutual &gt; Solo + Alone); others</td><td>29324862_analysis_0</td><td>Partnering.</td><td>0.145</td><td>1.000</td><td>0.744</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>29324862_3</td><td>Leading + Solo &gt; Mutual + Alone; others</td><td>29324862_analysis_4</td><td>Improvisation</td><td>0.182</td><td>1.000</td><td>0.755</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>29324862_4</td><td>Leading &gt; Conjunction; others</td><td>29324862_analysis_1</td><td>Leading &gt; Conjunction</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29324862_5</td><td>Leading &gt; Solo; others</td><td>29324862_analysis_6</td><td>Joint improvisation.</td><td>0.294</td><td>1.000</td><td>0.788</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>29324862_6</td><td>Mutual &gt; Conjunction; others</td><td>29324862_analysis_3</td><td>Mutual &gt; Conjunction</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29324862_7</td><td>[Leading + Solo + Mutual + Alone] &gt; Following; others</td><td>29324862_analysis_5</td><td>Self-initiation</td><td>0.233</td><td>1.000</td><td>0.770</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29432769</strong> | Pred included: 8 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=1, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29432769/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29432769_analysis_0</td><td>Self- vs. Celebrity-judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast (Self vs. Celebrity) is a social task probing self-referential and person-related processing; it measures social processing broadly (self and other representations).</td></tr>
<tr><td>29432769_analysis_1</td><td>Friend- vs. Celebrity-judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Friend vs. Celebrity is a social task probing representation of others (close other vs a non-close other) and thus falls under general social processing.</td></tr>
<tr><td>29432769_analysis_2</td><td>Self- vs. Celebrity-judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This analysis tests how interdependence moderates neural responses in the Self vs. Celebrity contrast — still squarely a social processing analysis (self/other representations and cultural modulation).</td></tr>
<tr><td>29432769_analysis_3</td><td>Friend- vs. Celebrity-judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This analysis examines moderation of neural responses in Friend vs. Celebrity — a social cognition contrast involving close-other representations — and thus fits broad social processing.</td></tr>
<tr><td>29432769_analysis_4</td><td>Self- vs. Celebrity-judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This analysis examines functional connectivity during Self vs. Celebrity — a social task assessing self/other representations and network interactions — so it falls under general social processing.</td></tr>
<tr><td>29432769_analysis_5</td><td>Friend- vs. Celebrity-judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This analysis examines functional connectivity during Friend vs. Celebrity — a social contrast probing network interactions when representing others — therefore counts as social processing.</td></tr>
<tr><td>29432769_analysis_6</td><td>Self- vs. Celebrity-judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This analysis tests modulation of functional connectivity in the Self vs. Celebrity contrast by interdependence — still within social processing of self/other representations and network effects.</td></tr>
<tr><td>29432769_analysis_7</td><td>Friend- vs. Celebrity-judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This analysis examines modulation of functional connectivity during Friend vs. Celebrity by interdependence — a social-network-level test of other-related representations — so it is social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29432769_1</td><td>Friend vs Celebrity; others</td><td>29432769_analysis_1</td><td>Friend- vs. Celebrity-judgments</td><td>0.760</td><td>0.500</td><td>0.578</td><td>uncertain</td><td>coord_count_mismatch</td></tr><tr><td>29432769_2</td><td>Self vs Celebrity; self</td><td>29432769_analysis_2</td><td>Self- vs. Celebrity-judgments</td><td>0.739</td><td>0.800</td><td>0.782</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29582502</strong> | Pred included: 6 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29582502/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29582502_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The analysis comes from a social decision-making fMRI task (iterated prisoner&#x27;s dilemma) involving interactions with cooperative, competitive, and random partners; the contrast(s) reflect social processing broadly (mentalizing, social exchange).</td></tr>
<tr><td>29582502_analysis_1</td><td>Competitive&gt;Cooperative</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The &#x27;Competitive&gt;Cooperative&#x27; contrast isolates social processing differences when interacting with a noncooperative vs cooperative partner during an interpersonal game, representing social cognition broadly.</td></tr>
<tr><td>29582502_analysis_2</td><td>Cooperative&gt;Competitive</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The &#x27;Cooperative&gt;Competitive&#x27; contrast concerns social interaction dynamics (responses during cooperative partner interaction) and thus reflects social processing broadly.</td></tr>
<tr><td>29582502_analysis_3</td><td>Competitive&gt;Cooperative</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This analysis (Competitive&gt;Cooperative) again targets social decision-making and mentalizing differences and thus meets broad social processing criteria.</td></tr>
<tr><td>29582502_analysis_4</td><td>Early phase Competitive&gt;Cooperative</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The &#x27;Early phase Competitive&gt;Cooperative&#x27; analysis examines time-dependent social processing (early interactions where mentalizing and learning are engaged) and thus reflects broad social processing.</td></tr>
<tr><td>29582502_analysis_5</td><td>Dynamic ToM‐Value Competitive&gt;Cooperative</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The &#x27;Dynamic ToM-Value Competitive&gt;Cooperative&#x27; analysis links behavioral adaptation (understanding multiple partners) with neural connectivity—this reflects broad social processing and social learning.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29582502_1</td><td>Competitive &gt; Cooperative; others</td><td>29582502_analysis_3</td><td>Competitive&gt;Cooperative</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29582502_2</td><td>Cooperative &gt; Competitive; others</td><td>29582502_analysis_2</td><td>Cooperative&gt;Competitive</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29582502_3</td><td>Dynamic ToM-Value Competitive &gt; Cooperative; others</td><td>29582502_analysis_5</td><td>Dynamic ToM‐Value Competitive&gt;Cooperative</td><td>0.977</td><td>1.000</td><td>0.993</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29582502_4</td><td>Early phase Competitive &gt; Cooperative; others</td><td>29582502_analysis_4</td><td>Early phase Competitive&gt;Cooperative</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29740753</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29740753/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29740753_analysis_0</td><td>Main effect of modality</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The main effect of modality analysis tests how facial, vocal, and bimodal stimuli influence emotion perception — a core social processing task involving perception and interpretation of social/emotional cues. It therefore measures Social Processing.</td></tr>
<tr><td>29740753_analysis_1</td><td>Main effect of emotion</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The main effect of emotion examines neural/behavioral responses to emotions (anger, happiness, neutral) — explicitly a social-emotional perception task and thus Social Processing.</td></tr>
<tr><td>29740753_analysis_2</td><td>The 3 (Emotion)×3 (Modality) interaction effects generated by repeated measures ANOVA.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Emotion × Modality interaction probes how modality (face/voice/bimodal) and emotion interact in social-emotional perception — clearly a Social Processing measure.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29740753_1</td><td>Emotion &gt; Modality; socialcommunication</td><td>29740753_analysis_1</td><td>Main effect of emotion</td><td>0.350</td><td>1.000</td><td>0.805</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>29740753_2</td><td>Modality &gt; Emotion; socialcommunication</td><td>29740753_analysis_0</td><td>Main effect of modality</td><td>0.390</td><td>1.000</td><td>0.817</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>29740753_3</td><td>Modality X Emotion; socialcommunication</td><td>29740753_analysis_2</td><td>The 3 (Emotion)×3 (Modality) interaction effects generated by repeated measures ANOVA.</td><td>0.320</td><td>1.000</td><td>0.796</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29777673</strong> | Pred included: 9 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29777673/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29777673_analysis_0</td><td>SA vs. SC</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>SA vs SC contrasts agentic vs communal trait ratings during self-evaluation — a social-cognition task (self-related social trait judgments). Meets social processing inclusion (task is social-related).</td></tr>
<tr><td>29777673_analysis_1</td><td>SC vs. SA</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>SC vs SA is a self-evaluation contrast of communal vs agentic traits — a social-cognition task involving trait judgments about the self.</td></tr>
<tr><td>29777673_analysis_2</td><td>OA vs. OC</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>OA vs OC contrasts endorsement of others&#x27; agentic vs communal evaluations of the self — a social task involving processing of social feedback and social trait information.</td></tr>
<tr><td>29777673_analysis_3</td><td>OC vs. OA</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>OC vs OA contrasts endorsement of others&#x27; communal vs agentic evaluations of the self — clearly a social-cognition task involving processing social feedback.</td></tr>
<tr><td>29777673_analysis_4</td><td>SA vs. Fixation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>SA vs Fixation regression examines neural responses during agentic self-evaluation and their relationship to self-esteem — a social-cognition/self-related analysis.</td></tr>
<tr><td>29777673_analysis_5</td><td>dlPFC as the seed region</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>PPI with dlPFC seed (SA &gt; Fixation) examines connectivity during agentic self-evaluation — a social-cognition/self-related processing analysis.</td></tr>
<tr><td>29777673_analysis_6</td><td>dlPFC as the seed region</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>dlPFC seed Fixation &gt; SA connectivity contrast is derived from the same social self-evaluation paradigm and is part of social-cognition analyses (contrasts involving SA and Fixation).</td></tr>
<tr><td>29777673_analysis_7</td><td>Thalamus as the seed region</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Thalamus seed PPI (SA &gt; Fixation) examines connectivity during agentic self-evaluation — clearly part of social/self-related processing.</td></tr>
<tr><td>29777673_analysis_8</td><td>Thalamus as the seed region</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Thalamus seed Fixation &gt; SA contrast is derived from the social self-evaluation paradigm and therefore part of social processing analyses.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29777673_1</td><td>OA &gt; OC; others</td><td>29777673_analysis_2</td><td>OA vs. OC</td><td>0.750</td><td>1.000</td><td>0.925</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29777673_2</td><td>SA vs. Fixation; self</td><td>29777673_analysis_4</td><td>SA vs. Fixation</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29777673_3</td><td>SC &gt; SA; self</td><td>29777673_analysis_1</td><td>SC vs. SA</td><td>0.750</td><td>1.000</td><td>0.925</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 30077577</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/30077577/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> other&gt; control; others</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>30077577_analysis_0</td><td>self-relevant&gt;control</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task explicitly probes recalling interpersonal/relationship episodes about self and others, which is a social-cognitive task assessing social processing (self- and other-referencing, autobiographical relationship memory). This matches the Social Processing domain.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>30077577_1</td><td>other&gt; control; others</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>30077577_2</td><td>self-relevant &gt; control; self</td><td>30077577_analysis_0</td><td>self-relevant&gt;control</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 30272134</strong> | Pred included: 3 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/30272134/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>30272134_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The study examines perception and integration of emotional expressions from faces and voices—clearly a social-related task measuring social processing (emotion recognition, multisensory social cues). The analysis (unnamed table but from this study) relates to these contrasts and thus measures social processing.</td></tr>
<tr><td>30272134_analysis_1</td><td>(BIMODAL &gt; UNIMODAL FACES) ∩ (BIMODAL &gt; UNIMODAL VOICES)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast (BIMODAL &gt; UNIMODAL FACES) ∩ (BIMODAL &gt; UNIMODAL VOICES) tests multisensory integration of emotional face/voice signals — a social task measuring social processing (emotion perception/integration).</td></tr>
<tr><td>30272134_analysis_2</td><td>INCONGRUENT &gt; CONGRUENT</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>INCONGRUENT &gt; CONGRUENT examines how conflicting facial and vocal emotional signals are processed — a social task measuring social processing (conflict in social-emotional communication).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>30272134_1</td><td>(Bimodal &gt; Unimodal faces) ∩ (Bimodal &gt; Unimodal Voices); socialcommunication</td><td>30272134_analysis_1</td><td>(BIMODAL &gt; UNIMODAL FACES) ∩ (BIMODAL &gt; UNIMODAL VOICES)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>30272134_2</td><td>Incongruent &gt; Congruent; socialcommunication</td><td>30272134_analysis_2</td><td>INCONGRUENT &gt; CONGRUENT</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 30649548</strong> | Pred included: 6 | Manual included (accepted matches only): 6 | Correct overlaps: 6 | Match statuses: accepted=6, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/30649548/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>30649548_analysis_0</td><td>Cooperation &gt; competition</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is a dyadic interactive social-exchange game (cooperation vs competition; concurrent vs turn-based) and the contrasts (Cooperation &gt; Competition) directly probe social processing (interpersonal brain-behavior dependencies).</td></tr>
<tr><td>30649548_analysis_1</td><td>Competition &gt; cooperation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Competition &gt; Cooperation contrasts probe social interaction dynamics and neural responses to others&#x27; behavior during competitive exchange, thus measuring social processing broadly.</td></tr>
<tr><td>30649548_analysis_2</td><td>CN &gt; TB</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>CN &gt; TB contrasts compare concurrent versus turn-based interaction structures in a dyadic social task; this directly probes social processing of different interaction modes.</td></tr>
<tr><td>30649548_analysis_3</td><td>TB (COO &amp;gt; COM) &amp;gt; CN (COO &amp;gt; COM)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This contrast tests whether the goal-related effect (Cooperation&gt;Competition) differs by interaction mode (TB vs CN) — a higher-order social interaction contrast directly addressing social processing.</td></tr>
<tr><td>30649548_analysis_4</td><td>Builder (COO &gt; COM) &gt; Other (COO &gt; COM)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This role-by-goal contrast (Builder (COO&gt;COM) &gt; Other (COO&gt;COM)) examines role-specific social processing during cooperative vs competitive exchanges and therefore probes social processing broadly.</td></tr>
<tr><td>30649548_analysis_5</td><td>Other (COO &gt; COM) &gt; Builder (COO &gt; COM)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Other (COO&gt;COM) &gt; Builder (COO&gt;COM) similarly probes role-specific social processing during cooperative vs competitive interaction and thus meets social processing criteria.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>30649548_1</td><td>Builder (COO &gt; COM) &gt; Other (COO &gt; COM); affiliation</td><td>30649548_analysis_4</td><td>Builder (COO &gt; COM) &gt; Other (COO &gt; COM)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>30649548_2</td><td>CN &gt; TB; affiliation</td><td>30649548_analysis_2</td><td>CN &gt; TB</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>30649548_3</td><td>Competition &gt; Cooperation; affiliation</td><td>30649548_analysis_1</td><td>Competition &gt; cooperation</td><td>1.000</td><td>0.938</td><td>0.956</td><td>accepted</td><td>high_coord_match</td></tr><tr><td>30649548_4</td><td>Cooperation &gt; competition; affiliation</td><td>30649548_analysis_0</td><td>Cooperation &gt; competition</td><td>1.000</td><td>0.943</td><td>0.960</td><td>accepted</td><td>high_coord_match</td></tr><tr><td>30649548_5</td><td>Other (COO &gt; COM) &gt; Builder (COO &gt; COM); affiliation</td><td>30649548_analysis_5</td><td>Other (COO &gt; COM) &gt; Builder (COO &gt; COM)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>30649548_6</td><td>TB (COO &gt; COM) &gt; CN (COO &gt; COM); affiliation</td><td>30649548_analysis_3</td><td>TB (COO &amp;gt; COM) &amp;gt; CN (COO &amp;gt; COM)</td><td>0.789</td><td>1.000</td><td>0.937</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 31090126</strong> | Pred included: 8 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/31090126/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>31090126_analysis_0</td><td>Stimulus type (expression&gt;mosaic)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast (dynamic facial expressions &gt; dynamic mosaics) tests perception and processing of social stimuli (emotional facial expressions) across a large sample, directly measuring social processing.</td></tr>
<tr><td>31090126_analysis_1</td><td>Stimulus type (expression&gt;mosaic)×emotion</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This interaction tests whether social processing (expression &gt; mosaic) differs by emotion; the base contrast is social and thus the analysis addresses social processing.</td></tr>
<tr><td>31090126_analysis_2</td><td>Stimulus type (expression&gt;mosaic)×gender</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This interaction assesses whether social processing (expression &gt; mosaic) differs by participant gender; it concerns social processing of faces and thus is included.</td></tr>
<tr><td>31090126_analysis_3</td><td>Stimulus type (expression&gt;mosaic)×emotion×gender</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Three-way interaction (stimulus×emotion×gender) still concerns social processing of facial expressions and how it may be modulated by emotion and sex; thus included.</td></tr>
<tr><td>31090126_analysis_4</td><td>Stimulus type (expression&gt;mosaic)×laterality</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Laterality analyses (original vs flipped) for expression &gt; mosaic test hemispheric aspects of social processing of faces, so they address social processing broadly.</td></tr>
<tr><td>31090126_analysis_5</td><td>Stimulus type (expression&gt;mosaic)×emotion×laterality</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This analysis tests emotion×laterality for expression &gt; mosaic and thus examines social processing of faces and its hemispheric modulation by emotion.</td></tr>
<tr><td>31090126_analysis_6</td><td>Stimulus type (expression&gt;mosaic)×sex×laterality</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Sex×laterality interaction for expression &gt; mosaic assesses social processing and its hemispheric modulation across sexes, so it&#x27;s within social processing.</td></tr>
<tr><td>31090126_analysis_7</td><td>Stimulus type (expression&gt;mosaic)×emotion×sex×laterality</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The four-way interaction including laterality, emotion, and sex still addresses social processing of dynamic facial expressions and their modulators, so included.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>31090126_1</td><td>(expression &gt; mosaic) × laterality; socialcommunication</td><td>31090126_analysis_4</td><td>Stimulus type (expression&gt;mosaic)×laterality</td><td>0.800</td><td>1.000</td><td>0.940</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>31090126_2</td><td>expression &gt; mosaic; socialcommunication</td><td>31090126_analysis_0</td><td>Stimulus type (expression&gt;mosaic)</td><td>0.704</td><td>0.959</td><td>0.882</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>
</details></section><section id="bucket-false-positive"><details class="bucket" open><summary><h2>False Positive (11)</h2></summary><p><strong>Match status totals:</strong> accepted=0 | uncertain=3 | unmatched=35</p>
<details class="doc-card">
  <summary><strong>PMID 31598216</strong> | Pred included: 7 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=2</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/31598216/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> decision-making &gt; results; socialcommunication, results &gt; decision-making; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>31598216_analysis_0</td><td>decision-making</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Decision-making contrast from the prisoners&#x27; dilemma is a social task assessing social behavior (cooperation/defection) and related social cognition; it therefore measures broad social processing.</td></tr>
<tr><td>31598216_analysis_1</td><td>results</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Result-phase contrast involves processing outcomes of social interactions (reciprocation/defection) and thus constitutes social processing.</td></tr>
<tr><td>31598216_analysis_2</td><td>PATIENTS</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Patient group analysis examines the same PDG social task within patients and therefore measures social processing.</td></tr>
<tr><td>31598216_analysis_3</td><td>CONTROLS</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Control group analysis also involves the PDG and related social cognitive measures, thus measuring social processing.</td></tr>
<tr><td>31598216_analysis_4</td><td>main effect of group</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Main effect of group compares activation during a social-interaction task (PDG) between patients and controls, addressing broad social processing differences.</td></tr>
<tr><td>31598216_analysis_5</td><td>main effect of condition</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Main effect of condition (decision vs result) assesses different phases of a social-interaction task and therefore involves social processing.</td></tr>
<tr><td>31598216_analysis_6</td><td>ROI-main effect of group</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>ROI main-effect-of-group targets social brain ROIs (frontal, ACC, amygdala, etc.) during the PDG, indexing social processing at ROI level.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>31598216_1</td><td>decision-making &gt; results; socialcommunication</td><td>31598216_analysis_0</td><td>decision-making</td><td>0.750</td><td>0.093</td><td>0.290</td><td>unmatched</td><td>coord_count_mismatch, low_coord_high_name, low_total_score</td></tr><tr><td>31598216_2</td><td>results &gt; decision-making; socialcommunication</td><td>31598216_analysis_3</td><td>CONTROLS</td><td>0.182</td><td>0.556</td><td>0.443</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  <details class="inner-accordion"><summary>PMC full text available (PMCID 6731699)</summary><p><strong>Title:</strong> Social cognition, behaviour and therapy adherence in frontal lobe epilepsy: a study combining neuroeconomic and neuropsychological methods</p><details><summary>Abstract</summary><pre class="paper-text">Social behaviour of healthy humans and its neural correlates have been extensively studied in social neuroscience and neuroeconomics. Whereas it is well established that several types of epilepsies, such as frontal lobe epilepsy, lead to social cognitive impairments, experimental evidence on how these translate into behavioural symptoms is scarce. Furthermore, it is unclear whether social cognitive or behavioural disturbances have an impact on therapy adherence, which is critical for effective disease management, but generally low in these patients. In order to investigate the relationship between social cognition, social behaviour, and therapy adherence in patients with frontal lobe epilepsies (FLE), we designed a study combining conventional neuropsychological with behavioural economic and functional magnetic resonance imaging (fMRI) methodology. Fifteen patients and 15 healthy controls played a prisoners&#x27; dilemma game (an established game to operationalize social behaviour) while undergoing fMRI. Additionally, social cognitive, basic neuropsychological variables, and therapy adherence were assessed. Our results implicate that social behaviour is indeed affected and can be quantified using neuroeconomic methods in patients with FLE. Impaired social behaviour in these patients might be a consequence of altered brain activation in the medial prefrontal cortex and play a role in low therapy adherence. Finally, this study serves as an example of how to integrate neuroeconomic methods in neurology.</pre></details><details><summary>Body</summary><pre class="paper-text">## Introduction 
  
Social cognition is a term used for several high-level cognitive functions that determine human behaviour in a social context. Several studies showed impairments of social cognition in frontal lobe epilepsies (FLE), such as Theory-of-Mind/mentalizing and facial emotion recognition [ ], as well as neuropsychiatric co-morbidities [ ], but studies quantifying social behaviour abnormalities of FLE patients in an experimental sense are scarce. Even though behaviour relies on cognitive functions, the relationship between cognition, behaviour and epilepsy variables is complex and not fully understood [ ], making it difficult to predict the impact of altered social cognition on social behaviour, and more specifically, therapy adherence in FLE. 

In neuroeconomics—the science of studying research questions in economics through the application of neuroscientific methods and theories—pro-social behaviours, such as trust or cooperation, have been extensively studied for decades, mainly through game paradigms, such as the trust game or the prisoners&#x27; dilemma game [ ]. Using this approach, several brain areas were found to play a role in pro-social behaviour of healthy humans. Crucial parts of this brain network reside in the frontal cortex such as the ventromedial frontal/orbitofrontal cortex and the anterior cingulate cortex [ ]. These discoveries have led to the adoption of economic methodology to study behaviour in neurology [ ], but to the best of our knowledge, no such study has focused on the behaviour of patients with epilepsy. 

Adherence to anti-epileptic drug therapy is critical for effective disease management. Although its measurement is difficult without a single method that has yet proved to be the gold standard [ ], therapy adherence of patients suffering from epilepsy is low (at about 30–50%) [ ]. This is unfortunate, as low therapy adherence not only leads to poorer seizure control, but also increases the risk of sudden unexpected death in epilepsy [ ]. The reasons for low therapy adherence in general are still a matter of research [ ]. Low therapy adherence seems to have a multifactorial origin with some factors being associated with neuropsychological impairments and psychiatric co-morbidities of chronic diseases [ ], and others reflecting pathophysiological changes of neural networks specifically affected in epilepsy [ ]. 

We thus designed a study combining conventional neuropsychological with neuroeconomic methods to address the following open research questions:
   
Is there a difference in social behaviour between FLE patients and healthy controls that can be experimentally operationalized? 
  
If such a difference exists, is it associated with altered social cognitive functions and their underlying frontal lobe network? 
  
Does social behaviour affect therapy adherence in FLE? 
  


## Methods 
  
### Subjects 
  
We included 15 FLE patients and 15 healthy controls. We established the following inclusion and exclusion criteria to ensure the feasibility of the study and avoid known confounders in behavioural research. 

Inclusion criteria for patients were: age between 18 and 50, right-handedness (Edinburgh handedness inventory; [ ]), no significant anxiety, depression, or obsessive-compulsive symptoms as assessed by a hospital anxiety and depression scale score (HADS) less than 10 [ ] and an obsessive compulsive inventory score (OCIS) less than 40 [ ], sufficient language skills, and a diagnosis of FLE. The latter was based either upon association between typical frontal lobe seizure semiology and existence of an epileptogenic MRI lesion within the frontal lobe or upon direct recording of seizures of frontal lobe origin during a long-term video-EEG monitoring performed in the Department of Functional Neurology and Epileptology at Hospices Civils de Lyon, France, in patients with normal MRI. Exclusion criteria included pregnancy, non-MRI suitable transplants, major perceptive impairments, non-epileptic seizures, a history of intellectual disability, other known neurological diseases, MRI-lesion outside of the frontal lobe or frontal cortical lesions larger than 1 cm in diameter, and past epilepsy or other brain surgery in order to achieve a patient sample of non-resected participants. 

Inclusion criteria for controls were: age between 18 and 50, right-handedness (Edinburgh handedness inventory; [ ]), no significant anxiety, depression, or obsessive-compulsive symptoms assessed by a HADS Score less than 10 [ ] and an OCIS less than 40 [ ] as well as sufficient language skills. Exclusion criteria were pregnancy, non-MRI suitable transplants, major perceptive impairments, medication other than contraceptives, or a history of neurological or psychiatric diseases. 


### Magnetic resonance data acquisition 
  
All images were acquired using the same MRI machine (Siemens Magneton Prisma 3 Tesla) in one session per participant. Structural MRI and shimming (to minimize field inhomogeneities) were performed on all subjects prior to gradient-echo echoplanar imaging that provided blood oxygen level dependent (BOLD) contrast. Each volume comprised 35 AC-PC aligned slices (order of acquisition: interleaved) with a thickness of 2.5 cm, field of view (FOV) 23 cm, parallel imaging parameters GRAPPA/acceleration factor 2, echo time (TE) 26 ms, repetition time (TR) 2260 ms. 


### Paradigm 
  
We designed our paradigm on the basis of similar experiments in the literature [ ] to ensure comparability. When subjects entered the laboratory for the experiment, they received written instructions explaining the prisoners&#x27; dilemma game (PDG) [ ]. In this game, two players decide at the same time whether or not to cooperate with the other player. Depending on the decisions of both players, there is a monetary pay-off, which is equal for both players in the case of mutual cooperation or defection, whereas in the case of divergent strategies, it is not existent for the cooperating player and highest for the defecting player. The pay-off structure of our version of the game is shown in  .
   
Pay-off structure of the prisoners&#x27; dilemma game. 
  

Participants were told that they would play with real money and be paid out their gain. Payment took place at the end of the experiment, but in fact, all participants received the same amount of money (40€) independent of their actual gain due to ethical considerations. The participants did not know the number of rounds played in the game, but in fact all subjects played 32 rounds. Moreover, participants (player 1) were told that they would be playing with four different human beings (two males and two females—here termed player 2) located in another room, but actually played against a computer-generated, randomized, strategy that simulated the other player&#x27;s behaviour. This means that each participant played 32 rounds with each of the four different counterparts (equals 128 decisions to cooperate or to defect in total). Player 2 was illustrated with face images from an established database (Glasgow Unfamiliar Face Database). Once installed in the MRI machine, participants first had to rate the trustworthiness of the presented player 2 on a Likert-scale between 1 and 7 (1 no trustworthiness, 7 highest possible trustworthiness) being shown a face picture of player 2. Next, the actual game began. Each round of the game consisted of 3 screens: first, the pay-off matrix of the game was shown for 2 s. Then, participants were asked to choose to either cooperate or to defect using two input buttons. After a random time interval between 4 and 6 s simulating variable decision times of player 2, the result of the round was shown for 2 s using the pay-off matrix with the result highlighted in yellow colour. After 32 rounds of the game, the face of player 2 was again shown to the participants, who had to rate the trustworthiness of the face another time in analogy to the start. Finally, the overall gain of the game was shown. See   for a visualization.
   
Visualization of the experimental paradigm. Notes: top left—visualization of the beginning and end of the paradigm, bottom right—visualization of the time period in between (corresponds to dashed line in the top left part of the figure); PDG, prisoners&#x27; dilemma game. 
  


### Demographic data, neuropsychological testing, questionnaires and pill counts 
  
We recorded the following variables in all participants via a self-report questionnaire: age, gender, profession and education. For patients, we included the number of seizures (generalized tonic-clonic seizures and other seizure types separately) in the last three months according to a seizure calendar commonly used in clinical routine and current anticonvulsive treatment (number and names of drugs, number of intakes per day, preparation of drugs for intake by the participant or by a carer) as recorded in the patient&#x27;s medical chart. 

Neuropsychological variables captured in all participants included psychomotor speed and mental flexibility (Trail Making test A and B [ ]), memory for faces and working memory (Faces subsets and numbers of the Wechsler Memory Scale, fourth edition [ ]). 

Social cognition was tested through the Reading the Mind in the Eyes test [ ] for Theory-of-Mind/mentalizing (in this test, subjects have to choose the correct word out of a list describing emotions to corresponding photos of a person&#x27;s expression of eyes) and a trust questionnaire ([ ]; French version), additionally to the trustworthiness ratings of faces during the fMRI paradigm. 

Furthermore, therapy adherence was measured in the patient group through pill counts at two consecutive visits [ ] by reviewing pill bottles of a six months period and several questionnaires comprising the Morisky adherence scale ([ , ]; validated French version), the Beliefs about Medicines Questionnaire (BMQ; [ , ]; validated French version) and the SATMED-Q (Treatment Satisfaction with Medicines Questionnaire, [ ]; French version). These questionnaires are commonly used instruments in research on therapy adherence. 


### Data analysis 
  
#### Imaging data 
  
fMRI data were analysed using SPM 12 ( ). Pre-processing involved slice time correction, realignment, normalization and smoothing with an 8 mm full width at half maximum Gaussian kernel. A general linear model with two conditions (decision phase and result phase) was estimated. No subject had to be excluded. The contrast images calculated for individual subjects were entered into a second level or random effects analysis [ ]. We first calculated   t  -tests for the two conditions (decision/result) for all participants as one group and in a second step analysed each group (patients/controls) separately in the same way. In a third step, we calculated two-sample   t  -tests between the two groups for both conditions. We then implemented a 2 × 2 repeated measures ANOVA using a flexible factorial design with the factors ‘group&#x27; (patients/controls) and ‘condition&#x27; (decision/result) to calculate main effects of group and condition as well as the interaction effect of group and condition. The resultant statistical parametric maps were thresholded using an FWE-corrected   p  -value threshold less than 0.001, reporting clusters greater than 20 voxels (  k   = 20) only. Anatomical structures of cluster maxima were labelled in Talairach space using the Talairach Client ( ). 

Based on the previous research, we   a priori   selected the following regions of interest (ROIs) for further analyses: superior, middle and inferior frontal gyri, medial and lateral orbital gyri, posterior orbital gyrus, straight gyrus, anterior cingulate gyrus, amygdala, thalamus and caudate nucleus. We used adult brain maximum probability maps (© Copyright Imperial College of Science, Technology and Medicine 2007. All rights reserved) to obtain the ROIs [ ]. 

In a subsequent step, we computed the % of BOLD signal change extracted from beta images from significant voxels from the second-level analysis within an 8 mm sphere surrounding the activation peak and calculated correlations with all other variables collected during the study. 


#### Neuropsychological and questionnaire data 
  
The statistical analysis was performed with SPSS, v. 20 and involved two-tailed, non-parametric testing (Wilcoxon test,   χ  ²-test), as well as Spearman&#x27;s rho correlations. We corrected for multiple testing using the Bonferroni–Holm procedure and chose a significance level of less than 0.05. 




## Results 
  
### Behavioural data, neuropsychological variables and questionnaires 
  
We included 15 FLE patients and 15 healthy controls. Four patients (26.67%) were seizure free, while the remaining eleven (73.33%) had a median monthly seizure frequency of 4 during a three-month period preceding the experiment. MRI was normal in nine patients (60%) and showed frontal lobe lesions—cavernoma (one patient), focal cortical dysplasia (one patient), diffuse axonal trauma (one patient), and post-haematoma scars (two patients)—in the remaining five patients (33.3%). The remaining patient had undergone skull (but not brain) surgery in childhood for craniostenosis and the current structural MRI showed no obvious pathological changes. Three patients were on monotherapy and 12 patients were under polytherapy (mean number ± s.d. of anti-epileptic drugs: 2.33 ± 0.98). Mean ± s.d. subjective (Morisky adherence scale) and objective (pill counts) measures of treatment adherence during a six-month period were 1.73 ± 0.88 (range: 0–8, lower number indicates higher adherence) and 7.00 ± 12.45 (number of prescribed pills not taken), indicating moderate level of adherence. Patients also showed high belief of treatment necessity (BMQ mean ± s.d.—necessity 21.13 ± 6.30, range: 5–25), average level of concerns and negative views regarding therapy (BMQ: concerns and harms 24.87 ± 9.36, range: 9–45; overuse 7.47 ± 3.27, range: 4–20) and an average treatment satisfaction (SATMED-Q mean ± s.d.: 65.36 ± 7.88, range: 17–85). Questionnaires capturing beliefs about medicines (  p   = 0.256), treatment satisfaction (  p   = 0.776), or adherence (  p   = 0.056) did not correlate significantly with therapy adherence measured through pill counts, although the Morisky adherence scale was close to being significant (  p   = 0.056). 

For all demographic, neuropsychological and neuroeconomic data collected in this study on both patient and control groups, please refer to  . In summary, there was no significant difference between the patient and control groups regarding age, gender, handedness, education, professional status, trust in doctors as captured by the respective questionnaire [ ], trustworthiness of game opponents, or working memory for numbers. By contrast, patients demonstrated statistically significant worse performance than controls in mentalizing measured through the Reading eyes in the mind test, memory for faces, psychomotor speed during Trail making test A, and mental flexibility performance during Trail making test B.
   
Summary of data collected on both participant groups of our study. 
    

Furthermore, there was also a significant difference in the total number of cooperative choices during the PDG, indicating higher cooperation in patients than in controls. The numbers of cooperative choices between games 1 and 4 differed significantly in both groups, indicating that cooperation decreased significantly between the first and the last game of the experiment in both groups ( ).
   
Mean numbers of cooperative choices of the patient and control groups in the four prisoners&#x27; dilemma games. 
  

Mentalizing correlated strongly with memory for faces (  r   = 0.715;   p   = 0.000) and with trust in doctors and the health system [ ] (  r   = 0.437;   p   = 0.026), showing that participants with high mentalizing abilities also better memorized faces and had higher trust in healthcare. Taken together these data supported a positive correlation between several pro-social cognition and behaviour variables. 

There was a significant positive correlation between cooperative choices in the PDG and missed medication intakes with high values representing low therapy adherence (  r   = 0.686;   p   = 0.010), indicating higher cooperative behaviour in patients with low therapy adherence. 


### Imaging results (see tables  ,   and  ) 
  
#### Voxel-based whole brain analysis 
  
 Brain activation during decision-making.   During the decision-making whether to cooperate or defect when playing the PDG, combined event-related fMRI analysis of data from all subjects (one sample   t  -test) showed significantly activated clusters in right inferior parietal lobule, left precuneus, left lingual gyrus, left insula, the middle and inferior frontal gyri bilaterally, left superior frontal gyrus, as well as the right anterior lobe of the cerebellum ( ). In controls, significant activation was observed in the right fusiform gyrus, right superior frontal gyrus, left insula and left superior temporal gyrus, while in patients, significant activation was observed in the left superior frontal gyrus, left precuneus, and left insula.
   
Visualization of brain activation of all participants (according to one sample   t  -test results reported in  ) during decision-making (yellow) and result perception (red)—thresholded at   p   &lt; 0.001, FWE-corrected,   k   = 20. 
    
Summary of analysis of all participants. FWE,   p   = 0.001. 
    
Summary of per group analyses. FWE,   p   = 0.001. 
    
Analysis of group differences and ROI. 
  

 Brain activation during result phase.   During the perception of the results of the game, combined analysis of data from all subjects (one sample   t  -test) showed activation in the inferior parietal lobules bilaterally and the right middle temporal gyrus—these results are visualized in   as well. In controls, significant activation was observed in the left middle frontal gyrus, inferior parietal lobules bilaterally, right inferior temporal gyrus, and left cingulate gyrus. In patients, significant activation was observed in both inferior parietal lobules, left superior temporal gyrus, right middle frontal gyrus, right thalamus, left insula and right precuneus. 

 Individual group comparisons for both conditions.   Two-sample   t  -tests between the patient and control groups did not yield any significant results for both conditions. 

 Integrated comparison across groups and conditions.   In the full factorial analysis, the main group effect (  F  -test) showed significant clusters in the right and left medial prefrontal cortex—Brodmann area 10 ( ). In the main effect of condition (decision-making versus result phase of the game), the following clusters were significant: right anterior lobe of the cerebellum, left precentral gyrus, right inferior frontal gyrus, right insula, left middle temporal gyrus and left superior frontal gyrus. There was no significant interaction between group and condition.
   
Difference in activation between the patient and control groups (main effect of groups,   F  -test) in the whole-brain analysis—thresholded at   p   &lt; 0.001, FWE-corrected,   k   = 20. 
  


#### Region of interest analysis 
  
ROI analysis (  F  -test) showed differences in activation between the patient and control groups in the right and left superior frontal gyrus, while the   t  -test analyses showed no significant differences. The mean % of BOLD signal changes in these ROIs in the result condition showed a significant negative correlation with initial trust (  r   = −0.448;   p   = 0.017), indicating that participants with high initial trust showed lower signal change in these brain areas during result perception. The mean % of BOLD signal changes in the choice condition also correlated significantly with differences between the initial and final trust (  r   = −0.618;   p   = 0.000; first ROI and   r   = −0.545;   p   = 0.003 for the second ROI), meaning that participants with a high decrease of trust from the beginning to the end of the games showed lower signal changes while making their choices in the game. 

Another significant correlation was detected between therapy adherence and the % BOLD signal change in the choice condition (  r   = 0.565;   p   = 0.044 for the first ROI) showing that participants with low therapy adherence had higher signal changes in this brain area. 




## Discussion 
  
In this study, we first confirmed that mentalizing is impaired in patients with FLE, as previously established [ ]. These abnormalities correlated with an altered memory for faces, a previously unreported finding in FLE, which may shed light on the mechanisms underlying dysfunction in social behaviour. Interestingly, there is evidence of frontal lobe contributions to memory for faces [ ]. Furthermore, mentalizing abilities correlated with the results of the trust in healthcare questionnaire implying an overall good correlation of pro-social cognition variables in our study. 

One of the goals of this study was to find out whether deficits in social cognition in FLE patients could lead to differences in social behaviour that can be operationalized. In fact, we showed that FLE patients behave differently from healthy controls in the PDG, but in a counterintuitive way, since they cooperated more than controls. While this finding was unexpected, we observed a frequent pattern of evolving cooperation during the game in both the patients&#x27; and controls&#x27; groups, with higher rates of cooperation in early game phases and less cooperative behaviour in the later ones [ ]. This strategy is consistent with the objective of maximizing profit. Indeed, future possible interactions encourage people to cooperate in the early phases of the game, with the hope to initiate a mutually cooperative relationship. If not reciprocated, strategy will later shift to defection in players who want to maximize their own profit [ ]. 

In this context, higher cooperation in patients might result from impaired negative feedback when cooperative behaviour is not reciprocated, especially because the ability to shift behaviour from cooperation to defection in such a case is dependent on frontal lobe functions [ ]. Alternatively, patients&#x27; behaviour could be interpreted as a preference for higher delayed rewards since higher cooperation leads to higher future profits [ ]. Although evidence on time preference for rewards (also referred to as ‘delay discounting&#x27;) in neurological patients is scarce, altered delay discounting as another behavioural symptom of neurological disorders was reported before [ ]. 

Prior functional brain imaging studies investigating cooperative behaviour through the PDG found, in essence, three brain networks to be active during the game: several frontal brain areas, especially the medial prefrontal cortex, as well as reward and limbic brain regions [ ] reflecting the cognitive functions necessary to successfully play the game, such as decision-making and reward-based learning. Our analyses of brain activation of all participants showed a similar pattern of brain areas to be active during the game. However, when looking at the patient and control group separately, controls, but not patients showed significant activation in several temporal regions during decision-making whether to cooperate or not. Interestingly, those regions have been implicated in both Theory-of-Mind and facial processing tasks (e.g. [ ]) and thus further substantiate our behavioural results of higher mentalizing and face memory abilities in the control group. During the perception of the results during the game, the cingulate gyrus, a region thought to be active in situations of cognitive conflict [ ], was significantly activated in controls, but not in patients. When opponents in an economic game do not reciprocate benevolent behaviour, this is perceived as a conflict between economic self-interest (i.e. rationality) and fairness considerations [ ]. Hypothetically, patients might have not perceived cognitive conflicts to the same extent as controls in such game results, which might also have led to higher cooperative behaviour. 

When comparing our functional imaging results between the patient and control groups on both whole-brain and ROI level, it becomes apparent that the activation of the medial prefrontal cortex (MPFC) differed significantly between the two groups during the game. The MPFC plays a pivotal role in social behaviour and decision-making [ , ], which is reflected in our results of correlating MPFC activation changes and face trustworthiness evaluations, although those have been based upon a low number of data points only. Therefore, a difference in MPFC activation between two groups showing such divergent cooperative behaviour seems plausible. Our fMRI findings do not allow us to infer the directionality of the observed difference in activation, potentially because of either the difference being based on both conditions rather than differences in activation during the individual conditions, the   t  -test comparisons between groups being underpowered, and/or the difference in activation between the groups not being sufficiently strong to pass the set threshold in the   t  -test analyses. Although a pathology-driven lower activation might seem more plausible, a compensatory higher activation is also possible [ ]. Further imaging studies are needed to address this question. 

Another goal of our study was to investigate possible links between cooperative behaviour and therapy adherence in FLE. Our results show that cooperative behaviour in the PDG correlated negatively with therapy adherence in patients (high cooperative behaviour correlating with low therapy adherence). Even though we could not find any previous literature on the relationship between cooperative behaviour and therapy adherence, there is some evidence that decision-making, in general, has effects on therapy adherence with lower decision-making skills leading to lower adherence [ ]. As we have outlined before, higher cooperation can be interpreted as lower social decision-making abilities in the context of our experiment. Thus, the inverse relation between therapy adherence and cooperative behaviour actually fits into the current scientific framework on the interaction of behaviour, decision-making and therapy adherence. Importantly, there was no correlation between questionnaire data about therapy adherence and pill counts in our study, reflecting the known difficulties in measuring adherence in epilepsy (e.g. [ ]). Moreover, the MPFC activation during the game showed a correlation with therapy adherence reflecting the close link between social cognition and therapy adherence. 

We acknowledge that our study design of comparing people with FLE to healthy controls does not allow distinguishing whether the study findings apply solely to FLE or to epilepsy in general. Looking at the published literature on other epilepsy syndromes with frontal lobe dysfunction, such as juvenile myoclonic epilepsy or genetic generalized epilepsies, it becomes apparent that patients with these types of epilepsies also show abnormalities in social functions such as Theory-of-Mind [ , ]. In our view, neuroeconomic methodology could help us to determine the behavioural consequences of these social cognitive impairments. Further studies comparing cooperative behaviour and therapy adherence between FLE and other epileptic disorders are therefore warranted. 


## Conclusion 
  
To conclude, our results implicate that (i) social behaviour is affected by FLE and (ii) can be measured using neuroeconomic methods. Impaired social behaviour in FLE might (iii) be a consequence of differing MPFC activation and (iv) might play a role in low therapy adherence. This is important as therapy adherence is difficult to measure, especially in patients with epilepsy where classical tools of measurement (e.g. questionnaires or electronic devices) have been shown to be imprecise [ ]. Integrating neuroeconomic testing of social behaviour into the neuropsychological testing routine could help to better understand therapy adherence of patients with epilepsies and consequently help to improve patient care through an identification of patients at risk. 


## Supplementary Material</pre></details></details>
  <details class="inner-accordion"><summary>Coordinate-relevant source tables (3)</summary><details class="inner-accordion"><summary>Table 3. (RSOS180850TB3) - Summary of analysis of all participants. FWE, p = 0.001.</summary><div class="table-html"><table-wrap id="RSOS180850TB3" orientation="portrait" position="float"><label>Table 3.</label><caption><p>Summary of analysis of all participants. FWE, <italic toggle="yes">p</italic> = 0.001.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /></colgroup><thead valign="bottom"><tr><th align="left" rowspan="1" colspan="1">hemisphere</th><th align="left" rowspan="1" colspan="1">lobe</th><th align="left" rowspan="1" colspan="1">cluster covering</th><th align="left" rowspan="1" colspan="1">Brodmann area</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">p</italic>-value</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">K</italic> size</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">T</italic> score</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th></tr></thead><tbody><tr><td colspan="10" rowspan="1"><italic toggle="yes">decision-making</italic></td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">parietal</td><td rowspan="1" colspan="1">inferior parietal lobule</td><td rowspan="1" colspan="1">BA 40</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">1720</td><td rowspan="1" colspan="1">13.10</td><td rowspan="1" colspan="1">48</td><td rowspan="1" colspan="1">−38</td><td rowspan="1" colspan="1">46</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">parietal</td><td rowspan="1" colspan="1">precuneus</td><td rowspan="1" colspan="1">BA 7</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">1748</td><td rowspan="1" colspan="1">12.95</td><td rowspan="1" colspan="1">−20</td><td rowspan="1" colspan="1">−66</td><td rowspan="1" colspan="1">52</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">occipital</td><td rowspan="1" colspan="1">lingual gyrus</td><td rowspan="1" colspan="1">BA 18</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">817</td><td rowspan="1" colspan="1">10.63</td><td rowspan="1" colspan="1">−4</td><td rowspan="1" colspan="1">−82</td><td rowspan="1" colspan="1">−6</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">middle frontal gyrus</td><td rowspan="1" colspan="1">BA 6</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">194</td><td rowspan="1" colspan="1">10.58</td><td rowspan="1" colspan="1">−28</td><td rowspan="1" colspan="1">8</td><td rowspan="1" colspan="1">52</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">insula</td><td rowspan="1" colspan="1">insula</td><td rowspan="1" colspan="1">BA 13</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">130</td><td rowspan="1" colspan="1">10.55</td><td rowspan="1" colspan="1">−30</td><td rowspan="1" colspan="1">22</td><td rowspan="1" colspan="1">0</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">middle frontal gyrus</td><td rowspan="1" colspan="1">BA 9</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">733</td><td rowspan="1" colspan="1">10.43</td><td rowspan="1" colspan="1">46</td><td rowspan="1" colspan="1">34</td><td rowspan="1" colspan="1">30</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">cerebellum anterior lobe</td><td rowspan="1" colspan="1">culmen</td><td rowspan="1" colspan="1">—</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">368</td><td rowspan="1" colspan="1">10.32</td><td rowspan="1" colspan="1">26</td><td rowspan="1" colspan="1">−48</td><td rowspan="1" colspan="1">−14</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">inferior frontal gyrus</td><td rowspan="1" colspan="1">BA 47</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">300</td><td rowspan="1" colspan="1">10.27</td><td rowspan="1" colspan="1">42</td><td rowspan="1" colspan="1">20</td><td rowspan="1" colspan="1">−2</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">inferior frontal gyrus</td><td rowspan="1" colspan="1">BA 6</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">105</td><td rowspan="1" colspan="1">9.90</td><td rowspan="1" colspan="1">28</td><td rowspan="1" colspan="1">16</td><td rowspan="1" colspan="1">56</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">superior frontal gyrus</td><td rowspan="1" colspan="1">BA 6</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">166</td><td rowspan="1" colspan="1">9.62</td><td rowspan="1" colspan="1">−6</td><td rowspan="1" colspan="1">12</td><td rowspan="1" colspan="1">52</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">temporal</td><td rowspan="1" colspan="1">middle temporal gyrus</td><td rowspan="1" colspan="1">BA 37</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">40</td><td rowspan="1" colspan="1">9.36</td><td rowspan="1" colspan="1">56</td><td rowspan="1" colspan="1">−52</td><td rowspan="1" colspan="1">−12</td></tr><tr><td colspan="10" rowspan="1"><italic toggle="yes">results</italic></td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">parietal</td><td rowspan="1" colspan="1">inferior parietal lobule</td><td rowspan="1" colspan="1">BA 40</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">343</td><td rowspan="1" colspan="1">10.57</td><td rowspan="1" colspan="1">52</td><td rowspan="1" colspan="1">−50</td><td rowspan="1" colspan="1">46</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">temporal</td><td rowspan="1" colspan="1">middle temporal gyrus</td><td rowspan="1" colspan="1">BA 21</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">74</td><td rowspan="1" colspan="1">8.72</td><td rowspan="1" colspan="1">58</td><td rowspan="1" colspan="1">−34</td><td rowspan="1" colspan="1">−8</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">parietal</td><td rowspan="1" colspan="1">inferior parietal lobule</td><td rowspan="1" colspan="1">BA 40</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">36</td><td rowspan="1" colspan="1">8.14</td><td rowspan="1" colspan="1">−58</td><td rowspan="1" colspan="1">−42</td><td rowspan="1" colspan="1">40</td></tr></tbody></table></table-wrap>
</div></details><details class="inner-accordion"><summary>Table 4. (RSOS180850TB4) - Summary of per group analyses. FWE, p = 0.001.</summary><div class="table-html"><table-wrap id="RSOS180850TB4" orientation="portrait" position="float"><label>Table 4.</label><caption><p>Summary of per group analyses. FWE, <italic toggle="yes">p</italic> = 0.001.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /></colgroup><thead valign="bottom"><tr><th align="left" rowspan="1" colspan="1">hemisphere</th><th align="left" rowspan="1" colspan="1">lobe</th><th align="left" rowspan="1" colspan="1">cluster covering</th><th align="left" rowspan="1" colspan="1">Brodmann area</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">p</italic>-value</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">K</italic> size</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">T</italic> score</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th></tr></thead><tbody><tr><td colspan="10" rowspan="1">PATIENTS</td></tr><tr><td colspan="10" rowspan="1"><italic toggle="yes">decision-making</italic></td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">occipital</td><td rowspan="1" colspan="1">lingual gyrus</td><td rowspan="1" colspan="1">BA 18</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">11 406</td><td rowspan="1" colspan="1">10.64</td><td rowspan="1" colspan="1">24</td><td rowspan="1" colspan="1">−74</td><td rowspan="1" colspan="1">−10</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">superior frontal gyrus</td><td rowspan="1" colspan="1">BA 6</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">8491</td><td rowspan="1" colspan="1">10.28</td><td rowspan="1" colspan="1">−16</td><td rowspan="1" colspan="1">0</td><td rowspan="1" colspan="1">64</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">subcortical insula</td><td rowspan="1" colspan="1">claustrum insula</td><td rowspan="1" colspan="1">—</td><td rowspan="1" colspan="1">0.006</td><td rowspan="1" colspan="1">456</td><td rowspan="1" colspan="1">7.63</td><td rowspan="1" colspan="1">−28</td><td rowspan="1" colspan="1">22</td><td rowspan="1" colspan="1">−2</td></tr><tr><td colspan="10" rowspan="1"><italic toggle="yes">results</italic></td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">parietal</td><td rowspan="1" colspan="1">inferior parietal lobule</td><td rowspan="1" colspan="1">BA 40</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">4211</td><td rowspan="1" colspan="1">12.48</td><td rowspan="1" colspan="1">−60</td><td rowspan="1" colspan="1">−42</td><td rowspan="1" colspan="1">38</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">parietal</td><td rowspan="1" colspan="1">inferior parietal lobule</td><td rowspan="1" colspan="1">BA 40</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">5094</td><td rowspan="1" colspan="1">11.53</td><td rowspan="1" colspan="1">58</td><td rowspan="1" colspan="1">−44</td><td rowspan="1" colspan="1">44</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">middle frontal gyrus</td><td rowspan="1" colspan="1">BA 46</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">2994</td><td rowspan="1" colspan="1">10.12</td><td rowspan="1" colspan="1">42</td><td rowspan="1" colspan="1">48</td><td rowspan="1" colspan="1">14</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">cerebellum</td><td rowspan="1" colspan="1">anterior lobe</td><td rowspan="1" colspan="1">—</td><td rowspan="1" colspan="1">0.003</td><td rowspan="1" colspan="1">439</td><td rowspan="1" colspan="1">6.91</td><td rowspan="1" colspan="1">−2</td><td rowspan="1" colspan="1">−54</td><td rowspan="1" colspan="1">−4</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">parietal</td><td rowspan="1" colspan="1">precuneus</td><td rowspan="1" colspan="1">BA 7</td><td rowspan="1" colspan="1">0.016</td><td rowspan="1" colspan="1">304</td><td rowspan="1" colspan="1">6.35</td><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">−78</td><td rowspan="1" colspan="1">46</td></tr><tr><td colspan="10" rowspan="1">CONTROLS</td></tr><tr><td colspan="10" rowspan="1"><italic toggle="yes">decision-making</italic></td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">temporal occipital</td><td rowspan="1" colspan="1">fusiform gyrus</td><td rowspan="1" colspan="1">BA 37</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">17309</td><td rowspan="1" colspan="1">13.94</td><td rowspan="1" colspan="1">54</td><td rowspan="1" colspan="1">−54</td><td rowspan="1" colspan="1">−16</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">superior frontal gyrus</td><td rowspan="1" colspan="1">BA 9</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">9140</td><td rowspan="1" colspan="1">11.15</td><td rowspan="1" colspan="1">42</td><td rowspan="1" colspan="1">36</td><td rowspan="1" colspan="1">28</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">insula</td><td rowspan="1" colspan="1">insula</td><td rowspan="1" colspan="1">BA 13</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">756</td><td rowspan="1" colspan="1">8.1</td><td rowspan="1" colspan="1">−34</td><td rowspan="1" colspan="1">18</td><td rowspan="1" colspan="1">8</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">temporal</td><td rowspan="1" colspan="1">superior temporal gyrus</td><td rowspan="1" colspan="1">BA 22</td><td rowspan="1" colspan="1">0.020</td><td rowspan="1" colspan="1">238</td><td rowspan="1" colspan="1">7.69</td><td rowspan="1" colspan="1">−50</td><td rowspan="1" colspan="1">−48</td><td rowspan="1" colspan="1">14</td></tr><tr><td colspan="10" rowspan="1"><italic toggle="yes">results</italic></td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">middle frontal gyrus</td><td rowspan="1" colspan="1">BA 10</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">67860</td><td rowspan="1" colspan="1">9.12</td><td rowspan="1" colspan="1">−34</td><td rowspan="1" colspan="1">48</td><td rowspan="1" colspan="1">−2</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">parietal</td><td rowspan="1" colspan="1">inferior parietal lobule</td><td rowspan="1" colspan="1">BA 40</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">3234</td><td rowspan="1" colspan="1">7.88</td><td rowspan="1" colspan="1">−46</td><td rowspan="1" colspan="1">−46</td><td rowspan="1" colspan="1">56</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">parietal</td><td rowspan="1" colspan="1">inferior parietal lobule</td><td rowspan="1" colspan="1">BA 40</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">1086</td><td rowspan="1" colspan="1">7.11</td><td rowspan="1" colspan="1">52</td><td rowspan="1" colspan="1">−50</td><td rowspan="1" colspan="1">46</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">temporal</td><td rowspan="1" colspan="1">inferior temporal gyrus</td><td rowspan="1" colspan="1">BA 20</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">596</td><td rowspan="1" colspan="1">7.08</td><td rowspan="1" colspan="1">58</td><td rowspan="1" colspan="1">−40</td><td rowspan="1" colspan="1">16</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">cingulate gyrus</td><td rowspan="1" colspan="1">BA 24</td><td rowspan="1" colspan="1">0.046</td><td rowspan="1" colspan="1">219</td><td rowspan="1" colspan="1">5.41</td><td rowspan="1" colspan="1">−2</td><td rowspan="1" colspan="1">−14</td><td rowspan="1" colspan="1">38</td></tr></tbody></table></table-wrap>
</div></details><details class="inner-accordion"><summary>Table 5. (RSOS180850TB5) - Analysis of group differences and ROI.</summary><div class="table-html"><table-wrap id="RSOS180850TB5" orientation="portrait" position="float"><label>Table 5.</label><caption><p>Analysis of group differences and ROI.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /></colgroup><thead valign="bottom"><tr><th align="left" rowspan="1" colspan="1">hemisphere</th><th align="left" rowspan="1" colspan="1">lobe</th><th align="left" rowspan="1" colspan="1">cluster covering</th><th align="left" rowspan="1" colspan="1">Brodmann area</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">p</italic>-value</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">K</italic> size</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">F</italic> score</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th></tr></thead><tbody><tr><td colspan="10" rowspan="1"><italic toggle="yes">main effect of group</italic></td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">medial frontal gyrus</td><td rowspan="1" colspan="1">BA 10</td><td rowspan="1" colspan="1">0.034</td><td rowspan="1" colspan="1">214</td><td rowspan="1" colspan="1">22.35</td><td rowspan="1" colspan="1">8</td><td rowspan="1" colspan="1">62</td><td rowspan="1" colspan="1">14</td></tr><tr><td colspan="10" rowspan="1"><italic toggle="yes">main effect of condition</italic></td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">cerebellum</td><td rowspan="1" colspan="1">anterior lobe</td><td rowspan="1" colspan="1">—</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">11343</td><td rowspan="1" colspan="1">108.49</td><td rowspan="1" colspan="1">26</td><td rowspan="1" colspan="1">−50</td><td rowspan="1" colspan="1">−12</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">precentral gyrus</td><td rowspan="1" colspan="1">BA 9</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">1439</td><td rowspan="1" colspan="1">81.83</td><td rowspan="1" colspan="1">−36</td><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">34</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">inferior frontal gyrus</td><td rowspan="1" colspan="1">BA 9</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">1770</td><td rowspan="1" colspan="1">64.81</td><td rowspan="1" colspan="1">42</td><td rowspan="1" colspan="1">10</td><td rowspan="1" colspan="1">26</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">insula</td><td rowspan="1" colspan="1">insula</td><td rowspan="1" colspan="1">BA 13</td><td rowspan="1" colspan="1">0.002</td><td rowspan="1" colspan="1">414</td><td rowspan="1" colspan="1">56.86</td><td rowspan="1" colspan="1">32</td><td rowspan="1" colspan="1">22</td><td rowspan="1" colspan="1">−2</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">temporal</td><td rowspan="1" colspan="1">middle temporal gyrus</td><td rowspan="1" colspan="1">BA 21</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">6458</td><td rowspan="1" colspan="1">52.55</td><td rowspan="1" colspan="1">−56</td><td rowspan="1" colspan="1">−22</td><td rowspan="1" colspan="1">−14</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">insula</td><td rowspan="1" colspan="1">insula</td><td rowspan="1" colspan="1">BA 13</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">4254</td><td rowspan="1" colspan="1">50.94</td><td rowspan="1" colspan="1">42</td><td rowspan="1" colspan="1">−12</td><td rowspan="1" colspan="1">6</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">cingulate gyrus</td><td rowspan="1" colspan="1">BA 24</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">1827</td><td rowspan="1" colspan="1">40.86</td><td rowspan="1" colspan="1">−4</td><td rowspan="1" colspan="1">−14</td><td rowspan="1" colspan="1">40</td></tr><tr><td colspan="10" rowspan="1"><italic toggle="yes">ROI-main effect of group</italic></td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">superior frontal gyrus</td><td rowspan="1" colspan="1">BA 10</td><td rowspan="1" colspan="1">0.007</td><td rowspan="1" colspan="1">219</td><td rowspan="1" colspan="1">31.57</td><td rowspan="1" colspan="1">14</td><td rowspan="1" colspan="1">60</td><td rowspan="1" colspan="1">14</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">middle frontal gyrus</td><td rowspan="1" colspan="1">BA 10</td><td rowspan="1" colspan="1">0.046</td><td rowspan="1" colspan="1">124</td><td rowspan="1" colspan="1">19.57</td><td rowspan="1" colspan="1">−32</td><td rowspan="1" colspan="1">54</td><td rowspan="1" colspan="1">8</td></tr></tbody></table></table-wrap></div></details></details>
</details>


<details class="doc-card">
  <summary><strong>PMID 17964185</strong> | Pred included: 1 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=1, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/17964185/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>17964185_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The task is a social interaction simulation using personalized peer (friend) and celebrity face stimuli and approach/avoid decisions; the reported contrasts (peers vs celebrities, friends vs others) directly assess social processing (empathy, reward, person knowledge). This meets both criteria: it is a social task and the analysis measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>17964185_1</td><td>(peer vs. celebrity) x (positive vs. non-positive); socialcommunication</td><td>17964185_analysis_0</td><td>analysis_0</td><td>0.167</td><td>0.903</td><td>0.682</td><td>uncertain</td><td>high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18603608</strong> | Pred included: 2 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18603608/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> compositions &gt; computer-generated pieces; others</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18603608_analysis_0</td><td>Predicted</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>The contrast (pieces cued as composed vs computer-generated) manipulates subjects&#x27; social attitude toward the stimulus and measures mentalizing/theory-of-mind processing. fMRI results show activation in aMFC, STS and temporal poles—canonical social cognition/mentalizing regions—so this contrast clearly measures social processing.</td></tr>
<tr><td>18603608_analysis_1</td><td>Not predicted</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Same experimental manipulation: belief that music is composed vs computer-generated drives mentalizing. The contrast assesses social processing and recruits canonical ToM regions (aMFC, STS, temporal poles).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18603608_1</td><td>compositions &gt; computer-generated pieces; others</td><td>18603608_analysis_0</td><td>Predicted</td><td>0.163</td><td>0.667</td><td>0.516</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 21206532</strong> | Pred included: 1 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=4</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/21206532/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> faces &gt; watches; socialcommunication, objects &gt; faces; socialcommunication, objects &gt; watches; socialcommunication, watches &gt; faces; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>21206532_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>The analysis includes face perception and identity discrimination tasks (individuation of faces), which are central social processing functions (recognizing and responding to social agents). The contrasts and ROI analyses directly assess neural responses to social stimuli (faces) versus non-face objects, meeting the broad social processing definition.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>21206532_1</td><td>faces &gt; watches; socialcommunication</td><td>21206532_analysis_0</td><td>analysis_0</td><td>0.240</td><td>0.000</td><td>0.072</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>21206532_2</td><td>objects &gt; faces; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>21206532_3</td><td>objects &gt; watches; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>21206532_4</td><td>watches &gt; faces; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24582805</strong> | Pred included: 7 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=9</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24582805/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> DA &gt; CA; self, DP &gt; CP; self, DS &gt; CS; self, OA &gt; CA; others, OP &gt; CP; others, OS &gt; CS; others, RA &gt; CA; self, RP &gt; CP; self, RS &gt; CS; self</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24582805_analysis_0</td><td>Main effect of age group</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>The main effect of age group is from an ANOVA of a social evaluation task (direct self, direct other, reflected self about best friend, and malleability). The task is intrinsically social, so this analysis measures social processing across groups.</td></tr>
<tr><td>24582805_analysis_1</td><td>Main effect of evaluative perspective</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>This analysis tests the main effect of evaluative perspective (direct self/other, reflected self, malleability) in a social-evaluative paradigm, directly indexing social processing.</td></tr>
<tr><td>24582805_analysis_2</td><td>Age group × evaluative perspective</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>The age group × evaluative perspective interaction examines developmental differences in social-evaluative processing (self/other/reflected), which is squarely within social processing.</td></tr>
<tr><td>24582805_analysis_3</td><td>Main effect of domain</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>The main effect of domain (academic/physical/social) is part of the social-evaluative paradigm and indexes domain-specific social processing (especially the social domain).</td></tr>
<tr><td>24582805_analysis_4</td><td>Age group × domain</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>The age group × domain interaction examines developmental differences in domain-specific social-evaluative processing (academic/physical/social), so it is social processing relevant.</td></tr>
<tr><td>24582805_analysis_5</td><td>Evaluative perspective × domain</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>The evaluative perspective × domain interaction directly tests how social-evaluative perspective (self/other/reflected) varies across domains (including social), making it clearly social processing.</td></tr>
<tr><td>24582805_analysis_6</td><td>Age group × evaluative perspective × domain</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>The three-way interaction (age × evaluative perspective × domain) pinpoints developmental differences in social-evaluative processing, especially reflected social self-evaluations, and is clearly within social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24582805_1</td><td>DA &gt; CA; self</td><td>24582805_analysis_0</td><td>Main effect of age group</td><td>0.270</td><td>0.000</td><td>0.081</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>24582805_2</td><td>DP &gt; CP; self</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>24582805_3</td><td>DS &gt; CS; self</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>24582805_4</td><td>OA &gt; CA; others</td><td>24582805_analysis_5</td><td>Evaluative perspective × domain</td><td>0.217</td><td>0.115</td><td>0.146</td><td>unmatched</td><td>low_total_score</td></tr><tr><td>24582805_5</td><td>OP &gt; CP; others</td><td>24582805_analysis_2</td><td>Age group × evaluative perspective</td><td>0.327</td><td>0.000</td><td>0.098</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>24582805_6</td><td>OS &gt; CS; others</td><td>24582805_analysis_6</td><td>Age group × evaluative perspective × domain</td><td>0.241</td><td>0.000</td><td>0.072</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>24582805_7</td><td>RA &gt; CA; self</td><td>24582805_analysis_3</td><td>Main effect of domain</td><td>0.286</td><td>0.040</td><td>0.114</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>24582805_8</td><td>RP &gt; CP; self</td><td>24582805_analysis_4</td><td>Age group × domain</td><td>0.320</td><td>0.000</td><td>0.096</td><td>unmatched</td><td>low_total_score, missing_coords_on_one_side</td></tr><tr><td>24582805_9</td><td>RS &gt; CS; self</td><td>24582805_analysis_1</td><td>Main effect of evaluative perspective</td><td>0.160</td><td>0.152</td><td>0.154</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25534111</strong> | Pred included: 4 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=2, unmatched=2</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25534111/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> (IJA − IJAc) − (RJA − RJAc); socialcommunication, IJA &gt; IJAc; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25534111_analysis_0</td><td>Responding to joint attention (RJA - RJAc)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The RJA vs RJAc contrast isolates social joint attention (responding to another&#x27;s gaze) using a social interactive task; it directly measures social processing. Matches I1 (social task) and I2 (measures social processing).</td></tr>
<tr><td>25534111_analysis_1</td><td>Initiating joint attention (IJA - IJAc)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>The IJA vs IJAc contrast isolates initiating joint attention in an interactive social task (guiding another&#x27;s attention), directly measuring social processing. Matches I1 and I2.</td></tr>
<tr><td>25534111_analysis_2</td><td>Conjunction of initiating and responding to joint attention (IJA - IJAc) with (RJA - RJAc)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The conjunction identifies regions common to both initiating and responding joint attention in an interactive social paradigm—clearly measures social processing. Matches I1 and I2.</td></tr>
<tr><td>25534111_analysis_3</td><td>Initiating Joint attention minus responding to joint attention (IJA - IJAc) - (RJA - RJAc)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>The IJA&gt;RJA contrast (after controlling for non-social controls) isolates social-role-dependent increases in joint attention processing (initiating&gt;responding), so it measures social processing. Matches I1 and I2.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25534111_1</td><td>(IJA - IJAc) with (RJA - RJAc); socialcommunication</td><td>25534111_analysis_2</td><td>Conjunction of initiating and responding to joint attention (IJA - IJAc) with (RJA - RJAc)</td><td>0.500</td><td>0.571</td><td>0.550</td><td>uncertain</td><td>low_total_score</td></tr><tr><td>25534111_2</td><td>(IJA − IJAc) − (RJA − RJAc); socialcommunication</td><td>25534111_analysis_3</td><td>Initiating Joint attention minus responding to joint attention (IJA - IJAc) - (RJA - RJAc)</td><td>0.410</td><td>0.435</td><td>0.427</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>25534111_3</td><td>IJA &gt; IJAc; socialcommunication</td><td>25534111_analysis_1</td><td>Initiating joint attention (IJA - IJAc)</td><td>0.367</td><td>0.567</td><td>0.507</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>25534111_4</td><td>RJA &gt; RJAc; socialcommunication</td><td>25534111_analysis_0</td><td>Responding to joint attention (RJA - RJAc)</td><td>0.346</td><td>0.733</td><td>0.617</td><td>uncertain</td><td>coord_count_mismatch</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25911123</strong> | Pred included: 2 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=4</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25911123/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Decreasing LOA &gt;  Increasing LOA; others, High-why + High-how &gt; Low-Why + Low-How; others, Increasing LOA &gt; Decreasing LOA; others, Low-Why + Low-How &gt; High-why + High-how; others</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25911123_analysis_0</td><td>Response to &lt;i&gt;why&lt;/i&gt; &gt; &lt;i&gt;how&lt;/i&gt; questions for all stimulus categories</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>The why&gt;how contrast across all stimulus categories includes social stimuli (emotional expressions and intentional actions) and targets attributional processing about others’ mental states; thus it measures social processing. ROI and whole-brain conjunction results explicitly report social-attribution activations (DMPFC, TPJ, aSTS, LOFC).</td></tr>
<tr><td>25911123_analysis_1</td><td>Stronger response to &lt;i&gt;why&lt;/i&gt; &gt; &lt;i&gt;how&lt;/i&gt; questions for social than for nonsocial stimuli</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>This contrast tests stronger why&gt;how responses for social versus nonsocial stimuli, directly indexing social-attribution processing and selective recruitment for social domain (DMPFC social-selective effects).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25911123_1</td><td>Decreasing LOA &gt;  Increasing LOA; others</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>25911123_2</td><td>High-why + High-how &gt; Low-Why + Low-How; others</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>25911123_3</td><td>Increasing LOA &gt; Decreasing LOA; others</td><td>25911123_analysis_1</td><td>Stronger response to &lt;i&gt;why&lt;/i&gt; &gt; &lt;i&gt;how&lt;/i&gt; questions for social than for nonsocial stimuli</td><td>0.234</td><td>0.041</td><td>0.099</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>25911123_4</td><td>Low-Why + Low-How &gt; High-why + High-how; others</td><td>25911123_analysis_0</td><td>Response to &lt;i&gt;why&lt;/i&gt; &gt; &lt;i&gt;how&lt;/i&gt; questions for all stimulus categories</td><td>0.286</td><td>0.000</td><td>0.086</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26143208</strong> | Pred included: 2 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=8</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26143208/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> FAC-Angry &gt; Control; socialcommunication, FAC-Angry &gt; FAC-Happy; socialcommunication, FAC-Happy &gt; Control; socialcommunication, [constant ISI &gt; variable ISI] - FAC-Angry; socialcommunication, [constant ISI &gt; variable ISI] - FAC-happy; socialcommunication, [constant ISI &gt; variable ISI] - control task; socialcommunication, [variable ISI &gt; constant ISI] - FAC-angry; socialcommunication, [variable ISI &gt; constant ISI] - control task; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26143208_analysis_0</td><td>Interaction: FAC-Angry × Control</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>The analysis contrasts emotional face tasks (gender identification of angry and happy faces) with a neutral control (shapes). This involves processing of social stimuli (faces) and emotion-related social information, satisfying the Social Processing inclusion criterion (I1).</td></tr>
<tr><td>26143208_analysis_1</td><td>Interaction: FAC-Happy × Control</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>This analysis contrasts gender identification of emotional faces (happy) with neutral shapes, involving social-emotional face processing. It therefore meets the Social Processing inclusion criterion (I1).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26143208_1</td><td>FAC-Angry &gt; Control; socialcommunication</td><td>26143208_analysis_0</td><td>Interaction: FAC-Angry × Control</td><td>0.706</td><td>0.000</td><td>0.212</td><td>unmatched</td><td>coord_count_mismatch, low_total_score, name_only_signal</td></tr><tr><td>26143208_2</td><td>FAC-Angry &gt; FAC-Happy; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>26143208_3</td><td>FAC-Happy &gt; Control; socialcommunication</td><td>26143208_analysis_1</td><td>Interaction: FAC-Happy × Control</td><td>0.706</td><td>0.064</td><td>0.257</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>26143208_4</td><td>[constant ISI &gt; variable ISI] - FAC-Angry; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>26143208_5</td><td>[constant ISI &gt; variable ISI] - FAC-happy; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>26143208_6</td><td>[constant ISI &gt; variable ISI] - control task; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>26143208_7</td><td>[variable ISI &gt; constant ISI] - FAC-angry; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>26143208_8</td><td>[variable ISI &gt; constant ISI] - control task; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29265483</strong> | Pred included: 4 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=3</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29265483/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Affective &gt; Cooperative social interactions, Cooperative &amp; Affective social interactions (Conjunction analysis), Cooperative &gt; Affective social interactions</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29265483_analysis_0</td><td>1a. Observation of social interactions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Analysis 1a (&#x27;Observation of social interactions&#x27;) explicitly involves observing social interactions and measures neural processing of social scenes; it directly assesses social processing across multiple social constructs.</td></tr>
<tr><td>29265483_analysis_1</td><td>1b. Cooperativity&gt;affectivity</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Analysis 1b (Cooperativity &gt; Affectivity) contrasts social interaction types and therefore measures social processing specific to cooperative interactions.</td></tr>
<tr><td>29265483_analysis_2</td><td>1c. Affectivity&gt;cooperativity</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Analysis 1c (Affectivity &gt; Cooperativity) isolates affective social interactions and measures neural responses to social-affective cues, thus indexing social processing.</td></tr>
<tr><td>29265483_analysis_3</td><td>analysis_3</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Analysis 3 (unnamed) is part of the same study&#x27;s set of analyses (DCM/network analyses) investigating processing of social interactions and their modulatory dimensions, thus indexing social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29265483_1</td><td>Affective &gt; Cooperative social interactions</td><td>29265483_analysis_2</td><td>1c. Affectivity&gt;cooperativity</td><td>0.622</td><td>0.222</td><td>0.342</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>29265483_2</td><td>Cooperative &amp; Affective social interactions (Conjunction analysis)</td><td>29265483_analysis_0</td><td>1a. Observation of social interactions</td><td>0.538</td><td>0.351</td><td>0.407</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>29265483_3</td><td>Cooperative &gt; Affective social interactions</td><td>29265483_analysis_1</td><td>1b. Cooperativity&gt;affectivity</td><td>0.622</td><td>0.122</td><td>0.272</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29723244</strong> | Pred included: 1 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29723244/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Social vs Non-Social; others</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29723244_analysis_0</td><td>Social&quot; brain regions identified in the NeuroSynth meta-analysis.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>The analysis explicitly targets social processing: a NeuroSynth meta-analysis of studies containing the term &#x27;social&#x27; and an independent fMRI contrast comparing social versus non-social images. The contrast (social &gt; non-social) directly measures social processing. Thus both inclusion criteria (task is social-related and the contrast measures social processing) are met.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29723244_1</td><td>Social vs Non-Social; others</td><td>29723244_analysis_0</td><td>Social&quot; brain regions identified in the NeuroSynth meta-analysis.</td><td>0.366</td><td>0.034</td><td>0.134</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 30056560</strong> | Pred included: 2 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/30056560/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> CON: own&gt;unknown masked with group×(own&gt;unknown); socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>30056560_analysis_0</td><td>Happy-own&gt;neutral-own</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast Happy (own) &gt; Neutral (own) is a facial emotion recognition task involving one&#x27;s own child and clearly taps broad social processing (perception and interpretation of social-emotional cues). It measures social processing across affiliation, emotion recognition, and empathic/mentalizing processes.</td></tr>
<tr><td>30056560_analysis_1</td><td>ELM: happy-own&gt;neutral-own masked with group×(happy-own&gt;neutral-own)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>This contrast isolates the ELM group-specific effect for Happy (own) &gt; Neutral (own), probing group differences in social-emotional processing of one&#x27;s child. It clearly assesses social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>30056560_1</td><td>CON: own&gt;unknown masked with group×(own&gt;unknown); socialcommunication</td><td>30056560_analysis_1</td><td>ELM: happy-own&gt;neutral-own masked with group×(happy-own&gt;neutral-own)</td><td>0.694</td><td>0.000</td><td>0.208</td><td>unmatched</td><td>coord_count_mismatch, low_total_score, name_only_signal</td></tr></tbody></table></div>
  </details>
  
  
</details>
</details></section><section id="bucket-false-negative"><details class="bucket" open><summary><h2>False Negative (1)</h2></summary><p><strong>Match status totals:</strong> accepted=2 | uncertain=0 | unmatched=0</p>
<details class="doc-card">
  <summary><strong>PMID 28931014</strong> | Pred included: 0 | Manual included (accepted matches only): 2 | Correct overlaps: 0 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/28931014/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>28931014_analysis_0</td><td>Fingerspelling &gt; Letter</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>The analysis tests phonological short-term memory and neural responses to letters vs. fingerspelling within a memory task. Although fingerspelling uses a communicative modality (sign language), the task probes memory/linguistic processing rather than social processes (affiliation, social interaction, perception of others’ emotions or intentions). It does not operationalize or measure social processing per the inclusion criterion I1.</td></tr>
<tr><td>28931014_analysis_1</td><td>Letter &gt; Fingerspelling</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>The contrast (Letter &gt; Fingerspelling) examines modality-specific neural activations related to letter perception and phonological maintenance. This is a language/memory contrast and does not measure social processing (affiliation, social interaction, or perception of self/others), so it does not meet inclusion criterion I1.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>28931014_1</td><td>Fingerspelling &gt; Letter; socialcommunication</td><td>28931014_analysis_0</td><td>Fingerspelling &gt; Letter</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>28931014_2</td><td>Letter &gt; Fingerspelling; socialcommunication</td><td>28931014_analysis_1</td><td>Letter &gt; Fingerspelling</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>
</details></section>
  
</body>
</html>
