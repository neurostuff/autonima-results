<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>social_processing_all review report</title>
  <style>
    :root {
      --bg: #f7f6f2;
      --panel: #ffffff;
      --ink: #1d2730;
      --line: #d8dde3;
    }
    body { margin: 0; padding: 1.25rem; font-family: "IBM Plex Sans", "Segoe UI", sans-serif; background: var(--bg); color: var(--ink); }
    header { background: var(--panel); border: 1px solid var(--line); border-radius: 10px; padding: 1rem; margin-bottom: 1rem; }
    .top-nav { position: sticky; top: 0; z-index: 10; display: flex; flex-wrap: wrap; gap: 0.5rem; background: #eef3f2; border: 1px solid var(--line); border-radius: 10px; padding: 0.6rem; margin-bottom: 1rem; }
    .top-nav a { display: inline-block; padding: 0.35rem 0.6rem; border: 1px solid var(--line); border-radius: 999px; background: #fff; text-decoration: none; font-size: 0.9rem; color: #0e4f85; }
    section { margin-bottom: 1rem; }
    .bucket > summary, .doc-card > summary, .inner-accordion > summary { cursor: pointer; }
    .doc-card { background: var(--panel); border: 1px solid var(--line); border-radius: 10px; padding: 0.85rem; margin-bottom: 0.85rem; }
    .table-wrap, .table-html { overflow-x: auto; }
    .inner-accordion { margin-top: 0.6rem; border-top: 1px dashed var(--line); padding-top: 0.4rem; }
    .paper-text { white-space: pre-wrap; max-height: 26rem; overflow-y: auto; background: #fbfcfe; border: 1px solid var(--line); border-radius: 8px; padding: 0.6rem; font-size: 0.88rem; line-height: 1.35; }
    table { width: 100%; border-collapse: collapse; font-size: 0.9rem; }
    th, td { border: 1px solid var(--line); padding: 0.45rem; vertical-align: top; text-align: left; }
    th { background: #edf2f5; }
    .decision-cell, .confusion-cell { text-align: center; vertical-align: middle; }
    .decision-pill, .confusion-pill {
      display: inline-flex;
      align-items: center;
      justify-content: center;
      min-width: 1.55rem;
      padding: 0.12rem 0.45rem;
      border-radius: 999px;
      font-weight: 700;
      font-size: 0.82rem;
      border: 1px solid transparent;
    }
    .decision-include { background: #e9f8ef; color: #1f7a3d; border-color: #b7e4c6; }
    .decision-exclude { background: #fdecec; color: #9b1c1c; border-color: #f6caca; }
    .decision-none { background: #f2f4f7; color: #5b6775; border-color: #dde3ea; }
    .confusion-good { background: #e9f8ef; color: #166534; border-color: #b7e4c6; }
    .confusion-bad { background: #fdecec; color: #991b1b; border-color: #f6caca; }
    .confusion-na { background: #f2f4f7; color: #5b6775; border-color: #dde3ea; }
    a { color: #0e4f85; }
  </style>
</head>
<body>
  <header>
    <a id="top"></a>
    <h1>social_processing_all report</h1>
    <p>Manual benchmark is sliced to the auto PMID universe from <code>outputs/nimads_annotation.json</code>. Analysis-level truth uses accepted fuzzy matches only.</p>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Level</th>
            <th>TP</th>
            <th>FP</th>
            <th>FN</th>
            <th>Precision</th>
            <th>Recall</th>
            <th>F1</th>
            <th>Manual Positives</th>
            <th>Predicted Positives</th>
            <th>Universe</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Document bucket overlap</td>
            <td>120</td>
            <td>11</td>
            <td>5</td>
            <td>0.916</td>
            <td>0.960</td>
            <td>0.938</td>
            <td>125</td>
            <td>131</td>
            <td>136</td>
          </tr>
          <tr>
            <td>Study inclusion</td>
            <td>132</td>
            <td>0</td>
            <td>2</td>
            <td>1.000</td>
            <td>0.985</td>
            <td>0.992</td>
            <td>134</td>
            <td>132</td>
            <td>134</td>
          </tr>
          <tr>
            <td>Analysis inclusion (accepted matches only)</td>
            <td>400</td>
            <td>210</td>
            <td>25</td>
            <td>0.656</td>
            <td>0.941</td>
            <td>0.773</td>
            <td>425</td>
            <td>610</td>
            <td>640</td>
          </tr>
        </tbody>
      </table>
    </div>
  </header>
  <nav class="top-nav">
    <a href="#bucket-correct">Correct (120)</a>
    <a href="#bucket-false-positive">False Positive (11)</a>
    <a href="#bucket-false-negative">False Negative (5)</a>
    <a href="#missing-manual">Missing PMIDs (0)</a>
    <a href="#top">Top</a>
  </nav>
  <section id="bucket-correct"><details class="bucket"><summary><h2>Correct (120)</h2></summary><p><strong>Match status totals:</strong> accepted=409 | uncertain=12 | unmatched=41</p>
<details class="doc-card">
  <summary><strong>PMID 29079809</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29079809/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29079809_analysis_0</td><td>clusters genetic &gt; non-genetic</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis contrasts brain responses when subjects view a moral dilemma believing sisters are genetic vs non-genetic. This is a social task (kinship, moral evaluation) and the ISC contrast measures social processing (mentalizing, moral/emotional conflict regulation).</td></tr>
<tr><td>29079809_analysis_1</td><td>clusters non-genetic &gt; genetic</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Movie-based moral-dilemma task manipulating perceived kinship probes social cognition broadly (mentalizing, moral evaluation), satisfying social-processing task and measurement.</td></tr>
<tr><td>29079809_analysis_2</td><td>moral dilemma decision task</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The moral dilemma decision task and the related ISC/movie-watching analysis are explicit social tasks (kinship, moral decisions about sister/friend/strangers) and probe social cognition across subjects; thus they meet both inclusion criteria.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29079809_1</td><td>clusters genetic&gt;non-genetic; self</td><td>29079809_analysis_0</td><td>clusters genetic &gt; non-genetic</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29079809_2</td><td>clusters non-genetic&gt;genetic; self</td><td>29079809_analysis_1</td><td>clusters non-genetic &gt; genetic</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29079809_3</td><td>moral dilemma decision task; self</td><td>29079809_analysis_2</td><td>moral dilemma decision task</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  <details class="inner-accordion"><summary>PMC full text available (PMCID 5660240)</summary><p><strong>Title:</strong> Differential inter-subject correlation of brain activity when kinship is a variable in moral dilemma</p><details><summary>Abstract</summary><pre class="paper-text">Previous behavioural studies have shown that humans act more altruistically towards kin. Whether and how knowledge of genetic relatedness translates into differential neurocognitive evaluation of observed social interactions has remained an open question. Here, we investigated how the human brain is engaged when viewing a moral dilemma between genetic vs. non-genetic sisters. During functional magnetic resonance imaging, a movie was shown, depicting refusal of organ donation between two sisters, with subjects guided to believe the sisters were related either genetically or by adoption. Although 90% of the subjects self-reported that genetic relationship was not relevant, their brain activity told a different story. Comparing correlations of brain activity across all subject pairs between the two viewing conditions, we found significantly stronger inter-subject correlations in insula, cingulate, medial and lateral prefrontal, superior temporal, and superior parietal cortices, when the subjects believed that the sisters were genetically related. Cognitive functions previously associated with these areas include moral and emotional conflict regulation, decision making, and mentalizing, suggesting more similar engagement of such functions when observing refusal of altruism from a genetic sister. Our results show that mere knowledge of a genetic relationship between interacting persons robustly modulates social cognition of the perceiver.</pre></details><details><summary>Body</summary><pre class="paper-text">## Introduction 
  
Evaluating and predicting social interactions of others is an integral part of social cognition, one of the most fundamental of human cognitive functions. Indeed, the evolution of social cognition may best explain why humans have a more developed neocortex than other species . So far, social cognition has been predominantly studied with stimuli depicting interactions between strangers, however, most of the significant interactions evaluated in daily life are between one’s family members, friends, and acquaintances 

More importantly, most of our social interactions (and social effort) is directed to a very small number of familiar individuals, 60% of our social effort is directed to just 15 close friends and family . There is also considerable experimental and observational evidence for a “kinship premium” in our interactions with others, especially when those interactions involve altruistic behaviour . We are more likely to help our genetic relatives compared to unrelated individuals, and to do so implicitly, without conscious elaboration . In a trolley dilemma , subjects have to decide if they would push a handle to set a trolley to another track so that instead of killing five people when left without intervention, it will kill a single person on an alternative track. If only strangers are considered, the study subjects favoured the survival of the five over one life; however, their judgement changed if the single person was genetically related to the subject. 

On the other hand it has been shown, that subjects judged incest to be equally morally wrong for a sibling, irrespective of whether this was a genetic, adoptive or step sibling . In these studies, rather co-residence with the sibling in the family, irrespective of genetic status, was the most relevant factor in decisions about the moral reprehensibility of incest. 

These and many other studies, have shown differences in multiple aspects of moral perception/processing, evaluation, judgement and decision making at the behavioural level when processing information about kin vs. non-kin. However, much less is known about the neuronal underpinnings of these effects. Recently, Wlodarski and Dunbar  have shown that different brain regions are active when subjects judge moral dilemmas about kin vs. friends. They found the sensorimotor cortex, ventromedial prefrontal cortex and posterior cingulate cortex to be more strongly activated when the subjects processed social information about their friends than about their kin. These differences imply that the brain processes kinship information differently than information on unrelated individuals. 

We explored this further by comparing subjects’ brain responses to a moral dilemma involving a pair of genetic versus adoptive (  i  .  e  ., unrelated) sisters. During functional magnetic resonance imaging (fMRI) the subjects viewed the same movie involving two sisters, but one group was primed with the information that they were genetic sisters and the other group with the information that they were sisters by adoption. The case of sisters related genetically vs. by adoption is especially suitable for testing whether knowledge of genetic relationship influences perception of a moral dilemma between kin given that there is no potential for shared genetic interest in future generations for adopted siblings . Note, however, that the current study examined perception of a kin relationship that subjects were seeing in a movie, while in Wlodarski and Dunbars  analysis the subjects answered questions about their own kin members and friends. 

In the present study, we utilized inter-subject correlation (ISC) of brain hemodynamic activity as a model-free analysis approach that makes it possible to use movies as ecologically valid stimuli during fMRI. Due to improvements in fMRI acquisition methods and data analysis algorithms , it has become possible to study specific aspects of social cognition between subjects using ecologically valid fMRI paradigms. The ecological validity is particularly important when studying moral dilemmas in order to engage the subjects and make the dilemma as credible and perceptible as possible in order to get authentic reactions. To investigate the degree of similarity in how individual brains respond to the common movie stimulus, the brains of individual subjects are aligned and ISC between the hemodynamic activity time courses for each voxel are calculated across all subject pairs. ISC can be interpreted as reflecting synchronized neural activity and thus similarity of cerebral information processing across individuals . It has been shown that when viewing a feature film during brain scanning, both “higher-order” prefrontal cortical as well as basic sensory cortex regions become synchronized across subjects . Further, ISC may not only reflect mutual neuronal responses, but could provide the basis of inducing a specific common mind set, e.g. built by context information or perspective taking as well as predicting the actions of others . 

The model-free approach of ISC does not require any a priori, pre-designed modeling of the fMRI signal to carry out the analysis and thus provides a powerful tool to investigate neuronal mechanisms as the correlations are exclusively based on similarities between the subjects’ brain activities when they react to the various aspects of the complex movie . At the same time, ISC has been shown to reliably detect involved brain regions in complex experimental setups almost as sensitively as a model-based analysis . 

In study 1, we asked whether people discriminate behaviourally between relatives with genetic vs. non-genetic backgrounds: In an implicit association test (IAT ) the subjects’ reaction time when associating the words “sister” and “adopted sister” to positive or negative connoted adjectives was measured. Further, after watching the movie, the subjects were asked whether genetic vs. non-genetic relationship status mattered to them in the moral dilemma that they observed. 

In study 2, we tested how the subjects perceived moral dilemmas involving genetically related vs. unrelated individuals during fMRI. In a first task, the subjects watched the movie depicting the moral dilemma between two sisters after being primed that they were either genetically related sisters or sisters related only by adoption. Should knowledge of genetic relationship matter, we expect to see differences in the behavioural tests (IAT; questionnaires) as well as the neuronal mechanisms: we predict that brain regions known to be involved in processing of mentalizing , conflict resolution , emotion regulation , and moral dilemmas  would be activated differently under the two viewing conditions. 

Second, following the hypothesis that moral processing is the most relevant factor to distinguish between watching the movie when believing the sisters to be genetic or adopted (i.e., non-genetic), each subject underwent a moral decision task during fMRI scanning to evaluate specifically which brain areas are associated with the perception and processing of moral dilemmas during movie-watching. In this task the subjects had to decide whom to save from a dangerous area and had different choices including their own sister, best friend, and strangers, an experimental design similar to the classical moral trolley dilemma. Again, if the genetic relationship had an effect on the viewers, as has previously been shown behaviourally , we hypothesize that the subjects will show kinship preference by saving their sister over others and that similar brain areas are engaged both in the decision task and when watching the movie believing that the sisters are genetic. 


## Results 
  
### Study 1: Implicit association test (IAT) 
  
To examine if a possible general implicit bias against adopted sisters (that potentially modulates brain functions during movie viewing) underlies the subjects’ perception of the movie, we asked 30 subjects in a behavioural experiment to undergo an IAT . In this test, reaction times during assignment of positive and negative connoted words to the categories of sister and adopted sister showed that there is no such implicit bias: Out of 30 subjects, nine favoured a genetic sister, 13 a non-genetic sister, and eight had no preference (one sampled t-test t = −0.9564 p = 0.3468). The TOST procedure  indicated that the ratings of emotional closeness were significantly similar (observed effect size (d = −0.17) was significantly within the equivalent bounds of d = −0.68 and d = 0.68; t(29) = 2.77, p = 0.005). 


### Study 2: Inter-subject correlation (ISC) of fMRI during movie watching 
  
#### Inter-subject correlation (ISC) across all conditions 
  
During fMRI scanning the subjects watched a movie depicting a moral dilemma between two sisters, either believing the sisters are genetic sisters or that the younger sister was adopted at birth. In a first step, the overall ISC (22) of hemodynamic activity of an independent set of 30 subjects was calculated during first viewing of the movie (Fig.  ). Significant ISC was observed extensively in occipital lobes, posterior parietal areas, and temporal cortices. In the frontal cortex, areas in the lateral inferior frontal gyrus (IFG), lateral middle frontal gyrus (MFG), dorsolateral prefrontal cortex (DLPFC), dorsomedial prefrontal cortex (DMPFC) and ventromedial prefrontal cortex (VMPFC) showed ISC between all subjects. The location of all brain areas were defined using anatomical brain atlases as specifically the Harvard-Oxford Cortical Structural Atlas and the Juelich Histological Atlas.   
Inter-subject correlation (ISC) of all 30 subjects during the first viewing of the movie. On top row are shown lateral and on bottom row medial surfaces of left and right cerebral hemispheres. Red-yellow colours indicate areas of significant ISC during movie watching (FDR q &lt; 0.05). Abbreviations: ACC = anterior cingulate cortex, ANG = angular gyrus, CAL = calcarine gyrus, DLPFC = dorsolateral prefrontal cortex, DMPFC = dorsomedial prefrontal cortex, IFG = inferior frontal gyrus, IOG = inferior occipital gyrus, MFG = middle frontal gyrus, MOG = middle occipital gyrus, MTG = middle temporal gyrus, PCC = posterior cingulate cortex, SOG = superior occipital gyrus, SPL = superior parietal lobe, STS/STG = superior temporal sulcus and gyrus, VMPFC = ventromedial prefrontal cortex, a = anterior, d = dorsal, p = posterior, v = ventral. 
  


#### Differences in ISC between conditions 
  
In a second step, the ISC of all subjects (N = 30) were contrasted between the genetic vs. non-genetic relationship viewing conditions. As each participant watched the movie in the genetic and in the non-genetic condition on two different scanning days in a counterbalanced order, this is a within-subject design. There were robust differences between the two conditions in the ISC of hemodynamic activity of the subjects, despite 90% of the subjects self-reporting that it did not matter to them whether the sisters were related genetically or not. When the subjects watched the movie believing that they were seeing genetically related sisters, the ISC was significantly stronger in the superior temporal sulcus and gyrus (STS/STG), VMPFC, DLPFC, anterior cingulate cortex (ACC) and posterior cingulate cortex (PCC), IFG, insula, cuneus, precuneus, and superior parietal lobule (SPL) (Fig.  , Table  ).   
Differential ISC between the conditions of an assumed genetic and non-genetic sisters and BOLD time series from two exemplary single voxels. (  A  ) Significant differences in brain activity when all subjects watched the movie thinking that the sisters were genetically vs. non-genetically related (FDR q &lt; 0.05, t = 2.1447, for consistent illustration purposes, the figures shows t-values from 3 to 9 and −3 to −9) (N = 30, within subject design). Red-yellow colours indicate areas of significantly higher ISC when the subjects watched the movie as depicting genetically related, as compared to non-genetically related, sisters. Blue colour indicates areas showing significantly higher ISC in the reverse contrast. Abbreviations: ACC = anterior cingulate cortex, CAL = calcarine gyrus, DLPFC = dorsolateral prefrontal cortex, IFG = inferior frontal gyrus, IOG = inferior occipital gyrus, MOG = middle occipital gyrus, PCC = posterior cingulate cortex, SPL = superior parietal lobe, STS/STG = superior temporal sulcus and gyrus, VMPFC = ventromedial prefrontal cortex, a = anterior, d = dorsal, p = posterior, v = ventral. (  B  ) Across subjects averaged BOLD time series of two voxels, one in the area VMPFC that showed significantly higher ISC when the subjects were viewing the sisters as genetic and one time series of a voxel in area V1 (primary visual cortex) that did not show significant between-condition ISC differences. The red line plots the group mean BOLD in the genetic sisters condition and the blue line plots the group mean BOLD in non-genetic sisters condition over the whole length of the movie. Red and blue shades indicate the 25  and 75  percentile of the variance. 
    
Clusters size, peak coordinates and t value of all clusters of Experiment 1 (movie watching task). 
  

When the subjects thought that the sisters were non-genetic, higher ISC was observed mainly in the occipital cortex. Importantly, the movie stimulus was identical in both viewing conditions. 

To illustrate blood oxygenation level dependent (BOLD) time series of specific voxels, in Fig.  , the panel B shows the time series of two exemplary voxels, over the whole length of the movie, from: i) VMPFC that showed higher ISC when the subjects viewed the sisters as genetic and ii) from a voxel in the area V1 (primary visual cortex), which is an early sensory brain area that did not show any between condition differences in ISC. 

Self-ratings of emotional valence and arousal obtained after the scans were not significantly different between the conditions (Valence: r = 0.0075, p = 0.3458, Arousal: r = −0.0189, p = 0.6081) (Fig.  ). Further, the mean ISC of eye-movements (eISC) over time windows showed no significant difference between the groups of participants believing in genetic or non-genetic sisters (p = 0.3918) (see Fig.  ). Likewise, no significant difference could be found in the heart and breathing rate comparing the conditions of assumed genetic versus non-genetic sisters (with bootstrap over 5000 permutations, breathing rate: t-value = 0.430, p = 0.335: heart rate: t-value = −1.12, p = 0.129) (see Fig.  ).   
Experienced emotional valence and arousal as well as physiological parameters when perceiving the sisters in the movie as genetic vs. non-genetic. (  A  ) Shown are dynamic self-ratings of emotional valence and arousal over the whole time course of the movie obtained during re-viewing of the movie after the fMRI sessions when the sisters were viewed as genetically related (red) or non-genetic (blue). The ratings were highly similar and there were no time periods where significant between-condition differences could have been observed. Note that half of the subjects (N = 2 × 15) rated experienced arousal and the rest rated experienced valence after the first fMRI session followed by rating the other emotional dimension after the second fMRI session. Plotted are means for all subjects in the red line for assumed genetic sisters and the blue line for non-genetic sisters condition. Red and blue dashed lines show the 25  and 75  percentile of the variance. (  B  ) Eye gaze behavior (N = 29) in the movies when the sisters were perceived as either genetic (right) or non-genetic (left) shown as a violin plot with the red cross depicting the means and green squares the medians. There were no significant differences between the conditions. (  C  ) Breathing and heart rates (N = 30) when the sisters were perceived as either genetic (red) or non-genetic (blue). There were no significant differences between the conditions. Red line plots the condition with assumed genetic sisters and the blue line non-genetic sisters. Red and blue shade show the 25  and 75  percentile of the variance. 
  



### Comparison with the moral dilemma decision experiment 
  
To further examine which neurocognitive processes might be involved, we studied whether the brain areas showing higher ISC in the genetic condition overlap with those engaged during a modified moral dilemma task  analysed with general linear modelling (GLM) (Fig.  , Tables   and  ). Naturally, it should be kept in mind that while ISC and GLM analyses of brain hemodynamic activity can yield converging results , this is not necessarily the case, as high ISC can be observed also when the BOLD signals are small.   
Having to decide in a simulation between saving one’s sister, friend, and others from crisis regions elicited significant brain activity in the VMPFC, ACC, precuneus, DLPFC, IFG, insula, TPJ and MTG. These activations of subjects (N = 30) were obtained by contrasting the decision phases (from the point of revealing the individuals involved until the decision signaled by the subject’s button press) against non-decision phases (subjects watching the background story depicting the two crisis regions and how the subjects only have resources to save individuals from one of the crisis regions) (FDR q &lt; 0.05, t = 2.0384, for consistent illustration purposes, the figures shows t-values from 3 to 9) Left-lateralized motor and supplementary motor are probably explained by the button press that the subjects performed to announce their decision. Abbreviations: ACC = anterior cingulate cortex, DLPFC = dorsolateral prefrontal cortex, IFG = inferior frontal gyrus, IOG = inferior occipital gyrus, ITG = inferior temporal gyrus, MC = motor cortex, MFC = medial frontal cortex, MOG = middle occipital gyrus, MTG = middle temporal gyrus, PCC = posterior cingulate cortex. SMA = supplementary motor area, SPL = superior parietal lobe, TPJ = temporo-parietal junction,VMPFC = ventromedial prefrontal cortex, a = anterior, d = dorsal, p = posterior, v = ventral. 
    
Clusters size, peak coordinates and t value of all clusters of and Experiment 2 (moral dilemma decision task). 
  

When the same subjects who watched the movie had to decide between saving their sister, best friend, vs. stranger(s), in various combinations, from a crisis region, 93% of the subjects showed a clear kin preference by choosing their sister (even when associated with some strangers) rather than their best female friend (chi-squared test ×  = 43.4 p &lt; 4 × 10 ). Further, as can be seen in Fig.   the VMPFC, ACC, IFG, MTG, SPL, PCC, precuneus, DLPFC, and anterior insula were consistently involved in both making choices of whom to prefer in a morally dilemmatic situation and when observing the moral dilemma between a genetic vs. non-genetic sister. Importantly, ratings of emotional closeness were not significantly different for the subjects’ sisters and their best friends with an average of 9.28 (sisters) and 8.80 (friends) on a 1–10 scale (Wilcoxon signed rank test = 0.12, t-test, t = 1.64 p = 0.11). The TOST procedure  indicated that the ratings of emotional closeness were significantly similar (observed effect size (d = 0.33) was significantly within the equivalent bounds of d = −0.68 and d = 0.68, or in raw scores: −1.07 and 1.07, t(29) = −1.92, p = 0.032).   
Activity during moral dilemma decision making as disclosed by GLM analysis (red) and the ISC when the subjects believed in a genetic relationship between the sisters in the movie (blue), along with the overlap of these two maps (violet), as well as the more strict overlap with a conjunction test (yellow);  , (FDR q &lt; 0.05, t = 2.0384 for GLM and t = 2.1447 for ISC). Abbreviations: ACC = anterior cingulate cortex, DLPFC = dorsolateral prefrontal cortex, IFG = inferior frontal gyrus, MFC = medial frontal cortex, MOG = middle occipital gyrus, MTG = midddle temporal gyrus, PCC = posterior cingulate cortex. SPL = superior parietal lobe, VMPFC = ventromedial prefrontal cortex, a = anterior, d = dorsal, p = posterior, v = ventral. 
  

As measured with an independent group of subjects outside the scanner, reaction times for the moral-dilemma decision were significantly longer in the case of a decision between a group comprised of their friend and four strangers on one side and their sister alone on the other side as in the case that only comprised strangers (on both sides) (paired Wilcoxon rank sum test p = 0.0011973). 



## Discussion 
  
In the present study, we investigated whether refusing altruism from a sister is perceived differently when the viewers think that the sisters are genetically related vs. when they think that one of the sisters has been adopted at young age. The results of the IAT in study 1 suggest that the subjects do not show an implicit bias against adoptive sisters compared to genetic sisters in general. Also, when explicitly asked if the relationship (as genetic or adopted) would matter in the decision of an organ donation, most subjects (90%) report that this knowledge would not affect the decision. Further, heart rate and breathing rate exhibited no significant differences between the two conditions, and self-reported emotional valence and arousal was likewise similar between the conditions (Fig.  ), suggesting that there were no robust differences in experienced emotions between the conditions. 

In contrast, the ISC of the hemodynamic brain activity show a different picture: robust differences were observed in patterns of brain activity due to the mere knowledge of the genetic relationship between the sisters in the movie. Specifically, there were multiple brain regions showing significantly higher ISC when the subjects thought that they are seeing a young girl refusing to donate her organ to save her genetic, as opposed to non-genetic, sister (Fig.  ). These areas included VMPFC, DLPFC, ACC, PCC, insula, precuneus, and SPL. While we would caution against drawing conclusions of specific cognitive functions involved on the basis of observed differences in brain activity, these brain regions have been previously shown to be associated with moral and emotional conflict regulation , decision making , mentalizing , and perspective taking , thus tentatively suggesting more uniform engagement of such neurocognitive functions when observing the dilemma of organ donation between genetic sisters. 

In the reverse contrast (i.e. when the subjects thought the sisters were non-genetic), higher ISC was observed in brain areas in the occipital cortex, conventionally associated mainly with visual perception . One possible explanation could potentially be that in the case of a non-genetic relationship between the sisters, the processing of complex social conflict associated with the moral dilemma is less demanding, and therefore leaves room for the subjects to focus on the visual aspects of the movie. However, eye-movements were not significantly different between the two viewing conditions, suggesting that differences in attention to movie events did not explain the observed robust differences in ISC. 

To specifically test for the possibility that the differences in ISC between the conditions reflected differences in moral evaluation, we compared the areas showing differences in ISC with areas activated when the subjects engaged in a separate moral-decision making control task. In this control task, the subjects had to make choices about saving people (including their sister, best friend, and strangers, in various combinations) from disaster. As each subject made only one decision that contrasted saving the friend over strangers and one decision of saving the friend over the own sister plus four strangers (as well as four decisions that contrasts the sister to groups of others), the statistical power in this experimental design was unfortunately not sufficient to differentiate directly between brain responses during decisions to save the sister vs. the friend. Rather, the results should be viewed as localization of brain regions involved in making moral decisions, yet also modulated by differences in, e.g., executive control, readiness for action, and attention, between the passive perception of the story and active decision making. However, significantly longer reaction times suggested increased difficulty when having to choose between a sister and the friend together with four strangers while areas in the VMPFC, DLPFC, ACC, PCC, precuneus, IFG, MTG, SPL and anterior insula were consistently involved in both making choices of whom to prefer in a morally dilemmatic situation and when observing the moral dilemma between a genetic vs. non-genetic sister (Fig.  ). This overlap in engaged brain regions suggests that processing of moral dilemmas took place during movie watching when the sisters were understood to be genetically related. It is significant that the brain regions flagged up in this analysis are those known to be involved in processing moral dilemmas and mentalizing. The DLPFC has been reported to play a role in overcoming a primary moral judgment in favour of greater welfare  and in cortical emotional processing , while the MTG has been implicated in attributing mental states as well as ingroup/outgroup distinctions , the ACC has been reported to be engaged in resolving conflicts , and the SPL, precuneus, and PCC have been implicated in mentalizing and perspective taking . Further, the VMPFC has been associated with viewing moral conflicts, making moral decisions, attributing mental states to self and others, adopting another person’s perspective, and evaluating their beliefs . 

Thus, the differences in ISC between the conditions appear to have arisen due to the knowledge about the sisters’ relationship influencing cognitive evaluation of the moral dilemma depicted in the movie. The contrast to the behavioural results assessed in study 1, where we find that behavioural decisions were not influenced by knowledge of the relationship, is particularly interesting since it suggests that differential processing is taking place under the surface. 

There could be at least two possible explanations for these findings. First, the study subjects might have purposely been hiding their “real” honest opinions as they might have not been willing to reveal these to the researchers, presumably because of social pressure against discriminating between genetic and adoptive siblings. However, the IAT is an implicit test for biases (it uses differences in reaction times for associations of a specific term with positively and negatively connoted words), so subjects are not aware of their performance on this task. Further, they do not know the exact measures which are used to calculate the IAT score, thus making it difficult to engineer potential biases; hence, it is very difficult, even impossible, to manipulate an IAT response in a desired direction . Thus, while a conscious manipulation of reported opinions would be possible in the open-format questionnaire (when asked if the relationship of the sisters matters in the situation of organ donation), it is very unlikely in the IAT. However, Liberman   et al  .  showed that, when judging incest reprehensibility, the coresidence of siblings is a stronger factor than the assumed relationship status and in when the two parameters are in conflict, the time spent in coresidence outweighs the belief of kin relation. As in this study the subjects were told that the apparent adoption took place as the younger sister was a newborn (implying coresidence of the sisters in both the genetic and the adoption case), we suggest, in accordance with Liberman   et al  ., that the factor of coresidence was given greater account than the kin relationship and thus the subjects’ explicit answers in the questionnaire could probably be seen/taken as truthful i.e. reporting authentic, honest thoughts. 

A second possible explanation for our findings is that, as the results of the implicit testing show, the study subjects indeed did not show any biases behaviourally and still pursued different ways of considering the case of a relationship by genes or by adoption, with resulting differences in brain activity patterns. These results show that an event that is behaviourally counter-intuitive (e.g. refusing to help a sister to prolong her life) needs different and potentially more intensive mental processing when the sisters are related genetically compared to adoptive sisters. As the differences in the brain activity patterns between the genetic and the adopted condition particularly comprise areas known to be involved in processing moral dilemmas and mentalizing as the VMPFC, DLPFC, ACC, PCC, precuneus, IFG, MTG, SPL, and anterior insula, we suggest that the study subjects’ expectations of morality are more strongly violated when close genetic relatives refuse to help each other than when unrelated individuals behave this way, despite their close social relation (adoption). 

Notwithstanding these points, we wish to caution the reader to keep in mind the caveats associated with reverse inference  (although see ). Specifically, even as we are suggesting that an activation observed in a certain region is indicative of a specific cognitive process based on results of previous research documented in the literature, it is possible that the activation of that region in the present study was due to some other cognitive process. This is because in general any given brain region is involved in multiple cognitive functions, thus making it difficult to infer with certainty the cognitive functions involved in a task based on brain regions that are activated. 

An alternative possibility is that the different measures operate at different levels of cognition: The null result in the IAT could be relying on a more basic level of attention to the social knowledge, whereas the questionnaire requires high level explicit cognition and the ISC during movie perception reflects some intermediate level of cognition. Had we thought to include them, other behavioural tests might have revealed more detail and background information on the subjects. Finally, it is always possible that something other than moral considerations could underlie the differences in brain patterns that we found, although, given the brain areas that show differences, this is unlikely. 

In summary, we observed robust differences in brain activity when subjects viewed a movie depicting refusal to donate an organ to a genetic vs. non-genetic sister. These differences in brain activity were observed despite the subjects self-reporting that the relational status of the sisters did not make any difference to them. Areas of increased synchrony in the case of genetic sisters overlapped with those activated in a separate moral dilemma decision task. Taken together, our results suggest that the precuneus, MTG, insula, SPL, and the VMPFC, along with the associated cognitive processes (i.e., moral and emotional conflict regulation), decision making, mentalizing and perspective taking are synchronized across subjects more robustly when they are viewing refusal of altruism from genetic as opposed to non-genetic, kin. Overall, these findings are fundamentally important for understanding social cognition, a pivotal ability that makes us human and, among other things, enables the existence of societies. Our findings point out that the perceived relationship of interacting persons robustly modulates how the brains of spectators process third-party interactions. This is highly significant given that majority of research to date on social cognition has been on strangers, whereas most of our social interactions take place between family members, friends, and acquaintances. 


## Material and Methods 
  
### Subjects 
  
We studied 33 healthy female subjects  (19–39 years, mean age of 26 years, one left-handed, laterality index of right handed 84.5%). None of the subjects reported any history of neurological or psychiatric disorders. When asked, all subjects reported either normal vision or corrected to normal vision by contact lenses. Three subjects were excluded due to discomfort in the scanner, so that the final analysis included 30 subjects. 27 of them were native Finnish speakers and three were native Russian speakers. All subjects were sufficiently proficient in English to follow the dialogue in the movie without subtitles. The experimental protocols were approved by the research ethics committee of the Aalto University and the study was carried out with their permission (Lausunto 9 2013 Sosiaalisen kognition aivomekanismit, 8.10.2013) and in accordance with the guidelines of the declaration of Helsinki . Written informed consent was obtained from each subject prior to participation. 


### Stimuli and Procedure 
  
The study consisted of two experiments. In the first experiment, the feature film   My Sister’s Keeper”   (dir. Nick Cassavetes, 2009, Curmudgeon Films), edited to 23 minutes and 44 s, (of which 14 min 17 s (60%) portray the theme of refusal of the organ donation),with the main story line retained, was shown to the subjects during fMRI. This shortened version of the movie focuses on the moral dilemma of the protagonist Anna to donate one of her kidneys to her sister Kate, who is fatally ill from cancer. In the course of the movie, Anna refuses to donate and Kate dies. The reason for Anna refusing to donate the kidney was not revealed to the subjects until after the experiment. The movie was shown to the subjects in the scanner four times in two separate scanning sessions on two different days. For each viewing of the movie the instructions were varied regarding the information about the sister’s relationship and the perspective to take in this viewing (Fig.  ). Each subject thus watched the movie assuming that the sisters were genetic sisters or that the younger sister Anna had been adopted as a newborn. In addition each subject was asked to take either the perspective of the potential donor (Anna) or the perspective of the potential recipient (Kate) on separate viewings (and both under the condition of a genetic or non-genetic relation background). The order of the different viewing conditions was counterbalanced between the subjects.   
Experimental procedure and ISC analysis in the movie watching task. (  A  ) Every subject watched the movie four times, in a 2 × 2 design assuming that the movie characters are either genetic sisters or not genetically related and taking the perspective of the to-be-donor sister Anna or the to-be-recipient sister Kate. The order of all the conditions were counter-balanced. (  B  ) Time series from each voxel from all the fMRI recordings are compared across subjects in pairwise correlations to obtain the mean inter-subject-correlation (ISC). 
  

In the second experiment, each subject carried out a moral-dilemma decision task during fMRI in order to localize brain regions that are related to moral decision making. For this purpose, a modified version of the classical trolley dilemma , was shown to the subjects. Each subject had to choose between rescuing different individuals, including unknown individuals, their sister and a best female friend. A presentation showing text and pictures told a story about civil unrest in a fictive distant country. This country had two parts: one part very dangerous and the other much less dangerous. Different people are in both parts of the country. Subjects were also told that as they were very rich and owned an airplane, they could go there and rescue some of the people. However, due to the circumstances in the country they had to decide which group of people to rescue. The two choices were always a group of five individuals on one side and a single person on the other. In seven runs the identity of the involved individual(s) was varied using the real names of the subject’s sister and best female friend. The 7 runs were: 1. All persons are unknown; 2. Sister is with four others in the dangerous part of the country, the single person is unknown; 3. Five persons are in the dangerous part of the country, the single person is the sister; 4. Five persons are in the dangerous part of the country, the single person is the friend; 5. Sister is with four others in the dangerous part of the country, the single person is the friend; 6. Friend is with four others in the dangerous part of the country, the single person is the sister; 7. Sister is with four others in the less dangerous part of the country, the single person is unknown. Responses in the moral dilemma decision task were recorded with a button press on a LUMItouch keypad (Photon Control Inc.8363, Canada). For the all questions, it was calculated with which percentage the sister was chosen over the friend and the stranger(s); statistical significance was tested with a Chi  test. 


### fMRI acquisition 
  
Before each scan the subjects were informed about the scanning procedures and asked to avoid bodily movements during the scans. All stimuli were presented to the subject with the Presentation software (Neurobehavioral Systems Inc., Albany, CA, USA), synchronizing the onset of the stimuli with the beginning of the functional scans. The movie was back-projected on a semitransparent screen using a data projector (PT-DZ8700/DZ110X Series, Panasonic, Osaka, Japan). The subjects viewed the screen at 33–35 cm viewing distance   via   a mirror located above their eyes. The audio track of the movie was played to the subjects with a Sensimetrics S14 audio system (Sensimetrics Corporation Malden, USA). The intensity of the auditory stimulation was individually adjusted to be loud enough to be heard over the scanner noise. The brain-imaging data were acquired with a 3T Siemens MAGNETOM Skyra (Siemens Healthcare, Erlangen, Germany), at the Advanced Magnetic Imaging center, Aalto University, using a standard 20-channel receiving head-neck coil. Anatomical images were acquired using a T1-weighted MPRAGE pulse sequence (TR 2530 ms, TE 3.3 ms, TI 1100 ms, flip angle 7°, 256 × 256 matrix, 176 sagittal slices, 1-mm3 resolution). Whole-brain functional data were acquired with T2*-weighted EPI sequence sensitive to the BOLD contrast (TR 2000 ms, TE 30 ms, flip angle 90, 64 × 64 matrix, 35 axial slices, slice thickness 4 mm, 3 × 3 mm in plane resolution). 

A total of 712 whole-brain EPI volumes were thus acquired for each movie viewing. The number of whole-brain EPI volumes for the moral dilemma decision task varied individually depending on the decision made by each subject (median 267 whole-brain EPI volumes). Heart pulse and respiration were monitored with the Biopac system (Biopac Systems Inc., Isla Vista, California, USA) during fMRI. Instantaneous values of heart rate and breathing rate were estimated with Drifter software package  (  http://becs.aalto.fi/en/research/bayes/drifter/  ). 


### fMRI preprocessing 
  
Standard fMRI preprocessing steps were applied using the FSL software (  www.fmrib.ox.ac.uk  ) and custom MATLAB code (available at   https://version.aalto.fi/gitlab/BML/bramila/  ). Briefly, EPI images were corrected for head motion using MCFLIRT. 

Then they were coregistered to the Montreal Neurological Institute 152 2 mm template in a two-step registration procedure using FLIRT: from EPI to subject’s anatomical image after brain extraction (9 degrees of freedom) and from anatomical to standard template (12 degrees of freedom). Further, spatial smoothing was applied with a Gaussian kernel of 6 mm full width at half maximum. High pass temporal filter at a cut-off frequency of 0.01 Hz was used to remove scanner drift. To further control for motion and physiological artefacts, BOLD time series were cleaned using 24 motion-related regressors, signal from deep white matter, ventricles and cerebral spinal fluid locations (see ) for details, cerebral spinal fluid mask from SPM8 file csf.nii, white matter and ventricles masks from Harvard Oxford atlas included with FSL). As a measure of quality control we computed framewise displacement to quantify instantaneous head motion. Out of all the 120 runs (30 subjects, 4 sessions each), 97.5% of the runs (117 runs) had 90% of time points (640 volumes) with framewise displacement under the 0.5 mm threshold suggested in . For the remaining three runs, the number of time points under 0.5 mm were 639 (89.7%), 633 (88.9%), 489 (68.7%), i.e. only one session had a considerable amount of head motion. While head motion is a concern in connectivity studies as it can increase spurious BOLD time series correlations that are affected by the same amount of instantaneous head motion, with across-brain time series correlation, head motion is expected to reduce the SNR. However, to make sure that head motion similarity did not explain any group difference, we computed the same permutation test for the ISC also for average framewise displacement by estimating the similarity of two subjects as the distance between their average framewise displacement value. We found that similarity in average head motion was not different between the two viewing conditions (t-value = 0.255; p = 0.398 obtained with 5000 permutations). 


### Inter-subject correlation (ISC) analysis of brain activity during movie watching 
  
To investigate how similar the brain activity was across subjects in the different experimental conditions, we performed inter-subject correlation (ISC) using the isc-toolbox (  https://www.nitrc.org/projects/isc-toolbox/  ) . For each voxel the toolbox computes a similarity matrix between subject pairs and within same subject in all conditions, with the conditions being: (i) shared assumption that the movie’s sisters are genetically related, (ii) shared assumption that the younger sister was adopted, (iii) shared perspective of the to-be-organ-donor, and (iv) shared perspective of the to-be-organ-recipient. The total size of the similarity matrix is then 120 × 120 (4 conditions × 30 subjects) with each subject having two viewings for the genetic and two viewings for the non-genetic condition. The comparison between the conditions of the sisters to be perceived as either genetic sisters or non-genetic sisters results thus in a total of 1740 pairs per condition, as the similarity of BOLD time series during the two viewings (in either the genetic or the non-genetic condition) of each subject is compared with the two respective viewings of the other N-1 subjects. As the order of subjects does not matter, the final number of pairs in same conditions will be 2*2*(N-1)*N/2 = 1740 with N = 30. Each value of the correlation matrix is a result of the correlation between the BOLD time series of the pair of subjects considered for the selected voxel. We computed differences between experimental conditions by first transforming the correlation values into z-scores with the Fisher Z transform and then computing t-values and corresponding p-values using a permutation based approach . 

The Fisher-Z transformed correlations of the two perspectives were pooled for either the genetic or the non-genetic sisterhood. 

Correction for the multiple comparison was performed with Benjamini-Hochberg false discovery rate (BH-FDR) correction at a q &lt; 0.05, corresponding to a t-value threshold of 2.133. For visualization purposes, all results were also cluster corrected by removing any significant cluster smaller than 4 × 4 × 4 voxels. Summary tables were generated with an increased t-value threshold of 3. For the conjunction or “intersection–union test”  the p values of the ISC and GLM results are pulled together by considering the maximum p-value at each voxel. Then, multiple comparisons correction is performed with the Benjamini-Hochberg false discovery rate procedure with an FDR threshold equal to q &lt; 0.05. 

Unthresholded statistical parametric maps can be found in neurovault:   http://neurovault.org/collections/WGSQZWPH/  . 

#### Perspective taking 
  
In the movie-viewing experiment, in addition to having the subjects to watch the movie in the conditions of sisters related by birth or by adoption, we had altogether four runs, so that on two of the runs the subjects were asked to view the movie from the perspective of the sister who was expected to donate the organ, and on two of the runs from the perspective of the to-be-recipient sister. Thus, there was one run wherein the subjects viewed the movie from the perspective of the to-be- donor thinking that the sisters were genetic, one run wherein the subjects viewed the movie from the perspective of the to-be- donor thinking that the sisters were non-genetic, one run wherein the subjects viewed the movie from the perspective of the to-be- recipient thinking that the sisters were genetic, and one run wherein the subjects viewed the movie from the perspective of the to-be- recipient thinking that the sisters were non-genetic. 

As the results of this task open up a completely other aspect of the experiment with various results to discuss, which go beyond the scope and the space limitation of this article, they will be reported separately elsewhere. These conditions are mentioned here for reasons of describing the experimental procedures thoroughly so that it would be possible for others to replicate the study should they wish to do so. 



### General linear model analysis of the fMRI data acquired during the control task 
  
A moral dilemma decision task was performed by all subjects to localize regions involved in moral processing. The moral dilemma decision task was analyzed with a general linear model approach using the SPM12 software (  www.fil.ion.ucl.ac.uk/spm  ). To distinguish between moments of decision in the moral dilemma and the simple perception of the presentation, we created a temporal model of the occurrence of decision moments during the experiment. The decision regressor included time points from the revelation of the identity of involved individuals to the moment of decision indicated by button press. The activity during these time points was compared to the activity in all other time points of the task, including telling the background story of the moral dilemma in the presentation. Regressors were convolved with canonical hemodynamic response function to account for hemodynamic lag. From the preprocessed input data (see above) low-frequency signal drifts were removed by high-pass filtering (cutoff 128 s). First, individual contrast images were generated for the main effects of the regressors, then first level analyses were subjected to second-level analyses in MATLAB using one-sample   t  -test to test which brain areas showed significant activations in decision vs. no decision moments in a one-sample   t  -test over subjects. Statistical threshold was set at   p   &lt; 0.05 (cluster-corrected using the threshold free cluster enhancement approach implemented by FSL randomize with 5000 permutations). 


### Recording of eye-movements 
  
Eye movements were recorded during fMRI scanning from all subjects with an EyeLink 1000 eye tracker (SR Research, Mississauga, Ontario, Canada; sampling rate 1000 Hz, spatial accuracy better than 0.5°, with a 0.01° resolution in the pupil-tracking mode). Due to technical problems, 4 subjects had to be excluded from the final data analysis (with the rejection criteria of blinks maximum 10% of the duration of the scan and majority of blinks and saccades less than 1 second in duration). In addition, a part of recordings from some additional subjects had to de discarded due to the same criteria mentioned above, resulting in 61 recorded files with sufficient quality, with 35 files remaining in the genetic condition and 26 remaining files for the non-genetic condition. Prior to the experiment the eye tracker was calibrated once with a nine-point calibration. 

Saccade detection was performed using a velocity threshold of 30°/s and an acceleration threshold of 4000°/s2. Because the experiment was relatively long and no intermediate drift correction was performed, we retrospectively corrected the mean effect of the drift. We first calculated the mean of all fixation locations over the entire experiment for each subject, and then rigidly shifted the fixation distributions so that the mean fixation location coincided with the grand mean fixation location over all subjects. 


### Eye-movement analysis 
  
Subject-wise gaze fixation distributions were compared across the genetic vs. non-genetic conditions in the movie viewing task. Individual heat maps were generated by modelling each fixation as a Gaussian function using a Gaussian kernel with a standard deviation of 1degree of visual angle and a radius of 3 standard deviations. The heat maps were generated in time windows of 2 seconds corresponding to the TR used in the fMRI measurements. Spatial similarities between each pair of heat maps across the eye-tracking sessions were calculated using Pearson’s product-moment correlation coefficient (inter-subject correlation of eye gaze, eyeISC ). In the end a similarity matrix was obtained with correlations between each pair for each of the 712 time windows. 

First, the mean eISC scores over all 712 time windows were examined. These mean scores were acquired by extracting the mean of Fisher’s Z-transformed correlation scores and then transforming these mean values back to the correlation scale before the statistical analysis. The statistical significance of the group differences was analysed by contrasting pairs in which both subjects assumed a genetic relationship with pairs in which both subjects assumed the younger sister to be adopted. Non-parametric permutation tests with a total of 100000 permutations were used to avoid making assumptions about the data distribution. In this procedure the data were mixed randomly to change groupings and differences in the resulting new randomised groups were used to form an estimated distribution of the data. A comparison of how many of the permuted random partitions into groups build a more extreme group mean difference that the one observed with the original grouping yielded the final p-values. 


### Behavioral Measurements and Self-reports 
  
#### Valence and Arousal measurements 
  
The subjects self-reported emotions they had experienced during movie viewing. This was carried out after the fMRI experiment by viewing the movie again (Full procedures have been described in an earlier publication ). Two aspects of emotional experience were rated: emotional valence (positive-negative scale) and arousal which were acquired on separate runs. While watching the movie in the middle of the screen, the subjects could move a small cursor on the right side of the screen up and down on a scale using the computer mouse to report their current state of valence or arousal using a web tool   https://version.aalto.fi/gitlab/eglerean/dynamicannotations  . The self-ratings were collected at 5 Hz sampling rate. 


#### Behavioral questionnaires 
  
The subjects were asked after the first fMRI session five short freeform questions about their perception of the movie, specifically about how easy it was to take one or the other perspective, and whether they would have donated their kidney if in place of the movie protagonist. After the second fMRI session all subjects were debriefed by showing them the ending of the original movie, where it is revealed that the sick sister had wished for the healthy sister to refuse donating her kidney. Afterwards they were asked if seeing the real ending changed their opinion on the roles of the two movie protagonists. 

As an additional self-report measure, the subjects’ disposition for catching emotions from others was assessed with two emotional empathy questionnaires: Hatfield’s Emotional Contagion Scale  and the BIS/BAS scale . Every subject also filled in a questionnaire quantifying their social network , including their emotional closeness to their sister and best friend. The names of the sister and best friend were obtained from this questionnaire for the moral dilemma task. 



### Analysis of behavioral measurements 
  
#### Valence and arousal measurements 
  
To test whether dynamic valence and arousal were different between the genetic and non-genetic condition, we first computed inter-subject similarity matrices using valence and arousal rating time-series. These were compared against a similarity matrix for the experimental conditions of the viewing preceding the valence/arousal rating, i.e. the model tests for the case where individuals are more similar within the same condition (genetic or non-genetic), but dissimilar between conditions. Tests were performed using Mantel test with 5000 permutations. We also performed a test to see if subjects who were rating arousal and valence for the genetic condition had a stronger group similarity than subjects who rated arousal and valence for the non-genetic condition. Tests were performed using permutation based t-tests. As dynamic ratings can also be different in specific time points, we also performed a permutation-based t-test on valence and arousal values at each time point corrected for multiple comparisons across time. 


#### Heart rate and breathing rate analysis 
  
Differences between experimental conditions were computed in the same way as in the ISC analysis: Correlation values were first transformed into z-scores with the Fisher Z’s transform and then a permutation based approach was used to compute t-values and corresponding p-values . Correction for the multiple comparisons was performed with Benjamini-Hochberg false discovery rate (BH-FDR) correction at a q &lt; 0.05, corresponding to a t-value threshold of 2.133. 



### Behavioral measurements with a new group of subjects 
  
Subsequent to the fMRI experiments a new group of 30 subjects (all female, and having a sister, 18–33 years, mean age 25.5 years, right handed) were recruited for two further behavioral measurements. The subjects first performed an implicit association test (IAT). The IAT measures attitudes and beliefs that might not be consciously self-recognized by the subject or attitudes that the subjects are unwilling to report. By asking the subjects to sort, as quickly as possible, positively and negatively connoted words into categories, the IAT can measure the reaction times of the association process between the categories and the evaluations (e.g., good, bad). It has been shown in previous studies that making a response is easier and thus faster if the category is matching the implicit evaluation the subject bears in mind . In this study the two categories were “genetic sister” (sisko) and “adopted sister” (adoptiosisko). The two categories were paired in different randomized runs with positive or negative words, thus the experiment comprised separate runs asking the subjects to either match the positive words with the category “genetic sister” and negative words with the category “adopted sister” or vice versa to match positive words with the category “adopted sister” and negative words with the category “genetic sister”. The order in which the runs are presented counter-balanced across subjects and categories switched their localization on the screen in different runs to be on the left or right side of the screen to the same extent. Subjects were asked to press a key with either the right or the left hand and thus assign the evaluation word to one category on either the left or right hand side of the computer screen. With the experiment going on, the number of trials in this part of the IAT is increased in order to minimize the effects of practice. The IAT score is based on how long it takes a person to sort the words with the condition associating positive words and genetic (and negative and adopted) in contrast to negative words and genetic (and positive words and adopted). If an implicit preference exist for one of the categories subjects would be faster to match positive words to that category relative to the reverse. Data were analysed using Matlab. Similarity between subjects’ scores were examined TOST testing . As a second task, reaction times for the moral decision task were measured with the same group of subjects that underwent the IAT. As a difference to the decision task performed during fMRI scanning the order of the decisions was randomized (with easy decision including only strangers and difficult decisions including the sister on one side and the friend on the other). Reaction times were measured as the time between the onset of the slide revealing the identity of the involved individuals and the button press of the subject that related her decision. 


### Data availability 
  
The data that support the findings of this study are available on request from the corresponding author MBT. The data are not publicly available due to a prohibition by the Finnish law: Juridical restrictions set by the Finnish law prevent public access to the collected data, be it anonymized or non-anonymized, when data are recorded from human individuals. As the consent given by the subjects only applies to the specific study reported in our manuscript, no portion of the data collected could be used or released for use by third parties.</pre></details></details>
  <details class="inner-accordion"><summary>Coordinate-relevant source tables (2)</summary><details class="inner-accordion"><summary>Table 1 (Tab1) - Clusters size, peak coordinates and t value of all clusters of Experiment 1 (movie watching task).</summary><div class="table-html"><table-wrap id="Tab1" position="float" orientation="portrait"><label>Table 1</label><caption><p>Clusters size, peak coordinates and t value of all clusters of Experiment 1 (movie watching task).</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="1" rowspan="1">Cluster Label: movie watching task</th><th colspan="1" rowspan="1">Cluster extent (voxels)</th><th colspan="1" rowspan="1">x MNI (mm)</th><th colspan="1" rowspan="1">y MNI (mm)</th><th colspan="1" rowspan="1">z MNI (mm)</th><th colspan="1" rowspan="1">Peak value (T-value)</th></tr></thead><tbody><tr><td colspan="6" rowspan="1">
<bold>clusters genetic &gt; non-genetic</bold>
</td></tr><tr><td colspan="1" rowspan="1">Superior parietal lobule (R)</td><td colspan="1" rowspan="1">8794</td><td colspan="1" rowspan="1">8</td><td colspan="1" rowspan="1">−86</td><td colspan="1" rowspan="1">44</td><td colspan="1" rowspan="1">14.6272</td></tr><tr><td colspan="1" rowspan="1">Ventromedial prefrontal cortex (R)</td><td colspan="1" rowspan="1">4099</td><td colspan="1" rowspan="1">0</td><td colspan="1" rowspan="1">54</td><td colspan="1" rowspan="1">−8</td><td colspan="1" rowspan="1">8.3312</td></tr><tr><td colspan="1" rowspan="1">Superior temporal gyrus (L)</td><td colspan="1" rowspan="1">2182</td><td colspan="1" rowspan="1">−42</td><td colspan="1" rowspan="1">−26</td><td colspan="1" rowspan="1">6</td><td colspan="1" rowspan="1">16.974</td></tr><tr><td colspan="1" rowspan="1">Superior temporal gyrus (R)</td><td colspan="1" rowspan="1">1138</td><td colspan="1" rowspan="1">62</td><td colspan="1" rowspan="1">−26</td><td colspan="1" rowspan="1">4</td><td colspan="1" rowspan="1">13.0493</td></tr><tr><td colspan="1" rowspan="1">Putamen (R)</td><td colspan="1" rowspan="1">616</td><td colspan="1" rowspan="1">18</td><td colspan="1" rowspan="1">16</td><td colspan="1" rowspan="1">−10</td><td colspan="1" rowspan="1">7.2211</td></tr><tr><td colspan="1" rowspan="1">Insula (L)</td><td colspan="1" rowspan="1">266</td><td colspan="1" rowspan="1">−40</td><td colspan="1" rowspan="1">18</td><td colspan="1" rowspan="1">−10</td><td colspan="1" rowspan="1">6.9642</td></tr><tr><td colspan="1" rowspan="1">Inferior temporal gyrus (R)</td><td colspan="1" rowspan="1">145</td><td colspan="1" rowspan="1">52</td><td colspan="1" rowspan="1">−46</td><td colspan="1" rowspan="1">−30</td><td colspan="1" rowspan="1">7.432</td></tr><tr><td colspan="1" rowspan="1">Middle temporal gyrus (R)</td><td colspan="1" rowspan="1">110</td><td colspan="1" rowspan="1">66</td><td colspan="1" rowspan="1">−4</td><td colspan="1" rowspan="1">−16</td><td colspan="1" rowspan="1">10.4489</td></tr><tr><td colspan="1" rowspan="1">Inferior frontal gyrus (L)</td><td colspan="1" rowspan="1">89</td><td colspan="1" rowspan="1">−36</td><td colspan="1" rowspan="1">34</td><td colspan="1" rowspan="1">20</td><td colspan="1" rowspan="1">5.3232</td></tr><tr><td colspan="1" rowspan="1">Superior frontal gyrus (R)</td><td colspan="1" rowspan="1">89</td><td colspan="1" rowspan="1">8</td><td colspan="1" rowspan="1">62</td><td colspan="1" rowspan="1">26</td><td colspan="1" rowspan="1">6.2544</td></tr><tr><td colspan="1" rowspan="1">Inferior parietal lobule (L)</td><td colspan="1" rowspan="1">86</td><td colspan="1" rowspan="1">−52</td><td colspan="1" rowspan="1">−60</td><td colspan="1" rowspan="1">48</td><td colspan="1" rowspan="1">5.0215</td></tr><tr><td colspan="1" rowspan="1">Postcentral gyrus (R)</td><td colspan="1" rowspan="1">81</td><td colspan="1" rowspan="1">56</td><td colspan="1" rowspan="1">−6</td><td colspan="1" rowspan="1">38</td><td colspan="1" rowspan="1">7.0252</td></tr><tr><td colspan="1" rowspan="1">Superior parietal lobule (L)</td><td colspan="1" rowspan="1">73</td><td colspan="1" rowspan="1">−14</td><td colspan="1" rowspan="1">−58</td><td colspan="1" rowspan="1">72</td><td colspan="1" rowspan="1">7.4174</td></tr><tr><td colspan="6" rowspan="1">
<bold>clusters non-genetic &gt; genetic</bold>
</td></tr><tr><td colspan="1" rowspan="1">Inferior occipital gyrus (R)</td><td colspan="1" rowspan="1">1938</td><td colspan="1" rowspan="1">40</td><td colspan="1" rowspan="1">−66</td><td colspan="1" rowspan="1">−8</td><td colspan="1" rowspan="1">−12.3679</td></tr><tr><td colspan="1" rowspan="1">Middle occipital gyrus (L)</td><td colspan="1" rowspan="1">604</td><td colspan="1" rowspan="1">−32</td><td colspan="1" rowspan="1">−84</td><td colspan="1" rowspan="1">4</td><td colspan="1" rowspan="1">−9.7755</td></tr><tr><td colspan="1" rowspan="1">Cerebellar crus II (R)</td><td colspan="1" rowspan="1">318</td><td colspan="1" rowspan="1">30</td><td colspan="1" rowspan="1">−86</td><td colspan="1" rowspan="1">−32</td><td colspan="1" rowspan="1">−7.3011</td></tr><tr><td colspan="1" rowspan="1">Temporal pole (middle) (R)</td><td colspan="1" rowspan="1">171</td><td colspan="1" rowspan="1">38</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">−34</td><td colspan="1" rowspan="1">−6.6407</td></tr><tr><td colspan="1" rowspan="1">Inferior temporal gyrus (L)</td><td colspan="1" rowspan="1">165</td><td colspan="1" rowspan="1">−54</td><td colspan="1" rowspan="1">−64</td><td colspan="1" rowspan="1">−4</td><td colspan="1" rowspan="1">−8.2858</td></tr><tr><td colspan="1" rowspan="1">Angular gyrus (L)</td><td colspan="1" rowspan="1">147</td><td colspan="1" rowspan="1">−42</td><td colspan="1" rowspan="1">−54</td><td colspan="1" rowspan="1">28</td><td colspan="1" rowspan="1">−5.5752</td></tr><tr><td colspan="1" rowspan="1">Superior temporal gyrus (R)</td><td colspan="1" rowspan="1">95</td><td colspan="1" rowspan="1">64</td><td colspan="1" rowspan="1">−28</td><td colspan="1" rowspan="1">20</td><td colspan="1" rowspan="1">−8.3381</td></tr><tr><td colspan="1" rowspan="1">Inferior frontal gyrus (R)</td><td colspan="1" rowspan="1">94</td><td colspan="1" rowspan="1">52</td><td colspan="1" rowspan="1">20</td><td colspan="1" rowspan="1">16</td><td colspan="1" rowspan="1">−5.7279</td></tr><tr><td colspan="1" rowspan="1">Superior temporal gyrus (R)</td><td colspan="1" rowspan="1">87</td><td colspan="1" rowspan="1">64</td><td colspan="1" rowspan="1">0</td><td colspan="1" rowspan="1">−4</td><td colspan="1" rowspan="1">−9.6944</td></tr><tr><td colspan="1" rowspan="1">Precentral gyrus (L)</td><td colspan="1" rowspan="1">86</td><td colspan="1" rowspan="1">−44</td><td colspan="1" rowspan="1">10</td><td colspan="1" rowspan="1">52</td><td colspan="1" rowspan="1">−6.1405</td></tr><tr><td colspan="1" rowspan="1">Superior frontal gyrus (L)</td><td colspan="1" rowspan="1">86</td><td colspan="1" rowspan="1">−8</td><td colspan="1" rowspan="1">20</td><td colspan="1" rowspan="1">60</td><td colspan="1" rowspan="1">−7.8522</td></tr></tbody></table></table-wrap>
</div></details><details class="inner-accordion"><summary>Table 2 (Tab2) - Clusters size, peak coordinates and t value of all clusters of and Experiment 2 (moral dilemma decision task).</summary><div class="table-html"><table-wrap id="Tab2" position="float" orientation="portrait"><label>Table 2</label><caption><p>Clusters size, peak coordinates and t value of all clusters of and Experiment 2 (moral dilemma decision task).</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="1" rowspan="1">Cluster Label: moral dilemma decision task</th><th colspan="1" rowspan="1">Cluster extent (voxels)</th><th colspan="1" rowspan="1">x MNI (mm)</th><th colspan="1" rowspan="1">y MNI (mm)</th><th colspan="1" rowspan="1">z MNI (mm)</th><th colspan="1" rowspan="1">Peak value (T-value)</th></tr></thead><tbody><tr><td colspan="1" rowspan="1">Cerebellar lobule VI (R)</td><td colspan="1" rowspan="1">10417</td><td colspan="1" rowspan="1">20</td><td colspan="1" rowspan="1">−54</td><td colspan="1" rowspan="1">−30</td><td colspan="1" rowspan="1">10.1921</td></tr><tr><td colspan="1" rowspan="1">Superior frontal gyrus (L)</td><td colspan="1" rowspan="1">3631</td><td colspan="1" rowspan="1">−8</td><td colspan="1" rowspan="1">10</td><td colspan="1" rowspan="1">48</td><td colspan="1" rowspan="1">8.4473</td></tr><tr><td colspan="1" rowspan="1">Precentral gyrus (L)</td><td colspan="1" rowspan="1">2476</td><td colspan="1" rowspan="1">−34</td><td colspan="1" rowspan="1">−18</td><td colspan="1" rowspan="1">58</td><td colspan="1" rowspan="1">7.2107</td></tr><tr><td colspan="1" rowspan="1">Inferior frontal gyrus (L)</td><td colspan="1" rowspan="1">1207</td><td colspan="1" rowspan="1">−52</td><td colspan="1" rowspan="1">12</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">6.3788</td></tr><tr><td colspan="1" rowspan="1">Superior parietal lobule (L)</td><td colspan="1" rowspan="1">815</td><td colspan="1" rowspan="1">−28</td><td colspan="1" rowspan="1">−56</td><td colspan="1" rowspan="1">48</td><td colspan="1" rowspan="1">6.0945</td></tr><tr><td colspan="1" rowspan="1">Amygdala (L)</td><td colspan="1" rowspan="1">720</td><td colspan="1" rowspan="1">−14</td><td colspan="1" rowspan="1">−12</td><td colspan="1" rowspan="1">−12</td><td colspan="1" rowspan="1">6.2453</td></tr><tr><td colspan="1" rowspan="1">Putamen (R)</td><td colspan="1" rowspan="1">257</td><td colspan="1" rowspan="1">24</td><td colspan="1" rowspan="1">10</td><td colspan="1" rowspan="1">8</td><td colspan="1" rowspan="1">5.4598</td></tr><tr><td colspan="1" rowspan="1">Superior parietal lobule (R)</td><td colspan="1" rowspan="1">199</td><td colspan="1" rowspan="1">26</td><td colspan="1" rowspan="1">−62</td><td colspan="1" rowspan="1">54</td><td colspan="1" rowspan="1">4.8181</td></tr><tr><td colspan="1" rowspan="1">Angular gyrus (L)</td><td colspan="1" rowspan="1">156</td><td colspan="1" rowspan="1">−48</td><td colspan="1" rowspan="1">−52</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">4.9727</td></tr><tr><td colspan="1" rowspan="1">Insula (R)</td><td colspan="1" rowspan="1">128</td><td colspan="1" rowspan="1">40</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">0</td><td colspan="1" rowspan="1">5.3664</td></tr><tr><td colspan="1" rowspan="1">Middle temporal gyrus (L)</td><td colspan="1" rowspan="1">123</td><td colspan="1" rowspan="1">−62</td><td colspan="1" rowspan="1">−24</td><td colspan="1" rowspan="1">−12</td><td colspan="1" rowspan="1">4.7632</td></tr><tr><td colspan="1" rowspan="1">Temporal pole (middle) (L)</td><td colspan="1" rowspan="1">77</td><td colspan="1" rowspan="1">−56</td><td colspan="1" rowspan="1">8</td><td colspan="1" rowspan="1">−24</td><td colspan="1" rowspan="1">5.4375</td></tr></tbody></table></table-wrap>
</div></details></details>
</details>


<details class="doc-card">
  <summary><strong>PMID 29890323</strong> | Pred included: 6 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29890323/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29890323_analysis_0</td><td>emotional &gt; neutral video clips</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares emotional versus neutral social video clips in an Empathic Accuracy Task; it assesses processing of others&#x27; emotions and social cognition.</td></tr>
<tr><td>29890323_analysis_1</td><td>neutral &gt; emotional video clips</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Empathic Accuracy Task is a social task requiring perception and understanding of others&#x27; emotional states; even the neutral vs emotional contrast probes social/emotional processing, so it measures social processing.</td></tr>
<tr><td>29890323_analysis_2</td><td>Positively related to Z-EA scores</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The Empathic Accuracy Task is explicitly a social task assessing perception and understanding of others&#x27; emotions; contrasts (emotional vs neutral) and correlations with empathic accuracy measure social processing.</td></tr>
<tr><td>29890323_analysis_3</td><td>Negatively related to Z-EA scores</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The Empathic Accuracy Task is explicitly a social task measuring perception and interpretation of others&#x27; emotions; the analysis examines brain activity related to empathic accuracy, which is social processing.</td></tr>
<tr><td>29890323_analysis_4</td><td>Positive correlation with participants&#x27; emotional intensity ratings</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves continuous rating of another person&#x27;s emotional intensity (empathic accuracy)—a social processing measure of perceiving and understanding others&#x27; emotions.</td></tr>
<tr><td>29890323_analysis_5</td><td>Negative correlation with participants&#x27; emotional intensity ratings</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The analysis uses an empathic accuracy task where participants continuously rate another person&#x27;s emotional intensity—this is clearly a social cognition task (perception and understanding of others) and measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29890323_1</td><td>emotional &gt; neutral video clips; others</td><td>29890323_analysis_0</td><td>emotional &gt; neutral video clips</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29890323_2</td><td>neutral &gt; emotional video clips; others</td><td>29890323_analysis_1</td><td>neutral &gt; emotional video clips</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  <details class="inner-accordion"><summary>PMC full text available (PMCID 6057276)</summary><p><strong>Title:</strong> Tracking emotions in the brain – Revisiting the Empathic Accuracy Task</p><details><summary>Abstract</summary><pre class="paper-text">Many empathy tasks lack ecological validity due to their use of simplistic stimuli and static analytical approaches. Empathic accuracy tasks overcome these limitations by using autobiographical emotional video clips. Usually, a single measure of empathic accuracy is computed by correlating the participants&#x27; continuous ratings of the narrator&#x27;s emotional state with the narrator&#x27;s own ratings. 

In this study, we validated a modified empathic accuracy task. A valence-independent rating of the narrator&#x27;s emotional intensity was added to provide comparability between videos portraying different primary emotions and to explore changes in neural activity related to variations in emotional intensity over time. We also added a new neutral control condition to investigate general emotional processing. In the scanner, 34 healthy participants watched 6 video clips of people talking about an autobiographical event (2 sad, 2 happy and 2 neutral clips) while continuously rating the narrator&#x27;s emotional intensity. 

Fluctuation in perceived emotional intensity correlated with activity in brain regions previously implicated in cognitive empathy (bilateral superior temporal sulcus, temporoparietal junction, and temporal pole) and affective empathy (right anterior insula and inferior frontal gyrus). When emotional video clips were compared to neutral video clips, we observed higher activity in similar brain regions. Empathic accuracy, on the other hand, was only positively related to activation in regions that have been implicated in cognitive empathy. 

Our modified empathic accuracy task provides a new method for studying the underlying components and dynamic processes involved in empathy. While the task elicited both cognitive and affective empathy, successful tracking of others&#x27; emotions relied predominantly on the cognitive components of empathy. The fMRI data analysis techniques developed here may prove valuable in characterising the neural basis of empathic difficulties observed across a range of psychiatric conditions. 
   Highlights  
  
Activity in affective and cognitive empathy related regions during emotional videos. 
  
Activity in similar regions related to changes in perceived emotional intensity. 
  
Only regions implicated in cognitive empathy were associated with empathic accuracy. 
  
No difference between video clips that did and did not elicit affect sharing. 
  
Empathic accuracy related to self-rated perspective-taking but not empathic concern.</pre></details><details><summary>Body</summary><pre class="paper-text">## Introduction 
  
Empathy, has been defined as “an emotional response [… which] is similar to one&#x27;s perception […] and understanding […] of the stimulus emotion, with recognition that the source of the emotion is not one&#x27;s own.” ( , page 150). Empathy is crucial for successful social interaction as it allows the individual to predict others&#x27; actions, emotions and intentions ( ). Deficits in empathic processing have been reported in psychiatric disorders such as autism spectrum disorder (ASD), schizophrenia, borderline personality disorder and bipolar disorder ( ). Identifying the neural substrates of empathy in healthy populations is important for understanding conditions that are characterised by empathic difficulties. In neuroscience, the concept of empathy is considered to include separate affective (sharing others&#x27; emotion) and cognitive (understanding others&#x27; emotion) components (for example,  ;  ). Previous research has identified distinct clusters of brain regions involved in affective empathy: medial/anterior cingulate cortex (MCC, ACC), anterior insula (AI) ( ;  ), and supplementary motor area (SMA) ( ). Within the broader domain of social cognition, cognitive empathy overlaps with the affective component of Theory of Mind (ToM) or mentalising, namely the capacity to infer other people&#x27;s thoughts, emotions and intentions without necessarily sharing them ( ). A recent meta-analysis of 144 fMRI studies using ToM tasks ( ) identified the medial prefrontal cortex (mPFC), medial orbitofrontal cortex (mOFC), ACC, precuneus, temporal pole (TP), posterior superior temporal gyrus (pSTS) and temporoparietal junction (TPJ) and inferior frontal gyrus (IFG) as key regions for mentalising. 

However, prior research on the neural mechanisms of empathy has often lacked ecological validity. Studies have often used simplistic stimuli that differ greatly from the complex cues that individuals have to process in real-life situations ( ,  ). Moreover, most studies focus on empathy for pain, while only a few studies have evaluated other emotions (e.g. disgust, happiness, sadness;  ;  ). In addition, empathy has mostly been operationalised as a static trait ( ). However, in the real world empathy fluctuates dynamically ( ). These fluctuations can happen spontaneously because of changes in internal state or in response to shifts in external circumstances, such the emotional intensity and expressivity of others. 

In the current study, we addressed these limitations of previous research by modifying an existing paradigm, the Empathic Accuracy Task (EAT;  ), that incorporates more naturalistic stimuli and reflects the dynamic nature of empathy. Participants (perceivers) watch video clips in which another person (target) describes an emotional autobiographical event. Perceivers continuously rate the target&#x27;s emotion while watching the clips (via button pressing). The EAT measures how   accurately   the perceiver infers changes in the target&#x27;s emotional states by correlating the perceiver&#x27;s ratings with the target&#x27;s ratings of their own emotions (see   for a detailed description).   found that empathic accuracy was associated with higher activation in both affective (i.e. inferior parietal lobule (IPL)) and cognitive (i.e. mPFC) empathy networks. In a recent study of adolescents, empathic accuracy related positively to activation in cognitive empathy or mentalising regions (mPFC, TPJ, STS) and negatively to activation in regions implicated in affective empathy (IPL, ACC, AI;  ). 

In the current study, new video clips were created and the EAT was modified in the following important ways: First, video clips depicted discrete primary emotions (happy, sad, angry, frightened) and participants rated changes in the targets&#x27; emotional intensity (instead of valence) to ensure comparability across different emotions and higher construct validity. Second, we introduced well-matched neutral video clips that acted as a control condition. In this condition, targets described their bedroom. This control condition allowed us to examine the neural correlates of emotion processing irrespective of empathic accuracy. Third, as empathy is a dynamic process, perceivers need to be able to continuously identify changes in the intensity of the target&#x27;s emotional state. We therefore utilised an analysis approach that tracked changes in the target&#x27;s emotional intensity throughout each video clip, in addition to deriving a single index of empathic accuracy (averaged across the clip). Fourth, we included ratings from participants regarding how they felt after watching each video to gain a better understanding of how the neural correlates of EA are influenced by cognitive and affective empathy. Finally, to validate the EAT, we related task performance to self-reported trait empathy and IQ as well as acquiring a normative data set with participants who completed the EAT outside of the scanner. 

The aim of this study was to validate a modified version of the Empathic Accuracy Task, using a staged analysis approach which replicates analyses presented previously in the literature, but which also included additional comparisons. First, we contrasted the blood-oxygen-level dependent (BOLD) responses to emotional and neutral clips to explore correlates of complex and multi-sensory emotional processing during extended clips rather than single emotional images. Second, we validated our emotional intensity rating scale by analysing the neural correlates of intra-individual variations in empathic accuracy. Third, we explored neural correlations with variations in perceived emotional intensity over time, thus capitalising on the availability of continuous ratings throughout each video clip. 

Given the results of prior neuroimaging studies of empathy and mentalising, we had the following hypotheses:   
At the group level, increased BOLD responses would be observed in brain regions previously linked to empathy and mentalising when participants watched targets describe emotional versus neutral events. 
  
There would be positive correlations between intra-individual variations in empathic accuracy and BOLD responses in these regions. 
  
We predicted positive correlations between fluctuations in perceived emotional intensity and BOLD responses in these regions during emotional video clips. 
  


## Methods 
  
### Participants 
  
#### fMRI study 
  
Forty-seven healthy participants aged between 20 and 30 years, fluent in English and with no history of neurological illness, took part in the study. Six participants were excluded from the analysis due to current or recurrent episodes of mental illness as assessed by the Mini International Neuropsychiatric Interview ( ). Five further participants were excluded because of excessive head movement or poor task performance (&lt;2 SD in empathic accuracy (EA) scores) and two participants had incomplete questionnaire data. The final dataset included 34 subjects (19 females, mean age: 24.0 years, SD: 2.7 years). The study received ethical approval from the Camberwell - St. Giles NHS Research Ethics Committee (14/LO/0477) and the University of Southampton Ethics Committee. 


#### Normative data collection 
  
To create a normative data set for the EAT and to validate the stimuli used in the fMRI task, an additional 73 healthy participants completed the EAT outside the MRI scanner. The same inclusion criteria as described above were applied. After excluding 13 participants due to current or recurrent episodes of mental illness, the final dataset included 60 healthy participants (36 females, mean age: 25.2 years, SD: 2.9 years). This aspect of the study was approved by the University of Southampton Ethics Committee. 



### Tasks and stimuli 
  
#### Video acquisition 
  
Eleven native English-speaking students from the University of Southampton acted as targets (8 females, mean age: 20.1 years, SD: 1.64 years). Before filming they were asked to recall a specific autobiographical event (happy, sad, angry or frightened), in which they remembered feeling a strong emotion. Each target wrote a short summary of each event and rated its overall emotional intensity on a 9-point scale (from 1, ‘no emotion’ to 9, ‘very strong emotion’). For the emotional stimuli, only events with a rating of 5 or above were filmed. Each target provided one video clip for each emotion and one clip in which they described their bedroom (neutral condition). An adapted emotion elicitation strategy, which involved imagining being in the situation, was used before filming to reinstate the affective states the targets had felt during the events ( ). They were advised to refrain from making specific reference to their affective state (e.g. happy) but were allowed to use generic descriptions (e.g. upset) or descriptions of bodily symptoms (e.g. shaking). All targets were filmed from the shoulders upwards, in front of a black background, for standardisation purposes. Each clip lasted between 83 and 140 s (mean = 100.3, SD = 15.2). After filming each clip, targets watched the video and continuously rated their emotional intensity using the same 9-point scale as above. Ratings were made by using arrow keys on the keyboard to move a coloured square on the scale (this shifted by one point per button press). Starting point for all ratings was “1”. 

For the fMRI study, the 6 video clips that were selected (one happy, one sad and one neutral video, featuring one female and one male target) were those which received high EA and target expressiveness scores in a pilot study with 13 participants (7 male, mean age: 21.54 years, SD: 2.37 years). A description of the target&#x27;s gender, the emotional condition, the clip length and the target&#x27;s rating of emotional intensity experienced during each clip is presented in  . For pre-training and volume adjustment, one additional sad, one neutral and two happy clips were added (depicting different targets from the main experiment). For the data collection outside the MRI scanner, 27 expressive video clips were selected (7 happy clips, 7 sad clips, 3 angry clips, 3 frightened clips and 7 neutral clips) as well as two happy clips and one sad clip for pre-training purposes. The task and instructions for filming stimuli are available on request.   
Video clips displayed in order of presentation during the Empathic Accuracy Task with target&#x27;s gender, emotional condition and length of the video clip and targets&#x27; average ratings of their own emotional intensity. 
  Table 1   


#### Empathic accuracy task (EAT) 
  
Participants were instructed to continuously rate the perceived emotional intensity of the target ( , top) using the same 9-point scale as above (from 1, ‘no emotion’ to 9, ‘very strong emotion’). In the fMRI study, participants used a button box to provide ratings. In the non-imaging study, participants used the computer&#x27;s arrow keys. The default rating at the start of each video clip was no emotion (i.e. rating of 1). Following each clip, participants were asked: (1) which emotion the target felt most strongly (cognitive empathy: options of “happy”, “angry”, “surprised”, “sad”, “frightened” and “no emotion”); and (2) which emotion they themselves felt most strongly (i.e., affective empathy: same response options as above).   
 Schematic representation of the Empathic Accuracy task and continuous rating scale data.   Top: example of a video clip and rating scale in the Empathic Accuracy Task. The target&#x27;s identity has been disguised in this image. Bottom: Illustration of fluctuations in the   target&#x27;s   emotional intensity, as rated by the target (blue) and an example participant&#x27;s ratings (green). An Empathic Accuracy (EA) score was computed by correlating the participant&#x27;s ratings and the target&#x27;s ratings for each video clip. 
  Fig. 1   


#### Interpersonal reactivity index 
  
The Interpersonal Reactivity Index (IRI) is a widely-used self-report questionnaire that measures dispositional empathy using four subscales: fantasy (FS), empathic concern (EC), perspective taking (PT) and personal distress (PD;  ). 


#### Wechsler abbreviated scale of intelligence, Second Edition 
  
The Wechsler Abbreviated Scale of Intelligence, Second Edition (WASI-II;  ) is a widely-used and reliable test of general intelligence. 



### Procedure 
  
#### fMRI study 
  
The EAT was part of the testing protocol of the English and Romanian Adoptees&#x27; Brain Imaging Study (for further details, see  ). Participants gave written informed consent to participate in the study. All participants completed the MINI and WASI-II, and an online survey, which included the IRI. Participants received pre-training on the fMRI tasks prior to the scan, during which they were familiarised with the EAT and the scanning environment. After observing the experimenter demonstrating how to rate one happy clip, participants rated two clips (one sad, one happy) themselves, while lying in a mock scanner. In the actual EAT experiment, participants watched and rated the 6 video clips in a fixed order ( ). The task took approximately 12 min. Participants were reimbursed for around 6 h of their time with a £100 Amazon voucher. 


#### Normative data collection 
  
For the non-scanning study, participants gave written consent to participate. For pre-training, participants first watched the experimenter rate one happy clip before rating two practice video clips themselves. They then watched and rated 27 video clips in randomised presentation order, in a quiet testing room. This lasted approximately 40 min. Participants also completed an online survey, which included the IRI. Participants were reimbursed for their time with a £15 Amazon voucher. 



### Behavioural data analysis 
  
Participants&#x27; and targets&#x27; ratings were analysed using Matlab 8.2.0 (The MathWorks Inc., Natick, Massachusetts, United States) and SPSS (Version 22, IBM Corp., Armonk, New York, United States). All ratings were separated into 2 s bins and one time-weighted average rating was calculated for each bin. We then tested for correlations between the participants&#x27; and targets&#x27; ratings ( , bottom). The resulting Pearson&#x27;s correlation coefficient for each video clip and each participant is referred to as the EA score. As expected, the variance of the ratings was low for neutral clips. EA scores were therefore only calculated for emotional video clips. EA scores were then r-to-Z transformed to allow comparison between correlation coefficients ( ,  ). 

#### Behavioural analysis of fMRI sample 
  
Paired t-tests examined whether Z-transformed EA scores, affective and cognitive empathy scores differed between happy and sad video clips. Moreover, paired t-tests were performed to test for differences in the average ratings of the target&#x27;s emotional intensity between emotional and neutral as well as happy and sad video clips. A paired   t  -test was also used to test whether Z-EA scores differed between video clips that elicited “affect sharing” (participants reported feeling the same emotion as the target) compared to those that did not (participants reported a different emotion or no emotion). In addition, Pearson correlations were conducted to test for relationships between mean Z-EA scores, the IRI subscales and IQ. 


#### Behavioural analysis of normative data sample 
  
To examine whether the video clips presented in the fMRI study induced Z-EA scores comparable to those in the non-scanning sessions, two Pearson correlations were performed within the normative data sample. Considering happy and sad video clips separately, we examined the correlation between Z-EA scores based on the two video clips presented in the scanner and Z-EA scores based on all seven video clips from the respective emotional category. Moreover, intra-individual standard deviations were calculated based on (1) the four emotional video clips presented in the scanner and (2) all 20 emotional video clips. These were then compared with a paired   t  -test. 



### fMRI data acquisition 
  
Functional images were acquired on a General Electric MR750 3.0 T MR scanner with a 12-channel head coil. A T2*-weighted gradient echo, echo-planar imaging sequence was used, which covered 41 axial slices and recorded 347 vol acquired sequentially, descending (TR/TE 2000/30 ms, flip angle 75°, 64 × 64 matrix, 3 mm thick, field of view (FoV) = 247 mm). To facilitate fMRI data registration and normalisation, we also acquired a T1-weighted Magnetization Prepared Rapid Gradient Echo MPRAGE image (TR/TE 7312/3.02 ms, flip angle 11°, 256 × 256 matrix, 1.2 mm thick, 196 sagittal slices, FoV = 270 mm). 


### fMRI data analysis 
  
We used SPM12 for pre-processing and subject-level (first level) analyses (Wellcome Department of Cognitive Neurology, Institute for Neurology, London, UK). FSL was utilised for cerebrospinal fluid (CSF) regression and statistical nonparametric permutation inference at the group level (second level) with “randomise” ( ; FMRIB Analysis Research, Oxford Centre for Functional MRI of the Brain, Oxford, UK). 

#### Preprocessing 
  
After reorientation, the EPI files were first slice-time corrected (middle slice as reference). Images were then realigned to the first image and subsequently to the time series mean. The mean EPI image was co-registered to the T1-weighted image to allow for normalisation. The structural files were segmented and the resulting grey matter, white matter and CSF files were used to create a common group-specific template using group-wise DARTEL registration ( ). This template was then employed to normalise the functional EPI files to MNI space. This step simultaneously resampled volumes (1.5 mm isotropic) and applied spatial smoothing (Gaussian FWHM kernel of 8 mm). Finally, for each participant, the time course signal of a CSF mask (top 5% from DARTEL CSF component) was extracted in native space. 


#### Emotional vs neutral video clips 
  
At the first level of analysis, each participant&#x27;s pre-processed data were modelled as a block design using a general linear model framework. We included 3 separate regressors (happy, sad, neutral) encoding the predicted BOLD response associated with video presentation, formed by convolution of the canonical haemodynamic response function (HRF) with boxcars delimiting the video presentation. 

We identified regional estimates of BOLD response associated with watching and rating the video clips. Separate parameter estimates for mean response during the emotional (happy and sad) and neutral category compared to the implicit baseline were produced. At the group level, in a random-effects model, paired t-tests were performed to identify clusters that were differentially activated when watching emotional video clips compared to neutral clips. Moreover, happy and sad clips were compared using paired t-tests. 


#### Intra-individual variation in empathic accuracy 
  
In accordance with  , Z-EA scores for each participant and each video clip were added as parametric modulators at the first level of analysis. On the group level, one sample t-tests were performed, to test whether the BOLD response during emotional video clips was modulated by intra-individual variations in Z-EA scores. 


#### Correlation with emotional intensity ratings 
  
We examined how the BOLD time series correlated with the participant&#x27;s ratings of the target&#x27;s emotional intensity. Scans were split and a model was fitted to each emotional video clip in turn. The continuous ratings of the target&#x27;s emotional intensity for each 2 s bin as rated by the participant were entered as regressors of interest. At the group level, one-sample t-tests assessed whether the relationship between BOLD response and changes in the emotional intensity ratings was significantly observed in any brain region across the group. 


#### Exploratory analysis: impact of affect sharing 
  
To examine differences in BOLD response for video clips that induced affect sharing compared to those that did not, we conducted an exploratory post-hoc analysis. We included the 20 participants who showed affect sharing in response to some, but not all video clips in order to be able to create 3 separate conditions in the first level in a block design (shared, non-shared, neutral). For each participant, emotional videos that induced affect sharing (participants reported to have the same emotion as the target) were included in the shared condition, while emotional videos that did not elicit affect sharing (participants reported to have a different emotion than the target or no emotion) were modelled in the non-shared condition. Separate parameter estimates for mean response during affect shared, non-shared and neutral video clip presentation compared to the implicit baseline were calculated. At the group level, paired t-tests were performed to identify clusters that were differentially activated when watching video clips that induced affect sharing compared to non-shared clips. 


#### Movement, scanner drifts and multiple comparisons correction 
  
As well as the regressors described above, all analyses included seven movement parameters (six standard parameters as well as volume-to-volume movement) as nuisance regressors. For each volume-to-volume movement exceeding 1 mm, an additional regressor was included marking the location of that volume and those immediately adjacent (for a summary of volume-to-volume movement see  ). The CSF regressor was also included as a nuisance regressor. To control for task-related hand movement artefacts, button presses were included as condition of no interest. To investigate the effect of controlling for button presses, we additionally repeated all analyses without including this condition. Moreover, we compared button presses during emotional video clips with button presses during neutral video clips as separate conditions to ensure that activity relating to emotion processing was not partialled out. 

Data were high pass filtered with a threshold of 209 s, which corresponds to twice the length of the longest video clip, to control for scanner drifts. 

Results reported are based on Family-Wise Error (FWE) corrected threshold-free cluster enhancement (TFCE:   p   &lt; 0.05 ( )). For each significant cluster, the peak activations with a minimum inter-peak distance of 20 voxels are reported to account for the wide-spanning clusters found in our analyses. 




## Results 
  
### Behavioural data 
  
#### Behavioural analysis of the fMRI sample 
  
On average, participants had high EA scores (mean   r   = .75, mean intra-individual standard deviation (iSD) = .35, range = .13 to .97). Fisher&#x27;s Z-transformed (Z-)EA scores were slightly, but significantly, lower for sad video clips (mean Z-EA = 0.97, SD = 0.21) than happy ones (mean Z-EA = 1.16, SD = 0.19;   t   (33) = 5.17,   p   &lt; .001). As expected, participants&#x27; average ratings of the target&#x27;s emotional intensity were higher for emotional than for neutral video clips (mean emotional = 5.18, mean neutral = 1.75,   t   (33) = 15.29,   p   &lt; .001), with higher ratings for sad compared to happy ones (mean sad = 5.49, mean happy = 4.87,   t   (33) = 3.02,   p   &lt; .01). 

On average, participants correctly inferred the target&#x27;s emotion in 90.4% of clips (emotion identification, SD = 15.1%), with no difference between happy and sad clips (  t   (33) = −0.33,   p   = .74). They also reported experiencing the same emotion as the target for the majority of the emotional video clips (affect sharing, mean = 72.8%, SD = 28.5%), with a higher degree concordance for sad (mean = 79.4%, SD = 32.8%) compared to happy clips (mean = 66.2%, SD = 31.9%;   t   (33) = 2.5,   p   &lt; .05). 13 participants shared the target&#x27;s emotion in every emotional video clip while one participant did not show affect sharing in any of the clips. For the remaining 20 participants who showed a mix of affect sharing and non-sharing, Z-EA scores did not differ for videos that elicited affect sharing (mean Z-EA = 1.09, SD = .24) compared to those that did not (mean Z-EA = 1.06, SD = .33,   t   (19) = .36,   p   = .72). 

Additionally, we found a positive correlation between participants&#x27; mean Z-EA scores and IRI perspective-taking (  r   = .48,   p   &lt; .01). No significant correlations were found between mean Z-EA scores and the other IRI subscales or estimated IQ (all   ps   &gt; .09). 

Note that while we used Pearson&#x27;s product-moment correlation, alternative methods for assessing agreement are available such as the intraclass correlation coefficient. EA scores derived using this measure were highly correlated (r = 0.89) with Pearson&#x27;s correlations. We chose the latter for two reasons. First, we were able to confirm our findings after partialling out dependency over time of the ratings (data not shown) and second, we wished to maintain compatibility with previous studies using similar tasks that also based estimates of inter-rater agreement on Pearson&#x27;s correlations. 


#### Behavioural analysis of the normative data sample 
  
The analysis showed that the mean Z-EA scores for the video clips presented in the fMRI study were strongly positively correlated with Z-EA scores for the seven clips presented in the normative data study (happy:   r   = .82,   p   &lt; .001; sad:   r   = .77,   p   &lt; .001). Furthermore, the intra-individual standard deviation of the four emotional video clips presented in the scanner (mean iSD = .36) did not differ from the individual standard deviation across all 20 emotional video clips presented outside the scanner (mean iSD = .39,   t   (59) = −1.64,   p   = .11). 



### fMRI data 
  
#### Emotional vs. neutral video clips 
  
Group-level analysis revealed a higher BOLD response during emotional compared to neutral clips in a large cluster spanning multiple regions, with peak activations in bilateral occipital poles and inferior lateral occipital cortex ( a,  ). The cluster included bilateral posterior and anterior superior temporal cortex (STC), as well as bilateral temporal pole (TP), bilateral planum temporale and bilateral posterior temporoparietal junction (pTPJ). Higher activation was also seen in right inferior frontal gyrus (IFG; including pars triangularis and opercularis), with the cluster extending into right anterior insular cortex (AI) and right putamen. A second cluster showed higher activation in supplementary motor area (SMA). While participants were watching neutral compared to emotional video clips, activation was higher in left superior lateral occipital cortex, left posterior cingulate cortex (PCC) and left precuneus. Significant activation was similar, albeit more widespread, when not controlling for button presses (see  ). Moreover, when analysing the button press condition separately for emotional and neutral video clips, no brain regions showed significant differences between both button press conditions.   
 Neural substrates of changes in empathy.   a) Significant brain activations when viewing emotional video clips compared to neutral ones. b) Regions significantly positively (red) and negatively (blue) modulated by variations in empathic accuracy (Z-EA scores). c) top: Brain areas significantly positively correlated over time with the participants&#x27; ratings of the target&#x27;s emotional intensity. bottom: BOLD response (after first level regression) of significant clusters (blue) and participant&#x27;s ratings of the target&#x27;s emotional intensity (green) of one exemplary participant. Key: STC - superior temporal cortex, TP - temporal pole, TPJ - temporoparietal junction, IFG - inferior frontal gyrus, SMA - supplementary motor area, aMCC - anterior midcingulate cortex. 
  Fig. 2     
Significant clusters and their peak activations for the contrasts emotional &gt; neutral video clips and neutral &gt; emotional video clips (threshold-free cluster enhancement   p   &lt; 0.05). 
  Table 2   

To explore differences between the different emotion conditions, we also directly compared happy and sad video clips. Activation in the bilateral STC was higher during happy compared to sad clips, while the right paracingulate gyrus and right precuneus showed higher activation during sad video clips (see   and  ). 


#### Intra-individual variation in empathic accuracy 
  
Participants&#x27; intra-individual variations in Z-EA scores were positively related to activation in clusters spanning the bilateral STC, planum temporale, TP and pTPJ, left hippocampus and left amygdala. Activity in the bilateral inferior lateral occipital cortex and fusiform cortex was also positively related to Z-EA scores ( b,  ). Activation in the bilateral paracingulate gyrus and right frontal pole as well as the right middle frontal gyrus was significantly negatively modulated by Z-EA scores.   
Significant clusters and their peak activations for the modulation of BOLD-response by intra-individual variation of Z-EA scores (threshold-free cluster enhancement   p   &lt; 0.05). 
  Table 3   


#### Correlation with emotional intensity ratings 
  
While watching emotional video clips, participants&#x27; fluctuations in ratings of the targets&#x27; emotional intensity were positively correlated over time with changes in BOLD response in multiple brain regions ( c,  ). Associations were found in multiple clusters including bilateral posterior STC, bilateral TP, bilateral IFG (including pars triangularis and opercularis), bilateral SMA, bilateral middle and superior frontal cortices, right anterior midcingulate cortex (aMCC), right AI, bilateral amygdala, bilateral putamen as well as pTPJ and right temporal occipital and anterior temporal fusiform cortex. Emotional intensity ratings and BOLD-response were negatively correlated in the in the bilateral superior lateral occipital cortex, PCC, and precuneus.   shows a binarised overlay of significant clusters in the different analyses.   
Binarised overlay of activations related to a) emotional compared to neutral video clips, b) variation positively related to empathic accuracy and c) positive correlation with emotional intensity. 
  Fig. 3     
Significant clusters and their peak activations for the correlation between BOLD-response and the participants&#x27; ratings of the target&#x27;s emotional intensity (threshold-free cluster enhancement   p   &lt; 0.05). 
  Table 4   


#### Exploratory analysis: impact of affect sharing 
  
For emotional video clips, there were no significant differences in BOLD response between clips that elicited, versus those that did not elicit, affect sharing (i.e. participants reported experiencing the same emotion as the target after providing their continuous ratings). 




## Discussion 
  
We used a modified version of the EAT to study neural substrates of empathic accuracy and to gain a better understanding of its underlying components. We demonstrated that fluctuations in participants&#x27; perceived emotional intensity ratings are correlated with activation in a network of brain regions previously implicated in empathy and broader aspects of social cognition (i.e., mentalising). More specifically, consistent with our first hypothesis, we observed increased activation in brain regions associated with empathy and mentalising when participants watched emotional compared to neutral clips. Supporting our second hypothesis, we found a positive correlation between intra-individual variations in empathic accuracy and the temporal lobe, “mentalising” regions of the same network. Confirming our third hypothesis, we found a correlation between fluctuations in ratings of the targets&#x27; perceived emotional intensity over time and activity in these same regions. This network of brain regions appears not only to have a general role in emotion and empathic processing but is also sensitive to   variations   in the intensity of others&#x27; emotions. 

The superior temporal sulcus (STS), temporoparietal junction (TPJ), and temporal pole (TP) have consistently been associated with mentalising ( ). In our study, these areas were more active with higher EA, i.e. when participants were more accurate at tracking the target&#x27;s emotion. Beyond this, we could also show these regions are sensitive to fluctuations in perceived emotional intensity of others. The STS is thought to facilitate mentalising by interpreting social aspects of observed biological motion ( ,  ) and the region has been implicated in EA ( ,  ). The TPJ is involved in inferring other people&#x27;s temporary mental states ( ) while the TP&#x27;s role in mentalising is thought to involve the integration of multimodal information and recollection of social scripts ( ;  ). Combined, these brain regions are involved in distinct emotional and cognitive processes that are required to perform our modified EAT: they are integral for the successful tracking of others&#x27; emotional intensity and correlate positively with intra-individual variations in EA. 

The anterior insula (AI), anterior midcingulate cortex (aMCC), inferior frontal gyrus (IFG) and supplementary motor area (SMA) have previously been implicated in empathy tasks and are associated with the affect sharing component of empathy (or affective empathy) ( ). Together these regions are implicated in the emotional processing of the modified EAT stimuli. Most importantly, we could show for the first time that their activity tracks the perceived emotional intensity of others. However, activity in these brain regions was not sensitive to changes in EA and thus seems more tied to the subjective perception of other&#x27;s feelings. 

This suggests it is the time-series variation in activation in the temporal lobe regions (STS, TPJ, TP) that might be informative for accurately tracking other people&#x27;s emotions, while activation in the frontal regions (AI, ACC, IFG, SMA) represents a different emotion processing component that does not vary with changes in EA ( ). This is consistent with previous studies on EA, which showed either no correlation between EA and activity in the above frontal regions ( ) or, in the case of adolescents, a negative correlation between EA and ACC and AI activation ( ). Furthermore, we could not replicate an association between EA and activity in the inferior parietal lobe, a region implicated in motor imitation and previously interpreted as an affective processing component of EA ( ). Taken together, these findings provide evidence that EA is more closely related to the concept of cognitive empathy and mentalising than affective empathy and emotion sharing. The role of EA in cognitive but not affective empathy is further supported by the positive correlation between EA scores and the perspective-taking scale of a well-established self-report measure of empathy (the IRI) but not with other more affective subscales such as empathic concern. Moreover, participants&#x27; average EA scores did not differ between videos where they shared the same emotion as the target compared to those were they did not, which again suggests that emotion sharing is neither necessary for, nor facilitates, EA. 

Even if EA does only relate to cognitive but not affective empathy, the EAT as a task successfully elicited affective empathy in most of our participants – they reported sharing the target&#x27;s emotion in 73% of the emotional video clips. However, there were no significant differences in brain activity when rating videos where participants shared the same emotion compared to videos where they did not. This further supports our hypothesis that the higher activation in aMCC, AI, SMA and IFG during emotional clips is associated with more basal, empathy-independent aspects of emotion processing. 

Higher activation of the bilateral STS could also be seen during happy compared to sad video clips, while the right paracingulate gyrus was more highly activated during sad video clips. This is in line with our behavioural findings of, on average, higher EA scores during happy video clips, which suggest more successful tracking and mentalising of the target&#x27;s emotion, while sad video clips induced higher rates of affect sharing among participants. The paracingulate gyrus has previously been implicated in affective empathy ( ). 

During the modified EAT, participants rated fluctuations in emotional intensity rather than valence as this allowed a comparable rating scale across different distinct emotions. Furthermore, previous literature suggests distinct neural correlates for processing emotional intensity and valence ( ), with the amygdala being associated with intensity and the orbitofrontal cortex with valence. In agreement with this, we found that bilateral activation of amygdala but not the orbitofrontal cortex covaried with the emotional intensity of the targets. Unexpectedly activation in the precuneus – a region implicated in self-referential processing ( ) – was stronger during neutral versus emotional clips and correlated negatively with emotional intensity ratings. The precuneus is associated with visual-spatial imagery ( ,  ) and is a component of the default mode network ( ). Higher activation during the neutral videos in which participants described their bedroom, might be explained by higher visual-spatial imagery and an increased tendency for mind-wandering during these less engaging parts of the task ( ). 

Empathy is a complex and dynamic process, which requires multiple higher order functions ( ) such as emotion recognition, multimodal sensory integration, self-other distinction and continuous processing of valence and intensity information. Compared to other commonly used empathy tasks, the modified EAT used a more naturalistic setting to examine which brain regions track fluctuations over time in perceived emotional intensity of others and intra-individual variations in empathic accuracy. Previous studies in the empathy and mentalising literature have largely focused on simplistic stimuli (e.g. static images of hands in painful situations). Compared to these earlier studies, we found that regions that have been separately implicated in mentalising and empathy were all involved in performing the modified EAT. However, only brain regions previously associated with mentalising were found to covary with EA, while regions previously implicated in classic affective empathy paradigms were positively correlated with the emotional intensity of others but were not sensitive to changes in EA. In this more naturalistic and complex task, it seems that an interplay between brain networks associated with mentalising and empathy enables the accurate tracking of other&#x27;s emotions. Furthermore, these regions were sensitive to fluctuations in perceived emotional intensity of others, which serves as a potential mechanism for successful communication between these networks to achieve empathic accuracy. 

A possible limitation of our study was the lower number of emotional video clips in comparison to previous studies on EA ( ,  ). This study was conducted within the framework of a larger project, and thus the scanning time was limited. However, we showed that our chosen video clips led to very similar EA scores relative to those obtained with the larger dataset of 27 video clips in the norm sample. More importantly, the intra-individual variation across videos was also comparable to that seen for the full set of video clips. 

The study had a number of strengths. The original EAT ( ) represented an important advance in empathy research, as it was the first task to utilise naturalistic stimuli and assess EA in an fMRI context. In this modified EAT, the stimuli used for fMRI purposes had been validated in a separate behavioural study. Moreover, we added a neutral control condition, which allowed us to identify brain regions that are generally more active during emotional video clips irrespective of empathic accuracy. Future studies could employ this paradigm to study psychiatric populations with empathy deficits (e.g., adolescents with Conduct Disorder;  ). By additionally taking the neutral control condition into account, one could examine whether emotional clips were ‘neutral-like’ in those with low EA scores. For future studies, it would be worth considering incorporating neutral videos with varying topics other than bedroom descriptions to ensure continued engagement throughout the task (see   for possible examples). Furthermore, we introduced the measurement of emotional intensity rather than valence, which is more closely related to the concept of empathy. This also made the video clips of different emotions comparable and allowed a more fine-grained analysis of changes over time in activation related to the emotional intensity of others. Together, we propose that the three analysis techniques used in this study, should be employed in conjunction to allow a comprehensive study of empathic accuracy and its different components. 

In conclusion, we provide the first evidence that the modified EAT is a suitable paradigm for studying empathy and its underlying components. We show that, while the modified EAT successfully induces both affective and cognitive empathy, EA relies more on cognitive empathy than affect sharing. The neutral control condition and the valence-independent rating scale represent valuable additions to the task. The fMRI data analysis techniques developed and described here may prove valuable in characterising differences between healthy participants and participants with psychiatric conditions associated with empathy deficits. 


## Funding 
  
This work was funded by a project grant from the   to ESB, MM and GF (MR/K022474/1). 


## Declaration of interest 
  
We do not have any financial, institutional or other relationships that might lead to a conflict of interest.</pre></details></details>
  <details class="inner-accordion"><summary>Coordinate-relevant source tables (3)</summary><details class="inner-accordion"><summary>Table 2 (tbl2) - Significant clusters and their peak activations for the contrasts emotional &gt; neutral video clips and neutral &gt; emotional video clips (threshold-free cluster enhancement pFWE &lt; 0.05).</summary><div class="table-html"><table-wrap id="tbl2" position="float" orientation="portrait"><label>Table 2</label><caption><p>Significant clusters and their peak activations for the contrasts emotional &gt; neutral video clips and neutral &gt; emotional video clips (threshold-free cluster enhancement <italic toggle="yes">p</italic><sub>FWE</sub> &lt; 0.05).</p></caption><alt-text id="alttext0035">Table 2</alt-text><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" colspan="1">Cluster</th><th rowspan="2" colspan="1">Anatomical region</th><th rowspan="2" colspan="1">Hemisphere</th><th rowspan="2" colspan="1">Cluster size</th><th colspan="3" rowspan="1">MNI coordinates [mm]<hr /></th><th rowspan="2" colspan="1">Peak-level <italic toggle="yes">t</italic></th></tr><tr><th colspan="1" rowspan="1">x</th><th colspan="1" rowspan="1">y</th><th colspan="1" rowspan="1">z</th></tr></thead><tbody><tr><td colspan="8" align="left" rowspan="1"><bold>emotional &gt; neutral video clips</bold><hr /></td></tr><tr><td rowspan="11" align="left" colspan="1">1</td><td align="left" colspan="1" rowspan="1">Occipital Pole</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">9901</td><td align="left" colspan="1" rowspan="1">20</td><td align="left" colspan="1" rowspan="1">−94</td><td align="left" colspan="1" rowspan="1">−2</td><td align="left" colspan="1" rowspan="1">7.33</td></tr><tr><td align="left" colspan="1" rowspan="1">Inferior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−32</td><td align="left" colspan="1" rowspan="1">−90</td><td align="left" colspan="1" rowspan="1">−6</td><td align="left" colspan="1" rowspan="1">6.86</td></tr><tr><td align="left" colspan="1" rowspan="1">Anterior Superior Temporal Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">52</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">−18</td><td align="left" colspan="1" rowspan="1">6.21</td></tr><tr><td align="left" colspan="1" rowspan="1">Occipital Pole</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−16</td><td align="left" colspan="1" rowspan="1">−94</td><td align="left" colspan="1" rowspan="1">12</td><td align="left" colspan="1" rowspan="1">5.94</td></tr><tr><td align="left" colspan="1" rowspan="1">Inferior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">40</td><td align="left" colspan="1" rowspan="1">−70</td><td align="left" colspan="1" rowspan="1">−4</td><td align="left" colspan="1" rowspan="1">5.1</td></tr><tr><td align="left" colspan="1" rowspan="1">Posterior Superior Temporal Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">56</td><td align="left" colspan="1" rowspan="1">−28</td><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">4.57</td></tr><tr><td align="left" colspan="1" rowspan="1">Insular Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">28</td><td align="left" colspan="1" rowspan="1">16</td><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">4.39</td></tr><tr><td align="left" colspan="1" rowspan="1">Temporal Occipital Fusiform Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">40</td><td align="left" colspan="1" rowspan="1">−50</td><td align="left" colspan="1" rowspan="1">−16</td><td align="left" colspan="1" rowspan="1">4.15</td></tr><tr><td align="left" colspan="1" rowspan="1">Frontal Operculum Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">48</td><td align="left" colspan="1" rowspan="1">16</td><td align="left" colspan="1" rowspan="1">0</td><td align="left" colspan="1" rowspan="1">4.02</td></tr><tr><td align="left" colspan="1" rowspan="1">Occipital Fusiform Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−36</td><td align="left" colspan="1" rowspan="1">−70</td><td align="left" colspan="1" rowspan="1">−16</td><td align="left" colspan="1" rowspan="1">4.01</td></tr><tr><td align="left" colspan="1" rowspan="1">Occipital Pole</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−10</td><td align="left" colspan="1" rowspan="1">−100</td><td align="left" colspan="1" rowspan="1">−14</td><td align="left" colspan="1" rowspan="1">3.44</td></tr><tr><td rowspan="4" align="left" colspan="1">2</td><td align="left" colspan="1" rowspan="1">Anterior Superior Temporal Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">2243</td><td align="left" colspan="1" rowspan="1">−52</td><td align="left" colspan="1" rowspan="1">−6</td><td align="left" colspan="1" rowspan="1">−14</td><td align="left" colspan="1" rowspan="1">5.32</td></tr><tr><td align="left" colspan="1" rowspan="1">Posterior Supramarginal Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−56</td><td align="left" colspan="1" rowspan="1">−44</td><td align="left" colspan="1" rowspan="1">14</td><td align="left" colspan="1" rowspan="1">4.45</td></tr><tr><td align="left" colspan="1" rowspan="1">Middle Temporal Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−44</td><td align="left" colspan="1" rowspan="1">−32</td><td align="left" colspan="1" rowspan="1">−2</td><td align="left" colspan="1" rowspan="1">3.85</td></tr><tr><td align="left" colspan="1" rowspan="1">Planum Temporale</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−60</td><td align="left" colspan="1" rowspan="1">−20</td><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">3.48</td></tr><tr><td align="left" colspan="1" rowspan="1">3</td><td align="left" colspan="1" rowspan="1">Supplementary Motor Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">250</td><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">60</td><td align="left" colspan="1" rowspan="1">5.04</td></tr><tr><td align="left" colspan="1" rowspan="1">4<hr /></td><td align="left" colspan="1" rowspan="1">Temporal Pole<hr /></td><td align="left" colspan="1" rowspan="1">L<hr /></td><td align="left" colspan="1" rowspan="1">6<hr /></td><td align="left" colspan="1" rowspan="1">−46<hr /></td><td align="left" colspan="1" rowspan="1">18<hr /></td><td align="left" colspan="1" rowspan="1">−26<hr /></td><td align="left" colspan="1" rowspan="1">3.53<hr /></td></tr><tr><td colspan="8" align="left" rowspan="1"><bold>neutral &gt; emotional video clips</bold><hr /></td></tr><tr><td align="left" colspan="1" rowspan="1">1</td><td align="left" colspan="1" rowspan="1">Superior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">1014</td><td align="left" colspan="1" rowspan="1">−34</td><td align="left" colspan="1" rowspan="1">−80</td><td align="left" colspan="1" rowspan="1">40</td><td align="left" colspan="1" rowspan="1">6.59</td></tr><tr><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">Superior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−44</td><td align="left" colspan="1" rowspan="1">−84</td><td align="left" colspan="1" rowspan="1">22</td><td align="left" colspan="1" rowspan="1">5.86</td></tr><tr><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">Posterior Cingulate Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">207</td><td align="left" colspan="1" rowspan="1">−4</td><td align="left" colspan="1" rowspan="1">−38</td><td align="left" colspan="1" rowspan="1">40</td><td align="left" colspan="1" rowspan="1">8.99</td></tr><tr><td align="left" colspan="1" rowspan="1">3</td><td align="left" colspan="1" rowspan="1">Precuneus Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">86</td><td align="left" colspan="1" rowspan="1">−14</td><td align="left" colspan="1" rowspan="1">−60</td><td align="left" colspan="1" rowspan="1">14</td><td align="left" colspan="1" rowspan="1">6.2</td></tr><tr><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">Superior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">54</td><td align="left" colspan="1" rowspan="1">36</td><td align="left" colspan="1" rowspan="1">−76</td><td align="left" colspan="1" rowspan="1">42</td><td align="left" colspan="1" rowspan="1">5.32</td></tr><tr><td align="left" colspan="1" rowspan="1">5</td><td align="left" colspan="1" rowspan="1">Lingual Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">34</td><td align="left" colspan="1" rowspan="1">−38</td><td align="left" colspan="1" rowspan="1">−10</td><td align="left" colspan="1" rowspan="1">5.49</td></tr><tr><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">Planum Temporale</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">30</td><td align="left" colspan="1" rowspan="1">−30</td><td align="left" colspan="1" rowspan="1">−20</td><td align="left" colspan="1" rowspan="1">5.46</td></tr></tbody></table></table-wrap></div></details><details class="inner-accordion"><summary>Table 3 (tbl3) - Significant clusters and their peak activations for the modulation of BOLD-response by intra-individual variation of Z-EA scores (threshold-free cluster enhancement pFWE &lt; 0.05).</summary><div class="table-html"><table-wrap id="tbl3" position="float" orientation="portrait"><label>Table 3</label><caption><p>Significant clusters and their peak activations for the modulation of BOLD-response by intra-individual variation of Z-EA scores (threshold-free cluster enhancement <italic toggle="yes">p</italic><sub>FWE</sub> &lt; 0.05).</p></caption><alt-text id="alttext0040">Table 3</alt-text><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" colspan="1">Cluster</th><th rowspan="2" colspan="1">Anatomical region</th><th rowspan="2" colspan="1">Hemisphere</th><th rowspan="2" colspan="1">Cluster size</th><th colspan="3" rowspan="1">MNI coordinates [mm]<hr /></th><th rowspan="2" colspan="1">Peak-level <italic toggle="yes">t</italic></th></tr><tr><th colspan="1" rowspan="1">x</th><th colspan="1" rowspan="1">y</th><th colspan="1" rowspan="1">z</th></tr></thead><tbody><tr><td colspan="8" align="left" rowspan="1"><bold>Positively related to Z-EA scores</bold><hr /></td></tr><tr><td rowspan="7" align="left" colspan="1">1</td><td align="left" colspan="1" rowspan="1">Posterior Superior Temporal Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">9036</td><td align="left" colspan="1" rowspan="1">−62</td><td align="left" colspan="1" rowspan="1">−26</td><td align="left" colspan="1" rowspan="1">10</td><td align="left" colspan="1" rowspan="1">9.88</td></tr><tr><td align="left" colspan="1" rowspan="1">Planum Temporale</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−38</td><td align="left" colspan="1" rowspan="1">−34</td><td align="left" colspan="1" rowspan="1">14</td><td align="left" colspan="1" rowspan="1">9.17</td></tr><tr><td align="left" colspan="1" rowspan="1">Temporal Pole</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−54</td><td align="left" colspan="1" rowspan="1">−2</td><td align="left" colspan="1" rowspan="1">−2</td><td align="left" colspan="1" rowspan="1">7.02</td></tr><tr><td align="left" colspan="1" rowspan="1">Hippocampus</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−20</td><td align="left" colspan="1" rowspan="1">−14</td><td align="left" colspan="1" rowspan="1">−20</td><td align="left" colspan="1" rowspan="1">6.50</td></tr><tr><td align="left" colspan="1" rowspan="1">Inferior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−44</td><td align="left" colspan="1" rowspan="1">−72</td><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">6.03</td></tr><tr><td align="left" colspan="1" rowspan="1">Posterior Temporal Fusiform Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−38</td><td align="left" colspan="1" rowspan="1">−42</td><td align="left" colspan="1" rowspan="1">−26</td><td align="left" colspan="1" rowspan="1">4.67</td></tr><tr><td align="left" colspan="1" rowspan="1">Occipital Fusiform Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−20</td><td align="left" colspan="1" rowspan="1">−90</td><td align="left" colspan="1" rowspan="1">−18</td><td align="left" colspan="1" rowspan="1">4.61</td></tr><tr><td rowspan="2" align="left" colspan="1">2</td><td align="left" colspan="1" rowspan="1">Planum Temporale</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">2421</td><td align="left" colspan="1" rowspan="1">64</td><td align="left" colspan="1" rowspan="1">−16</td><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">7.37</td></tr><tr><td align="left" colspan="1" rowspan="1">Planum Temporale</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">34</td><td align="left" colspan="1" rowspan="1">−28</td><td align="left" colspan="1" rowspan="1">14</td><td align="left" colspan="1" rowspan="1">4.93</td></tr><tr><td rowspan="2" align="left" colspan="1">3<hr /></td><td align="left" colspan="1" rowspan="1">Inferior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">2315</td><td align="left" colspan="1" rowspan="1">46</td><td align="left" colspan="1" rowspan="1">−66</td><td align="left" colspan="1" rowspan="1">0</td><td align="left" colspan="1" rowspan="1">7.80</td></tr><tr><td align="left" colspan="1" rowspan="1">Occipital Fusiform Cortex<hr /></td><td align="left" colspan="1" rowspan="1">R<hr /></td><td colspan="1" rowspan="1"><hr /></td><td align="left" colspan="1" rowspan="1">22<hr /></td><td align="left" colspan="1" rowspan="1">−88<hr /></td><td align="left" colspan="1" rowspan="1">−8<hr /></td><td align="left" colspan="1" rowspan="1">5.37<hr /></td></tr><tr><td colspan="8" align="left" rowspan="1"><bold>Negatively related to Z-EA scores</bold><hr /></td></tr><tr><td rowspan="3" align="left" colspan="1">1</td><td align="left" colspan="1" rowspan="1">Paracingulate Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">275</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">22</td><td align="left" colspan="1" rowspan="1">48</td><td align="left" colspan="1" rowspan="1">4.11</td></tr><tr><td align="left" colspan="1" rowspan="1">Frontal Pole</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">10</td><td align="left" colspan="1" rowspan="1">62</td><td align="left" colspan="1" rowspan="1">36</td><td align="left" colspan="1" rowspan="1">4.01</td></tr><tr><td align="left" colspan="1" rowspan="1">Paracingulate Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−6</td><td align="left" colspan="1" rowspan="1">44</td><td align="left" colspan="1" rowspan="1">30</td><td align="left" colspan="1" rowspan="1">3.81</td></tr><tr><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">Middle Frontal Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">31</td><td align="left" colspan="1" rowspan="1">36</td><td align="left" colspan="1" rowspan="1">14</td><td align="left" colspan="1" rowspan="1">32</td><td align="left" colspan="1" rowspan="1">4.42</td></tr></tbody></table></table-wrap></div></details><details class="inner-accordion"><summary>Table 4 (tbl4) - Significant clusters and their peak activations for the correlation between BOLD-response and the participants&#x27; ratings of the target&#x27;s emotional intensity (threshold-free cluster enhancement pFWE &lt; 0.05).</summary><div class="table-html"><table-wrap id="tbl4" position="float" orientation="portrait"><label>Table 4</label><caption><p>Significant clusters and their peak activations for the correlation between BOLD-response and the participants' ratings of the target's emotional intensity (threshold-free cluster enhancement <italic toggle="yes">p</italic><sub>FWE</sub> &lt; 0.05).</p></caption><alt-text id="alttext0045">Table 4</alt-text><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" colspan="1">Cluster</th><th rowspan="2" colspan="1">Anatomical region</th><th rowspan="2" colspan="1">Hemisphere</th><th rowspan="2" colspan="1">Cluster size</th><th colspan="3" rowspan="1">MNI coordinates [mm]<hr /></th><th rowspan="2" colspan="1">Peak-level <italic toggle="yes">t</italic></th></tr><tr><th colspan="1" rowspan="1">x</th><th colspan="1" rowspan="1">y</th><th colspan="1" rowspan="1">z</th></tr></thead><tbody><tr><td colspan="8" align="left" rowspan="1"><bold>Positive correlation with participants' emotional intensity ratings</bold><hr /></td></tr><tr><td rowspan="17" align="left" colspan="1">1</td><td align="left" colspan="1" rowspan="1">Posterior Superior Temporal Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">24492</td><td align="left" colspan="1" rowspan="1">58</td><td align="left" colspan="1" rowspan="1">−16</td><td align="left" colspan="1" rowspan="1">0</td><td align="left" colspan="1" rowspan="1">9.56</td></tr><tr><td align="left" colspan="1" rowspan="1">Posterior Middle Frontal Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">62</td><td align="left" colspan="1" rowspan="1">−36</td><td align="left" colspan="1" rowspan="1">0</td><td align="left" colspan="1" rowspan="1">8.26</td></tr><tr><td align="left" colspan="1" rowspan="1">Temporal Pole</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">58</td><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">−16</td><td align="left" colspan="1" rowspan="1">8.19</td></tr><tr><td align="left" colspan="1" rowspan="1">Planum Temporale</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−64</td><td align="left" colspan="1" rowspan="1">−14</td><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">8.05</td></tr><tr><td align="left" colspan="1" rowspan="1">Putamen</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">26</td><td align="left" colspan="1" rowspan="1">−92</td><td align="left" colspan="1" rowspan="1">−6</td><td align="left" colspan="1" rowspan="1">7.4</td></tr><tr><td align="left" colspan="1" rowspan="1">Temporal Pole</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−56</td><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">−10</td><td align="left" colspan="1" rowspan="1">7.04</td></tr><tr><td align="left" colspan="1" rowspan="1">Middle Frontal Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">48</td><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">38</td><td align="left" colspan="1" rowspan="1">6.92</td></tr><tr><td align="left" colspan="1" rowspan="1">Middle Temporal Gyrus, temporooccipital part</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">46</td><td align="left" colspan="1" rowspan="1">−56</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">6.49</td></tr><tr><td align="left" colspan="1" rowspan="1">Temporal Occipital Fusiform Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">40</td><td align="left" colspan="1" rowspan="1">−46</td><td align="left" colspan="1" rowspan="1">−16</td><td align="left" colspan="1" rowspan="1">6.06</td></tr><tr><td align="left" colspan="1" rowspan="1">Temporal Occipital Fusiform Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−46</td><td align="left" colspan="1" rowspan="1">−64</td><td align="left" colspan="1" rowspan="1">−28</td><td align="left" colspan="1" rowspan="1">5.7</td></tr><tr><td align="left" colspan="1" rowspan="1">Insular Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">38</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">−20</td><td align="left" colspan="1" rowspan="1">5.49</td></tr><tr><td align="left" colspan="1" rowspan="1">Middle Temporal Gyrus, temporooccipital part</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−64</td><td align="left" colspan="1" rowspan="1">−44</td><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">5.31</td></tr><tr><td align="left" colspan="1" rowspan="1">Inferior Frontal Gyrus, pars triangularis</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">56</td><td align="left" colspan="1" rowspan="1">28</td><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">5.04</td></tr><tr><td align="left" colspan="1" rowspan="1">Temporal Pole</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−44</td><td align="left" colspan="1" rowspan="1">20</td><td align="left" colspan="1" rowspan="1">−26</td><td align="left" colspan="1" rowspan="1">4.93</td></tr><tr><td align="left" colspan="1" rowspan="1">Occipital Fusiform Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−30</td><td align="left" colspan="1" rowspan="1">−82</td><td align="left" colspan="1" rowspan="1">−18</td><td align="left" colspan="1" rowspan="1">4.87</td></tr><tr><td align="left" colspan="1" rowspan="1">Planum Temporale</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−40</td><td align="left" colspan="1" rowspan="1">−36</td><td align="left" colspan="1" rowspan="1">10</td><td align="left" colspan="1" rowspan="1">4.84</td></tr><tr><td align="left" colspan="1" rowspan="1">Amygdala</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−18</td><td align="left" colspan="1" rowspan="1">−6</td><td align="left" colspan="1" rowspan="1">−14</td><td align="left" colspan="1" rowspan="1">4.78</td></tr><tr><td rowspan="2" align="left" colspan="1">2</td><td align="left" colspan="1" rowspan="1">Supplementary Motor Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">1735</td><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">66</td><td align="left" colspan="1" rowspan="1">6.85</td></tr><tr><td align="left" colspan="1" rowspan="1">Anterior Midcingulate Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">14</td><td align="left" colspan="1" rowspan="1">38</td><td align="left" colspan="1" rowspan="1">3.74</td></tr><tr><td rowspan="2" align="left" colspan="1">3</td><td align="left" colspan="1" rowspan="1">Precentral Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">1714</td><td align="left" colspan="1" rowspan="1">−40</td><td align="left" colspan="1" rowspan="1">−8</td><td align="left" colspan="1" rowspan="1">56</td><td align="left" colspan="1" rowspan="1">5.64</td></tr><tr><td align="left" colspan="1" rowspan="1">Superior Frontal Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−24</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">72</td><td align="left" colspan="1" rowspan="1">4.96</td></tr><tr><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">Postcentral Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">206</td><td align="left" colspan="1" rowspan="1">−48</td><td align="left" colspan="1" rowspan="1">−26</td><td align="left" colspan="1" rowspan="1">40</td><td align="left" colspan="1" rowspan="1">4.05</td></tr><tr><td align="left" colspan="1" rowspan="1">5<hr /></td><td align="left" colspan="1" rowspan="1">Putamen<hr /></td><td align="left" colspan="1" rowspan="1">R<hr /></td><td align="left" colspan="1" rowspan="1">173<hr /></td><td align="left" colspan="1" rowspan="1">18<hr /></td><td align="left" colspan="1" rowspan="1">10<hr /></td><td align="left" colspan="1" rowspan="1">6<hr /></td><td align="left" colspan="1" rowspan="1">4.67<hr /></td></tr><tr><td colspan="8" align="left" rowspan="1"><bold>Negative correlation with participants' emotional intensity ratings</bold><hr /></td></tr><tr><td rowspan="7" align="left" colspan="1">1</td><td align="left" colspan="1" rowspan="1">Cuneus Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">10193</td><td align="left" colspan="1" rowspan="1">10</td><td align="left" colspan="1" rowspan="1">−86</td><td align="left" colspan="1" rowspan="1">24</td><td align="left" colspan="1" rowspan="1">6.42</td></tr><tr><td align="left" colspan="1" rowspan="1">Posterior Cingulate Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">−34</td><td align="left" colspan="1" rowspan="1">38</td><td align="left" colspan="1" rowspan="1">5.48</td></tr><tr><td align="left" colspan="1" rowspan="1">Precuneus Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−4</td><td align="left" colspan="1" rowspan="1">−66</td><td align="left" colspan="1" rowspan="1">16</td><td align="left" colspan="1" rowspan="1">5.3</td></tr><tr><td align="left" colspan="1" rowspan="1">Superior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">38</td><td align="left" colspan="1" rowspan="1">−74</td><td align="left" colspan="1" rowspan="1">22</td><td align="left" colspan="1" rowspan="1">5.25</td></tr><tr><td align="left" colspan="1" rowspan="1">Precuneus Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−12</td><td align="left" colspan="1" rowspan="1">−58</td><td align="left" colspan="1" rowspan="1">34</td><td align="left" colspan="1" rowspan="1">4.82</td></tr><tr><td align="left" colspan="1" rowspan="1">Lingual Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">26</td><td align="left" colspan="1" rowspan="1">−52</td><td align="left" colspan="1" rowspan="1">−4</td><td align="left" colspan="1" rowspan="1">4.66</td></tr><tr><td align="left" colspan="1" rowspan="1">Superior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">44</td><td align="left" colspan="1" rowspan="1">−64</td><td align="left" colspan="1" rowspan="1">46</td><td align="left" colspan="1" rowspan="1">3.99</td></tr><tr><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">Superior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">466</td><td align="left" colspan="1" rowspan="1">−38</td><td align="left" colspan="1" rowspan="1">−70</td><td align="left" colspan="1" rowspan="1">32</td><td align="left" colspan="1" rowspan="1">4.69</td></tr><tr><td align="left" colspan="1" rowspan="1">3</td><td align="left" colspan="1" rowspan="1">Temporal Occipital Fusiform Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">121</td><td align="left" colspan="1" rowspan="1">−24</td><td align="left" colspan="1" rowspan="1">−56</td><td align="left" colspan="1" rowspan="1">−12</td><td align="left" colspan="1" rowspan="1">3.23</td></tr><tr><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">Superior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">32</td><td align="left" colspan="1" rowspan="1">−50</td><td align="left" colspan="1" rowspan="1">−74</td><td align="left" colspan="1" rowspan="1">26</td><td align="left" colspan="1" rowspan="1">3.77</td></tr></tbody></table></table-wrap></div></details></details>
</details>


<details class="doc-card">
  <summary><strong>PMID 30349467</strong> | Pred included: 7 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=2, unmatched=3</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/30349467/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Activations: Leading &gt; Following (Followers only); others, Activations: Leading &gt; Following (Whole-group); others, Deactivations: Following &gt; Leading (Whole-group); others</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>30349467_analysis_0</td><td>Leaders only (n = 11)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves dyadic joint action (leading vs following) which requires perceiving, interpreting, and responding to social information; contrasts probe role-related social processes and authors discuss recruitment of social/mentalizing networks (TPJ, PCC, mPFC).</td></tr>
<tr><td>30349467_analysis_1</td><td>Followers only (n = 10)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is a joint-action social interaction (leading vs following) and contrasts/regressions specifically probe social processing (mentalizing, TPJ, pSTS, mPFC, PCC) tied to perception/response to social cues; thus both I1 and I2 are satisfied.</td></tr>
<tr><td>30349467_analysis_2</td><td>Activations: Leading &gt; Following</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The task involves naturalistic two-person interaction (leading vs following) and the contrasts probe recruitment of social/mentalizing networks (TPJ, PCC, mPFC, pSTS), so it measures social processing.</td></tr>
<tr><td>30349467_analysis_3</td><td>Deactivations: Following &gt; Leading</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task involves naturalistic joint action with explicit social interaction (leader–follower signaling, mentalizing) and the contrast measures social processing (following vs leading).</td></tr>
<tr><td>30349467_analysis_4</td><td>Activation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task involves interactive joint action (leader vs follower) and the contrast probes social interaction processes; brain regions and regressions relate to social/mentalizing networks for roles. Satisfies social-related task and measures social processing.</td></tr>
<tr><td>30349467_analysis_5</td><td>Deactivation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The task is a dyadic joint-action (leading vs following) and the analysis tests how brain activity during this social interaction covaries with leader expertise; this measures social processing of interaction roles.</td></tr>
<tr><td>30349467_analysis_6</td><td>Leading versus following correlated with skill as a follower.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The task is an interactive joint-action involving leader/follower roles and the reported activations and regressions implicate mentalizing/social networks (TPJ, mPFC, PCC, pSTS). The contrast examines social interaction and processing of others’ actions; it therefore meets inclusion I1 (social-related task) and I2 (measures social processing).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>30349467_1</td><td>Activations: Leading &gt; Following (Followers only); others</td><td>30349467_analysis_6</td><td>Leading versus following correlated with skill as a follower.</td><td>0.491</td><td>0.000</td><td>0.147</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>30349467_2</td><td>Activations: Leading &gt; Following (Leaders only); others</td><td>30349467_analysis_2</td><td>Activations: Leading &gt; Following</td><td>0.810</td><td>0.529</td><td>0.614</td><td>uncertain</td><td>coord_count_mismatch</td></tr><tr><td>30349467_3</td><td>Activations: Leading &gt; Following (Whole-group); others</td><td>30349467_analysis_4</td><td>Activation</td><td>0.357</td><td>0.000</td><td>0.107</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>30349467_4</td><td>Deactivations: Following &gt; Leading (Followers only); others</td><td>30349467_analysis_3</td><td>Deactivations: Following &gt; Leading</td><td>0.800</td><td>0.571</td><td>0.640</td><td>uncertain</td><td>coord_count_mismatch</td></tr><tr><td>30349467_5</td><td>Deactivations: Following &gt; Leading (Whole-group); others</td><td>30349467_analysis_5</td><td>Deactivation</td><td>0.400</td><td>0.000</td><td>0.120</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>30349467_6</td><td>[Leading &gt; Rest] and [Following &gt; Rest] (followers only); others</td><td>30349467_analysis_1</td><td>Followers only (n = 10)</td><td>0.380</td><td>1.000</td><td>0.814</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>30349467_7</td><td>[Leading &gt; Rest] and [Following &gt; Rest] (leaders only); others</td><td>30349467_analysis_0</td><td>Leaders only (n = 11)</td><td>0.347</td><td>1.000</td><td>0.804</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  <details class="inner-accordion"><summary>PMC full text available (PMCID 6186800)</summary><p><strong>Title:</strong> Role-Specific Brain Activations in Leaders and Followers During Joint Action</p><details><summary>Abstract</summary><pre class="paper-text">Much of social interaction in human life requires that individuals perform different roles during joint actions, the most basic distinction being that between a leader and a follower. A number of neuroimaging studies have examined the brain networks for leading and following, but none have examined what effect prior expertise at these roles has on brain activations during joint motor tasks. Couple dancers (e.g., dancers of Tango, Salsa, and swing) are an ideal population in which examine such effects, since leaders and followers of partnered dances have similar overall levels of motor expertise at dancing, but can differ strikingly in their role-specific skill sets. To explore role-specific expertise effects on brain activations for the first time, we recruited nine skilled leaders and nine skilled followers of couple dances for a functional magnetic resonance imaging study. We employed a two-person scanning arrangement that allowed a more naturalistic interaction between two individuals. The dancers interacted physically with an experimenter standing next to the bore of the magnet so as to permit bimanual partnered movements. Together, they alternated between leading and following the joint movements. The results demonstrated that the brain activations during the acts of leading and following were enhanced by prior expertise at being a leader or follower, and that activity in task-specific brain areas tended to be positively correlated with the level of expertise at the corresponding role. These findings provide preliminary evidence that training at one role of a joint motor task can selectively enhance role-related brain activations.</pre></details><details><summary>Body</summary><pre class="paper-text">## Introduction 
  
Much joint action between two people involves the contrastive roles of leader and follower ( ). For example, when two people move a sofa, the front person is often the one who navigates the joint movement as well as the one who determines the speed at which the two people move, while the back person responds to these movement-cues and attempts to coordinate his/her actions with the front person. However, the experimental literature that examines joint action in the lab does not give consideration to individual differences, for example the fact that people may be predisposed toward being a leader or follower based on their personality traits or life experiences ( ). In typical studies of joint action, people are randomly assigned to being a leader or follower (or both) of a joint task without assessing individual differences in task expertise that may exist between them. This applies to studies of both experts ( ;  ) and non-experts ( ;  ;  ;  ). This may be problematic since many studies demonstrate that expertise has an effect on behavioral performance and brain activations across many domains ( ;  ;  ). 

An interesting solution to this problem is to examine couple dancers, such as Tango dancers, since such people engage in extensive training to develop expertise at one specific role in the dance, thereby making the assessment of leading/following experience on joint action quite feasible. Leaders and followers of a couple dance have similar overall levels of motor expertise at dancing, but they can differ strikingly in their role-specific skill sets, such that dancers of one role are often unable to dance the opposite role. This applies not merely to the movement patterns themselves, but to the   coordination   skills required for leading (e.g., force conveyance) and following (e.g., responsiveness to force cues). While previous neuroimaging studies have looked separately at the topics of leading/following and expertise, the current study–which is a follow-up analysis to a previously published study from our lab ( )–represents a first attempt at examining   role-specific expertise   at leading and following, doing so using trained leaders and followers of couple dances. The principal aim of the study is to identify role-specific brain activations, namely leading-related activations in trained leaders compared to non-leaders, and following-related activations in trained followers compared to non-followers. 

Previous studies of leading and following have tended to emphasize the networks for leading, more so than those for following. For example, studies of interactive imitation have compared the initiation and imitation of visual actions within the same group of participants, and have highlighted an initiation network involved in self-monitoring, willed action, and decision making ( ;  ;  ;  ). Studies of auditory-entrainment tasks, such as finger tapping, have studied expert leaders or individuals who spontaneously emerge as leaders with in the context of the study, and have similarly identified a network involved in decision making, movement initiation, and self-processing ( ;  ;  ). These studies have provided either no results or inconsistent findings regarding following or expert followers. In a previous publication from our lab ( ), we characterized the networks for leading and following during a joint-action task with physical interaction, using the same dancer participants as those employed in the present study. In accordance with the previous literature, we found that leading showed a motor- and self-oriented profile, engaging areas associated with motor planning, spatial navigation, sequencing, action monitoring, and error correction. In contrast, following showed a far more sensory- and externally oriented profile, revealing areas involved in somatosensation, proprioception, motion tracking, social cognition, and outcome monitoring. However, while that study compared the act of leading with the act of following, it did not assess the influence of prior expertise at being a leader or follower on the brain activations. That was the major objective of the current follow-up analysis, namely to examine role-specific expertise. 

It is well-established that expertise can influence both the structure and function of the brain. There is now a vast literature devoted to various forms of motor, perceptual, and cognitive expertise (reviewed in  ). A general finding of such studies is that brain activations and gray matter volume are enhanced in experts, as compared to non-experts, in areas that process the skills that underlie a person’s domain of expertise ( ;  ;  ). For example, with regard to perceptual tasks, trained musicians and other auditory experts show enhanced effects in auditory cortex ( ,  ;  ;  ), while visual experts show effects in visual cortex ( ,  ;  ). In the motor domain, effects are found in cortical and subcortical motor and premotor areas involved in motor execution, control, planning, and representation ( ;  ). Motor experts, such as athletes, dancers, and musicians, additionally demonstrate changes in perceptual and cognitive areas associated with their trained skills ( ). For example, sensorimotor coupling is enhanced in musicians and athletes ( ;  ). In addition, activations in the action-observation network [including premotor cortex (PMC), superior parietal lobule (SPL), and inferior parietal lobule (IPL)] are enhanced when dancers view specific dance patterns that they are expert in ( ), or when athletes view sports actions that they are expert in ( ), as compared to when the same people view dances or sports movements that they are not trained in.   suggested that this effect was due to motor training, rather than the associated perceptual training. Expertise, in addition to producing enhancements in processing, has also been linked to decreases in the overall number of activated foci in neuroimaging studies, especially in attentional and cognitive-control networks, suggesting an enhancement in automaticity of processing for the trained skill ( ;  ). The “two stage expertise hypothesis” ( ;  ) suggests that short-term training leads to enhancements of brain activations for the trained skill, while long-term training and skill mastering lead instead to decreases or reorganizations in brain activations. 

While previous neuroimaging studies have looked at leading/following and expertise in isolation, no study thus far has combined the two issues, which is the principal objective of the present study. As mentioned above, couple dancers are an ideal cohort for exploring role-specific expertise in leading and following, since they spend many years developing expertise at typically just one of the two roles of the dance. As a result, expert leaders are usually unskilled followers, and vice versa, while both groups have comparable levels of overall motor expertise at the dance. More specifically, leader expertise during couple dancing requires the generation of a motor plan for both the self and the partner, and the efficient conveyance of signals to the partner, while follower expertise requires the tracking of information coming from the leader and its interpretation to construct either an identical or complementary movement pattern in real time. 

In order to assess the effect of role expertise on brain activations during an ecologically valid joint-action task, we carried out an exploratory follow-up analysis to our previous publication that looked at leading and following ( ) in order to examine the effects of role-specific expertise on brain activations. In the previous study, skilled leaders and followers of couple dances performed both a leading and following task in a magnetic resonance imaging (MRI) scanner in interaction with an experimenter standing next to the bore of the magnet. The participant and experimenter were in physical contact at their hands, and alternated between being the leader and follower of joint improvised bimanual movements. The principal aim of the study was to compare brain activity during the acts of leading and following. The current study follows up on those results using the same dataset in order to examine the effects of individual differences on the brain activations, in particular an individual’s expertise at a given role of the dance. The aim was to look for role-specific brain activations, in other words leading-related activations in trained leaders compared to non-leaders (i.e., followers), and following-related activations in trained followers compared to non-followers (i.e., leaders). Based on the literature cited above demonstrating that experts show enhancements in task-specific brain areas compared to non-experts when performing the same tasks, we predicted that leaders, as compared with non-leaders, would show an enhancement of leading-related activations when leading (only), and likewise that followers, as compared with non-followers, would show an enhancement of following-related activations when following (only). Given that we were not able to effectively rule out the influence of gender on dance role in our design, the results need to be viewed as exploratory. 


## Materials and Methods 
  
### Participants 
  
Eighteen participants (nine of each gender) took part in this study after giving their written informed consent in accordance with the Hamilton Integrated Research Ethics Board, who approved the study (St. Joseph’s Healthcare, R. P. #12-3777). They received monetary compensation for their participation. None of them had a past history of neurological or psychiatric disease. An inclusion criterion for the study was that participants have at least 2 years of experience at one or more kinds of couple dances involving leading and following (e.g., Argentine Tango, Salsa, Swing, and Ballroom). Male participants (40.7 ± 14.9 years old) had a mean dance experience of 8.7 ± 7.2 years, principally as leaders, although one male had significant experience as a follower as well. Female participants (40.2 ± 12.3 years old) had a mean dance experience of 5.6 ± 2.9 years, principally as followers, although two females had significant experience as leaders as well. 

On the day of the experiment, participants reported their ability to lead or follow a couple dance using a scale from 0 to 100, where 0 corresponds to no expertise at leading or following, and 100 corresponds to a very high level of expertise at leading or following. Each person did separate ratings for leading and following skill, with results shown in   Figure   . We explained to participants that these scales emphasized the ability to transmit/receive information while dancing with a partner, rather than the ability to perform complex or stylistic movements. Males reported a mean leading ability of 69.8 ± 17.7 (one male was at 35 and the rest ranged from 60 to 90). Likewise, females reported a mean following ability of 77.2 ± 8.3 (ranging from 70 to 90). With regards to the complementary skill, males reported a mean following ability of 33.7 ± 21.6; the male with significant following experience reported his following ability at 78, while all the others males rated it at between 8 and 50. Females reported a mean leading ability of 28.9 ± 25.2; both females with significant leading experience reported their leading ability at 70, while all other females rated themselves at between 5 and 40. Correlations between leading ability, following ability, years of experience at dancing, and age showed that leading ability, but not following ability, correlated with the number of years of experience (  Table   ). Anecdotal evidence suggests that leading skill requires a greater amount of time and effort to achieve than does following skill, which may explain the exclusive correlation of leading skill with years of experience. Since leading and following ability were not anti-correlated in the analysis, participants designated as “leaders” in this study were comprised of all the participants who were primarily trained as leaders for at least 2 years (i.e., all the of males) plus the two participants who, although primarily trained as followers, had significant leading experience and a strong leading ability (two females). Those designated as “followers” were comprised of all the participants who were primarily trained as followers for at least 2 years (i.e., all of the females) plus one participant who, although primarily trained as leader, had significant following experience and a strong following ability (one male). Thus, three participants belonged in both groups. This division was used in only the first set of analyses (see below). 
  
Self-report scales for skills as a leader and follower of couple dances. The   x  -axis shows the self-rating scale for leader skill (left panel) and follower skill (right panel) for couple dancing, where 100 is the highest rating. The   y  -axis of each graph shows the number of participants, from the pool of 18, who rated themselves at the various levels of skill for each role. Female participants are color-coded red and males are color-coded blue, both here and in   Figures  ,   . Participants designated as “leaders” in this study were comprised of all the males plus the two females with strong leading ability, while those designated as “followers” were comprised of all the females plus the male with strong following ability. Leaders are color coded as purple here and in   Figures  –  , whereas followers are color coded as pink here and in   Figures  –   (not to be confused with the color coding of gender). 
    
Correlation between age, years of couple-dance experience, and self-reported leading and following skill. 
    

### Procedure 
  
While the participant was lying supine in the MRI scanner, an experimenter (LASC) stood next to the bore of the scanner in order to have physical contact with the participant’s two hands. The participant’s forearms were fastened to the side of their body such that only their wrists, hands and fingers were able to move. Participants’ hands (palms up) were always below the experimenter’s hands (palms down), so that the participants’ hands could not be passively moved. The experimenter had significant experience both as a follower and a leader of couple dances. Together, the participant and experimenter performed highly controlled joint hand movements in all three planes of motion, alternating between leading and following the joint movement during different task-epochs of the scan. The movement patterns were improvised, rather than pre-learned, in order to maintain an ongoing requirement for motor planning during leading and a comparably heightened sense of responsiveness during following. No external cuing of tempo or rhythm was done with a metronome or with music. Participants performed all conditions with their eyes closed, and were instructed about which task to perform by means of pre-recorded verbal cues delivered through MRI-compatible headphones. Each condition was performed in a random order six times in blocks of 28 s. 

Complete methods and details concerning fMRI acquisition and image analysis, including participant training, are described in  . Briefly, the functional MRI imaging parameters were 2000 ms TR, 35 ms TE, 90° flip angle, 39 axial slices, 4 mm slice thickness, 0 mm gap, 3.75 × 3.75 mm in-plane resolution, 64 × 64 matrix, and 240 mm field of view. An automatic shimming procedure was performed before each scan to minimize inhomogeneities in the static magnetic field. For each of the three functional scans, 216 volumes–corresponding to 12 epochs of 28 s task + 8 s rest–were collected over 7’12”, resulting in a total of 648 volumes. Two magnetic field maps (5 ms then 8 ms TE) with the same imaging parameters as the fMRI were acquired in order to unwarp the data. Unwarping was performed with the relaxation method of “anatabacus”, a plugin in BrainVoyager, in order to correct for non-rigid deformations. In addition, the head-motion parameters were included as nuisance regressors in the analysis. Functional and structural images were processed using BrainVoyager QX 2.8. Coordinate tables were computed using NeuroElf. 


### Analysis 
  
We first performed qualitative analyses on three groups to assess if there were any differences between being a leader and being a follower. Specifically, we carried out three random-effects analyses for the bidirectional contrast “Leading versus Following” (1) for the whole group of 18 participants, (2) for the 11 leaders only, and (3) for the 10 followers only. These were performed at a two-tailed statistical threshold of   p   &lt; 0.005 uncorrected with a cluster-level correction of   k   = 28 voxels determined with Alphasim (family-wise error   p   &lt; 0.05) in NeuroElf. The conjunction of [Leading &gt; Rest] ∩ [Following &gt; Rest] was also performed on these three groups in order to serve as a reference for the general network of brain areas activated by the movement tasks, irrespective of role. It was performed at a two-tailed statistical threshold of   p   &lt; 0.005 uncorrected with a cluster-level correction of   k   = 49 voxels determined with Alphasim. 

Since qualitative differences were found (see Results section), we tested further for the effect of role by performing whole-brain regression analyses on the full group of participants (  n   = 18). We chose to perform statistical regression analyses instead of a direct statistical comparison between leaders and followers for two reasons. First, we consider role expertise to be a continuous trait, rather than a dichotomous one. Dancers can belong to both groups if they are trained at both leading and following. Thus a binary distinction would have led to a “male versus female” contrast, rather than a “leader versus follower” contrast. Second, the number of participants in each group was small (  n   = 10 and 11 for leaders and followers, respectively), whereas the regression involved the full group of 18 participants. Because of the small number of participants in the analysis and because of the small number of female leaders and male followers in the cohort, we consider this an exploratory study. Future studies will need to examine larger numbers of participants who have both leading and following skills, although such dual training tends to be limited to professional teachers of a dance. 

For the whole-brain regression analyses, the self-reported values of leading and following skill were used as covariates in two separate analyses to regress the betas values of the contrast “Leading versus Following”. These regressions were also performed at a two-tailed statistical threshold of   p   &lt; 0.005 uncorrected with a cluster-level correction of   k   = 25 voxels, determined with Alphasim. However, this threshold led to null results, and so we reported the activation at a less stringent threshold of   p   &lt; 0.025 uncorrected with a cluster-level correction of k = 46 voxels, determined with Alphasim. We note that these results should be interpreted with caution and need to be replicated in future analyses. In order to examine the influence of gender, the mean beta value of each activated cluster was extracted for each participant and regressed against his/her corresponding leading or following skill. 



## Results 
  
In order to identify the basic sensorimotor network involved in performing our joint bimanual tasks, we carried out the conjunction of [Leading &gt; Rest] ∩ [Following &gt; Rest], with results shown in   Figure    and Talairach coordinates reported in   Table   . This shared network between leading and following consisted of a widespread sensorimotor cortical (primary motor and somatosensory cortex) and subcortical (thalamus and cerebellum) network, as well as the supplementary motor area (SMA), midcingulate cortex (MCC), SPL, inferior frontal gyrus (IFG), IPL (including the secondary somatosensory cortex [SII] and extending to the insula), and inferior temporal gyrus (ITG), extending to the middle temporal gyrus (MTG). Except for the ITG, which was present in leaders only, this network was found in both leaders and followers. 
  
Shared network for leading and following. The figure shows the results of the conjunction [Leading &gt; Rest] ∩ [Following &gt; Rest] in leaders only (left panel) and followers only (right panel),   p   &lt; 0.005 uncorrected (  k   = 49 voxels). With the exception of the inferior temporal gyrus, the activated network is similar in both followers and leaders. CB, cerebellum; IFG, inferior frontal gyrus; IPL, inferior parietal lobule; ITG, inferior temporal gyrus; MCC, middle cingulate cortex; SMA, supplementary motor area; SMC, sensorimotor cortex; SPL, superior parietal lobule; and Th., thalamus. 
    
The shared network for leading and following. 
    
We next wanted to explore our question of interest, namely whether there was evidence for role-specific activations, in other words activations found only in skilled individuals while performing the role they are trained in. This would reveal whether leaders and followers engage different brain resources during leading and following. As shown in   Figure    and   Table   , we first qualitatively compared three types of analyses of the “Leading &gt; Following” contrast (cyan clusters) and “Following &gt; Leading” contrast (yellow clusters): the whole group of 18 participants; only the leaders (a subset of 11 participants); and only the followers (a subset of 10 participants). Overall, the leaders-only analysis showed basically the same network for leading as the whole group, but no brain areas for following. Likewise, the followers-only analysis showed basically the same network for following as the whole group, but only the dorsolateral prefrontal cortex (DLPFC) for leading (Note that only role-specific activations are labeled in the   Figure   ). 
  
Role-specific brain activations. The figure shows an analysis of the bidirectional “Leading versus Following” contrast in three groupings: the whole group of 18 participants; only the leaders (a subset of 11 participants); and only the followers (a subset of 10 participants). Contrasts are performed at   p   &lt; 0.005 uncorrected (  k   = 28 voxels). The top panel is the midsagittal view, the lower left panel is the left hemisphere, and the lower right panel is the right hemisphere. Each panel is set up as a triad, with the whole group at the top and the restricted analyses of leaders-only and followers-only below that. Cyan clusters and outlines reflect the contrast of “Leading &gt; Following”, whereas yellow clusters and outlines reflect the reverse contrast of “Following &gt; Leading”. In order to facilitate the visualization of role-specific activations, we use colored outlines to represent whole-group activations that are missing in either the leaders-only or the followers-only analyses. More specifically, cyan outlines are regions of whole-group activation that are present in the leaders-only analysis, but not the followers-only analysis, while yellow outlines are regions of whole-group activation that present in the followers-only analysis, but not the leaders-only analysis. The leaders-only analysis shows the same network for leading as the whole group, but no brain areas for following. The followers-only analysis shows the same network for following as the whole group, but only the cerebellum and dorsolateral prefrontal cortex for leading. Only role-specific activations are labeled in this figure. Leading network: CMA: cingulate motor area; PMC, premotor cortex; SMA, supplementary motor area; and SPL, superior parietal lobule. Following network: PCC, posterior cingulate cortex and TPJ, temporo-parietal junction. 
    
Leading versus following in the whole group, the leader-only group, and the follower-only group. 
    
Regarding the leading task, role-specific activations that were found exclusively in skilled leaders (cyan activations in   Figure    in both the leaders-only and whole-group brains that correspond with the cyan outlines in the followers-only brain) were observed in the SMA and cingulate motor area (CMA; top panel), SPL (right and left hemispheres in the lower panels), and PMC(left hemisphere). In addition, while leading, leaders showed a more extended premotor activation than the whole-group, especially in the right hemisphere (  Table   ). 

Regarding the following task, role-specific activations that were found exclusively in skilled followers (yellow activations in   Figure    in both the followers-only and whole-group brains that correspond with the yellow outlines in the leaders-only brain) were observed in the posterior cingulate cortex (PCC; top panel), temporo-parietal junction (TPJ; right and left hemispheres in the lower panels), and parahippocampal cortex (PHC, not shown). In addition, while following, followers showed activity in the posterior superior temporal sulcus (pSTS) that was not present in the whole group (  Table   ). To summarize, the networks associated with leading and following seemed to be more strongly engaged by experts at the corresponding role than non-experts at that role. 

We followed up on these qualitative analyses with whole-brain regressions in which the self-reported expertise at being a leader or follower (see   Figure    above) was used as the covariate for the contrast of leading versus following. Activations for these analyses were only found at a more lenient threshold, but are still reported since they are consistent with both our hypotheses and the qualitative analyses reported above. However, the results should be interpreted with caution.   Figure    shows the regressions with leader skill, and   Figure    shows the regressions with follower skill. The regions where activations during the leading task correlated with leader skill included the SMA, pre-SMA, dorsal PMC (dPMC), superior temporal gyrus (STG), and insula (  Figure    top panel,   Table   ). The regions where activations during the following task correlated with follower skill include the PCC, TPJ, pSTS, and mPFC (  Figure    top panel,   Table   ). For each cluster, the coefficient of determination (  R  ) of the regression of the mean beta value against leader and follower skill is shown in   Tables  ,   , respectively. 
  
Regression of brain activation with leader skill in the whole group of participants. The top panel of this figure shows brain activity that correlates with the contrasts “Leading &gt; Following” (cyan activations) and “Following &gt; Leading” (yellow activations). Contrasts are performed at   p   &lt; 0.02 uncorrected (  k   = 25 voxels). Brain areas for “Leading &gt; Following” that correlate with leader skill include the dorsal premotor cortex (dPMC), insula (Ins.), superior temporal gyrus (STG), and supplementary motor area (SMA). Almost no areas for the contrast “Following &gt; Leading” correlate with leader skill (see   Table   ). The lower plots show mean beta values extracted from the SMA, dPMC, posterior insula and STG against leader skill, where female participants are shown with red dots and male participants with blue dots. Activity for leading increased with increasing leader skill, and this seems to be independent of gender. 
    
Regression of brain activation with the follower skill in the whole group of participants. The top panel of this figure shows brain activity that correlates with the contrasts “Leading &gt; Following” (cyan activations) and “Following &gt; Leading” (yellow activations). Contrasts are performed at   p   &lt; 0.02 uncorrected (  k   = 25 voxels). Brain areas for “Following &gt; Leading” that correlate with follower skill include the medial prefrontal cortex (mPFC), posterior parietal cortex (PCC), posterior superior temporal sulcus (pSTS), and temporo-parietal junction (TPJ). No areas appeared for the contrast “Leading &gt; Following” correlate with follower skill (see   Table   ). The lower plots show mean beta values extracted from the TPJ, PCC, mPFC, and pSTS against follower skill, where female participants are shown with red dots and male participants with blue dots. Activity for following increased with increasing follower skill, and this seems to be independent of gender. 
    
Leading versus following correlated with skill as a leader. 
      
Leading versus following correlated with skill as a follower. 
    
Examples of how the mean beta value in these regions covaries with leader and follower skill are shown in the bottom panels of   Figures  ,   , respectively. The results provide some evidence that activity in these regions might depend on the level of expertise. However, they in no way rule out a gender effect, either alone or in interaction with expertise, and so the results have to be seen as preliminary. In the dPMC and STG (  Figure   , bottom panels), activity for the contrast of “Leading &gt; Following” increased with leader skill, but a male with low leader skill had a low activity, whereas females with high leader skill had a high activity. Other areas that correlated with leader skill had the same trend (not shown). Similarly, in the mPFC and TPJ (  Figure   , bottom panels), activity for the contrast “Leading &gt; Following” decreased with follower skill (that is, “Following &gt; Leading” activity increased with follower skill), but a male with high follower skill had a low activity, similar to females with high follower skill. Other areas that correlated with follower skill had the same trend (not shown). Future studies will be needed to fully exclude the influence of gender on the expertise effects observed here. Hence, the current study must be seen as a pilot study that gives a first glimpse at role-specific expertise effects without being able to effectively factor out the influence of gender. 


## Discussion 
  
This current exploratory study examined for the first time the effect of expertise at the coordinative skills involved in leading and following on brain activations during a joint-action task in a realistic setting. Its results provide support for the existence of role-specific brain activations during joint actions. In particular, we observed that leading-related activations were enhanced in leaders compared to followers when both groups performed the leading task, and that following-related activations were enhanced in followers compared to leaders when both groups performed the following task. Additionally, we showed that leading-related brain regions in the whole group of participants tended to correlate with expertise at being a leader, whereas following-related brain regions tended to correlate with expertise at being a follower. Another way of conceptualizing these results is that the skilled leaders hardly engaged any areas during following that were not already engaged during leading; likewise, the skilled followers hardly engaged any areas during leading that were not already engaged during following. This might explain the null results found in some previous studies when comparing following with leading ( ). These results suggest that expertise at one role of a joint-action task can enhance brain activations for the trained role compared to the untrained role. Hence, not only do the results support the existing literature on expertise effects for motor tasks, but they extend it for the first time to the contrastive roles of leader and follower in joint actions. 

The major finding of the initial qualitative analysis (  Figure   ) was that the brain networks that we observed for leading and following in the whole group seemed to be mainly supported by prior experience at being a leader or follower. In particular, skilled followers strongly engaged the mentalizing and social networks (PCC, TPJ, and STS) while following, which is consistent with a view of following as a process of adapting to one’s partner or as inferring knowledge from one’s partner ( ;  ;  ;  ;  ;  ). In contrast, skilled leaders strongly engaged networks for motor control and planning (SMA, CMA, PMC, and cerebellum) and for spatial navigation and exploration (SPL) while leading, which is consistent with the requirements of the leading role ( ;  ;  ;  ;  ). Interestingly, both skilled leaders and skilled followers activated the DLPFC during leading, which implies that self-initiation and action selection ( ;  ;  ) are probably the most important characteristics of leading, regardless of expertise. 

By performing whole-brain regressions with leading or following skill, we treated being a leader or follower as a continuous trait, rather than a dichotomous one. Although we did not find any activity using our   a priori   threshold, the activations observed at a more lenient threshold were consistent with both our hypotheses and the qualitative results, and are thus reported as exploratory findings. We observed that distinct brain areas tended to correlate with the level of self-reported expertise at being a leader or a follower, respectively. The areas that correlated with follower skill were principally components of the following network, such as the mPFC, PCC, TPJ, and pSTS. Thus, the more that someone is trained at following, the more that s/he will recruit brain regions of the mentalizing and social networks, which might indicate more attention to, or more efficient processing of, social stimuli (i.e., cues coming from the leader) and the mental states of others (i.e., their intentions and action plans). Another characteristic of followers is their ability to track their partner’s movements or other signaling cues so as to produce either imitative or complementary movements. Along these lines, the pSTS has been specifically implicated in the multisensory perception of biological motion ( ;  ), indicating that a trained follower might be specialized in analyzing information coming from the partner’s movement, not least haptic information emanating from body contact ( ). 

In contrast to this profile for following, the areas that tended to correlate with leader skill were mainly part of the leading network, including premotor areas (pre-SMA, SMA, and PMC). Other areas that tended to correlate with leader skill were the insula and STG. This network is quite similar to the one shown to be activated by motor experts in the meta-analysis of  . In addition, all of the areas associated with leader skill in the present study have been previously shown to be involved in improvisation ( ). Since leading requires the ability to improvise movements, we can assume that the better a person is at leading, the better s/he can improvise a motor plan for both the self and the partner, and thus the more s/he recruits premotor areas and the STG. However, it has also been shown that improvisational expertise (in musicians, for example) is related to a deactivation in the DLPFC, TPJ, IFG, and insula ( ;  ), which has been interpreted as indicating an automation of cognitive processing and a greater focus on internal processes during improvisation ( ). The absence of deactivations in these regions in our study can potentially be explained by the fact that our use of a joint task may have precluded the adoption of an internal focus by the participants when leading. Indeed, a study of joint improvisation also found an activation increase in the DLPFC, pre-SMA, and STG ( ), which is quite similar to a situation of improvising with a dance partner when leading. 

Overall, the study integrates two issues in the cognitive neuroscience of motor performance, first the contrast between leading and following, and second the influence of individual differences in motor expertise on brain activations. As mentioned in the Introduction, many experimental studies of joint action randomly assign people to being a leader or follower of a joint task ( ;  ;  ;  ;  ). However, in Western dance culture, people are generally assigned these roles based on their gender, with men tending to be assigned the role of leader in couple dances. Thus, in contrast to a study of piano duetting ( ), for example, people come to a dance study like ours with years of experience at just one role of the joint task. This provides us with the unique ability to examine individual differences in joint action based not on random factors but on role-specific training. Previous studies of expertise processing have demonstrated enhanced brain activations in experts compared to non-experts ( ,  ;  ,  ;  ;  ;  ;  ;  ;  ;  ). However, this has often has been investigated using non-motor tasks, even in motor experts like professional ballet dancers ( ). We have instead probed this using a motor task, with the added benefit of doing this using a joint-action task. The integration of these two issues is that we were able to examine the contrast between leading and following–as per studies of joint action–but to incorporate the factor of prior motor experience, as per studies of expertise processing. The results revealed a clear overlap between these two issues, such that the brain activations during the acts of leading and following were enhanced by prior expertise at being a leader or follower, and that activity in task-specific brain areas tended to be positively correlated with the level of expertise at the corresponding role. In other words, we were able to demonstrate   role-specific enhancements   in brain activation. 

### Limitations 
  
Given that this study was a first attempt to examine the effect of role expertise on brain activations during joint action, we are aware that it has a number of significant limitations. First, we were limited in our ability to measure behavioral performance during task production in the scanner due to an absence of MRI-compatible technologies such as motion capture at our imaging center. Thus, we cannot determine if the differences between leaders and followers seen in the study are due to trait-related differences in activation or behavioral differences as well. The joint-action task performed in this study was quite simple and involved very small hand movements. Hence, it did not require any type of specialized skill, which would foster similar performance in the two groups. In addition, the experimenter was the sole interaction partner for all of the participants in the study and was thus a controlled factor in the interaction. However, the absence of a technology like motion capture means that we are unable to rule out behavioral differences between participants as a source of the results. Further research taking advantage of MRI-compatible technologies will be required to explore this issue. 

Second, the qualitative analyses showed an interesting pattern that was confirmed by the whole-group regression at a more lenient threshold, but not at a standard threshold. Hence, the effects seem to be small. Although the observed activations at the less stringent threshold were consistent with our expectations based on previous studies, the results of this study should be taken with caution and need to be replicated, preferentially with a larger cohort and a wider spread of skill levels. In addition, the skill levels that were used to regress the brain data were self-report data. They might thus have been subject to self-report biases and inaccuracies. However, no objective measure of leadership and/or followership skills exists in the literature. Given the preliminary results of this study, it would be worthwhile to develop such measures in future. Such measures could be used to see if the results of the present study could be replicated based on people’s role expertise in some other motor skill outside of dancing, or even on people’s natural predispositions to be a leader or follower, as related to personality traits and life experiences, rather than the specialized skill of dance training. 

Finally, and importantly, we are unable to rule out gender as a factor in determining the role-specific effects in our study, and hence the results need to be seen as quite preliminary. While the leader and follower groups were not exclusively of one gender, they did have a majority of one gender. Given the evidence for gender effects on a diversity of perceptual, cognitive, and motor tasks ( ;  ;  ;  ;  ), further studies will be required to assess a gender contribution to our results with trained couple dancers. Given the paucity of female leaders and male followers in the world of couple dancing, perhaps the only approach that will be able to address the limitations of the current study is a training study. A study that crosses gender with role during a several-month training program of leading or following for some joint-action task could permit a disentangling of the relative effects of gender and expertise. If female leaders and male followers showed the same role-specific effects as in the current study, this would argue against a gender interpretation in favor of expertise   per se  . Such a study could also reveal potential gender effects as well. 



## Conclusion 
  
This study is the first to look at the influence of prior individual training at being a leader or follower on the brain activations occurring during the acts of leading and following, thereby assessing the effect of role expertise during naturalistic joint action. Our major finding was that leaders and followers do not seem approach leading and following in the same way at the neural level, with leaders engaging more brain resources during leading, and followers during following, thus reflecting role-specific activations. Additionally, we showed that activity in leading-related brain regions tended to correlate with expertise at being a leader, and likewise that activity in following-related brain regions tended to correlate with expertise at being a follower. These findings highlight the fact that the acts of leading and following might be skill-specific, and thus that prior experience at these roles should be assessed when studying leading and following during joint action. However, given our inability to disentangle gender from dance role, the current results must be seen as preliminary. A training study that crosses gender with role will probably be required to truly distinguish dance role from gender. 


## Author Contributions 
  
LC ran the experiment and analyzed the data. LC and SB conceived the experiment, analyzed the results, and wrote the manuscript. 


## Conflict of Interest Statement 
  
The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</pre></details></details>
  <details class="inner-accordion"><summary>Coordinate-relevant source tables (4)</summary><details class="inner-accordion"><summary>Table 2 (T2) - The shared network for leading and following.</summary><div class="table-html"><table-wrap id="T2" position="float" orientation="portrait"><label>Table 2</label><caption><p>The shared network for leading and following.</p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="center" colspan="5" rowspan="1">Leaders only (<italic toggle="yes">n</italic> = 11)</th><th valign="top" align="center" colspan="5" rowspan="1">Followers only (<italic toggle="yes">n</italic> = 10)</th></tr><tr><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" colspan="5" rowspan="1"><hr /></th><th valign="top" align="left" colspan="5" rowspan="1"><hr /></th></tr><tr><th valign="top" align="left" rowspan="1" colspan="1">Area</th><th valign="top" align="left" rowspan="1" colspan="1">BA</th><th valign="top" align="left" rowspan="1" colspan="1">Hemisphere</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">k</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Max</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">k</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Max</th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">SMC</td><td valign="top" align="left" rowspan="1" colspan="1">1,3,4,5,6,40</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">33</td><td valign="top" align="center" rowspan="1" colspan="1">-40</td><td valign="top" align="center" rowspan="1" colspan="1">58</td><td valign="top" align="center" rowspan="1" colspan="1">1356</td><td valign="top" align="center" rowspan="1" colspan="1">17.01</td><td valign="top" align="center" rowspan="1" colspan="1">30</td><td valign="top" align="center" rowspan="1" colspan="1">-37</td><td valign="top" align="center" rowspan="1" colspan="1">61</td><td valign="top" align="center" rowspan="1" colspan="1">1149</td><td valign="top" align="center" rowspan="1" colspan="1">16.54</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">SMC</td><td valign="top" align="left" rowspan="1" colspan="1">2,3,4,5,6,40</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-39</td><td valign="top" align="center" rowspan="1" colspan="1">-43</td><td valign="top" align="center" rowspan="1" colspan="1">52</td><td valign="top" align="center" rowspan="1" colspan="1">1419</td><td valign="top" align="center" rowspan="1" colspan="1">17.67</td><td valign="top" align="center" rowspan="1" colspan="1">-39</td><td valign="top" align="center" rowspan="1" colspan="1">-37</td><td valign="top" align="center" rowspan="1" colspan="1">55</td><td valign="top" align="center" rowspan="1" colspan="1">1135</td><td valign="top" align="center" rowspan="1" colspan="1">18.19</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">IFG</td><td valign="top" align="left" rowspan="1" colspan="1">6,13,44</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">54</td><td valign="top" align="center" rowspan="1" colspan="1">2</td><td valign="top" align="center" rowspan="1" colspan="1">19</td><td valign="top" align="center" rowspan="1" colspan="1">174</td><td valign="top" align="center" rowspan="1" colspan="1">5.86</td><td valign="top" align="center" rowspan="1" colspan="1">54</td><td valign="top" align="center" rowspan="1" colspan="1">8</td><td valign="top" align="center" rowspan="1" colspan="1">7</td><td valign="top" align="center" rowspan="1" colspan="1">108</td><td valign="top" align="center" rowspan="1" colspan="1">8.05</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">SMA/MCC</td><td valign="top" align="left" rowspan="1" colspan="1">6, 24, 31</td><td valign="top" align="left" rowspan="1" colspan="1">RH/LH</td><td valign="top" align="center" rowspan="1" colspan="1">3</td><td valign="top" align="center" rowspan="1" colspan="1">-13</td><td valign="top" align="center" rowspan="1" colspan="1">52</td><td valign="top" align="center" rowspan="1" colspan="1">610</td><td valign="top" align="center" rowspan="1" colspan="1">14.68</td><td valign="top" align="center" rowspan="1" colspan="1">0</td><td valign="top" align="center" rowspan="1" colspan="1">-22</td><td valign="top" align="center" rowspan="1" colspan="1">49</td><td valign="top" align="center" rowspan="1" colspan="1">683</td><td valign="top" align="center" rowspan="1" colspan="1">12.14</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">IPL/SII</td><td valign="top" align="left" rowspan="1" colspan="1">13,40,41</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">48</td><td valign="top" align="center" rowspan="1" colspan="1">-28</td><td valign="top" align="center" rowspan="1" colspan="1">25</td><td valign="top" align="center" rowspan="1" colspan="1">294</td><td valign="top" align="center" rowspan="1" colspan="1">7.26</td><td valign="top" align="center" rowspan="1" colspan="1">45</td><td valign="top" align="center" rowspan="1" colspan="1">-34</td><td valign="top" align="center" rowspan="1" colspan="1">31</td><td valign="top" align="center" rowspan="1" colspan="1">108</td><td valign="top" align="center" rowspan="1" colspan="1">6.82</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">IPL/SII</td><td valign="top" align="left" rowspan="1" colspan="1">13, 22,40</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-51</td><td valign="top" align="center" rowspan="1" colspan="1">-28</td><td valign="top" align="center" rowspan="1" colspan="1">19</td><td valign="top" align="center" rowspan="1" colspan="1">240</td><td valign="top" align="center" rowspan="1" colspan="1">9.52</td><td valign="top" align="center" rowspan="1" colspan="1">-48</td><td valign="top" align="center" rowspan="1" colspan="1">-34</td><td valign="top" align="center" rowspan="1" colspan="1">19</td><td valign="top" align="center" rowspan="1" colspan="1">314</td><td valign="top" align="center" rowspan="1" colspan="1">9.36</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">SPL</td><td valign="top" align="left" rowspan="1" colspan="1">7</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">24</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">58</td><td valign="top" align="center" rowspan="1" colspan="1">197</td><td valign="top" align="center" rowspan="1" colspan="1">7.06</td><td valign="top" align="center" rowspan="1" colspan="1">24</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">55</td><td valign="top" align="center" rowspan="1" colspan="1">166</td><td valign="top" align="center" rowspan="1" colspan="1">6.52</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">SPL</td><td valign="top" align="left" rowspan="1" colspan="1">7</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-24</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">58</td><td valign="top" align="center" rowspan="1" colspan="1">453</td><td valign="top" align="center" rowspan="1" colspan="1">10.52</td><td valign="top" align="center" rowspan="1" colspan="1">-27</td><td valign="top" align="center" rowspan="1" colspan="1">-55</td><td valign="top" align="center" rowspan="1" colspan="1">58</td><td valign="top" align="center" rowspan="1" colspan="1">268</td><td valign="top" align="center" rowspan="1" colspan="1">9.76</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">ITG</td><td valign="top" align="left" rowspan="1" colspan="1">37</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">51</td><td valign="top" align="center" rowspan="1" colspan="1">-58</td><td valign="top" align="center" rowspan="1" colspan="1">-8</td><td valign="top" align="center" rowspan="1" colspan="1">117</td><td valign="top" align="center" rowspan="1" colspan="1">6.45</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">ITG</td><td valign="top" align="left" rowspan="1" colspan="1">19, 37</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-48</td><td valign="top" align="center" rowspan="1" colspan="1">-58</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">93</td><td valign="top" align="center" rowspan="1" colspan="1">6.30</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Thalamus</td><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">15</td><td valign="top" align="center" rowspan="1" colspan="1">-25</td><td valign="top" align="center" rowspan="1" colspan="1">10</td><td valign="top" align="center" rowspan="1" colspan="1">105</td><td valign="top" align="center" rowspan="1" colspan="1">7.03</td><td valign="top" align="center" rowspan="1" colspan="1">0</td><td valign="top" align="center" rowspan="1" colspan="1">-16</td><td valign="top" align="center" rowspan="1" colspan="1">16</td><td valign="top" align="center" rowspan="1" colspan="1">49</td><td valign="top" align="center" rowspan="1" colspan="1">6.73</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Thalamus</td><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-15</td><td valign="top" align="center" rowspan="1" colspan="1">-19</td><td valign="top" align="center" rowspan="1" colspan="1">10</td><td valign="top" align="center" rowspan="1" colspan="1">139</td><td valign="top" align="center" rowspan="1" colspan="1">7.41</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Cerebellum</td><td valign="top" align="left" rowspan="1" colspan="1">Vermis</td><td valign="top" align="left" rowspan="1" colspan="1">RH/LH</td><td valign="top" align="center" rowspan="1" colspan="1">-3</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">-17</td><td valign="top" align="center" rowspan="1" colspan="1">308</td><td valign="top" align="center" rowspan="1" colspan="1">10.74</td><td valign="top" align="center" rowspan="1" colspan="1">3</td><td valign="top" align="center" rowspan="1" colspan="1">-58</td><td valign="top" align="center" rowspan="1" colspan="1">-14</td><td valign="top" align="center" rowspan="1" colspan="1">163</td><td valign="top" align="center" rowspan="1" colspan="1">7.72</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Cerebellum</td><td valign="top" align="left" rowspan="1" colspan="1">Culmen/Declive</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">15</td><td valign="top" align="center" rowspan="1" colspan="1">-49</td><td valign="top" align="center" rowspan="1" colspan="1">-17</td><td valign="top" align="center" rowspan="1" colspan="1">164</td><td valign="top" align="center" rowspan="1" colspan="1">9.53</td><td valign="top" align="center" rowspan="1" colspan="1">12</td><td valign="top" align="center" rowspan="1" colspan="1">-46</td><td valign="top" align="center" rowspan="1" colspan="1">-17</td><td valign="top" align="center" rowspan="1" colspan="1">104</td><td valign="top" align="center" rowspan="1" colspan="1">6.19</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Cerebellum</td><td valign="top" align="left" rowspan="1" colspan="1">Culmen/Declive</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-21</td><td valign="top" align="center" rowspan="1" colspan="1">-49</td><td valign="top" align="center" rowspan="1" colspan="1">-20</td><td valign="top" align="center" rowspan="1" colspan="1">140</td><td valign="top" align="center" rowspan="1" colspan="1">10.20</td><td valign="top" align="center" rowspan="1" colspan="1">-15</td><td valign="top" align="center" rowspan="1" colspan="1">-52</td><td valign="top" align="center" rowspan="1" colspan="1">-17</td><td valign="top" align="center" rowspan="1" colspan="1">144</td><td valign="top" align="center" rowspan="1" colspan="1">8.87</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Cerebellum</td><td valign="top" align="left" rowspan="1" colspan="1">Tuber/Declive</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">42</td><td valign="top" align="center" rowspan="1" colspan="1">-58</td><td valign="top" align="center" rowspan="1" colspan="1">-23</td><td valign="top" align="center" rowspan="1" colspan="1">94</td><td valign="top" align="center" rowspan="1" colspan="1">7.03</td><td valign="top" align="center" rowspan="1" colspan="1">45</td><td valign="top" align="center" rowspan="1" colspan="1">-58</td><td valign="top" align="center" rowspan="1" colspan="1">-20</td><td valign="top" align="center" rowspan="1" colspan="1">156</td><td valign="top" align="center" rowspan="1" colspan="1">7.86</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /></tr></tbody></table><table-wrap-foot><attrib><italic toggle="yes">Talairach coordinates for the conjunction of Leading and Following compared to rest (<italic toggle="yes">p</italic> &gt; 0.005 uncorrected, <italic toggle="yes">k</italic> = 49 voxels). IFG, inferior frontal gyrus; IPL, inferior parietal lobule; ITG, inferior temporal gyrus; SII, secondary somatosensory cortex; SMA, supplementary motor area; SMC, sensorimotor cortex; and SPL, superior parietal lobule.</italic></attrib></table-wrap-foot></table-wrap></div></details><details class="inner-accordion"><summary>Table 3 (T3) - Leading versus following in the whole group, the leader-only group, and the follower-only group.</summary><div class="table-html"><table-wrap id="T3" position="float" orientation="portrait"><label>Table 3</label><caption><p>Leading versus following in the whole group, the leader-only group, and the follower-only group.</p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="center" colspan="5" rowspan="1">Whole-group (<italic toggle="yes">n</italic> = 18)</th><th valign="top" align="center" colspan="5" rowspan="1">Leaders only (<italic toggle="yes">n</italic> = 11)</th><th valign="top" align="center" colspan="5" rowspan="1">Followers only (<italic toggle="yes">n</italic> = 10)</th></tr><tr><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" colspan="5" rowspan="1"><hr /></th><th valign="top" align="left" colspan="5" rowspan="1"><hr /></th><th valign="top" align="left" colspan="5" rowspan="1"><hr /></th></tr><tr><th valign="top" align="left" rowspan="1" colspan="1">Area</th><th valign="top" align="center" rowspan="1" colspan="1">BA</th><th valign="top" align="left" rowspan="1" colspan="1">Hemisphere</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">k</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Max</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">k</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Max</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">k</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Max</th></tr></thead><tbody><tr><td valign="top" align="left" colspan="2" rowspan="1"><bold>Activations: Leading &gt; Following</bold></td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   pre-SMA</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="left" rowspan="1" colspan="1">RH/LH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">3</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">58</td><td valign="top" align="center" rowspan="1" colspan="1">29</td><td valign="top" align="center" rowspan="1" colspan="1">5.24</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   SMA</td><td valign="top" align="center" rowspan="1" colspan="1">4,6</td><td valign="top" align="left" rowspan="1" colspan="1">RH/LH</td><td valign="top" align="center" rowspan="1" colspan="1">-4</td><td valign="top" align="center" rowspan="1" colspan="1">-4</td><td valign="top" align="center" rowspan="1" colspan="1">59</td><td valign="top" align="center" rowspan="1" colspan="1">81</td><td valign="top" align="center" rowspan="1" colspan="1">5.97</td><td valign="top" align="center" rowspan="1" colspan="1">-3</td><td valign="top" align="center" rowspan="1" colspan="1">-13</td><td valign="top" align="center" rowspan="1" colspan="1">64</td><td valign="top" align="center" rowspan="1" colspan="1">109</td><td valign="top" align="center" rowspan="1" colspan="1">6.28</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   CMA</td><td valign="top" align="center" rowspan="1" colspan="1">24</td><td valign="top" align="left" rowspan="1" colspan="1">RH/LH</td><td valign="top" align="center" rowspan="1" colspan="1">-6</td><td valign="top" align="center" rowspan="1" colspan="1">8</td><td valign="top" align="center" rowspan="1" colspan="1">37</td><td valign="top" align="center" rowspan="1" colspan="1">47</td><td valign="top" align="center" rowspan="1" colspan="1">4.84</td><td valign="top" align="center" rowspan="1" colspan="1">0</td><td valign="top" align="center" rowspan="1" colspan="1">2</td><td valign="top" align="center" rowspan="1" colspan="1">40</td><td valign="top" align="center" rowspan="1" colspan="1">85</td><td valign="top" align="center" rowspan="1" colspan="1">8.41</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   PMC</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">21</td><td valign="top" align="center" rowspan="1" colspan="1">-4</td><td valign="top" align="center" rowspan="1" colspan="1">55</td><td valign="top" align="center" rowspan="1" colspan="1">145</td><td valign="top" align="center" rowspan="1" colspan="1">8.01</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   PMC</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-26</td><td valign="top" align="center" rowspan="1" colspan="1">-13</td><td valign="top" align="center" rowspan="1" colspan="1">54</td><td valign="top" align="center" rowspan="1" colspan="1">51</td><td valign="top" align="center" rowspan="1" colspan="1">4.36</td><td valign="top" align="center" rowspan="1" colspan="1">-30</td><td valign="top" align="center" rowspan="1" colspan="1">-16</td><td valign="top" align="center" rowspan="1" colspan="1">64</td><td valign="top" align="center" rowspan="1" colspan="1">32</td><td valign="top" align="center" rowspan="1" colspan="1">5.71</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   DLPFC</td><td valign="top" align="center" rowspan="1" colspan="1">8,9</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-40</td><td valign="top" align="center" rowspan="1" colspan="1">29</td><td valign="top" align="center" rowspan="1" colspan="1">38</td><td valign="top" align="center" rowspan="1" colspan="1">98</td><td valign="top" align="center" rowspan="1" colspan="1">7.35</td><td valign="top" align="center" rowspan="1" colspan="1">-48</td><td valign="top" align="center" rowspan="1" colspan="1">32</td><td valign="top" align="center" rowspan="1" colspan="1">31</td><td valign="top" align="center" rowspan="1" colspan="1">46</td><td valign="top" align="center" rowspan="1" colspan="1">5.84</td><td valign="top" align="center" rowspan="1" colspan="1">-39</td><td valign="top" align="center" rowspan="1" colspan="1">44</td><td valign="top" align="center" rowspan="1" colspan="1">34</td><td valign="top" align="center" rowspan="1" colspan="1">76</td><td valign="top" align="center" rowspan="1" colspan="1">7.08</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   DLPFC</td><td valign="top" align="center" rowspan="1" colspan="1">9</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">-36</td><td valign="top" align="center" rowspan="1" colspan="1">23</td><td valign="top" align="center" rowspan="1" colspan="1">25</td><td valign="top" align="center" rowspan="1" colspan="1">30</td><td valign="top" align="center" rowspan="1" colspan="1">6.91</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   SPL</td><td valign="top" align="center" rowspan="1" colspan="1">7</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="center" rowspan="1" colspan="1">-73</td><td valign="top" align="center" rowspan="1" colspan="1">42</td><td valign="top" align="center" rowspan="1" colspan="1">70</td><td valign="top" align="center" rowspan="1" colspan="1">6.39</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="center" rowspan="1" colspan="1">-73</td><td valign="top" align="center" rowspan="1" colspan="1">49</td><td valign="top" align="center" rowspan="1" colspan="1">47</td><td valign="top" align="center" rowspan="1" colspan="1">7.56</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   SPL</td><td valign="top" align="center" rowspan="1" colspan="1">7</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-16</td><td valign="top" align="center" rowspan="1" colspan="1">-73</td><td valign="top" align="center" rowspan="1" colspan="1">36</td><td valign="top" align="center" rowspan="1" colspan="1">84</td><td valign="top" align="center" rowspan="1" colspan="1">5.44</td><td valign="top" align="center" rowspan="1" colspan="1">-18</td><td valign="top" align="center" rowspan="1" colspan="1">-79</td><td valign="top" align="center" rowspan="1" colspan="1">43</td><td valign="top" align="center" rowspan="1" colspan="1">48</td><td valign="top" align="center" rowspan="1" colspan="1">6.34</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   Cerebellum</td><td valign="top" align="center" rowspan="1" colspan="1">Tuber</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">47</td><td valign="top" align="center" rowspan="1" colspan="1">-65</td><td valign="top" align="center" rowspan="1" colspan="1">-17</td><td valign="top" align="center" rowspan="1" colspan="1">37</td><td valign="top" align="center" rowspan="1" colspan="1">5.00</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" colspan="2" rowspan="1"><bold>Deactivations: Following &gt; Leading</bold></td><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   PCC</td><td valign="top" align="center" rowspan="1" colspan="1">7,31</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">3</td><td valign="top" align="center" rowspan="1" colspan="1">-54</td><td valign="top" align="center" rowspan="1" colspan="1">23</td><td valign="top" align="center" rowspan="1" colspan="1">129</td><td valign="top" align="center" rowspan="1" colspan="1">-5.36</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">3</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">31</td><td valign="top" align="center" rowspan="1" colspan="1">92</td><td valign="top" align="center" rowspan="1" colspan="1">-11.12</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   TPJ</td><td valign="top" align="center" rowspan="1" colspan="1">39,40</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">45</td><td valign="top" align="center" rowspan="1" colspan="1">-59</td><td valign="top" align="center" rowspan="1" colspan="1">25</td><td valign="top" align="center" rowspan="1" colspan="1">28</td><td valign="top" align="center" rowspan="1" colspan="1">-5.33</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">48</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">31</td><td valign="top" align="center" rowspan="1" colspan="1">89</td><td valign="top" align="center" rowspan="1" colspan="1">-8.86</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   TPJ</td><td valign="top" align="center" rowspan="1" colspan="1">39,40</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-53</td><td valign="top" align="center" rowspan="1" colspan="1">-63</td><td valign="top" align="center" rowspan="1" colspan="1">23</td><td valign="top" align="center" rowspan="1" colspan="1">105</td><td valign="top" align="center" rowspan="1" colspan="1">-5.70</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   STS</td><td valign="top" align="center" rowspan="1" colspan="1">19,39</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">48</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">16</td><td valign="top" align="center" rowspan="1" colspan="1">92</td><td valign="top" align="center" rowspan="1" colspan="1">-10.18</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   STS</td><td valign="top" align="center" rowspan="1" colspan="1">37,39</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">-51</td><td valign="top" align="center" rowspan="1" colspan="1">-52</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">66</td><td valign="top" align="center" rowspan="1" colspan="1">-5.94</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   aSTG</td><td valign="top" align="center" rowspan="1" colspan="1">13,22</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">57</td><td valign="top" align="center" rowspan="1" colspan="1">-16</td><td valign="top" align="center" rowspan="1" colspan="1">-2</td><td valign="top" align="center" rowspan="1" colspan="1">72</td><td valign="top" align="center" rowspan="1" colspan="1">-9.70</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   Temporal pole</td><td valign="top" align="center" rowspan="1" colspan="1">38</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">-48</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">-23</td><td valign="top" align="center" rowspan="1" colspan="1">30</td><td valign="top" align="center" rowspan="1" colspan="1">-8.09</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   PHC</td><td valign="top" align="center" rowspan="1" colspan="1">30,36</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">17</td><td valign="top" align="center" rowspan="1" colspan="1">-33</td><td valign="top" align="center" rowspan="1" colspan="1">0</td><td valign="top" align="center" rowspan="1" colspan="1">39</td><td valign="top" align="center" rowspan="1" colspan="1">-4.72</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">42</td><td valign="top" align="center" rowspan="1" colspan="1">-40</td><td valign="top" align="center" rowspan="1" colspan="1">1</td><td valign="top" align="center" rowspan="1" colspan="1">28</td><td valign="top" align="center" rowspan="1" colspan="1">-6.13</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   PHC</td><td valign="top" align="center" rowspan="1" colspan="1">28</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-21</td><td valign="top" align="center" rowspan="1" colspan="1">-16</td><td valign="top" align="center" rowspan="1" colspan="1">-6</td><td valign="top" align="center" rowspan="1" colspan="1">103</td><td valign="top" align="center" rowspan="1" colspan="1">-5.76</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">-30</td><td valign="top" align="center" rowspan="1" colspan="1">-22</td><td valign="top" align="center" rowspan="1" colspan="1">-11</td><td valign="top" align="center" rowspan="1" colspan="1">67</td><td valign="top" align="center" rowspan="1" colspan="1">-7.52</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   Thalamus</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">21</td><td valign="top" align="center" rowspan="1" colspan="1">-25</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">59</td><td valign="top" align="center" rowspan="1" colspan="1">-6.72</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /></tr></tbody></table><table-wrap-foot><attrib><italic toggle="yes">Talairach coordinates for the contrast “Leading versus Following” in the whole group, leaders only, and followers only (<italic toggle="yes">p</italic> &gt; 0.005 uncorrected, <italic toggle="yes">k</italic> = 28 voxels). aSTG, anterior superior temporal gyrus; CMA, cingulate motor area; DLPFC, dorsolateral prefrontal cortex; PCC, posterior cingulate cortex; PHC, parahippocampal cortex; PMC, premotor cortex; SMA, supplementary motor area; SPL, superior parietal lobule; STS, superior temporal sulcus; and TPJ, temporo-parietal junction.</italic></attrib></table-wrap-foot></table-wrap></div></details><details class="inner-accordion"><summary>Table 4 (T4) - Leading versus following correlated with skill as a leader.</summary><div class="table-html"><table-wrap id="T4" position="float" orientation="portrait"><label>Table 4</label><caption><p>Leading versus following correlated with skill as a leader.</p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><thead><tr><td valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1">Area</th><th valign="top" align="center" rowspan="1" colspan="1">BA</th><th valign="top" align="left" rowspan="1" colspan="1">Hemisphere</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">k</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Max</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">R</italic><sup>2</sup></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Activation</bold></td><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">pre-SMA</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="center" rowspan="1" colspan="1">8</td><td valign="top" align="center" rowspan="1" colspan="1">58</td><td valign="top" align="center" rowspan="1" colspan="1">55</td><td valign="top" align="center" rowspan="1" colspan="1">0.73</td><td valign="top" align="center" rowspan="1" colspan="1">0.37</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">SMA</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">12</td><td valign="top" align="center" rowspan="1" colspan="1">-7</td><td valign="top" align="center" rowspan="1" colspan="1">55</td><td valign="top" align="center" rowspan="1" colspan="1">184</td><td valign="top" align="center" rowspan="1" colspan="1">0.81</td><td valign="top" align="center" rowspan="1" colspan="1">0.46</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">dPMC</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">36</td><td valign="top" align="center" rowspan="1" colspan="1">-1</td><td valign="top" align="center" rowspan="1" colspan="1">37</td><td valign="top" align="center" rowspan="1" colspan="1">46</td><td valign="top" align="center" rowspan="1" colspan="1">0.66</td><td valign="top" align="center" rowspan="1" colspan="1">0.49</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">Insula</td><td valign="top" align="center" rowspan="1" colspan="1">13</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">33</td><td valign="top" align="center" rowspan="1" colspan="1">-25</td><td valign="top" align="center" rowspan="1" colspan="1">28</td><td valign="top" align="center" rowspan="1" colspan="1">101</td><td valign="top" align="center" rowspan="1" colspan="1">0.71</td><td valign="top" align="center" rowspan="1" colspan="1">0.50</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">STG</td><td valign="top" align="center" rowspan="1" colspan="1">41,22</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">54</td><td valign="top" align="center" rowspan="1" colspan="1">-28</td><td valign="top" align="center" rowspan="1" colspan="1">10</td><td valign="top" align="center" rowspan="1" colspan="1">62</td><td valign="top" align="center" rowspan="1" colspan="1">0.66</td><td valign="top" align="center" rowspan="1" colspan="1">0.48</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Deactivation</bold></td><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">Cingulate</td><td valign="top" align="center" rowspan="1" colspan="1">13,13</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-21</td><td valign="top" align="center" rowspan="1" colspan="1">-34</td><td valign="top" align="center" rowspan="1" colspan="1">28</td><td valign="top" align="center" rowspan="1" colspan="1">87</td><td valign="top" align="center" rowspan="1" colspan="1">-0.74</td><td valign="top" align="center" rowspan="1" colspan="1">0.37</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">Lingual</td><td valign="top" align="center" rowspan="1" colspan="1">19</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-33</td><td valign="top" align="center" rowspan="1" colspan="1">-58</td><td valign="top" align="center" rowspan="1" colspan="1">-2</td><td valign="top" align="center" rowspan="1" colspan="1">46</td><td valign="top" align="center" rowspan="1" colspan="1">-0.72</td><td valign="top" align="center" rowspan="1" colspan="1">0.30</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /></tr></tbody></table><table-wrap-foot><attrib><italic toggle="yes">Talairach coordinates for the contrast “Leading versus Following” in the whole group correlated with the covariate “leader skill” (<italic toggle="yes">p</italic> &gt; 0.025 uncorrected, <italic toggle="yes">k</italic> = 46 voxels). <italic toggle="yes">R</italic><sup>2</sup> is the coefficient of determination of the regression of the cluster’s mean beta value against leader skill. dPMC, dorsal premotor cortex; SMA, supplementary motor area; and STG, superior temporal cortex.</italic></attrib></table-wrap-foot></table-wrap></div></details><details class="inner-accordion"><summary>Table 5 (T5) - Leading versus following correlated with skill as a follower.</summary><div class="table-html"><table-wrap id="T5" position="float" orientation="portrait"><label>Table 5</label><caption><p>Leading versus following correlated with skill as a follower.</p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><thead><tr><td valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1">Area</th><th valign="top" align="center" rowspan="1" colspan="1">BA</th><th valign="top" align="left" rowspan="1" colspan="1">Hemisphere</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">k</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Max</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">R</italic><sup>2</sup></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Activation</bold></td><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Deactivation</bold></td><td valign="top" align="left" rowspan="1" colspan="1">PCC</td><td valign="top" align="center" rowspan="1" colspan="1">7,31</td><td valign="top" align="left" rowspan="1" colspan="1">RH/LH</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="center" rowspan="1" colspan="1">-55</td><td valign="top" align="center" rowspan="1" colspan="1">37</td><td valign="top" align="center" rowspan="1" colspan="1">78</td><td valign="top" align="center" rowspan="1" colspan="1">-0.75</td><td valign="top" align="center" rowspan="1" colspan="1">0.30</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">mPFC</td><td valign="top" align="center" rowspan="1" colspan="1">9,10</td><td valign="top" align="left" rowspan="1" colspan="1">RH/LH</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="center" rowspan="1" colspan="1">47</td><td valign="top" align="center" rowspan="1" colspan="1">22</td><td valign="top" align="center" rowspan="1" colspan="1">64</td><td valign="top" align="center" rowspan="1" colspan="1">-0.73</td><td valign="top" align="center" rowspan="1" colspan="1">0.27</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">pSTS</td><td valign="top" align="center" rowspan="1" colspan="1">19,39</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">42</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">13</td><td valign="top" align="center" rowspan="1" colspan="1">90</td><td valign="top" align="center" rowspan="1" colspan="1">-0.75</td><td valign="top" align="center" rowspan="1" colspan="1">0.61</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">TPJ</td><td valign="top" align="center" rowspan="1" colspan="1">39,40</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">48</td><td valign="top" align="center" rowspan="1" colspan="1">-52</td><td valign="top" align="center" rowspan="1" colspan="1">43</td><td valign="top" align="center" rowspan="1" colspan="1">72</td><td valign="top" align="center" rowspan="1" colspan="1">-0.72</td><td valign="top" align="center" rowspan="1" colspan="1">0.48</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /></tr></tbody></table><table-wrap-foot><attrib><italic toggle="yes">Talairach coordinates for the contrast “Leading versus Following” in the whole group correlated with the covariate “follower skill” (<italic toggle="yes">p</italic> &gt; 0.025 uncorrected, <italic toggle="yes">k</italic> = 46 voxels). <italic toggle="yes">R</italic><sup>2</sup> is the coefficient of determination of the regression of the cluster’s mean beta value against follower skill. mPFC, medial prefrontal cortex; PCC, posterior cingulate cortex; pSTS, superior temporal sulcus; and TPJ, temporo-parietal junction.</italic></attrib></table-wrap-foot></table-wrap></div></details></details>
</details>


<details class="doc-card">
  <summary><strong>PMID 31056647</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/31056647/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>31056647_analysis_0</td><td>Emotional support group &gt; no support group</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Cyberball is a social exclusion task; the contrast assesses changes in social processing (effects of social support on exclusion). Both inclusion criteria (social-related task and measuring social processing) are met.</td></tr>
<tr><td>31056647_analysis_1</td><td>Appraisal support group &gt; no support group</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast examines neural responses to social exclusion (cyberball) and modulation by social support, directly targeting social processing (social pain, belonging). It satisfies that the task is social and the contrast measures social processing.</td></tr>
<tr><td>31056647_analysis_2</td><td>Appraisal support group &gt; no support group</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast examines social exclusion (Cyberball) and effects of social support on neural/behavioral responses — clearly a social processing task measuring responses to social interactions and exclusion.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>31056647_1</td><td>appraisal support group &gt; no support group (run 1 &gt; run 2); affiliation</td><td>31056647_analysis_1</td><td>Appraisal support group &gt; no support group</td><td>0.840</td><td>1.000</td><td>0.952</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>31056647_2</td><td>appraisal support group &gt; no support group (run 2 &gt; run 1); affiliation</td><td>31056647_analysis_2</td><td>Appraisal support group &gt; no support group</td><td>0.840</td><td>1.000</td><td>0.952</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>31056647_3</td><td>emotional support group &gt; no support group (run 1 &gt; run 2); affiliation</td><td>31056647_analysis_0</td><td>Emotional support group &gt; no support group</td><td>0.840</td><td>1.000</td><td>0.952</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  <details class="inner-accordion"><summary>PMC full text available (PMCID 6688450)</summary><p><strong>Title:</strong> Social support modulates the neural correlates underlying social exclusion</p><details><summary>Abstract</summary><pre class="paper-text">Ostracism threatens the human need for social interactions, with negative consequences on cognition, affect and behavior. Understanding the mechanisms that can alleviate these consequences has therefore become an important research agenda. In this study, we used behavioral and fMRI measures to advance our understanding how social support can buffer the negative effects of social exclusion. We focused on two different types of support from a friend: emotional support, conveyed by gentle touch and appraisal support, implemented as informative text messages. Seventy-one female participants underwent fMRI scanning while playing a virtual ball-tossing game in the course of which they were excluded. Two consecutive runs of the game were separated according to the participant’s experimental condition (appraisal support, emotional support and no support). Results showed that the experience of social exclusion is modulated by the type of support received. Specifically, emotional support decreased negative emotions and anterior insula activity, while appraisal support increased negative emotions, with concomitant increase of subgenual anterior cingulate cortex and decrease of temporal-parietal junction activity. These divergent effects of social support point to the necessity to characterize whether and under which conditions it represents an effective and positive resource to alleviate the negative consequences of social exclusion.</pre></details><details><summary>Body</summary><pre class="paper-text">## Introduction 
  
The aim of the present study was to investigate how different types of social support reduce negative feelings associated with social exclusion and its activation at the neural level. Human beings have a fundamental need to interact with each other. Ostracism (social exclusion) threatens this need and has various effects on cognition, affect and behavior ( ). It is often associated with experiences of pain, often called social pain, defined as ‘the distressing experience arising from the perception of actual or potential psychological distance from close others or a social group’ ( ;  ).   refers to it as one of the most painful and emotionally unpleasant conditions that the individual can live with, as it bears the risk of damaging his ability to relate to other individuals. Experimental neuroscientific research over the past decades has extensively focused on the understanding of ostracism’s neurophysiological underpinnings. Mainly investigated via computer-controlled ball-tossing games (the cyberball game, see   for review), the experience of exclusion from the game (social exclusion) usually results in feelings of unpleasantness and discomfort, with concomitant recruitment of a network of brain areas associated with the processing of negative affect, such as the dorsal anterior cingulate cortex (dACC), the subgenual anterior cingulate cortex (subACC) ( ;  ;  ;  ) and the anterior insula (AI) ( ). It is currently a matter of debate if the fingerprint of social exclusion resembles the negative experience associated with pain of physical nature ( ;  ). For example, the experiences of social exclusion and physical pain reflect many common psychological and biological characteristics: from the use of similar words (‘I feel hurt’) ( ), the involvement of overlapping neurochemical ( ;  ) and neural systems ( ), to comparable inflammatory responses and genetic regulation ( ;  ;  ). These commonalities may stem from similar adaptive evolutionary functions ( ). As physical damage to an organism threatens its survival, and the presence of pain lead to protective responses via unpleasant and distressing psychological states, feelings of pain and discomfort after separation from the individual’s social group may serve as protective factors preventing such separation. Consequently, social pain may have promoted safety in a similar manner as physical pain; when a ‘socially painful’ event has occurred, it may drive the individual to repair the social relationship or to seek new ones ( ). However, behaviors that are adaptive when an individual experiences acute pain, e.g. avoiding activities that increase pain, when pain becomes chronic may develop into patterns of behavior that are maladaptive and impair long-term health ( ). Similarly, social pain responses that are situationally appropriate, e.g. feeling angry or avoiding a group after being rejected, may lead to less-effective coping and long-term social isolation, when they become a chronic issue ( ). Given the negative and serious long-term consequences of pain exposure, it is mandatory therefore to understand and promote factors that facilitate the remission or prevent the initiation of such psychological and behavioral effects. In that regard, positive aspects of one’s social world (social support) may improve coping responses and overall well-being. For example, according to  , p. 11), social support is configured as an ‘exchange of resources between two individuals, perceived by the one who provides it - or by those who receive it - as something aimed at increasing the well-being of the recipient’.   describes it in terms of perceived and real, useful and/or significant supplies provided by the community, social networks and trustworthy partners associated to the well-being of the subject.   identifies different types of social support:   `  emotional support’ is associated with sharing life experiences and involves the provision of empathy, love, trust and care; `instrumental support’ involves behaviors that directly help people in need using tangible help (like tangible services and economic benefits); `informational support’ involves the provision of advice, suggestions and information that a person can use to address problems; and finally `appraisal support’ involves the provision of information that is useful for evaluation purposes: constructive feedback, affirmation and social comparison. Several empirical studies ( ;  ;  ) have examined the function of social support on the perception of physical pain, demonstrating a remarkable correlation between social support and the reduction of physical pain experience. Meaningful social connections have also been shown to serve a protective role in reducing neural, physiological and neuroendocrine responses to pain and stress including heart rate, blood pressure and cardiovascular and neuroendocrine responses ( ;  ). Given the strong commonalities between physical and social pain, it is not surprising that the interest on the effects of social support on physical pain has been extended to stressors of social nature, with similar results reported. In particular, psychosocial stress caused by social evaluation ( ) has been observed to be reduced by social support ( ). Interestingly, different types of social supports (verbal support, physical contact) have been associated to different reactions in women ( ), suggesting that not all types of social support are effective in reducing the physiological responses to social stress. In spite of the rich scientific literature on social support and psychological stress upon social evaluation, only few studies have directly examined the effects of social support on the feeling of social pain caused by, for example, social exclusion or ostracism. Similarly, to psychological stress, these studies suggest that the presence of a friend ( ), supportive emotional texts ( ) or gentle slow touch ( ) are able to reduce the negative feelings caused by social exclusion. On the neural level, self-reported supportive daily life interactions have been shown to diminish neuroendocrine stress responses and to correlate with decreased activity in the dACC following ostracism ( ). Similarly,   observed that supportive emotional text leads to reduced AI and enhanced theory of mind (ToM) network activity ( ;  ;  ;  ) during social exclusion. 

To date, however, a single study examining how different types of social support modulates feelings of social pain and how this is represented at the neural level has not been performed yet. Our study aimed, for the first time, at disclosing the role of different support strategies in modulating the behavioral and neural correlates involved in social exclusion. Specifically, we used two different types of support: emotional physical support (emotional support), which we implemented as gentle touch, and informational/appraisal support (appraisal support), which we implemented as informative text messages allowing to better understand the situation. In line with the previous literature, we hypothesized feelings of social pain, induced via exclusion from a virtual ball-tossing game, to be reduced after experiencing social support. Furthermore, we hypothesized such behavior to be associated with reduced activity of the neural network involved during the experience of social exclusion. Finally, we expect different neurophysiological effects depending on the type of social support experienced. In particular, we expected the emotional support group to show modulatory effect in the affective network (e.g. AI, ACC) while the appraisal support group to additionally modulate the ToM network ( ) 


## METHODS 
  
### Participants 
  
In total, 81 Italian female volunteers (age, 21.67 ± 2.29 years) with no history of neurological or psychiatric disorders (assessed with semi-structured interviews conducted by a psychologist) were recruited among undergraduate students at the University of Turin. We chose to include females only, as gender differences on social exclusion are well-documented (see  ;  ). All participants were right-handed according to the Edinburgh Handedness Inventory ( ). Female friends of a similar age as the participants were invited to participate in the experiment, and instructed to act as confederates. Subjects were randomly assigned to one of the three groups: appraisal support group (N = 26), emotional support group (N = 26) and no support group (N = 29). Ten participants were excluded from the study because of excessive movement or lack of compliance during the functional Magnetic Resonance Imaging (fMRI) session, leaving the final sample for the three groups as follows: appraisal support group (N = 23), emotional support group (N = 23) and no support group (N = 25). All participants signed the information
consent after the experimental procedures have been described to them. The study was approved by the Bioethics Committee of the University of Turin. 


### Social pain task 
  
In order to create in the fMRI environment the uncomfortable situation in which participants could experience social exclusion, we used a modified version of the well-known `cyberball game’ ( ), which has been widely used in the literature ( ;  ;  ;  ;  ). Our version was developed by  , who replaced the animated cartoons of the cyberball game by videos showing schematic virtual representations of real people tossing the ball to each other. The task was composed of 10 blocks with two experimental conditions: `social inclusion’ and `social exclusion’. In each block the ball-tossing game included a total of 12 passes, distributed between three players (including the participant). In the five blocks inducing the experience of social inclusion, the participant received at least one third of the total passes, while in the five blocks inducing social exclusion, the participant received less than one third of the total passages (see   for a detailed description of the stimuli preparation and procedure). Once the participant received the ball, she had to decide to whom to throw it back by pressing with her index (left player) or middle (right player) finger on an Magnetic Resonance Imaging (MRI) compatible button box. The presentation of the blocks was equal for all the participants with a pseudorandomized order: the first three and the last two blocks belonged to the inclusion condition, while the five blocks placed in the central position of the task belonged to the exclusion condition. Each ball-tossing game had an average duration of 33.5 s (range, 30–40 s). At the end of each game, the participant was asked to answer the question ‘How are your emotions?’ in order to report the valence and intensity of the emotions experienced during the game on a Likert scale with nine discrete values (from −4 = very negative on 0 to +4 = very positive) displayed for 4 s. The answer was given by using the same button box used to throw the ball (see  ). Of crucial relevance, this sequence of 10 blocks was performed twice, in two separate fMRI runs. In between the runs, emotional or appraisal support was provided by the participant’s friend in the two experimental groups, while no support was provided in the control group. 
  
 Exemplar trial for the social pain task.   In each trial, participants played the game with other two virtual players. During the game, once they receive the ball, they have to decide to whom to throw it back (as illustrated by the two arrows) by pressing the left or right key on the pad. In the inclusion condition, participants received the ball at least one third of the total tosses. In the exclusion condition, participants received the ball less than one third of the total tosses. Immediately after the game, they were asked to answer the question ‘How are your emotions?’ on a 9-point Likert scale, displayed for 4 s. Interstimulus interval was randomly jittered between 1 and 3 s. Arrows in the inclusion condition are inserted only for descriptive purposes and not displayed during the game. 
  

### Social support manipulation 
  
Two experimental groups of social support have been defined: emotional and appraisal. In the emotional support group  ,   each confederate (the female friend) was instructed to gently touch the hand of the participant, with the aim of comforting her. The characteristic of this group was the administration of support only through physical contact, without the use of verbal or expressive linguistic expressions. No specific constraints on how to deliver the touch was given to the confederates. Rather, they should hold, caress and tenderly squeeze her friend’s hand as she would normally do when trying to comfort her. 

In the appraisal support group, social support was given by the participant’s friend through text messages delivered and displayed on the back-projection screen in the scanner. In particular, the participants were told that the phrases they read on the monitor were written and sent directly by their friend from a PC situated in another room, where she could follow the game. Each participant saw 10 pre-prepared phrases meant to give additional information in order to help the understanding of the experience of social exclusion (for example: ‘I think that these two players are actually friends’ or ‘I think that when the experiment will end, we’ll see them go away together’). Importantly, the content of the text was never aimed to comfort the subject but rather to give information allowing the reappraisal of the situation, and it was always emotionally neutral. 

Finally, in order to tease apart the effect of the repetition of the task (adaptation, fatigue, etc.), the control group did the social exclusion task twice but without receiving any kind of support in between. We chose such control condition because the mere presence of a friend, even without delivering any social support, could have affected the following experience of social exclusion ( ). All conditions of social support lasted for 3 min and were delivered between runs 1 and 2 of the cyberball game, while the subject was resting inside the scanner. For the no support group, the same interval was kept between runs 1 and 2, and the subject asked to wait still for the next run to start. 


### Procedure 
  
Each participant, previously randomly assigned to one of three groups, and her friend (except for the no support group in which participants came alone) were received in the fMRI room of the hospital and informed about the study. Specifically, participants were told that they would be connected via Internet to two other players, located in another room of the hospital. After the general information, each confederate was accommodated in the adjacent room for observing through a monitor what happens to her friend during the game. Here she was instructed on what she had to do for the different support conditions. For all participants, after the verbal instruction about the cyberball game, a training session was performed outside of the scanner to ensure that participants understood the game. A second short practice session was administered in the scanner to familiarize the participants with the response recording system. The cyberball game was programmed using Cogent toolbox (2000), running on Matlab 2007 (Mathworks, Cherborn, MA, USA). Inside the scanner, the stimuli were presented via a head coil-mounted display system (Resonance Technology, Inc.). The fMRI session was composed of three phases performed on the same day (see  ): (i) social pain task run 1: each participant was scanned while engaging in the virtual cyberball game, as described above; (ii) social support: each experimental group received social support (e.g. emotional or appraisal), while the control group did not receive any kind of support. During this section, no fMRI scanning was performed. (iii) Social pain task run 2: each participant was scanned for the second time while engaging in the virtual cyberball task, as described above. After the fMRI session, each participant answered a brief interview aimed at investigating the believability of the manipulation. In particular, we asked indirect questions such as: ‘What do you think about the players? How was the game for you? Do you have any comments?’ None of the participants expressed doubts about the veracity of the situation. 
  
 Timeline of the fMRI session.   Each fMRI session was divided into three phases performed on the same day: (i) social pain task run 1, (ii) social support (emotional, appraisal, no support), (iii) social pain task run 2. Social support was either emotional or appraisal for a duration of 3 min. In the case of the no support group, a 3 min break between the two runs was carried out. 
  

### MRI data acquisition 
  
The MRI data were acquired using a 3.0 T MRI Scanner (Philips Ingenia) with a 32-channel array head coil. The study was performed at the Center of Brain Imaging 3 T-NIT, at the Hospital Città della Salute e della Scienza in Turin, Italy. Echo-Planar Image (EPI) sequence [TR/TE, 2000/30 ms; 33 slices, matrix size, 64 × 64; interslice gap, 0.5 mm; field of view (FOV), 230 × 230 mm ; flip angle, 90 degrees; slices aligned to the AC-PC line, 230 volumes/run] for functional images was applied. A total of 226 volumes per subject per run were collected. The first four volumes of each run were discarded to allow the equilibration of T1 saturation effects. T1-weighted sequence MP-RAGE (TR, 8.1 ms; TI, 900 ms; TE, 3.7 ms; voxel size, 1 × 1 × 1 mm ) for structural images of the whole brain was used. 
  
Contrasts of interest 
  
Significant voxels are reported threshold of   P   ≤ 0.05 FWE corrected for small volumes.Peak activity coordinates are given in MNI space. Significant value for   P   &lt; 0.001 uncorrected. 
  

### Data analysis 
  
#### Behavioral analysis 
  
Emotional ratings given by the participants after each round of the cyberball game were analysed in order to investigate differences in the emotional experience between exclusion and inclusion trials and between the first and second run, i.e. before and after receiving social support. We conducted a repeated-measures ANOVA with two within-subjects factors, condition (inclusion, exclusion), time (runs 1 and 2), and one between-subject factor, group (emotional support, appraisal support, no support). Ratings of the exclusion condition were multiplied by −1 in order to carry the same direction as the inclusion ratings, allowing to test the three-way interaction. Statistical analyses were performed with IBM SPSS Statistics version 24. 


#### fMRI data analysis 
  
The MRI data were analysed using Statistical Parametric Mapping 12 (SPM12, Wellcome Department of Cognitive Neurology, London, UK) run on Matlab 2007 (Mathworks, Cherborn, MA, USA). All functional images have been pre-processed following this order: spatially realigned to the first volume, co-registered to the mean image, segmented in cerebrospinal fluid tissues, gray matter and white matter, then normalized to the Montreal Neurological Institute (MNI) space and finally smoothed at the first level with an 8 mm full-width half-maximum Gaussian Kernel, with an additional 6 mm at the second level. Low-frequency drifts, high-pass temporal filtering with a cut-off of 128 s was used. After preprocessing, a General Linear Model ( ) for statistical analysis was used for both functional runs. Regressors of interest were convolved with a canonical hemodynamic response function. For each participant’s first level analysis, six regressors were computed: social inclusion (I), social exclusion (I), emotion rating (I), social inclusion (II), social exclusion (II) and emotion rating (II). In addition, six parametric regressors of no interest were added to the design matrix to correct residual effects of head motion. At the second level, four contrasts of interest from the first-level analyses were fed into a flexible factorial design aiming at investigating the effect of social support on social exclusion, using a random effects analysis ( ). Linear contrast of the repeated-measures ANOVA with the within-subject factors, condition (exclusion, inclusion), time (runs 1 and 2), and the between-subject factor, group (emotional support, appraisal support, no support), were used to assess the interaction between the factors group and time. Given the main research question of our paper, only results for the exclusion condition are reported. We performed whole brain analyses with an initial threshold of   P   &lt; 0.001 uncorrected and reports clusters that survived Family-Wise Error (FWE) correction for small volumes (SVC) at   P   &lt; 0.05. For the SVC, we created two binary masks encompassing, first, the affective network specifically detected in social exclusion paradigms, and second, a network associated to representing other minds and intentions (ToM). Both masks are based on the most recent published meta-analyses on social exclusion and ToM, respectively. More specifically, the first mask included coordinates derived from two meta-analyses on social exclusion published by   and  . In spite of repeated attempts, it was, however, not possible to receive the original maps from both authors. Therefore, spheres of 10 mm radius centered on the reported main activation loci were generated and combined into one mask with the toolbox MarsBaR ( ). The second mask was provided as an image-based mask by ( ), based on their meta-analysis on ToM tasks (see   for more details). Given we did not expect the involvement of the ToM network for the emotional support group, only the first (affective) mask was used to investigate differences in activations between this group and the no support group. To investigate differences in activations between the appraisal support and no support groups and the emotional support and appraisal support groups, both the affective and the ToM masks were used. The MRIcron software package ( ;  ) was used for anatomical and cytoarchitectonic display and interpretation. 


#### Brain–behavior correlation analyses 
  
Pearson correlation analyses between brain activity and behavioral ratings were performed with IBM SPSS Statistics version 24. In particular, the difference in activity (∆) between the first and second run of social exclusion in the regions showing significant statistical difference (see  ) was correlated with the difference in emotional ratings between the two runs (run 1 minus run 2). Activity in these regions was extracted with REX (  http://web.mit.edu/swg/rex/rex.pdf  ). Correlations were performed for each group separately and corrected for the number of ROIs used in each group. 




## RESULTS 
  
### Behavioral results 
  
The ANOVA revealed a significant interaction effect time*condition*group [  F   = 3.39,   P   = 0.040, partial Eta squared = 0.091]. All the other effects and interactions were not significant (  F   &lt; .103) . Post hoc pairwise comparisons were used in order to characterize the effect of the triple interaction. In particular, in the emotional support group, a significant difference between exclusion run 1   vs   run 2 was observed, defined by a reduction of unpleasantness ratings during the second run (  M   = 5.57, SE = 1.91,   P   = 0.005). In the appraisal support group  ,   a significant difference between exclusion run 1   vs   run 2 was also observed, but with an opposite pattern, namely an increase of unpleasant emotions in the second run (  M   = −3.93, SE = 1.91,   P   = 0.044). The no support group did not show any significant difference between runs 1 and 2 for both conditions (see  ). Finally, the differences between the inclusion and exclusion runs (Δ inclusion, Δ exclusion) were entered in a one-way ANOVA to assess whether the groups significantly differed. The analysis revealed a significant difference between the groups in the Δ exclusion only (  F   = 6.22,   P   = 0.003). Post hoc multiple comparisons were used in order to characterize the effect. In particular, we observed a significant difference both between the emotional support group and the no support group (  M   = 0.564, SE = 0.265,   P   = 0.037) and the emotional support group and the appraisal support group (  M   = 0.949, SE = 0.270,   P   = 0.001). 
  
 Behavioral results.   Mean and confidence intervals (95%) divided by group, condition and run. Significant differences are marked with an asterisk (  P   &lt; 0.05, based on post hoc pairwise comparisons) 
  

### fMRI results 
  
  Emotional support group vs. No support group.   

 Emotional support (social exclusion run 1 &gt; social exclusion run 2) &gt; no support (social exclusion run 1 &gt; social exclusion run 2).  

The analysis revealed significantly reduced activation in the right AI (rAI, x = 33, y = 27, z = −8) for the emotional support group compared to the no support group ( ;  ) for the second run compared to the first run of social exclusion . 
  
 FMRI results.   Differences in the neural activation between the emotional support group vs. the no support group for the contrast: social exclusion run 1   &gt;   social exclusion run 2. The bar plots represent contrast estimates and 90% confidence intervals in the right AI. For illustrative purposes, statistical maps are displayed with a threshold of   P   &lt; 0.001 uncorrected and superimposed on a standard T1 template. 
  
 Emotional support (social exclusion run 2 &gt; social exclusion run 1) &gt; No support (social exclusion run 2 &gt; social exclusion run 1).  

No suprathreshold voxels were observed for the reverse contrast. 

  Appraisal support group vs. no support group.   

 Appraisal support (social exclusion run 1 &gt; social exclusion run 2) &gt; No support (social exclusion run 1 &gt; social exclusion run 2).  

The analysis revealed significantly reduced activation in the right temporal parietal junction (rTPJ, x = 46, y = −47, z = 27) for the appraisal support group compared to the no support group ( ;  ) for the second compared to the first run of social exclusion. A more liberal threshold of   P   &lt; 0.001 revealed reduced activation also in the left temporal parietal junction (lTPJ, x = −48, y = −53, z = 34). 
  
 FMRI results.   Differences in the neural activation between the appraisal support group   vs   the no support group for the contrast: social exclusion run 1 &gt; social exclusion run 2. The bar plots represent contrast estimates and 90% confidence intervals in the right TPJ. For illustrative purposes, statistical maps are displayed with a threshold of   P   &lt; 0.001 uncorrected and superimposed on a standard T1 template. 
  
 Appraisal support (social exclusion run 2 &gt; social exclusion run 1) &gt; No support (social exclusion run 2 &gt; social exclusion run 1).  

The analysis revealed significantly increased activation in the subACC (x = −5; y = 32, z = −5) for the appraisal support group compared to the no support group ( .  ) for the second compared to the first run of social exclusion. A more liberal threshold of   P   &lt; 0.001 revealed reduced activation also in the ventromedial prefrontal cortex (vmPFC) (2, y = 37, z = −8). 
  
 FMRI results.   Differences in the neural activation between the appraisal support group   vs   the no support group for the contrast: social exclusion run 2 &gt; social exclusion run 1. The bar plots represent contrast estimates and 90% confidence intervals in the subACC. For illustrative purposes, statistical maps are displayed with a threshold of   P   &lt; 0.001 uncorrected and superimposed on a standard T1 template. 
    
 Correlation results.   Scatterplot of the correlation between the difference in subACC activity between exclusion runs 1 and 2 (∆ subACC) and the difference in unpleasantness ratings between exclusion runs 1 and 2. 
  
  Emotional support group vs. Appraisal support group.   

No suprathreshold voxels were observed in any of the possible combinations. 


### Brain-behavior correlation analyses 
  
The following correlations were performed: (i) for the emotional support group, correlation between ∆ activity in rAI and ∆ unpleasantness ratings and (ii) for the appraisal support group, correlation between ∆ activity in rTPJ, subACC and ∆ unpleasantness ratings. The correlation analyses revealed a significant positive relationship between ∆ subACC and ∆ unpleasantness ratings in the appraisal support group (r(23) = 0.443,   P   &lt; 0.017 one tailed, corrected for the number of correlations performed). This means that in the appraisal support group, the increase of subACC activity observed in the second run of exclusion was associated to increased unpleasantness feelings in the second run ( ). All the other correlations were not significant. 



## DISCUSSION 
  
In the present study, we investigated the effects of different types of social support (emotional and appraisal) on the behavioral and neural correlates of the experience of social exclusion. Seventy-one female participants were scanned twice while playing the cyberball game. Between the two runs of the game, different types of support were delivered by a female friend. At the behavioral level, we observed that, compared to the control group (no support), the sample that received emotional support in the form of gentle touch, reported reduced feeling of unpleasantness during exclusion trials between the first and second run of the game, i.e. after they had received the emotional support. Our results are in line with the findings of  , which showed reduced reported distress associated to ostracism, after being touched with optimal speed (3 cm/s) to induce positive feelings and thereby promoting interpersonal touch and affiliative behavior ( ). By adding these results, our study was able to show for the first time that the experience of emotional support is associated, at the neural level, to a reduction of activity in right AI, a brain area involved in the processing of negative affect during social exclusion and self- and other-directed aversive experiences ( ;  ;  ). The effects of emotional social support on the experience of social pain resemble the findings reported on pain of physical nature ( ;  ). In particular, during the administration of painful stimuli, married women who held the hand of their partners indicated a lower value of perceived pain. The subjective experience was correlated with reduced activation of the brain areas involved in pain processing, including the AI ( ). Moreover, imagined social support, provided through the visualization of images portraying of loved ones, was also able to modify the neural activation of the insula ( ;  ) and reduce the feeling of distress upon physical pain. The similar effect of emotional support on social and physical pain suggests overlapping regulatory mechanisms, possibly associated to the activity of the μ-opioid system and its analgesic properties ( ). 

The more informative type of support yielded instead different results. At the behavioral level, participants reported increased feelings of unpleasantness after receiving information about the other two participants. The subjective experience was accompanied by a reduced activation in the right TPJ, an area included in the ToM network ( ;  ;  ) and involved in incongruency detection and self-other distinction ( ;  ;  ). TPJ is considered a central structure implicated in the representation of mental states of others ( ). A recent study has associated the function of this brain region to the update of the internal models of the situation in order to generate appropriate actions to the social contexts ( ). This function is particularly important when faced with unexpected stimuli that demand attention reorienting and model updates. The findings of the present study suggest that the information received during the support possibly allowed the participants to interpret what was happening during the first run of the game. Indeed, the participants that received information (e.g. ‘the two players are friends’ or ‘there is understanding between them’) leading to a better understating of the social situation, showed an increase of unpleasant emotions (possibly anger) and possibly a reduced need to understand what was happening, indicated by reduced activity in TPJ. To corroborate this hypothesis, we observed increased recruitment of the subACC after receiving the appraisal support. Furthermore, the increased activity in subACC was positively correlated with the increased negative feelings reported during the second run. Interestingly, the subACC is a region involved in affective processes but not in physical pain ( ). Several social pain studies have indicated an increase in activity in the subACC during the negative experience of social exclusion ( ;  ;  ).   indicated the possibility that greater responsivity in the subACC during peer rejection could reflect an inability to properly regulate emotions evocated by negative events. In line with this literature, some studies have shown that this area is more responsive to negative emotional stimuli among depressed patients and correlates to the severity of depressive symptoms ( ;  ). Notably and differently from subACC, the increased negative affect did not result in a concomitant increase of AI activity, suggesting that the effects of ostracism on affective pain-related brain areas were not modulated by this type of support received. These findings point to a different role of these two areas in emotional processing during social exclusion, possible link to affective saliency and the need of emotion regulation. Our results are partially in line with the findings by  , who reported different reactions depending on the type of social support (verbal or physical contact) received. In particular, they observed that only physical contact was effective in reducing the symptoms of distress associated to negative social evaluation, while verbal support did not show any different from the no support condition. In our case, though, the appraisal support group showed increased negative feelings and concomitant neural response. It is possible to speculate that the negative reaction observed after appraisal support could have adaptive functions for the person experiencing it, in that it may drive the individual to seek for new relationship, when the actual ones are dysfunctional ( ). 

In conclusion, our study provides the first neuroimaging evidences that experiences of social support can modulate regions of the brain recruited during social pain and possibly responsible for coding the negative valence and intensity of emotion experience. Furthermore, for the first time, we showed that this effect may be different depending on the type of support received. Social support is a very complex phenomenon in which various factors can influence how it is effective for the receiver (e.g. who is providing it, in which form, etc.). It has been shown that it does not always result in a reduction of the negative experiences associated to social stress ( ) and social pain. Instead, as observed in our study, it can also increase the negative emotional experience, which can still be functional for the individual in the short term. Therefore, it is very important to understand under which conditions (contextual, personal, modality, etc.) social support can represent an effective and positive resource to alleviate the negative consequences of social exclusion. Importantly, our findings are restricted to a female sample; therefore not generalizable to the entire population. Future studied are needed to extend these findings to samples representative of the general population such as male participants and different age groups ( ) and to explore alternative types of social support (e.g. instrumental, informational). 


## Supplementary Material</pre></details></details>
  <details class="inner-accordion"><summary>Coordinate-relevant source tables (1)</summary><details class="inner-accordion"><summary>Table 1 (TB1) - Contrasts of interest</summary><div class="table-html"><table-wrap id="TB1" orientation="portrait" position="float"><label>Table 1</label><caption><p>Contrasts of interest</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /></colgroup><thead><tr><th rowspan="1" colspan="1" /><th colspan="3" align="left" rowspan="1">
<bold>MNI coordinates</bold>
</th><th align="left" rowspan="1" colspan="1">
<bold><italic toggle="yes">Z</italic>-score</bold>
</th><th align="left" rowspan="1" colspan="1">
<bold><italic toggle="yes">T</italic>-value</bold>
</th><th align="center" rowspan="1" colspan="1">
<bold><italic toggle="yes">P</italic>-value</bold>
</th></tr><tr><th align="left" rowspan="1" colspan="1">
<bold>Anatomical region</bold>
</th><th align="left" rowspan="1" colspan="1">
<italic toggle="yes">X</italic>
</th><th align="left" rowspan="1" colspan="1">
<italic toggle="yes">Y</italic>
</th><th align="left" rowspan="1" colspan="1">
<italic toggle="yes">Z</italic>
</th><th rowspan="1" colspan="1" /><th rowspan="1" colspan="1" /><th align="center" rowspan="1" colspan="1">
<italic toggle="yes">FWE corrected</italic>
</th></tr></thead><tbody><tr><td align="left" colspan="7" rowspan="1">
<bold><italic toggle="yes">Emotional support group &gt; no support group</italic></bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic toggle="yes">Exclusion run 1 &gt; exclusion run 2</italic>
</td><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /></tr><tr><td align="left" rowspan="1" colspan="1">Right AI</td><td align="left" rowspan="1" colspan="1">33</td><td align="left" rowspan="1" colspan="1">27</td><td align="left" rowspan="1" colspan="1">−8</td><td align="left" rowspan="1" colspan="1">3.29</td><td align="left" rowspan="1" colspan="1">3.35</td><td align="left" rowspan="1" colspan="1">.052</td></tr><tr><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /></tr><tr><td align="left" colspan="7" rowspan="1">
<bold><italic toggle="yes">Appraisal support group &gt; no support group</italic></bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic toggle="yes">Exclusion run 1 &gt; exclusion run 2</italic>
</td><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /></tr><tr><td align="left" rowspan="1" colspan="1">rTPJ</td><td align="left" rowspan="1" colspan="1">46</td><td align="left" rowspan="1" colspan="1">−47</td><td align="left" rowspan="1" colspan="1">27</td><td align="left" rowspan="1" colspan="1">3.42</td><td align="left" rowspan="1" colspan="1">3.48</td><td align="left" rowspan="1" colspan="1">.046</td></tr><tr><td align="left" rowspan="1" colspan="1">lTPJ</td><td align="left" rowspan="1" colspan="1">−48</td><td align="left" rowspan="1" colspan="1">−53</td><td align="left" rowspan="1" colspan="1">34</td><td align="left" rowspan="1" colspan="1">3.22</td><td align="left" rowspan="1" colspan="1">3.27</td><td align="left" rowspan="1" colspan="1">.001<sup>*</sup></td></tr><tr><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /></tr><tr><td align="left" rowspan="1" colspan="1">
<bold><italic toggle="yes">Appraisal support group &gt; no support group</italic></bold>
</td><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /></tr><tr><td align="left" rowspan="1" colspan="1">
<italic toggle="yes">Exclusion run 2 &gt; exclusion run 1</italic>
</td><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /><td rowspan="1" colspan="1" /></tr><tr><td align="left" rowspan="1" colspan="1">Left subACC</td><td align="left" rowspan="1" colspan="1">−5</td><td align="left" rowspan="1" colspan="1">32</td><td align="left" rowspan="1" colspan="1">−5</td><td align="left" rowspan="1" colspan="1">3.34</td><td align="left" rowspan="1" colspan="1">3.39</td><td align="left" rowspan="1" colspan="1">.046</td></tr><tr><td align="left" rowspan="1" colspan="1">Right vmPFC</td><td align="left" rowspan="1" colspan="1">2</td><td align="left" rowspan="1" colspan="1">37</td><td align="left" rowspan="1" colspan="1">−8</td><td align="left" rowspan="1" colspan="1">2.99</td><td align="left" rowspan="1" colspan="1">3.03</td><td align="left" rowspan="1" colspan="1">.001<sup>*</sup></td></tr></tbody></table><table-wrap-foot><p>Significant voxels are reported threshold of <italic toggle="yes">P</italic> ≤ 0.05 FWE corrected for small volumes.Peak activity coordinates are given in MNI space.<sup>*</sup>Significant value for <italic toggle="yes">P</italic> &lt; 0.001 uncorrected.</p></table-wrap-foot></table-wrap></div></details></details>
</details>


<details class="doc-card">
  <summary><strong>PMID 31142792</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/31142792/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>31142792_analysis_0</td><td>Increased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares neural responses to disfigured vs. non-disfigured faces and discusses effects on empathy/mentalizing (anterior cingulate/medial prefrontal) and social bias — a social-related task measuring social processing.</td></tr>
<tr><td>31142792_analysis_1</td><td>Decreased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involved viewing faces and assessed implicit bias, dehumanization, and neural responses related to social cognition (empathy, mentalizing); so it measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>31142792_1</td><td>before treatment &gt; after treatment (decreased activation); self</td><td>31142792_analysis_1</td><td>Decreased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing.</td><td>0.414</td><td>1.000</td><td>0.824</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>31142792_2</td><td>before treatment &gt; after treatment (increased activation); self</td><td>31142792_analysis_0</td><td>Increased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing.</td><td>0.414</td><td>1.000</td><td>0.824</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  <details class="inner-accordion"><summary>PMC full text available (PMCID 6541618)</summary><p><strong>Title:</strong> Behavioural and Neural Responses to Facial Disfigurement</p><details><summary>Abstract</summary><pre class="paper-text">Faces are among the most salient and relevant visual and social stimuli that humans encounter. Attractive faces are associated with positive character traits and social skills and automatically evoke larger neural responses than faces of average attractiveness in ventral occipito-temporal cortical areas. Little is known about the behavioral and neural responses to disfigured faces. In two experiments, we tested the hypotheses that people harbor a disfigured is bad bias and that ventral visual neural responses, known to be amplified to attractive faces, represent an attentional effect to facial salience rather than to their rewarding properties. In our behavioral study (N = 79), we confirmed the existence of an implicit ‘  disfigured is bad  ’ bias. In our functional MRI experiment (N = 31), neural responses to photographs of disfigured faces before treatment evoked greater neural responses within ventral occipito-temporal cortex and diminished responses within anterior cingulate cortex. The occipito-temporal activity supports the hypothesis that these areas are sensitive to attentional, rather than reward properties of faces. The relative deactivation in anterior cingulate cortex, informed by our behavioral study, may reflect suppressed empathy and social cognition and indicate evidence of a possible neural mechanism underlying dehumanization.</pre></details><details><summary>Body</summary><pre class="paper-text">## Introduction 
  
Physical appearance has a profound impact on a person’s life. Beautiful people are preferred and enjoy many advantages compared to average-looking people . While conceptually orthogonal, the correlation of attractiveness and positive character traits indicates the prevalence of a ‘beautiful is good’ stereotype . This stereotype might be innate . Attractive people are seen as more trustworthy, socially competent, dominant, better adjusted, more capable in school and work, and also receive greater rewards and lesser punishments than their average looking peers . Adults and children ascribe desirable personality traits to attractive faces of adults and children and discriminate against unattractive faces even if they are friends and family members . Attractiveness and trustworthiness judgments are consistent across cultures  and are made extremely quickly . Longer exposure to a face does not attenuate these biases and instead only consolidates people’s confidence in a judgement already made . Attractiveness also highly influences visual exploration of faces . 

In this study we examine a corollary to the ‘beautiful is good’ stereotype, that an automatic ‘disfigured is bad’ stereotype also exists. People with facial disfigurement are stigmatized and are often targets of discrimination. Looking at disfigured faces makes observers feel less happy, less in control, less dominant, and more aroused . People with facial disfigurements are not only perceived as less attractive and less likely to be selected as romantic partners, they are also thought of as having unfavourable personality traits (e.g., lack of emotional stability, conscientiousness), internal attributes (e.g., unhappiness, lower intelligence), social qualities (e.g., untrustworthiness, unpopularity)  and are treated poorly in social interactions . In popular culture, facial disfigurement is often used to distinguish good and evil characters . Well known examples of disfigured villains are Scar in the   Lion King   (large facial scar over left eye), Freddy Krueger in   Nightmare on Elm Street   (3rd degree burns and exposed tissue), the   James Bond   villains Le Chiffre (facial scar over left eye), Emilio Largo (missing eye), Ernst Stavro Blofeld (large scar over right eye covering most of his right side of the face), and Alec Trevelyan (facial burn scars), Elle Driver in   Kill Bill   (missing eye), Two Face in the   Batman   Universe (acid scars covering the left side of his head), Hopper in   A Bug’s Life   (scar covering right eye), and the Duchess from   Alice in a Wonderland   (Macrocephaly). This ‘disfigurement is bad’ stereotype is only partially explained by lower attractiveness of disfigured faces . 

Attractiveness of faces –and therefore attribution of a’beauty is good’ stereotype- is highly correlated with typicality or statistical averageness of faces . In addition to being statistical averages of groups, attractive faces are also symmetric . Both facial symmetry and averageness are considered markers of physical health and influence peoples’ choices of partners . Disfigured faces are neither typical nor average, and are usually not symmetric. They often deviate substantially from the norm. If proximity to the norm predicts positive social attributions, being ‘different’ could lead to negative evaluations. Disfigured faces might be linked to unfavourable personality traits, internal attributes, and social qualities because they are less typical and deviate from the population average. The association of disfigurement with negative attributes probably drives stigmatization and discrimination of disfigured people in social, academic, and professional contexts . The stigmatization and discrimination of disfigured people likely contributes to low self-esteem  and long term mental health concerns similar to other stigmatized groups that are subject to dehumanization . Dehumanization deprives a person or a group of people of positive human qualities and has been shown for several stigmatized groups such as homeless people and drug addicts . Dehumanization is used as a propaganda tool in political conflicts . The strongest predictors of dehumanization are hypothesized to be perceived competence and warmth . Faces rated lowest on both competence and warmth most robustly evoke dehumanization - including feelings of disgust and lack of empathy . 

Neuroimaging studies show that seeing attractive faces evokes brain responses in reward, emotion, and visual areas compared to seeing faces of average attractiveness . Attractive faces produce activations in areas associated with reward, like the nucleus accumbens , and orbitofrontal cortex . Moreover, attractiveness correlates with increased activations in areas associated with emotion, empathy, and social cognition like the anterior cingulate cortex and medio-prefrontal cortex  the latter being particularly active in tasks in which people are not making explicit attractiveness judgements . Different regions of the prefrontal cortex are selectively responsive to either attractive or unattractive faces  which is consistent with findings that ventral medio-prefrontal cortex processes stimulus value attributes in coordination with higher order visual areas like fusiform gyri and semantic processing areas (posterior superior temporal sulcus) . Orbital frontal  and medial prefrontal cortices  seem to process both aesthetic and moral values and may represent the biological link between these two kinds of evaluation . 

Left and right amygdala seem to be sensitive to both attractive  and unattractive faces . These non-linear effects for extremes at either end of the attractiveness spectrum suggest that amygdala activation reflects sensitivity to valence intensity rather than positive or negative valence per se . In line with the valence processing hypothesis for the functional role of amygdala, increased activation in the amygdala (bilaterally) is linked to untrustworthiness of faces . A meta-analysis of brain activations to attractiveness and trustworthiness suggests that activation of amygdala and adjacent nucleus accumbens is driven by extremes and atypicality . There is some tentative evidence that face typicality can also account for the activations in medio-prefrontal and anterior cingulate cortex . The authors note that the brain networks activated in response to extremes of attractiveness and trustworthiness are remarkably similar to brain networks that process positive and negative emotions . 

In addition to increased brain activations in reward and emotion areas, attractive faces also evoke larger neural responses in selective visual processing areas within ventral occipito-temporal cortex (such as the fusiform face area) as compared to faces of average attractiveness . These areas remain sensitive to facial attractiveness even when subjects are engaged in tasks in which attractiveness judgements are not queried explicitly. These observations have previously been interpreted as evidence that these areas also process rewards. While a reward response is one possible explanation for this amplified neural response to attractive faces, it is also possible that this reflects sensitivity to the saliency of attractive faces . If this alternate hypothesis is true, other salient features, such as disfigurement, should lead to similarly amplified neural responses in visual processing areas. 

Viewing faces of stigmatized groups fails to activate brain regions associated with empathy and social cognition . Krendl and colleagues reported increased activation in anterior insula and amygdala which correlated with self-reported disgust in response to viewing faces of stigmatized groups . The lack of activation in empathy and social cognition regions of the brain is postulated to be a neural correlate of dehumanization . 

Appearance clearly affects how people are viewed and treated by others. The same mechanisms that benefit attractive people in social interaction, put unattractive people at an unfair disadvantage. The effects of discriminating against people with facial disfigurement seem to extend beyond the specific effects of lower overall attractiveness and may tie in more with the pattern of results that have been shown with stigmatized groups. 

The goal of the present study was to test the behavioural and brain responses to facial disfigurement and investigate whether surgical treatment mitigates these responses. In two experiments, we used a set of photograph pairs of patients with different types of facial disfigurements before and after surgical treatment of the disfigurement. In experiment one we tested if people harbour implicit biases against disfigured faces and if such implicit biases were different from consciously aware self-reported explicit biases. In a follow up functional MRI (fMRI) study, we tested differential automatic brain responses to the same picture pairs when naïve participants were engaged in an unrelated cover task. We hypothesized that people have negative biases against faces with disfigurement. For the neural responses to facial disfigurement we tested competing hypotheses: visual cortices respond to rewards per se, or visual cortices respond to salience. In addition, we expected disfigured faces to show selective responses in emotion and valence areas such as anterior insulae and amygdalae and anterior cingulate and lateral or medial prefrontal areas in line with the research reviewed above. 


## Results and Discussion 
  
The behavioural experiment (N = 79, see method section for details) consisted of an implicit association test  (IAT) and an explicit bias questionnaire (EBQ) to test the hypothesis that people have a negative bias for disfigured faces. For the IAT, we used a stimulus set of photographs of real patients taken before and after treatment for disfigurement. The EBQ consisted of 11 questions which query conscious biases against people with facial disfigurements (see   https://osf.io/ca2u9/   for all items and data). We found no indication of an explicit bias. However, we did find that non-disfigured faces were preferred in the IAT (see Fig.  ). This bias was particularly robust for men, consistent with previous findings . Prior exposure to disfigured faces did not modulate the implicit bias of individuals.   
Female respondents demonstrate significantly less, although still strong, implicit preference for non-disfigured faces than male respondents. Male respondents show a moderate explicit preference for non-disfigured faces while women show no explicit preference. Error bars indicate 95% confidence intervals. 
  

We used the same set of photographs of people before and after surgical treatment that we used in the IAT in the fMRI study (N = 31). Participants viewed these photographs and engaged in a gender judgement task. We measured neural responses to facial disfigurement to test competing hypotheses of reward versus salience in visual areas like fusiform face area. If these visual areas respond to rewards, then non-disfigured faces compared to disfigured faces would show increased activity in visual areas linked to face processing. If these visual areas respond to salience, then we should find the opposite results; disfigured faces compared to non-disfigured faces should show increased activity in these areas. Because people with facial disfigurement are likely treated as an outgroup , neural patterns in response to disfigurement should be similar to previous findings investigating other stigmatized groups . We predicted decreased activation in areas linked to social cognition such as medio-prefrontal cortex and anterior cingulate cortex, as well as increased activations in areas linked to disgust and negative emotion like anterior insula and amygdala. 

We found that images of people with facial disfigurement, as compared to images of the same faces after surgical treatment, evoked greater neural responses within ventral occipito-temporal cortex, particularly bilateral fusiform gyri (see Fig.  ), and right inferior frontal cortex. This observation confirms the hypothesis that face processing and adjacent areas respond automatically to the salience of faces, rather than their attractiveness or rewarding properties per se.   
Increased activations (red yellow) and deactivations (blue-green) in response to faces before treatment. Results were corrected for multiple comparisons by familywise error correction at p &lt; 0.05 with Monte Carlo permutation testing in SnPM with a combined cluster-voxel threshold (cluster defining threshold p &lt; 0.001, T &gt; 3.3852). 
  

In addition to increased responses in visual areas, we found decreases in neural response amplitude to disfigured faces in the medial anterior cingulate gyrus extending towards medial prefrontal cortex (see Figs   and  ), as well as in a region stretching from right cuneus to the right calcarine gyrus and right lingual gyrus. This finding is similar to previous observations of neural responses to other stigmatized outgroups such as drug addicts and homeless people  and could reflect suppression empathy and mentalizing or increased demands in cognitive control, e.g. inhibition of staring at the area of lesion or inhibition of inappropriate social behaviour like obvious avoidance. Both possible hypotheses are not mutually exclusive and could be linked to the increased activation in the left inferior frontal gyrus - a region linked to cognitive control.   
Increased activations (red yellow) and deactivations (blue-green) in response to faces before treatment. Results were corrected for multiple comparisons by familywise error correction at p &lt; 0.05 with Monte Carlo permutation testing in SnPM with a combined cluster-voxel threshold (cluster defining threshold p &lt; 0.001, T &gt; 3.3852). 
  

In previous studies, increased amygdala activation has been reported to both positive and negative valence of faces . Moreover, studies investigating the brain responses to extreme outgroups like homeless people and drug addicts find activations in anterior insula where it is typically interpreted as a disgust response . We did not find statistically significant activations in amygdala and anterior insula. It is possible that this lack of effect is because of our smaller stimulus sample or that the difference between before and after stimulus pairs is not large enough to produce statistically significant results in this before-after contrast of the same face. 

In sum, we found that people have implicit negative biases against faces that are disfigured, without being aware of harbouring such biases. Disfigured faces evoke greater neural responses in ventral occipito-temporal and right inferior frontal regions as compared to non-disfigured faces. This finding refutes the hypothesis that attractiveness and reward per se drives automatic ventral cortical responses and instead confirms the idea that ventral occipito-temporal regions are sensitive to the salience of faces. 

Moreover, disfigured faces evoke lower neural responses in the anterior cingulate and medio-prefrontal cortex, as well as some visual areas. This result is similar to previously reported neural responses to stigmatized outgroups like homeless people and drug addicts . In agreement with this research, we speculate that the de-activation of these brain areas upon seeing disfigured faces as opposed to the same faces after surgical treatment possibly reflects an inhibition of empathy and mentalizing or inhibition of socially inappropriate behaviour. The medial anterior cingulate gyrus and the adjacent medial prefrontal cortex are core areas of the theory of mind and empathy networks  and are crucial for inferring other’s beliefs, feelings, and mental states. Together with previous behavioural research showing a clear association of negative personality traits and our findings of an implicit bias against disfigured faces, we take these response patterns as neural evidence for stigmatization. Future research should investigate if the de-activation of anterior cingulate cortex represents a consistent neural marker for dehumanization of people with disfigured faces or if it reflects social adaptive behaviour to people who deviate from the norm. 

The emphasis of attractiveness, its association with positive attributes and robustness of these associations across cultures  highlights the pervasive effect of attractiveness in social interaction. People who fall towards the lower end of the attractiveness spectrum are disadvantaged or even subject to discrimination and social isolation as in the case of facial disfigurement. Encouragingly, our findings suggest that surgical treatment of disfigurement mitigates the negative effects of disfigurement. Our findings highlight the importance of recognizing that we implicitly and automatically regard flawed faces as flawed people and that corrective surgery confers social and psychological benefits to people with facial disfigurement. Alternative prevention strategies against discrimination of disfigured people and effective support for people with facial conditions should be explored. 


## Methods 
  
### Implicit association test (IAT) and explicit bias questionnaire (EBQ) 
  
#### Participants 
  
80 participants were recruited via an online recruiting system for psychology experiments at the University of Pennsylvania (55 female, 25 male, mean age = 23 years, SD = 6.4, range 18–56). The sample size was determined based on estimates suggested by a meta-analysis on attitudes towards individuals with disabilities as measured by an IAT . Prior to participation, participants were informed that the task was about categorising faces and words but were naïve to the fact that some of those faces might be disfigured. Participation was voluntary, and participants received money as compensation. Study procedures were approved by the Institutional Review Board (IRB) at the University of Pennsylvania (Protocol #806447). IRB approval was in accordance with the International Conference on Harmonization and the Belmont report. All participants gave written informed consent. 

One participant was excluded from the data analysis for the IAT because more than 10% of the total test trials were unreasonably fast (&lt;300 ms). After data exclusion, the data of 79 participants went into the final analysis (55 female, mean age = 23 years, SD = 6.4, range 18–56). 


#### Procedure 
  
Task order between the IAT and the EBQ was counterbalanced so that half of the participants completed the IAT first, and half of the participants completed the EBQ first. Participants were seated in a testing room, in front of a testing laptop. After having been briefed on the order of the tasks, participants gave written informed consent. The entire experiment took about 30 minutes. 

The IAT  was designed using E-Prime software and was modelled after the IATs from   Project Implicit   (  https://implicit.harvard.edu  ). A total of 16 words were used for the IAT: 8 were positive words (attractive, happy, approachable, friendly, adore, lovely, spectacular, excellent), and 8 were negative words (ugly, evil, sickening, rotten, disaster, disgust, pain, despise). 

Participants completed the EBQ as a survey on Qualtrics. Questions were modelled after the Project Implicit and Changing Faces explicit questionnaires . The questionnaire included 11 questions asking about participants’ prior exposure to and conscious biases against people with facial disfigurement. Participants responded on a scale ranging from 1 to 7 (see   https://osf.io/ca2u9/   for details). 


#### Pictures 
  
Images consisted of photographs of patients with facial disfigurements before and after corrective surgery. These photos were collected from craniofacial and dental surgery atlases and compilations of plastic surgery results. The disfigured faces were photos of the individuals before treatment that were affected by one of the following disfigurements: carcinoma, hyperpigmentation, birthmark, scar or small wound, facial paralysis, isolated weight loss, bone disfigurement, or facial trauma. The non-disfigured faces were photographs of the same individuals after treatment (see   https://osf.io/ca2u9/   for all stimulus pairs). Pre-treatment and post-treatment photographs were cropped (to show only faces, with some hair and neck) and colour-corrected to match in size and coloring . The stimulus set consisted of 28 faces, of which 22 were female and 6 were male. 16 of the faces were oriented frontally, 10 were oriented in a three-quarters portrait view, and 2 were profiles (see   https://osf.io/ca2u9/  ). 


#### Implicit association test and explicit bias measure results 
  
Explicit scores range from −3 to +3, with zero indicating no relative preference for non-disfigured vs. disfigured faces. Positive scores indicate a preference for non-disfigured faces, and negative scores indicate a preference for disfigured faces. We found a significant implicit preference for non-disfigured faces (mean difference score = 0.90; SD = 0.58; min = −0.26; max = 2.00;   t   = 13.80; 95% CI = 0.77 to 1.03; p &lt; 0.001; Cohen’s   d   = 1.55). This effect was particularly strong for male respondents (see Table   for details, see Fig.  ). Participants showed no significant explicit preference for non-disfigured vs. disfigured faces (mean explicit score = 0.01; SD = 0.51; min = −1.50; max = 1.08.168;   t   = 0.17; 95% CI = −0.11 to 0.12; p = 0.866; Cohen’s   d =   0.02). Prior exposure had no effect on bias for either the IAT or the EBQ. There was a small to moderate correlation between implicit and explicit scores that was, however, not statistically significant (Pearson’s correlation coefficient, r = 0.22; p = 0.052) making it difficult to draw conclusions as to whether people are aware of their biases.   
Implicit preferences for non-disfigured vs. disfigured faces for all participants by gender. 
  
IAT D scores range from −2 to +2, with zero indicating no relative preference for non-disfigured vs. disfigured faces. Positive scores indicate an implicit preference for non-disfigured faces while negative scores indicate an implicit preference for disfigured faces. D scores were interpreted according to specific, conservative break points based on Cohen’s   d  : ±0.15 (‘slight’ bias), 0.35 (‘moderate’ bias), 0.65 (‘strong’ bias). 

Cohen’s   d   is a standardized effect size, interpreted as   d   of 0.2 = small effect,   d   of 0.5 = medium effect, and   d   ≥ 0.8 = large effect. 
  



### FMRI experiment 
  
#### Participants 
  
We recruited 34 healthy right-handed college students from University of Pennsylvania (24 females, 10 males). Age of participants ranged from 18–35 years. Participants had normal or corrected to normal vision and no prior history of psychiatric or neurological disease. Before participation in the study, each individual gave informed consent approved by the IRB at the University of Pennsylvania (Protocol #806447) in accordance with the International Conference on Harmonization and the Belmont report. 

The data of three participants was excluded from the final analysis. One dataset was excluded because of technical failure which stopped the stimulus presentation halfway through the experiment. Two other datasets were excluded because of synchronization problems between experimenter laptop and the scanner triggers. The data of 31 participants entered the final analysis (22 females, 9 males). 

The EBQ for the participants in the fMRI experiment showed that about half of the participants have a close friend or family member with either a facial disfigurement or a disability. Exposure to people with facial disfigurement was normally distributed in the sample, and most participants reported no to slight preference for non-disfigured over disfigured people (22/28 data entries, 5 missing values). 


#### Procedure and stimulus presentation 
  
The experiment consisted of one session. Participants were presented with 28 pictures of faces in randomized order and were asked to decide whether the displayed face was male or female. Half of the presented pictures were photographs of patients before treatment, and half after treatment. The pictures were identical to the ones used in the behavioural experiment (IAT, see above). Stimuli were presented using E-prime software by projecting them onto a screen using a projector outside the MR scanner room, which could be seen by participants through a mirror mounted over the head coil. Each picture was presented for 6 seconds. Responses were recorded with a 2-button response device. After the experiment, a high-resolution anatomical scan (~7 min) was conducted. After the scanning session, participants were taken out of the scanner and completed the EBQ for disfigurement on a testing computer outside the scanner room. This test was identical to the EBQ in the online sample reported above. 


#### fMRI data acquisition and pre-processing 
  
Images of blood-oxygen level dependent (BOLD) changes were acquired with a 3 T Siemens Magnetom Prisma scanner (Erlangen, Germany) with a 64-channel head coil. We used cushions to minimize participants’ head movement. We used two localizing scans and auto-alignment. Functional images were acquired using a standard BOLD sequence (TR: 2000 ms, TE: 30 ms, flip angle: 60 degrees, voxel size: 2.0 × 2.0 × 2.0 mm, 81 slices). High resolution (0.8 × 0.8 × 0.8 mm) structural (anatomical) images were acquired using an SPC T1 GRAPPA sequence . Data were pre-processed using the Matlab toolbox SPM12 (  http://www.fil.ion.ucl.ac.uk/spm  ). Images were motion corrected and registered to the first image of the scanning block. The mean of the motion-corrected images was co-registered with the individual participants’ anatomical scan. The anatomical and functional scans were spatially normalized to the standard MNI template. Finally, all data were spatially smoothed using an isotropic 8 mm full width at half maximum (FWHM) Gaussian kernel. 


#### fMRI data analysis 
  
At the single-subject level, statistical analysis was performed using a general linear model. The motion estimates of the motion correction algorithm were modelled as regressors of no interest to account for head motion. We performed a whole-brain group analysis by directly contrasting the mean activations per condition in a non-parametric design with SnPM (  https://warwick.ac.uk/fac/sci/statistics/staff/academic-research/nichols/software/snpm  ). Results were corrected for multiple comparisons with a combined voxel-cluster level threshold by familywise error correction at p &lt; 0.05 with Monte Carlo permutation testing. 

In addition to the whole brain group analysis, we performed an item-wise region of interest control analysis to test if the effects in the group analysis are driven by specific items. The two clusters were defined by the group contrasts in the whole brain analysis and consisted of one area comprising of the two large occipital activation clusters, and one comprising the (de-)activation cluster in the anterior cingulate cortex. Mean values for these two regions were extracted for each subject and item. The mean values were normalised with the individual subject’s mean activation in this area to create relative difference scores per subject and item. The data for the item-wise analysis were analysed with linear mixed effect models in RStudio. We built one base model for each dependent variable (occipital cluster activation, anterior cingulate cluster activation) that included condition (pre or post surgery picture) as a predictor and subject and item as random factors with random intercepts. We tested for both random factors whether including random slopes for the condition would improve the model fit and tested interactions with gender and EBQ responses with the best base model (see   https://osf.io/ca2u9/   for details). 


#### FMRI sample results 
  
Participants performed at ceiling for the gender judgment task. 

An ANOVA analysis of the reaction time data in the gender judgement task in the scanner revealed no differences in reaction times between before and after treatment pictures (F  = 0.56, p = 0.45, see Fig.  ) and no differences for item (F  = 1.26, p = 0.17) and no interaction between item and face type (F  = 1.06, p = 0.38).   
Reaction times for gender judgement task per item split by face type. Error bars display 95% confidence intervals. 
  

We found increased activations in temporo-occipital regions encompassing bilateral middle occipital and fusiform gyrus, left inferior occipital gyrus, as well as right inferior temporal and right inferior frontal gyrus (Fig.  ; see Table   for details). An area in the medial anterior cingulate cortex and an area in the right calcarine gyrus showed significant decrease in activation in response to faces before surgery (Fig.  ; see Table   for details). All clusters statistically significant at p &lt; 0.05 FWE at the cluster level corrected by Monte Carlo permutation testing (cluster forming threshold p &lt; 0.001 per voxel).   
Increased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing. 
    
Decreased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing. 
  

The ROI analysis controlling for random effects of items and subjects confirmed the results of the whole brain analysis (see Figs   and  , see   https://osf.io/ca2u9/   for analysis code and full statistical details). Whether the picture of a person was presented from before or after surgery had a significant effect on the BOLD activation level in the anterior cingulate cluster (β = −0.15, s.e. = 0.05, t = −2.95), as well as the occipital cortex (β = 0.17, s.e. = 0.03, t = 5.31). Neither gender of the participant, any of the EBQ measures (see Tables   and   for descriptive statistics), or the gender of the depicted person was found to be related to BOLD activation level differences.   
Itemwise mean activation in the occipital cortex. Stimulus items that do not follow the general activation pattern are Item 2, 7, 12, 25, and 28. 
    
Itemwise mean activation in the anterior cingulate cortex. Stimulus items that do not follow the general activation pattern are Item 1, 25, and 28. 
    
Summary of the EBQ responses I. 
    
Summary of the EBQ responses II. 
  



 ## Data Availability

The datasets generated and analysed during the current study will be made available without restriction on Open Science Framework (DOI 10.17605/OSF.IO/CA2U9) upon acceptance of the article for publication, https://osf.io/ca2u9/. https://osf.io/ca2u9/</pre></details></details>
  <details class="inner-accordion"><summary>Coordinate-relevant source tables (2)</summary><details class="inner-accordion"><summary>Table 2 (Tab2) - Increased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing.</summary><div class="table-html"><table-wrap id="Tab2" position="float" orientation="portrait"><label>Table 2</label><caption><p>Increased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing.</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="1" rowspan="1">Location</th><th colspan="1" rowspan="1">k</th><th colspan="1" rowspan="1">T-max</th><th colspan="1" rowspan="1">x</th><th colspan="1" rowspan="1">y</th><th colspan="1" rowspan="1">z</th></tr></thead><tbody><tr><td colspan="1" rowspan="1">left lateral occipital gyrus/BA 18</td><td colspan="1" rowspan="1">3442</td><td colspan="1" rowspan="1">8.08</td><td colspan="1" rowspan="1">−28</td><td colspan="1" rowspan="1">−98</td><td colspan="1" rowspan="1">8</td></tr><tr><td colspan="1" rowspan="1">right lateral occipital gyrus/BA 18</td><td colspan="1" rowspan="1">2377</td><td colspan="1" rowspan="1">6.98</td><td colspan="1" rowspan="1">34</td><td colspan="1" rowspan="1">−90</td><td colspan="1" rowspan="1">2</td></tr><tr><td colspan="1" rowspan="1">right inferior frontal gyrus/BA 44</td><td colspan="1" rowspan="1">230</td><td colspan="1" rowspan="1">5.02</td><td colspan="1" rowspan="1">42</td><td colspan="1" rowspan="1">8</td><td colspan="1" rowspan="1">26</td></tr></tbody></table></table-wrap></div></details><details class="inner-accordion"><summary>Table 3 (Tab3) - Decreased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing.</summary><div class="table-html"><table-wrap id="Tab3" position="float" orientation="portrait"><label>Table 3</label><caption><p>Decreased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing.</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="1" rowspan="1">Location</th><th colspan="1" rowspan="1">k</th><th colspan="1" rowspan="1">T-max</th><th colspan="1" rowspan="1">x</th><th colspan="1" rowspan="1">y</th><th colspan="1" rowspan="1">z</th></tr></thead><tbody><tr><td colspan="1" rowspan="1">left and right anterior cingulate cortex/BA 24</td><td colspan="1" rowspan="1">765</td><td colspan="1" rowspan="1">4.92</td><td colspan="1" rowspan="1">−2</td><td colspan="1" rowspan="1">36</td><td colspan="1" rowspan="1">10</td></tr><tr><td colspan="1" rowspan="1">right calcarine gyrus/BA 18</td><td colspan="1" rowspan="1">247</td><td colspan="1" rowspan="1">4.10</td><td colspan="1" rowspan="1">6</td><td colspan="1" rowspan="1">−88</td><td colspan="1" rowspan="1">12</td></tr></tbody></table></table-wrap></div></details></details>
</details>


<details class="doc-card">
  <summary><strong>PMID 14568477</strong> | Pred included: 4 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/14568477/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>14568477_analysis_0</td><td>Internal &gt; external</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves attributing social events to self or others (internal vs external attributions) and examines self-responsibility and self-serving bias, which are core social-cognitive processes; meets both I1 and I2.</td></tr>
<tr><td>14568477_analysis_1</td><td>External &gt; internal</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves attribution of causality for social events (internal vs external attributions); this directly measures social processing (self/other understanding).</td></tr>
<tr><td>14568477_analysis_2</td><td>Self-serving bias</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task explicitly involves social causal attributions (self vs other responsibility) and investigates the self-serving bias — clearly a social processing task. It measures processes of perceiving and interpreting social information about self and others.</td></tr>
<tr><td>14568477_analysis_3</td><td>Non-self-serving bias</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves social attribution decisions about events involving friends (internal vs external attributions) and measures social cognition (self-responsibility and attributional bias). Satisfies social-related task and measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>14568477_1</td><td>External &gt; internal; others</td><td>14568477_analysis_1</td><td>External &gt; internal</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>14568477_2</td><td>Internal &gt; external; others</td><td>14568477_analysis_0</td><td>Internal &gt; external</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>14568477_3</td><td>Non-self-serving bias &gt; Self-serving bias; others</td><td>14568477_analysis_3</td><td>Non-self-serving bias</td><td>0.677</td><td>1.000</td><td>0.903</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>14568477_4</td><td>Self-serving bias &gt; Non-self-serving bias; others</td><td>14568477_analysis_2</td><td>Self-serving bias</td><td>0.586</td><td>1.000</td><td>0.876</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 14980212</strong> | Pred included: 4 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/14980212/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>14980212_analysis_0</td><td>Affective-Neutral Faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task involves social learning about cooperators and defectors and compares affective (cooperator/defector) faces to neutral faces, directly measuring social processing.</td></tr>
<tr><td>14980212_analysis_1</td><td>Cooperator-Neutral Faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves learned social judgments about cooperators vs neutral faces (social cognition), directly measuring social processing.</td></tr>
<tr><td>14980212_analysis_2</td><td>Defector-Neutral Faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves learned social judgments (cooperation vs defection) and perception of social agents; contrast (defector vs neutral faces) measures social processing.</td></tr>
<tr><td>14980212_analysis_3</td><td>Cerebral Foci of Activation for Intentional versus Nonintentional Cooperator Faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves social learning (Prisoner’s Dilemma) and perception of moral status of faces; the contrast (intentional vs nonintentional cooperators) measures social processing related to judgments about others’ social behavior and intentionality.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>14980212_1</td><td>Affective &gt; Neutral faces; socialcommunication</td><td>14980212_analysis_0</td><td>Affective-Neutral Faces</td><td>0.917</td><td>1.000</td><td>0.975</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>14980212_2</td><td>Cooperator &gt; Neutral faces; socialcommunication</td><td>14980212_analysis_1</td><td>Cooperator-Neutral Faces</td><td>0.920</td><td>1.000</td><td>0.976</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>14980212_3</td><td>Defector &gt; Neutral faces; socialcommunication</td><td>14980212_analysis_2</td><td>Defector-Neutral Faces</td><td>0.913</td><td>1.000</td><td>0.974</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 15006683</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/15006683/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>15006683_analysis_0</td><td>Relational vs. alone segment</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares observation of social interactions (relational segment) vs an alone segment; it directly measures social processing of interactions and social relations.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>15006683_1</td><td>Relational &gt; alone; others</td><td>15006683_analysis_0</td><td>Relational vs. alone segment</td><td>0.739</td><td>1.000</td><td>0.922</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 15488424</strong> | Pred included: 4 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/15488424/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>15488424_analysis_0</td><td>Cooperation versus independent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast &#x27;Cooperation versus independent&#x27; is a social interaction task probing social cognition (cooperation) and compares it to independent play; it therefore measures social processing (self/other monitoring, mentalizing, social reward).</td></tr>
<tr><td>15488424_analysis_1</td><td>Competition versus independent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast pits a social interaction condition (competition) against independent play. This directly assesses social cognition (mentalizing, self–other monitoring, social stance), satisfying both criteria.</td></tr>
<tr><td>15488424_analysis_2</td><td>Cooperation versus competition</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast directly manipulates social interaction (cooperation vs competition) and measures social processing (self–other monitoring, mentalizing, reward in social context).</td></tr>
<tr><td>15488424_analysis_3</td><td>Competition versus cooperation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task directly involves social interaction (cooperation vs competition) and the contrasts measure social processing (self–other monitoring, mentalizing, reward in social context).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>15488424_1</td><td>Competition versus cooperation; affiliation</td><td>15488424_analysis_3</td><td>Competition versus cooperation</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>15488424_2</td><td>Competition versus independent; affiliation</td><td>15488424_analysis_1</td><td>Competition versus independent</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>15488424_3</td><td>Cooperation versus competition; affiliation</td><td>15488424_analysis_2</td><td>Cooperation versus competition</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>15488424_4</td><td>Cooperation versus independent; affiliation</td><td>15488424_analysis_0</td><td>Cooperation versus independent</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 15528097</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=4</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/15528097/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Embarrassment &gt; Neutral; socialcommunication, Embarrassment &gt; guilt; socialcommunication, Guilt &gt; Embarrassment; socialcommunication, Guilt &gt; Neutral; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>15528097_analysis_0</td><td>Brain regions commonly activated by guilt and embarrassment conditions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves evaluative judgments of self-conscious social emotions (guilt, embarrassment) and explicitly invokes theory-of-mind/social cognition; thus it measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>15528097_1</td><td>Embarrassment &gt; Neutral; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>15528097_2</td><td>Embarrassment &gt; guilt; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>15528097_3</td><td>G &gt; N masked E &gt; N; socialcommunication</td><td>15528097_analysis_0</td><td>Brain regions commonly activated by guilt and embarrassment conditions</td><td>0.275</td><td>1.000</td><td>0.783</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>15528097_4</td><td>Guilt &gt; Embarrassment; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>15528097_5</td><td>Guilt &gt; Neutral; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 15808992</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/15808992/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>15808992_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task directly involves self–other social discrimination (viewing self vs a highly familiar other) and measures social cognitive processing related to perception and understanding of self and others.</td></tr>
<tr><td>15808992_analysis_1</td><td>other-self contrast</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task contrasts self vs familiar other faces and examines neural correlates of self/other perception—this is a social-related task and measures social processing (self and other representations).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>15808992_1</td><td>Other - Self; socialcommunication</td><td>15808992_analysis_1</td><td>other-self contrast</td><td>0.645</td><td>1.000</td><td>0.894</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>15808992_2</td><td>Self - Other; socialcommunication</td><td>15808992_analysis_0</td><td>analysis_0</td><td>0.140</td><td>1.000</td><td>0.742</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 16035037</strong> | Pred included: 5 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/16035037/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>16035037_analysis_0</td><td>CBF change during distracter minus null contrast</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast examines perception of faces (distracter/unknown faces) versus scrambled baseline; this is a social-related task measuring social perception, so meets I1 (social-related task) and I2 (measures social processing).</td></tr>
<tr><td>16035037_analysis_1</td><td>familiar minus distracter contrast</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast of personally familiar face vs unknown distracter is a social task involving perception and recognition of socially relevant faces and understanding of self/other relations; thus measures social processing.</td></tr>
<tr><td>16035037_analysis_2</td><td>Local maxima of CBF change during self minus distracter contrast corrected at P = 0.001 and cluster at P = 0.05</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves self-face recognition contrasted with distracter (unknown) faces, which is a social-related task measuring perception/processing of self in social context. Satisfies both criteria.</td></tr>
<tr><td>16035037_analysis_3</td><td>familiar minus self contrast</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast (familiar minus self) involves recognizing self and personally familiar others, which is a social-related task measuring social processing (perception/understanding of self and others).</td></tr>
<tr><td>16035037_analysis_4</td><td>Local maxima of CBF change during self minus familiar contrast</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task contrasts self-face with personally familiar faces, which is a social-related task involving perception and interpretation of self in a social context (self vs familiar). Both inclusion criteria are met.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>16035037_1</td><td>distracter &gt; null; socialcommunication</td><td>16035037_analysis_0</td><td>CBF change during distracter minus null contrast</td><td>0.512</td><td>1.000</td><td>0.853</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16035037_2</td><td>familiar face &gt; distracter; socialcommunication</td><td>16035037_analysis_1</td><td>familiar minus distracter contrast</td><td>0.667</td><td>1.000</td><td>0.900</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>16035037_3</td><td>familiar face &gt; self face; socialcommunication</td><td>16035037_analysis_3</td><td>familiar minus self contrast</td><td>0.604</td><td>1.000</td><td>0.881</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>16035037_4</td><td>self face &gt; distracter; socialcommunication</td><td>16035037_analysis_2</td><td>Local maxima of CBF change during self minus distracter contrast corrected at P = 0.001 and cluster at P = 0.05</td><td>0.312</td><td>1.000</td><td>0.794</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16035037_5</td><td>self face &gt; famililar face; socialcommunication</td><td>16035037_analysis_4</td><td>Local maxima of CBF change during self minus familiar contrast</td><td>0.367</td><td>1.000</td><td>0.810</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 16055351</strong> | Pred included: 7 | Manual included (accepted matches only): 7 | Correct overlaps: 7 | Match statuses: accepted=7, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/16055351/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>16055351_analysis_0</td><td>Anger vs. Neutral (AN + NA) vs. (NN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves processing emotional prosody (anger) in voices, which is social information (perception and interpretation of others&#x27; emotions). The contrast (AN+NA vs NN) directly measures social processing.</td></tr>
<tr><td>16055351_analysis_1</td><td>Anger to-be-attended vs. Neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves perception and interpretation of emotional prosody in others&#x27; voices (anger vs neutral), which is social processing. The contrast measures social processing of emotional cues.</td></tr>
<tr><td>16055351_analysis_2</td><td>Anger to-be-ignored vs. Neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast examines processing of angry vocal prosody—an interpersonal, social cue—so it measures social processing (perception of others&#x27; emotional states).</td></tr>
<tr><td>16055351_analysis_3</td><td>Anger to-be-attended vs. to-be-ignored</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast examines processing of angry prosody in voices, i.e., perception and interpretation of others&#x27; emotional social cues; it measures social processing.</td></tr>
<tr><td>16055351_analysis_4</td><td>Anger to-be-ignored vs. to-be-attended</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast examines perception of angry prosody in voices—recognition of others&#x27; emotional states and social cues—so it is a social-processing task. It directly measures social processing (emotion perception in others) via the anger attended vs ignored contrast.</td></tr>
<tr><td>16055351_analysis_5</td><td>Spatial attention towards right vs. left ear</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves perception and processing of emotional prosody in voices (anger vs. neutral), a social cue; contrast directly measures social processing.</td></tr>
<tr><td>16055351_analysis_6</td><td>Spatial attention towards left vs. right ear</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves perceiving and interpreting emotional prosody (anger) in voices — a social signal; contrasts directly test emotion processing and attention to social cues.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>16055351_1</td><td>Anger &gt; Neutral (AN + NA) &gt; (NN); socialcommunication</td><td>16055351_analysis_0</td><td>Anger vs. Neutral (AN + NA) vs. (NN)</td><td>0.882</td><td>0.889</td><td>0.887</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>16055351_2</td><td>Anger to be attended &gt; to be ignored; socialcommunication</td><td>16055351_analysis_3</td><td>Anger to-be-attended vs. to-be-ignored</td><td>0.838</td><td>0.800</td><td>0.811</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>16055351_3</td><td>Anger to-be-attended &gt; Neutral; socialcommunication</td><td>16055351_analysis_1</td><td>Anger to-be-attended vs. Neutral</td><td>0.935</td><td>1.000</td><td>0.981</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>16055351_4</td><td>Anger to-be-ignored &gt; Neutral; socialcommunication</td><td>16055351_analysis_2</td><td>Anger to-be-ignored vs. Neutral</td><td>0.933</td><td>1.000</td><td>0.980</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>16055351_5</td><td>anger to be ignored &gt; to be attended; socialcommunication</td><td>16055351_analysis_4</td><td>Anger to-be-ignored vs. to-be-attended</td><td>0.838</td><td>1.000</td><td>0.951</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>16055351_6</td><td>spatial attention to left ear &gt; right ear; socialcommunication</td><td>16055351_analysis_6</td><td>Spatial attention towards left vs. right ear</td><td>0.847</td><td>0.889</td><td>0.876</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>16055351_7</td><td>spatial attention to right ear&gt; left ear; socialcommunication</td><td>16055351_analysis_5</td><td>Spatial attention towards right vs. left ear</td><td>0.847</td><td>1.000</td><td>0.954</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 16122944</strong> | Pred included: 5 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/16122944/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>16122944_analysis_0</td><td>‘ToM’ - ‘Physical 1’</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast ‘ToM’ − ‘Physical 1’ involves theory-of-mind (mentalizing) processing, a core social process; it uses social cartoon stimuli to infer others&#x27; mental states, meeting both I1 and I2.</td></tr>
<tr><td>16122944_analysis_1</td><td>‘Empathy’ - ‘Physical 2’</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast ‘Empathy − Physical 2’ explicitly requires inferring the protagonist&#x27;s emotions and engages empathic/social-cognitive processing; it is a social-related task measuring social processing.</td></tr>
<tr><td>16122944_analysis_2</td><td>Conjuction analysis</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The conjunction analysis examines Theory of Mind and empathy using cartoon tasks that require perceiving and inferring others&#x27; mental and emotional states—clearly a social-processing task. Satisfies both specifying a social-related task and measuring social processing.</td></tr>
<tr><td>16122944_analysis_3</td><td>(‘ToM’ - ‘Physical 1’) - (‘Empathy’ - ‘Physical 2’)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task contrasts Theory of Mind and Empathy conditions—both are canonical social-cognitive tasks involving perception and understanding of others’ mental and emotional states. The contrast measures social processing directly.</td></tr>
<tr><td>16122944_analysis_4</td><td>(‘Empathy’ - ‘Physical 2’) - (‘ToM’ - ‘Physical 1’)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrasts compare Theory of Mind and Empathy versus physical causality controls—both are core social processes (perception and inference about others). Satisfies I1 (social-related task) and I2 (measures Social Processing).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>16122944_1</td><td>(Empathy - Physical 2) - (ToM - Physical 1); others</td><td>16122944_analysis_4</td><td>(‘Empathy’ - ‘Physical 2’) - (‘ToM’ - ‘Physical 1’)</td><td>0.915</td><td>1.000</td><td>0.974</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>16122944_2</td><td>(ToM - Physical 1) - (Empathy - Physical 2); others</td><td>16122944_analysis_3</td><td>(‘ToM’ - ‘Physical 1’) - (‘Empathy’ - ‘Physical 2’)</td><td>0.915</td><td>1.000</td><td>0.974</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>16122944_3</td><td>Conjunction Analysis; others</td><td>16122944_analysis_2</td><td>Conjuction analysis</td><td>0.974</td><td>1.000</td><td>0.992</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>16122944_4</td><td>Empathy - Physical 2; others</td><td>16122944_analysis_1</td><td>‘Empathy’ - ‘Physical 2’</td><td>0.909</td><td>1.000</td><td>0.973</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>16122944_5</td><td>ToM - Physical 1; others</td><td>16122944_analysis_0</td><td>‘ToM’ - ‘Physical 1’</td><td>0.889</td><td>1.000</td><td>0.967</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 16171833</strong> | Pred included: 6 | Manual included (accepted matches only): 6 | Correct overlaps: 6 | Match statuses: accepted=6, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/16171833/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>16171833_analysis_0</td><td>a) Common activations of social interaction (SOC &gt; ARB)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast SOC&gt;ARB tests perception of socially relevant facial expressions (social interaction) and the task manipulates social involvement; it measures social processing.</td></tr>
<tr><td>16171833_analysis_1</td><td>b) Common activations of arbitrary facial movements (ARB &gt; SOC)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves perception of social interaction and facial expressions (SOC vs ARB) and measures social processing across conditions.</td></tr>
<tr><td>16171833_analysis_2</td><td>c) Common activations of self-involvement (ME &gt; OTHER)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast ME&gt;OTHER and related SOC&gt;ARB contrasts probe social involvement, gaze, and perception of social interaction — clearly a social-processing task. Satisfies both I1 and I2.</td></tr>
<tr><td>16171833_analysis_3</td><td>d) Common activations of other-related activity (OTHER &gt; ME)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast OTHER&gt;ME examines perception of social interactions (gaze direction, facial expressions) and neural correlates of observing others — directly targets social processing.</td></tr>
<tr><td>16171833_analysis_4</td><td>e) Common activations of the statistical interaction SOC × ME</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis tests perception of socially relevant facial expressions (SOC vs ARB) and self-involvement (ME vs OTHER); the SOC×ME interaction directly probes social processing (joint attention, self-related social cues).</td></tr>
<tr><td>16171833_analysis_5</td><td>f) Common activations of the statistical interaction SOC × OTHER</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast probes perception of social interaction (SOC vs ARB) and how it is directed (OTHER), i.e. social cognition/processing. It directly measures social processing across conditions.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>16171833_1</td><td>ARB &gt; SOC; socialcommunication</td><td>16171833_analysis_1</td><td>b) Common activations of arbitrary facial movements (ARB &gt; SOC)</td><td>0.250</td><td>1.000</td><td>0.775</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16171833_2</td><td>ME &gt; OTHER; socialcommunication</td><td>16171833_analysis_2</td><td>c) Common activations of self-involvement (ME &gt; OTHER)</td><td>0.312</td><td>1.000</td><td>0.794</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16171833_3</td><td>OTHER &gt; ME; socialcommunication</td><td>16171833_analysis_3</td><td>d) Common activations of other-related activity (OTHER &gt; ME)</td><td>0.286</td><td>1.000</td><td>0.786</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16171833_4</td><td>SOC &gt; ARB; socialcommunication</td><td>16171833_analysis_0</td><td>a) Common activations of social interaction (SOC &gt; ARB)</td><td>0.281</td><td>1.000</td><td>0.784</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16171833_5</td><td>SOC x ME&gt;Other; socialcommunication</td><td>16171833_analysis_4</td><td>e) Common activations of the statistical interaction SOC × ME</td><td>0.245</td><td>1.000</td><td>0.773</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16171833_6</td><td>SOC x OTHER&gt; ME; socialcommunication</td><td>16171833_analysis_5</td><td>f) Common activations of the statistical interaction SOC × OTHER</td><td>0.250</td><td>1.000</td><td>0.775</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 16759672</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/16759672/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> faces associated with nice behaviors &gt; faces associated with neutral behaviors; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>16759672_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast tests spontaneous retrieval of affective person knowledge during face perception—a social cognition task—so it meets both (I1) social-related task and (I2) measures social processing.</td></tr>
<tr><td>16759672_analysis_1</td><td>Faces associated with disgusting behaviors greater than faces associated with aggressive behaviors</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast examines spontaneous retrieval of affective person knowledge during face perception—clearly a social-related task assessing social processing (perception/understanding of others and social cognition).</td></tr>
<tr><td>16759672_analysis_2</td><td>Faces associated with aggressive behaviors greater than faces associated with disgusting behaviors</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast examines retrieval of affective person knowledge during face perception (faces associated with behaviors), a social task measuring social cognition and processing of others’ traits and emotions, so it meets I1 and I2.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>16759672_1</td><td>face associated with behavior &gt; novel faces; socialcommunication</td><td>16759672_analysis_0</td><td>analysis_0</td><td>0.151</td><td>1.000</td><td>0.745</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16759672_2</td><td>faces associated with aggressive behaviors &gt; faces associated with disgusting behaviors; socialcommunication</td><td>16759672_analysis_2</td><td>Faces associated with aggressive behaviors greater than faces associated with disgusting behaviors</td><td>0.930</td><td>1.000</td><td>0.979</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>16759672_3</td><td>faces associated with disgusting behaviors &gt; faces associated with aggressive behaviors; socialcommunication</td><td>16759672_analysis_1</td><td>Faces associated with disgusting behaviors greater than faces associated with aggressive behaviors</td><td>0.930</td><td>0.944</td><td>0.940</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>16759672_4</td><td>faces associated with nice behaviors &gt; faces associated with neutral behaviors; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 17071110</strong> | Pred included: 3 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=2, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/17071110/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Retaliation interaction with low CU &gt; High CU; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>17071110_analysis_0</td><td>Receiving aversive stimuli; parametric modulation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The task is a social interactive paradigm (competitive reaction time task) involving observing and responding to another person (opponent). The contrast &#x27;Receiving aversive stimuli; parametric modulation&#x27; measures anticipation of punishment and social interaction-related processing, satisfying I1 and I2.</td></tr>
<tr><td>17071110_analysis_1</td><td>Retaliation; parametric modulation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The task is an interactive social aggression paradigm (competition, retaliation, observing an opponent) and the contrast measures social processing (retaliation and watching opponent), satisfying both I1 and I2.</td></tr>
<tr><td>17071110_analysis_2</td><td>Conjunction; retaliation and watching the opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task is an interactive social paradigm involving provocation, retaliation, and observation of an opponent — clearly a social processing task measuring social interaction and related processes (empathy, mentalizing).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>17071110_1</td><td>Retaliation &gt; Watching opponent; socialcommunication</td><td>17071110_analysis_1</td><td>Retaliation; parametric modulation</td><td>0.554</td><td>0.750</td><td>0.691</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>17071110_2</td><td>Retaliation interaction with low CU &gt; High CU; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>17071110_3</td><td>Watching opponent &gt; Retaliation; socialcommunication</td><td>17071110_analysis_0</td><td>Receiving aversive stimuli; parametric modulation</td><td>0.375</td><td>0.842</td><td>0.702</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>17071110_4</td><td>Watching opponent &gt; Retaliation (conjunction); socialcommunication</td><td>17071110_analysis_2</td><td>Conjunction; retaliation and watching the opponent</td><td>0.484</td><td>0.900</td><td>0.775</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 17408704</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/17408704/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>17408704_analysis_0</td><td>EMO</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Emotion recognition from faces is a social-related task that probes perception and interpretation of others&#x27; emotions, satisfying both social processing inclusion criteria.</td></tr>
<tr><td>17408704_analysis_1</td><td>AGE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The AGE contrast involves implicit processing of facial stimuli (age discrimination), which is a social-related task involving perception of social cues from faces and thus measures social processing.</td></tr>
<tr><td>17408704_analysis_2</td><td>EMO-AGE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task explicitly involves recognizing emotions from faces (explicit emotion recognition and implicit processing), which is social processing—meets both social-related task and measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>17408704_1</td><td>explicit (emotion) &gt; baseline; socialcommunication</td><td>17408704_analysis_0</td><td>EMO</td><td>0.188</td><td>1.000</td><td>0.756</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>17408704_2</td><td>explicit (emotion) &gt; implicit (age); socialcommunication</td><td>17408704_analysis_2</td><td>EMO-AGE</td><td>0.286</td><td>1.000</td><td>0.786</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>17408704_3</td><td>implicit (age) &gt; baseline; socialcommunication</td><td>17408704_analysis_1</td><td>AGE</td><td>0.214</td><td>1.000</td><td>0.764</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 17627852</strong> | Pred included: 4 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/17627852/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>17627852_analysis_0</td><td>Communication—control</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares communicative (social) speech vs description and manipulates familiarity; it targets social interaction and mentalization processes, so both I1 and I2 are met.</td></tr>
<tr><td>17627852_analysis_1</td><td>Description—control</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast targets communicative speech and social interaction, engaging theory-of-mind and social-context processing; it is a social-related task and directly measures social processing (communication vs description).</td></tr>
<tr><td>17627852_analysis_2</td><td>Communication— description</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task contrasts communicative speech vs description and involves social interaction, theory-of-mind processing, and familiarity—clearly a social-processing task.</td></tr>
<tr><td>17627852_analysis_3</td><td>Familiar communication – unfamiliar communication</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares communicative vs descriptive speech and manipulates actor familiarity, directly probing social interaction and processing (theory-of-mind/interaction context). Satisfies social-related task and measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>17627852_1</td><td>Communication &gt; Description; socialcommunication</td><td>17627852_analysis_2</td><td>Communication— description</td><td>0.943</td><td>0.714</td><td>0.783</td><td>accepted</td><td>coord_count_mismatch</td></tr><tr><td>17627852_2</td><td>Communication &gt; control; socialcommunication</td><td>17627852_analysis_0</td><td>Communication—control</td><td>0.909</td><td>1.000</td><td>0.973</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>17627852_3</td><td>Description &gt; control; socialcommunication</td><td>17627852_analysis_1</td><td>Description—control</td><td>0.900</td><td>1.000</td><td>0.970</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>17627852_4</td><td>Familiar communication &gt; unfamiliar communication; socialcommunication</td><td>17627852_analysis_3</td><td>Familiar communication – unfamiliar communication</td><td>0.980</td><td>1.000</td><td>0.994</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18486491</strong> | Pred included: 4 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18486491/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18486491_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>PD (Prisoner’s Dilemma) is an explicit social interactive task; the PD–Gamble contrast directly measures social processing and mentalizing (theory-of-mind) networks.</td></tr>
<tr><td>18486491_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The analysis contrasts a social interactive task (Prisoner’s Dilemma) with a non-social Gamble task and explicitly examines brain networks supporting social interaction and mentalizing; it therefore measures social processing.</td></tr>
<tr><td>18486491_analysis_2</td><td>Regions where the cooperation difference score (in-group-out-group) is significantly correlated with the difference in BOLD signal during in-group and out-group interactions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Analysis uses an interactive Prisoner’s Dilemma social task and tests neural responses to in-group vs out-group interactions, directly measuring social processing.</td></tr>
<tr><td>18486491_analysis_3</td><td>DMPFC connectivity with in-group - DMPFC connectivity with out-group</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The analysis compares neural connectivity during a social interactive task (Prisoner’s Dilemma) for in-group vs out-group partners, directly measuring social processing and group-based social cognition.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18486491_1</td><td>PD – Gamble; affiliation</td><td>18486491_analysis_0</td><td>analysis_0</td><td>0.190</td><td>1.000</td><td>0.757</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18501639</strong> | Pred included: 15 | Manual included (accepted matches only): 8 | Correct overlaps: 8 | Match statuses: accepted=8, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18501639/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18501639_analysis_0</td><td>Main effect [(Sf + Sn)–(Ff + Fn) masked by Sf–Ff and Sn–Fn]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task is familiar/unfamiliar judgement of self, friend, and stranger using faces and names — a social-related task probing self- and other-processing. The contrast compares self vs friend across face and name, measuring social processing related to self/other distinction.</td></tr>
<tr><td>18501639_analysis_1</td><td>Face (simple effect) [Sf–Ff]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task contrasts self, friend, and unfamiliar persons using face and name recognition, which probes perception/understanding of self and others and social processing (self-recognition, familiarity, social interaction preparatory processes).</td></tr>
<tr><td>18501639_analysis_2</td><td>Name (simple effect) [Sn–Fn]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast compares self versus friend recognition (names), which is a social-related task probing perception/understanding of self and others and social processing; it therefore satisfies both I1 and I2.</td></tr>
<tr><td>18501639_analysis_3</td><td>Face specific (interaction) [(Sf–Ff)–(Sn–Fn) masked by Sf–Ff]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves familiar/unfamiliar judgments for self, friend, and stranger using faces and names—this probes perception/understanding of self and others and social processing (including preparation for social interaction). Contrast directly measures social processing.</td></tr>
<tr><td>18501639_analysis_4</td><td>Name specific (interaction) [(Sn–Fn)–(Sf–Ff) masked by Sn–Fn]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task requires familiar/unfamiliar judgments for self, friend, and unfamiliar persons using face and name stimuli; contrasts probe self vs friend and friend/self vs unfamiliar, which measure social processing (self/other perception, social interaction preparation).</td></tr>
<tr><td>18501639_analysis_5</td><td>Main effect [(Ff + Fn)–(Sf + Sn) masked by Ff–Sf and Fn–Sn]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task explicitly involves social-related processing (self vs friend vs unfamiliar) using face and name recognition; the contrast measures social processing (self/other perception and social cognition).</td></tr>
<tr><td>18501639_analysis_6</td><td>Face (simple effect) [Ff–Sf]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves self- and other-recognition (self, friend, unfamiliar) using faces and names; the contrast (Ff–Sf) measures social processing (perception/understanding of self vs other).</td></tr>
<tr><td>18501639_analysis_7</td><td>Name (simple effect) [Fn–Sn]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task is a familiar/unfamiliar judgment comparing self, friend, and unfamiliar persons using face and name stimuli. This is a social-related task probing perception/understanding of self and others and social-cognitive processes (e.g., preparation for social interaction), satisfying both inclusion criteria.</td></tr>
<tr><td>18501639_analysis_8</td><td>Face specific (interaction) [(Ff–Sf)–(Fn–Sn) masked by Ff–Sf]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves familiar/unfamiliar judgments of self, friend, and stranger across face and name stimuli, directly probing social perception and self/other processing.</td></tr>
<tr><td>18501639_analysis_9</td><td>Name specific (interaction) [(Fn–Sn)–(Ff–Sf) masked by Fn–Sn]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task is social (familiar/unfamiliar judgments for self, friend, and stranger using faces and names) and the contrasts (self vs friend, friend vs self, self+friend vs control) directly probe social processing and self/other social cognition.</td></tr>
<tr><td>18501639_analysis_10</td><td>Main effect [(Sf + Ff + Sn + Fn)–2(Cf + Cn) masked by Sf–Cf, Ff–Cf, Sn–Cn, and Fn–Cn]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast examines person recognition (self, friend, unfamiliar) during a familiar/unfamiliar judgment task and probes social-cognitive processes (self vs others, familiarity), so it meets both I1 (social-related task) and I2 (measures social processing).</td></tr>
<tr><td>18501639_analysis_11</td><td>Face (simple effect) [Sf + Ff–2Cf masked by Sf–Cf, and Ff–Cf]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves recognition of self, friend, and unfamiliar persons (face and name), probing self- vs other-processing and social cognition; contrasts (self vs friend, friend vs control, self+friend vs control) directly measure social processing.</td></tr>
<tr><td>18501639_analysis_12</td><td>Name (simple effect) [Sn + Fn–2Cn masked by Sn–Cn, and Fn–Cn]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves recognition of self, friend, and unfamiliar persons using faces and names; contrasts directly probe social processing (self vs friend, friend vs unfamiliar).</td></tr>
<tr><td>18501639_analysis_13</td><td>Face specific (interaction) [(Sf + Ff–2Cf)–(Sn + Fn–2Cn) masked by Sf + Ff–2Cf]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task required familiar/unfamiliar judgments for self, friend, and unfamiliar persons using face and name stimuli—this directly probes social processing (perception/understanding of self and others). The contrast explicitly measures social processing (self vs friend).</td></tr>
<tr><td>18501639_analysis_14</td><td>Name specific (interaction) [(Sn + Fn–2Cn)–(Sf + Ff–2Cf) masked by Sn + Fn–2Cn]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves social-related judgments (self, friend, unfamiliar) and the contrast measures social processing (familiarity/self-other recognition across names vs faces).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18501639_1</td><td>Face (simple effect) [Ff–Sf]; socialcommunication</td><td>18501639_analysis_6</td><td>Face (simple effect) [Ff–Sf]</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18501639_2</td><td>Face (simple effect) [Sf+Ff–2Cf masked by Sf–Cf, and Ff–Cf]; socialcommunication</td><td>18501639_analysis_11</td><td>Face (simple effect) [Sf + Ff–2Cf masked by Sf–Cf, and Ff–Cf]</td><td>0.983</td><td>1.000</td><td>0.995</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18501639_3</td><td>Face (simple effect) [Sf–Ff]; socialcommunication</td><td>18501639_analysis_1</td><td>Face (simple effect) [Sf–Ff]</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18501639_4</td><td>Face specific (interaction) [(Sf+Ff–2Cf)–(Sn+Fn–2Cn) masked by Sf+Ff–2Cf]; socialcommunication</td><td>18501639_analysis_13</td><td>Face specific (interaction) [(Sf + Ff–2Cf)–(Sn + Fn–2Cn) masked by Sf + Ff–2Cf]</td><td>0.961</td><td>1.000</td><td>0.988</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18501639_5</td><td>Face specific (interaction) [(Sf–Ff)–(Sn–Fn) masked by Sf–Ff]; socialcommunication</td><td>18501639_analysis_3</td><td>Face specific (interaction) [(Sf–Ff)–(Sn–Fn) masked by Sf–Ff]</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18501639_6</td><td>Main effect [(Ff+Fn)–(Sf+Sn) masked by Ff–Sf and Fn–Sn]; socialcommunication</td><td>18501639_analysis_5</td><td>Main effect [(Ff + Fn)–(Sf + Sn) masked by Ff–Sf and Fn–Sn]</td><td>0.965</td><td>1.000</td><td>0.989</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18501639_7</td><td>Main effect [(Sf+Ff+Sn+Fn)–2(Cf+Cn) masked by Sf–Cf, Ff–Cf, Sn–Cn, and Fn–Cn]; socialcommunication</td><td>18501639_analysis_10</td><td>Main effect [(Sf + Ff + Sn + Fn)–2(Cf + Cn) masked by Sf–Cf, Ff–Cf, Sn–Cn, and Fn–Cn]</td><td>0.951</td><td>0.667</td><td>0.752</td><td>accepted</td><td></td></tr><tr><td>18501639_8</td><td>Name (simple effect) [Sn+Fn–2Cn masked by Sn–Cn, and Fn–Cn]; socialcommunication</td><td>18501639_analysis_12</td><td>Name (simple effect) [Sn + Fn–2Cn masked by Sn–Cn, and Fn–Cn]</td><td>0.983</td><td>1.000</td><td>0.995</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18514546</strong> | Pred included: 6 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18514546/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18514546_analysis_0</td><td>SELF versus high-level baseline</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The SELF task requires focusing on one&#x27;s own emotional response to others&#x27; facial expressions (and the study investigates empathy), which is a social-related task and the contrast (SELF vs high-level baseline) measures social processing of emotion and perspective taking.</td></tr>
<tr><td>18514546_analysis_1</td><td>OTHER versus high-level baseline</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The OTHER vs high-level baseline contrast involves evaluating others&#x27; emotional states (empathy task), which is a prototypical social processing task.</td></tr>
<tr><td>18514546_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves empathy-related SELF and OTHER perspective taking and perception of emotional faces—clearly social processing.</td></tr>
<tr><td>18514546_analysis_3</td><td>Interaction (SELF_f – B_f) – (SELF_m – B_m)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The analysis contrasts SELF-task (self-oriented emotional perspective taking) across genders, which is a social-related task (empathy, perspective taking). It clearly measures social processing of self/other emotions.</td></tr>
<tr><td>18514546_analysis_4</td><td>Interaction (SELF_m – B_m) – (SELF_f – B_f)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task directly probes empathy/emotional perspective taking (SELF and OTHER), which is a social processing construct involving perception and understanding of self and others in social interactions.</td></tr>
<tr><td>18514546_analysis_5</td><td>Interaction (OTHER_f – B_f) – (OTHER_m – B_m)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast examines OTHER (evaluating others&#x27; emotional states) vs baseline and a gender interaction — this is a social/empathy task probing perception and understanding of others, so it meets social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18514546_1</td><td>Other &gt; high-level baseline; socialcommunication</td><td>18514546_analysis_1</td><td>OTHER versus high-level baseline</td><td>0.881</td><td>1.000</td><td>0.964</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18514546_2</td><td>Self &gt; high-level baseline; socialcommunication</td><td>18514546_analysis_0</td><td>SELF versus high-level baseline</td><td>0.877</td><td>1.000</td><td>0.963</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18537114</strong> | Pred included: 3 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18537114/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18537114_analysis_0</td><td>P</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The Social Motor Response Learning task explicitly manipulates social inclusion/exclusion and models TD learning about social outcomes; it clearly assesses social processing.</td></tr>
<tr><td>18537114_analysis_1</td><td>S</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The analysis includes a Social Motor Response Learning task that manipulates social inclusion/exclusion and tests learning about social inclusion — clearly a social processing task.</td></tr>
<tr><td>18537114_analysis_2</td><td>Brain activation in Pavlovian compared with social task</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis includes a Social Motor Response Learning task manipulating social inclusion/exclusion and models TD signals for social interaction, directly measuring social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18537114_1</td><td>Pavlovian &gt; with social task; affiliation</td><td>18537114_analysis_2</td><td>Brain activation in Pavlovian compared with social task</td><td>0.651</td><td>1.000</td><td>0.895</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18633788</strong> | Pred included: 14 | Manual included (accepted matches only): 11 | Correct overlaps: 11 | Match statuses: accepted=11, uncertain=1, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18633788/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Cards: Descriptives &gt; Precautions; others</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18633788_analysis_0</td><td>Stories&gt;Rest</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The stories are social in nature (social-exchange, precautionary, and descriptive social rules) and the contrast examines story-related social processing versus rest; thus it measures social processing broadly (I1 and I2 satisfied).</td></tr>
<tr><td>18633788_analysis_1</td><td>Rest&gt;Stories</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is explicitly about reasoning concerning social exchange and inferring others’ mental states (ToM); it is a social-related task and measures social processing during interpretation and violation-detection stages.</td></tr>
<tr><td>18633788_analysis_2</td><td>Cards &gt; Rest</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task involves reasoning about social exchange and theory-of-mind processes (detecting cheaters, inferring others&#x27; desires/intentions). This is a social-related task and directly measures social processing during interpretation and decision phases.</td></tr>
<tr><td>18633788_analysis_3</td><td>Rest &gt; Cards</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis involves Wason selection tasks with social content (social exchange, precaution, descriptive) and Rest&gt;Cards contrasts reveal activation/deactivation in ToM/default-mode areas; thus it measures social processing.</td></tr>
<tr><td>18633788_analysis_4</td><td>Social Contracts
&gt;Precautions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task explicitly involves theory-of-mind and reasoning about social exchange and cheater detection—clear Social Processing (perception and interpretation of others’ mental states).</td></tr>
<tr><td>18633788_analysis_5</td><td>Social Contracts&gt;Descriptives</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is explicitly about social exchange and theory-of-mind (cheater detection, inferring others&#x27; desires/intentions), which is core social processing; both inclusion criteria are met.</td></tr>
<tr><td>18633788_analysis_6</td><td>Social Contracts&gt;Precautions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The contrast explicitly compares social-exchange (social contract) vs precautionary reasoning and probes theory-of-mind/social-exchange processing; meets both I1 (social task) and I2 (measures social processing).</td></tr>
<tr><td>18633788_analysis_7</td><td>Social Contracts&gt;Descriptives</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The &#x27;Social Contracts &gt; Descriptives (Cards)&#x27; analysis uses Wason selection tasks contrasting social-exchange rules (cheater detection, theory-of-mind) vs descriptive rules. This is clearly a social-related task and measures social processing (interpreting others&#x27; intentions, detecting social contract violations).</td></tr>
<tr><td>18633788_analysis_8</td><td>Stories: Precautions &gt; Social Contracts</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast contrasts social-exchange stories and precautionary stories and explicitly probes theory-of-mind and social-exchange processing (cheater detection, inferring desires/intentions). This directly measures social processing.</td></tr>
<tr><td>18633788_analysis_9</td><td>Stories: Precautions &gt; Descriptives</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Precautionary vs descriptive stories are social-rule reasoning tasks about people’s behavior; the contrast probes social processing (interpretation of social rules, detection of violations). Satisfies I1 (social-related task) and I2 (measures social processing).</td></tr>
<tr><td>18633788_analysis_10</td><td>Cards: Precautions &gt; Social Contracts</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast explicitly compares social-exchange (social contract) reasoning to precautionary reasoning and discusses theory-of-mind and social-exchange processing—meets I1 and I2.</td></tr>
<tr><td>18633788_analysis_11</td><td>Cards: Precautions &gt; Descriptives</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task contrasts precautionary vs descriptive social-rule reasoning using stories and Wason cards about people’s behavior; this is a social-related task and measures social processing (reasoning about others).</td></tr>
<tr><td>18633788_analysis_12</td><td>Stories</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task explicitly involves social scenarios (social exchange, precaution, descriptive rules about people) and the study assesses neural correlates of social processing/ToM during story interpretation and violation detection.</td></tr>
<tr><td>18633788_analysis_13</td><td>Cards</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task explicitly investigates social exchange and theory-of-mind processing (cheater detection, inferring others’ desires/intentions), so it is a social-related task and measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18633788_1</td><td>Cards &gt; Rest; others</td><td>18633788_analysis_2</td><td>Cards &gt; Rest</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633788_10</td><td>Stories: Precautions &gt; Descriptives; others</td><td>18633788_analysis_9</td><td>Stories: Precautions &gt; Descriptives</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633788_11</td><td>Stories: Precautions &gt; Social Contracts; others</td><td>18633788_analysis_8</td><td>Stories: Precautions &gt; Social Contracts</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633788_12</td><td>Stories: Social Contracts &gt; Descriptives; others</td><td>18633788_analysis_5</td><td>Social Contracts&gt;Descriptives</td><td>0.873</td><td>1.000</td><td>0.962</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633788_13</td><td>Stories: Social Contracts &gt; Precautions; others</td><td>18633788_analysis_4</td><td>Social Contracts
&gt;Precautions</td><td>0.870</td><td>1.000</td><td>0.961</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633788_2</td><td>Cards: Descriptives &gt; Precautions; others</td><td>18633788_analysis_6</td><td>Social Contracts&gt;Precautions</td><td>0.635</td><td>0.000</td><td>0.190</td><td>unmatched</td><td>low_total_score, missing_coords_on_one_side, name_only_signal</td></tr><tr><td>18633788_3</td><td>Cards: Descriptives &gt; Social Contracts; others</td><td>18633788_analysis_13</td><td>Cards</td><td>0.233</td><td>0.727</td><td>0.579</td><td>uncertain</td><td>coord_count_mismatch</td></tr><tr><td>18633788_4</td><td>Cards: Precautions &gt; Descriptives; others</td><td>18633788_analysis_11</td><td>Cards: Precautions &gt; Descriptives</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633788_5</td><td>Cards: Precautions &gt; Social Contracts; others</td><td>18633788_analysis_10</td><td>Cards: Precautions &gt; Social Contracts</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633788_6</td><td>Rest &gt; Cards; others</td><td>18633788_analysis_3</td><td>Rest &gt; Cards</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633788_7</td><td>Rest &gt; Stories; others</td><td>18633788_analysis_1</td><td>Rest&gt;Stories</td><td>1.000</td><td>0.950</td><td>0.965</td><td>accepted</td><td>high_coord_match</td></tr><tr><td>18633788_8</td><td>Stories &gt; Rest; others</td><td>18633788_analysis_0</td><td>Stories&gt;Rest</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633788_9</td><td>Stories: Descriptives &gt; Precautions; others</td><td>18633788_analysis_12</td><td>Stories</td><td>0.333</td><td>1.000</td><td>0.800</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18633834</strong> | Pred included: 6 | Manual included (accepted matches only): 6 | Correct overlaps: 6 | Match statuses: accepted=6, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18633834/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18633834_analysis_0</td><td>STEP1
+STEP2 - REST</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task explicitly probes social information in footstep sounds (one vs two walkers) and authors interpret activations as social/mentalizing and socio-emotional processing; the contrasts measure social processing.</td></tr>
<tr><td>18633834_analysis_1</td><td>NOISE1
+NOISE2 - REST</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task contrasts listening to one vs two people walking and corresponding controls; this probes perception and interpretation of social auditory scenes and mentalizing (number of walkers, intentions). Both inclusion criteria (social-related task; measures social processing) are satisfied.</td></tr>
<tr><td>18633834_analysis_2</td><td>(STEP2 - NOISE2) - (STEP1 - NOISE1)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast compares stepping sounds of two versus one person (controlling for noise) to probe processing of social scenes and group vs individual perception; task is social and measures social processing/mentalizing.</td></tr>
<tr><td>18633834_analysis_3</td><td>STEP1 - NOISE1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>STEP1–NOISE1 contrasts footsteps (social auditory stimuli) versus matched noise, probing perception of social cues (identity, biological motion) and recruiting social/emotional regions (STS, amygdala). Meets both criteria for social processing.</td></tr>
<tr><td>18633834_analysis_4</td><td>STEP2 - NOISE2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task contrasts involve listening to one vs two people walking and evoke social cognition (mentalizing, group vs single-person processing); contrasts (STEP2 – NOISE2) and STEP2 vs STEP1 measure social processing.</td></tr>
<tr><td>18633834_analysis_5</td><td>STEP2 - STEP1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast STEP2 vs STEP1 compares hearing two people vs one person walking; authors interpret activations as recruitment of social brain circuitry (temporal pole, subcallosal gyrus, amygdala) and mentalizing — meets social-processing task and measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18633834_1</td><td>(STEP2 - NOISE2) - (STEP1 - NOISE1); socialcommunication</td><td>18633834_analysis_2</td><td>(STEP2 - NOISE2) - (STEP1 - NOISE1)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633834_2</td><td>NOISE1 + NOISE2 - REST; socialcommunication</td><td>18633834_analysis_1</td><td>NOISE1
+NOISE2 - REST</td><td>0.977</td><td>1.000</td><td>0.993</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633834_3</td><td>STEP1 + STEP2 - REST; socialcommunication</td><td>18633834_analysis_0</td><td>STEP1
+STEP2 - REST</td><td>0.974</td><td>1.000</td><td>0.992</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633834_4</td><td>STEP1 - NOISE1; socialcommunication</td><td>18633834_analysis_3</td><td>STEP1 - NOISE1</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633834_5</td><td>STEP1 - STEP1; socialcommunication</td><td>18633834_analysis_5</td><td>STEP2 - STEP1</td><td>0.923</td><td>1.000</td><td>0.977</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633834_6</td><td>STEP2 - NOISE2; socialcommunication</td><td>18633834_analysis_4</td><td>STEP2 - NOISE2</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18633846</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18633846/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18633846_analysis_0</td><td>Main effect of type of observed action</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast directly compares observation of social interactions vs individual actions, measuring social processing (interpreting social interactions).</td></tr>
<tr><td>18633846_analysis_1</td><td>Main effect of gaze</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involved observing social interactions and manipulation of gaze; contrast measures social processing (main effect of gaze and social vs individual actions).</td></tr>
<tr><td>18633846_analysis_2</td><td>Interaction</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Study explicitly investigates observation and interpretation of social interactions and the modulatory role of gaze; the interaction contrast measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18633846_1</td><td>Interaction [( Individual gaze + Social No-gaze) - (Individual No-gaze + Social gaze)];socialcommunication</td><td>18633846_analysis_2</td><td>Interaction</td><td>0.227</td><td>1.000</td><td>0.768</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>18633846_2</td><td>[( Social gaze + Individual gaze) - ( Social No-gaze + Individual No-gaze)]; socialcommunication</td><td>18633846_analysis_1</td><td>Main effect of gaze</td><td>0.149</td><td>1.000</td><td>0.745</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>18633846_3</td><td>[(Individual gaze + Social No-gaze) - (Individual No-gaze + Social Gaze); socialcommunication</td><td>18633846_analysis_0</td><td>Main effect of type of observed action</td><td>0.183</td><td>1.000</td><td>0.755</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18633856</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18633856/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18633856_analysis_0</td><td>Angry&gt;Happy</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast Angry&gt;Happy manipulates perception of social signals (emotion, dominance/affiliation) during social approach — a social processing task. It directly measures social processing differences between angry (threatening) and happy (affiliative) displays.</td></tr>
<tr><td>18633856_analysis_1</td><td>Happy&gt;Angry</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves viewing dynamic social approaches and differentiating intentions (happy vs angry), directly measuring social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18633856_1</td><td>Angry &gt; Happy; affiliation</td><td>18633856_analysis_0</td><td>Angry&gt;Happy</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>18633856_2</td><td>Happy &gt; Angry; affiliation</td><td>18633856_analysis_1</td><td>Happy&gt;Angry</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18783371</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18783371/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> interaction between observed (hand and foot) and group (Compatible and Incompatible) &gt; baseline during Action Observation task; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18783371_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis involves passive observation of others’ actions and tests mirror-system responses to observed actions, which fits Perception and Understanding of Others (Action Perception) and thus meets social processing criteria.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18783371_1</td><td>interaction between observed (hand and foot) and group (Compatible and Incompatible) &gt; baseline during Action Observation task; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>18783371_2</td><td>observation of both hands and feet &gt; baseline and action execution (hands and feet) &gt; baseline (conjunction analysis); socialcommunication</td><td>18783371_analysis_0</td><td>analysis_0</td><td>0.126</td><td>1.000</td><td>0.738</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 19048432</strong> | Pred included: 7 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/19048432/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>19048432_analysis_0</td><td>Main effect of viewing eyes</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Viewing eye stimuli and processing others&#x27; pupil changes is a social perception task probing social information (implicit evaluation of others&#x27; salient cues); the contrast measures social processing.</td></tr>
<tr><td>19048432_analysis_1</td><td>Region of interest analysis</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves viewing others&#x27; eyes and dynamic pupillary signals and examines neural responses to social salience and coherence between observer and observed — fits social processing.</td></tr>
<tr><td>19048432_analysis_2</td><td>Main effect of change in observed and observer&#x27;s pupil size</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves viewing others&#x27; eyes and dynamic pupillary signals; analysis examines neural responses to observed pupil changes and coherence/incoherence between observer and observed—this is social processing of cues about others&#x27; state.</td></tr>
<tr><td>19048432_analysis_3</td><td>Region of interest analysis</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves viewing others’ eye stimuli and dynamic pupillary biofeedback to assess how observed pupil changes modulate brain activity—a clear social-processing task measuring perception and interpretation of social cues.</td></tr>
<tr><td>19048432_analysis_4</td><td>Regions of interest</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task involves viewing eye stimuli and monitoring coherence between observer&#x27;s and observed pupils—a social exchange and processing of social cues; the contrast measures social processing (responses in amygdala, STS, insula).</td></tr>
<tr><td>19048432_analysis_5</td><td>(positive &gt; negative)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task required viewing eye stimuli and processing coherence/incoherence between observer and observed pupils—this is a social-related task probing perception and interpretation of social cues; the contrast measures social processing (positive vs negative feedback modulates regions for social/emotional processing).</td></tr>
<tr><td>19048432_analysis_6</td><td>Regions of interest</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves viewing eye stimuli and implicit monitoring of another&#x27;s pupillary signals and their coherence with the observer — clearly a social-related task probing social perception and processing of others&#x27; states.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>19048432_1</td><td>Interaction between feedback condition and variance in pupil size (positive &gt; negative); socialcommunication</td><td>19048432_analysis_5</td><td>(positive &gt; negative)</td><td>0.389</td><td>1.000</td><td>0.817</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>19048432_2</td><td>Main effect of change in observed and observer’s pupil size; socialcommunication</td><td>19048432_analysis_2</td><td>Main effect of change in observed and observer&#x27;s pupil size</td><td>0.983</td><td>1.000</td><td>0.995</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>19048432_3</td><td>Main effect of viewing eyes; socialcommunication</td><td>19048432_analysis_0</td><td>Main effect of viewing eyes</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 19107754</strong> | Pred included: 6 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/19107754/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>19107754_analysis_0</td><td>Individualism (IND) &gt; Collectivism (COL)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves self-judgments and examines cultural modulation of self-representation (Perception/Understanding of Self), which is a form of social processing. The contrast measures social processing related to self-construal (I1 and I2 satisfied).</td></tr>
<tr><td>19107754_analysis_1</td><td>Collectivism (COL) &gt; Individualism (IND)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task explicitly involves self-related social cognition (self-construal, self-judgments in social contexts) and the contrast measures social processing of self (individualism vs collectivism effects on self-representation).</td></tr>
<tr><td>19107754_analysis_2</td><td>General &gt; Contextual</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves self-related social cognition (general and contextual self-judgments) which measures social processing of self-construal (individualism vs collectivism).</td></tr>
<tr><td>19107754_analysis_3</td><td>Contextual &gt; General</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Analysis contrasts general vs contextual self-judgments, i.e., perception/understanding of self within social context; clearly a social-processing task. Satisfies I1 (social-related task) and I2 (measures social processing).</td></tr>
<tr><td>19107754_analysis_4</td><td>fMRI results of interaction contrast [(INDgeneral + COLcontextual) - (INDcontextual + COLgeneral)]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves judgments about the self in social contexts (general vs contextual self judgments) and examines how cultural values modulate neural processing of self—meets social processing criteria.</td></tr>
<tr><td>19107754_analysis_5</td><td>Table V. fMRI results of whole-brain correlation analysis of self-judgment contrast image [contextual-general] with self-construal style index [COL score-IND score]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task involves self-judgments (general and contextual) and a contrast (contextual–general) correlated with self-construal (individualism/collectivism). This probes perception and understanding of the self—a social-cognitive process—so it meets both I1 and I2.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>19107754_1</td><td>Collectivism &gt; Individualism; self</td><td>19107754_analysis_1</td><td>Collectivism (COL) &gt; Individualism (IND)</td><td>0.824</td><td>1.000</td><td>0.947</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>19107754_2</td><td>Contextual &gt; General; self</td><td>19107754_analysis_3</td><td>Contextual &gt; General</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>19107754_3</td><td>General &gt; Contextual; self</td><td>19107754_analysis_2</td><td>General &gt; Contextual</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>19107754_4</td><td>Individualism &gt; Collectivism; self</td><td>19107754_analysis_0</td><td>Individualism (IND) &gt; Collectivism (COL)</td><td>0.824</td><td>1.000</td><td>0.947</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>19107754_5</td><td>Self Judgement ( Contextual &gt; General) &gt; Self-Construal Style Index ( Collectivism &gt; Individualism); self</td><td>19107754_analysis_5</td><td>Table V. fMRI results of whole-brain correlation analysis of self-judgment contrast image [contextual-general] with self-construal style index [COL score-IND score]</td><td>0.520</td><td>1.000</td><td>0.856</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 19347874</strong> | Pred included: 5 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/19347874/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Coorelation -- attachment avoidance with brain responses to masked sad faces; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>19347874_analysis_0</td><td>Brain regions exhibiting significantly increased activation in response to masked sad faces compared to neutral faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involved perception of emotional facial expressions and examined attachment-related modulation of responses—directly assesses social processing (perception and response to social cues).</td></tr>
<tr><td>19347874_analysis_1</td><td>Table II. Brain regions exhibiting significantly increased activation in response to masked happy faces compared to neutral faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves perception of emotional facial expressions and is explicitly about social/attachment signals; it measures social processing of others&#x27; emotions.</td></tr>
<tr><td>19347874_analysis_2</td><td>Negative correlations of attachment avoidance with brain responses to masked sad faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves viewing emotional facial expressions (sad, happy) and measuring neural responses; this is social processing (perception/response to others&#x27; emotions). Meets I1 (social-related task) and I2 (measures social processing).</td></tr>
<tr><td>19347874_analysis_3</td><td>Positive correlations</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task involves perception of facial emotions and attachment-related individual differences—clearly social processing.</td></tr>
<tr><td>19347874_analysis_4</td><td>Negative correlations</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves perception of emotional facial expressions and examines attachment-related differences in social/emotional processing; directly measures social processing of others&#x27; emotions.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>19347874_1</td><td>Coorelation -- attachment avoidance with brain responses to masked sad faces; socialcommunication</td><td>19347874_analysis_3</td><td>Positive correlations</td><td>0.227</td><td>0.500</td><td>0.418</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>19347874_2</td><td>Masked sad faces &gt; neutral faces; socialcommunication</td><td>19347874_analysis_0</td><td>Brain regions exhibiting significantly increased activation in response to masked sad faces compared to neutral faces</td><td>0.416</td><td>1.000</td><td>0.825</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>19347874_3</td><td>Negative coorelation -- attachment avoidance with brain responsed to masked sad faces; socialcommunication</td><td>19347874_analysis_2</td><td>Negative correlations of attachment avoidance with brain responses to masked sad faces</td><td>0.947</td><td>0.857</td><td>0.884</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>19347874_4</td><td>masked happy faces &gt; neutral faces; socialcommunication</td><td>19347874_analysis_1</td><td>Table II. Brain regions exhibiting significantly increased activation in response to masked happy faces compared to neutral faces</td><td>0.405</td><td>1.000</td><td>0.821</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 19439183</strong> | Pred included: 9 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/19439183/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>19439183_analysis_0</td><td>Pain &gt; no pain</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task involves perception of others&#x27; pain and manipulation of social context/agency; the contrast reflects social processing of observed pain (empathy).</td></tr>
<tr><td>19439183_analysis_1</td><td>Self + Other &gt; Self</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast (Self+Other &gt; Self) explicitly manipulates presence of another person and perceived agency; the task examines social context/processing of others&#x27; pain and intentions, satisfying both criteria.</td></tr>
<tr><td>19439183_analysis_2</td><td>Self &gt; Self + Other</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast compares trials with and without a second individual and assesses perceived agency and empathy for others&#x27; pain—this is a social-related task and directly measures social processing.</td></tr>
<tr><td>19439183_analysis_3</td><td>PCO &gt; PCS</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast PCO&gt;PCS tests perceived agency/social context (pain caused by another vs by self) and examines processing of others&#x27; actions and intentions; this is a social-related task and directly measures social processing.</td></tr>
<tr><td>19439183_analysis_4</td><td>PCS &gt; PCO</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task manipulates social context/perceived agency (self vs other) and the PPI contrast assesses context-dependent connectivity related to social processing, so both I1 and I2 are satisfied.</td></tr>
<tr><td>19439183_analysis_5</td><td>Emotion contagion score (during PCS trials)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The analysis correlates Emotion Contagion (a social-emotional trait) with brain responses while viewing pain stimuli (PCS trials). This measures social processing/empathy for others&#x27; pain.</td></tr>
<tr><td>19439183_analysis_6</td><td>Pain ratings (during PCS trials)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The analysis contrasts pain caused by self vs pain caused by another and tests main effects and interactions of social context and perceived agency; this directly measures social processing (perception of others, social context/agency).</td></tr>
<tr><td>19439183_analysis_7</td><td>Emotion contagion score (during PCO trials)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Analysis correlates individual emotional contagion (EC) scores with brain activity during PCO trials (pain caused by another), which directly involves social processing — perception and appraisal of others&#x27; pain and social context (agency).</td></tr>
<tr><td>19439183_analysis_8</td><td>Pain ratings (during PCO trials)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>PCO trials involve viewing another person intentionally inflicting pain; this is a social task probing perception of others and empathy, so it measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>19439183_1</td><td>Pain &gt; no pain; others</td><td>19439183_analysis_0</td><td>Pain &gt; no pain</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>19439183_2</td><td>Self + Other &gt; Self; others</td><td>19439183_analysis_1</td><td>Self + Other &gt; Self</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 19733672</strong> | Pred included: 6 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/19733672/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>19733672_analysis_0</td><td>Movie scenes theory of mind (ToM) &gt; movie scenes physical inference (PI)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast Movie scenes ToM &gt; movie scenes PI directly targets Theory of Mind—inferring others&#x27; mental states—i.e., social processing. The task is explicitly social and the contrast measures social cognitive processing.</td></tr>
<tr><td>19733672_analysis_1</td><td>Silent answer theory of mind (ToM) &gt; silent answer physical inference (PI)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares Theory of Mind (ToM) versus physical inference using a social cognition movie task (MASC). This directly probes social processing (inferring others&#x27; mental states).</td></tr>
<tr><td>19733672_analysis_2</td><td>MC answer theory of mind (ToM) &gt; MC answer physical inference (PI)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares Theory of Mind (ToM) vs Physical Inference (PI) on an MASC movie-based task assessing mental state inference about others—clearly a social-processing task. The MC answer ToM&gt;PI contrast measures social cognition/processing.</td></tr>
<tr><td>19733672_analysis_3</td><td>IC 1 (rank 8 within all 80 components)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task is an fMRI adaptation of the Movie for the Assessment of Social Cognition (MASC) probing Theory of Mind and social cognition; contrasts (ToM vs PI) explicitly measure social processing.</td></tr>
<tr><td>19733672_analysis_4</td><td>IC 2 (rank 13 within all 80 components)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task is an fMRI adaptation of the Movie for the Assessment of Social Cognition (MASC) probing Theory of Mind; IC2 timecourse correlates with ToM conditions and shows ToM&gt;PI effects, so it measures social processing.</td></tr>
<tr><td>19733672_analysis_5</td><td>IC 3 (rank 19 within all 80 components)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task is the Movie for the Assessment of Social Cognition (MASC) and explicitly contrasts Theory of Mind (ToM) vs physical inference (PI); it measures social processing (perception and reasoning about others).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>19733672_1</td><td>MC answer theory of mind (ToM)NMC answer physical inference (PI); others</td><td>19733672_analysis_2</td><td>MC answer theory of mind (ToM) &gt; MC answer physical inference (PI)</td><td>0.969</td><td>1.000</td><td>0.991</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>19733672_2</td><td>Movie scenes theory of mind (ToM) &gt; movie scenes physical inference (PI); others</td><td>19733672_analysis_0</td><td>Movie scenes theory of mind (ToM) &gt; movie scenes physical inference (PI)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>19733672_3</td><td>Silent answer theory of mind (ToM) &gt; silent answer physical inference (PI); others</td><td>19733672_analysis_1</td><td>Silent answer theory of mind (ToM) &gt; silent answer physical inference (PI)</td><td>1.000</td><td>0.800</td><td>0.860</td><td>accepted</td><td>high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 19944083</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/19944083/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>19944083_analysis_0</td><td>Emotional &gt; neutral stimuli</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast compares emotional vs neutral social scenes and probes perception/understanding of others and social cognition (empathy, mentalizing). Meets both social-related task and measures social processing.</td></tr>
<tr><td>19944083_analysis_1</td><td>Neutral &gt; emotional stimuli</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast uses social stimuli (pictures of people in emotional or neutral social situations) and probes social/empathic processing; it meets both: (I1) a social-related task and (I2) measures social processing (emotion perception/ empathy).</td></tr>
<tr><td>19944083_analysis_2</td><td>Social relation &gt; single person</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast compares stimuli depicting social relations (two persons) vs single person and probes social cognition/processing (mentalizing, STS, mPFC); meets both criteria.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>19944083_1</td><td>Emotional &gt; neutral stimuli; self</td><td>19944083_analysis_0</td><td>Emotional &gt; neutral stimuli</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>19944083_2</td><td>Neutral &gt; emotional stimuli; self</td><td>19944083_analysis_1</td><td>Neutral &gt; emotional stimuli</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>19944083_3</td><td>Social relation &gt; single person; self</td><td>19944083_analysis_2</td><td>Social relation &gt; single person</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 20045478</strong> | Pred included: 4 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/20045478/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>20045478_analysis_0</td><td>Self &gt; syllables</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast (Self &gt; syllables) indexes self-referential processing, which is a form of social processing (Perception/Understanding of Self) and thus meets both inclusion criteria.</td></tr>
<tr><td>20045478_analysis_1</td><td>Other &gt; syllables</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves making trait judgments about a friend (social reference), which is a social-processing task assessing perception/understanding of others and self–other similarity; contrast Other &gt; syllables measures social processing.</td></tr>
<tr><td>20045478_analysis_2</td><td>Self &gt; other</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task contrasts self versus friend trait judgments and examines perceived similarity — clearly a social cognition task assessing perception/understanding of self and others.</td></tr>
<tr><td>20045478_analysis_3</td><td>Other &gt; self</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task directly involves social cognition: trait judgments about self and a close friend; contrast assesses processing of others vs self and uses perceived similarity—meets social processing criteria.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>20045478_1</td><td>Other &gt; self; others</td><td>20045478_analysis_3</td><td>Other &gt; self</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>20045478_2</td><td>Other &gt; syllables; others</td><td>20045478_analysis_1</td><td>Other &gt; syllables</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>20045478_3</td><td>Self &gt; other; self</td><td>20045478_analysis_2</td><td>Self &gt; other</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>20045478_4</td><td>Self &gt; syllables; self</td><td>20045478_analysis_0</td><td>Self &gt; syllables</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 20056152</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/20056152/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>20056152_analysis_0</td><td>Places &gt; bodies</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves attributing what another person sees (joint attention, gaze following) and contrasts brain responses when the avatar looks at bodies vs places; this directly measures social processing and perception/representation of others&#x27; mental content.</td></tr>
<tr><td>20056152_analysis_1</td><td>Bodies &gt; places</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task uses a joint-attention paradigm where participants represent what another person (avatar) sees; contrast Bodies &gt; Places probes social cognition/content attribution. Meets I1 (social-related task) and I2 (measures Social Processing).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>20056152_1</td><td>Bodies &gt; Places; socialcommunication</td><td>20056152_analysis_1</td><td>Bodies &gt; places</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>20056152_2</td><td>Places &gt; Bodies; socialcommunication</td><td>20056152_analysis_0</td><td>Places &gt; bodies</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 20096792</strong> | Pred included: 4 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/20096792/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>20096792_analysis_0</td><td>Live&gt;Recorded</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Live&gt;Recorded contrast manipulates social contingency and face-to-face interaction, directly targeting social processing (social cognition, contingent interaction). It meets both criteria: it is a social-related task and the contrast measures social processing.</td></tr>
<tr><td>20096792_analysis_1</td><td>Recorded&gt;Live</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is a live vs. recorded social interaction; the contrast probes social processing (contingency, social relevance). Both inclusion criteria are met.</td></tr>
<tr><td>20096792_analysis_2</td><td>JA&gt;SA</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Joint Attention vs Solo Attention is a live social-interaction task probing social cognition and coordination of attention; it directly measures social processing (joint attention).</td></tr>
<tr><td>20096792_analysis_3</td><td>SA&gt;JA</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task contrasts live/joint vs recorded/solo attention in face-to-face interactions and explicitly targets social interaction and joint attention; it clearly measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>20096792_1</td><td>Live &gt; Recorded; socialcommunication</td><td>20096792_analysis_0</td><td>Live&gt;Recorded</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>20096792_2</td><td>Recorded &gt; Live; socialcommunication</td><td>20096792_analysis_1</td><td>Recorded&gt;Live</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>20096792_3</td><td>JA &gt; SA; socialcommunication</td><td>20096792_analysis_2</td><td>JA&gt;SA</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 20119878</strong> | Pred included: 4 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/20119878/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>20119878_analysis_0</td><td>Neural regions active to warmth expectancy violation social targets</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis tests social expectancy violations in perceptions of others (warmth and competence), using behavioral attributions and pictures of social targets — a social cognition task measuring social processing.</td></tr>
<tr><td>20119878_analysis_1</td><td>Neural regions active to warmth expectancy consistent social targets</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task explicitly involves perceiving social targets, making trait attributions (warmth/competence), and examining social expectancy violations—this is social processing of others.</td></tr>
<tr><td>20119878_analysis_2</td><td>Neural regions active to competence expectancy violation social targets</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis is a social task examining expectancy violations in trait (warmth/competence) judgments about other people and associated neural responses — this measures social processing.</td></tr>
<tr><td>20119878_analysis_3</td><td>Neural regions active to competence expectancy consistent social targets</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task explicitly involves forming expectancies about social targets (warmth and competence) and perceiving faces to evaluate trait consistency/violation — a core social processing measure.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>20119878_1</td><td>competence expectancy violation &gt; consistant competence expectency; others</td><td>20119878_analysis_2</td><td>Neural regions active to competence expectancy violation social targets</td><td>0.540</td><td>1.000</td><td>0.862</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>20119878_2</td><td>consistant competence expectency &gt; competence expectancy violation; others</td><td>20119878_analysis_3</td><td>Neural regions active to competence expectancy consistent social targets</td><td>0.507</td><td>1.000</td><td>0.852</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>20119878_3</td><td>consistent warmth expectancy &gt;  warm expectancy violation; others</td><td>20119878_analysis_1</td><td>Neural regions active to warmth expectancy consistent social targets</td><td>0.468</td><td>1.000</td><td>0.840</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>20119878_4</td><td>warm expectancy violation  &gt;  consistent warmth expectancy; others</td><td>20119878_analysis_0</td><td>Neural regions active to warmth expectancy violation social targets</td><td>0.504</td><td>1.000</td><td>0.851</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 20188182</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=6</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/20188182/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> loved one &gt; self; affiliation, loved one &gt; stranger; affiliation, self &gt; loved one; self, self &gt; stranger; self, stranger &gt; loved one; others, stranger &gt; self; others</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>20188182_analysis_0</td><td>Brain regions showing a significant effect of pain.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves perspective-taking about others in painful vs neutral situations (empathy for pain). The contrast (pain vs neutral across perspectives) reflects social processing (empathy/perception of others), satisfying I1 (social-related task) and I2 (measures social processing).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>20188182_1</td><td>loved one &gt; self; affiliation</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>20188182_2</td><td>loved one &gt; stranger; affiliation</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>20188182_3</td><td>pain &gt; no pain; others</td><td>20188182_analysis_0</td><td>Brain regions showing a significant effect of pain.</td><td>0.369</td><td>1.000</td><td>0.811</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>20188182_4</td><td>self &gt; loved one; self</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>20188182_5</td><td>self &gt; stranger; self</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>20188182_6</td><td>stranger &gt; loved one; others</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>20188182_7</td><td>stranger &gt; self; others</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 20188190</strong> | Pred included: 7 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/20188190/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>20188190_analysis_0</td><td>Preference</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The &#x27;Preference&#x27; task explicitly engages social evaluation of others (judging whether the subject likes a person). This is a social-related task measuring social processing (social preference), so both I1 and I2 are satisfied.</td></tr>
<tr><td>20188190_analysis_1</td><td>Gender</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast compares Preference (liking a person) vs Gender identification using faces; this directly probes social evaluation/social preference and thus measures social processing.</td></tr>
<tr><td>20188190_analysis_2</td><td>Preference &gt; Gender</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Preference &gt; Gender contrast explicitly probes social preference judgments about faces (&quot;Do I like this person?&quot;), a social-related task and measures social processing (evaluation of others).</td></tr>
<tr><td>20188190_analysis_3</td><td>Gender &gt; Preference</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task explicitly probes social preference judgments (&#x27;Do I like this person?&#x27;) using faces and contrasts Preference &gt; Gender, directly measuring social processing.</td></tr>
<tr><td>20188190_analysis_4</td><td>aMFC</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task explicitly probes social preference for faces (Preference vs Gender), measuring social processing of others; meets both I1 and I2.</td></tr>
<tr><td>20188190_analysis_5</td><td>vMFC</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task explicitly probes social preference (&#x27;Do I like this person?&#x27;) and the contrast (Preference vs Gender) measures social processing and evaluation of others.</td></tr>
<tr><td>20188190_analysis_6</td><td>PCC</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task explicitly probes social preference (&#x27;Do I like this person?&#x27;) and the contrast (Preference &gt; Gender) measures social processing and related neural responses.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>20188190_1</td><td>Gender &gt; Preference; socialcommunication</td><td>20188190_analysis_3</td><td>Gender &gt; Preference</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>20188190_2</td><td>Preference &gt; Gender; socialcommunication</td><td>20188190_analysis_2</td><td>Preference &gt; Gender</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 21249224</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/21249224/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>21249224_analysis_0</td><td>Brain areas showing increased activity in response to the social interaction condition.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast (SI vs NSI) directly probes perception and understanding of social interactions and social intentions using point-light displays, meeting both criteria.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>21249224_1</td><td>social interactions &gt; nonsocial interactions; others</td><td>21249224_analysis_0</td><td>Brain areas showing increased activity in response to the social interaction condition.</td><td>0.397</td><td>1.000</td><td>0.819</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 21320516</strong> | Pred included: 2 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/21320516/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>21320516_analysis_0</td><td>Female and male</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task involves processing humorous social stimuli and the authors explicitly discuss social-cognitive processes (theory-of-mind/mentalizing, TPJ) and interpret results in terms of social/emotional processing. Contrasts (CvsN and parametric modulation) measure social processing.</td></tr>
<tr><td>21320516_analysis_1</td><td>Female and male</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task examines humor processing, which the authors frame as a social phenomenon and discuss mentalizing/ToM and perception of others (TPJ, ACC). The fMRI contrasts and parametric modulation assess social-emotional processing tied to understanding/processing social stimuli, satisfying both I1 and I2.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>21320516_1</td><td>cartoons &gt; neutral pictures; socialcommunication</td><td>21320516_analysis_0</td><td>Female and male</td><td>0.238</td><td>1.000</td><td>0.771</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 21600991</strong> | Pred included: 2 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/21600991/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>21600991_analysis_0</td><td>Activations in the retrieval of social context</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The analysis explicitly contrasts social vs non-social (solitary) encoding/retrieval {(rSS+rSO)−(rNS+rNO)}, targeting representation of social context in episodic memory; this directly tests social processing.</td></tr>
<tr><td>21600991_analysis_1</td><td>Activations in the retrieval of self-generation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis explicitly manipulates and contrasts social vs. non-social (solitary) context during encoding and retrieval (SS/SO vs NS/NO) and identifies brain activation related to social context retrieval (right mPFC). This directly measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>21600991_1</td><td>Retrieval of social context &gt; Retrieval of self-generation; socialcommunication</td><td>21600991_analysis_1</td><td>Activations in the retrieval of self-generation</td><td>0.724</td><td>1.000</td><td>0.917</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 21703352</strong> | Pred included: 3 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/21703352/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>21703352_analysis_0</td><td>Neural regions engaged during decisions to accept Costly-Donation relative to Noncostly-Reward trials.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast examines prosocial decisions (Costly-Donation vs Noncostly-Reward) involving family, engaging social cognition and prosocial behavior; it thus uses a social-related task and measures social processing.</td></tr>
<tr><td>21703352_analysis_1</td><td>Neural regions associated with family obligation preferences during decisions to accept Costly-Donation versus Noncostly-Reward trials.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves prosocial decisions about family (social behavior) and the contrast (Costly-Donation vs Noncostly-Reward) directly measures social processing (helping others, mentalizing).</td></tr>
<tr><td>21703352_analysis_2</td><td>Neural regions associated with the ventral striatum during decisions to accept Costly-Donation relative to Noncostly-Reward trials that correlated positively with participants&#x27; family obligation preferences.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task is explicitly social (decisions about helping family) and the contrast (Costly-Donation vs Noncostly-Reward) measures social processing (mentalizing, social preferences).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>21703352_1</td><td>Costly-Donation relative to Noncostly-Reward (accept); others</td><td>21703352_analysis_0</td><td>Neural regions engaged during decisions to accept Costly-Donation relative to Noncostly-Reward trials.</td><td>0.594</td><td>1.000</td><td>0.878</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>21703352_2</td><td>Costly-Donation versus Noncostly-Reward (Family obligtations); others</td><td>21703352_analysis_1</td><td>Neural regions associated with family obligation preferences during decisions to accept Costly-Donation versus Noncostly-Reward trials.</td><td>0.439</td><td>1.000</td><td>0.832</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 21955370</strong> | Pred included: 4 | Manual included (accepted matches only): 3 | Correct overlaps: 2 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/21955370/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>21955370_analysis_0</td><td>I(H + M) &gt; C(H + M)</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Contrast is I(H+M) &gt; C(H+M): main effect of Stroop (incongruent vs congruent) collapsed across Human and Machine. It measures executive/inhibition processes, not social processing specifically, so it does not satisfy I2 (must measure Social Processing). Although the task includes a social context, this contrast does not isolate social effects.</td></tr>
<tr><td>21955370_analysis_1</td><td>C(H + M) &gt; I(H + M)</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The experiment is a social-competition paradigm (so the task is social: I1 would be satisfied), but this specific contrast (C(H+M) &gt; I(H+M)) tests congruent vs incongruent stimuli collapsed across Human and Machine. It isolates an executive Stroop effect rather than social processing or ToM. Therefore it does not meet I2 (the contrast does not measure Social Processing specifically).</td></tr>
<tr><td>21955370_analysis_2</td><td>H(I + C) &gt; M(I + C)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast compares human–human vs human–machine competition and is explicitly designed to engage Theory of Mind and social interaction processes, satisfying both criteria.</td></tr>
<tr><td>21955370_analysis_3</td><td>M(I + C) &gt; H(I + C)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast compares human–human vs human–machine competition and was designed to elicit Theory of Mind/social interaction processes. This is a social-related task and the contrast measures social processing (ToM in competition).</td></tr>
<tr><td>21955370_analysis_4</td><td>[H(I &gt; C)] &gt; [M(I &gt; C)]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast isolates brain activity related to social interaction (human vs machine competition) and Theory of Mind during the Stroop task, directly measuring social processing.</td></tr>
<tr><td>21955370_analysis_5</td><td>[M(I &gt; C)] &gt; [H(I &gt; C)]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task contrasts human vs. machine competition and isolates regions modulated by social (human–human) interaction/mentalizing — directly measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>21955370_1</td><td>H(I + C) &gt; M(I + C); affiliation</td><td>21955370_analysis_2</td><td>H(I + C) &gt; M(I + C)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>21955370_2</td><td>I(H + M) &gt; C(H + M); affiliation</td><td>21955370_analysis_0</td><td>I(H + M) &gt; C(H + M)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>21955370_3</td><td>[H(I &gt; C)] &gt; [M(I &gt; C)]; affiliation</td><td>21955370_analysis_4</td><td>[H(I &gt; C)] &gt; [M(I &gt; C)]</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 22019860</strong> | Pred included: 2 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/22019860/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> observation of biological motion displays &gt; scrambled displays; others</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>22019860_analysis_0</td><td>A</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is visual perception of biological motion (point-light walkers) and the contrast (biological vs scrambled) assesses perception/understanding of others&#x27; actions and social cues; this meets Social Processing inclusion criteria.</td></tr>
<tr><td>22019860_analysis_1</td><td>B</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The task involves perception of biological motion (point-light walkers) and the analysis focuses on connectivity between cerebellum and pSTS, a region implicated in social cognition; this measures social processing (perception/understanding of others).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>22019860_1</td><td>Observation of biological motion displays &gt; observation of scrambled displays; others</td><td>22019860_analysis_0</td><td>A</td><td>0.026</td><td>1.000</td><td>0.708</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>22019860_2</td><td>observation of biological motion displays &gt; scrambled displays; others</td><td>22019860_analysis_1</td><td>B</td><td>0.032</td><td>0.076</td><td>0.062</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 22174872</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/22174872/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>22174872_analysis_0</td><td>Subtraction of neutral form emotional trials.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Emotional prosody comprehension is a social-related task that requires perceiving and interpreting others&#x27; emotional states; the emotional &gt; neutral contrast measures social processing (recognition/interpretation of others&#x27; emotions).</td></tr>
<tr><td>22174872_analysis_1</td><td>Subtraction of simple from complex emotion trials.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task examines emotional prosody comprehension and contrast (complex &gt; simple) which taps social cognition (inferring others&#x27; mental states) and social-emotional processing; satisfies both criteria.</td></tr>
<tr><td>22174872_analysis_2</td><td>Subtraction of simple from complex emotion trials (controlled for pitch).</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is emotional prosody comprehension comparing complex vs simple emotions, requiring inference about others&#x27; mental states and social cognition (authors explicitly link complex emotion decoding to ToM and perspective-taking). This satisfies both social-related task and measurement of social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>22174872_1</td><td>Complex emotion trials &gt; Simple emotion trials</td><td>22174872_analysis_1</td><td>Subtraction of simple from complex emotion trials.</td><td>0.458</td><td>1.000</td><td>0.838</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>22174872_2</td><td>Complex emotion trials &gt; Simple emotion trials (controlling for pitch)</td><td>22174872_analysis_2</td><td>Subtraction of simple from complex emotion trials (controlled for pitch).</td><td>0.601</td><td>1.000</td><td>0.880</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>22174872_3</td><td>Emotional trials &gt; Neutral Trials</td><td>22174872_analysis_0</td><td>Subtraction of neutral form emotional trials.</td><td>0.410</td><td>1.000</td><td>0.823</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 22726841</strong> | Pred included: 5 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/22726841/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>22726841_analysis_0</td><td>Simulated-other&#x27;s reward prediction error</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis uses an explicit social task in which subjects predict another person’s choices and models simulated-other reward and action prediction errors — directly measuring social processing (simulation of others).</td></tr>
<tr><td>22726841_analysis_1</td><td>Simulated-other&#x27;s action prediction error</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task requires predicting another person&#x27;s choices and the analysis measures simulated-other prediction errors—directly assessing social cognition/processing of others.</td></tr>
<tr><td>22726841_analysis_2</td><td>Reward probability</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task explicitly requires predicting and simulating another person&#x27;s decisions (simulation learning of others), which is a social-processing task and the analysis measures social processing (simulation of others&#x27; values and prediction errors).</td></tr>
<tr><td>22726841_analysis_3</td><td>Reward prediction error</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis probes prediction of another person&#x27;s choices and neural signals (simulated-other reward prediction error), which is a social task and directly measures social processing (simulation/understanding of others).</td></tr>
<tr><td>22726841_analysis_4</td><td>Reward probability</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis (‘Reward probability’/Other task) requires subjects to predict another person’s choices and models simulated-other reward and action prediction errors—this is a social-processing task and directly measures social cognition/simulation.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>22726841_1</td><td>Reward Prediction Error (control) &gt; Reward probability (other); affiliation</td><td>22726841_analysis_3</td><td>Reward prediction error</td><td>0.541</td><td>1.000</td><td>0.862</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>22726841_2</td><td>Reward probability (other) &gt;  Reward Prediction Error (control); affiliation</td><td>22726841_analysis_4</td><td>Reward probability</td><td>0.450</td><td>1.000</td><td>0.835</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>22726841_3</td><td>Reward probability (other) &gt; Reward Prediction Error (other); affiliation</td><td>22726841_analysis_2</td><td>Reward probability</td><td>0.462</td><td>1.000</td><td>0.838</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>22726841_4</td><td>Simulated-other’s action prediction error &gt; Simulated-other’s reward prediction error; affiliation</td><td>22726841_analysis_1</td><td>Simulated-other&#x27;s action prediction error</td><td>0.635</td><td>1.000</td><td>0.890</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>22726841_5</td><td>Simulated-other’s reward prediction error &gt; Simulated-other’s action prediction error; affiliation</td><td>22726841_analysis_0</td><td>Simulated-other&#x27;s reward prediction error</td><td>0.635</td><td>1.000</td><td>0.890</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 22841755</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/22841755/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>22841755_analysis_0</td><td>Power motive</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis uses social movie clips (affiliation and power) and regresses neural responses on affiliation/power motive scores—this directly probes social processing (social motivations and responses).</td></tr>
<tr><td>22841755_analysis_1</td><td>Affiliation motive</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis uses film clips of affiliation and power and regresses neural responses on affiliation/power motive scores — a social-related task measuring affiliation/power processing, satisfying both criteria.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>22841755_1</td><td>affiliation &gt; power; affiliation</td><td>22841755_analysis_1</td><td>Affiliation motive</td><td>0.757</td><td>1.000</td><td>0.927</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>22841755_2</td><td>power &gt; affiliation; affiliation</td><td>22841755_analysis_0</td><td>Power motive</td><td>0.516</td><td>1.000</td><td>0.855</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23063451</strong> | Pred included: 7 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23063451/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23063451_analysis_0</td><td>Self &gt; Other</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is explicitly social (empathy, perspective taking Self vs Other) and the contrast measures social processing of self/other perspectives in an empathy-for-pain paradigm.</td></tr>
<tr><td>23063451_analysis_1</td><td>Other &gt; Self</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task explicitly involves perspective taking and empathy (Self vs Other) and measures social cognition about others, fulfilling social processing criteria.</td></tr>
<tr><td>23063451_analysis_2</td><td>OtherGood &gt; OtherBad performer</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast compares successful versus unsuccessful perspective taking for Other (third-person) during empathy-for-pain task, which directly measures social processing (perception and understanding of others and perspective-taking).</td></tr>
<tr><td>23063451_analysis_3</td><td>OtherBad &gt; OtherGood performer</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task explicitly involves perspective taking, empathy, and judgments about self/other—core social processing constructs. The analysis contrasts Self vs Other and uses subjective success ratings, directly measuring social processing.</td></tr>
<tr><td>23063451_analysis_4</td><td>SelfGood &gt; SelfBad performer</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The analysis tests perspective taking and empathy for pain (SelfGood vs SelfBad), which are social cognitive processes involving perception and understanding of self/others and empathic responding — meets social processing criteria.</td></tr>
<tr><td>23063451_analysis_5</td><td>SelfBad &gt; SelfGood performer</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast involves perspective-taking (Self vs Other) and compares successful vs unsuccessful self-perspective performance, which is a core social-cognitive task assessing perception/understanding of self/others and empathic responding. Satisfies both social-task and measurement of social processing.</td></tr>
<tr><td>23063451_analysis_6</td><td>analysis_6</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task directly involves perspective taking, empathy, and self/other distinction—core social processing. The contrasts (Self vs Other; successful vs unsuccessful perspective taking) measure social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23063451_1</td><td>Conjunction of Other and Self; others</td><td>23063451_analysis_6</td><td>analysis_6</td><td>0.170</td><td>1.000</td><td>0.751</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>23063451_2</td><td>Other &gt; Self; others</td><td>23063451_analysis_1</td><td>Other &gt; Self</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23063451_3</td><td>Self &gt; Other; self</td><td>23063451_analysis_0</td><td>Self &gt; Other</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23221019</strong> | Pred included: 5 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=2</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23221019/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Conjunction of all Conditions &gt; Fixation Baseline; socialcommunication, Load x Goal &gt; Fixation Baseline; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23221019_analysis_0</td><td>Conjunction of all conditions versus fixation baseline</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task involves observing others’ actions and inferring goals/mental states (why/how task) — directly measures social processing and mentalizing/mirror systems.</td></tr>
<tr><td>23221019_analysis_1</td><td>Conjunction of low-load/how-goal condition &gt; low-load/observe-goal condition and high-load/how-goal condition &gt; high-load/observe-goal condition</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves observing others’ actions and inferring mental states (why/how goals); it is a social-cognitive task measuring social processing (mirror and mentalizing systems).</td></tr>
<tr><td>23221019_analysis_2</td><td>Modulation by load for any of the four goals</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task involved observing actions and adopting goals (what/why/how) to infer others’ actions and mental states, directly measuring social cognitive processing (action understanding and mentalizing).</td></tr>
<tr><td>23221019_analysis_3</td><td>Low-load/why-goal condition compared with high-load/why-goal condition, low-load/how-goal condition, and high-load/how-goal condition combined</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves observing actions and inferring others’ intentions/mental states (why/how goals) — clearly social processing.</td></tr>
<tr><td>23221019_analysis_4</td><td>Load-by-goal interaction</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The task required participants to adopt goals (what/why/how/observe) while observing actions and to infer actors’ motives and actions—directly measuring social-cognitive processing and action understanding (mentalizing and mirror systems). This satisfies I1 (social-related task) and I2 (measures social processing).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23221019_1</td><td>Conjunction of all Conditions &gt; Fixation Baseline; socialcommunication</td><td>23221019_analysis_0</td><td>Conjunction of all conditions versus fixation baseline</td><td>0.932</td><td>0.200</td><td>0.420</td><td>unmatched</td><td>coord_count_mismatch, low_coord_high_name, low_total_score</td></tr><tr><td>23221019_2</td><td>Conjunction of low-load/how-goal condition &gt; low-load/observe-goal condition and high-load/how-goal condition &gt; high-load/observe-goal condition; socialcommunication</td><td>23221019_analysis_1</td><td>Conjunction of low-load/how-goal condition &gt; low-load/observe-goal condition and high-load/how-goal condition &gt; high-load/observe-goal condition</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23221019_3</td><td>Load x Goal &gt; Fixation Baseline; socialcommunication</td><td>23221019_analysis_4</td><td>Load-by-goal interaction</td><td>0.545</td><td>0.429</td><td>0.464</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>23221019_4</td><td>Low-load/why-goal condition compared with high-load/why-goal condition, low-load/how-goal condition, and high-load/how-goal condition combined; socialcommunication</td><td>23221019_analysis_3</td><td>Low-load/why-goal condition compared with high-load/why-goal condition, low-load/how-goal condition, and high-load/how-goal condition combined</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23221019_5</td><td>Modulation by load for any of the four goals; socialcommunication</td><td>23221019_analysis_2</td><td>Modulation by load for any of the four goals</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23298748</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23298748/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23298748_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task required judgments of face trustworthiness (social trait perception), directly measuring social processing (perception of others). Both inclusion criteria met.</td></tr>
<tr><td>23298748_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task explicitly manipulates social information (trustworthiness of faces) and compares social vs nonsocial working memory, so it measures social processing.</td></tr>
<tr><td>23298748_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task explicitly manipulated sociality (trustworthiness judgments) and contrasted social vs nonsocial conditions; analysis measures social processing (main effect of sociality and interactions).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23298748_1</td><td>interaction between sociality and working memory load; socialcommunication</td><td>23298748_analysis_2</td><td>analysis_2</td><td>0.127</td><td>1.000</td><td>0.738</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>23298748_2</td><td>sociality &gt; working memory load; socialcommunication</td><td>23298748_analysis_0</td><td>analysis_0</td><td>0.146</td><td>1.000</td><td>0.744</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>23298748_3</td><td>working memory load &gt; sociality; socialcommunication</td><td>23298748_analysis_1</td><td>analysis_1</td><td>0.195</td><td>1.000</td><td>0.759</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23378834</strong> | Pred included: 10 | Manual included (accepted matches only): 12 | Correct overlaps: 7 | Match statuses: accepted=12, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23378834/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23378834_analysis_0</td><td>FAMOUS FACES vs. BASELINE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Contrasting famous faces vs baseline is a person-related task that involves perceiving and retrieving social/identity information about others (person knowledge/familiarity), so it qualifies as social processing.</td></tr>
<tr><td>23378834_analysis_1</td><td>FAMILIAR FACES vs. BASELINE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast compares familiar (famous/personal) faces to baseline and includes tasks (social closeness judgments, face recognition) that engage social perception and person knowledge — meets both I1 and I2.</td></tr>
<tr><td>23378834_analysis_2</td><td>FAMOUS ∩ FAMILIAR FACES</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Contrast involves social-related tasks (famous and personally familiar faces) and specifically a social closeness task; the analysis measures social processing (Facesfriends vs. Facesnovel, famous vs. novel).</td></tr>
<tr><td>23378834_analysis_3</td><td>Faces &gt; Landmarks</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Faces &gt; Landmarks contrasts involve face perception and recognition of people, which are social processes (paper includes famous and personally familiar faces and social-closeness tasks). The contrast measures social processing (perception/recognition of others), meeting I1 and I2.</td></tr>
<tr><td>23378834_analysis_4</td><td>Landmarks &gt; Faces</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>The contrast is Landmarks &gt; Faces (landmarks greater than faces). This contrast does not probe social-related processing; it identifies regions responding more to landmarks than to faces. Therefore it does not meet the inclusion criteria for Social Processing (I1/I2).</td></tr>
<tr><td>23378834_analysis_5</td><td>Famous faces &gt; Novel faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast (famous &gt; novel faces) taps person-related social information and person knowledge (recognition, biographical/semantic retrieval), which is social processing per the definition.</td></tr>
<tr><td>23378834_analysis_6</td><td>Novel faces &gt; Famous faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast examines faces varying in familiarity (novel vs famous), which implicates social perception and person knowledge — a social processing task measuring perception/recognition of others.</td></tr>
<tr><td>23378834_analysis_7</td><td>Novel faces &gt; Novel landmarks</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast compares novel (unfamiliar) faces to novel landmarks — a face-perception task that involves perceiving others and social information; therefore it measures social processing (perception of others).</td></tr>
<tr><td>23378834_analysis_8</td><td>Novel landmarks &gt; Novel faces</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Contrast &#x27;Novel landmarks &gt; Novel faces&#x27; compares non-social scenes (landmarks) to faces in a perceptual task; it does not probe social processes (e.g., affiliation, theory-of-mind, social judgments). Although faces are stimuli, the contrast emphasizes landmarks over faces and the task is not social, so inclusion criteria I1/I2 are not met.</td></tr>
<tr><td>23378834_analysis_9</td><td>Famous faces &gt; Novel landmarks</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast involves famous faces (person identification/person memory), which is social processing (perception and knowledge about other people). The contrast (famous faces &gt; novel landmarks) assesses social/person-related processing compared to non-social stimuli.</td></tr>
<tr><td>23378834_analysis_10</td><td>Novel landmarks &gt; Famous faces</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>The contrast &#x27;Novel landmarks &gt; Famous faces&#x27; compares non-social (landmarks) to social (famous faces) stimuli and does not target social processing per se (it identifies regions more active for landmarks). Although famous faces are social stimuli, this contrast does not measure social processing constructs (e.g., perception/understanding of others) in the intended direction, so inclusion criteria I1/I2 are not satisfied.</td></tr>
<tr><td>23378834_analysis_11</td><td>Famous landmarks &gt; Novel landmarks</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Contrast is Famous landmarks &gt; Novel landmarks (place/landmark recognition). This is a non-social perceptual/semantic familiarity contrast about landmarks/places, not a social-task measuring affiliation, social interaction, or perception of people. It does not satisfy I1 or I2.</td></tr>
<tr><td>23378834_analysis_12</td><td>Novel landmarks &gt; Famous landmarks</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>The contrast (novel landmarks &gt; famous landmarks) compares place/landmark stimuli, not social or person-related stimuli. It does not involve a social-related task or measures of social processing (fails I1 and I2).</td></tr>
<tr><td>23378834_analysis_13</td><td>Familiar faces &gt; Novel faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares familiar (famous/personal) vs novel faces and the tasks include social-closeness and person recognition judgments — clearly probing social processing and person perception/knowledge.</td></tr>
<tr><td>23378834_analysis_14</td><td>Famous ∩ Familiar faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrasts involve face recognition, famous vs. unfamiliar faces and social closeness judgments with friends—tasks that probe social perception and person-knowledge. Meets I1 (social-related tasks) and I2 (measures social processing).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23378834_1</td><td>Faces &gt; Landmarks; socialcommunication</td><td>23378834_analysis_3</td><td>Faces &gt; Landmarks</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_10</td><td>Novel landmarks &gt; Famous faces; socialcommunication</td><td>23378834_analysis_10</td><td>Novel landmarks &gt; Famous faces</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_11</td><td>Novel landmarks &gt; Famous landmarks; socialcommunication</td><td>23378834_analysis_12</td><td>Novel landmarks &gt; Famous landmarks</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_12</td><td>Novel landmarks &gt; Novel faces; socialcommunication</td><td>23378834_analysis_8</td><td>Novel landmarks &gt; Novel faces</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_2</td><td>Familiar faces &gt; Novel faces; socialcommunication</td><td>23378834_analysis_13</td><td>Familiar faces &gt; Novel faces</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_3</td><td>Famous faces &gt; Novel faces; socialcommunication</td><td>23378834_analysis_5</td><td>Famous faces &gt; Novel faces</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_4</td><td>Famous faces &gt; Novel landmarks; socialcommunication</td><td>23378834_analysis_9</td><td>Famous faces &gt; Novel landmarks</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_5</td><td>Famous landmarks &gt; Novel landmarks; socialcommunication</td><td>23378834_analysis_11</td><td>Famous landmarks &gt; Novel landmarks</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_6</td><td>Famous ∩ Familiar faces; socialcommunication</td><td>23378834_analysis_14</td><td>Famous ∩ Familiar faces</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_7</td><td>Landmarks &gt; Faces; socialcommunication</td><td>23378834_analysis_4</td><td>Landmarks &gt; Faces</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_8</td><td>Novel faces &gt; Famous faces; socialcommunication</td><td>23378834_analysis_6</td><td>Novel faces &gt; Famous faces</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_9</td><td>Novel faces &gt; Novel landmarks; socialcommunication</td><td>23378834_analysis_7</td><td>Novel faces &gt; Novel landmarks</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23599165</strong> | Pred included: 8 | Manual included (accepted matches only): 7 | Correct overlaps: 7 | Match statuses: accepted=7, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23599165/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23599165_analysis_0</td><td>Yes (Match + Unrequited) &gt; No (Rejection + Disinterest)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is a real-world social task (speed-dating) probing responses to others&#x27; romantic decisions; contrasts (Yes vs No, Match vs Unrequited, violations of expectation) directly measure social processing (mentalizing, social reward, updating beliefs).</td></tr>
<tr><td>23599165_analysis_1</td><td>No (Rejection + Disinterest) &gt; Yes (Match + Unrequited)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task is a real-world social task (speed-dating) and the contrast examines neural responses to partners&#x27; social decisions, expectations, and learning—direct measures of social processing.</td></tr>
<tr><td>23599165_analysis_2</td><td>Match &gt; Unrequited</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares social outcomes from a speed-dating task (Match vs Unrequited), clearly measuring social processing (responses to others&#x27; romantic interest, expectations, and updating).</td></tr>
<tr><td>23599165_analysis_3</td><td>Rejection &gt; Disinterest</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast Rejection &gt; Disinterest arises from a real-world social task (speed-dating) and measures responses to social outcomes, expectations, and learning about romantic interest/rejection—clearly indexing social processing.</td></tr>
<tr><td>23599165_analysis_4</td><td>Mismatched (Rejection + Unrequited) &gt; matched (Match + Disinterest)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task uses real-world social interactions (speed-dating) and the contrast indexes social processing (violations of expectations about partners&#x27; decisions, mentalizing and affective responses).</td></tr>
<tr><td>23599165_analysis_5</td><td>Unsigned prediction errors from RL model</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis models learning from real-world romantic feedback (speed-dating) and examines prediction errors reflecting expectation violations about partner decisions, which is a social task and measures social processing (updating beliefs about others and self in a social context).</td></tr>
<tr><td>23599165_analysis_6</td><td>Partners who were given a yes &gt; those given a no</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast (partners given yes &gt; no) is from a speed-dating task where participants learn others&#x27; romantic decisions and update beliefs; this is clearly a social task and measures social processing (responses to social feedback, expectations, learning).</td></tr>
<tr><td>23599165_analysis_7</td><td>Partners who were given a no &gt; those given a yes</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is a speed-dating paradigm investigating responses to partners&#x27; acceptance vs rejection, clearly a social task probing perception, interpretation, and response to social information; the contrast measures social processing (responses to partner decisions).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23599165_1</td><td>Match &gt; Unrequited; socialcommunication</td><td>23599165_analysis_2</td><td>Match &gt; Unrequited</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23599165_2</td><td>Mismatched (Rejection + Unrequited) &gt; matched (Match + Disinterest); socialcommunication</td><td>23599165_analysis_4</td><td>Mismatched (Rejection + Unrequited) &gt; matched (Match + Disinterest)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23599165_3</td><td>Partners who were given a no &gt; those given a yes; socialcommunication</td><td>23599165_analysis_7</td><td>Partners who were given a no &gt; those given a yes</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23599165_4</td><td>Partners who were given a yes &gt; those given a no; socialcommunication</td><td>23599165_analysis_6</td><td>Partners who were given a yes &gt; those given a no</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23599165_5</td><td>Rejection &gt; Disinterest; socialcommunication</td><td>23599165_analysis_3</td><td>Rejection &gt; Disinterest</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23599165_6</td><td>Unsigned prediction errors from RL model; socialcommunication</td><td>23599165_analysis_5</td><td>Unsigned prediction errors from RL model</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23599165_7</td><td>Yes (Match + Unrequited) &gt; No (Rejection + Disinterest); socialcommunication</td><td>23599165_analysis_0</td><td>Yes (Match + Unrequited) &gt; No (Rejection + Disinterest)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23667619</strong> | Pred included: 4 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23667619/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23667619_analysis_0</td><td>CSL&gt;TIC</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The CSL&gt;TIC contrast compares complex social laughter (joy, taunt) to tickling laughter and probes connectivity related to processing social information and mentalizing; tasks include explicit social categorization. Satisfies both criteria.</td></tr>
<tr><td>23667619_analysis_1</td><td>TIC&gt;CSL</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast involves perception of social vocalizations (laughter) and the experiment included an explicit social task (laughter type categorization) and contrasts probing social content differences; thus it measures social processing.</td></tr>
<tr><td>23667619_analysis_2</td><td>CAT&gt;COU</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The CAT&gt;COU contrast directly compares explicit categorization of laughter types (explicit social evaluation) vs a non-social counting task, so it measures social processing and involves a social-related task.</td></tr>
<tr><td>23667619_analysis_3</td><td>HAP_CAT ∩ TAU_CAT ∩ TIC_CAT ∩ HAP_COU ∩ TAU_COU ∩ TIC_COU</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The tasks explicitly manipulate and measure processing of social information in laughter (laughter type categorization vs. bout counting) and contrasts (CSL vs TIC, CAT&gt;COU) probe social processing and mentalizing, satisfying both criteria.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23667619_1</td><td>CAT &gt; COU; socialcommunication</td><td>23667619_analysis_2</td><td>CAT&gt;COU</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23667619_2</td><td>CSL &gt; TIC; socialcommunication</td><td>23667619_analysis_0</td><td>CSL&gt;TIC</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23667619_3</td><td>TIC &gt; CSL; socialcommunication</td><td>23667619_analysis_1</td><td>TIC&gt;CSL</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23684882</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=3</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23684882/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> [(S-IMIO &gt; NS-IMIO) &gt; (S-CTO &gt; NS-CTO)] &gt; [(S-IMIE &gt; NS-IMIE) &gt; (S-CTE &gt; NS- CTE)]; socialcommunication, [(S-IMIO &gt; S-CTO) + (S-IMIE &gt; S-CTE)] &gt; [(NS-IMIO &gt; NS-CTO) + (NS-IMIE &gt; NS-CTE)]; socialcommunication, [S (IMIO + CTO + IMIE + CTE) &gt; NS (IMIO + CTO + IMIE + CTE)]; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23684882_analysis_0</td><td>(IMI_O &gt; CT_O) ∩ (IMI_E &gt; CT_E)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast tests imitation versus a control task involving observation and execution of gestures (including communicative/social gestures). It probes processes of perceiving, interpreting, and responding to socially relevant gestures, so it measures social processing.</td></tr>
<tr><td>23684882_analysis_1</td><td>(S-IMI_O &gt; NS-IMI_O) &gt; (S-CT_O &gt; NS-CT_O)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast tests social vs non-social gestures during imitation/observation, directly probing social processing and communicative intention.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23684882_1</td><td>(IMIO &gt; CTO) ∩ (IMIE &gt; CTE); socialcommunication</td><td>23684882_analysis_0</td><td>(IMI_O &gt; CT_O) ∩ (IMI_E &gt; CT_E)</td><td>0.931</td><td>0.950</td><td>0.944</td><td>accepted</td><td>high_coord_match</td></tr><tr><td>23684882_2</td><td>(S-IMIO&gt;NS-IMIO) &gt; (S-CTO &gt; NS-CTO); socialcommunication</td><td>23684882_analysis_1</td><td>(S-IMI_O &gt; NS-IMI_O) &gt; (S-CT_O &gt; NS-CT_O)</td><td>0.949</td><td>1.000</td><td>0.985</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23684882_3</td><td>[(S-IMIO &gt; NS-IMIO) &gt; (S-CTO &gt; NS-CTO)] &gt; [(S-IMIE &gt; NS-IMIE) &gt; (S-CTE &gt; NS- CTE)]; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>23684882_4</td><td>[(S-IMIO &gt; S-CTO) + (S-IMIE &gt; S-CTE)] &gt; [(NS-IMIO &gt; NS-CTO) + (NS-IMIE &gt; NS-CTE)]; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>23684882_5</td><td>[S (IMIO + CTO + IMIE + CTE) &gt; NS (IMIO + CTO + IMIE + CTE)]; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23722983</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23722983/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23722983_analysis_0</td><td>Intention effect</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is explicitly social (message communicators deciding whether to recommend ideas to others) and the intention effect models interns’ intentions to recommend — a social-processing measure involving evaluation in a social-communicative context.</td></tr>
<tr><td>23722983_analysis_1</td><td>Salesperson effect</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The salesperson effect measures social-influence processes (influencers encoding ideas to persuade others) and engages mentalizing/social cognition; it is a social task and measures social processing.</td></tr>
<tr><td>23722983_analysis_2</td><td>Buzz effect</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves social processes (message recommendation, influence) and the buzz effect measures neural activity related to social processing (mentalizing, reward tied to propagation).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23722983_1</td><td>Buzz effect; socialcommunication</td><td>23722983_analysis_2</td><td>Buzz effect</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23722983_2</td><td>Intention effect; socialcommunication</td><td>23722983_analysis_0</td><td>Intention effect</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23722983_3</td><td>Salesperson effect; socialcommunication</td><td>23722983_analysis_1</td><td>Salesperson effect</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23813661</strong> | Pred included: 5 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23813661/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23813661_analysis_0</td><td>Table I. Regions more responsive to meaningful than scrambled videos</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involved viewing and rating dyadic social interactions (naturalness of contingent/smooth vs mirrored/scrambled videos). The contrast compares meaningful (social) videos to scrambled baseline, directly measuring social processing.</td></tr>
<tr><td>23813661_analysis_1</td><td>1. Contingent &gt; Mirrored</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves viewing dyadic social interactions and rating naturalness; the contrast (contingent &gt; mirrored) directly measures social processing of interaction contingency and perception of others.</td></tr>
<tr><td>23813661_analysis_2</td><td>2. Mirrored &gt; Contingent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task explicitly involved observing dyadic social interactions and rating their naturalness; the contrast (mirrored &gt; contingent) probes processing of social contingency and thus social processing.</td></tr>
<tr><td>23813661_analysis_3</td><td>1. Rigid &gt; Smooth</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task involves perceiving and evaluating dyadic nonverbal social interactions; the contrast (rigid &gt; smooth) examines social processing of movement kinematics and related neural responses, meeting both I1 and I2.</td></tr>
<tr><td>23813661_analysis_4</td><td>2. Interaction: (Contingent &gt; Mirrored) &gt; (Smooth &gt; Rigid)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves viewing dyadic social interactions and contrasts (contingent vs mirrored; smooth vs rigid) that probe social perception and interpretation—measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23813661_1</td><td>(Contingent &gt; Mirrored) &gt; (Smooth &gt; Rigid); others</td><td>23813661_analysis_4</td><td>2. Interaction: (Contingent &gt; Mirrored) &gt; (Smooth &gt; Rigid)</td><td>0.840</td><td>1.000</td><td>0.952</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23813661_2</td><td>Contingent &gt; Mirrored; others</td><td>23813661_analysis_1</td><td>1. Contingent &gt; Mirrored</td><td>0.933</td><td>1.000</td><td>0.980</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23813661_3</td><td>Mirrored &gt; Contingent; others</td><td>23813661_analysis_2</td><td>2. Mirrored &gt; Contingent</td><td>0.933</td><td>1.000</td><td>0.980</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23813661_4</td><td>Rigid &gt; Smooth; others</td><td>23813661_analysis_3</td><td>1. Rigid &gt; Smooth</td><td>0.903</td><td>1.000</td><td>0.971</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23813661_5</td><td>meaningful videos &gt; scrambled videos; others</td><td>23813661_analysis_0</td><td>Table I. Regions more responsive to meaningful than scrambled videos</td><td>0.538</td><td>1.000</td><td>0.862</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24243619</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24243619/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24243619_analysis_0</td><td>Main effects of social judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrasts test explicit social trait judgments (trustworthiness and attractiveness) of other people from voices, so this is a social-processing task measuring social evaluation.</td></tr>
<tr><td>24243619_analysis_1</td><td>Overlapping effects during social and emotional judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis directly tests social trait judgments (trustworthiness, attractiveness) and comparisons with emotional and cognitive judgments, measuring social processing of others.</td></tr>
<tr><td>24243619_analysis_2</td><td>Overlapping effects during social and cognitive judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrasts examine explicit social trait judgments (trustworthiness, attractiveness) versus controls, directly measuring social evaluation processes; satisfies I1 (social-related task) and I2 (measures social processing).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24243619_1</td><td>[(TR−AG)∩(AT−AG)∩(HA−AG)]; socialcommunication</td><td>24243619_analysis_1</td><td>Overlapping effects during social and emotional judgments</td><td>0.291</td><td>1.000</td><td>0.787</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>24243619_2</td><td>[(TR−HA)∩(AT−HA)∩(AG−HA)]; socialcommunication</td><td>24243619_analysis_2</td><td>Overlapping effects during social and cognitive judgments</td><td>0.330</td><td>1.000</td><td>0.799</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>24243619_3</td><td>[(TR−HA)∩(AT−HA)∩(TR−AG)∩(AT−AG)]; socialcommunication</td><td>24243619_analysis_0</td><td>Main effects of social judgments</td><td>0.256</td><td>1.000</td><td>0.777</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24294841</strong> | Pred included: 8 | Manual included (accepted matches only): 7 | Correct overlaps: 7 | Match statuses: accepted=7, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24294841/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24294841_analysis_0</td><td>Main effect (ES + TS + SRS) - (EN + TN + SRN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task involves empathy, Theory of Mind, and self–other differentiation—core social processes. The contrast examines social conditions (sad vs neutral) across these tasks, so it measures social processing.</td></tr>
<tr><td>24294841_analysis_1</td><td>EmpathyES-EN</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task directly probes social cognition (empathy, Theory of Mind, self–other differentiation) across conditions and contrasts; it clearly measures social processing.</td></tr>
<tr><td>24294841_analysis_2</td><td>ToMTS-TN</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task explicitly manipulates empathy, Theory of Mind, and self–other differentiation (inferring others’ feelings, deciding what would make them feel better), which are core social processes. Meets both social-related task and measurement of social processing.</td></tr>
<tr><td>24294841_analysis_3</td><td>Self-referenceSRS-SRN</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task explicitly probes empathy, theory-of-mind, and self–other differentiation—core social processes. It directly measures social processing across conditions.</td></tr>
<tr><td>24294841_analysis_4</td><td>Empathy &gt; ToM(ES + EN)-(TS + TN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast compares empathy and ToM using tasks that require inferring others’ internal emotional/mental states — clearly a social processing task. It directly measures social processing (empathy/ToM).</td></tr>
<tr><td>24294841_analysis_5</td><td>ToM &gt; Empathy(TS + TN)-(ES + EN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task explicitly probes social processes (empathy and Theory of Mind) and the contrast ToM &gt; Empathy measures social cognitive processing of others’ internal states across emotional contexts.</td></tr>
<tr><td>24294841_analysis_6</td><td>Empathy &gt; Self-reference(ES + EN)-(SRS + SRN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task directly involves social cognition (empathy, ToM, self–other differentiation) and contrast measures social processing of others vs self.</td></tr>
<tr><td>24294841_analysis_7</td><td>Self-reference &gt; Empathy(SRS + SRN)-(ES + EN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task explicitly probes empathy, ToM and self-reference—core social processing (perception/understanding of others and self). Contrast measures social cognitive processes.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24294841_1</td><td>Empathy &gt; Self-reference; others</td><td>24294841_analysis_6</td><td>Empathy &gt; Self-reference(ES + EN)-(SRS + SRN)</td><td>0.727</td><td>1.000</td><td>0.918</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24294841_2</td><td>Empathy ES–EN; others</td><td>24294841_analysis_1</td><td>EmpathyES-EN</td><td>0.880</td><td>0.846</td><td>0.856</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>24294841_3</td><td>Main effect (ES + TS + SRS) – (EN + TN + SRN); others</td><td>24294841_analysis_0</td><td>Main effect (ES + TS + SRS) - (EN + TN + SRN)</td><td>0.978</td><td>1.000</td><td>0.993</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24294841_4</td><td>Self-reference &gt;  Empathy; self</td><td>24294841_analysis_7</td><td>Self-reference &gt; Empathy(SRS + SRN)-(ES + EN)</td><td>0.720</td><td>1.000</td><td>0.916</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24294841_5</td><td>Self-reference SRS–SRN; self</td><td>24294841_analysis_3</td><td>Self-referenceSRS-SRN</td><td>0.930</td><td>1.000</td><td>0.979</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24294841_6</td><td>ToM &gt; Empathy; others</td><td>24294841_analysis_5</td><td>ToM &gt; Empathy(TS + TN)-(ES + EN)</td><td>0.642</td><td>1.000</td><td>0.892</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24294841_7</td><td>ToM TS–TN; others</td><td>24294841_analysis_2</td><td>ToMTS-TN</td><td>0.824</td><td>1.000</td><td>0.947</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24294906</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24294906/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24294906_analysis_0</td><td>Main effect of social value orientation on decision-making</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task is a social dilemma (Prisoner’s Dilemma) probing cooperation, trust, and mentalizing; contrasts directly measure social processing (differences in social value orientation and associated social-cognitive activations).</td></tr>
<tr><td>24294906_analysis_1</td><td>Interaction effect between dispositional trust and social value orientation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis uses a social task (one-shot Prisoner’s Dilemma) and explicitly examines neural processes of social cognition/mentalizing (inferring others’ intentions, trust), satisfying both I1 and I2.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24294906_1</td><td>Interaction effect between dispositional trust and social value orientation; others</td><td>24294906_analysis_1</td><td>Interaction effect between dispositional trust and social value orientation</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24294906_2</td><td>Main effect of social value orientation on decision-making; others</td><td>24294906_analysis_0</td><td>Main effect of social value orientation on decision-making</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24414614</strong> | Pred included: 7 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24414614/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24414614_analysis_0</td><td>Imitating</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task is a live reciprocal imitation social-interaction and contrasts (imitating/being imitated vs observation) directly probe social processing and interaction/understanding of others; PPI examines connectivity changes due to social context.</td></tr>
<tr><td>24414614_analysis_1</td><td>Being imitated</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is a live social interaction (reciprocal imitation/being imitated) requiring understanding and anticipating another’s intentions; the contrast explicitly measures social processing (connectivity modulation during being imitated).</td></tr>
<tr><td>24414614_analysis_2</td><td>Observation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task is an online reciprocal imitation social interaction and the analysis (GLM and PPI) explicitly assesses social processing (interaction, understanding others’ intentions, mirror–mentalizing system coupling).</td></tr>
<tr><td>24414614_analysis_3</td><td>Imitating-IFG</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task is an online reciprocal imitation social interaction probing understanding of others’ actions and intentions; contrasts and PPI specifically assess social processing (imitating, being imitated vs observation).</td></tr>
<tr><td>24414614_analysis_4</td><td>Being imitated-IFG</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves live reciprocal imitation and online social interaction; contrasts (being imitated vs observation) and PPI assess social processing and interaction-related neural responses.</td></tr>
<tr><td>24414614_analysis_5</td><td>Imitating-IPL*</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Study uses live dyadic imitation and PPI contrasts (imitating vs observation; being imitated vs observation) probing social interaction, action understanding, and mentalizing—clearly a social processing task.</td></tr>
<tr><td>24414614_analysis_6</td><td>Being imitated-IPL</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves live social interaction (reciprocal imitation, role switching) and the contrast (being imitated vs observation) measures social processing (perception/anticipation of others&#x27; actions and intentions).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24414614_1</td><td>being imitated &gt; rest; socialcommunication</td><td>24414614_analysis_1</td><td>Being imitated</td><td>0.800</td><td>1.000</td><td>0.940</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24414614_2</td><td>imitating &gt; rest; socialcommunication</td><td>24414614_analysis_0</td><td>Imitating</td><td>0.720</td><td>1.000</td><td>0.916</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24414614_3</td><td>observation &gt; rest; socialcommunication</td><td>24414614_analysis_2</td><td>Observation</td><td>0.759</td><td>1.000</td><td>0.928</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24462962</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24462962/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24462962_analysis_0</td><td>Significant clusters of activation in houses and faces fMRI task.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The faces vs houses fMRI task and associated analyses probe face perception and social-cognitive traits (EQ, SRS) predicting fusiform activation — a social processing measure.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24462962_1</td><td>house + faces; socialcommunication</td><td>24462962_analysis_0</td><td>Significant clusters of activation in houses and faces fMRI task.</td><td>0.308</td><td>1.000</td><td>0.792</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24583253</strong> | Pred included: 5 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24583253/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24583253_analysis_0</td><td>Decrease in activity with the increase in group size</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves observing social situations (bystander presence) and measures neural responses to social context (group size) — meets social processing criteria.</td></tr>
<tr><td>24583253_analysis_1</td><td>Increase in activity with the increase in group size</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task uses social stimuli (emergency scenes with varying numbers of bystanders) and examines neural responses to social context (bystander group size). This meets I1 (social-related task) and I2 (measures social processing).</td></tr>
<tr><td>24583253_analysis_2</td><td>Control &gt; bystander.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task involves observing an emergency and varying number of bystanders; the contrast compares social (bystander) versus control, so it assesses social processing of others and group influence on helping-related perception/action preparation.</td></tr>
<tr><td>24583253_analysis_3</td><td>Falling &gt; standing</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast (falling &gt; standing) and the study manipulate bystander presence and measure neural responses to witnessing an emergency—clearly a social task probing perception/response to others; meets both I1 and I2.</td></tr>
<tr><td>24583253_analysis_4</td><td>Standing &gt; falling</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast manipulates social context (number of bystanders) and measures neural responses to witnessing an emergency, which is social processing of others and group influence on action preparation.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24583253_1</td><td>control &gt; bystander; others</td><td>24583253_analysis_2</td><td>Control &gt; bystander.</td><td>0.974</td><td>1.000</td><td>0.992</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24583253_2</td><td>falling &gt; standing; others</td><td>24583253_analysis_3</td><td>Falling &gt; standing</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24583253_3</td><td>standing &gt;  falling; others</td><td>24583253_analysis_4</td><td>Standing &gt; falling</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24726338</strong> | Pred included: 6 | Manual included (accepted matches only): 6 | Correct overlaps: 6 | Match statuses: accepted=6, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24726338/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24726338_analysis_0</td><td>Self &gt; other</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task involves social contexts (intergroup competition, self vs other moral judgments) and indexes social processing (self-referential processing in mPFC in social context).</td></tr>
<tr><td>24726338_analysis_1</td><td>Other &gt; self</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task contrasts self- vs other-referential moral statements during intergroup competition, a prototypical social-processing paradigm (self/other, group membership, competition). It directly measures social processing (self-reference and intergroup context).</td></tr>
<tr><td>24726338_analysis_2</td><td>Communication &gt; moral (collapsing across self/other)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is explicitly social (intergroup competition, self/other moral statements) and the contrast indexes social processing related to self- and other-relevant moral and communication stimuli.</td></tr>
<tr><td>24726338_analysis_3</td><td>Moral &gt; communication (collapsing across self/other)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task and contrast involve processing of socially-relevant stimuli (moral vs communication statements presented in a social competitive context) and index self/other social processing; thus it measures social processing.</td></tr>
<tr><td>24726338_analysis_4</td><td>Self &gt; other (collapsing across moral/communication)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast (Self &gt; Other) was derived from a competitive social task manipulating group vs alone and compares self-referential versus other-referential processing in social contexts (mPFC response to self vs other). This satisfies that a social-related task was performed and that the analysis measures social processing.</td></tr>
<tr><td>24726338_analysis_5</td><td>Other &gt; self (collapsing across moral/communication)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves social interaction (group vs alone competition), self/other processing, and measures social processing (mPFC response to self vs other moral/communication statements).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24726338_1</td><td>Communication &gt; moral (collapsing across self/other); others</td><td>24726338_analysis_2</td><td>Communication &gt; moral (collapsing across self/other)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24726338_2</td><td>Moral &gt; communication (collapsing across self/other); others</td><td>24726338_analysis_3</td><td>Moral &gt; communication (collapsing across self/other)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24726338_3</td><td>Other &gt; Self; others</td><td>24726338_analysis_1</td><td>Other &gt; self</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24726338_4</td><td>Other &gt; self (collapsing across moral/communication); others</td><td>24726338_analysis_5</td><td>Other &gt; self (collapsing across moral/communication)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24726338_5</td><td>Self &gt; other; self</td><td>24726338_analysis_0</td><td>Self &gt; other</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24726338_6</td><td>Self &gt; other (collapsing across moral/communication); self</td><td>24726338_analysis_4</td><td>Self &gt; other (collapsing across moral/communication)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24772075</strong> | Pred included: 7 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24772075/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24772075_analysis_0</td><td>MAIN EFFECT: FEEDBACK ONSET: SELF &gt; OTHER</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis uses a social feedback task (self vs other feedback) examining processing of social information (conformity, positivity bias, self-related neural activity), meeting both criteria.</td></tr>
<tr><td>24772075_analysis_1</td><td>MAIN EFFECT: FEEDBACK ONSET: OTHER &gt; SELF</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves receiving and processing social feedback about self and others, measuring social conformity, positivity bias, and self/other processing—meets both criteria.</td></tr>
<tr><td>24772075_analysis_2</td><td>INTERACTION: FEEDBACK ONSET: (SELF &gt; OTHER) × (GERMAN &gt; CHINESE)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves receiving and processing social feedback about self and others during a face-to-face interaction—direct measure of social processing and self/other social cognition.</td></tr>
<tr><td>24772075_analysis_3</td><td>WHOLE-BRAIN CORRELATION WITH OVERALL RELATIVE ABSOLUTE MEAN UPDATES IN THE CONTRAST FEEDBACK ONSET: SELF &gt; OTHER</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis tests neural correlates of receiving social feedback and updates to self/other trait ratings in a real-life social interaction task, directly measuring social processing.</td></tr>
<tr><td>24772075_analysis_4</td><td>FEEDBACK RATING (TRIAL-BY-TRIAL CORRELATION): SELF &gt; OTHER</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves receiving, interpreting, and updating self- and other-related social feedback (social interaction, conformity, positivity bias)—direct measure of social processing.</td></tr>
<tr><td>24772075_analysis_5</td><td>FEEDBACK DISCREPANCIES (POSITIVE TRIAL-BY-TRIAL CORRELATION): SELF AND OTHER</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task involves receiving and integrating social feedback in a face-to-face interaction, assessing conformity and positivity biases, and measuring self- and other-related processing—clearly a social processing task.</td></tr>
<tr><td>24772075_analysis_6</td><td>FEEDBACK DISCREPANCIES (NEGATIVE TRIAL-BY-TRIAL CORRELATION): SELF AND OTHER</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves receiving social feedback about self and others, measuring social conformity, positivity biases, and self/other processing — directly assesses social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24772075_1</td><td>(SELF &gt; OTHER) × (GERMAN &gt; CHINESE); self</td><td>24772075_analysis_2</td><td>INTERACTION: FEEDBACK ONSET: (SELF &gt; OTHER) × (GERMAN &gt; CHINESE)</td><td>0.707</td><td>1.000</td><td>0.912</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24772075_2</td><td>OTHER &gt; SELF; others</td><td>24772075_analysis_1</td><td>MAIN EFFECT: FEEDBACK ONSET: OTHER &gt; SELF</td><td>0.453</td><td>1.000</td><td>0.836</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>24772075_3</td><td>SELF &gt; OTHER; self</td><td>24772075_analysis_0</td><td>MAIN EFFECT: FEEDBACK ONSET: SELF &gt; OTHER</td><td>0.453</td><td>1.000</td><td>0.836</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>24772075_4</td><td>SELF &gt; OTHER (CORRELATION); self</td><td>24772075_analysis_3</td><td>WHOLE-BRAIN CORRELATION WITH OVERALL RELATIVE ABSOLUTE MEAN UPDATES IN THE CONTRAST FEEDBACK ONSET: SELF &gt; OTHER</td><td>0.174</td><td>1.000</td><td>0.752</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24814646</strong> | Pred included: 5 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=2, unmatched=6</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24814646/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> A&amp;B; socialcommunication, p2&gt;n2; socialcommunication, D&amp;E; socialcommunication, a1&gt; n1; socialcommunication, a2&gt; n2; socialcommunication, p1&gt; n1; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24814646_analysis_0</td><td>fMRI contrasts on the basis of the neutral condition as baseline</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task presents first-person social interaction video-clips (reactive–aggressive, social-positive, neutral) and contrasts affective vs neutral interactions; clearly measures social processing (perception and response to social cues).</td></tr>
<tr><td>24814646_analysis_1</td><td>Initial phase of video-clip: A</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The task consists of viewing realistic first-person social interactions (reactive–aggressive, social-positive, neutral) and participants were instructed to empathize/engage, so it clearly measures social processing across perception and response to social cues. It satisfies I1 and I2.</td></tr>
<tr><td>24814646_analysis_2</td><td>Initial phase of video-clip: B</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task involves viewing first-person social interaction videos and requires empathic involvement and evaluation of social scenarios; contrasts test social processing (reactive-aggressive, social-positive, neutral).</td></tr>
<tr><td>24814646_analysis_3</td><td>Final phase of video-clip: C</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task presents realistic social interaction scenarios (reactive-aggressive, social-positive, neutral) from a first-person perspective and contrasts affective social conditions vs neutral; clearly measures social processing.</td></tr>
<tr><td>24814646_analysis_4</td><td>Final phase of video-clip: D</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task presents 90 first-person social interaction video-clips (reactive-aggressive, social-positive, neutral) with participants instructed to put themselves into the scenarios; fMRI contrasts probe processing of social interactions and affective responses. Satisfies I1 (social-related task) and I2 (measures social processing).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24814646_1</td><td>A&amp;B; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>24814646_10</td><td>p2&gt;n2; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>24814646_2</td><td>D&amp;E; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>24814646_3</td><td>a1&gt; n1; socialcommunication</td><td>24814646_analysis_0</td><td>fMRI contrasts on the basis of the neutral condition as baseline</td><td>0.304</td><td>0.276</td><td>0.285</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>24814646_4</td><td>a1&gt;p1; socialcommunication</td><td>24814646_analysis_1</td><td>Initial phase of video-clip: A</td><td>0.207</td><td>0.952</td><td>0.729</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>24814646_5</td><td>a2&gt; n2; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>24814646_6</td><td>a2&gt;p2; socialcommunication</td><td>24814646_analysis_3</td><td>Final phase of video-clip: C</td><td>0.286</td><td>1.000</td><td>0.786</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>24814646_7</td><td>p1&gt; n1; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>24814646_8</td><td>p1&gt;a1; socialcommunication</td><td>24814646_analysis_2</td><td>Initial phase of video-clip: B</td><td>0.172</td><td>0.938</td><td>0.708</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>24814646_9</td><td>p2&gt;a2; socialcommunication</td><td>24814646_analysis_4</td><td>Final phase of video-clip: D</td><td>0.179</td><td>1.000</td><td>0.754</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24824165</strong> | Pred included: 2 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24824165/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24824165_analysis_0</td><td>Table 1. Clusters of activation for (atypical-upright+atypical-inverted)-(typical-upright+typical-inverted) assessed by using all data</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast directly compares atypical (incongruent) vs typical social interactions using point-light displays while participants viewed dyadic social interactions; this measures social processing of others&#x27; interactions.</td></tr>
<tr><td>24824165_analysis_1</td><td>Table 2. Clusters of activation for (atypical-upright+atypical-inverted)-(typical-upright+typical-inverted) assessed by using two separate subsets of data</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involved viewing and discriminating typical vs atypical social interactions (point-light dyads); the contrast directly measures social processing (responses to social congruency/incongruency).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24824165_1</td><td>(atypical-upright 1 atypical-inverted) 2 (typical-upright 1 typical-inverted); others</td><td>24824165_analysis_1</td><td>Table 2. Clusters of activation for (atypical-upright+atypical-inverted)-(typical-upright+typical-inverted) assessed by using two separate subsets of data</td><td>0.594</td><td>1.000</td><td>0.878</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24825504</strong> | Pred included: 4 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24825504/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24825504_analysis_0</td><td>Brain areas activated in the conjunction triad ∩ self ∩ other.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Tasks directly probe social cognition (triadic interaction, self-referential and other-referential trials) and the conjunction identifies core mentalizing regions—thus measures social processing.</td></tr>
<tr><td>24825504_analysis_1</td><td>Triad &gt; (Self &amp; Other)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The triad task explicitly involves imagining a social interaction (self + another + object) and contrasts triadic with self/other processing, thus measuring social processing.</td></tr>
<tr><td>24825504_analysis_2</td><td>Self &gt; (Other &amp; Triad)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task set (self, other, triad) is explicitly social and the contrast isolates self-referential social processing, satisfying that the analysis measures social processing.</td></tr>
<tr><td>24825504_analysis_3</td><td>Other &gt; (Self &amp; Triad)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast Other &gt; (Self &amp; Triad) tests other-referential social cognition (judging whether an object is self-relevant to another person), which is a social processing task involving perception/understanding of others.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24825504_1</td><td>Other &gt; (self &amp; triad); others</td><td>24825504_analysis_3</td><td>Other &gt; (Self &amp; Triad)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24825504_2</td><td>Self &gt; (other &amp; triad); self</td><td>24825504_analysis_2</td><td>Self &gt; (Other &amp; Triad)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24825504_3</td><td>Triad &gt; (self &amp; other); others</td><td>24825504_analysis_1</td><td>Triad &gt; (Self &amp; Other)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24825504_4</td><td>triad ∩ self ∩ other; others</td><td>24825504_analysis_0</td><td>Brain areas activated in the conjunction triad ∩ self ∩ other.</td><td>0.488</td><td>1.000</td><td>0.846</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24834034</strong> | Pred included: 5 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24834034/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24834034_analysis_0</td><td>FAIR &gt; UNFAIR</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Ultimatum Game is an explicitly social task manipulating human vs computer proposers and fairness; the FAIR &gt; UNFAIR contrast measures social norm/fairness processing and responses to social offers, satisfying both I1 (social task) and I2 (measures Social Processing).</td></tr>
<tr><td>24834034_analysis_1</td><td>FAIR &lt; UNFAIR</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>This analysis uses an ultimatum game with human vs computer proposers and contrasts fair vs unfair offers; it is a social-interaction task and the contrast measures social processing (fairness/norm enforcement).</td></tr>
<tr><td>24834034_analysis_2</td><td>HUMAN &gt; COMPUTER</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares human vs computer proposers in an ultimatum game, isolating social interaction context and thus measuring social processing related to interpersonal interaction and social norm enforcement.</td></tr>
<tr><td>24834034_analysis_3</td><td>HIGH(UNFAIR–FAIR) &gt; LOW(UNFAIR–FAIR)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Ultimatum Game is a social interaction task (human vs computer) probing fairness-related social decision-making; the contrast directly measures social processing (modulation of fairness by monetary incentives in social context).</td></tr>
<tr><td>24834034_analysis_4</td><td>HIGH(UNFAIR–FAIR) &gt; LOW(UNFAIR–FAIR) WITHIN HUMAN</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast tests fairness decisions in the human proposer condition (ultimatum game) and examines modulation of social-norm-related behavior by monetary incentives. This is a social task and the contrast measures social processing (fairness in social interaction).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24834034_1</td><td>FAIR &lt; UNFAIR; self</td><td>24834034_analysis_1</td><td>FAIR &lt; UNFAIR</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24834034_2</td><td>FAIR &gt; UNFAIR; self</td><td>24834034_analysis_0</td><td>FAIR &gt; UNFAIR</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24834034_3</td><td>HIGH(UNFAIR–FAIR) &gt; LOW(UNFAIR–FAIR); self</td><td>24834034_analysis_3</td><td>HIGH(UNFAIR–FAIR) &gt; LOW(UNFAIR–FAIR)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24834034_4</td><td>HIGH(UNFAIR–FAIR) &gt; LOW(UNFAIR–FAIR) WITHIN HUMAN; self</td><td>24834034_analysis_4</td><td>HIGH(UNFAIR–FAIR) &gt; LOW(UNFAIR–FAIR) WITHIN HUMAN</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24834034_5</td><td>HUMAN &gt; COMPUTER; self</td><td>24834034_analysis_2</td><td>HUMAN &gt; COMPUTER</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24842782</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24842782/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24842782_analysis_0</td><td>Angry &gt;neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task is an interactive social paradigm (Taylor Aggression Paradigm) and the contrast (angry &gt; neutral) measures processing of social cues (angry facial expressions), satisfying both social-task and measurement criteria.</td></tr>
<tr><td>24842782_analysis_1</td><td>Angry &gt;neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is a social interaction (Taylor Aggression Paradigm) involving opponent videos; the angry&gt;neutral contrast directly measures neural processing of social signals (angry facial expressions). Meets I1 (social-related task) and I2 (measures social processing).</td></tr>
<tr><td>24842782_analysis_2</td><td>Parametric modulation angry &gt;neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task is an interactive social task (Taylor Aggression Paradigm) using videos of an opponent; the contrast (angry &gt; neutral, parametric modulation by punishment selections) measures neural processing of social cues and responses, satisfying social-processing criteria.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24842782_1</td><td>Decision phase: Angry &gt; neutral; socialcommunication</td><td>24842782_analysis_1</td><td>Angry &gt;neutral</td><td>0.652</td><td>1.000</td><td>0.896</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24842782_2</td><td>Decision phase: Parametric modulation angry &gt; neutral; socialcommunication</td><td>24842782_analysis_2</td><td>Parametric modulation angry &gt;neutral</td><td>0.822</td><td>1.000</td><td>0.947</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24842782_3</td><td>Outcome phase: Angry &gt; neutral; socialcommunication</td><td>24842782_analysis_0</td><td>Angry &gt;neutral</td><td>0.667</td><td>1.000</td><td>0.900</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24936688</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24936688/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24936688_analysis_0</td><td>Status Type by Status Level interaction</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is explicit impression formation and evaluation of others varying in moral and financial status (social status), and the analyzed interaction examines VMPFC responses to social information about others — this directly measures social processing.</td></tr>
<tr><td>24936688_analysis_1</td><td>Status Type main effect</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is impression formation of others varying in social status (financial and moral). This is a social-related task measuring perception and evaluation of others; the analysis examines VMPFC responses to social status, so it measures social processing.</td></tr>
<tr><td>24936688_analysis_2</td><td>Status Level main effect</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves impression formation of others based on social-status cues (financial and moral), directly measuring social perception and evaluation. Meets I1 (social-related task) and I2 (measures social processing).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24936688_1</td><td>Status Level &gt; baseline; socialcommunication</td><td>24936688_analysis_2</td><td>Status Level main effect</td><td>0.723</td><td>1.000</td><td>0.917</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24936688_2</td><td>Status Type &gt; baseline; socialcommunication</td><td>24936688_analysis_1</td><td>Status Type main effect</td><td>0.711</td><td>1.000</td><td>0.913</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>24936688_3</td><td>Status Type x Status Level &gt; baseline; socialcommunication</td><td>24936688_analysis_0</td><td>Status Type by Status Level interaction</td><td>0.763</td><td>1.000</td><td>0.929</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25118071</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25118071/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25118071_analysis_0</td><td>CV&gt;NV contrast</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares campaign (emotionally and socially rich) vs neutral videos and specifically targets empathy and socio-cognitive processing (STS activation and correlations with empathic expression). This satisfies both: a social-related task and measurement of social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25118071_1</td><td>CV &gt; NV; others</td><td>25118071_analysis_0</td><td>CV&gt;NV contrast</td><td>0.774</td><td>1.000</td><td>0.932</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25281889</strong> | Pred included: 12 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25281889/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25281889_analysis_0</td><td>HA&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves labeling briefly presented emotional facial expressions (happy&gt;neutral contrast) which is a social task measuring perception/interpretation of others’ emotions; thus satisfies social processing.</td></tr>
<tr><td>25281889_analysis_1</td><td>AN&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task requires labeling brief emotional facial expressions of others, which is social processing (perception/interpretation of others&#x27; emotions).</td></tr>
<tr><td>25281889_analysis_2</td><td>FE&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task requires labeling briefly presented emotional facial expressions—clearly social processing (perception and understanding of others&#x27; emotions). Contrast FE&gt;NE measures social processing of facial emotions.</td></tr>
<tr><td>25281889_analysis_3</td><td>HA&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast probes labeling of emotional facial expressions (happy&gt;neutral) — a social task assessing perception/interpretation of others&#x27; emotions, thus meets social processing criteria.</td></tr>
<tr><td>25281889_analysis_4</td><td>AN&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task required participants to label emotional facial expressions (perception and interpretation of others&#x27; emotions), which is social processing. The analysis examines brain responses to emotional faces and correlations with alexithymia, directly measuring social processing.</td></tr>
<tr><td>25281889_analysis_5</td><td>FE&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task requires labeling emotional facial expressions and assesses ability to perceive and interpret others&#x27; emotions (alexithymia correlations), meeting social processing criteria.</td></tr>
<tr><td>25281889_analysis_6</td><td>HA&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task requires labeling briefly presented emotional facial expressions — a social task involving perception and interpretation of others&#x27; emotions; contrast HA&gt;NE measures social processing of facial emotion.</td></tr>
<tr><td>25281889_analysis_7</td><td>AN&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task required labeling briefly presented emotional facial expressions (perception and interpretation of others&#x27; emotions), which is a social processing task. The AN&gt;NE (angry&gt;neutral) contrast measures social/emotional processing of faces.</td></tr>
<tr><td>25281889_analysis_8</td><td>FE&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task requires participants to label brief emotional facial expressions of others, which is a social task assessing perception and interpretation of others&#x27; emotions; thus it measures social processing.</td></tr>
<tr><td>25281889_analysis_9</td><td>HA&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves labeling emotional facial expressions (happy vs neutral), which is a social-related task measuring social processing (perception of others&#x27; emotions).</td></tr>
<tr><td>25281889_analysis_10</td><td>AN&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast AN&gt;NE comes from a facial emotion labeling task—explicitly measuring perception and labeling of others’ emotions—so it is a social processing task. Satisfies I1 (social-related task) and I2 (measures Social Processing).</td></tr>
<tr><td>25281889_analysis_11</td><td>FE&gt;NE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task requires labeling emotional facial expressions of other people (perception/interpretation of others’ emotions), which is a social processing task; contrast FE&gt;NE measures social processing of fearful versus neutral faces.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25281889_1</td><td>AN &gt; NE; socialcommunication</td><td>25281889_analysis_1</td><td>AN&gt;NE</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25281889_2</td><td>FE &gt; NE; socialcommunication</td><td>25281889_analysis_2</td><td>FE&gt;NE</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25281889_3</td><td>HA &gt; NE; socialcommunication</td><td>25281889_analysis_0</td><td>HA&gt;NE</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25315788</strong> | Pred included: 3 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25315788/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25315788_analysis_0</td><td>A. Univariate analysis: friend minus pc</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task contrasts messages believed to be from a friend vs a computer and probes mentalizing/ social processing (dmPFC, precuneus, TPJ). This directly measures social processing.</td></tr>
<tr><td>25315788_analysis_1</td><td>B. Searchlight-based MVPA: happy versus sad</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task involves processing text messages attributed to a friend versus a computer and the study probes social gating and mentalizing; the analysis examines encoding of socially relevant message content within a social context, satisfying both I1 and I2.</td></tr>
<tr><td>25315788_analysis_2</td><td>C. Searchlight-based MVCA: friend minus pc</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast compares processing of messages from a friend versus a computer and examines social-context-dependent changes in neural processing (mentalizing network), so it is a social-related task and measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25315788_1</td><td>univariate analysis: friend minus pc; others</td><td>25315788_analysis_0</td><td>A. Univariate analysis: friend minus pc</td><td>0.960</td><td>1.000</td><td>0.988</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25640962</strong> | Pred included: 5 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25640962/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> (IC &gt; NG ∩ ego &gt; allo) (conjunction analysis); socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25640962_analysis_0</td><td>IC&gt;NG</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is explicitly social (participants judged whether they felt addressed) and the IC&gt;NG contrast measures processing of social cues (gesture presence), satisfying both I1 and I2.</td></tr>
<tr><td>25640962_analysis_1</td><td>ego&gt;allo</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task explicitly assesses social addressment (feeling addressed) based on body orientation and gestures—measures social processing and social cognition.</td></tr>
<tr><td>25640962_analysis_2</td><td>allo&gt;ego</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task explicitly measures feeling addressed and social engagement; the contrast (allo vs ego, gesture presence) probes social processing and self-involvement/mentalizing.</td></tr>
<tr><td>25640962_analysis_3</td><td>(IC-ego&gt;IC-allo)&gt;(NG-ego&gt;NG-allo)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task required participants to judge whether they felt addressed by communicative stimuli (video clips with actor orientation and gestures). This is a social-related task measuring social processing and self-involvement/mentalizing. The interaction contrast probes how social cues (gesture × orientation) modulate this processing.</td></tr>
<tr><td>25640962_analysis_4</td><td>(IC-allo&gt;NG-allo)&gt;(IC-ego&gt;NG-ego)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task explicitly assesses social processing (feeling addressed) and the contrast tests social cues (gesture × orientation) affecting social perception.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25640962_1</td><td>(IC &gt; NG ∩ ego &gt; allo) (conjunction analysis); socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>25640962_2</td><td>(IC-allo&gt;NG-allo)&gt;(IC-ego&gt;NG-ego); socialcommunication</td><td>25640962_analysis_4</td><td>(IC-allo&gt;NG-allo)&gt;(IC-ego&gt;NG-ego)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25640962_3</td><td>(IC-ego&gt;IC-allo)&gt; (NG-ego&gt;NG-allo); socialcommunication</td><td>25640962_analysis_3</td><td>(IC-ego&gt;IC-allo)&gt;(NG-ego&gt;NG-allo)</td><td>1.000</td><td>0.800</td><td>0.860</td><td>accepted</td><td>high_coord_match</td></tr><tr><td>25640962_4</td><td>IC &gt; NG; socialcommunication</td><td>25640962_analysis_0</td><td>IC&gt;NG</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25640962_5</td><td>allo &gt; ego; socialcommunication</td><td>25640962_analysis_2</td><td>allo&gt;ego</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25640962_6</td><td>ego &gt; allo; socialcommunication</td><td>25640962_analysis_1</td><td>ego&gt;allo</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25697049</strong> | Pred included: 7 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25697049/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25697049_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The study uses person-dyad stimuli and identifies face/body-selective ROIs via a localizer; the analysis pertains to person perception and the neural processing of social interactions, satisfying both: (I1) a social-related task and (I2) measurement of social processing.</td></tr>
<tr><td>25697049_analysis_1</td><td>Congruent Interactions &gt; Incongruent Interactions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves viewing and judging person dyads and contrasts probe effects of social interaction congruency — directly measuring social processing of others and interactions.</td></tr>
<tr><td>25697049_analysis_2</td><td>Incongruent Interactions &gt; Congruent Interactions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares incongruent vs congruent person interactions (dyads) and examines neural processing tied to social meaningfulness; although the overt task was sex categorization, the stimuli and the contrast probe social processing. Both I1 (social-related task) and I2 (measures social processing) are satisfied.</td></tr>
<tr><td>25697049_analysis_3</td><td>Congruent Interactions &gt; Non-Interactions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Contrast compares meaningful social interactions (congruent interactions) versus non-interactions using person dyads; this directly probes social processing of others in scenes (stimuli and semantic ratings).</td></tr>
<tr><td>25697049_analysis_4</td><td>Non-Interactions &gt; Congruent Interactions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast compares types of person dyads (non-interactions vs congruent interactions) and the task and stimuli probe perception of social interactions/meaningfulness—this directly measures social processing.</td></tr>
<tr><td>25697049_analysis_5</td><td>Incongruent Interactions &gt; Non-Interactions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast (Incongruent Interactions &gt; Non-Interactions) probes perception and interpretation of social interactions between people (dyads) during a social task (sex-categorization of interacting people), so it meets both I1 and I2.</td></tr>
<tr><td>25697049_analysis_6</td><td>Non-Interactions &gt; Incongruent Interactions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Contrast compares types of person dyads (non-interactions vs incongruent interactions) during a social perception task; it directly measures social processing of interactions.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25697049_1</td><td>Incongruent Interactions &gt; Congruent Interactions; others</td><td>25697049_analysis_2</td><td>Incongruent Interactions &gt; Congruent Interactions</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25697049_2</td><td>Incongruent Interactions &gt; Non-Interactions; others</td><td>25697049_analysis_5</td><td>Incongruent Interactions &gt; Non-Interactions</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25716010</strong> | Pred included: 11 | Manual included (accepted matches only): 10 | Correct overlaps: 10 | Match statuses: accepted=10, uncertain=1, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25716010/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25716010_analysis_0</td><td>A. Fear&gt;happy+neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves viewing emotional crowds and assessing social interactions/dynamics; the contrast (fear&gt;happy+neutral) indexes social-emotional perception of others, satisfying both social-related task and measurement of social processing.</td></tr>
<tr><td>25716010_analysis_1</td><td>B. Fear+happy&gt;neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares interactive vs individual emotional crowds and perception of group emotion—a social task measuring perception and interpretation of social interactions (meets I1 and I2).</td></tr>
<tr><td>25716010_analysis_2</td><td>C. Fear+neutral&gt;happy</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast involves viewing crowds and the dynamics between people (interactive vs individual) and assesses perception of others&#x27; emotions and social interactions—this is a social-related task and measures social processing.</td></tr>
<tr><td>25716010_analysis_3</td><td>D. Happy&gt;fear+neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares emotional expressions (happy vs fear+neutral) in dynamic crowds—a social task probing perception and interpretation of others&#x27; emotions and interactions, so it satisfies both social-related task (I1) and measurement of social processing (I2).</td></tr>
<tr><td>25716010_analysis_4</td><td>E. Neutral&gt;fear+happy</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves perception of emotions and interactions in crowds—a social-related task measuring social processing of others&#x27; emotions and interactions.</td></tr>
<tr><td>25716010_analysis_5</td><td>Main effect of dynamics.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task explicitly involves perceiving and interpreting social interactions in crowds (interactive vs individual dynamics) and measures social processing of others&#x27; emotions and interactions.</td></tr>
<tr><td>25716010_analysis_6</td><td>A. Interactive fear&gt;individual fear</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves perceiving emotions and interactions in crowds (interactive vs individual), which is a social-related task measuring social processing of others’ emotions and interactions.</td></tr>
<tr><td>25716010_analysis_7</td><td>B. Interactive fear&gt;individual fear+interactive happy&gt;individual happy</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares interactive vs individual emotional crowds and assesses perception and interpretation of social interactions and group emotion—clearly a social processing task.</td></tr>
<tr><td>25716010_analysis_8</td><td>C. Interactive fear&gt;individual fear+interactive neutral&gt;individual neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast explicitly tests perception of group social interactions and emotional crowd perception (interactive vs individual dynamics) — a social processing task. Satisfies I1 (social-related task) and I2 (measures social processing).</td></tr>
<tr><td>25716010_analysis_9</td><td>D. Interactive fear&gt;individual fear+individual neutral&gt;interactive neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares interactive vs individual group emotional displays, which is a social task assessing perception and interpretation of others’ interactions and emotions (measures social processing).</td></tr>
<tr><td>25716010_analysis_10</td><td>E. Interactive neutral&gt;individual neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares interactive versus individual crowds, a social perception task assessing dynamics between people and group-level social processing (perception of others/interactions). Meets I1 (social-related task) and I2 (measures social processing).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25716010_1</td><td>Fear +  happy &gt; neutral; socialcommunication</td><td>25716010_analysis_1</td><td>B. Fear+happy&gt;neutral</td><td>0.889</td><td>1.000</td><td>0.967</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25716010_10</td><td>Neutral &gt; fear +  happy; socialcommunication</td><td>25716010_analysis_4</td><td>E. Neutral&gt;fear+happy</td><td>0.889</td><td>1.000</td><td>0.967</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25716010_11</td><td>interactive &gt; individual; socialcommunication</td><td>25716010_analysis_5</td><td>Main effect of dynamics.</td><td>0.348</td><td>0.882</td><td>0.722</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>25716010_2</td><td>Fear + neutral &gt; happy; socialcommunication</td><td>25716010_analysis_2</td><td>C. Fear+neutral&gt;happy</td><td>0.889</td><td>1.000</td><td>0.967</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25716010_3</td><td>Fear &gt; happy +  neutral; socialcommunication</td><td>25716010_analysis_0</td><td>A. Fear&gt;happy+neutral</td><td>0.889</td><td>1.000</td><td>0.967</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25716010_4</td><td>Happy &gt; fear + neutral; socialcommunication</td><td>25716010_analysis_3</td><td>D. Happy&gt;fear+neutral</td><td>0.889</td><td>1.000</td><td>0.967</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25716010_5</td><td>Interactive fear &gt; individual fear; socialcommunication</td><td>25716010_analysis_6</td><td>A. Interactive fear&gt;individual fear</td><td>0.958</td><td>1.000</td><td>0.987</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25716010_6</td><td>Interactive fear &gt; individual fear +  individual neutral &gt; interactive neutral; socialcommunication</td><td>25716010_analysis_9</td><td>D. Interactive fear&gt;individual fear+individual neutral&gt;interactive neutral</td><td>0.968</td><td>1.000</td><td>0.990</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25716010_7</td><td>Interactive fear &gt; individual fear + interactive happy &gt; individual happy; socialcommunication</td><td>25716010_analysis_7</td><td>B. Interactive fear&gt;individual fear+interactive happy&gt;individual happy</td><td>0.966</td><td>1.000</td><td>0.990</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25716010_8</td><td>Interactive fear &gt; individual fear + interactive neutral &gt; individual neutral; socialcommunication</td><td>25716010_analysis_8</td><td>C. Interactive fear&gt;individual fear+interactive neutral&gt;individual neutral</td><td>0.968</td><td>1.000</td><td>0.990</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25716010_9</td><td>Interactive neutral &gt; individual neutral; socialcommunication</td><td>25716010_analysis_10</td><td>E. Interactive neutral&gt;individual neutral</td><td>0.964</td><td>1.000</td><td>0.989</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25729358</strong> | Pred included: 6 | Manual included (accepted matches only): 6 | Correct overlaps: 6 | Match statuses: accepted=6, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25729358/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25729358_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task examines intention to deceive, inferring receiver beliefs, and interactive messaging — a social task engaging theory-of-mind and social cognition. Meets both I1 (social task) and I2 (measures social processing).</td></tr>
<tr><td>25729358_analysis_1</td><td>Simple deception vs. truth</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task is an interactive sender–receiver game probing deception and the intention to deceive; contrasts (deception vs. truth) target social cognitive processes (ToM, understanding others), satisfying both criteria.</td></tr>
<tr><td>25729358_analysis_2</td><td>Sophisticated deception vs. truth</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast examines intention to deceive in a sender-receiver social interaction and engages theory-of-mind and social-cognitive processes (inferring others&#x27; beliefs), satisfying both criteria.</td></tr>
<tr><td>25729358_analysis_3</td><td>Sophisticated deception vs. simple deception</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is a social interactive sender–receiver game requiring participants to reason about others&#x27; beliefs and intentions (deception, ToM). The contrast (sophisticated vs. simple deception) directly measures social processing (intent to deceive, perspective-taking).</td></tr>
<tr><td>25729358_analysis_4</td><td>analysis_4</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The sender–receiver game is an interactive social task requiring participants to consider others&#x27; beliefs and intentions (theory of mind); the contrast (deception vs. truth) directly measures social processing (intention to deceive).</td></tr>
<tr><td>25729358_analysis_5</td><td>Parametric analysis modeling the incentive to deceive for simple deception trials</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task is a strategic sender–receiver game probing deception and intention to deceive; the parametric analysis models socio-cognitive processes (theory-of-mind/understanding others) so it measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25729358_1</td><td>difference between sender and reciever payoff &gt; baseline; others</td><td>25729358_analysis_5</td><td>Parametric analysis modeling the incentive to deceive for simple deception trials</td><td>0.248</td><td>1.000</td><td>0.774</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>25729358_2</td><td>simple &amp; sophisticated deception &gt; truth; others</td><td>25729358_analysis_0</td><td>analysis_0</td><td>0.120</td><td>1.000</td><td>0.736</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>25729358_3</td><td>simple deception &gt; truth; others</td><td>25729358_analysis_1</td><td>Simple deception vs. truth</td><td>0.920</td><td>1.000</td><td>0.976</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25729358_4</td><td>sophisticated deception &gt; simple deception; others</td><td>25729358_analysis_3</td><td>Sophisticated deception vs. simple deception</td><td>0.953</td><td>1.000</td><td>0.986</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25729358_5</td><td>sophisticated deception &gt; truth; others</td><td>25729358_analysis_2</td><td>Sophisticated deception vs. truth</td><td>0.938</td><td>1.000</td><td>0.981</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25729358_6</td><td>truth &gt; simple deception &amp; sophisticated deception; others</td><td>25729358_analysis_4</td><td>analysis_4</td><td>0.100</td><td>1.000</td><td>0.730</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25929599</strong> | Pred included: 5 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25929599/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25929599_analysis_0</td><td>Incongruent &gt; Congruent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The SAMT is explicitly a social-affective mimicry task manipulating emotional expression and group membership; the Incongruent&gt;Congruent contrast indexes regulation of mimicry in response to social cues, i.e. social processing.</td></tr>
<tr><td>25929599_analysis_1</td><td>Happy (Incongruent &gt; Congruent) masked inclusively with Happy (Incongruent &gt; Congruent) &gt; Angry (Incongruent &gt; Congruent)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis uses an automatic imitation (mimicry) task with facial emotional expressions and group membership manipulations, directly probing social cognition (affiliation, perception of others) and neural correlates of social processing (e.g., TPJ, AI). It therefore satisfies both I1 (social-related task) and I2 (measures social processing).</td></tr>
<tr><td>25929599_analysis_2</td><td>Angry (Incongruent &gt; Congruent) masked inclusively with Angry (Incongruent &gt; Congruent) &gt; Happy (Incongruent &gt; Congruent)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The SAMT manipulates emotional expression and group membership and assesses neural regulation of mimicry in social contexts, directly measuring social processing (perception of others and social interaction).</td></tr>
<tr><td>25929599_analysis_3</td><td>Out-group (Incongruent &gt; Congruent) masked inclusively with Out-group (Incongruent &gt; Congruent) &gt; In-group (Incongruent &gt; Congruent)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The SAMT is explicitly social: faces with emotion and group membership modulate mimicry. The contrast tests social processing (mimicry regulation in response to out-group vs in-group), satisfying both I1 and I2.</td></tr>
<tr><td>25929599_analysis_4</td><td>In-group (Incongruent &gt; Congruent) masked inclusively with In-group (Incongruent &gt; Congruent) &gt; Out-group (Incongruent &gt; Congruent)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast probes mimicry regulation in response to social cues (in-group vs out-group faces and emotional expressions). The task is explicitly social and measures social processing (affiliation-relevant responses, group membership effects).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25929599_1</td><td>Angry (Incongruent &gt; Congruent) masked inclusively with Angry (Incongruent &gt; Congruent) &gt; Happy (Incongruent &gt; Congruent); socialcommunication</td><td>25929599_analysis_2</td><td>Angry (Incongruent &gt; Congruent) masked inclusively with Angry (Incongruent &gt; Congruent) &gt; Happy (Incongruent &gt; Congruent)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25929599_2</td><td>Happy (Incongruent &gt; Congruent) masked inclusively with Happy (Incongruent &gt; Congruent) &gt; Angry (Incongruent &gt; Congruent); socialcommunication</td><td>25929599_analysis_1</td><td>Happy (Incongruent &gt; Congruent) masked inclusively with Happy (Incongruent &gt; Congruent) &gt; Angry (Incongruent &gt; Congruent)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25929599_3</td><td>In-group (Incongruent &gt; Congruent) masked inclusively with In-group (Incongruent &gt; Congruent) &gt; Out-group (Incongruent &gt; Congruent); socialcommunication</td><td>25929599_analysis_4</td><td>In-group (Incongruent &gt; Congruent) masked inclusively with In-group (Incongruent &gt; Congruent) &gt; Out-group (Incongruent &gt; Congruent)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25929599_4</td><td>Incongruent &gt; Congruent; socialcommunication</td><td>25929599_analysis_0</td><td>Incongruent &gt; Congruent</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25929599_5</td><td>Out-group (Incongruent &gt; Congruent) masked inclusively with Out-group (Incongruent &gt; Congruent) &gt; In-group (Incongruent &gt; Congruent);socialcommunication</td><td>25929599_analysis_3</td><td>Out-group (Incongruent &gt; Congruent) masked inclusively with Out-group (Incongruent &gt; Congruent) &gt; In-group (Incongruent &gt; Congruent)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25996424</strong> | Pred included: 6 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=1, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25996424/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25996424_analysis_0</td><td>Eye Contact &gt; Averted Gaze</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task involves observing eye contact and gaze following — clearly social processing and measures social perception/interaction.</td></tr>
<tr><td>25996424_analysis_1</td><td>Averted Gaze &gt; Eye Contact</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves observing eye contact and gaze following between people, which is a social task probing perception and processing of social cues; the contrast measures social processing of gaze/attentional relations.</td></tr>
<tr><td>25996424_analysis_2</td><td>Congruent Gaze Cues &gt; Incongruent Gaze Cues</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task investigates gaze following and how observed eye contact between faces modulates processing of subsequent gaze cues—this is clearly a social-related task and measures social processing (social attention/interpretation of others&#x27; gaze).</td></tr>
<tr><td>25996424_analysis_3</td><td>Incongruent Gaze Cues &gt; Congruent Gaze Cues</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task involves perceiving and interpreting social cues (observed eye contact and gaze following) and the contrast measures social processing of others&#x27; gaze congruency; satisfies both inclusion criteria.</td></tr>
<tr><td>25996424_analysis_4</td><td>Eye Contact congruent &gt; Averted Gaze congruent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task manipulates social cues (observed eye contact and gaze following) and the contrast tests how social context (eye contact vs averted gaze) modulates processing of gaze — it measures social processing.</td></tr>
<tr><td>25996424_analysis_5</td><td>Averted Gaze incongruent &gt; Averted Gaze congruent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task involves observing eye contact and gaze-following, which are social cues and social attention processes; the contrast measures social processing of gaze congruency within an averted-gaze context.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25996424_1</td><td>averted gaze &gt; eye contact; socialcommunication</td><td>25996424_analysis_1</td><td>Averted Gaze &gt; Eye Contact</td><td>1.000</td><td>0.941</td><td>0.959</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>25996424_2</td><td>averted gaze x incongruent &gt; averted  gaze x congruent; socialcommunication</td><td>25996424_analysis_5</td><td>Averted Gaze incongruent &gt; Averted Gaze congruent</td><td>0.961</td><td>1.000</td><td>0.988</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25996424_3</td><td>congruent gaze cues &gt; incongruent gaze cues; socialcommunication</td><td>25996424_analysis_2</td><td>Congruent Gaze Cues &gt; Incongruent Gaze Cues</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25996424_4</td><td>eye contact &gt; averted gaze; socialcommunication</td><td>25996424_analysis_0</td><td>Eye Contact &gt; Averted Gaze</td><td>1.000</td><td>0.500</td><td>0.650</td><td>uncertain</td><td>coord_count_mismatch</td></tr><tr><td>25996424_5</td><td>eye contact x congruent &gt; averted gaze x congruent; socialcommunication</td><td>25996424_analysis_4</td><td>Eye Contact congruent &gt; Averted Gaze congruent</td><td>0.958</td><td>0.800</td><td>0.848</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>25996424_6</td><td>incongruent gaze cues &gt; congruent gaze cues; socialcommunication</td><td>25996424_analysis_3</td><td>Incongruent Gaze Cues &gt; Congruent Gaze Cues</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26235682</strong> | Pred included: 5 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26235682/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26235682_analysis_0</td><td>Positive vs. Neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves processing social reputation (positive vs. neutral comments from others) and measures social processing of pleasantness induced by social interaction.</td></tr>
<tr><td>26235682_analysis_1</td><td>Negative vs. Neutral</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves receiving and evaluating social reputation (positive/negative/neutral) from others and rating pleasantness—directly measures social processing.</td></tr>
<tr><td>26235682_analysis_2</td><td>(Positive &gt; Neutral) inclusively masked with (Negative &gt; Neutral)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves processing social reputation (positive/negative/neutral comments from others) and measures social processing of received social information and subjective pleasantness.</td></tr>
<tr><td>26235682_analysis_3</td><td>(Positive vs. Neutral) vs. (Negative vs. Neutral)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves receiving social reputation (comments from others) and comparing positive, negative, and neutral social feedback — this is a social-processing task that directly measures social processing via the specified contrast.</td></tr>
<tr><td>26235682_analysis_4</td><td>(Negative vs. Neutral) vs. (Positive vs. Neutral)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task assesses processing of social reputation (receiving positive/negative comments from others) and the contrast isolates responses to social stimuli (positive vs. neutral and negative vs. neutral). This meets both I1 (social-related task) and I2 (measures social processing).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26235682_1</td><td>(Positive &gt; Neutral) inclusively masked with (Negative &gt; Neutral); others</td><td>26235682_analysis_2</td><td>(Positive &gt; Neutral) inclusively masked with (Negative &gt; Neutral)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26235682_2</td><td>(Positive vs. Neutral) &gt; (Negative vs. Neutral); others</td><td>26235682_analysis_3</td><td>(Positive vs. Neutral) vs. (Negative vs. Neutral)</td><td>0.958</td><td>1.000</td><td>0.988</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26235682_3</td><td>Negative &gt; Neutral; others</td><td>26235682_analysis_1</td><td>Negative vs. Neutral</td><td>0.895</td><td>1.000</td><td>0.968</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26235682_4</td><td>Positive &gt; Neutral; others</td><td>26235682_analysis_0</td><td>Positive vs. Neutral</td><td>0.895</td><td>1.000</td><td>0.968</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26254589</strong> | Pred included: 6 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26254589/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26254589_analysis_0</td><td>EmpaToM: emotionally negative &gt; neutral video</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The EmpaToM contrast (emotionally negative &gt; neutral videos) probes empathy and social understanding of others, a social-related task measuring social processing.</td></tr>
<tr><td>26254589_analysis_1</td><td>EmpaToM: ToM &gt; nonToM question</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>EmpaToM manipulates and measures empathy and Theory of Mind (ToM) within the same paradigm, directly probing social processes (understanding others&#x27; emotions and mental states). This satisfies both I1 (social-related task) and I2 (measures Social Processing).</td></tr>
<tr><td>26254589_analysis_2</td><td>EmpaToM: emotionally negative &gt; neutral video</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The EmpaToM emotionally negative&gt;neutral contrast probes empathic responding to others&#x27; emotional narratives, a core social-processing task assessing perception and response to social information (empathy, compassion, ToM). It satisfies both inclusion criteria.</td></tr>
<tr><td>26254589_analysis_3</td><td>EmpaToM: ToM &gt; nonToM questions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The EmpaToM ToM&gt;nonToM contrast probes Theory of Mind—understanding others&#x27; mental states—so it clearly involves social processing.</td></tr>
<tr><td>26254589_analysis_4</td><td>EmpaToM: (emotional &gt; neutral video) &gt; (ToM &gt; nonToM questions)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The EmpaToM task explicitly manipulates empathy and Theory of Mind to assess social understanding of others; it is a social-related task and directly measures social processing.</td></tr>
<tr><td>26254589_analysis_5</td><td>EmpaToM: (ToM &gt; nonToM questions) &gt; (emotionally negative &gt; neutral video)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The EmpaToM contrasts explicitly probe empathy and Theory of Mind (understanding others&#x27; emotions and mental states), which are social processing constructs. The contrast measures social processing (affective and cognitive understanding of others).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26254589_1</td><td>EmpaToM: (ToM N nonToM questions) &gt; (emotionally negative N neutral video); others</td><td>26254589_analysis_5</td><td>EmpaToM: (ToM &gt; nonToM questions) &gt; (emotionally negative &gt; neutral video)</td><td>0.973</td><td>1.000</td><td>0.992</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26254589_2</td><td>EmpaToM: (emotional N neutral video) &gt; (ToM N nonToM questions); others</td><td>26254589_analysis_4</td><td>EmpaToM: (emotional &gt; neutral video) &gt; (ToM &gt; nonToM questions)</td><td>0.968</td><td>1.000</td><td>0.990</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26254589_3</td><td>EmpaToM: ToM &gt; nonToM questions; others</td><td>26254589_analysis_3</td><td>EmpaToM: ToM &gt; nonToM questions</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26254589_4</td><td>EmpaToM: emotionally negative &gt; neutral video; others</td><td>26254589_analysis_2</td><td>EmpaToM: emotionally negative &gt; neutral video</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26262561</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26262561/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26262561_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is explicitly social (gaze-following with political in-group/out-group faces) and the contrasts probe social processing (incongruent&gt;congruent; in-group vs out-group; correlations with social-dimension measures SDO and PS).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26262561_1</td><td>[incongruent &gt; congruent trials]; self</td><td>26262561_analysis_0</td><td>analysis_0</td><td>0.208</td><td>1.000</td><td>0.762</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26301900</strong> | Pred included: 2 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26301900/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26301900_analysis_0</td><td>ToM &gt; R</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The ToM &gt; R contrast uses a Theory of Mind task (animated shapes eliciting attributions of mental states), which is a social-related task assessing perception/understanding of others; thus it meets I1 and I2.</td></tr>
<tr><td>26301900_analysis_1</td><td>Bayesian analysis to evaluate the theory that the response in the mPFC is the same as the response in the right superior temporal gyrus during “ToM &gt; R” (volume of interest (VOI): mPFC-coordinates based on literature, right posterior superior temporal gyrus coordinates based on our sample (MNI: 54-48 16), radius 15 mm; mean and standard deviation (SD) represent the average BOLD-signal within a volume of interest).</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task is a Theory of Mind (ToM) / mentalization paradigm (moving triangles) that requires attributing mental states to others, so it is a social-processing task assessing perception and understanding of others.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26301900_1</td><td>ToM &gt; R; others</td><td>26301900_analysis_0</td><td>ToM &gt; R</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26323252</strong> | Pred included: 5 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=1, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26323252/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> ingroup members &gt; outgroup members; others</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26323252_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task explicitly involves empathic responses to others’ pain and manipulates group membership (ingroup vs outgroup), i.e., a social-related task measuring perception/response to others—meets both I1 and I2.</td></tr>
<tr><td>26323252_analysis_1</td><td>Main effect of condition</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task explicitly manipulates group membership and asks participants to empathize with others’ pain; the main effect of condition (ingroup vs outgroup) and pain×group interaction measure social processing of others and group-based social cognition.</td></tr>
<tr><td>26323252_analysis_2</td><td>Main effect of gender</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task involves empathy for others’ pain and manipulations of ingroup/outgroup and gender — a social-related task measuring perception and response to social information.</td></tr>
<tr><td>26323252_analysis_3</td><td>Pain×condition</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The contrast Pain×condition tests empathy for ingroup vs outgroup members — a social task assessing perception/understanding of others’ emotional states and group-based social processing, satisfying both I1 (social-related task) and I2 (measures social processing).</td></tr>
<tr><td>26323252_analysis_4</td><td>Pain×gender</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The Pain×gender analysis examines neural responses to others’ pain (empathy), a social task assessing perception and understanding of others’ emotional states — meets social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26323252_1</td><td>ingroup members &gt; outgroup members; others</td><td>26323252_analysis_2</td><td>Main effect of gender</td><td>0.218</td><td>0.667</td><td>0.532</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>26323252_2</td><td>pain stimuli &gt; neutral stimuli; others</td><td>26323252_analysis_0</td><td>analysis_0</td><td>0.300</td><td>1.000</td><td>0.790</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>26323252_3</td><td>pain x condition &gt; pain x gender; others</td><td>26323252_analysis_3</td><td>Pain×condition</td><td>0.565</td><td>0.778</td><td>0.714</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26365506</strong> | Pred included: 1 | Manual included (accepted matches only): 2 | Correct overlaps: 1 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26365506/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26365506_analysis_0</td><td>Self-referential &gt; social</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>The study includes a social vs non-social manipulation, but this specific contrast (self-referential &gt; social) isolates self-referential effects rather than measuring social processing directly, so it does not meet I2.</td></tr>
<tr><td>26365506_analysis_1</td><td>Social &gt; self-referential</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The study explicitly manipulates social content (social vs non-social pictures) and includes contrasts for social processing, including a direct contrast isolating social &gt; self-referential, so it measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26365506_1</td><td>Self-referential &gt; social; self</td><td>26365506_analysis_0</td><td>Self-referential &gt; social</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26365506_2</td><td>Social &gt; self-referential; self</td><td>26365506_analysis_1</td><td>Social &gt; self-referential</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26417673</strong> | Pred included: 3 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=2</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26417673/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Disgust &gt; Neutral; socialcommunication, Out-group &gt; In-group; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26417673_analysis_0</td><td>Brain activation of the racial prejudice in disgust perception during the passive viewing task ((disgusted out-group-neutral out-group)-(disgusted in-group-neutral in-group))</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast examines perception of disgust in in-group vs out-group faces (social category effects), which is clearly social processing of others&#x27; emotional expressions.</td></tr>
<tr><td>26417673_analysis_1</td><td>Positive connectivity</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task involves passive viewing and interpretation of others&#x27; facial emotions across in-/out-group (racial) contexts; analysis targets social perception and prejudice. Satisfies social-related task and measures social processing of others&#x27; emotions.</td></tr>
<tr><td>26417673_analysis_2</td><td>Negative connectivity</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The contrast examines perception of disgusted faces for in-group vs out-group (implicit racial prejudice) — a social task measuring perception and interpretation of others&#x27; emotions and group-based social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26417673_1</td><td>Disgust &gt; Neutral; socialcommunication</td><td>26417673_analysis_1</td><td>Positive connectivity</td><td>0.316</td><td>0.023</td><td>0.111</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>26417673_2</td><td>Disgusted out-group-neutral out-group &gt; Disgusted In-group-neutral in-group; socialcommunication</td><td>26417673_analysis_0</td><td>Brain activation of the racial prejudice in disgust perception during the passive viewing task ((disgusted out-group-neutral out-group)-(disgusted in-group-neutral in-group))</td><td>0.578</td><td>1.000</td><td>0.873</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26417673_3</td><td>Out-group &gt; In-group; socialcommunication</td><td>26417673_analysis_2</td><td>Negative connectivity</td><td>0.194</td><td>0.067</td><td>0.105</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26481048</strong> | Pred included: 4 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=2</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26481048/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Activation &gt; Deactivation; self, Deactivation &gt; Activation; self</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26481048_analysis_0</td><td>Compared to implicit baseline</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The task involved processing agentic and communal trait words (social content) in a valence-classification task; the contrasts and conjunction explicitly probe neural responses to social content (agency and communion), satisfying both I1 (social-related task) and I2 (measures social processing).</td></tr>
<tr><td>26481048_analysis_1</td><td>Compared to fixation task</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task involves processing socially relevant content (agentic and communal trait words) and conjunction analysis identifies mentalizing and social cognition regions; meets both I1 (social-related task) and I2 (measures social processing).</td></tr>
<tr><td>26481048_analysis_2</td><td>Agency vs. Communion</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves processing social content (agentic vs. communal trait words) and contrasts measure social cognitive processing (mentalizing, DMN deactivations), satisfying both social-task and measurement criteria.</td></tr>
<tr><td>26481048_analysis_3</td><td>Communion vs. Agency</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves processing social trait words (agency vs. communion) and probes social cognition; contrast directly measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26481048_1</td><td>Activation &gt; Deactivation; self</td><td>26481048_analysis_1</td><td>Compared to fixation task</td><td>0.400</td><td>0.123</td><td>0.206</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>26481048_2</td><td>Agency vs. Communion; self</td><td>26481048_analysis_2</td><td>Agency vs. Communion</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26481048_3</td><td>Communion vs. Agency; self</td><td>26481048_analysis_3</td><td>Communion vs. Agency</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26481048_4</td><td>Deactivation &gt; Activation; self</td><td>26481048_analysis_0</td><td>Compared to implicit baseline</td><td>0.167</td><td>0.571</td><td>0.450</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26505303</strong> | Pred included: 4 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26505303/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26505303_analysis_0</td><td>Words &gt; Faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task involves observing communicative interactions (Naming and Requesting) and the contrast Words&gt;Faces captures processing of spoken communicative signals and engages social cognition regions (e.g., right TPJ), satisfying both I1 (social-related task) and I2 (measures social processing).</td></tr>
<tr><td>26505303_analysis_1</td><td>Request &gt; Naming</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task explicitly investigates comprehension of communicative actions (Naming vs Requesting) between two people, involving intentions, social interaction and theory-of-mind; the contrast Request &gt; Naming measures social processing.</td></tr>
<tr><td>26505303_analysis_2</td><td>Request &gt; Naming</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast compares comprehension of communicative speech acts (Request vs Naming) in interactive contexts, directly measuring social processing and understanding of others&#x27; communicative intentions.</td></tr>
<tr><td>26505303_analysis_3</td><td>Naming &gt; Request</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast compares comprehension of communicative speech acts (Naming vs Request) and examines understanding of intentions, action predictions and theory-of-mind processes—clearly a social processing task. Both inclusion criteria are met.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26505303_1</td><td>Request &gt; Naming; socialcommunication</td><td>26505303_analysis_1</td><td>Request &gt; Naming</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26505303_2</td><td>Words &gt; Faces; socialcommunication</td><td>26505303_analysis_0</td><td>Words &gt; Faces</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26567160</strong> | Pred included: 7 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26567160/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Trust &gt; Distrust; affiliation</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26567160_analysis_0</td><td>Attitude &gt; Age</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task explicitly involves controlling and evaluating interpersonal trust/distrust (social attitude toward others) compared to an age-evaluation control — clearly a social-processing task.</td></tr>
<tr><td>26567160_analysis_1</td><td>Trust &gt; Age</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast Trust &gt; Age directly probes control of interpersonal trust/distrust (social attitudes) vs a non-social age evaluation; it clearly measures social processing.</td></tr>
<tr><td>26567160_analysis_2</td><td>Distrust &gt; Age</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast &#x27;Distrust &gt; Age&#x27; involves explicitly manipulating interpersonal trust/distrust and mentalizing about others’ intentions; this is a social-related task and directly measures social processing.</td></tr>
<tr><td>26567160_analysis_3</td><td>Trust</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task explicitly involves controlling and evaluating interpersonal trust/distrust toward faces, which is a social cognitive process. It meets I1 (social-related task) and I2 (measures social processing).</td></tr>
<tr><td>26567160_analysis_4</td><td>Distrust</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The task explicitly probes interpersonal trust/distrust and mentalizing about others (control-of-trust/distrust vs age), which is a social processing task measuring perception and evaluation of social cues.</td></tr>
<tr><td>26567160_analysis_5</td><td>Precuneus Connectivity-Positive</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task explicitly involves controlling and evaluating interpersonal trust/distrust (social attitudes) and measures brain activity related to social processing (mentalizing network, precuneus connectivity).</td></tr>
<tr><td>26567160_analysis_6</td><td>IFG Connectivity-Negative</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task explicitly involves social processing—participants controlled and evaluated interpersonal trust/distrust and mentalizing about others’ intentions; contrasts measure social processing (trust/distrust &gt; age).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26567160_1</td><td>Attitude &gt; Age; affiliation</td><td>26567160_analysis_0</td><td>Attitude &gt; Age</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26567160_2</td><td>Distrust &gt; Age; affiliation</td><td>26567160_analysis_2</td><td>Distrust &gt; Age</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26567160_3</td><td>Trust &gt; Age; affiliation</td><td>26567160_analysis_1</td><td>Trust &gt; Age</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26567160_4</td><td>Trust &gt; Distrust; affiliation</td><td>26567160_analysis_4</td><td>Distrust</td><td>0.667</td><td>0.000</td><td>0.200</td><td>unmatched</td><td>coord_count_mismatch, low_total_score, name_only_signal</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26803059</strong> | Pred included: 10 | Manual included (accepted matches only): 7 | Correct overlaps: 7 | Match statuses: accepted=7, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26803059/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26803059_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task requires affective theory-of-mind judgments about a protagonist&#x27;s emotional state and manipulates presence/absence of emotional facial expressions—this is clearly social processing. The contrast (EFE &gt; no EFE during affective ToM) directly measures social processing.</td></tr>
<tr><td>26803059_analysis_1</td><td>EFE &gt; no EFE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task requires affective Theory of Mind judgments about another person’s emotional state and manipulates emotional facial expressions (EFE); directly measures social processing.</td></tr>
<tr><td>26803059_analysis_2</td><td>No EFE &gt; EFE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast involves affective Theory of Mind judgments about another&#x27;s emotional state (presence/absence of emotional facial expressions), which is a social-related task and directly measures social processing.</td></tr>
<tr><td>26803059_analysis_3</td><td>Correlation of differential activation EFE &gt; no EFE with RT reduction by EFE, P &lt; 0.001 (uncorrected); k = 10</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast examines affective Theory of Mind with vs without emotional facial expressions and their behavioral correlate (RT), which is clearly social processing involving perception and understanding of others&#x27; emotions.</td></tr>
<tr><td>26803059_analysis_4</td><td>Correlation of differential activation no EFE &gt; EFE with RT reduction by EFE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis tests affective Theory-of-Mind judgments and the effect of emotional facial expressions (EFE) on behavior and brain activation—clearly a social task probing perception/understanding of others and social processing.</td></tr>
<tr><td>26803059_analysis_5</td><td>Greater EFE effects with explicit demand of affective ToM judgments (EFE ToM - no EFE ToM) - (EFE no ToM - no EFE no ToM)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task explicitly assesses affective theory of mind—judging another&#x27;s emotional state—which is a core social-processing task (perception and understanding of others).</td></tr>
<tr><td>26803059_analysis_6</td><td>Greater EFE effects with explicit demand of affective ToM judgments (EFE no ToM - no EFE no ToM) - (EFE ToM - no EFE ToM)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task is affective theory of mind involving inferring others&#x27; emotional states and processing emotional facial expressions—meets social processing.</td></tr>
<tr><td>26803059_analysis_7</td><td>PPI</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task is an affective theory-of-mind task requiring participants to judge protagonists&#x27; emotional states, i.e., social cognition. Satisfies both social-related task and measurement of social processing.</td></tr>
<tr><td>26803059_analysis_8</td><td>Pos. correlation: affective ToM matching with consensus judgments and PPI effects</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The analysis uses an affective theory-of-mind task involving judgments about others&#x27; emotional states and effects of emotional facial expressions (EFE), clearly measuring social processing.</td></tr>
<tr><td>26803059_analysis_9</td><td>Neg. correlation: affective ToM matching with consensus judgments and PPI effects</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task explicitly measures affective Theory of Mind and recognition of others&#x27; emotional states via emotional facial expressions and consensus judgments—clearly social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26803059_1</td><td>(EFE ToM − no EFE ToM) − (EFE no ToM − no EFE no ToM); others</td><td>26803059_analysis_5</td><td>Greater EFE effects with explicit demand of affective ToM judgments (EFE ToM - no EFE ToM) - (EFE no ToM - no EFE no ToM)</td><td>0.575</td><td>0.900</td><td>0.802</td><td>accepted</td><td>high_coord_match</td></tr><tr><td>26803059_2</td><td>(EFE no ToM − no EFE no ToM) − (EFE ToM − no EFE ToM); others</td><td>26803059_analysis_6</td><td>Greater EFE effects with explicit demand of affective ToM judgments (EFE no ToM - no EFE no ToM) - (EFE ToM - no EFE ToM)</td><td>0.575</td><td>1.000</td><td>0.872</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26803059_3</td><td>3rdppA &gt; 1stppV; others</td><td>26803059_analysis_0</td><td>analysis_0</td><td>0.182</td><td>1.000</td><td>0.755</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>26803059_4</td><td>EFE &gt; no EFE; others</td><td>26803059_analysis_1</td><td>EFE &gt; no EFE</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26803059_5</td><td>EFE &gt; no EFE with RT reduction; others</td><td>26803059_analysis_3</td><td>Correlation of differential activation EFE &gt; no EFE with RT reduction by EFE, P &lt; 0.001 (uncorrected); k = 10</td><td>0.489</td><td>1.000</td><td>0.847</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>26803059_6</td><td>No EFE &gt; EFE; others</td><td>26803059_analysis_2</td><td>No EFE &gt; EFE</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26803059_7</td><td>no EFE &gt; EFE with RT reduction; others</td><td>26803059_analysis_4</td><td>Correlation of differential activation no EFE &gt; EFE with RT reduction by EFE</td><td>0.566</td><td>1.000</td><td>0.870</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26812250</strong> | Pred included: 11 | Manual included (accepted matches only): 11 | Correct overlaps: 11 | Match statuses: accepted=11, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26812250/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26812250_analysis_0</td><td>Negative vs. positive performance feedback.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task involves receiving performance feedback (social evaluation) and subsequent empathic/unempathic comments; the contrast (negative vs positive feedback) reflects social processing related to social evaluation and emotional responses to others’ feedback.</td></tr>
<tr><td>26812250_analysis_1</td><td>(A) Emotional empathic (EE) &gt; emotional unempathic (EN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast compares empathic vs unempathic social responses (verbal comments) during negative feedback, directly probing social cognition and processing of social information.</td></tr>
<tr><td>26812250_analysis_2</td><td>(B) Unempathic (EN + CN) &gt; empathic (EE + CE)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast examines responses to empathic vs. unempathic social comments and neural processing of social interactions/mentalizing; it is a social-processing task and measures social cognition.</td></tr>
<tr><td>26812250_analysis_3</td><td>(C) Cognitive unempathic (CN) &gt; cognitive empathic (CE)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares responses to empathic vs. unempathic comments (social interactions), directly measuring social cognition/social processing (mentalizing, response to social support). Satisfies I1 (social-related task) and I2 (measures social processing).</td></tr>
<tr><td>26812250_analysis_4</td><td>(D) Empathic (EE + CE) &gt; high level baseline</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task involves receiving empathic vs. unempathic verbal comments and neural processing of social responses—clearly a social-related task and measures social processing.</td></tr>
<tr><td>26812250_analysis_5</td><td>(E) Emotional empathic (EE) &gt; high level baseline</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves receiving and processing empathic/unempathic verbal social responses and engages social-cognitive and emotion-processing networks (mentalizing, empathy), so it clearly measures social processing.</td></tr>
<tr><td>26812250_analysis_6</td><td>(F) Cognitive empathic (CE) &gt; high level baseline</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast involves processing empathic social responses (cognitive empathy) and measures neural/social-cognitive processing of social information.</td></tr>
<tr><td>26812250_analysis_7</td><td>(A) Emotional (EE + EN) &gt; cognitive (CE + CN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task involves receiving and processing empathic vs unempathic verbal comments—clearly a social task; the contrast measures social processing (empathy, social cognition, mentalizing).</td></tr>
<tr><td>26812250_analysis_8</td><td>(B) Emotional empathic (EE) &gt; cognitive empathic (CE)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast involves processing verbal empathic comments and reactions to social responses, clearly a social task and measures social processing (mentalizing, emotion/social cognition).</td></tr>
<tr><td>26812250_analysis_9</td><td>(C) Emotional unempathic (EN) &gt; cognitive unempathic (CN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares processing of empathic vs. unempathic social comments (verbal social responses), which is a social-related task and directly measures social processing.</td></tr>
<tr><td>26812250_analysis_10</td><td>(D) Cognitive unempathic (CN) &gt; emotional unempathic (EN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast involves processing of empathic vs unempathic social comments; task is explicitly social and measures social-cognitive processing of others’ empathic expressions.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26812250_1</td><td>Cognitive empathic (CE) &gt; high level baseline; others</td><td>26812250_analysis_6</td><td>(F) Cognitive empathic (CE) &gt; high level baseline</td><td>0.957</td><td>1.000</td><td>0.987</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26812250_10</td><td>Unempathic (EN + CN) &gt; empathic (EE + CE); others</td><td>26812250_analysis_2</td><td>(B) Unempathic (EN + CN) &gt; empathic (EE + CE)</td><td>0.953</td><td>1.000</td><td>0.986</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26812250_11</td><td>negative vs positive performance; others</td><td>26812250_analysis_0</td><td>Negative vs. positive performance feedback.</td><td>0.853</td><td>1.000</td><td>0.956</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26812250_2</td><td>Cognitive unempathic (CN) &gt; cognitive empathic (CE); others</td><td>26812250_analysis_3</td><td>(C) Cognitive unempathic (CN) &gt; cognitive empathic (CE)</td><td>0.962</td><td>1.000</td><td>0.989</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26812250_3</td><td>Cognitive unempathic (CN) &gt; emotional unempathic (EN); others</td><td>26812250_analysis_10</td><td>(D) Cognitive unempathic (CN) &gt; emotional unempathic (EN)</td><td>0.964</td><td>1.000</td><td>0.989</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26812250_4</td><td>Emotional (EE + EN) &gt; cognitive (CE + CN); others</td><td>26812250_analysis_7</td><td>(A) Emotional (EE + EN) &gt; cognitive (CE + CN)</td><td>0.953</td><td>1.000</td><td>0.986</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26812250_5</td><td>Emotional Empathic (EE) &gt; emotional unempathic (EN); others</td><td>26812250_analysis_1</td><td>(A) Emotional empathic (EE) &gt; emotional unempathic (EN)</td><td>0.962</td><td>1.000</td><td>0.989</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26812250_6</td><td>Emotional empathic (EE) &gt; cognitive empathic (CE); others</td><td>26812250_analysis_8</td><td>(B) Emotional empathic (EE) &gt; cognitive empathic (CE)</td><td>0.961</td><td>1.000</td><td>0.988</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26812250_7</td><td>Emotional empathic (EE) &gt; high level baseline; others</td><td>26812250_analysis_5</td><td>(E) Emotional empathic (EE) &gt; high level baseline</td><td>0.957</td><td>1.000</td><td>0.987</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26812250_8</td><td>Emotional unempathic (EN) &gt; cognitive unempathic (CN); others</td><td>26812250_analysis_9</td><td>(C) Emotional unempathic (EN) &gt; cognitive unempathic (CN)</td><td>0.964</td><td>1.000</td><td>0.989</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26812250_9</td><td>Empathic (EE + CE) &gt; high level baseline; others</td><td>26812250_analysis_4</td><td>(D) Empathic (EE + CE) &gt; high level baseline</td><td>0.952</td><td>1.000</td><td>0.986</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26892859</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26892859/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26892859_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task uses naturalistic social-evaluative videos (approval/disapproval) and contrasts (positive/negative vs neutral) explicitly probe social evaluation and related neural responses (mentalizing, self-relevance, emotion), satisfying both criteria.</td></tr>
<tr><td>26892859_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task uses naturalistic social-evaluative videos; contrasts (positive&gt;neutral, negative&gt;neutral) probe neural processing of social evaluation, mentalizing, and self-relevance — meets I1 and I2.</td></tr>
<tr><td>26892859_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task uses social-evaluative videos and explicitly probes neural responses to social evaluation, mentalizing, and self/other-related processing (fits social processing).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26892859_1</td><td>Negative &gt; neutral; affiliation</td><td>26892859_analysis_0</td><td>analysis_0</td><td>0.214</td><td>1.000</td><td>0.764</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>26892859_2</td><td>positive &gt; neutral; affiliation</td><td>26892859_analysis_1</td><td>analysis_1</td><td>0.143</td><td>1.000</td><td>0.743</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>26892859_3</td><td>positive &gt; neutral and negative &gt; neutral (conjunction analysis); affiliation</td><td>26892859_analysis_2</td><td>analysis_2</td><td>0.216</td><td>1.000</td><td>0.765</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26908320</strong> | Pred included: 6 | Manual included (accepted matches only): 6 | Correct overlaps: 6 | Match statuses: accepted=6, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26908320/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26908320_analysis_0</td><td>A. Increased activation with more racial trust disparity</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves perceiving and evaluating faces (trustworthiness, differentiation) and examines social-cognitive processes underlying race-based social judgments — meets both criteria for social processing.</td></tr>
<tr><td>26908320_analysis_1</td><td>Increased activation with less racial trust disparity</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves perceiving and evaluating other people (race perception and trustworthiness ratings), which is social processing.</td></tr>
<tr><td>26908320_analysis_2</td><td>B. Increased connectivity with orbitofrontal cortex (18, 66, 0) with less racial trust disparity</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves perceiving and evaluating faces by race and predicting racial trust disparity—clearly a social task engaging perception, evaluation, and social cognition processes (meets both criteria).</td></tr>
<tr><td>26908320_analysis_3</td><td>A. Increased activation with more differentiation disparity</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves perceiving and evaluating other people (race perception, trustworthiness ratings, face differentiation)—clear social processing of others.</td></tr>
<tr><td>26908320_analysis_4</td><td>Increased activation with less differentiation disparity</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves perceiving and evaluating social stimuli (Black and White faces), measuring race-related social cognition (trustworthiness evaluations and differentiation), meeting social processing constructs.</td></tr>
<tr><td>26908320_analysis_5</td><td>B. Increased connectivity with dorsolateral prefrontal seed (24, 42, 21) with less differentiation disparity</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involved viewing Black and White faces and later trustworthiness/differentiation ratings—clearly social processing (perception and evaluation of others).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26908320_1</td><td>Black &gt; White faces: A. Increased activation with less differentiation disparity; socialcommunication</td><td>26908320_analysis_4</td><td>Increased activation with less differentiation disparity</td><td>0.824</td><td>1.000</td><td>0.947</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26908320_2</td><td>Black &gt; White faces: A. Increased activation with less racial trust disparities; socialcommunication</td><td>26908320_analysis_1</td><td>Increased activation with less racial trust disparity</td><td>0.788</td><td>1.000</td><td>0.936</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26908320_3</td><td>Black &gt; White faces: A. Increased activation with more differentiation disparity; socialcommunication</td><td>26908320_analysis_3</td><td>A. Increased activation with more differentiation disparity</td><td>0.849</td><td>1.000</td><td>0.955</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26908320_4</td><td>Black &gt; White faces: A. Increased activation with more racial trust disparities; socialcommunication</td><td>26908320_analysis_0</td><td>A. Increased activation with more racial trust disparity</td><td>0.815</td><td>1.000</td><td>0.944</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26908320_5</td><td>Black &gt; White faces: B. Increassed connectivity with dorsolateral prefrontal seed (24, 42, 21) with less differentiation disparity; socialcommunication</td><td>26908320_analysis_5</td><td>B. Increased connectivity with dorsolateral prefrontal seed (24, 42, 21) with less differentiation disparity</td><td>0.908</td><td>1.000</td><td>0.972</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>26908320_6</td><td>Black &gt; White faces: B. Increased connectivity with orbitofrontal cortex (18, 66, 0) with less racial trust disparity; socialcommunication</td><td>26908320_analysis_2</td><td>B. Increased connectivity with orbitofrontal cortex (18, 66, 0) with less racial trust disparity</td><td>0.901</td><td>1.000</td><td>0.970</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 27039141</strong> | Pred included: 4 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=1, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/27039141/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Physical &gt; Meaning; others</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>27039141_analysis_0</td><td>A Meaning &gt; Physical</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The contrast &#x27;Meaning &gt; Physical&#x27; explicitly manipulatives interpretive attitude to attend to social/semantic meaning of artifacts and elicits activity in canonical social-cognition regions (mPFC, TPJ). This satisfies both performing a social-related task and measuring social processing.</td></tr>
<tr><td>27039141_analysis_1</td><td>B Physical &gt; Meaning</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The contrast ‘meaning &gt; physical’ and own vs other comparisons explicitly probe social cognition/processing (mentalizing, social meaning). This satisfies performing a social-related task and measuring social processing (I1, I2).</td></tr>
<tr><td>27039141_analysis_2</td><td>C Own &gt; Other (meaning related task)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast is &#x27;own &gt; other&#x27; within the meaning-related task, which explicitly engages social cognition (mPFC, TPJ, ACC) and involves interpreting social meaning of artifacts — meeting both I1 and I2.</td></tr>
<tr><td>27039141_analysis_3</td><td>D Own &gt; Other × Collective &gt; Individual (meaning related task)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast targets social cognition: meaning-related judgments of own vs others’ models and collective vs individual conditions engage social processing (mPFC, TPJ, ACC, insula) and thus meets both I1 and I2.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>27039141_1</td><td>Meaning &gt; Physical; others</td><td>27039141_analysis_0</td><td>A Meaning &gt; Physical</td><td>0.947</td><td>0.500</td><td>0.634</td><td>uncertain</td><td>coord_count_mismatch</td></tr><tr><td>27039141_2</td><td>Own &gt; Other (meaning related task); others</td><td>27039141_analysis_2</td><td>C Own &gt; Other (meaning related task)</td><td>0.971</td><td>0.750</td><td>0.816</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>27039141_3</td><td>Own &gt; Other × Collective &gt; Individual (meaning related task); others</td><td>27039141_analysis_3</td><td>D Own &gt; Other × Collective &gt; Individual (meaning related task)</td><td>0.984</td><td>0.667</td><td>0.762</td><td>accepted</td><td>coord_count_mismatch</td></tr><tr><td>27039141_4</td><td>Physical &gt; Meaning; others</td><td>27039141_analysis_1</td><td>B Physical &gt; Meaning</td><td>0.947</td><td>0.333</td><td>0.518</td><td>unmatched</td><td>coord_count_mismatch, low_coord_high_name, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 27090501</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/27090501/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>27090501_analysis_0</td><td>Significant activation for the (toss - button press) high-frequency effect.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares social ball-toss (Cyberball) to a non-social button-press control and isolates high-frequency social interaction effects (reward/experience). This is a social-related task and the contrast measures social processing (social reward and related activations).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>27090501_1</td><td>Significant activation for the (toss – button press) high-frequency effect; others</td><td>27090501_analysis_0</td><td>Significant activation for the (toss - button press) high-frequency effect.</td><td>0.980</td><td>1.000</td><td>0.994</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 27095057</strong> | Pred included: 3 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/27095057/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Social-Look &gt; Social-Reg; self</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>27095057_analysis_0</td><td>Social-Reg &gt; Social-Look</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast isolates brain activity during socially-induced emotion regulation by a psychotherapist (Social-Reg vs Social-Look). This is a social task engaging social cognition and DMN regions; it directly measures social processing in the Social-Reg condition and its neural correlates.</td></tr>
<tr><td>27095057_analysis_1</td><td>(Reg &gt; Look)_Social ∩ (Reg &gt; Look)_Self</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The analysis includes a Social-Reg task (psychotherapist-induced reappraisal) and reports common neural activations that overlap with the DMN/social-DMN; it therefore measures social processing related to social cognition and socially-induced emotion regulation.</td></tr>
<tr><td>27095057_analysis_2</td><td>Distinct areas recruited by Social-Reg: (Reg &gt; Look)_Social &gt; (Reg &gt; Look)_Self ∩ (Reg &gt; Look)_social</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast isolates brain regions specific to socially-induced emotion regulation (Social-Reg) vs self-regulation, involving a social task (psychotherapist instructions) and measures social processing (mentalizing, TPJ, precuneus, dmPFC).</td></tr>
<tr><td>27095057_analysis_3</td><td>Distinct areas recruited by Self-Reg: (Reg &gt; Look)_Self &gt; (Reg &gt; Look)_social ∩ (Reg &gt; Look)_Self</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast isolates regions more active for Self-Reg than Social-Reg (i.e., distinct Self-Reg areas). Although the experiment includes a social condition, this specific analysis does not measure social processing per se but rather self-induced regulation; therefore it does not satisfy the criterion requiring the contrast to measure Social Processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>27095057_1</td><td>Social-Look &gt; Social-Reg; self</td><td>27095057_analysis_1</td><td>(Reg &gt; Look)_Social ∩ (Reg &gt; Look)_Self</td><td>0.406</td><td>0.000</td><td>0.122</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>27095057_2</td><td>Social-Reg &gt; Social-Look; self</td><td>27095057_analysis_0</td><td>Social-Reg &gt; Social-Look</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 27096431</strong> | Pred included: 14 | Manual included (accepted matches only): 8 | Correct overlaps: 8 | Match statuses: accepted=8, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/27096431/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>27096431_analysis_0</td><td>Aggressive reaction to provoking opponent &gt; non aggressive reaction to non-provoking opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Taylor Aggression Paradigm is an interpersonal, competitive social interaction task (provoking vs non-provoking opponent). The contrast directly measures social processing (responses to another agent’s provocation).</td></tr>
<tr><td>27096431_analysis_1</td><td>Non aggressive reaction to non-provoking opponent &gt; aggressive reaction to provoking opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Taylor Aggression Paradigm is an interpersonal social interaction task (competition with provoking vs non-provoking opponents) and the contrast directly measures social processing (responses to opponents).</td></tr>
<tr><td>27096431_analysis_2</td><td>Won &gt; lost</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The TAP is an interactive social task (competition vs opponent). The Won&gt;Lost contrast reflects outcome in a social interaction context and thus measures social processing.</td></tr>
<tr><td>27096431_analysis_3</td><td>Lost &gt; won</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast arises from a social interaction task (Taylor Aggression Paradigm) comparing losing vs winning against an opponent; it measures social processing of interactions/outcomes and responses to provocation.</td></tr>
<tr><td>27096431_analysis_4</td><td>Won against the provoking opponent &gt; won against the non-provoking opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The TAP is a social interaction (competitive) task; the contrast compares outcomes against a provoking vs non‑provoking opponent, which indexes social interaction/perception and response to social cues (provocation). Satisfies I1 (social task) and I2 (measures social processing).</td></tr>
<tr><td>27096431_analysis_5</td><td>Won against the non-provoking opponent &gt; won against the provoking opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task is a social interaction paradigm (Taylor Aggression Paradigm) involving interaction with provoking vs non-provoking opponents and measures social processing (perception of provocation and retaliatory behavior).</td></tr>
<tr><td>27096431_analysis_6</td><td>Lost against the provoking opponent &gt; lost against the non-provoking opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task is a social interaction paradigm (Taylor Aggression Paradigm) contrasting provoking vs non-provoking opponents; the contrast measures neural responses to social provocation/interaction, satisfying both I1 and I2.</td></tr>
<tr><td>27096431_analysis_7</td><td>Lost against the non-provoking opponent &gt; lost against the provoking opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>TAP is an interactive social task contrasting responses to a provoking vs non‑provoking opponent; the contrast measures social processing of interpersonal provocation/outcome, satisfying both criteria.</td></tr>
<tr><td>27096431_analysis_8</td><td>Retaliation independent of opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The TAP is an interactive social task involving opponents and provocation; the analysis measures social processing (retaliatory behavior in response to a social opponent).</td></tr>
<tr><td>27096431_analysis_9</td><td>Retaliation interacting with provoking opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task is a social interaction (Taylor Aggression Paradigm) contrasting provoking vs non‑provoking opponent and measures participants’ responses to social provocation—thus assesses social processing.</td></tr>
<tr><td>27096431_analysis_10</td><td>Retaliation interacting with non-provoking opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The TAP is an interpersonal competitive interaction; the contrast (&#x27;Retaliation interacting with non-provoking opponent&#x27;) involves social interaction and behavioral responses to opponents, satisfying social-related task and measurement of social processing.</td></tr>
<tr><td>27096431_analysis_11</td><td>Won</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The TAP is an interactive social task (provoking vs non-provoking opponent) measuring social interaction and retaliation; the analysis explicitly examines behavior during social interaction and parametric modulation by aggression, satisfying both criteria.</td></tr>
<tr><td>27096431_analysis_12</td><td>Won against provoking opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The TAP is a social interaction (competition with provoking vs non-provoking opponents). The contrast &#x27;won against provoking opponent&#x27; occurs in a social context and measures behavior/outcomes during social interaction, satisfying I1 (social task) and I2 (measures social processing).</td></tr>
<tr><td>27096431_analysis_13</td><td>Won against non-provoking opponent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The Taylor Aggression Paradigm is an interactive social task (competition with provoking vs non-provoking opponents). The contrast &#x27;Won against non-provoking opponent&#x27; is derived from a social interaction and reflects social processing in an interpersonal context.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>27096431_1</td><td>Aggressive reaction to provoking opponent &gt; non aggressive reaction to non-provoking opponent; others</td><td>27096431_analysis_0</td><td>Aggressive reaction to provoking opponent &gt; non aggressive reaction to non-provoking opponent</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27096431_2</td><td>Lost &gt; Won; others</td><td>27096431_analysis_3</td><td>Lost &gt; won</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27096431_3</td><td>Lost against the non-provoking opponent &gt; lost against the provoking opponent; others</td><td>27096431_analysis_7</td><td>Lost against the non-provoking opponent &gt; lost against the provoking opponent</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27096431_4</td><td>Non aggressive reaction to non-provoking opponent &gt; aggressive reaction to provoking opponent; others</td><td>27096431_analysis_1</td><td>Non aggressive reaction to non-provoking opponent &gt; aggressive reaction to provoking opponent</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27096431_5</td><td>Retaliation independent of opponent; others</td><td>27096431_analysis_8</td><td>Retaliation independent of opponent</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27096431_6</td><td>Retaliation interacting with non-provoking opponent; others</td><td>27096431_analysis_10</td><td>Retaliation interacting with non-provoking opponent</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27096431_7</td><td>Retaliation interacting with provoking opponent; others</td><td>27096431_analysis_9</td><td>Retaliation interacting with provoking opponent</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27096431_8</td><td>Won &gt; Lost; others</td><td>27096431_analysis_2</td><td>Won &gt; lost</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 27236373</strong> | Pred included: 8 | Manual included (accepted matches only): 6 | Correct overlaps: 6 | Match statuses: accepted=6, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/27236373/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>27236373_analysis_0</td><td>Time-point 2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast (SocAdj &gt; PhyConf) contrasts social scenarios requiring contextual adjustment with physical scenarios and is a classical Theory of Mind/localizer contrast—measures social processing (understanding others&#x27; mental states).</td></tr>
<tr><td>27236373_analysis_1</td><td>Response period</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Contrast SocAdj &gt; PhyConf isolates social (Theory of Mind) processing; task explicitly manipulates social inferences and contextual adjustments, meeting both inclusion criteria.</td></tr>
<tr><td>27236373_analysis_2</td><td>Time-point 1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The REMICS task includes Social (Soc) scenarios and contrasts (Soc&gt;Phy) at Time-point 1 assessing Theory-of-Mind/social representations—this measures social processing.</td></tr>
<tr><td>27236373_analysis_3</td><td>Time-point 2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The REMICS task explicitly manipulates social scenarios and measures Theory-of-Mind (mental state inference) and context-based social processing, so it satisfies social processing criteria.</td></tr>
<tr><td>27236373_analysis_4</td><td>Response period</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>REMICS Response period contrasts involve Theory of Mind/social inference tasks (social vs physical scenarios, SocAdj etc.) and measure social processing (mentalizing).</td></tr>
<tr><td>27236373_analysis_5</td><td>Time-point 2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The REMICS task manipulates social (Soc) versus physical scenarios and explicitly measures Theory of Mind (inferring others&#x27; mental states) and contextualized social inferences, satisfying both social-related task and measurement of social processing.</td></tr>
<tr><td>27236373_analysis_6</td><td>Response period</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The REMICS task is explicitly a Theory of Mind (ToM) social inference task contrasting Social vs Physical scenarios and social adjustments; the Response period contrasts (e.g., SocAdj &gt; PhyConf, Soc &gt; Phy) directly measure social processing/mentalizing.</td></tr>
<tr><td>27236373_analysis_7</td><td>analysis_7</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The REMICS task directly probes Theory of Mind / mentalizing (social inference about others) and contrasts social vs. physical scenarios and context-based social adjustments, satisfying social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>27236373_1</td><td>Adj &gt; Conf, Response Period; others</td><td>27236373_analysis_6</td><td>Response period</td><td>0.714</td><td>1.000</td><td>0.914</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27236373_2</td><td>Soc &gt; Phy, Response Period; others</td><td>27236373_analysis_4</td><td>Response period</td><td>0.732</td><td>1.000</td><td>0.920</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27236373_3</td><td>Soc &gt; Phy, Time-Point 1; others</td><td>27236373_analysis_2</td><td>Time-point 1</td><td>0.686</td><td>1.000</td><td>0.906</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27236373_4</td><td>Soc &gt; Phy, Time-Point 2; others</td><td>27236373_analysis_3</td><td>Time-point 2</td><td>0.686</td><td>1.000</td><td>0.906</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27236373_5</td><td>SocAdj &gt; PhyConf, Response Period; others</td><td>27236373_analysis_1</td><td>Response period</td><td>0.625</td><td>1.000</td><td>0.887</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27236373_6</td><td>SocAdj &gt; PhyConf, Time-Point 2; others</td><td>27236373_analysis_0</td><td>Time-point 2</td><td>0.571</td><td>1.000</td><td>0.871</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 27375449</strong> | Pred included: 7 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/27375449/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>27375449_analysis_0</td><td>Angry &gt; Joyful session</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves watching actors exhibiting emotional (angry vs joyful) social behaviors; contrasts explicitly probe perception and interpretation of others in social contexts and connectivity underlying social processing.</td></tr>
<tr><td>27375449_analysis_1</td><td>Grasping &gt; Faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task involves watching actors grasp objects with emotional facial expressions (angry/joyful); this is clearly a social-related task probing perception/interpretation of others and social-emotional context. The Grasping &gt; Faces contrast derives from this social task and measures social processing.</td></tr>
<tr><td>27375449_analysis_2</td><td>Faces &gt; Grasping</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves viewing others’ actions and emotions (faces vs. grasping) and the contrast assesses social perception of others; satisfies both social-related task and measurement of social processing.</td></tr>
<tr><td>27375449_analysis_3</td><td>Interaction analysis between grasping and neutral grasping</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves observing others’ actions and emotional expressions (angry vs joyful grasping), measuring perception and interpretation of social information—meets social processing criteria.</td></tr>
<tr><td>27375449_analysis_4</td><td>Angry &gt; Joyful run</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves viewing actors’ emotions and actions (angry vs joyful contexts) and examines perception/processing of others’ emotional social cues and responses (insula and STG connectivity). Satisfies social processing.</td></tr>
<tr><td>27375449_analysis_5</td><td>Angry grasping &gt; Joyful grasping</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast compares observing others grasping objects with angry vs joyful expressions, which is a social task involving perception and interpretation of others’ emotional and action cues. It directly measures social processing (emotion/context effects on social perception and connectivity).</td></tr>
<tr><td>27375449_analysis_6</td><td>PPI: seed in the right Insula</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves observing others’ emotional actions (angry vs. joyful contexts); the contrast (angry vs joyful) explicitly measures social processing of others’ emotions and social context effects.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>27375449_1</td><td>Angry &gt; Joyful session; socialcommunication</td><td>27375449_analysis_0</td><td>Angry &gt; Joyful session</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27375449_2</td><td>Faces &gt; Grasping; socialcommunication</td><td>27375449_analysis_2</td><td>Faces &gt; Grasping</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27375449_3</td><td>Grasping &gt; Faces; socialcommunication</td><td>27375449_analysis_1</td><td>Grasping &gt; Faces</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27375449_4</td><td>Interaction analysis between grasping and neutral grasping; socialcommunication</td><td>27375449_analysis_3</td><td>Interaction analysis between grasping and neutral grasping</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 27477020</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/27477020/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>27477020_analysis_0</td><td>S-performance</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task manipulates cooperation vs competition and examines how self and other ability estimates and neural representations interact—this is a social-processing task and the analysis measures social processing (self/other representations and interaction).</td></tr>
<tr><td>27477020_analysis_1</td><td>O-performance</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task centers on cooperation and competition and examines self-other merging, neural signals related to social cognition (area 9, pgACC); therefore it measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>27477020_1</td><td>O-performance &gt; S - performance; others</td><td>27477020_analysis_1</td><td>O-performance</td><td>0.591</td><td>1.000</td><td>0.877</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27477020_2</td><td>S-performance &gt; O - performance; others</td><td>27477020_analysis_0</td><td>S-performance</td><td>0.591</td><td>1.000</td><td>0.877</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 27494142</strong> | Pred included: 6 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/27494142/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>27494142_analysis_0</td><td>CC-A</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is a social Prisoner’s Dilemma measuring neural responses to cooperation vs other outcomes; it directly assesses social processing.</td></tr>
<tr><td>27494142_analysis_1</td><td>A-CC</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis uses a Prisoner’s Dilemma cooperation task and contrasts mutual cooperation (CC) vs other outcomes, directly measuring social processing of interactions and social reward.</td></tr>
<tr><td>27494142_analysis_2</td><td>Gain-Loss</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task is a social interaction (Prisoner’s Dilemma) probing neural responses to cooperation vs other outcomes, directly measuring social processing.</td></tr>
<tr><td>27494142_analysis_3</td><td>Loss-Gain</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task is a social one-shot Prisoner’s Dilemma examining responses to mutual cooperation vs other outcomes; this directly measures social processing (perception, evaluation, and interaction).</td></tr>
<tr><td>27494142_analysis_4</td><td>(CC-A) Gain - (CC-A) Loss</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis uses a one-shot Prisoner’s Dilemma cooperation task and contrasts mutual cooperation (CC) with other outcomes, directly indexing social interaction and processing of social outcomes (reward from cooperation). This satisfies I1 (social-related task) and I2 (measures Social Processing).</td></tr>
<tr><td>27494142_analysis_5</td><td>(CC-A) Loss - (CC-A) Gain</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task is a social one-shot Prisoner’s Dilemma probing cooperation; contrasts examine neural responses to mutual cooperation and Outcome×Context interactions, directly measuring social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>27494142_1</td><td>(CC-A)Gain &gt; (CC-A)Loss; others</td><td>27494142_analysis_4</td><td>(CC-A) Gain - (CC-A) Loss</td><td>0.917</td><td>1.000</td><td>0.975</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27494142_2</td><td>A &gt; CC; others</td><td>27494142_analysis_1</td><td>A-CC</td><td>0.600</td><td>1.000</td><td>0.880</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27494142_3</td><td>CC &gt; A; others</td><td>27494142_analysis_0</td><td>CC-A</td><td>0.600</td><td>1.000</td><td>0.880</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27494142_4</td><td>Gain &gt; Loss; others</td><td>27494142_analysis_2</td><td>Gain-Loss</td><td>0.800</td><td>1.000</td><td>0.940</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 27568587</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/27568587/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> PAINFUL &gt; NON-PAINFUL and SELF PAINFUL &gt; NON-PAINFUL; others</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>27568587_analysis_0</td><td>Mentalizing with Dissimilar &gt; Similar person</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast is from a mentalizing task (estimating others&#x27; mental states) and directly measures social processing (perception/understanding of others and affiliation-related manipulations). It satisfies I1 (social-related task) and I2 (measures social processing).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>27568587_1</td><td>DISSIMILAR &gt; SIMILAR; others</td><td>27568587_analysis_0</td><td>Mentalizing with Dissimilar &gt; Similar person</td><td>0.667</td><td>1.000</td><td>0.900</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27568587_2</td><td>PAINFUL &gt; NON-PAINFUL and SELF PAINFUL &gt; NON-PAINFUL; others</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 27622781</strong> | Pred included: 5 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/27622781/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>27622781_analysis_0</td><td>Working memory maintenance</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The analysis manipulates social competition and examines neural responses (mPFC, PCC/precuneus) related to social comparison/mentalizing during working memory and feedback—this is a social-related task and the contrasts measure social processing.</td></tr>
<tr><td>27622781_analysis_1</td><td>Effect of performance parametric modulator on no competition</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The analysis specifically examines the performance parametric modulator within the no-competition (non-social) condition, not a social task or social-processing contrast; it does not measure social processing.</td></tr>
<tr><td>27622781_analysis_2</td><td>Effect of performance parametric modulator on competition</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The analysis contrasts competitive vs noncompetitive conditions and examines neural correlates of social comparison/mentalizing (mPFC, PCC) and performance-related modulators during competition — it is a social-related task and measures social processing.</td></tr>
<tr><td>27622781_analysis_3</td><td>Event‐Related Analysis at Feedback</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The analysis manipulates social competition (competition vs no competition) and examines feedback-related activation in social/mentalizing regions (mPFC, PCC/precuneus), directly measuring social processing.</td></tr>
<tr><td>27622781_analysis_4</td><td>Competition&gt;No competition</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares competitive (social) versus noncompetitive conditions during feedback and examines mentalizing/social networks (mPFC, PCC/precuneus). This is a social-related task and directly measures social processing.</td></tr>
<tr><td>27622781_analysis_5</td><td>No Competition&gt;Competition</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast manipulates social context (competition vs no competition) and probes social processing (mPFC, PCC, STS, mentalizing). Satisfies social-related task and measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>27622781_1</td><td>Competition &gt; No Competition; self</td><td>27622781_analysis_4</td><td>Competition&gt;No competition</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27622781_2</td><td>No Competition &gt; Competition; self</td><td>27622781_analysis_5</td><td>No Competition&gt;Competition</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 28477977</strong> | Pred included: 8 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/28477977/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>28477977_analysis_0</td><td>SELF minus OTHER [(SELF_No + SELF_Single + SELF_ Group) - (OTHER_No + OTHER_Single + OTHER_Group)] (Fig. 3)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is explicitly social (pseudo-interactive joke task) and the contrast (SELF minus OTHER) probes self-related social processing; it measures social processing (self vs other in social interaction).</td></tr>
<tr><td>28477977_analysis_1</td><td>Group minus No Laughter [(SELF_ Group - SELF_No) + (OTHER_ Group - OTHER_No)]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task is explicitly social (joke-telling, listener responses). The Group vs No Laughter contrast measures social processing of others&#x27; responses and social reward, satisfying both criteria.</td></tr>
<tr><td>28477977_analysis_2</td><td>Single minus No Laughter [(SELF_ Single - SELF_No) + (OTHER_Single - OTHER_No)]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is explicitly social (participant telling jokes and hearing listener responses). The Single vs No Laughter contrast measures processing of social feedback (laughter), meeting both I1 (social task) and I2 (measures social processing).</td></tr>
<tr><td>28477977_analysis_3</td><td>Group minus Single Laughter [(SELF_ Group - SELF_Single) + (OTHER_ Group - OTHER_Single)]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is explicitly social (pseudo-interactive joke task) and the contrast (Group minus Single laughter) measures processing of social feedback (laughter), so it indexes social processing.</td></tr>
<tr><td>28477977_analysis_4</td><td>[(SELF_ Group - SELF_No) - (OTHER_Group - OTHER_No)] (Fig. 4)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task is a social interaction (telling jokes and listener responses); the contrast tests self vs other and listener responses, directly indexing social processing (action-outcome contingency, social reward).</td></tr>
<tr><td>28477977_analysis_5</td><td>[(SELF_ Single - SELF_No) - (OTHER_Single - OTHER_No)]</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task is a social interaction (telling jokes, listener responses) and the contrast tests social action-outcome contingency (self vs other), i.e., social processing.</td></tr>
<tr><td>28477977_analysis_6</td><td>Physio-physiological interaction (PPI) seeded on the right auditory cortex and mPFC.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task explicitly involves social interaction (telling jokes, listener responses) and contrasts/PPI probe self-relevant vs other-relevant social processing and social reward; both inclusion criteria satisfied.</td></tr>
<tr><td>28477977_analysis_7</td><td>Physio-physiological interaction (PPI) analysis in the left auditory cortex and mPFC.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task and contrasts involve social interaction (joke telling, listener responses) and measure social processing (self vs other, listener feedback, and reward), including PPI of mPFC and auditory cortex tied to social contingency.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>28477977_1</td><td>SELFGroup−SELFNo &gt; OTHER Group–OTHERNo; socialcommunication</td><td>28477977_analysis_4</td><td>[(SELF_ Group - SELF_No) - (OTHER_Group - OTHER_No)] (Fig. 4)</td><td>0.485</td><td>1.000</td><td>0.845</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>28477977_2</td><td>group &gt; no laughter; socialcommunication</td><td>28477977_analysis_1</td><td>Group minus No Laughter [(SELF_ Group - SELF_No) + (OTHER_ Group - OTHER_No)]</td><td>0.427</td><td>1.000</td><td>0.828</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>28477977_3</td><td>group &gt; single laughter; socialcommunication</td><td>28477977_analysis_3</td><td>Group minus Single Laughter [(SELF_ Group - SELF_Single) + (OTHER_ Group - OTHER_Single)]</td><td>0.406</td><td>1.000</td><td>0.822</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>28477977_4</td><td>self &gt; other; socialcommunication</td><td>28477977_analysis_0</td><td>SELF minus OTHER [(SELF_No + SELF_Single + SELF_ Group) - (OTHER_No + OTHER_Single + OTHER_Group)] (Fig. 3)</td><td>0.271</td><td>1.000</td><td>0.781</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>28477977_5</td><td>single &gt; no laughter; socialcommunication</td><td>28477977_analysis_2</td><td>Single minus No Laughter [(SELF_ Single - SELF_No) + (OTHER_Single - OTHER_No)]</td><td>0.450</td><td>1.000</td><td>0.835</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 28504911</strong> | Pred included: 5 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/28504911/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>28504911_analysis_0</td><td>Select &gt; content</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The select &gt; content contrast engages self- and social-cognition processes; authors report activation in social-cognition ROIs for select &gt; content, so the analysis measures social processing.</td></tr>
<tr><td>28504911_analysis_1</td><td>Share &gt; content</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The &#x27;share &gt; content&#x27; contrast directly probes social processing: decisions about sharing with others (broadcast or narrowcast) engage social-cognition ROIs and reflect social-oriented cognition. This satisfies both performing a social-related task and measuring social processing.</td></tr>
<tr><td>28504911_analysis_2</td><td>Share &gt; select</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares sharing (a social act) versus selecting and the paper reports activation in social-cognition ROIs; the task is explicitly social (sharing with others), so it measures social processing.</td></tr>
<tr><td>28504911_analysis_3</td><td>Select</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The &#x27;select&#x27; contrast (select &gt; content) involves judgments about reading for oneself and the study explicitly reports activation in social-processing ROIs (self-related and social-cognition regions). The task and contrast therefore measure social-related processing (perception/understanding of self and engagement of social-cognition regions).</td></tr>
<tr><td>28504911_analysis_4</td><td>Share</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task explicitly involved social considerations (deciding to share articles with others) and the analysis measured social processing (social-cognition ROIs, contrasts share &gt; content and share &gt; select).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>28504911_1</td><td>Select &gt; content; others</td><td>28504911_analysis_0</td><td>Select &gt; content</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>28504911_2</td><td>Share &gt; content; others</td><td>28504911_analysis_1</td><td>Share &gt; content</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>28504911_3</td><td>Share &gt; select; others</td><td>28504911_analysis_2</td><td>Share &gt; select</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 28905269</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/28905269/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>28905269_analysis_0</td><td>Regions with increased activation for monogamous men compared to non-monogamous men for the romantic &gt; neutral contrast</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task uses romantic images and compares romantic &gt; neutral responses between monogamous and non-monogamous men, which probes social processes related to affiliation/pair-bonding. This satisfies both I1 (social-related task) and I2 (measures social processing).</td></tr>
<tr><td>28905269_analysis_1</td><td>Regions with increased activation for non-monogamous men compared to monogamous men for the romantic &gt; sexual contrast</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast involves viewing romantic (couple) images and compares romantic vs sexual processing across groups, which is a social-related task probing affiliation/attachment and social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>28905269_1</td><td>monogamous men compared to nonmonogamous, romantic &gt; neutral contrast; self</td><td>28905269_analysis_0</td><td>Regions with increased activation for monogamous men compared to non-monogamous men for the romantic &gt; neutral contrast</td><td>0.723</td><td>1.000</td><td>0.917</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>28905269_2</td><td>monogamous men compared to nonmonogamous, romantic &gt; sexual contrast; self</td><td>28905269_analysis_1</td><td>Regions with increased activation for non-monogamous men compared to monogamous men for the romantic &gt; sexual contrast</td><td>0.688</td><td>1.000</td><td>0.906</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29039129</strong> | Pred included: 2 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29039129/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29039129_analysis_0</td><td>Incongruent vs. Congruent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The IAT used target categories ‘monogamy’ and ‘adultery’ and the contrast Incongruent vs. Congruent indexes implicit social attitudes and conflict about romantic/relationship content — a social-processing task; therefore it meets both criteria.</td></tr>
<tr><td>29039129_analysis_1</td><td>Congruent vs. Incongruent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The IAT contrast (incongruent vs. congruent) probes implicit attitudes about monogamy vs. adultery and the study examines regulation of interest in extra‑pair relationships—clearly a social task assessing social processing about relationships.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29039129_1</td><td>Incongruent &gt; Congruent; socialcommunication</td><td>29039129_analysis_0</td><td>Incongruent vs. Congruent</td><td>0.917</td><td>1.000</td><td>0.975</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29097704</strong> | Pred included: 14 | Manual included (accepted matches only): 8 | Correct overlaps: 8 | Match statuses: accepted=8, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29097704/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29097704_analysis_0</td><td>FT&gt;FA</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task required judging whether stimuli were facing toward or away (social orientation) and contrasts FT&gt;FA probe social involvement; thus it is a social-related task and measures social processing.</td></tr>
<tr><td>29097704_analysis_1</td><td>FA&gt;FT</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task required participants to judge whether stimuli (PLD and HL walkers) were facing toward or away, probing perception of social involvement and social cues; the FA&gt;FT contrast measures social processing of potential social involvement.</td></tr>
<tr><td>29097704_analysis_2</td><td>HL&gt;PLD</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task requires judging facing approach/away of human-like and point-light walkers and examines neural responses in mirror and mentalizing systems—clearly a social-processing task assessing perception/interpretation of others.</td></tr>
<tr><td>29097704_analysis_3</td><td>PLD&gt;HL</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task requires judging orientation and potential for social involvement of agents (PLD vs HL), which is a social-processing task; the contrast measures social processing (PLD&gt;HL).</td></tr>
<tr><td>29097704_analysis_4</td><td>STIMULUS*DIRECTION</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task required participants to judge whether observed walkers (PLD or HL) were facing toward or away, manipulating potential for social involvement; contrasts directly probe social processing (perception of social cues, social involvement).</td></tr>
<tr><td>29097704_analysis_5</td><td>POST-HOC ANALYSIS</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task required participants to judge orientation (facing toward/away) of biological agents and the study explicitly examines neural responses to potential for social involvement, engaging mirror and mentalizing systems.</td></tr>
<tr><td>29097704_analysis_6</td><td>FT_PLD&gt;HL</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task explicitly required participants to judge whether stimuli (PLD and HL) were facing towards or away, manipulating potential for social involvement; contrast involves social perception processing, so it meets I1 and I2.</td></tr>
<tr><td>29097704_analysis_7</td><td>FT_HL&gt;PLD</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task required participants to judge whether human-like and point-light walkers were facing toward or away, which assesses perception of social cues and potential for social involvement—measures Social Processing.</td></tr>
<tr><td>29097704_analysis_8</td><td>FA_PLD&gt;HL</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves perceiving and interpreting social cues (facing towards/away, potential for social involvement) and contrasts probe social processing (PLD vs HL; FT vs FA).</td></tr>
<tr><td>29097704_analysis_9</td><td>FA_HL&gt;PLD</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task required participants to judge-facing towards/away (social orientation) and contrasts probe social processing (mirror/mentalizing systems). Matches social processing inclusion criteria.</td></tr>
<tr><td>29097704_analysis_10</td><td>PLD_FT&gt;FA</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task required participants to judge whether observed agents (PLD) were facing toward or away — a social perception task assessing potential for social involvement. The contrast examines social processing of others’ motion (PLD FT vs FA).</td></tr>
<tr><td>29097704_analysis_11</td><td>PLD_FA&gt;FT</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task required participants to judge approach vs. away of biological/human-like stimuli and manipulated potential for social involvement; this is a social-related task and directly measures social processing.</td></tr>
<tr><td>29097704_analysis_12</td><td>HL_FT&gt;FA</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task required participants to judge whether observed human-like walkers were facing towards or away — a social-related task probing perception of social involvement; the HL_FT&gt;FA contrast measures social processing related to potential for social interaction.</td></tr>
<tr><td>29097704_analysis_13</td><td>HL_FA&gt;FT</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task and contrast involve perceiving others (HL stimuli) and their potential for social involvement (facing towards vs away), meeting both I1 (social-related task) and I2 (measures social processing).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29097704_1</td><td>FA &gt; FT; others</td><td>29097704_analysis_1</td><td>FA&gt;FT</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29097704_2</td><td>FA_HL &gt; PLD; others</td><td>29097704_analysis_9</td><td>FA_HL&gt;PLD</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29097704_3</td><td>FA_PLD &gt; HL; others</td><td>29097704_analysis_8</td><td>FA_PLD&gt;HL</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29097704_4</td><td>HL &gt; PLD; others</td><td>29097704_analysis_2</td><td>HL&gt;PLD</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29097704_5</td><td>HL_FT &gt; FA; others</td><td>29097704_analysis_12</td><td>HL_FT&gt;FA</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29097704_6</td><td>PLD &gt; HL; others</td><td>29097704_analysis_3</td><td>PLD&gt;HL</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29097704_7</td><td>PLD_FA &gt; FT; others</td><td>29097704_analysis_11</td><td>PLD_FA&gt;FT</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29097704_8</td><td>Stimulus*Direction; others</td><td>29097704_analysis_4</td><td>STIMULUS*DIRECTION</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29221830</strong> | Pred included: 4 | Manual included (accepted matches only): 6 | Correct overlaps: 4 | Match statuses: accepted=6, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29221830/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29221830_analysis_0</td><td>Collaborative &gt; Arbitrary</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares retrieval of collaboratively learned labels (socially encoded) versus arbitrary labels and the paper explicitly links collaborative retrieval to theory-of-mind/social-cognition regions; thus it measures social processing.</td></tr>
<tr><td>29221830_analysis_1</td><td>Individual &gt; Arbitrary</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Although the fMRI task is a communicative game, the Individual &gt; Arbitrary contrast isolates retrieval of self-generated (semantic) labels and produced activations in left angular gyrus and temporal poles (semantic network), not core social/ToM regions. Thus the contrast does not measure social processing per the annotation&#x27;s second inclusion criterion.</td></tr>
<tr><td>29221830_analysis_2</td><td>Collaborative &gt; Individual</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares retrieval of collaboratively vs individually learned labels from a communicative/collaborative task and authors report engagement of theory-of-mind/social cognition regions (mPFC, TPJ, precuneus). This is a social processing task and the contrast measures social processing.</td></tr>
<tr><td>29221830_analysis_3</td><td>Arbitrary &gt; Individual</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>The contrast is Arbitrary &gt; Individual, comparing retrieval of arbitrarily learned vs self-generated labels. Although the fMRI task was a communicative game, this specific contrast targets memory/hippocampal differences rather than social processing (the Collaborative &gt; Individual contrast would index social processes). Therefore it does not meet the requirement to measure Social Processing (I2).</td></tr>
<tr><td>29221830_analysis_4</td><td>Individual &gt; Collaborative</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast compares collaboratively vs individually learned labels within a referential communication task that engages social cognition (mentalizing/theory of mind). This is a social-related task and the contrast measures social processing differences between conditions.</td></tr>
<tr><td>29221830_analysis_5</td><td>Arbitrary &gt; Collaborative</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task involves collaborative communicative encoding and retrieval and the contrast distinguishes collaboratively learned (social) vs arbitrarily learned (non-social) labels; the analysis targets theory-of-mind/social cognition regions, so it measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29221830_1</td><td>Arbitrary &gt; Collaborative; socialcommunication</td><td>29221830_analysis_5</td><td>Arbitrary &gt; Collaborative</td><td>1.000</td><td>0.946</td><td>0.962</td><td>accepted</td><td>high_coord_match</td></tr><tr><td>29221830_2</td><td>Arbitrary &gt; Individual; socialcommunication</td><td>29221830_analysis_3</td><td>Arbitrary &gt; Individual</td><td>1.000</td><td>0.979</td><td>0.985</td><td>accepted</td><td>high_coord_match</td></tr><tr><td>29221830_3</td><td>Collaborative &gt; Arbitrary; socialcommunication</td><td>29221830_analysis_0</td><td>Collaborative &gt; Arbitrary</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29221830_4</td><td>Collaborative &gt; Individual; socialcommunication</td><td>29221830_analysis_2</td><td>Collaborative &gt; Individual</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29221830_5</td><td>Individual &gt; Arbitrary; socialcommunication</td><td>29221830_analysis_1</td><td>Individual &gt; Arbitrary</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29221830_6</td><td>Individual &gt; Collaborative; socialcommunication</td><td>29221830_analysis_4</td><td>Individual &gt; Collaborative</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29324862</strong> | Pred included: 7 | Manual included (accepted matches only): 7 | Correct overlaps: 7 | Match statuses: accepted=7, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29324862/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29324862_analysis_0</td><td>Partnering</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis examines interpersonal joint action (leading, following, mutual) with haptic communication and reports engagement of mentalizing/social networks (mPFC, TPJ, pSTS), so it is a social-processing task measuring social cognition and interaction.</td></tr>
<tr><td>29324862_analysis_1</td><td>Leading &gt; Conjunction</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is explicitly a two-person joint-action paradigm (leading vs. following) involving interpersonal interaction and social cognition. The &#x27;Leading &gt; Conjunction&#x27; contrast isolates role-specific activity within a social interaction context, so it measures social processing.</td></tr>
<tr><td>29324862_analysis_2</td><td>Following &gt; Conjunction</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Following contrast isolates role-related social interaction (partnered haptic joint action) and engages social-cognitive/mentalizing and social-perception areas (pSTS, TPJ, mPFC, ventral ACC), meeting both I1 (social task) and I2 (measures social processing).</td></tr>
<tr><td>29324862_analysis_3</td><td>Mutual &gt; Conjunction</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The Mutual condition is a social interaction task (paired joint action) and the contrast isolates mutual interaction which engages mentalizing and social-reward networks; thus it measures social processing.</td></tr>
<tr><td>29324862_analysis_4</td><td>Improvisation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is a two-person joint-action paradigm (leading, following, mutual) involving social interaction, mentalizing and interpersonal coordination; contrasts explicitly probe social processing networks (TPJ, mPFC, pSTS) and partner-related conditions.</td></tr>
<tr><td>29324862_analysis_5</td><td>Self-initiation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is a two-person joint-action paradigm (partnered Leading/Following/Mutual) and the contrast taps self- versus externally-oriented processing in a social interaction context. Thus it is a social-related task and the contrast measures social-processing relevant constructs (self vs other orientation during interaction).</td></tr>
<tr><td>29324862_analysis_6</td><td>Joint improvisation.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task is explicitly social (two-person joint action with leader/follower/mutual roles) and the contrasts probe social processing (mentalizing network, social reward, perception of partner’s actions).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29324862_1</td><td>Following &gt; Conjunction; others</td><td>29324862_analysis_2</td><td>Following &gt; Conjunction</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29324862_2</td><td>Leading + Following + Mutual &gt; Solo + Alone); others</td><td>29324862_analysis_0</td><td>Partnering</td><td>0.148</td><td>1.000</td><td>0.744</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>29324862_3</td><td>Leading + Solo &gt; Mutual + Alone; others</td><td>29324862_analysis_4</td><td>Improvisation</td><td>0.182</td><td>1.000</td><td>0.755</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>29324862_4</td><td>Leading &gt; Conjunction; others</td><td>29324862_analysis_1</td><td>Leading &gt; Conjunction</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29324862_5</td><td>Leading &gt; Solo; others</td><td>29324862_analysis_6</td><td>Joint improvisation.</td><td>0.294</td><td>1.000</td><td>0.788</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>29324862_6</td><td>Mutual &gt; Conjunction; others</td><td>29324862_analysis_3</td><td>Mutual &gt; Conjunction</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29324862_7</td><td>[Leading + Solo + Mutual + Alone] &gt; Following; others</td><td>29324862_analysis_5</td><td>Self-initiation</td><td>0.233</td><td>1.000</td><td>0.770</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29432769</strong> | Pred included: 11 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=1, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29432769/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29432769_analysis_0</td><td>Self- vs. Celebrity-judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task explicitly involves social judgments (self, friend, celebrity) and the contrast Self vs Celebrity measures self-related social processing. Satisfies I1 (social-related task) and I2 (measures Social Processing).</td></tr>
<tr><td>29432769_analysis_1</td><td>Friend- vs. Celebrity-judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task involves explicit social judgments about self, a friend (close other), and a celebrity; contrasts (self vs. celebrity, friend vs. celebrity) directly measure social processing (self- and other-referential social cognition).</td></tr>
<tr><td>29432769_analysis_2</td><td>Modulation effect of Interdependence</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task required judgments about self and others (self, friend, celebrity) and analyses examine neural responses to self- and other-referential processing—meets social-related task and measures social processing.</td></tr>
<tr><td>29432769_analysis_3</td><td>Self- vs. Celebrity-judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast Self vs. Celebrity directly measures social processing (self-related versus other person-related judgments). It fits both inclusion criteria: it is a social-related task and the contrast measures social processing.</td></tr>
<tr><td>29432769_analysis_4</td><td>Friend- vs. Celebrity-judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Contrast uses friend vs. celebrity judgments in a social role task assessing processing of social information about persons; meets I1 (social-related task) and I2 (measures Social Processing).</td></tr>
<tr><td>29432769_analysis_5</td><td>Functional connectivity</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involved self- and other-related social role judgments and contrasts (self vs. celebrity, friend vs. celebrity) that measure social processing.</td></tr>
<tr><td>29432769_analysis_6</td><td>Self- vs. Celebrity-judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves self-, friend-, and celebrity-judgments of social roles—clearly measures social processing (self/other perception).</td></tr>
<tr><td>29432769_analysis_7</td><td>Friend- vs. Celebrity-judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task is a social role judgment (self, friend, celebrity) and the contrast (Friend vs. Celebrity; Self vs. Celebrity) measures social cognition/self–other processing, satisfying both criteria.</td></tr>
<tr><td>29432769_analysis_8</td><td>Modulation effect of Interdependence</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task is explicitly social (self, friend, celebrity judgments) and contrasts (self vs. celebrity; friend vs. celebrity) measure social processing broadly (self/other representation).</td></tr>
<tr><td>29432769_analysis_9</td><td>Self- vs. Celebrity-judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast is from a social-role judgment task (Self vs Celebrity), which directly probes social cognition and self/other representations, satisfying both that it is a social task and measures social processing.</td></tr>
<tr><td>29432769_analysis_10</td><td>Friend- vs. Celebrity-judgments</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Friend vs. Celebrity judgments are a social task probing perception/understanding of others and social processing (close other vs. public other). The contrast directly measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29432769_1</td><td>Friend vs Celebrity; others</td><td>29432769_analysis_1</td><td>Friend- vs. Celebrity-judgments</td><td>0.760</td><td>0.500</td><td>0.578</td><td>uncertain</td><td>coord_count_mismatch</td></tr><tr><td>29432769_2</td><td>Self vs Celebrity; self</td><td>29432769_analysis_3</td><td>Self- vs. Celebrity-judgments</td><td>0.739</td><td>0.800</td><td>0.782</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29582502</strong> | Pred included: 6 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29582502/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29582502_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task is an iterated prisoner&#x27;s dilemma and contrasts (competitive vs cooperative) probe Theory of Mind and social decision-making, directly measuring social processing.</td></tr>
<tr><td>29582502_analysis_1</td><td>Competitive&gt;Cooperative</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task is a social decision-making (modified prisoner&#x27;s dilemma) comparing competitive vs cooperative partners; the contrast assays Theory of Mind/social processing. Satisfies I1 (social task) and I2 (measures social processing).</td></tr>
<tr><td>29582502_analysis_2</td><td>Cooperative&gt;Competitive</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task is an interactive prisoner&#x27;s dilemma probing Theory of Mind and social decision-making (competitive vs cooperative partners), directly measuring social processing.</td></tr>
<tr><td>29582502_analysis_3</td><td>Competitive&gt;Cooperative</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The COMP&gt;COOP contrast is from a social decision-making task (iterated prisoner&#x27;s dilemma) that probes processing of others&#x27; intentions and social interaction; it clearly measures social processing (Theory of Mind, detection of noncooperation).</td></tr>
<tr><td>29582502_analysis_4</td><td>Early phase Competitive&gt;Cooperative</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task is a social decision‐making (iterated prisoner&#x27;s dilemma) examining Theory of Mind (rTPJ) and responses to others’ intentions — meets both I1 and I2.</td></tr>
<tr><td>29582502_analysis_5</td><td>Dynamic ToM‐Value Competitive&gt;Cooperative</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task is an interpersonal prisoner&#x27;s dilemma and contrast (competitive &gt; cooperative) assesses Theory of Mind and social decision-making—clearly social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29582502_1</td><td>Competitive &gt; Cooperative; others</td><td>29582502_analysis_3</td><td>Competitive&gt;Cooperative</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29582502_2</td><td>Cooperative &gt; Competitive; others</td><td>29582502_analysis_2</td><td>Cooperative&gt;Competitive</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29582502_3</td><td>Dynamic ToM-Value Competitive &gt; Cooperative; others</td><td>29582502_analysis_5</td><td>Dynamic ToM‐Value Competitive&gt;Cooperative</td><td>0.977</td><td>1.000</td><td>0.993</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29582502_4</td><td>Early phase Competitive &gt; Cooperative; others</td><td>29582502_analysis_4</td><td>Early phase Competitive&gt;Cooperative</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29740753</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29740753/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29740753_analysis_0</td><td>Main effect of modality</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task explicitly involves perceiving and judging others’ emotions from facial and vocal expressions, which is core social processing (emotion perception).</td></tr>
<tr><td>29740753_analysis_1</td><td>Main effect of emotion</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The task required participants to perceive and judge emotional expressions (faces, voices, bimodal), which is social processing (perception/understanding of others&#x27; emotions). Satisfies I1 (social-related task) and I2 (measures social processing).</td></tr>
<tr><td>29740753_analysis_2</td><td>3 (Emotion)×3 (Modality) interaction</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task required participants to perceive and judge others’ emotional expressions (facial, vocal, bimodal), which is social processing. The analysis (Emotion × Modality interaction) measures neural responses during social/emotion perception.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29740753_1</td><td>Emotion &gt; Modality; socialcommunication</td><td>29740753_analysis_1</td><td>Main effect of emotion</td><td>0.350</td><td>1.000</td><td>0.805</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>29740753_2</td><td>Modality &gt; Emotion; socialcommunication</td><td>29740753_analysis_0</td><td>Main effect of modality</td><td>0.390</td><td>1.000</td><td>0.817</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>29740753_3</td><td>Modality X Emotion; socialcommunication</td><td>29740753_analysis_2</td><td>3 (Emotion)×3 (Modality) interaction</td><td>0.519</td><td>1.000</td><td>0.856</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29777673</strong> | Pred included: 7 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29777673/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29777673_analysis_0</td><td>SA vs. SC</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves self-evaluation and endorsement of others’ evaluations (social feedback)—clearly a social processing task. The SA vs. SC contrast compares agentic vs. communal trait processing, which measures social processing.</td></tr>
<tr><td>29777673_analysis_1</td><td>SC vs. SA</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task involves self-evaluation and endorsement of others’ evaluations (socially relevant processing about the self and others), meeting criteria for a social-related task and measuring social processing.</td></tr>
<tr><td>29777673_analysis_2</td><td>OA vs. OC</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast OA vs OC examines endorsement of others’ agentic vs communal evaluations of the self — a social task involving perception and processing of social feedback and self/other perspective. This satisfies social processing.</td></tr>
<tr><td>29777673_analysis_3</td><td>OC vs. OA</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves self-evaluation and endorsing others&#x27; evaluations of the self — clearly social processing (perception/interpretation of social information).</td></tr>
<tr><td>29777673_analysis_4</td><td>SA vs. Fixation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task is agentic self-evaluation (self-related social cognition). This clearly involves social processing (perception/understanding of self) and thus meets both inclusion criteria.</td></tr>
<tr><td>29777673_analysis_5</td><td>dlPFC as the seed region</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The analysis examines agentic self-evaluation and dlPFC connectivity during SA vs. Fixation; this is a social-related task involving perception/understanding of the self and social evaluation, satisfying both I1 and I2.</td></tr>
<tr><td>29777673_analysis_6</td><td>Thalamus as the seed region</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The analysis uses agentic self-evaluation (SA) and related PPI connectivity during SA vs Fixation; this is a social-related task measuring perception/understanding of the self and social evaluation processes.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29777673_1</td><td>OA &gt; OC; others</td><td>29777673_analysis_2</td><td>OA vs. OC</td><td>0.750</td><td>1.000</td><td>0.925</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29777673_2</td><td>SA vs. Fixation; self</td><td>29777673_analysis_4</td><td>SA vs. Fixation</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29777673_3</td><td>SC &gt; SA; self</td><td>29777673_analysis_1</td><td>SC vs. SA</td><td>0.750</td><td>1.000</td><td>0.925</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 30077577</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/30077577/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> other&gt; control; others</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>30077577_analysis_0</td><td>self-relevant&gt;control</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task explicitly involves recalling self-relevant relationship episodes and comparing to control; this is a social-related task probing self-/other-referencing and social cognition, so it measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>30077577_1</td><td>other&gt; control; others</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>30077577_2</td><td>self-relevant &gt; control; self</td><td>30077577_analysis_0</td><td>self-relevant&gt;control</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 30272134</strong> | Pred included: 3 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/30272134/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>30272134_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The experiment assesses perception and integration of others&#x27; facial and vocal emotional expressions (fearful vs neutral), which is social processing.</td></tr>
<tr><td>30272134_analysis_1</td><td>(BIMODAL &gt; UNIMODAL FACES) ∩ (BIMODAL &gt; UNIMODAL VOICES)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis tests perception and integration of emotional expressions from faces and voices—clearly a social-related task measuring perception/understanding of others&#x27; emotions.</td></tr>
<tr><td>30272134_analysis_2</td><td>INCONGRUENT &gt; CONGRUENT</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task uses face and voice emotion recognition and integration (congruent vs incongruent), which is a social-related task measuring social processing of others&#x27; emotional signals.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>30272134_1</td><td>(Bimodal &gt; Unimodal faces) ∩ (Bimodal &gt; Unimodal Voices); socialcommunication</td><td>30272134_analysis_1</td><td>(BIMODAL &gt; UNIMODAL FACES) ∩ (BIMODAL &gt; UNIMODAL VOICES)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>30272134_2</td><td>Incongruent &gt; Congruent; socialcommunication</td><td>30272134_analysis_2</td><td>INCONGRUENT &gt; CONGRUENT</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 30649548</strong> | Pred included: 6 | Manual included (accepted matches only): 6 | Correct overlaps: 6 | Match statuses: accepted=6, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/30649548/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>30649548_analysis_0</td><td>Cooperation &gt; competition</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis uses a social-interaction hyperscanning task contrasting cooperation vs competition and explicitly models neural responses to a partner’s behavior (iBBDs), directly measuring social processing.</td></tr>
<tr><td>30649548_analysis_1</td><td>Competition &gt; cooperation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task is a two-person interactive game (cooperation vs competition) and the contrast measures interpersonal brain-behavior dependencies (iBBDs)—clearly social processing.</td></tr>
<tr><td>30649548_analysis_2</td><td>CN &gt; TB</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis uses a dual-fMRI hyperscanning interactive task (cooperation vs competition, concurrent vs turn-based) and models brain responses to a partner’s behavior (iBBDs), which is clearly social processing.</td></tr>
<tr><td>30649548_analysis_3</td><td>TB (COO &amp;gt; COM) &amp;gt; CN (COO &amp;gt; COM)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task is an interactive cooperative/competitive hyperscanning paradigm and contrasts model brain responses to a partner’s behavior (iBBDs), directly measuring social processing.</td></tr>
<tr><td>30649548_analysis_4</td><td>Builder (COO &gt; COM) &gt; Other (COO &gt; COM)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The analysis uses a social interaction (cooperation vs competition) hyperscanning task and explicitly models brain responses to a co-player’s behavior (iBBD), which measures social processing.</td></tr>
<tr><td>30649548_analysis_5</td><td>Other (COO &gt; COM) &gt; Builder (COO &gt; COM)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Task is a dual‑fMRI hyperscanning interactive game contrasting cooperation vs competition and models brain responses to a partner’s behavior — clearly a social task measuring social processing (interpersonal brain‑behavior dependencies).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>30649548_1</td><td>Builder (COO &gt; COM) &gt; Other (COO &gt; COM); affiliation</td><td>30649548_analysis_4</td><td>Builder (COO &gt; COM) &gt; Other (COO &gt; COM)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>30649548_2</td><td>CN &gt; TB; affiliation</td><td>30649548_analysis_2</td><td>CN &gt; TB</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>30649548_3</td><td>Competition &gt; Cooperation; affiliation</td><td>30649548_analysis_1</td><td>Competition &gt; cooperation</td><td>1.000</td><td>0.938</td><td>0.956</td><td>accepted</td><td>high_coord_match</td></tr><tr><td>30649548_4</td><td>Cooperation &gt; competition; affiliation</td><td>30649548_analysis_0</td><td>Cooperation &gt; competition</td><td>1.000</td><td>0.943</td><td>0.960</td><td>accepted</td><td>high_coord_match</td></tr><tr><td>30649548_5</td><td>Other (COO &gt; COM) &gt; Builder (COO &gt; COM); affiliation</td><td>30649548_analysis_5</td><td>Other (COO &gt; COM) &gt; Builder (COO &gt; COM)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>30649548_6</td><td>TB (COO &gt; COM) &gt; CN (COO &gt; COM); affiliation</td><td>30649548_analysis_3</td><td>TB (COO &amp;gt; COM) &amp;gt; CN (COO &amp;gt; COM)</td><td>0.789</td><td>1.000</td><td>0.937</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 31090126</strong> | Pred included: 5 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/31090126/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>31090126_analysis_0</td><td>Stimulus type (expression&gt;mosaic)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast (dynamic facial expressions &gt; dynamic mosaic) probes social perception of facial expressions and emotional processing; it is a social-related task measuring social processing.</td></tr>
<tr><td>31090126_analysis_1</td><td>Stimulus type (expression&gt;mosaic)emotion</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task contrasts dynamic facial expressions (social stimuli) vs nonsocial mosaics and assesses processing of social cues (emotion, facial perception); meets both social-processing inclusion criteria.</td></tr>
<tr><td>31090126_analysis_2</td><td>Stimulus type (expression&gt;mosaic)gender</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task required passive viewing of dynamic facial expressions vs mosaics, which is a social-related task measuring perception and processing of others&#x27; emotional/social cues (affect recognition, social perception). Satisfies I1 and I2.</td></tr>
<tr><td>31090126_analysis_3</td><td>Stimulus type (expression&gt;mosaic)emotiongender</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast (dynamic facial expressions vs dynamic mosaics) explicitly probes social processing — perception and interpretation of others&#x27; emotional expressions. Matches both I1 (social-related task) and I2 (measures social processing).</td></tr>
<tr><td>31090126_analysis_4</td><td>Stimulus type (expression&gt;mosaic)×laterality</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The contrast (dynamic facial expressions vs dynamic mosaics) measures processing of others’ emotional facial expressions—clearly a social processing task (perception/understanding of others), satisfying I1 and I2.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>31090126_1</td><td>(expression &gt; mosaic) × laterality; socialcommunication</td><td>31090126_analysis_4</td><td>Stimulus type (expression&gt;mosaic)×laterality</td><td>0.800</td><td>1.000</td><td>0.940</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>31090126_2</td><td>expression &gt; mosaic; socialcommunication</td><td>31090126_analysis_0</td><td>Stimulus type (expression&gt;mosaic)</td><td>0.704</td><td>0.959</td><td>0.882</td><td>accepted</td><td>coord_count_mismatch, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>
</details></section><section id="bucket-false-positive"><details class="bucket" open><summary><h2>False Positive (11)</h2></summary><p><strong>Match status totals:</strong> accepted=0 | uncertain=3 | unmatched=35</p>
<details class="doc-card">
  <summary><strong>PMID 31598216</strong> | Pred included: 7 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=2</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/31598216/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> decision-making &gt; results; socialcommunication, results &gt; decision-making; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>31598216_analysis_0</td><td>decision-making</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Prisoners&#x27; dilemma is a social task assessing cooperation/competition and social decision-making; the contrast (decision-making) measures social processing.</td></tr>
<tr><td>31598216_analysis_1</td><td>results</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The analysis used a prisoners&#x27; dilemma game and measured cooperative choices, trust ratings, and mentalizing; this is a social-related task and explicitly measures social processing.</td></tr>
<tr><td>31598216_analysis_2</td><td>PATIENTS</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The prisoners&#x27; dilemma (PDG) is a social task probing cooperative/competitive behaviour, mentalizing, and trust; the analysis directly measures social processing (decision and result phases, group differences, MPFC activation).</td></tr>
<tr><td>31598216_analysis_3</td><td>CONTROLS</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The task is a prisoners&#x27; dilemma game (cooperation/defection) and associated trustworthiness ratings—this is a social task probing social behavior and social cognition. The fMRI contrasts (decision and result phases) measure social processing.</td></tr>
<tr><td>31598216_analysis_4</td><td>main effect of group</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The analysis uses a prisoners&#x27; dilemma game and measures social behaviour, mentalizing, trust and MPFC activation differences between patients and controls—clearly a social-processing task.</td></tr>
<tr><td>31598216_analysis_5</td><td>main effect of condition</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The analysis is of a prisoners&#x27; dilemma (cooperation) fMRI task and the main effect of condition (decision vs result) measures social processing related to social behaviour/cooperation.</td></tr>
<tr><td>31598216_analysis_6</td><td>ROI-main effect of group</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The analysis used the prisoners&#x27; dilemma (a social interaction task) and reports group differences in brain activation during social decision-making, directly measuring social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>31598216_1</td><td>decision-making &gt; results; socialcommunication</td><td>31598216_analysis_0</td><td>decision-making</td><td>0.750</td><td>0.093</td><td>0.290</td><td>unmatched</td><td>coord_count_mismatch, low_coord_high_name, low_total_score</td></tr><tr><td>31598216_2</td><td>results &gt; decision-making; socialcommunication</td><td>31598216_analysis_3</td><td>CONTROLS</td><td>0.182</td><td>0.556</td><td>0.443</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  <details class="inner-accordion"><summary>PMC full text available (PMCID 6731699)</summary><p><strong>Title:</strong> Social cognition, behaviour and therapy adherence in frontal lobe epilepsy: a study combining neuroeconomic and neuropsychological methods</p><details><summary>Abstract</summary><pre class="paper-text">Social behaviour of healthy humans and its neural correlates have been extensively studied in social neuroscience and neuroeconomics. Whereas it is well established that several types of epilepsies, such as frontal lobe epilepsy, lead to social cognitive impairments, experimental evidence on how these translate into behavioural symptoms is scarce. Furthermore, it is unclear whether social cognitive or behavioural disturbances have an impact on therapy adherence, which is critical for effective disease management, but generally low in these patients. In order to investigate the relationship between social cognition, social behaviour, and therapy adherence in patients with frontal lobe epilepsies (FLE), we designed a study combining conventional neuropsychological with behavioural economic and functional magnetic resonance imaging (fMRI) methodology. Fifteen patients and 15 healthy controls played a prisoners&#x27; dilemma game (an established game to operationalize social behaviour) while undergoing fMRI. Additionally, social cognitive, basic neuropsychological variables, and therapy adherence were assessed. Our results implicate that social behaviour is indeed affected and can be quantified using neuroeconomic methods in patients with FLE. Impaired social behaviour in these patients might be a consequence of altered brain activation in the medial prefrontal cortex and play a role in low therapy adherence. Finally, this study serves as an example of how to integrate neuroeconomic methods in neurology.</pre></details><details><summary>Body</summary><pre class="paper-text">## Introduction 
  
Social cognition is a term used for several high-level cognitive functions that determine human behaviour in a social context. Several studies showed impairments of social cognition in frontal lobe epilepsies (FLE), such as Theory-of-Mind/mentalizing and facial emotion recognition [ ], as well as neuropsychiatric co-morbidities [ ], but studies quantifying social behaviour abnormalities of FLE patients in an experimental sense are scarce. Even though behaviour relies on cognitive functions, the relationship between cognition, behaviour and epilepsy variables is complex and not fully understood [ ], making it difficult to predict the impact of altered social cognition on social behaviour, and more specifically, therapy adherence in FLE. 

In neuroeconomics—the science of studying research questions in economics through the application of neuroscientific methods and theories—pro-social behaviours, such as trust or cooperation, have been extensively studied for decades, mainly through game paradigms, such as the trust game or the prisoners&#x27; dilemma game [ ]. Using this approach, several brain areas were found to play a role in pro-social behaviour of healthy humans. Crucial parts of this brain network reside in the frontal cortex such as the ventromedial frontal/orbitofrontal cortex and the anterior cingulate cortex [ ]. These discoveries have led to the adoption of economic methodology to study behaviour in neurology [ ], but to the best of our knowledge, no such study has focused on the behaviour of patients with epilepsy. 

Adherence to anti-epileptic drug therapy is critical for effective disease management. Although its measurement is difficult without a single method that has yet proved to be the gold standard [ ], therapy adherence of patients suffering from epilepsy is low (at about 30–50%) [ ]. This is unfortunate, as low therapy adherence not only leads to poorer seizure control, but also increases the risk of sudden unexpected death in epilepsy [ ]. The reasons for low therapy adherence in general are still a matter of research [ ]. Low therapy adherence seems to have a multifactorial origin with some factors being associated with neuropsychological impairments and psychiatric co-morbidities of chronic diseases [ ], and others reflecting pathophysiological changes of neural networks specifically affected in epilepsy [ ]. 

We thus designed a study combining conventional neuropsychological with neuroeconomic methods to address the following open research questions:
   
Is there a difference in social behaviour between FLE patients and healthy controls that can be experimentally operationalized? 
  
If such a difference exists, is it associated with altered social cognitive functions and their underlying frontal lobe network? 
  
Does social behaviour affect therapy adherence in FLE? 
  


## Methods 
  
### Subjects 
  
We included 15 FLE patients and 15 healthy controls. We established the following inclusion and exclusion criteria to ensure the feasibility of the study and avoid known confounders in behavioural research. 

Inclusion criteria for patients were: age between 18 and 50, right-handedness (Edinburgh handedness inventory; [ ]), no significant anxiety, depression, or obsessive-compulsive symptoms as assessed by a hospital anxiety and depression scale score (HADS) less than 10 [ ] and an obsessive compulsive inventory score (OCIS) less than 40 [ ], sufficient language skills, and a diagnosis of FLE. The latter was based either upon association between typical frontal lobe seizure semiology and existence of an epileptogenic MRI lesion within the frontal lobe or upon direct recording of seizures of frontal lobe origin during a long-term video-EEG monitoring performed in the Department of Functional Neurology and Epileptology at Hospices Civils de Lyon, France, in patients with normal MRI. Exclusion criteria included pregnancy, non-MRI suitable transplants, major perceptive impairments, non-epileptic seizures, a history of intellectual disability, other known neurological diseases, MRI-lesion outside of the frontal lobe or frontal cortical lesions larger than 1 cm in diameter, and past epilepsy or other brain surgery in order to achieve a patient sample of non-resected participants. 

Inclusion criteria for controls were: age between 18 and 50, right-handedness (Edinburgh handedness inventory; [ ]), no significant anxiety, depression, or obsessive-compulsive symptoms assessed by a HADS Score less than 10 [ ] and an OCIS less than 40 [ ] as well as sufficient language skills. Exclusion criteria were pregnancy, non-MRI suitable transplants, major perceptive impairments, medication other than contraceptives, or a history of neurological or psychiatric diseases. 


### Magnetic resonance data acquisition 
  
All images were acquired using the same MRI machine (Siemens Magneton Prisma 3 Tesla) in one session per participant. Structural MRI and shimming (to minimize field inhomogeneities) were performed on all subjects prior to gradient-echo echoplanar imaging that provided blood oxygen level dependent (BOLD) contrast. Each volume comprised 35 AC-PC aligned slices (order of acquisition: interleaved) with a thickness of 2.5 cm, field of view (FOV) 23 cm, parallel imaging parameters GRAPPA/acceleration factor 2, echo time (TE) 26 ms, repetition time (TR) 2260 ms. 


### Paradigm 
  
We designed our paradigm on the basis of similar experiments in the literature [ ] to ensure comparability. When subjects entered the laboratory for the experiment, they received written instructions explaining the prisoners&#x27; dilemma game (PDG) [ ]. In this game, two players decide at the same time whether or not to cooperate with the other player. Depending on the decisions of both players, there is a monetary pay-off, which is equal for both players in the case of mutual cooperation or defection, whereas in the case of divergent strategies, it is not existent for the cooperating player and highest for the defecting player. The pay-off structure of our version of the game is shown in  .
   
Pay-off structure of the prisoners&#x27; dilemma game. 
  

Participants were told that they would play with real money and be paid out their gain. Payment took place at the end of the experiment, but in fact, all participants received the same amount of money (40€) independent of their actual gain due to ethical considerations. The participants did not know the number of rounds played in the game, but in fact all subjects played 32 rounds. Moreover, participants (player 1) were told that they would be playing with four different human beings (two males and two females—here termed player 2) located in another room, but actually played against a computer-generated, randomized, strategy that simulated the other player&#x27;s behaviour. This means that each participant played 32 rounds with each of the four different counterparts (equals 128 decisions to cooperate or to defect in total). Player 2 was illustrated with face images from an established database (Glasgow Unfamiliar Face Database). Once installed in the MRI machine, participants first had to rate the trustworthiness of the presented player 2 on a Likert-scale between 1 and 7 (1 no trustworthiness, 7 highest possible trustworthiness) being shown a face picture of player 2. Next, the actual game began. Each round of the game consisted of 3 screens: first, the pay-off matrix of the game was shown for 2 s. Then, participants were asked to choose to either cooperate or to defect using two input buttons. After a random time interval between 4 and 6 s simulating variable decision times of player 2, the result of the round was shown for 2 s using the pay-off matrix with the result highlighted in yellow colour. After 32 rounds of the game, the face of player 2 was again shown to the participants, who had to rate the trustworthiness of the face another time in analogy to the start. Finally, the overall gain of the game was shown. See   for a visualization.
   
Visualization of the experimental paradigm. Notes: top left—visualization of the beginning and end of the paradigm, bottom right—visualization of the time period in between (corresponds to dashed line in the top left part of the figure); PDG, prisoners&#x27; dilemma game. 
  


### Demographic data, neuropsychological testing, questionnaires and pill counts 
  
We recorded the following variables in all participants via a self-report questionnaire: age, gender, profession and education. For patients, we included the number of seizures (generalized tonic-clonic seizures and other seizure types separately) in the last three months according to a seizure calendar commonly used in clinical routine and current anticonvulsive treatment (number and names of drugs, number of intakes per day, preparation of drugs for intake by the participant or by a carer) as recorded in the patient&#x27;s medical chart. 

Neuropsychological variables captured in all participants included psychomotor speed and mental flexibility (Trail Making test A and B [ ]), memory for faces and working memory (Faces subsets and numbers of the Wechsler Memory Scale, fourth edition [ ]). 

Social cognition was tested through the Reading the Mind in the Eyes test [ ] for Theory-of-Mind/mentalizing (in this test, subjects have to choose the correct word out of a list describing emotions to corresponding photos of a person&#x27;s expression of eyes) and a trust questionnaire ([ ]; French version), additionally to the trustworthiness ratings of faces during the fMRI paradigm. 

Furthermore, therapy adherence was measured in the patient group through pill counts at two consecutive visits [ ] by reviewing pill bottles of a six months period and several questionnaires comprising the Morisky adherence scale ([ , ]; validated French version), the Beliefs about Medicines Questionnaire (BMQ; [ , ]; validated French version) and the SATMED-Q (Treatment Satisfaction with Medicines Questionnaire, [ ]; French version). These questionnaires are commonly used instruments in research on therapy adherence. 


### Data analysis 
  
#### Imaging data 
  
fMRI data were analysed using SPM 12 ( ). Pre-processing involved slice time correction, realignment, normalization and smoothing with an 8 mm full width at half maximum Gaussian kernel. A general linear model with two conditions (decision phase and result phase) was estimated. No subject had to be excluded. The contrast images calculated for individual subjects were entered into a second level or random effects analysis [ ]. We first calculated   t  -tests for the two conditions (decision/result) for all participants as one group and in a second step analysed each group (patients/controls) separately in the same way. In a third step, we calculated two-sample   t  -tests between the two groups for both conditions. We then implemented a 2 × 2 repeated measures ANOVA using a flexible factorial design with the factors ‘group&#x27; (patients/controls) and ‘condition&#x27; (decision/result) to calculate main effects of group and condition as well as the interaction effect of group and condition. The resultant statistical parametric maps were thresholded using an FWE-corrected   p  -value threshold less than 0.001, reporting clusters greater than 20 voxels (  k   = 20) only. Anatomical structures of cluster maxima were labelled in Talairach space using the Talairach Client ( ). 

Based on the previous research, we   a priori   selected the following regions of interest (ROIs) for further analyses: superior, middle and inferior frontal gyri, medial and lateral orbital gyri, posterior orbital gyrus, straight gyrus, anterior cingulate gyrus, amygdala, thalamus and caudate nucleus. We used adult brain maximum probability maps (© Copyright Imperial College of Science, Technology and Medicine 2007. All rights reserved) to obtain the ROIs [ ]. 

In a subsequent step, we computed the % of BOLD signal change extracted from beta images from significant voxels from the second-level analysis within an 8 mm sphere surrounding the activation peak and calculated correlations with all other variables collected during the study. 


#### Neuropsychological and questionnaire data 
  
The statistical analysis was performed with SPSS, v. 20 and involved two-tailed, non-parametric testing (Wilcoxon test,   χ  ²-test), as well as Spearman&#x27;s rho correlations. We corrected for multiple testing using the Bonferroni–Holm procedure and chose a significance level of less than 0.05. 




## Results 
  
### Behavioural data, neuropsychological variables and questionnaires 
  
We included 15 FLE patients and 15 healthy controls. Four patients (26.67%) were seizure free, while the remaining eleven (73.33%) had a median monthly seizure frequency of 4 during a three-month period preceding the experiment. MRI was normal in nine patients (60%) and showed frontal lobe lesions—cavernoma (one patient), focal cortical dysplasia (one patient), diffuse axonal trauma (one patient), and post-haematoma scars (two patients)—in the remaining five patients (33.3%). The remaining patient had undergone skull (but not brain) surgery in childhood for craniostenosis and the current structural MRI showed no obvious pathological changes. Three patients were on monotherapy and 12 patients were under polytherapy (mean number ± s.d. of anti-epileptic drugs: 2.33 ± 0.98). Mean ± s.d. subjective (Morisky adherence scale) and objective (pill counts) measures of treatment adherence during a six-month period were 1.73 ± 0.88 (range: 0–8, lower number indicates higher adherence) and 7.00 ± 12.45 (number of prescribed pills not taken), indicating moderate level of adherence. Patients also showed high belief of treatment necessity (BMQ mean ± s.d.—necessity 21.13 ± 6.30, range: 5–25), average level of concerns and negative views regarding therapy (BMQ: concerns and harms 24.87 ± 9.36, range: 9–45; overuse 7.47 ± 3.27, range: 4–20) and an average treatment satisfaction (SATMED-Q mean ± s.d.: 65.36 ± 7.88, range: 17–85). Questionnaires capturing beliefs about medicines (  p   = 0.256), treatment satisfaction (  p   = 0.776), or adherence (  p   = 0.056) did not correlate significantly with therapy adherence measured through pill counts, although the Morisky adherence scale was close to being significant (  p   = 0.056). 

For all demographic, neuropsychological and neuroeconomic data collected in this study on both patient and control groups, please refer to  . In summary, there was no significant difference between the patient and control groups regarding age, gender, handedness, education, professional status, trust in doctors as captured by the respective questionnaire [ ], trustworthiness of game opponents, or working memory for numbers. By contrast, patients demonstrated statistically significant worse performance than controls in mentalizing measured through the Reading eyes in the mind test, memory for faces, psychomotor speed during Trail making test A, and mental flexibility performance during Trail making test B.
   
Summary of data collected on both participant groups of our study. 
    

Furthermore, there was also a significant difference in the total number of cooperative choices during the PDG, indicating higher cooperation in patients than in controls. The numbers of cooperative choices between games 1 and 4 differed significantly in both groups, indicating that cooperation decreased significantly between the first and the last game of the experiment in both groups ( ).
   
Mean numbers of cooperative choices of the patient and control groups in the four prisoners&#x27; dilemma games. 
  

Mentalizing correlated strongly with memory for faces (  r   = 0.715;   p   = 0.000) and with trust in doctors and the health system [ ] (  r   = 0.437;   p   = 0.026), showing that participants with high mentalizing abilities also better memorized faces and had higher trust in healthcare. Taken together these data supported a positive correlation between several pro-social cognition and behaviour variables. 

There was a significant positive correlation between cooperative choices in the PDG and missed medication intakes with high values representing low therapy adherence (  r   = 0.686;   p   = 0.010), indicating higher cooperative behaviour in patients with low therapy adherence. 


### Imaging results (see tables  ,   and  ) 
  
#### Voxel-based whole brain analysis 
  
 Brain activation during decision-making.   During the decision-making whether to cooperate or defect when playing the PDG, combined event-related fMRI analysis of data from all subjects (one sample   t  -test) showed significantly activated clusters in right inferior parietal lobule, left precuneus, left lingual gyrus, left insula, the middle and inferior frontal gyri bilaterally, left superior frontal gyrus, as well as the right anterior lobe of the cerebellum ( ). In controls, significant activation was observed in the right fusiform gyrus, right superior frontal gyrus, left insula and left superior temporal gyrus, while in patients, significant activation was observed in the left superior frontal gyrus, left precuneus, and left insula.
   
Visualization of brain activation of all participants (according to one sample   t  -test results reported in  ) during decision-making (yellow) and result perception (red)—thresholded at   p   &lt; 0.001, FWE-corrected,   k   = 20. 
    
Summary of analysis of all participants. FWE,   p   = 0.001. 
    
Summary of per group analyses. FWE,   p   = 0.001. 
    
Analysis of group differences and ROI. 
  

 Brain activation during result phase.   During the perception of the results of the game, combined analysis of data from all subjects (one sample   t  -test) showed activation in the inferior parietal lobules bilaterally and the right middle temporal gyrus—these results are visualized in   as well. In controls, significant activation was observed in the left middle frontal gyrus, inferior parietal lobules bilaterally, right inferior temporal gyrus, and left cingulate gyrus. In patients, significant activation was observed in both inferior parietal lobules, left superior temporal gyrus, right middle frontal gyrus, right thalamus, left insula and right precuneus. 

 Individual group comparisons for both conditions.   Two-sample   t  -tests between the patient and control groups did not yield any significant results for both conditions. 

 Integrated comparison across groups and conditions.   In the full factorial analysis, the main group effect (  F  -test) showed significant clusters in the right and left medial prefrontal cortex—Brodmann area 10 ( ). In the main effect of condition (decision-making versus result phase of the game), the following clusters were significant: right anterior lobe of the cerebellum, left precentral gyrus, right inferior frontal gyrus, right insula, left middle temporal gyrus and left superior frontal gyrus. There was no significant interaction between group and condition.
   
Difference in activation between the patient and control groups (main effect of groups,   F  -test) in the whole-brain analysis—thresholded at   p   &lt; 0.001, FWE-corrected,   k   = 20. 
  


#### Region of interest analysis 
  
ROI analysis (  F  -test) showed differences in activation between the patient and control groups in the right and left superior frontal gyrus, while the   t  -test analyses showed no significant differences. The mean % of BOLD signal changes in these ROIs in the result condition showed a significant negative correlation with initial trust (  r   = −0.448;   p   = 0.017), indicating that participants with high initial trust showed lower signal change in these brain areas during result perception. The mean % of BOLD signal changes in the choice condition also correlated significantly with differences between the initial and final trust (  r   = −0.618;   p   = 0.000; first ROI and   r   = −0.545;   p   = 0.003 for the second ROI), meaning that participants with a high decrease of trust from the beginning to the end of the games showed lower signal changes while making their choices in the game. 

Another significant correlation was detected between therapy adherence and the % BOLD signal change in the choice condition (  r   = 0.565;   p   = 0.044 for the first ROI) showing that participants with low therapy adherence had higher signal changes in this brain area. 




## Discussion 
  
In this study, we first confirmed that mentalizing is impaired in patients with FLE, as previously established [ ]. These abnormalities correlated with an altered memory for faces, a previously unreported finding in FLE, which may shed light on the mechanisms underlying dysfunction in social behaviour. Interestingly, there is evidence of frontal lobe contributions to memory for faces [ ]. Furthermore, mentalizing abilities correlated with the results of the trust in healthcare questionnaire implying an overall good correlation of pro-social cognition variables in our study. 

One of the goals of this study was to find out whether deficits in social cognition in FLE patients could lead to differences in social behaviour that can be operationalized. In fact, we showed that FLE patients behave differently from healthy controls in the PDG, but in a counterintuitive way, since they cooperated more than controls. While this finding was unexpected, we observed a frequent pattern of evolving cooperation during the game in both the patients&#x27; and controls&#x27; groups, with higher rates of cooperation in early game phases and less cooperative behaviour in the later ones [ ]. This strategy is consistent with the objective of maximizing profit. Indeed, future possible interactions encourage people to cooperate in the early phases of the game, with the hope to initiate a mutually cooperative relationship. If not reciprocated, strategy will later shift to defection in players who want to maximize their own profit [ ]. 

In this context, higher cooperation in patients might result from impaired negative feedback when cooperative behaviour is not reciprocated, especially because the ability to shift behaviour from cooperation to defection in such a case is dependent on frontal lobe functions [ ]. Alternatively, patients&#x27; behaviour could be interpreted as a preference for higher delayed rewards since higher cooperation leads to higher future profits [ ]. Although evidence on time preference for rewards (also referred to as ‘delay discounting&#x27;) in neurological patients is scarce, altered delay discounting as another behavioural symptom of neurological disorders was reported before [ ]. 

Prior functional brain imaging studies investigating cooperative behaviour through the PDG found, in essence, three brain networks to be active during the game: several frontal brain areas, especially the medial prefrontal cortex, as well as reward and limbic brain regions [ ] reflecting the cognitive functions necessary to successfully play the game, such as decision-making and reward-based learning. Our analyses of brain activation of all participants showed a similar pattern of brain areas to be active during the game. However, when looking at the patient and control group separately, controls, but not patients showed significant activation in several temporal regions during decision-making whether to cooperate or not. Interestingly, those regions have been implicated in both Theory-of-Mind and facial processing tasks (e.g. [ ]) and thus further substantiate our behavioural results of higher mentalizing and face memory abilities in the control group. During the perception of the results during the game, the cingulate gyrus, a region thought to be active in situations of cognitive conflict [ ], was significantly activated in controls, but not in patients. When opponents in an economic game do not reciprocate benevolent behaviour, this is perceived as a conflict between economic self-interest (i.e. rationality) and fairness considerations [ ]. Hypothetically, patients might have not perceived cognitive conflicts to the same extent as controls in such game results, which might also have led to higher cooperative behaviour. 

When comparing our functional imaging results between the patient and control groups on both whole-brain and ROI level, it becomes apparent that the activation of the medial prefrontal cortex (MPFC) differed significantly between the two groups during the game. The MPFC plays a pivotal role in social behaviour and decision-making [ , ], which is reflected in our results of correlating MPFC activation changes and face trustworthiness evaluations, although those have been based upon a low number of data points only. Therefore, a difference in MPFC activation between two groups showing such divergent cooperative behaviour seems plausible. Our fMRI findings do not allow us to infer the directionality of the observed difference in activation, potentially because of either the difference being based on both conditions rather than differences in activation during the individual conditions, the   t  -test comparisons between groups being underpowered, and/or the difference in activation between the groups not being sufficiently strong to pass the set threshold in the   t  -test analyses. Although a pathology-driven lower activation might seem more plausible, a compensatory higher activation is also possible [ ]. Further imaging studies are needed to address this question. 

Another goal of our study was to investigate possible links between cooperative behaviour and therapy adherence in FLE. Our results show that cooperative behaviour in the PDG correlated negatively with therapy adherence in patients (high cooperative behaviour correlating with low therapy adherence). Even though we could not find any previous literature on the relationship between cooperative behaviour and therapy adherence, there is some evidence that decision-making, in general, has effects on therapy adherence with lower decision-making skills leading to lower adherence [ ]. As we have outlined before, higher cooperation can be interpreted as lower social decision-making abilities in the context of our experiment. Thus, the inverse relation between therapy adherence and cooperative behaviour actually fits into the current scientific framework on the interaction of behaviour, decision-making and therapy adherence. Importantly, there was no correlation between questionnaire data about therapy adherence and pill counts in our study, reflecting the known difficulties in measuring adherence in epilepsy (e.g. [ ]). Moreover, the MPFC activation during the game showed a correlation with therapy adherence reflecting the close link between social cognition and therapy adherence. 

We acknowledge that our study design of comparing people with FLE to healthy controls does not allow distinguishing whether the study findings apply solely to FLE or to epilepsy in general. Looking at the published literature on other epilepsy syndromes with frontal lobe dysfunction, such as juvenile myoclonic epilepsy or genetic generalized epilepsies, it becomes apparent that patients with these types of epilepsies also show abnormalities in social functions such as Theory-of-Mind [ , ]. In our view, neuroeconomic methodology could help us to determine the behavioural consequences of these social cognitive impairments. Further studies comparing cooperative behaviour and therapy adherence between FLE and other epileptic disorders are therefore warranted. 


## Conclusion 
  
To conclude, our results implicate that (i) social behaviour is affected by FLE and (ii) can be measured using neuroeconomic methods. Impaired social behaviour in FLE might (iii) be a consequence of differing MPFC activation and (iv) might play a role in low therapy adherence. This is important as therapy adherence is difficult to measure, especially in patients with epilepsy where classical tools of measurement (e.g. questionnaires or electronic devices) have been shown to be imprecise [ ]. Integrating neuroeconomic testing of social behaviour into the neuropsychological testing routine could help to better understand therapy adherence of patients with epilepsies and consequently help to improve patient care through an identification of patients at risk. 


## Supplementary Material</pre></details></details>
  <details class="inner-accordion"><summary>Coordinate-relevant source tables (3)</summary><details class="inner-accordion"><summary>Table 3. (RSOS180850TB3) - Summary of analysis of all participants. FWE, p = 0.001.</summary><div class="table-html"><table-wrap id="RSOS180850TB3" orientation="portrait" position="float"><label>Table 3.</label><caption><p>Summary of analysis of all participants. FWE, <italic toggle="yes">p</italic> = 0.001.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /></colgroup><thead valign="bottom"><tr><th align="left" rowspan="1" colspan="1">hemisphere</th><th align="left" rowspan="1" colspan="1">lobe</th><th align="left" rowspan="1" colspan="1">cluster covering</th><th align="left" rowspan="1" colspan="1">Brodmann area</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">p</italic>-value</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">K</italic> size</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">T</italic> score</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th></tr></thead><tbody><tr><td colspan="10" rowspan="1"><italic toggle="yes">decision-making</italic></td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">parietal</td><td rowspan="1" colspan="1">inferior parietal lobule</td><td rowspan="1" colspan="1">BA 40</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">1720</td><td rowspan="1" colspan="1">13.10</td><td rowspan="1" colspan="1">48</td><td rowspan="1" colspan="1">−38</td><td rowspan="1" colspan="1">46</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">parietal</td><td rowspan="1" colspan="1">precuneus</td><td rowspan="1" colspan="1">BA 7</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">1748</td><td rowspan="1" colspan="1">12.95</td><td rowspan="1" colspan="1">−20</td><td rowspan="1" colspan="1">−66</td><td rowspan="1" colspan="1">52</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">occipital</td><td rowspan="1" colspan="1">lingual gyrus</td><td rowspan="1" colspan="1">BA 18</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">817</td><td rowspan="1" colspan="1">10.63</td><td rowspan="1" colspan="1">−4</td><td rowspan="1" colspan="1">−82</td><td rowspan="1" colspan="1">−6</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">middle frontal gyrus</td><td rowspan="1" colspan="1">BA 6</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">194</td><td rowspan="1" colspan="1">10.58</td><td rowspan="1" colspan="1">−28</td><td rowspan="1" colspan="1">8</td><td rowspan="1" colspan="1">52</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">insula</td><td rowspan="1" colspan="1">insula</td><td rowspan="1" colspan="1">BA 13</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">130</td><td rowspan="1" colspan="1">10.55</td><td rowspan="1" colspan="1">−30</td><td rowspan="1" colspan="1">22</td><td rowspan="1" colspan="1">0</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">middle frontal gyrus</td><td rowspan="1" colspan="1">BA 9</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">733</td><td rowspan="1" colspan="1">10.43</td><td rowspan="1" colspan="1">46</td><td rowspan="1" colspan="1">34</td><td rowspan="1" colspan="1">30</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">cerebellum anterior lobe</td><td rowspan="1" colspan="1">culmen</td><td rowspan="1" colspan="1">—</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">368</td><td rowspan="1" colspan="1">10.32</td><td rowspan="1" colspan="1">26</td><td rowspan="1" colspan="1">−48</td><td rowspan="1" colspan="1">−14</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">inferior frontal gyrus</td><td rowspan="1" colspan="1">BA 47</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">300</td><td rowspan="1" colspan="1">10.27</td><td rowspan="1" colspan="1">42</td><td rowspan="1" colspan="1">20</td><td rowspan="1" colspan="1">−2</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">inferior frontal gyrus</td><td rowspan="1" colspan="1">BA 6</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">105</td><td rowspan="1" colspan="1">9.90</td><td rowspan="1" colspan="1">28</td><td rowspan="1" colspan="1">16</td><td rowspan="1" colspan="1">56</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">superior frontal gyrus</td><td rowspan="1" colspan="1">BA 6</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">166</td><td rowspan="1" colspan="1">9.62</td><td rowspan="1" colspan="1">−6</td><td rowspan="1" colspan="1">12</td><td rowspan="1" colspan="1">52</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">temporal</td><td rowspan="1" colspan="1">middle temporal gyrus</td><td rowspan="1" colspan="1">BA 37</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">40</td><td rowspan="1" colspan="1">9.36</td><td rowspan="1" colspan="1">56</td><td rowspan="1" colspan="1">−52</td><td rowspan="1" colspan="1">−12</td></tr><tr><td colspan="10" rowspan="1"><italic toggle="yes">results</italic></td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">parietal</td><td rowspan="1" colspan="1">inferior parietal lobule</td><td rowspan="1" colspan="1">BA 40</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">343</td><td rowspan="1" colspan="1">10.57</td><td rowspan="1" colspan="1">52</td><td rowspan="1" colspan="1">−50</td><td rowspan="1" colspan="1">46</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">temporal</td><td rowspan="1" colspan="1">middle temporal gyrus</td><td rowspan="1" colspan="1">BA 21</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">74</td><td rowspan="1" colspan="1">8.72</td><td rowspan="1" colspan="1">58</td><td rowspan="1" colspan="1">−34</td><td rowspan="1" colspan="1">−8</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">parietal</td><td rowspan="1" colspan="1">inferior parietal lobule</td><td rowspan="1" colspan="1">BA 40</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">36</td><td rowspan="1" colspan="1">8.14</td><td rowspan="1" colspan="1">−58</td><td rowspan="1" colspan="1">−42</td><td rowspan="1" colspan="1">40</td></tr></tbody></table></table-wrap>
</div></details><details class="inner-accordion"><summary>Table 4. (RSOS180850TB4) - Summary of per group analyses. FWE, p = 0.001.</summary><div class="table-html"><table-wrap id="RSOS180850TB4" orientation="portrait" position="float"><label>Table 4.</label><caption><p>Summary of per group analyses. FWE, <italic toggle="yes">p</italic> = 0.001.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /></colgroup><thead valign="bottom"><tr><th align="left" rowspan="1" colspan="1">hemisphere</th><th align="left" rowspan="1" colspan="1">lobe</th><th align="left" rowspan="1" colspan="1">cluster covering</th><th align="left" rowspan="1" colspan="1">Brodmann area</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">p</italic>-value</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">K</italic> size</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">T</italic> score</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th></tr></thead><tbody><tr><td colspan="10" rowspan="1">PATIENTS</td></tr><tr><td colspan="10" rowspan="1"><italic toggle="yes">decision-making</italic></td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">occipital</td><td rowspan="1" colspan="1">lingual gyrus</td><td rowspan="1" colspan="1">BA 18</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">11 406</td><td rowspan="1" colspan="1">10.64</td><td rowspan="1" colspan="1">24</td><td rowspan="1" colspan="1">−74</td><td rowspan="1" colspan="1">−10</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">superior frontal gyrus</td><td rowspan="1" colspan="1">BA 6</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">8491</td><td rowspan="1" colspan="1">10.28</td><td rowspan="1" colspan="1">−16</td><td rowspan="1" colspan="1">0</td><td rowspan="1" colspan="1">64</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">subcortical insula</td><td rowspan="1" colspan="1">claustrum insula</td><td rowspan="1" colspan="1">—</td><td rowspan="1" colspan="1">0.006</td><td rowspan="1" colspan="1">456</td><td rowspan="1" colspan="1">7.63</td><td rowspan="1" colspan="1">−28</td><td rowspan="1" colspan="1">22</td><td rowspan="1" colspan="1">−2</td></tr><tr><td colspan="10" rowspan="1"><italic toggle="yes">results</italic></td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">parietal</td><td rowspan="1" colspan="1">inferior parietal lobule</td><td rowspan="1" colspan="1">BA 40</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">4211</td><td rowspan="1" colspan="1">12.48</td><td rowspan="1" colspan="1">−60</td><td rowspan="1" colspan="1">−42</td><td rowspan="1" colspan="1">38</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">parietal</td><td rowspan="1" colspan="1">inferior parietal lobule</td><td rowspan="1" colspan="1">BA 40</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">5094</td><td rowspan="1" colspan="1">11.53</td><td rowspan="1" colspan="1">58</td><td rowspan="1" colspan="1">−44</td><td rowspan="1" colspan="1">44</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">middle frontal gyrus</td><td rowspan="1" colspan="1">BA 46</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">2994</td><td rowspan="1" colspan="1">10.12</td><td rowspan="1" colspan="1">42</td><td rowspan="1" colspan="1">48</td><td rowspan="1" colspan="1">14</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">cerebellum</td><td rowspan="1" colspan="1">anterior lobe</td><td rowspan="1" colspan="1">—</td><td rowspan="1" colspan="1">0.003</td><td rowspan="1" colspan="1">439</td><td rowspan="1" colspan="1">6.91</td><td rowspan="1" colspan="1">−2</td><td rowspan="1" colspan="1">−54</td><td rowspan="1" colspan="1">−4</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">parietal</td><td rowspan="1" colspan="1">precuneus</td><td rowspan="1" colspan="1">BA 7</td><td rowspan="1" colspan="1">0.016</td><td rowspan="1" colspan="1">304</td><td rowspan="1" colspan="1">6.35</td><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">−78</td><td rowspan="1" colspan="1">46</td></tr><tr><td colspan="10" rowspan="1">CONTROLS</td></tr><tr><td colspan="10" rowspan="1"><italic toggle="yes">decision-making</italic></td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">temporal occipital</td><td rowspan="1" colspan="1">fusiform gyrus</td><td rowspan="1" colspan="1">BA 37</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">17309</td><td rowspan="1" colspan="1">13.94</td><td rowspan="1" colspan="1">54</td><td rowspan="1" colspan="1">−54</td><td rowspan="1" colspan="1">−16</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">superior frontal gyrus</td><td rowspan="1" colspan="1">BA 9</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">9140</td><td rowspan="1" colspan="1">11.15</td><td rowspan="1" colspan="1">42</td><td rowspan="1" colspan="1">36</td><td rowspan="1" colspan="1">28</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">insula</td><td rowspan="1" colspan="1">insula</td><td rowspan="1" colspan="1">BA 13</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">756</td><td rowspan="1" colspan="1">8.1</td><td rowspan="1" colspan="1">−34</td><td rowspan="1" colspan="1">18</td><td rowspan="1" colspan="1">8</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">temporal</td><td rowspan="1" colspan="1">superior temporal gyrus</td><td rowspan="1" colspan="1">BA 22</td><td rowspan="1" colspan="1">0.020</td><td rowspan="1" colspan="1">238</td><td rowspan="1" colspan="1">7.69</td><td rowspan="1" colspan="1">−50</td><td rowspan="1" colspan="1">−48</td><td rowspan="1" colspan="1">14</td></tr><tr><td colspan="10" rowspan="1"><italic toggle="yes">results</italic></td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">middle frontal gyrus</td><td rowspan="1" colspan="1">BA 10</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">67860</td><td rowspan="1" colspan="1">9.12</td><td rowspan="1" colspan="1">−34</td><td rowspan="1" colspan="1">48</td><td rowspan="1" colspan="1">−2</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">parietal</td><td rowspan="1" colspan="1">inferior parietal lobule</td><td rowspan="1" colspan="1">BA 40</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">3234</td><td rowspan="1" colspan="1">7.88</td><td rowspan="1" colspan="1">−46</td><td rowspan="1" colspan="1">−46</td><td rowspan="1" colspan="1">56</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">parietal</td><td rowspan="1" colspan="1">inferior parietal lobule</td><td rowspan="1" colspan="1">BA 40</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">1086</td><td rowspan="1" colspan="1">7.11</td><td rowspan="1" colspan="1">52</td><td rowspan="1" colspan="1">−50</td><td rowspan="1" colspan="1">46</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">temporal</td><td rowspan="1" colspan="1">inferior temporal gyrus</td><td rowspan="1" colspan="1">BA 20</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">596</td><td rowspan="1" colspan="1">7.08</td><td rowspan="1" colspan="1">58</td><td rowspan="1" colspan="1">−40</td><td rowspan="1" colspan="1">16</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">cingulate gyrus</td><td rowspan="1" colspan="1">BA 24</td><td rowspan="1" colspan="1">0.046</td><td rowspan="1" colspan="1">219</td><td rowspan="1" colspan="1">5.41</td><td rowspan="1" colspan="1">−2</td><td rowspan="1" colspan="1">−14</td><td rowspan="1" colspan="1">38</td></tr></tbody></table></table-wrap>
</div></details><details class="inner-accordion"><summary>Table 5. (RSOS180850TB5) - Analysis of group differences and ROI.</summary><div class="table-html"><table-wrap id="RSOS180850TB5" orientation="portrait" position="float"><label>Table 5.</label><caption><p>Analysis of group differences and ROI.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /><col align="left" span="1" /></colgroup><thead valign="bottom"><tr><th align="left" rowspan="1" colspan="1">hemisphere</th><th align="left" rowspan="1" colspan="1">lobe</th><th align="left" rowspan="1" colspan="1">cluster covering</th><th align="left" rowspan="1" colspan="1">Brodmann area</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">p</italic>-value</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">K</italic> size</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">F</italic> score</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th></tr></thead><tbody><tr><td colspan="10" rowspan="1"><italic toggle="yes">main effect of group</italic></td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">medial frontal gyrus</td><td rowspan="1" colspan="1">BA 10</td><td rowspan="1" colspan="1">0.034</td><td rowspan="1" colspan="1">214</td><td rowspan="1" colspan="1">22.35</td><td rowspan="1" colspan="1">8</td><td rowspan="1" colspan="1">62</td><td rowspan="1" colspan="1">14</td></tr><tr><td colspan="10" rowspan="1"><italic toggle="yes">main effect of condition</italic></td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">cerebellum</td><td rowspan="1" colspan="1">anterior lobe</td><td rowspan="1" colspan="1">—</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">11343</td><td rowspan="1" colspan="1">108.49</td><td rowspan="1" colspan="1">26</td><td rowspan="1" colspan="1">−50</td><td rowspan="1" colspan="1">−12</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">precentral gyrus</td><td rowspan="1" colspan="1">BA 9</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">1439</td><td rowspan="1" colspan="1">81.83</td><td rowspan="1" colspan="1">−36</td><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">34</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">inferior frontal gyrus</td><td rowspan="1" colspan="1">BA 9</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">1770</td><td rowspan="1" colspan="1">64.81</td><td rowspan="1" colspan="1">42</td><td rowspan="1" colspan="1">10</td><td rowspan="1" colspan="1">26</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">insula</td><td rowspan="1" colspan="1">insula</td><td rowspan="1" colspan="1">BA 13</td><td rowspan="1" colspan="1">0.002</td><td rowspan="1" colspan="1">414</td><td rowspan="1" colspan="1">56.86</td><td rowspan="1" colspan="1">32</td><td rowspan="1" colspan="1">22</td><td rowspan="1" colspan="1">−2</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">temporal</td><td rowspan="1" colspan="1">middle temporal gyrus</td><td rowspan="1" colspan="1">BA 21</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">6458</td><td rowspan="1" colspan="1">52.55</td><td rowspan="1" colspan="1">−56</td><td rowspan="1" colspan="1">−22</td><td rowspan="1" colspan="1">−14</td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">insula</td><td rowspan="1" colspan="1">insula</td><td rowspan="1" colspan="1">BA 13</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">4254</td><td rowspan="1" colspan="1">50.94</td><td rowspan="1" colspan="1">42</td><td rowspan="1" colspan="1">−12</td><td rowspan="1" colspan="1">6</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">cingulate gyrus</td><td rowspan="1" colspan="1">BA 24</td><td rowspan="1" colspan="1">0.000</td><td rowspan="1" colspan="1">1827</td><td rowspan="1" colspan="1">40.86</td><td rowspan="1" colspan="1">−4</td><td rowspan="1" colspan="1">−14</td><td rowspan="1" colspan="1">40</td></tr><tr><td colspan="10" rowspan="1"><italic toggle="yes">ROI-main effect of group</italic></td></tr><tr><td rowspan="1" colspan="1">right</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">superior frontal gyrus</td><td rowspan="1" colspan="1">BA 10</td><td rowspan="1" colspan="1">0.007</td><td rowspan="1" colspan="1">219</td><td rowspan="1" colspan="1">31.57</td><td rowspan="1" colspan="1">14</td><td rowspan="1" colspan="1">60</td><td rowspan="1" colspan="1">14</td></tr><tr><td rowspan="1" colspan="1">left</td><td rowspan="1" colspan="1">frontal</td><td rowspan="1" colspan="1">middle frontal gyrus</td><td rowspan="1" colspan="1">BA 10</td><td rowspan="1" colspan="1">0.046</td><td rowspan="1" colspan="1">124</td><td rowspan="1" colspan="1">19.57</td><td rowspan="1" colspan="1">−32</td><td rowspan="1" colspan="1">54</td><td rowspan="1" colspan="1">8</td></tr></tbody></table></table-wrap></div></details></details>
</details>


<details class="doc-card">
  <summary><strong>PMID 17964185</strong> | Pred included: 1 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=1, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/17964185/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>17964185_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The task is a social interaction simulation contrasting responses to friends (positive peers) versus other peers/celebrities; it directly involves social processing. Both inclusion criteria are met.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>17964185_1</td><td>(peer vs. celebrity) x (positive vs. non-positive); socialcommunication</td><td>17964185_analysis_0</td><td>analysis_0</td><td>0.167</td><td>0.903</td><td>0.682</td><td>uncertain</td><td>high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18603608</strong> | Pred included: 2 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18603608/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> compositions &gt; computer-generated pieces; others</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18603608_analysis_0</td><td>Predicted</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task explicitly manipulates participants’ attitude toward stimuli to elicit attribution of intentions and engages brain regions for mental state attribution (theory of mind). This is a social-processing task measuring understanding of others’ intentions.</td></tr>
<tr><td>18603608_analysis_1</td><td>Not predicted</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The contrast Composer vs Computer manipulates participants’ perception of agency and elicits mentalizing about intentions of a creator, which is a social-related task and directly measures social processing (understanding others&#x27; intentions).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18603608_1</td><td>compositions &gt; computer-generated pieces; others</td><td>18603608_analysis_0</td><td>Predicted</td><td>0.163</td><td>0.667</td><td>0.516</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 21206532</strong> | Pred included: 1 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=4</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/21206532/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> faces &gt; watches; socialcommunication, objects &gt; faces; socialcommunication, objects &gt; watches; socialcommunication, watches &gt; faces; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>21206532_analysis_0</td><td>Characterization of FFA, OFA, and LOC regions of interest</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The analysis involves face perception and individuation, which is a form of social-related processing (perception/recognition of others). Thus it satisfies performing a social-related task and measuring social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>21206532_1</td><td>faces &gt; watches; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>21206532_2</td><td>objects &gt; faces; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>21206532_3</td><td>objects &gt; watches; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>21206532_4</td><td>watches &gt; faces; socialcommunication</td><td>21206532_analysis_0</td><td>Characterization of FFA, OFA, and LOC regions of interest</td><td>0.237</td><td>0.000</td><td>0.071</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24582805</strong> | Pred included: 7 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=9</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24582805/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> DA &gt; CA; self, DP &gt; CP; self, DS &gt; CS; self, OA &gt; CA; others, OP &gt; CP; others, OS &gt; CS; others, RA &gt; CA; self, RP &gt; CP; self, RS &gt; CS; self</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24582805_analysis_0</td><td>Main effect of age group</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task involves self-, other-, and reflected self-evaluations from a close peer’s perspective—clearly social processing.</td></tr>
<tr><td>24582805_analysis_1</td><td>Main effect of evaluative perspective</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task involves evaluating self, close other, and reflected self from a best friend&#x27;s perspective—clear social processing (self/other perception, peer evaluation).</td></tr>
<tr><td>24582805_analysis_2</td><td>Age group × evaluative perspective</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task involves self-, other-, and reflected self-evaluations from a peer’s perspective, clearly a social-related task measuring social processing (self/peer evaluation, perspective-taking, peer influence).</td></tr>
<tr><td>24582805_analysis_3</td><td>Main effect of domain</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task involves self-, other-, and reflected self-evaluations across social domain (social traits, peer perspective-taking). Fits Social Processing (perception/understanding of self and others and peer-related social evaluation).</td></tr>
<tr><td>24582805_analysis_4</td><td>Age group × domain</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The task involves direct self-evaluations, direct other-evaluations (best friend), and reflected self-evaluations from a peer’s perspective—clearly social processes (self/other perception, peer evaluation). The analysis measures social processing across domains and perspectives.</td></tr>
<tr><td>24582805_analysis_5</td><td>Evaluative perspective × domain</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task explicitly involves self-, other-, and reflected social evaluations (direct self, direct other, reflected self from best friend&#x27;s perspective) and examines social domains (academic, physical, social)—measures social processing.</td></tr>
<tr><td>24582805_analysis_6</td><td>Age group × evaluative perspective × domain</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task involves self- and reflected self-evaluations from a close peer’s perspective and direct other-evaluations—clearly social processing (peer influence, self/other perspective-taking).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24582805_1</td><td>DA &gt; CA; self</td><td>24582805_analysis_0</td><td>Main effect of age group</td><td>0.270</td><td>0.000</td><td>0.081</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>24582805_2</td><td>DP &gt; CP; self</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>24582805_3</td><td>DS &gt; CS; self</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>24582805_4</td><td>OA &gt; CA; others</td><td>24582805_analysis_5</td><td>Evaluative perspective × domain</td><td>0.217</td><td>0.115</td><td>0.146</td><td>unmatched</td><td>low_total_score</td></tr><tr><td>24582805_5</td><td>OP &gt; CP; others</td><td>24582805_analysis_2</td><td>Age group × evaluative perspective</td><td>0.327</td><td>0.000</td><td>0.098</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>24582805_6</td><td>OS &gt; CS; others</td><td>24582805_analysis_6</td><td>Age group × evaluative perspective × domain</td><td>0.241</td><td>0.000</td><td>0.072</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>24582805_7</td><td>RA &gt; CA; self</td><td>24582805_analysis_3</td><td>Main effect of domain</td><td>0.286</td><td>0.040</td><td>0.114</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>24582805_8</td><td>RP &gt; CP; self</td><td>24582805_analysis_4</td><td>Age group × domain</td><td>0.320</td><td>0.000</td><td>0.096</td><td>unmatched</td><td>low_total_score, missing_coords_on_one_side</td></tr><tr><td>24582805_9</td><td>RS &gt; CS; self</td><td>24582805_analysis_1</td><td>Main effect of evaluative perspective</td><td>0.160</td><td>0.152</td><td>0.154</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25534111</strong> | Pred included: 4 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=2, unmatched=2</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25534111/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> (IJA − IJAc) − (RJA − RJAc); socialcommunication, IJA &gt; IJAc; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25534111_analysis_0</td><td>Responding to joint attention (RJA - RJAc)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The RJA − RJAc contrast isolates responding to joint attention, a clearly social task involving perception and interpretation of another&#x27;s gaze and interactive behavior; it directly measures social processing.</td></tr>
<tr><td>25534111_analysis_1</td><td>Initiating joint attention (IJA - IJAc)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The contrast isolates social joint attention (IJA vs matched control) and the task is explicitly social; it measures social processing related to perceiving and interacting with another agent.</td></tr>
<tr><td>25534111_analysis_2</td><td>Conjunction of initiating and responding to joint attention (IJA - IJAc) with (RJA - RJAc)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task is an interactive joint attention paradigm probing social interactions, gaze following/initiating and representation of others&#x27; attention—meets social processing criteria.</td></tr>
<tr><td>25534111_analysis_3</td><td>Initiating Joint attention minus responding to joint attention (IJA - IJAc) - (RJA - RJAc)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task explicitly involves interactive social behavior (initiating/responding to joint attention) and the contrasts isolate social vs. non-social processing, so it measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25534111_1</td><td>(IJA - IJAc) with (RJA - RJAc); socialcommunication</td><td>25534111_analysis_2</td><td>Conjunction of initiating and responding to joint attention (IJA - IJAc) with (RJA - RJAc)</td><td>0.500</td><td>0.714</td><td>0.650</td><td>uncertain</td><td></td></tr><tr><td>25534111_2</td><td>(IJA − IJAc) − (RJA − RJAc); socialcommunication</td><td>25534111_analysis_3</td><td>Initiating Joint attention minus responding to joint attention (IJA - IJAc) - (RJA - RJAc)</td><td>0.410</td><td>0.430</td><td>0.424</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>25534111_3</td><td>IJA &gt; IJAc; socialcommunication</td><td>25534111_analysis_1</td><td>Initiating joint attention (IJA - IJAc)</td><td>0.367</td><td>0.567</td><td>0.507</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>25534111_4</td><td>RJA &gt; RJAc; socialcommunication</td><td>25534111_analysis_0</td><td>Responding to joint attention (RJA - RJAc)</td><td>0.346</td><td>0.733</td><td>0.617</td><td>uncertain</td><td>coord_count_mismatch</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25911123</strong> | Pred included: 2 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=4</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25911123/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Decreasing LOA &gt;  Increasing LOA; others, High-why + High-how &gt; Low-Why + Low-How; others, Increasing LOA &gt; Decreasing LOA; others, Low-Why + Low-How &gt; High-why + High-how; others</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25911123_analysis_0</td><td>Response to why &gt; how questions for all stimulus categories</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task explicitly contrasts attributional (why) vs factual (how) questions about emotional expressions and intentional actions (social stimuli), directly measuring social processing (theory of mind/understanding others).</td></tr>
<tr><td>25911123_analysis_1</td><td>Stronger response to why &gt; how questions for social than for nonsocial stimuli</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The contrast isolates attributional processing (why &gt; how) for social stimuli (emotional expressions and intentional actions). This directly measures social processing (perception/understanding of others and social inference).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25911123_1</td><td>Decreasing LOA &gt;  Increasing LOA; others</td><td>25911123_analysis_0</td><td>Response to why &gt; how questions for all stimulus categories</td><td>0.333</td><td>0.000</td><td>0.100</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>25911123_2</td><td>High-why + High-how &gt; Low-Why + Low-How; others</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>25911123_3</td><td>Increasing LOA &gt; Decreasing LOA; others</td><td>25911123_analysis_1</td><td>Stronger response to why &gt; how questions for social than for nonsocial stimuli</td><td>0.312</td><td>0.041</td><td>0.122</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>25911123_4</td><td>Low-Why + Low-How &gt; High-why + High-how; others</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26143208</strong> | Pred included: 2 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=8</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26143208/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> FAC-Angry &gt; Control; socialcommunication, FAC-Angry &gt; FAC-Happy; socialcommunication, FAC-Happy &gt; Control; socialcommunication, [constant ISI &gt; variable ISI] - FAC-Angry; socialcommunication, [constant ISI &gt; variable ISI] - FAC-happy; socialcommunication, [constant ISI &gt; variable ISI] - control task; socialcommunication, [variable ISI &gt; constant ISI] - FAC-angry; socialcommunication, [variable ISI &gt; constant ISI] - control task; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26143208_analysis_0</td><td>Interaction: FAC-Angry × Control</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The analysis uses gender identification of emotional faces (angry and happy) versus neutral shapes, which is a social-related task and measures processing of social stimuli (face perception and implicit emotion processing).</td></tr>
<tr><td>26143208_analysis_1</td><td>Interaction: FAC-Happy × Control</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task involved processing faces (happy facial expressions) and comparing face-based task to control shapes; contrast assesses social/emotional face processing, meeting both criteria.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26143208_1</td><td>FAC-Angry &gt; Control; socialcommunication</td><td>26143208_analysis_0</td><td>Interaction: FAC-Angry × Control</td><td>0.706</td><td>0.000</td><td>0.212</td><td>unmatched</td><td>coord_count_mismatch, low_total_score, name_only_signal</td></tr><tr><td>26143208_2</td><td>FAC-Angry &gt; FAC-Happy; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>26143208_3</td><td>FAC-Happy &gt; Control; socialcommunication</td><td>26143208_analysis_1</td><td>Interaction: FAC-Happy × Control</td><td>0.706</td><td>0.064</td><td>0.257</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>26143208_4</td><td>[constant ISI &gt; variable ISI] - FAC-Angry; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>26143208_5</td><td>[constant ISI &gt; variable ISI] - FAC-happy; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>26143208_6</td><td>[constant ISI &gt; variable ISI] - control task; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>26143208_7</td><td>[variable ISI &gt; constant ISI] - FAC-angry; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>26143208_8</td><td>[variable ISI &gt; constant ISI] - control task; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29265483</strong> | Pred included: 4 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=3</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29265483/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Affective &gt; Cooperative social interactions, Cooperative &amp; Affective social interactions (Conjunction analysis), Cooperative &gt; Affective social interactions</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29265483_analysis_0</td><td>1a. Observation of social interactions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task involves passive observation of social interactions and DCM assesses neural processing of social interaction dimensions (cooperativity, affectivity), satisfying social processing criteria.</td></tr>
<tr><td>29265483_analysis_1</td><td>1b. Cooperativity&gt;affectivity</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task involves observing cooperative and affective social interactions and modeling how cooperativity/affectivity modulate neural processing—directly assessing social processing.</td></tr>
<tr><td>29265483_analysis_2</td><td>1c. Affectivity&gt;cooperativity</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Task involves observing social interactions (cooperative and affective) and the contrast (Affectivity&gt;Cooperativity) measures social processing of others’ interaction intentions and affect — satisfies both I1 and I2.</td></tr>
<tr><td>29265483_analysis_3</td><td>analysis_3</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves observing social interactions and parametric contrasts (affectivity vs cooperativity) and DCM of social processing — meets both I1 and I2.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29265483_1</td><td>Affective &gt; Cooperative social interactions</td><td>29265483_analysis_2</td><td>1c. Affectivity&gt;cooperativity</td><td>0.622</td><td>0.222</td><td>0.342</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>29265483_2</td><td>Cooperative &amp; Affective social interactions (Conjunction analysis)</td><td>29265483_analysis_0</td><td>1a. Observation of social interactions</td><td>0.538</td><td>0.351</td><td>0.407</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>29265483_3</td><td>Cooperative &gt; Affective social interactions</td><td>29265483_analysis_1</td><td>1b. Cooperativity&gt;affectivity</td><td>0.622</td><td>0.122</td><td>0.272</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29723244</strong> | Pred included: 1 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29723244/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Social vs Non-Social; others</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29723244_analysis_0</td><td>“Social” brain regions identified in the NeuroSynth meta-analysis.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The analysis directly contrasts social vs. non-social images and tests whether ‘‘social’’ stimuli preferentially activate brain regions; it is a clear social-processing task and the contrast measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29723244_1</td><td>Social vs Non-Social; others</td><td>29723244_analysis_0</td><td>“Social” brain regions identified in the NeuroSynth meta-analysis.</td><td>0.362</td><td>0.034</td><td>0.133</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 30056560</strong> | Pred included: 2 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/30056560/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> CON: own&gt;unknown masked with group×(own&gt;unknown); socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>30056560_analysis_0</td><td>Happy-own&gt;neutral-own</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task is an emotional face recognition paradigm involving own vs unknown child and processing of facial emotions, which is social in nature and measures perception/interpretation of social cues (emotion recognition).</td></tr>
<tr><td>30056560_analysis_1</td><td>ELM: happy-own&gt;neutral-own masked with group×(happy-own&gt;neutral-own)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>The contrast examines processing of a child&#x27;s facial emotions (own child happy vs neutral), a social task tapping perception and interpretation of social cues; thus it measures social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>30056560_1</td><td>CON: own&gt;unknown masked with group×(own&gt;unknown); socialcommunication</td><td>30056560_analysis_1</td><td>ELM: happy-own&gt;neutral-own masked with group×(happy-own&gt;neutral-own)</td><td>0.694</td><td>0.000</td><td>0.208</td><td>unmatched</td><td>coord_count_mismatch, low_total_score, name_only_signal</td></tr></tbody></table></div>
  </details>
  
  
</details>
</details></section><section id="bucket-false-negative"><details class="bucket" open><summary><h2>False Negative (5)</h2></summary><p><strong>Match status totals:</strong> accepted=16 | uncertain=0 | unmatched=0</p>
<details class="doc-card">
  <summary><strong>PMID 29330483</strong> | Pred included: 0 | Manual included (accepted matches only): 10 | Correct overlaps: 0 | Match statuses: accepted=10, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29330483/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29330483_analysis_0</td><td>Heterosexual Women</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Task contrasts erotic pictures of males vs females to assess sexual arousal/reward (ventral striatum) and visual/auditory processing; not a social processing task (no measures of affiliation, social interaction, or understanding of others as a primary construct). Although some brain regions related to social cognition were reported, the contrast does not target social processing.</td></tr>
<tr><td>29330483_analysis_1</td><td>Heterosexual Women</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>This analysis contrasts neural responses to erotic pictures of males vs females in heterosexual women; it is an arousal/sexual stimulus task, not a social-processing task (no social interactions, affiliation, or measures of social cognition). Does not meet the inclusion criteria (I1,I2).</td></tr>
<tr><td>29330483_analysis_2</td><td>Bisexual Women</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>The task involves viewing erotic pictures to assess sexual orientation and ventral striatum reward responses, not a social-processing task (no measures of social interaction, affiliation, or perception of others). Inclusion criteria I1/I2 not met.</td></tr>
<tr><td>29330483_analysis_3</td><td>Bisexual Women</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>The analysis contrasts responses to erotic pictures of males vs females (sexual stimuli). This is a passive sexual/erotic perception task, not a social-related task measuring affiliation, communication, or perception-of-others as defined. Although some social-cognition regions were reported, the task does not target social processing constructs described in the inclusion criteria.</td></tr>
<tr><td>29330483_analysis_4</td><td>Homosexual Women</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Task involves viewing erotic pictures/videos to assess sexual orientation and ventral striatum responses, not a social-processing task (no measures of affiliation, social communication, perception of self/others). Although some activations in social-cognition regions are reported, the analysis does not manipulate or measure social processing constructs per the inclusion criteria.</td></tr>
<tr><td>29330483_analysis_5</td><td>Homosexual Women</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>The task contrasts responses to male versus female erotic stimuli (sexual arousal/reward). It does not involve an explicit social-processing task (e.g., affiliation, social communication, or judgments about others&#x27; mental states). The analysis does not measure Social Processing per the inclusion criteria.</td></tr>
<tr><td>29330483_analysis_6</td><td>Heterosexual Women: Female &gt; Male Videos</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Task involves viewing erotic videos to assess sexual arousal and ventral striatum responses (male vs female stimuli). It is not a social-processing task (no social interaction, affiliation, or explicit social-cognitive judgments). Does not meet I1 or I2.</td></tr>
<tr><td>29330483_analysis_7</td><td>Heterosexual Women: Male &gt; Female Videos</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Task involves viewing erotic videos to measure sexual/arousal responses (ventral striatum), not social processing or social-cognitive tasks; does not meet I1 or I2.</td></tr>
<tr><td>29330483_analysis_8</td><td>Bisexual Women: Female &gt; Male Videos</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>The contrast examines neural and subjective responses to erotic videos (female vs male) to assess sexual orientation and reward (ventral striatum). It is not a social-processing task per se (no measures of social interaction, affiliation, communication, or understanding of others), so it does not satisfy I1 or I2.</td></tr>
<tr><td>29330483_analysis_9</td><td>Bisexual Women: Male &gt; Female Videos</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>The analysis is a sexual-arousal task (viewing erotic videos) contrasting responses to male vs. female stimuli in bisexual women. It measures sexual incentive/responsivity (ventral striatum and subjective ratings), not social processing or social-task constructs (no affiliation, interaction, or social-perception task). Although some brain regions linked to social cognition are reported, the paradigm and contrasts do not target social processing constructs.</td></tr>
<tr><td>29330483_analysis_10</td><td>Homosexual Women: Female &gt; Male Videos</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Task involves viewing erotic videos to assess sexual orientation and ventral striatum responses; it does not operationalize a social processing task (e.g., affiliation, social communication, or explicit perception/interpretation of social cues). Does not meet I1 or I2.</td></tr>
<tr><td>29330483_analysis_11</td><td>Homosexual Women: Male &gt; Female Videos</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>The analysis examines neural and subjective responses to erotic male vs female stimuli (sexual arousal/reward). The task is not a social-processing task (no measures of affiliation, social interaction, social communication, or explicit perception/understanding of others’ mental states), so it does not meet the inclusion criteria I1–I2.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29330483_1</td><td>(Bisexual Women) Female &gt; Male Pictures; self</td><td>29330483_analysis_2</td><td>Bisexual Women</td><td>0.528</td><td>0.923</td><td>0.805</td><td>accepted</td><td>high_coord_match</td></tr><tr><td>29330483_10</td><td>(Homosexual Women) Male &gt; Female Videos; self</td><td>29330483_analysis_11</td><td>Homosexual Women: Male &gt; Female Videos</td><td>0.961</td><td>1.000</td><td>0.988</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29330483_2</td><td>(Bisexual Women) Female &gt; Male Videos; self</td><td>29330483_analysis_8</td><td>Bisexual Women: Female &gt; Male Videos</td><td>0.959</td><td>1.000</td><td>0.988</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29330483_3</td><td>(Bisexual Women) Male &gt; Female Pictures; self</td><td>29330483_analysis_3</td><td>Bisexual Women</td><td>0.528</td><td>1.000</td><td>0.858</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>29330483_4</td><td>(Bisexual Women) Male &gt; Female Videos; self</td><td>29330483_analysis_9</td><td>Bisexual Women: Male &gt; Female Videos</td><td>0.959</td><td>1.000</td><td>0.988</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29330483_5</td><td>(Heterosexual Women) Female &gt; Male Pictures; self</td><td>29330483_analysis_0</td><td>Heterosexual Women</td><td>0.590</td><td>1.000</td><td>0.877</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29330483_6</td><td>(Heterosexual Women) Female &gt; Male Videos; self</td><td>29330483_analysis_6</td><td>Heterosexual Women: Female &gt; Male Videos</td><td>0.963</td><td>1.000</td><td>0.989</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29330483_7</td><td>(Heterosexual Women) Male &gt; Female Videos; self</td><td>29330483_analysis_7</td><td>Heterosexual Women: Male &gt; Female Videos</td><td>0.963</td><td>1.000</td><td>0.989</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29330483_8</td><td>(Homosexual Women) Female &gt; Male Pictures; self</td><td>29330483_analysis_4</td><td>Homosexual Women</td><td>0.561</td><td>1.000</td><td>0.868</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29330483_9</td><td>(Homosexual Women) Female &gt; Male Videos; self</td><td>29330483_analysis_10</td><td>Homosexual Women: Female &gt; Male Videos</td><td>0.961</td><td>1.000</td><td>0.988</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  <details class="inner-accordion"><summary>PMC full text available (PMCID 5766543)</summary><p><strong>Title:</strong> Neural Correlates of Sexual Orientation in Heterosexual, Bisexual, and Homosexual Women</p><details><summary>Abstract</summary><pre class="paper-text">We used fMRI to investigate neural correlates of responses to erotic pictures and videos in heterosexual (N = 26), bisexual (N = 26), and homosexual (N = 24) women, ages 25–50. We focused on the ventral striatum, an area of the brain associated with desire, extending previous findings from the sexual psychophysiology literature in which homosexual women had greater category specificity (relative to heterosexual and bisexual women) in their responses to male and female erotic stimuli. We found that homosexual women’s subjective and neural responses reflected greater bias towards female stimuli, compared with bisexual and heterosexual women, whose responses did not significantly differ. These patterns were also suggested by whole brain analyses, with homosexual women showing category-specific activations of greater extents in visual and auditory processing areas. Bisexual women tended to show more mixed patterns, with activations more responsive to female stimuli in sensory processing areas, and activations more responsive to male stimuli in areas associated with social cognition.</pre></details><details><summary>Body</summary><pre class="paper-text">## Introduction 
  
Studies using physiological measures have found that women tend to have non-specific patterns of genital arousal . That is, in contrast to men, women tend to show similar degrees of arousal to erotic stimuli depicting either sex. For example, heterosexual women have generally shown equivalent arousal to both erotic stimuli featuring men and erotic stimuli featuring women. This has been repeatedly demonstrated with vaginal photoplethysmography . This pattern has also been found using less direct measures such as looking time , pupil dilation , and fMRI . Notably, homosexual women’s arousal patterns are more category-specific than heterosexual women’s, although less so than men’s . 

The fact that women’s sexual arousal patterns are less category-specific than men’s has been interpreted as a potential contributor to gender differences in “erotic plasticity” , which Baumeister has defined as “the extent to which sex drive is shaped by social, cultural, and situational factors.” 

Baumeister offered three lines of evidence when he initially proposed that women may have greater erotic plasticity compared with men: (1) women show larger effects of social and cultural factors on sexual attitudes, desire, and behavior; (2) sexual attitude-behavior consistency is lower in women than in men; (3) individual women exhibit more variation in sexual behavior across time than men. Women’s less specific arousal patterns may also contribute to their increased “sexual fluidity” , which Diamond has defined as an individual’s “capacity for situation-dependent flexibility in sexual responsiveness, which allows individuals to experience changes in same-sex or other-sex desire across both short-term and long-term time periods” . 

One might hypothesize that arousal patterns of bisexual women should be similar to the non-specific arousal patterns of heterosexual women; however, studies of women’s arousal patterns have mostly neglected to include bisexual women. Heterosexual women’s arousal does not appear to favor erotic stimuli of either sex, and thus may be considered to reflect a bisexual pattern. (We do not mean to imply that heterosexual women are confused or in denial about their “real preferences”; rather, the findings in need of explanation are why heterosexual women show non-heterosexual arousal patterns in the laboratory). The implication of women’s non-specific arousal patterns for their sexual orientations is difficult to interpret. Most women, like most men, behave and identify heterosexually . However, men are more likely than women to identify as completely heterosexual or completely homosexual, and women are more likely than men to identify as bisexual or “mostly heterosexual” . 

If arousal patterns are similar between heterosexual and bisexual women, the question remains what distinguishes the two groups. One possibility, supported by some research, is that bisexual women tend to have greater sexual motivation, which may increase the likelihood of exploring a capacity for attraction to both sexes . Or, bisexual women may be more aware than heterosexual women of their non-specific arousal , which could partially contribute to bisexual sexual motivation. Alternatively, bisexual women may be more likely than heterosexual women to interpret their non-specific arousal states in sexual or romantic terms. 

It is also possible that bisexual women’s arousal patterns differ from those observed in heterosexual women. Consistent with this possibility, recent studies suggest that women with bisexual interests tend to be more aroused by female than by male erotic stimuli . Perhaps for some women with female-biased arousal patterns, this bias can motivate non-heterosexual feelings, behavior, and identity. 

Interpretations of non-specific arousal patterns in women are further complicated by the fact that female genital arousal exhibits relatively low correlations with subjectively reported sexual arousal, in contrast to the high correlations observed in men . Discrepancies between existing genital and subjective measures indicate that some women may report substantial subjective arousal without substantial genital arousal, and vice versa. It has also been suggested that non-specific arousal patterns may not indicate affective responses to erotic stimuli, but may instead reflect a kind of protective preparatory response . 

Neuroimaging assessments may shed light on the neural systems that are involved in responding to a given paradigm. Functional magnetic resonance imaging (fMRI) is a neuroimaging approach that allows for the indirect assessment of brain activity by tracking ratios of oxygenated and deoxygenated blood a proxy for neural firing. When used in the context of presenting erotic stimuli, this non-invasive neural measure could provide a converging line of evidence for interpreting the genital and subjective arousal findings described above. In this study, we used fMRI to specifically focused on the “reward system” in order to address the question: to what extent is there an affective significance to findings from the literature on women’s sexual orientation and genital arousal? 

The part of the “reward system” that we focused on is the ventral striatum, a dopamine-sensitive area of the brain that is a reliable measure of reward-related processing–and in particular, wanting and “incentive motivation” –including with respect to sexual orientation . Most neuroimaging studies of sexual response have focused on men , but the ventral striatum has also been found to reliably activate in studies of women’s responses to erotic stimuli . However, until now, no studies have measured neural responses to erotic stimuli in bisexual women. 

The present investigation primarily focused on two hypotheses: (1) Homosexual women may show greater category-specificity than non-homosexual women in brain activity, as suggested by the genital arousal literature; (2) Bisexual women may show larger biases towards female stimuli, compared with heterosexual women. We tested these hypotheses with respect to subjective and neural responses to erotic pictures and erotic videos. We used two different kinds of erotic stimuli because of their potentially non-overlapping strengths and weaknesses. Erotic pictures may be particularly well-suited for assessing the initial appraisal of sexual stimuli, but their brevity may not reflect the kinds of experiences that drive sexuality in the real world. Erotic videos may allow for the measurement of more intense states, but their extended duration may also provide opportunities for self-regulatory efforts to modify erotic responses. 


## Method 
  
### Participants 
  
Participants were 26 heterosexual women, 26 bisexual women, and 24 homosexual women, recruited from a variety of publicly-posted and online advertisements seeking (paid) volunteers for a neuroimaging study of sexual orientation and arousal. Bisexual women were required to have had at least two previous sexual partners and one romantic partner (of three months or greater duration) of each sex. Homosexual and heterosexual participants all met these criteria with respect to their respective preferred sexes. 

After responding to advertisements, participants were screened for inclusion using online questionnaires. Participants provided information about sexual orientation, sexual interests, and personality, in addition to answering screening questions relevant to medical eligibility for fMRI research. Participants were required to be right handed, non-claustrophobic, free from ferromagnetic implants, and not currently taking psychiatric medications. Participants were informed of the risks and nature of the study and agreed to participate in all portions of the research. This study was approved by the Institutional Review Board of Northwestern University and carried out in accordance with its guidelines. Informed consent was obtained from each participant for every portion of the study in which they participated. 

Participants’ sexual orientation was assessed using self-reported identities (i.e. “Homosexual”/“Gay”, “Bisexual”/“Bi”, “Heterosexual”/“Straight”), as well as with a modified Kinsey score, which asked participants about their sexual fantasies throughout adulthood as well as in the past year. The scale ranged from 0 to 6, with 0 corresponding to an exclusively heterosexual orientation and 6 corresponding to an exclusively homosexual orientation. Responses to questions about adulthood and about the past year were averaged to create a Kinsey score for each participant. The average Kinsey score was 0.8 for heterosexual women (  SD   = 0.7,   range   = 0–2), 2.63 for bisexual women (  SD   = 0.7,   range   = 2–4.5), and 5.2 for homosexual women (  SD   = 0.68,   range   = 4–6). 

Participants’ ages ranged from 21 to 46 years old. Mean ages were 29.7 for heterosexual women (  SD   = 5.86,   range   = 25–46), 30.27 for bisexual women (  SD   = 6.41,   range   = 21–48), and 29 for homosexual women (  SD   = 3.12,   range   = 25–38). The sample of 76 participants was racially and ethnically diverse, with 23 non-Caucasian participants including two Latina participants, ten African-American participants, four Asian-American participants, and seven participants who identified otherwise or who identified as multiethnic/multiracial. Groups did not significantly differ either with respect to age (  F  (2,73) = 0.348,   p   = 0.708) or ethnicity (c (2, N = 76) = 2.94, p = 0.23). We also confirmed that ethnicity did not significantly impact responses to the erotic stimuli. 


### Stimuli and Procedure 
  
Subjects experienced two experimental paradigms in the scanner: first erotic pictures were shown (over a period of ~21 minutes), and then erotic videos were shown (over a period of ~19 minutes) after a brief rest period. Picture stimuli were shown before video stimuli for all participants in an attempt to promote stimulus engagement. That is, it was assumed that potentially less intense stimuli might be better presented earlier in the experimental session while attentional resources are highest. Further, there was concern that first showing more intense stimuli would reduce engagement with subsequent stimuli. As such, pictures and videos stimuli were not counterbalanced with respect to each other. 

Participants watched stimuli while laying down with a combination of earplugs (to minimize scanner noise) and over-ear headphones (for video sound and communication with experimenters). Images were displayed via projector onto a wall, which was made viewable to participants via an angled mirror placed above the eyes. 

#### Erotic pictures paradigm 
  
The present study employed a subset of the picture stimuli used in Safron   et al  .  and Sylva   et al  . . Pictures depicted a nude man, a nude woman, or a same-sex couple (i.e., either two men or two women) engaged in explicit sexual contact. Erotic stimuli featuring both individual nudes and same-sex pairs engaging in explicit sexual interaction is common in research on sexual arousal and sexual orientation , which is not the case when stimuli featuring male-female couples is presented. However, erotic stimuli featuring explicit sexual activity in same-sex couples tends to be substantially more arousing compared with pictures of single nudes . Such stimuli are similar to pictures of nude individuals, in the sense that only men or women, but not both, are depicted in a given picture. Thus, sexual arousal induced by them is relatively unambiguous in terms of the gender to which participants are responding. 

In each of two 10.5-minute runs (ordering counterbalanced), participants viewed 40 erotic pictures featuring male models and 40 erotic pictures featuring female models. Each picture was shown for 3.5 seconds, followed by a variable-duration fixation cross presented for either 1.5, 6.5, or 11.5 seconds. Variable-duration baselines were utilized for superior deconvolution of the BOLD signal in a rapid event-related design for fMRI (in which evoked signals are never allowed to return to baseline levels). During the presentation of each picture, participants used buttons held in their right hands to rate that image on a scale of −2 to +2 (respectively: “strongly disliked,” “disliked,” “liked,” “strongly liked”), with no option of 0 for neutral ratings. Neutral options for ratings were not provided for the sake of consistency with previous research using the same stimuli. Note: Subjective ratings of pictures were lost for some participants due to a button-box equipment error. 


#### Erotic videos paradigm 
  
Following picture assessment, participants were shown six video clips depicting individual masturbating men and six video clips depicting individual masturbating women. Depicted individuals appeared sexually aroused but did not reach orgasm. To estimate baseline responses, six natural landscape videos were shown. 

In each of two 9.25-minute runs (ordering counterbalanced), videos were presented for 15 seconds each, followed by a 15-second distraction task requiring participants to indicate via button-press when a number in a series decreased by an interval other than seven. This task was intended to facilitate a return to emotional and physiological baseline. 15-second stimulus presentations were chosen as a desirable stimulation period in an fMRI block design, which can potentially be more sensitive than event-related designs . 

After leaving the scanner, participants viewed the videos once more and provided ratings of each clip. Videos were rated using a 5-point scale for degree of sexual appeal, ranging from “not at all” (0) to “very much” (4), with a midpoint of “somewhat” (2).’ 



### fMRI signal extraction methods 
  
#### Image acquisition 
  
A Siemens Trio 3 T magnet and 12-channel RF head coil were used to collect T2*-weighted gradient-recalled EPI images from the whole brain (32 3-mm slices with a 0.99-mm interslice gap; TR = 2500 ms; TE = 20 ms; flip angle = 80°; FOV = 200 × 220 mm, 120 × 128 acquisition matrix). Slices were taken along the plane connecting the anterior and posterior commissures, with a 1.72 mm × 1.72 mm × 3.99 mm resolution, with more refined axial dimensions intended to produce less distortion and signal dropout in sub-cortical areas, although possibly at the expense of signal-to-noise ratio. During each picture run, 250 whole-brain volumes were collected, and during each video run, 220 whole-brain volumes were collected, with the first four volumes discarded to account for initial magnetization effects. For anatomical localization, a structural MRI scan consisting of T1-weighted images was conducted after the testing runs (160 1-mm axial slices; TR = 2.1 ms; TE = 4.38 ms; flip angle = 15°; FOV = 220 mm; 256 × 192 matrix). 


#### Image pre-processing 
  
Image pre-processing and analysis was performed using SPM 12b (Wellcome Trust Centre for Neuroimaging, London, UK), and implemented in Matlab v 8.1.604 (The MathWorks Inc., MA, USA). 

Functional (EPI) volumes were first corrected for slice timing. Each participant’s volumes were then registered to the mean slice, after which the registered volumes were resliced, used to create a mean resliced image, and then co-registered to the structural (T1) image. All EPI images, including the mean resliced image, as well as the structural (T1) scans were then spatially normalized to Montreal Neurological Institute (MNI) space, and re-sampled to 3 × 3 × 3 mm (27 mm ) resolution. Normalized functional images were then smoothed to an 8 mm full-width-at-half-maximum Gaussian kernel. 


#### Signal to noise ratio and head coverage exclusions 
  
To exclude participants with poor signal due to either head motion or scanner conditions, average signal-to-noise ratio (SNR) over time was calculated for each subject (after preprocessing, using a mask that included only voxels with appreciable EPI signal). The SNR ratio for each voxel (mean divided by standard deviation) was averaged across all voxels in the brain . Participants whose picture data SNR was less than one standard deviation below the mean were excluded from picture analyses. Similarly, participants whose video data SNR was less than one standard deviation below the mean were excluded from video analyses. 

Based on these criteria, fourteen participants (five heterosexual, five bisexual, and four homosexual) were excluded from fMRI and subjective picture analyses, and sixteen participants (six heterosexual, six bisexual, and four homosexual) were excluded from fMRI and subjective video analyses. After exclusions were performed for SNR, we included a total of twenty-one heterosexual women, twenty-one bisexual women, and twenty homosexual women in fMRI picture analyses. Video analyses after SNR exclusion included eighteen heterosexual women, eighteen bisexual women, and twenty homosexual women. To check the validity of our SNR criterion, head motion plots were visually inspected for all participants (Parrish,   et al  . ). Excluded participants had highly variable head positions as compared to included participants. An additional validity-check was performed using evoked responses to erotic pictures minus a fixation-cross baseline. Excluded participants had substantially reduced activity in visual cortices as compared to included participants. 

An additional thirty-two participants (twelve heterosexual, twelve bisexual, and eight homosexual) were excluded from subjective picture rating analyses due to insufficient subjective data resulting from a button-box equipment error. Five participants (three bisexual and two homosexual) were excluded from subjective video analyses for the same reason. Thus, after exclusions were performed for insufficient subjective data, we included a total of nine heterosexual women, nine bisexual women, and twelve homosexual women in subjective picture analyses, and twenty heterosexual women, seventeen bisexual women, and eighteen homosexual women in subjective video analyses. 

For whole-brain analyses, mean functional scans were individually examined to identify participants with substantial cutoffs in head coverage. As a result, one heterosexual female who had substantial frontal lobe cutoff was excluded from whole-brain analyses in addition to those participants excluded for SNR. 


#### First-level analyses 
  
For both the video and picture assessments, a standard general linear model (GLM)  was used in identifying hemodynamic changes for each participant, and a high-pass filter (cutoff 128 s) was used to remove low-frequency temporal noise. 

Estimated average activity was calculated for each participant’s separate responses to male pictures, female pictures, male videos, and female videos (contrasted with fixation cross for pictures and neutral nature scenes for videos). These estimates were used for region of interest analyses. For whole-brain analyses, estimated average activity was also calculated for each participant’s response to male compared with female pictures and videos. For both the picture and video assessments, each participant’s responses to each stimulus contrast of interest were concatenated within stimulus type, using data from both the 1  and 2  runs. 

Ventral striatum region of interest analyses. An a priori region of interest (ROI) analysis was performed on the ventral striatum—centered on the nucleus accumbens—as this was the area most likely to indicate desire. The ventral striatum and hypothalamus are the only two areas that have been shown to be specifically associated with sexual (as opposed to general) arousal . We focused on the ventral striatum because it likely has higher validity for reflecting sexual incentive value compared with the hypothalamus, which contains a variety of nuclei with heterogeneous functions (including sexual arousal) that would be difficult to disambiguate with the limited spatial resolution of 3 T fMRI. 

The ventral striatum ROI mask used in the present study was drawn on an MNI template brain using the WFU PickAtlas toolbox for SPM 8 . It was anatomically defined as a dilated intersection of the ventral anterior caudate and putamen. The resulting ventral striatum ROI is shown in Fig.  .   
Mask used as the ventral striatum (VS) ROI, drawn using an average brain in the WFU PickAtlas toolbox for SPM 8. MNI coordinates displayed: x = 0, y = 17, z = −8. 
  

Estimates of average ventral striatum activity for each participant were extracted using the MarsBar toolbox for SPM8 . Extracted ventral striatum ROI data were analyzed using JMP Pro v11 (SAS Institute, Cary, NC). 



### Planned contrasts and within-group tests 
  
We constructed separate dependent variables for each combination of stimulus type (i.e. picture or video) and response type (i.e., subjective or ventral striatum activation) by subtracting response to female stimuli from response to male stimuli. That is, we constructed dependent variables for 1) subjective response to pictures, 2) subjective response to videos, 3) ventral striatum activation to pictures, and 4) ventral striatum responses to videos, each of which reflected responses to male stimuli minus responses to female stimuli. We refer to this as the Male-Female contrast. 

Because there were three groups (i.e., heterosexual, homosexual, and bisexual women), two orthogonal between-groups contrasts were constructed to examine what we believe to be the most interesting pair of independent questions based on previous literature . The first question was whether homosexual women differed from the other two groups in their Male-Female contrasts. The second question was whether bisexual women differed from heterosexual women in their Male-Female contrasts. The use of orthogonal planned contrasts allowed us to test these hypotheses with maximum statistical power while simultaneously minimizing the number of overall comparisons. 

Within-group t-tests were also performed separately in each group in order to characterize relative responding to male and female stimuli. 


### Whole-brain analyses 
  
Finally, we examined overall patterns of differential activation in response to male compared with female erotic stimuli across the entire brain. If bisexual and heterosexual women have less specific arousal patterns, then they are likely to exhibit less extensive differential activity between male and female stimuli compared with the activity patterns expected for homosexual women. 

Tests of average group responses to stimulus conditions were performed using one-sample contrasts. Each group (heterosexual women, bisexual women, and homosexual women) was tested individually for clusters of greater activity for male stimuli compared with female stimuli, and female stimuli compared with male stimuli, using a corrected statistical threshold (p &lt; 0.05 FWE). 

For these analyses, cluster reports were generated in SPM. Peak activations and cluster extents (extent threshold k = 5) were visually examined as overlays on slice and render maps. Neuroanatomical descriptions were determined based on agreement between two trained investigators, and checked against designations from the WFU Atlas (Maldjian   et al  ., 2003). 


### Data availability statement 
  
The datasets generated and analyzed during the current study are available from the corresponding author on request. 



## Results 
  
### Between-group planned contrasts 
  
As previously described, planned comparisons for the ventral striatum ROI were conducted via multiple regression using two orthogonal between-groups contrasts: one comparing homosexual women with heterosexual and bisexual women, and one comparing heterosexual with bisexual women. Separate analyses were conducted for each of the Male-Female contrasts (i.e., responses to female stimuli subtracted from responses to male stimuli). Results are presented in Table  .    
Planned contrasts comparing women of different orientation groups. 
  
*Significant p-value &lt; 0.05. **Signifcant p-value &lt; 0.01. 

***Significant p-value &lt; 0.001. 
    
Within-group male – female (male minus female) stimuli difference scores for subjective ratings and ventral striatum (VS) responses, by sexual orientation. Difference scores are defined as a participant’s average response to stimuli depicting males minus average response to stimuli depicting females. Points represent individual participants. Horizontal bars indicate group means and 95% confidence intervals of the means. Horizontal lines at 0 indicate no difference between ratings to erotic stimuli depicting each sex. (  a  ) Difference scores for subjective ratings of picture stimuli. (b) Difference scores for VS activation evoked by picture stimuli. (c) Difference scores for subjective ratings of video stimuli. (d) Difference scores for VS activation evoked by video stimuli. ***p &lt; 0.001, **p &lt; 0.01, *p &lt; 0.05. 
  

#### Homosexual versus non-homosexual women 
  
Subjective ratings. Compared with non-homosexual women, homosexual women had significantly more negative (i.e., gynephilic) Male-Female contrasts for both pictures (p = 0.015) and videos (p &lt; 0.001). That is, homosexual women showed a greater preference for pictures and videos of females relative to males, compared with both bisexual and heterosexual women. 

Ventral striatum activation patterns. Homosexual women had significantly more female-biased ventral striatum responses compared to non-homosexual women for pictures (p = 0.002), but not videos. 


#### Bisexual versus heterosexual women 
  
We compared heterosexual and bisexual women’s subjective and ventral striatum responses to erotic pictures and videos, and observed only one significant difference: for video stimuli, bisexual women had significantly more female-preferring subjective responses than did heterosexual women (p = 0.026). 



### Within-group tests comparing responses to male and female erotic stimuli 
  
Figure   (showing the distribution of Male-Female contrasts for the three groups) shows that heterosexual women exhibited a non-significant trend (p = 0.079) towards favoring female erotic pictures compared with male erotic pictures, and had no differentiation between stimulus sex for other tests. Bisexual women also did not subjectively differentiate among stimulus types based on sex, although they did exhibit (non-significant) marginal female-favoring ventral striatum scores for picture (p = 0.063) and video (p = 0.054) stimuli. Homosexual women, in contrast to heterosexual and bisexual women, showed clear favoring of female stimuli as assessed by subjective liking of pictures (p &lt; 0.001), appeal ratings of videos (p &lt; 0.001), as well as in ventral striatum responses to pictures (p = 0.003) and non-significantly for ventral striatum responses to videos (p = 0.073). Note that these results are presented descriptively. Inferences about differences among the three groups depend on the tests presented in Table  . 


### Whole brain tests comparing responses to male and female erotic stimuli 
  
Note: Activation patterns are described in greater detail in the discussion, with interpretations of possible functional significances. 

#### Picture stimuli 
  
Comparing activation to female versus male erotic pictures, heterosexual women exhibited relatively greater activity for female pictures in occipital (i.e., visual) and occipitotemporal cortices, with no brain areas showing significantly greater activation for male pictures (Fig.  ; Table  ). Bisexual women also showed greater activity in visual cortices for female relative to male pictures, but they showed greater activity for male pictures in other areas including supramarginal and angular gyri, as well as the posterior cingulate. Homosexual women exhibited significant activations for female compared with male pictures in visual cortex, parietal lobes, and parahippocampal cortex, but with no brain areas showing significantly greater activation for male pictures.   
Differential brain activations towards male and female pictures in heterosexual, bisexual, and homosexual women. Whole brain activations are shown for the male picture minus female picture contrasts (with brain activation evoked by viewing neutral stimuli subtracted from activations toward the erotic pictures). Height threshold is set at p &lt; 0.05 FWE with a cluster threshold of k = 5. Axial slice 31, sagittal slice 50, and coronal slice 38 are shown for all groups. 
    
Differential whole-brain activations in response to male vs. female pictures. 
  


#### Video stimuli 
  
When viewing female compared with male erotic videos (Fig.  ; Table  ), all groups showed activity in bilateral superior temporal cortices, likely indicating an auditory confound in which more extensive and substantial vocalizations were present in female erotic videos . However, this effect appeared to vary by sexual orientation, with homosexual women showing the most extensive and robust evoked activity (peak T = 14.22) compared with heterosexual (peak T = 11.71) and bisexual women (peak T = 8.83). In the opposite direction of greater responses to male compared with female erotic videos, heterosexual and bisexual (but not homosexual) women exhibited activations in occipital cortices. While all groups had greater activity towards male videos in (anterior) superior parietal cortices, these activations appeared to be more extensive and robust in bisexual women (peak T = 11.55) compared with heterosexual (peak T = 7.64) and homosexual women (peak T = 7.99).   
Differential brain activations between male and female videos in heterosexual, bisexual, and homosexual women. Whole brain activations are shown for the male video minus female video contrasts (with brain activation evoked by viewing neutral stimuli subtracted from activation toward the erotic videos). Height threshold is set at p &lt; 0.05 FWE with a cluster threshold of k = 5. Axial slice 37, sagittal slice 61, and coronal slice 38 are shown for all groups. 
    
Differential whole-brain activations in response to male vs. female videos. 
  




## Discussion 
  
In this fMRI study of female sexual orientation—the first to include bisexual women—we extended several key findings from the sexual psychophysiology literature . Using the ventral striatum as a neural measure of incentive motivation, we demonstrated that homosexual women have greater gender bias in their responses to male and female erotic stimuli. 

### Main findings: subjective and ventral striatum responses to male and female erotic stimuli 
  
Direct comparisons of bisexual and heterosexual women revealed no significant differences, with the exception of bisexual women having more gynephilic subjective responses to erotic videos. However, bisexual and heterosexual women did not differ with respect to their ventral striatum responses toward these stimuli. When contrasted to bisexual and heterosexual women, homosexual women showed distinctly greater bias toward female stimuli in both their subjective responses to videos and pictures, and also in their ventral striatum responses to pictures. In sum, our planned contrast findings are consistent with the genital arousal literature in which more category-specific responses were observed in homosexual women . 

Another set of tests, comparing male vs. female stimuli within each group, revealed that neither bisexual nor heterosexual women were significantly biased toward stimuli depicting males or stimuli depicting females. This was true both in ventral striatum response and in subjective arousal, for both picture and video stimuli. Homosexual women, however, were uniquely gynephilic (i.e., female-preferring), with significantly greater responses to female stimuli for subjective responses to pictures, subjective responses to videos, and ventral striatum responses to pictures. This gynephilic bias in homosexual women was consistent with our direct comparisons and previous literature. 

Our findings are only partially consistent with observations from the genital arousal literature in which homosexual and bisexual women both had gynephilic responses, but where heterosexual women had non-specific responses . We found significant biases in ventral striatum responses toward female stimuli among homosexual women, but with more indifferent patterns among heterosexual and bisexual women. However, with one exception—bisexual women showing more gynephilic subjective responses to erotic videos than did heterosexual women, in a direct comparison—heterosexual and bisexual women’s patterns of results did not differ significantly. 

Our a priori tests in the ventral striatum allowed us to explore whether women of different sexual orientations also exhibited different degrees of incentive motivation toward male and female erotic stimuli. But fMRI also provides the ability to look at activation patterns across the entire brain, potentially allowing for a more detailed characterization of the neural systems involved. Below we review activation patterns for each group in viewing male compared with female erotic stimuli, along with some reverse inferences as to their functional significance. 


### Whole brain responses to erotic pictures 
  
For heterosexual women viewing erotic pictures, activity was greater for female relative to male stimuli bilaterally in lateral occipital cortices, likely indicative of visual attention , as well as in right-lateralized fusiform cortex, potentially suggesting face or body processing .   In no brain areas did heterosexual women have significantly greater activation for male relative to female erotic pictures  . Rather, they seemed to have a somewhat gynephilic pattern of visual attention, consistent with results from eye-tracking and looking-time studies in which heterosexual women attended to erotic characteristics of female pictures . 

Bisexual women showed more activity in response to female (relative to male) erotic pictures throughout the visual system, including fusiform cortex, which (as described above) is often associated with perception of faces and bodies . Patterns were similar to those observed in heterosexual women (and presumably with similar functional significances), but with larger spatial extents of activation. Although bisexual and heterosexual women were not directly contrasted, this more extensive visual activation could be taken as support for somewhat greater gynephilic interest on the part of bisexual women, consistent with ventral striatum activation patterns. 

For bisexual women viewing erotic pictures, activity was greater for male relative to female stimuli in posterior midcingulate and right retrosplenial cingulate cortices, potentially suggesting greater perceptual salience and emotional memory for male erotic stimuli . Additional male-biased activations were identified bilaterally in supramarginal and angular gyri, indicating processes relating to mental imagery, or possibly mentalizing . 

Thus, in contrast to heterosexual participants, bisexual women showed greater activity towards male (relative to female) erotic pictures in affect-related brain areas. In this way, it seems that it would be overly simplistic to say that bisexual women are similar to heterosexual women, but with the addition of gynephilic interest. Rather,   bisexual women seem to have greater responses to both male and female erotic stimuli, depending on the brain area being considered  . Patterns of greater overall responsiveness are consistent with suggestions that bisexual women may be distinguished by having overall greater degrees of sexual motivation relative to heterosexual women . 

It is also notable that bisexual women uniquely showed greater activations to male stimuli in areas of the brain implicated in higher-order cognition, including mentalizing. Speculatively, these activations could be related to more complex processing of sexual motivation in bisexual women . To the degree that these activation patterns in bisexual women actually specifically reflect social cognition, the question remains open as to why this may be more likely to be observed in bisexual but not heterosexual or homosexual women. 

For homosexual women viewing erotic pictures, greater activations for female (relative to male) stimuli extended throughout the visual system, with additional clusters in occipitotemporal cortices. Clusters in the right inferior precuneus may have indicated mental imagery , and clusters in posterior parahippocampal cortex may have indicated either memory encoding or retrieval .   For homosexual women, no brain areas had significantly greater activation for male relative to female erotic pictures. Thus, homosexual women were the only group that exhibited an overall pattern of differential brain activity (between male and female sexual stimuli) greater only for pictures depicting their preferred gender  . 


### Whole brain responses to erotic videos 
  
For heterosexual women viewing erotic videos, activity was greater for female relative to male stimuli in bilateral superior temporal cortices likely indicating an auditory confound deriving from more extensive and substantial vocalizations being present in female erotic videos . Activity was greater for male relative to female videos in posterior occipital cortex, likely indicating enhanced visual attention . Further clusters (greater for male compared with female videos) in the inferolateral postcentral gyrus and parietal somatosensory association areas may have indicated awareness of bodily sensations, possibly related to sexual imagery . 

For bisexual women viewing erotic videos, activations were greater for female (relative to male) stimuli in superior temporal cortices, likely indicating the same auditory-related activity present in heterosexual women. Bisexual women’s brain activity was greater for male (relative to female) erotic videos in occipital cortex, likely indicating visual attention . Male-biased activations in somatosensory cortices may have indicated processing of bodily sensations , and further activations in bilateral superior parietal lobules, premotor and supplementary motor cortices, and right supramarginal gyrus may have indicated mental imagery or possibly mirroring with the actors shown in the videos . 

Similar to the findings for erotic pictures,   bisexual women were unique in the degree to which male videos produced activations in brain areas associated with more abstract (and possibly complex) processing  . Again, the significance of this pattern remains unclear. 

For homosexual women viewing female relative to male erotic videos, activity in superior temporal cortices likely indicated the same auditory-related processing observed in heterosexual and bisexual women, albeit more robustly and extensively, consistent with enhanced attention to emotionally salient stimulus features. When viewing male relative to female erotic videos, activations in the right somatosensory cortex may have indicated processing of bodily sensations , which may have been either positive or negative in valence. Thus, while emotionally associated brain areas did not exhibit differential activations for videos,   homosexual women’s particularly strong engagement of auditory cortices for female stimuli provided yet further evidence of uniquely gender-biased responding, relative to heterosexual and bisexual women  . 


### Comparisons with previous findings 
  
Few studies have investigated the category-specificity of brain activity in non-heterosexual women. Ponseti   et al  .  found that both heterosexual and homosexual women showed gender-specific patterns of brain activity in multiple areas, including the ventral striatum. Sylva   et al  .  also found some evidence for category-specific responding in women, although not in the ventral striatum, and without specifically testing whether or not heterosexual or homosexual women differed in their responses. 

The patterns observed Ponseti   et al  .  stand in contrast to the present investigation in which homosexual women tended to be the only group showing strongly category-specific responses to erotic stimuli. One possible interpretations for their findings of category-specific responses in all women was the unusual nature of the stimuli (i.e., close-up images of male and female genitalia, isolated from interpersonal contextual factors) . As suggested by Chivers (2017) , it may be the case that sex and gender cues can produce specific responses in heterosexual women, but that these are usually trumped by contextual factors in driving arousal responses in women. The stimuli utilized in the present study contained contextual factors (e.g. body posture, facial expression) that are more typical of those found in the genital arousal literature. 

However, it should be noted that the present study did not find support for greater category-specificity in homosexual women across all stimulus conditions. Rather, planned contrasts in the ventral striatum only revealed significant group differences between homosexual and non-homosexual women for erotic pictures. There were no significant differences in ventral striatum response between homosexual and non-homosexual women for erotic videos (even though subjective evaluations of those stimuli did significantly differ across the groups). 

This pattern of differing results for pictures versus videos may be related to differences in how individuals respond to these stimuli, limitations of our video paradigm, or both. While erotic videos may theoretically allow for the assessment of qualitatively different states of sexual response, it may be the case that incentive motivation is greatest when stimuli are first presented, but then diminishes with longer stimulus presentations . Additionally, erotic pictures may have been more effective at driving ventral striatum responses due to factors such as unpredictably varied presentation times of preferred stimuli contributing to larger magnitude reward-prediction errors . 


### Limitations 
  
One limitation of nearly all studies of erotic responses in women—including this one—is a failure to control for hormonal conditions or contraceptive usage. By default, it can generally be assumed that most women were not measured within the ovulatory window, when responses to erotic stimuli might be greatest . Additionally, a number of women may have been using hormonal contraceptives. Measuring women’s responses outside of the fertile phase of their cycles—or while they were using hormonal contraceptives —may have yielded a restricted range of arousal responses. However, the specificity of erotic responding has not been shown to be influenced by menstrual cycle in previous studies of genital arousal . 

Another source of potential limitations may have been the nature of the stimuli used. Though our stimuli were pilot-tested and rated by individuals of different sexual orientations in order to confirm that they would appeal to a broad participant sample, it is never possible to ensure that common stimuli will evoke the responses intended. This may be especially true for something as emotionally salient and individual as sexual arousal. Thus, it is possible that category specificity patterns could appear to be different if stimuli better reflected participants’ subjective preferences. This is a limitation of many studies of sexual responding, although data gleaned from more individualized stimulus sets are difficult to interpret. 

One more aspect of the stimuli that is difficult to control for is sensory details that are inherently different between male and female stimuli. Differences in actors’ vocalizations (for videos), actors’ body positions (for both videos and pictures), and actors’ body motions (in the videos) were present (on average) between male and female stimuli. These features are difficult to control for and could conceivably lead to differences in both subjective and neural responding when viewing male vs. female stimuli, especially in more primary sensory areas of the brain such as visual and auditory cortices. However, such differences may also serve to reinforce the gendered nature of the stimuli and improve their correspondence with real-world experiences and real-world arousal. 



## Conclusions 
  
Though the neural data presented here align with previously-observed patterns in women’s genital and subjective arousal, much remains unknown about the relationship between arousal patterns, orientation, and the development of sexual motivation towards particular sexes in women. Our study supports past findings indicating that women tend not to have strongly category-specific responses to erotic stimuli, with homosexual women showing somewhat greater specificity than heterosexual and bisexual women. Future research should explore the extent to which women’s non-specific sexual response contributes to erotic plasticity (i.e., change with context) and sexual fluidity (i.e., change over time) .</pre></details></details>
  <details class="inner-accordion"><summary>Coordinate-relevant source tables (2)</summary><details class="inner-accordion"><summary>Table 2 (Tab2) - Differential whole-brain activations in response to male vs. female pictures.</summary><div class="table-html"><table-wrap id="Tab2" position="float" orientation="portrait"><label>Table 2</label><caption><p>Differential whole-brain activations in response to male vs. female pictures.</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="1" rowspan="1">R/L</th><th colspan="1" rowspan="1">Region</th><th colspan="1" rowspan="1">BA</th><th colspan="1" rowspan="1">MNI</th><th colspan="1" rowspan="1">voxels</th><th colspan="1" rowspan="1">peak T</th></tr></thead><tbody><tr><td colspan="6" rowspan="1">
<italic toggle="yes">Heterosexual Women</italic>
</td></tr><tr><td colspan="6" rowspan="1">    Female &gt; Male Pictures</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">lingual gyrus, inferolateral occipital</td><td colspan="1" rowspan="1">18, 19</td><td colspan="1" rowspan="1">(−33 −76 −10)</td><td colspan="1" rowspan="1">21</td><td colspan="1" rowspan="1">8.01</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">fusiform gyrus</td><td colspan="1" rowspan="1">37</td><td colspan="1" rowspan="1">(30 −67 −7)</td><td colspan="1" rowspan="1">26</td><td colspan="1" rowspan="1">7.81</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">inferolateral occipital, fusiform gyrus</td><td colspan="1" rowspan="1">19, 37</td><td colspan="1" rowspan="1">(42 −70 −16)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.78</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">fusiform gyrus</td><td colspan="1" rowspan="1">37</td><td colspan="1" rowspan="1">(30 −58 −10)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.59</td></tr><tr><td colspan="6" rowspan="1">    Male &gt; Female Pictures: no differential activations</td></tr><tr><td colspan="6" rowspan="1">
<italic toggle="yes">Bisexual Women</italic>
</td></tr><tr><td colspan="6" rowspan="1">    Female &gt; Male Pictures</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">inferior occipital cortex, middle occipital gyrus, lingual gyrus</td><td colspan="1" rowspan="1">18, 19</td><td colspan="1" rowspan="1">(36 −70 −10)</td><td colspan="1" rowspan="1">86</td><td colspan="1" rowspan="1">10.68</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">19</td><td colspan="1" rowspan="1">(48 −64 −10)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.96</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">fusiform gyrus</td><td colspan="1" rowspan="1">37</td><td colspan="1" rowspan="1">(33 −55 −13)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.15</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">inferolateral occipital, middle occipital gyrus</td><td colspan="1" rowspan="1">19, 18</td><td colspan="1" rowspan="1">(−39 −85 −7)</td><td colspan="1" rowspan="1">138</td><td colspan="1" rowspan="1">9.07</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">18, 19</td><td colspan="1" rowspan="1">(−30 −88 5)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">8.47</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">inferior occipital gyrus, primary visual cortex, lingual gyrus</td><td colspan="1" rowspan="1">18, 17</td><td colspan="1" rowspan="1">(−24 −94 −4)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">8.06</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">occipital cortex, middle occipital gyrus</td><td colspan="1" rowspan="1">19</td><td colspan="1" rowspan="1">(30 −79 17)</td><td colspan="1" rowspan="1">43</td><td colspan="1" rowspan="1">9.03</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">occipital cortex, middle occipital gyrus</td><td colspan="1" rowspan="1">19</td><td colspan="1" rowspan="1">(30 −82 26)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.38</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">inferior occipital cortex, lingual gyrus</td><td colspan="1" rowspan="1">18</td><td colspan="1" rowspan="1">(−24 −85 −13)</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">8.22</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">primary visual cortex, cuneus</td><td colspan="1" rowspan="1">17</td><td colspan="1" rowspan="1">(15 −100 −4)</td><td colspan="1" rowspan="1">12</td><td colspan="1" rowspan="1">8.09</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">18</td><td colspan="1" rowspan="1">(42 −82 −1)</td><td colspan="1" rowspan="1">27</td><td colspan="1" rowspan="1">8.05</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">18</td><td colspan="1" rowspan="1">(27 −85 2)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.62</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">18</td><td colspan="1" rowspan="1">(33 −91 8)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">6.86</td></tr><tr><td colspan="2" rowspan="1">    Male &gt; Female Pictures</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1" /></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">angular gyrus, supramarginal gyrus</td><td colspan="1" rowspan="1">39, 40</td><td colspan="1" rowspan="1">(−51 −64 41)</td><td colspan="1" rowspan="1">21</td><td colspan="1" rowspan="1">9.37</td></tr><tr><td colspan="1" rowspan="1">      R/L</td><td colspan="1" rowspan="1">posterior cingulate</td><td colspan="1" rowspan="1">23</td><td colspan="1" rowspan="1">(0 −22 35)</td><td colspan="1" rowspan="1">10</td><td colspan="1" rowspan="1">8.23</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">angular gyrus</td><td colspan="1" rowspan="1">39</td><td colspan="1" rowspan="1">(48 −61 35)</td><td colspan="1" rowspan="1">27</td><td colspan="1" rowspan="1">7.94</td></tr><tr><td colspan="1" rowspan="1">       R</td><td colspan="1" rowspan="1">supramarginal gyrus</td><td colspan="1" rowspan="1">40</td><td colspan="1" rowspan="1">(51 −61 44)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.75</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">retrosplenial cingulate</td><td colspan="1" rowspan="1">30</td><td colspan="1" rowspan="1">(15 −52 29)</td><td colspan="1" rowspan="1">6</td><td colspan="1" rowspan="1">7.68</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">supramarginal gyrus</td><td colspan="1" rowspan="1">40</td><td colspan="1" rowspan="1">(57 −49 35)</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">7.38</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">supramarginal gyrus</td><td colspan="1" rowspan="1">40</td><td colspan="1" rowspan="1">(−36 −61 44)</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">7.08</td></tr><tr><td colspan="6" rowspan="1">
<italic toggle="yes">Homosexual Women</italic>
</td></tr><tr><td colspan="6" rowspan="1">    Female &gt; Male Pictures</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">19</td><td colspan="1" rowspan="1">(−27 −82 14)</td><td colspan="1" rowspan="1">139</td><td colspan="1" rowspan="1">10.01</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">18, 19</td><td colspan="1" rowspan="1">(−33 −88 −1)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">8.99</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">middle occipital gyrus, primary visual cortex</td><td colspan="1" rowspan="1">18, 17</td><td colspan="1" rowspan="1">(−18 −97 2)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">8.57</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">19</td><td colspan="1" rowspan="1">(33 −79 14)</td><td colspan="1" rowspan="1">89</td><td colspan="1" rowspan="1">9.83</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">inferior lateral occipital cortex</td><td colspan="1" rowspan="1">19</td><td colspan="1" rowspan="1">(42 −85 2)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">8.19</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">19</td><td colspan="1" rowspan="1">(33 −70 8)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.78</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">fusiform gyrus, posterior paraphippocampal gyrus</td><td colspan="1" rowspan="1">37</td><td colspan="1" rowspan="1">(33 −52 −10)</td><td colspan="1" rowspan="1">36</td><td colspan="1" rowspan="1">9.56</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">fusiform gyrus, middle occipital gyrus</td><td colspan="1" rowspan="1">18</td><td colspan="1" rowspan="1">(33 −70 −13)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">8.03</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">primary visual cortex</td><td colspan="1" rowspan="1">17</td><td colspan="1" rowspan="1">(18 −94 −1)</td><td colspan="1" rowspan="1">11</td><td colspan="1" rowspan="1">8.56</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">fusiform gyrus, lingual gyrus, posterior parahippocampal gyrus</td><td colspan="1" rowspan="1">37</td><td colspan="1" rowspan="1">(−33 −61 −7)</td><td colspan="1" rowspan="1">26</td><td colspan="1" rowspan="1">8.45</td></tr><tr><td colspan="1" rowspan="1">       L</td><td colspan="1" rowspan="1">fusiform gyrus</td><td colspan="1" rowspan="1">37</td><td colspan="1" rowspan="1">(−39 −61 −13)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.62</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">precuneus, occipitoparietal</td><td colspan="1" rowspan="1">7</td><td colspan="1" rowspan="1">(24 −73 41)</td><td colspan="1" rowspan="1">6</td><td colspan="1" rowspan="1">7.18</td></tr><tr><td colspan="6" rowspan="1">    Male &gt; Female Pictures: no differential activations</td></tr></tbody></table></table-wrap></div></details><details class="inner-accordion"><summary>Table 3 (Tab3) - Differential whole-brain activations in response to male vs. female videos.</summary><div class="table-html"><table-wrap id="Tab3" position="float" orientation="portrait"><label>Table 3</label><caption><p>Differential whole-brain activations in response to male vs. female videos.</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="1" rowspan="1">R/L</th><th colspan="1" rowspan="1">Region</th><th colspan="1" rowspan="1">BA</th><th colspan="1" rowspan="1">MNI</th><th colspan="1" rowspan="1">voxels</th><th colspan="1" rowspan="1">peak T</th></tr></thead><tbody><tr><td colspan="6" rowspan="1">
<italic toggle="yes">Heterosexual Women</italic>
</td></tr><tr><td colspan="6" rowspan="1">    Female &gt; Male Videos</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">superior temporal gyrus, primary and secondary auditory cortex</td><td colspan="1" rowspan="1">22, 41, 42</td><td colspan="1" rowspan="1">(−57 −25 8)</td><td colspan="1" rowspan="1">124</td><td colspan="1" rowspan="1">11.71</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">superior temporal gyrus, primary and secondary auditory cortex</td><td colspan="1" rowspan="1">22, 41, 42</td><td colspan="1" rowspan="1">(−42 −31 11)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">10.15</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">superior temporal gyrus</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">(−66 −28 8)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">8.99</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">superior temporal gyrus, primary and secondary auditory cortex</td><td colspan="1" rowspan="1">22, 41, 42</td><td colspan="1" rowspan="1">(54 −16 −1)</td><td colspan="1" rowspan="1">48</td><td colspan="1" rowspan="1">10.42</td></tr><tr><td colspan="6" rowspan="1">    Male &gt; Female Videos</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">primary visual cortex, lingual gyrus</td><td colspan="1" rowspan="1">17, 18</td><td colspan="1" rowspan="1">(−9 −82 2)</td><td colspan="1" rowspan="1">30</td><td colspan="1" rowspan="1">10.14</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">inferolateral postcentral gyrus</td><td colspan="1" rowspan="1">3</td><td colspan="1" rowspan="1">(60 −16 29)</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">7.94</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">superior parietal lobule</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">(33 −49 62)</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">7.64</td></tr><tr><td colspan="6" rowspan="1">
<italic toggle="yes">Bisexual Women</italic>
</td></tr><tr><td colspan="6" rowspan="1">    Female &gt; Male Videos</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">superior temporal, primary and secondary auditory cortex</td><td colspan="1" rowspan="1">22, 41, 42</td><td colspan="1" rowspan="1">(−54 −10 5)</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">8.83</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">superior temporal gyrus</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">(63 −25 2)</td><td colspan="1" rowspan="1">8</td><td colspan="1" rowspan="1">7.26</td></tr><tr><td colspan="6" rowspan="1">    Male &gt; Female Videos</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">superior parietal lobule, extending into supramarginal gyrus</td><td colspan="1" rowspan="1">7, 5, 40</td><td colspan="1" rowspan="1">(36 −46 59)</td><td colspan="1" rowspan="1">211</td><td colspan="1" rowspan="1">11.55</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">postcentral gyrus</td><td colspan="1" rowspan="1">3, 1, 2</td><td colspan="1" rowspan="1">(36 −37 53)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">11.27</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">postcentral sulcus</td><td colspan="1" rowspan="1">1, 2</td><td colspan="1" rowspan="1">(33 −31 41)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">9.51</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">postcentral gyrus, postcentral sulcus</td><td colspan="1" rowspan="1">3, 1, 2</td><td colspan="1" rowspan="1">(−36 −37 56)</td><td colspan="1" rowspan="1">25</td><td colspan="1" rowspan="1">8.45</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">superior parietal lobule</td><td colspan="1" rowspan="1">5, 7</td><td colspan="1" rowspan="1">(−33 −49 59)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.55</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">supplementary motor area</td><td colspan="1" rowspan="1">6</td><td colspan="1" rowspan="1">(30 −10 59)</td><td colspan="1" rowspan="1">12</td><td colspan="1" rowspan="1">8.14</td></tr><tr><td colspan="1" rowspan="1">       L</td><td colspan="1" rowspan="1">supplementary motor area</td><td colspan="1" rowspan="1">6</td><td colspan="1" rowspan="1">(−24 −13 62)</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">7.73</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">cuneus</td><td colspan="1" rowspan="1">17</td><td colspan="1" rowspan="1">(−9 −82 2)</td><td colspan="1" rowspan="1">9</td><td colspan="1" rowspan="1">7.6</td></tr><tr><td colspan="6" rowspan="1">
<italic toggle="yes">Homosexual Women</italic>
</td></tr><tr><td colspan="6" rowspan="1">    Female &gt; Male Videos</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">superior temporal gyrus</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">(51 −10 2)</td><td colspan="1" rowspan="1">578</td><td colspan="1" rowspan="1">14.22</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">primary and secondary auditory cortex, superior temporal gyrus</td><td colspan="1" rowspan="1">41 42, 22</td><td colspan="1" rowspan="1">(54 −19 5)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">13.91</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">superior temporal gyrus</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">(60 −1 −4)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">13.26</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">superior temporal gyrus</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">(−63 −19 2)</td><td colspan="1" rowspan="1">247</td><td colspan="1" rowspan="1">12.7</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">primary and secondary auditory cortex</td><td colspan="1" rowspan="1">41, 42</td><td colspan="1" rowspan="1">(−45 −25 8)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">11.97</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">superior temporal gyrus</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">(−66 −28 5)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">10.99</td></tr><tr><td colspan="6" rowspan="1">     Male &gt; Female Videos</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">postcentral gyrus</td><td colspan="1" rowspan="1">3</td><td colspan="1" rowspan="1">(33 −34 47)</td><td colspan="1" rowspan="1">7</td><td colspan="1" rowspan="1">7.99</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">postcentral sulcus</td><td colspan="1" rowspan="1">2</td><td colspan="1" rowspan="1">(42 −28 41)</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">7.76</td></tr></tbody></table></table-wrap></div></details></details>
</details>


<details class="doc-card">
  <summary><strong>PMID 16406606</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 0 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/16406606/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>16406606_analysis_0</td><td>Active conditions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task assesses self vs. other (ownership) detection—falls under Perception and Understanding of Self, which is encompassed by Social Processing.</td></tr>
<tr><td>16406606_analysis_1</td><td>Passive conditions</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Task examines visuo-motor/proprioceptive synchrony and agency detection for self vs non-self movement, not social interactions or social-cognitive processing; does not meet inclusion criteria I1/I2 for social processing.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>16406606_1</td><td>Active conditions &gt; passive conditions; others</td><td>16406606_analysis_1</td><td>Passive conditions</td><td>0.643</td><td>1.000</td><td>0.893</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 21569855</strong> | Pred included: 0 | Manual included (accepted matches only): 1 | Correct overlaps: 0 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/21569855/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>21569855_analysis_0</td><td>Incongruent &gt; Congruent</td><td class="decision-cell"><span class="decision-pill decision-none">?</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td>manual+ (accepted)</td><td></td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>21569855_1</td><td>Incongruent &gt; Congruent; others</td><td>21569855_analysis_0</td><td>Incongruent &gt; Congruent</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 21664277</strong> | Pred included: 0 | Manual included (accepted matches only): 2 | Correct overlaps: 0 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/21664277/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>21664277_analysis_0</td><td>a Social alliance vs. ‘number equal’ (see Fig. 3)</td><td class="decision-cell"><span class="decision-pill decision-none">?</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td>manual+ (accepted)</td><td></td></tr>
<tr><td>21664277_analysis_1</td><td>b Social hierarchy vs. fame, age, gender and ‘no. higher / lower’ (see Fig. 4)</td><td class="decision-cell"><span class="decision-pill decision-none">?</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td>manual+ (accepted)</td><td></td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>21664277_1</td><td>Social alliance vs. ‘number equal’; affiliation</td><td>21664277_analysis_0</td><td>a Social alliance vs. ‘number equal’ (see Fig. 3)</td><td>0.819</td><td>1.000</td><td>0.946</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>21664277_2</td><td>Social hierarchy vs. fame, age, gender and ‘no. higher / lower’; affiliation</td><td>21664277_analysis_1</td><td>b Social hierarchy vs. fame, age, gender and ‘no. higher / lower’ (see Fig. 4)</td><td>0.894</td><td>1.000</td><td>0.968</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 28931014</strong> | Pred included: 0 | Manual included (accepted matches only): 2 | Correct overlaps: 0 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/28931014/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>28931014_analysis_0</td><td>Fingerspelling &gt; Letter</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>The analysis is a phonological working memory task contrasting letters and fingerspelling during maintenance; it does not involve social tasks, interactions, or social perception. Fingerspelling is linguistic/visuomotor, not measuring social processing.</td></tr>
<tr><td>28931014_analysis_1</td><td>Letter &gt; Fingerspelling</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>This is a verbal working-memory task (letters vs fingerspelling) that does not probe social interactions, social perception, emotion, or other social constructs. Although fingerspelling uses hand movements, the stimuli are linguistic and the task is memory of nonsense syllable sequences rather than any social communication or social-cognitive judgment.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>28931014_1</td><td>Fingerspelling &gt; Letter; socialcommunication</td><td>28931014_analysis_0</td><td>Fingerspelling &gt; Letter</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>28931014_2</td><td>Letter &gt; Fingerspelling; socialcommunication</td><td>28931014_analysis_1</td><td>Letter &gt; Fingerspelling</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>
</details></section>
  
</body>
</html>
