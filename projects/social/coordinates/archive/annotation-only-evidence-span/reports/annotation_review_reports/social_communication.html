<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>social_communication review report</title>
  <style>
    :root {
      --bg: #f7f6f2;
      --panel: #ffffff;
      --ink: #1d2730;
      --line: #d8dde3;
    }
    body { margin: 0; padding: 1.25rem; font-family: "IBM Plex Sans", "Segoe UI", sans-serif; background: var(--bg); color: var(--ink); }
    header { background: var(--panel); border: 1px solid var(--line); border-radius: 10px; padding: 1rem; margin-bottom: 1rem; }
    .top-nav { position: sticky; top: 0; z-index: 10; display: flex; flex-wrap: wrap; gap: 0.5rem; background: #eef3f2; border: 1px solid var(--line); border-radius: 10px; padding: 0.6rem; margin-bottom: 1rem; }
    .top-nav a { display: inline-block; padding: 0.35rem 0.6rem; border: 1px solid var(--line); border-radius: 999px; background: #fff; text-decoration: none; font-size: 0.9rem; color: #0e4f85; }
    section { margin-bottom: 1rem; }
    .bucket > summary, .doc-card > summary, .inner-accordion > summary { cursor: pointer; }
    .doc-card { background: var(--panel); border: 1px solid var(--line); border-radius: 10px; padding: 0.85rem; margin-bottom: 0.85rem; }
    .table-wrap, .table-html { overflow-x: auto; }
    .inner-accordion { margin-top: 0.6rem; border-top: 1px dashed var(--line); padding-top: 0.4rem; }
    .paper-text { white-space: pre-wrap; max-height: 26rem; overflow-y: auto; background: #fbfcfe; border: 1px solid var(--line); border-radius: 8px; padding: 0.6rem; font-size: 0.88rem; line-height: 1.35; }
    table { width: 100%; border-collapse: collapse; font-size: 0.9rem; }
    th, td { border: 1px solid var(--line); padding: 0.45rem; vertical-align: top; text-align: left; }
    th { background: #edf2f5; }
    .decision-cell, .confusion-cell { text-align: center; vertical-align: middle; }
    .decision-pill, .confusion-pill {
      display: inline-flex;
      align-items: center;
      justify-content: center;
      min-width: 1.55rem;
      padding: 0.12rem 0.45rem;
      border-radius: 999px;
      font-weight: 700;
      font-size: 0.82rem;
      border: 1px solid transparent;
    }
    .decision-include { background: #e9f8ef; color: #1f7a3d; border-color: #b7e4c6; }
    .decision-exclude { background: #fdecec; color: #9b1c1c; border-color: #f6caca; }
    .decision-none { background: #f2f4f7; color: #5b6775; border-color: #dde3ea; }
    .confusion-good { background: #e9f8ef; color: #166534; border-color: #b7e4c6; }
    .confusion-bad { background: #fdecec; color: #991b1b; border-color: #f6caca; }
    .confusion-na { background: #f2f4f7; color: #5b6775; border-color: #dde3ea; }
    a { color: #0e4f85; }
  </style>
</head>
<body>
  <header>
    <a id="top"></a>
    <h1>social_communication report</h1>
    <p>Manual benchmark is sliced to the auto PMID universe from <code>outputs/nimads_annotation.json</code>. Analysis-level row is evaluated only on manual analyses with an assigned auto match (truth positives are accepted fuzzy matches only).</p>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Level</th>
            <th>TP</th>
            <th>FP</th>
            <th>FN</th>
            <th>Precision</th>
            <th>Recall</th>
            <th>F1</th>
            <th>Manual Positives</th>
            <th>Predicted Positives</th>
            <th>Universe</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Document bucket overlap</td>
            <td>26</td>
            <td>37</td>
            <td>7</td>
            <td>0.413</td>
            <td>0.788</td>
            <td>0.542</td>
            <td>33</td>
            <td>63</td>
            <td>70</td>
          </tr>
          <tr>
            <td>Study inclusion</td>
            <td>44</td>
            <td>21</td>
            <td>11</td>
            <td>0.677</td>
            <td>0.800</td>
            <td>0.733</td>
            <td>55</td>
            <td>65</td>
            <td>128</td>
          </tr>
          <tr>
            <td>Analysis inclusion (matched manual universe; accepted=positive)</td>
            <td>66</td>
            <td>51</td>
            <td>15</td>
            <td>0.564</td>
            <td>0.815</td>
            <td>0.667</td>
            <td>81</td>
            <td>117</td>
            <td>170</td>
          </tr>
        </tbody>
      </table>
    </div>
  </header>
  <nav class="top-nav">
    <a href="#bucket-correct">Correct (26)</a>
    <a href="#bucket-false-positive">False Positive (37)</a>
    <a href="#bucket-false-negative">False Negative (7)</a>
    <a href="#missing-manual">Missing PMIDs (0)</a>
    <a href="#top">Top</a>
  </nav>
  <section id="bucket-correct"><details class="bucket"><summary><h2>Correct (26)</h2></summary><p><strong>Match status totals:</strong> accepted=69 | uncertain=10 | unmatched=18</p>
<details class="doc-card">
  <summary><strong>PMID 15808992</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/15808992/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>15808992_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;activation in the right hemisphere, including the inferior parietal lobule, inferior frontal gyrus, and inferior occipital gyrus.&quot;</td></tr>
<tr><td>15808992_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Other–self contrast shows signal changes in the precuneus, ventromedial prefrontal cortex, dorsomedial prefrontal cortex.&quot;</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>15808992_1</td><td>Other - Self; socialcommunication</td><td>15808992_analysis_1</td><td>analysis_1</td><td>0.140</td><td>1.000</td><td>0.742</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>15808992_2</td><td>Self - Other; socialcommunication</td><td>15808992_analysis_0</td><td>analysis_0</td><td>0.140</td><td>1.000</td><td>0.742</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 16035037</strong> | Pred included: 5 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/16035037/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>16035037_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;unknown face vs. scrambled face&quot;.</td></tr>
<tr><td>16035037_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;familiar face vs. unknown face&quot;.</td></tr>
<tr><td>16035037_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;self-face vs. unknown distracter face&quot;.</td></tr>
<tr><td>16035037_analysis_3</td><td>analysis_3</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;familiar minus self contrast&quot;.</td></tr>
<tr><td>16035037_analysis_4</td><td>analysis_4</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;self minus familiar contrast&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>16035037_1</td><td>distracter &gt; null; socialcommunication</td><td>16035037_analysis_0</td><td>analysis_0</td><td>0.148</td><td>1.000</td><td>0.744</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16035037_2</td><td>familiar face &gt; distracter; socialcommunication</td><td>16035037_analysis_1</td><td>analysis_1</td><td>0.222</td><td>1.000</td><td>0.767</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16035037_3</td><td>familiar face &gt; self face; socialcommunication</td><td>16035037_analysis_3</td><td>analysis_3</td><td>0.171</td><td>1.000</td><td>0.751</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16035037_4</td><td>self face &gt; distracter; socialcommunication</td><td>16035037_analysis_2</td><td>analysis_2</td><td>0.188</td><td>1.000</td><td>0.756</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16035037_5</td><td>self face &gt; famililar face; socialcommunication</td><td>16035037_analysis_4</td><td>analysis_4</td><td>0.140</td><td>1.000</td><td>0.742</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 16171833</strong> | Pred included: 5 | Manual included (accepted matches only): 6 | Correct overlaps: 5 | Match statuses: accepted=6, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/16171833/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>16171833_analysis_0</td><td>a) Common activations of social interaction (SOC &gt; ARB)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Perception of socially relevant facial expressions (SOC&gt;ARB)&quot;.</td></tr>
<tr><td>16171833_analysis_1</td><td>b) Common activations of arbitrary facial movements (ARB &gt; SOC)</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Excluded because this contrast emphasizes arbitrary (non-communicative) facial movements over social ones and thus does not index Social Communication as defined (missing SOCIAL_COMMUNICATION_I2).</td></tr>
<tr><td>16171833_analysis_2</td><td>c) Common activations of self-involvement (ME &gt; OTHER)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;being gazed at by virtual characters (ME&gt;OTHER)&quot;.</td></tr>
<tr><td>16171833_analysis_3</td><td>d) Common activations of other-related activity (OTHER &gt; ME)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;precuneus for OTHER&gt;ME&quot; (observation of others&#x27; interactions).</td></tr>
<tr><td>16171833_analysis_4</td><td>analysis_4</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;SOC×ME (interaction) observed in right ventral medial prefrontal cortex and STG&quot;.</td></tr>
<tr><td>16171833_analysis_5</td><td>analysis_5</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;SOC×OTHER&quot; (social signals directed towards someone else recruit parietal processing).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>16171833_1</td><td>ARB &gt; SOC; socialcommunication</td><td>16171833_analysis_1</td><td>b) Common activations of arbitrary facial movements (ARB &gt; SOC)</td><td>0.250</td><td>1.000</td><td>0.775</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16171833_2</td><td>ME &gt; OTHER; socialcommunication</td><td>16171833_analysis_2</td><td>c) Common activations of self-involvement (ME &gt; OTHER)</td><td>0.312</td><td>1.000</td><td>0.794</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16171833_3</td><td>OTHER &gt; ME; socialcommunication</td><td>16171833_analysis_3</td><td>d) Common activations of other-related activity (OTHER &gt; ME)</td><td>0.286</td><td>1.000</td><td>0.786</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16171833_4</td><td>SOC &gt; ARB; socialcommunication</td><td>16171833_analysis_0</td><td>a) Common activations of social interaction (SOC &gt; ARB)</td><td>0.281</td><td>1.000</td><td>0.784</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16171833_5</td><td>SOC x ME&gt;Other; socialcommunication</td><td>16171833_analysis_4</td><td>analysis_4</td><td>0.128</td><td>1.000</td><td>0.738</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16171833_6</td><td>SOC x OTHER&gt; ME; socialcommunication</td><td>16171833_analysis_5</td><td>analysis_5</td><td>0.128</td><td>1.000</td><td>0.738</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 16759672</strong> | Pred included: 2 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=1, unmatched=2</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/16759672/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> faces associated with aggressive behaviors &gt; faces associated with disgusting behaviors; socialcommunication, faces associated with nice behaviors &gt; faces associated with neutral behaviors; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>16759672_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;scanned while engaged in a one-back recognition task in which they saw the faces that were associated with behaviors and 30 novel faces.&quot;</td></tr>
<tr><td>16759672_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;faces associated with disgusting behaviors evoked a stronger response in left anterior insula than faces associated with aggressive behaviors.&quot;</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>16759672_1</td><td>face associated with behavior &gt; novel faces; socialcommunication</td><td>16759672_analysis_0</td><td>analysis_0</td><td>0.151</td><td>1.000</td><td>0.745</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>16759672_2</td><td>faces associated with aggressive behaviors &gt; faces associated with disgusting behaviors; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>16759672_3</td><td>faces associated with disgusting behaviors &gt; faces associated with aggressive behaviors; socialcommunication</td><td>16759672_analysis_1</td><td>analysis_1</td><td>0.082</td><td>0.895</td><td>0.651</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>16759672_4</td><td>faces associated with nice behaviors &gt; faces associated with neutral behaviors; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 17408704</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/17408704/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>17408704_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;explicit emotion recognition&quot;.</td></tr>
<tr><td>17408704_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;explicit emotion recognition&quot;.</td></tr>
<tr><td>17408704_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;explicit emotion recognition&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>17408704_1</td><td>explicit (emotion) &gt; baseline; socialcommunication</td><td>17408704_analysis_0</td><td>analysis_0</td><td>0.154</td><td>1.000</td><td>0.746</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>17408704_2</td><td>explicit (emotion) &gt; implicit (age); socialcommunication</td><td>17408704_analysis_2</td><td>analysis_2</td><td>0.121</td><td>1.000</td><td>0.736</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>17408704_3</td><td>implicit (age) &gt; baseline; socialcommunication</td><td>17408704_analysis_1</td><td>analysis_1</td><td>0.179</td><td>1.000</td><td>0.754</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18633834</strong> | Pred included: 10 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=2, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18633834/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18633834_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;footstep sounds of one or two persons walking&quot;.</td></tr>
<tr><td>18633834_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;footstep sounds of one or two persons walking&quot;.</td></tr>
<tr><td>18633834_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;footstep sounds of one or two persons walking&quot;.</td></tr>
<tr><td>18633834_analysis_3</td><td>analysis_3</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;STEP1 – NOISE1 revealed activations in the left STSp and left amygdala, and contrast STEP2 – NOISE2 in subcallosal gyrus, right temporal pole, and right amygdala.&quot;</td></tr>
<tr><td>18633834_analysis_4</td><td>analysis_4</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;STEP1 – NOISE1 revealed activations in the left STSp and left amygdala, and contrast STEP2 – NOISE2 in subcallosal gyrus, right temporal pole, and right amygdala.&quot;</td></tr>
<tr><td>18633834_analysis_5</td><td>analysis_5</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;These areas seem to be involved in the analysis of persons&#x27; identity and complex social stimuli on the basis of auditory cues.&quot;</td></tr>
<tr><td>18633834_analysis_6</td><td>analysis_6</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;the right temporal pole is involved in the analysis of features revealing personal identity within the social auditory scene&quot;.</td></tr>
<tr><td>18633834_analysis_7</td><td>analysis_7</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;STSp was activated bilaterally in STEP1 + STEP2 – REST and the activation was lateralized to left in STEP1 – NOISE1&quot;.</td></tr>
<tr><td>18633834_analysis_8</td><td>analysis_8</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;The contrast STEP2 – NOISE2 revealed activation in the right temporal pole&quot;.</td></tr>
<tr><td>18633834_analysis_9</td><td>analysis_9</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;the amygdalar activations in both STEP – NOISE contrasts were strongly contributed by the suppressive effects of the noise bursts&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18633834_1</td><td>(STEP2 - NOISE2) - (STEP1 - NOISE1); socialcommunication</td><td>18633834_analysis_2</td><td>analysis_2</td><td>0.178</td><td>1.000</td><td>0.753</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>18633834_2</td><td>NOISE1 + NOISE2 - REST; socialcommunication</td><td>18633834_analysis_1</td><td>analysis_1</td><td>0.250</td><td>1.000</td><td>0.775</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>18633834_3</td><td>STEP1 + STEP2 - REST; socialcommunication</td><td>18633834_analysis_0</td><td>analysis_0</td><td>0.133</td><td>1.000</td><td>0.740</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>18633834_4</td><td>STEP1 - NOISE1; socialcommunication</td><td>18633834_analysis_5</td><td>analysis_5</td><td>0.250</td><td>0.833</td><td>0.658</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>18633834_5</td><td>STEP1 - STEP1; socialcommunication</td><td>18633834_analysis_9</td><td>analysis_9</td><td>0.174</td><td>1.000</td><td>0.752</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>18633834_6</td><td>STEP2 - NOISE2; socialcommunication</td><td>18633834_analysis_7</td><td>analysis_7</td><td>0.250</td><td>0.733</td><td>0.588</td><td>uncertain</td><td>coord_count_mismatch</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 19048432</strong> | Pred included: 4 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=2, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/19048432/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>19048432_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Viewing the eye stimuli was associated, as a main effect, with enhanced activation within the right fusiform cortex&quot;.</td></tr>
<tr><td>19048432_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Activity within left amygdala and left superior temporal sulcus responded to the magnitude of dynamic changes&quot;.</td></tr>
<tr><td>19048432_analysis_2</td><td>Interaction between feedback condition and variance in pupil size (negative &gt; positive)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;discordance between observed and observer&#x27;s pupillary changes enhanced activity within bilateral anterior insula, left amygdala and anterior cingulate&quot;.</td></tr>
<tr><td>19048432_analysis_3</td><td>Interaction between feedback condition and variance in pupil size (positive &gt; negative)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Pupil change in the positive feedback condition was associated with increasing activity within right frontal operculum&quot;.</td></tr>
<tr><td>19048432_analysis_4</td><td>Interaction between feedback condition and variance in pupil size (positive &gt; negative) - Regions of interest</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because this analysis is an ROI analysis and thus fails the global whole-brain inclusion criteria.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>19048432_1</td><td>Interaction between feedback condition and variance in pupil size (positive &gt; negative); socialcommunication</td><td>19048432_analysis_3</td><td>Interaction between feedback condition and variance in pupil size (positive &gt; negative)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>19048432_2</td><td>Main effect of change in observed and observer’s pupil size; socialcommunication</td><td>19048432_analysis_1</td><td>analysis_1</td><td>0.174</td><td>0.750</td><td>0.577</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>19048432_3</td><td>Main effect of viewing eyes; socialcommunication</td><td>19048432_analysis_0</td><td>analysis_0</td><td>0.172</td><td>0.833</td><td>0.635</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 19347874</strong> | Pred included: 5 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=1, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/19347874/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Coorelation -- attachment avoidance with brain responses to masked sad faces; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>19347874_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Brain regions exhibiting significantly increased activation in response to masked sad faces compared to neutral faces&quot;.</td></tr>
<tr><td>19347874_analysis_1</td><td>Masked happy faces &gt; neutral faces (increased activation)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Brain regions exhibiting significantly increased activation in response to masked happy faces compared to neutral faces&quot;.</td></tr>
<tr><td>19347874_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Negative correlations of attachment avoidance with brain responses to masked sad faces&quot;.</td></tr>
<tr><td>19347874_analysis_3</td><td>analysis_3</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Attachment avoidance was positively related to activation of the bilateral paracentral lobules (BA 5) in response to masked happy faces.&quot;</td></tr>
<tr><td>19347874_analysis_4</td><td>analysis_4</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Significant negative correlations were found between attachment avoidance and responses of the left inferior frontal gyrus and the left middle temporal gyrus to masked happy facial expression.&quot;</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>19347874_1</td><td>Coorelation -- attachment avoidance with brain responses to masked sad faces; socialcommunication</td><td>19347874_analysis_3</td><td>analysis_3</td><td>0.093</td><td>0.500</td><td>0.378</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>19347874_2</td><td>Masked sad faces &gt; neutral faces; socialcommunication</td><td>19347874_analysis_0</td><td>analysis_0</td><td>0.238</td><td>1.000</td><td>0.771</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>19347874_3</td><td>Negative coorelation -- attachment avoidance with brain responsed to masked sad faces; socialcommunication</td><td>19347874_analysis_2</td><td>analysis_2</td><td>0.086</td><td>0.857</td><td>0.626</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>19347874_4</td><td>masked happy faces &gt; neutral faces; socialcommunication</td><td>19347874_analysis_1</td><td>Masked happy faces &gt; neutral faces (increased activation)</td><td>0.768</td><td>1.000</td><td>0.930</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 20056152</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/20056152/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>20056152_analysis_0</td><td>Places &gt; bodies</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;virtual avatar shift his gaze to pictures of bodies or places&quot;.</td></tr>
<tr><td>20056152_analysis_1</td><td>Bodies &gt; places</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;joint attention&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>20056152_1</td><td>Bodies &gt; Places; socialcommunication</td><td>20056152_analysis_1</td><td>Bodies &gt; places</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>20056152_2</td><td>Places &gt; Bodies; socialcommunication</td><td>20056152_analysis_0</td><td>Places &gt; bodies</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 20096792</strong> | Pred included: 5 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=1, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/20096792/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Live &gt; Recorded; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>20096792_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;interacted with a human experimenter face-to-face&quot;.</td></tr>
<tr><td>20096792_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;greater activation during live presentation of a person as compared to a video recording&quot;.</td></tr>
<tr><td>20096792_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;face-to-face interactions engaged social-cognitive brain regions&quot;.</td></tr>
<tr><td>20096792_analysis_3</td><td>Experiment 2: Joint Attention &gt; Solo Attention (p &lt; .05, corrected)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;the participant followed the experimenter&#x27;s gaze to the correct house&quot;.</td></tr>
<tr><td>20096792_analysis_4</td><td>Experiment 2: Joint Attention vs Solo Attention — p &lt; .001, uncorrected</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;gaze following (participant follows experimenter&#x27;s gaze)&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>20096792_1</td><td>Live &gt; Recorded; socialcommunication</td><td>20096792_analysis_0</td><td>analysis_0</td><td>0.160</td><td>0.667</td><td>0.515</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>20096792_2</td><td>Recorded &gt; Live; socialcommunication</td><td>20096792_analysis_2</td><td>analysis_2</td><td>0.160</td><td>1.000</td><td>0.748</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>20096792_3</td><td>JA &gt; SA; socialcommunication</td><td>20096792_analysis_3</td><td>Experiment 2: Joint Attention &gt; Solo Attention (p &lt; .05, corrected)</td><td>0.253</td><td>0.700</td><td>0.566</td><td>uncertain</td><td>coord_count_mismatch</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23298748</strong> | Pred included: 3 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=2</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23298748/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> interaction between sociality and working memory load; socialcommunication, sociality &gt; working memory load; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23298748_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;participants were instructed to focus on the trustworthiness of each face&quot;.</td></tr>
<tr><td>23298748_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;participants were instructed to focus on the trustworthiness of each face&quot;.</td></tr>
<tr><td>23298748_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;participants were instructed to focus on the trustworthiness of each face&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23298748_1</td><td>interaction between sociality and working memory load; socialcommunication</td><td>23298748_analysis_2</td><td>analysis_2</td><td>0.127</td><td>0.308</td><td>0.253</td><td>unmatched</td><td>low_total_score</td></tr><tr><td>23298748_2</td><td>sociality &gt; working memory load; socialcommunication</td><td>23298748_analysis_0</td><td>analysis_0</td><td>0.146</td><td>0.062</td><td>0.088</td><td>unmatched</td><td>low_total_score</td></tr><tr><td>23298748_3</td><td>working memory load &gt; sociality; socialcommunication</td><td>23298748_analysis_1</td><td>analysis_1</td><td>0.195</td><td>1.000</td><td>0.759</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23667619</strong> | Pred included: 4 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23667619/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23667619_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Laughter is an ancient signal of social communication&quot;.</td></tr>
<tr><td>23667619_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;perception of laughter as non-verbal vocal communication&quot;.</td></tr>
<tr><td>23667619_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;modulations of cerebral connectivity associated with different laughter types&quot;.</td></tr>
<tr><td>23667619_analysis_3</td><td>analysis_3</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;large parts of the bilateral primary auditory and auditory association cortex (R and L STG/MTG)&quot; activated by laughter stimuli.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23667619_1</td><td>CAT &gt; COU; socialcommunication</td><td>23667619_analysis_2</td><td>analysis_2</td><td>0.200</td><td>1.000</td><td>0.760</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>23667619_2</td><td>CSL &gt; TIC; socialcommunication</td><td>23667619_analysis_0</td><td>analysis_0</td><td>0.211</td><td>1.000</td><td>0.763</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>23667619_3</td><td>TIC &gt; CSL; socialcommunication</td><td>23667619_analysis_1</td><td>analysis_1</td><td>0.211</td><td>1.000</td><td>0.763</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24243619</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24243619/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24243619_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;emotional prosody processing&quot;.</td></tr>
<tr><td>24243619_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;emotional prosody processing&quot;.</td></tr>
<tr><td>24243619_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;emotional prosody processing&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24243619_1</td><td>[(TR−AG)∩(AT−AG)∩(HA−AG)]; socialcommunication</td><td>24243619_analysis_1</td><td>analysis_1</td><td>0.143</td><td>1.000</td><td>0.743</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>24243619_2</td><td>[(TR−HA)∩(AT−HA)∩(AG−HA)]; socialcommunication</td><td>24243619_analysis_2</td><td>analysis_2</td><td>0.143</td><td>1.000</td><td>0.743</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>24243619_3</td><td>[(TR−HA)∩(AT−HA)∩(TR−AG)∩(AT−AG)]; socialcommunication</td><td>24243619_analysis_0</td><td>analysis_0</td><td>0.125</td><td>1.000</td><td>0.738</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24414614</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24414614/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24414614_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;imitating&quot;.</td></tr>
<tr><td>24414614_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;being imitated&quot;.</td></tr>
<tr><td>24414614_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;observation&quot;.</td></tr>
<tr><td>24414614_analysis_3</td><td>analysis_3</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because a global exclusion criterion applies: this analysis is a seed-based connectivity (PPI) analysis which is excluded by GLOBAL_E2.</td></tr>
<tr><td>24414614_analysis_4</td><td>analysis_4</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because a global exclusion criterion applies: this analysis is a seed-based connectivity (PPI) analysis which is excluded by GLOBAL_E2.</td></tr>
<tr><td>24414614_analysis_5</td><td>analysis_5</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because a global exclusion criterion applies: this analysis is a seed-based connectivity (PPI) analysis which is excluded by GLOBAL_E2.</td></tr>
<tr><td>24414614_analysis_6</td><td>analysis_6</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because a global exclusion criterion applies: this analysis is a seed-based connectivity (PPI) analysis which is excluded by GLOBAL_E2.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24414614_1</td><td>being imitated &gt; rest; socialcommunication</td><td>24414614_analysis_1</td><td>analysis_1</td><td>0.154</td><td>1.000</td><td>0.746</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>24414614_2</td><td>imitating &gt; rest; socialcommunication</td><td>24414614_analysis_0</td><td>analysis_0</td><td>0.213</td><td>1.000</td><td>0.764</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>24414614_3</td><td>observation &gt; rest; socialcommunication</td><td>24414614_analysis_2</td><td>analysis_2</td><td>0.214</td><td>1.000</td><td>0.764</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24462962</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24462962/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24462962_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;faces versus houses fMRI task&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24462962_1</td><td>house + faces; socialcommunication</td><td>24462962_analysis_0</td><td>analysis_0</td><td>0.182</td><td>1.000</td><td>0.755</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24814646</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=8</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24814646/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> A&amp;B; socialcommunication, p2&gt;n2; socialcommunication, D&amp;E; socialcommunication, a2&gt; n2; socialcommunication, a2&gt;p2; socialcommunication, p1&gt; n1; socialcommunication, p1&gt;a1; socialcommunication, p2&gt;a2; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24814646_analysis_0</td><td>Initial phase of video-clip &gt; A &gt; a 1&gt; n 1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;activation patterns ... posterior temporal regions&quot;.</td></tr>
<tr><td>24814646_analysis_1</td><td>Direct fMRI contrasts between reactive aggressive and social positive scenarios | Initial phase of video-clip | A ⁎ | a 1&gt; p 1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;posterior superior temporal gyrus&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24814646_1</td><td>A&amp;B; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>24814646_10</td><td>p2&gt;n2; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>24814646_2</td><td>D&amp;E; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>24814646_3</td><td>a1&gt; n1; socialcommunication</td><td>24814646_analysis_0</td><td>Initial phase of video-clip &gt; A &gt; a 1&gt; n 1</td><td>0.280</td><td>1.000</td><td>0.784</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>24814646_4</td><td>a1&gt;p1; socialcommunication</td><td>24814646_analysis_1</td><td>Direct fMRI contrasts between reactive aggressive and social positive scenarios | Initial phase of video-clip | A ⁎ | a 1&gt; p 1</td><td>0.219</td><td>1.000</td><td>0.766</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>24814646_5</td><td>a2&gt; n2; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>24814646_6</td><td>a2&gt;p2; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>24814646_7</td><td>p1&gt; n1; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>24814646_8</td><td>p1&gt;a1; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>24814646_9</td><td>p2&gt;a2; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25281889</strong> | Pred included: 8 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25281889/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25281889_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;label briefly presented (≤100ms) emotional (happy, angry, fearful) facial expressions&quot;.</td></tr>
<tr><td>25281889_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;label briefly presented (≤100ms) emotional (happy, angry, fearful) facial expressions&quot;.</td></tr>
<tr><td>25281889_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;label briefly presented (≤100ms) emotional (happy, angry, fearful) facial expressions&quot;.</td></tr>
<tr><td>25281889_analysis_3</td><td>analysis_3</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Correlations between brain response to emotional faces and TAS-20 total score&quot;.</td></tr>
<tr><td>25281889_analysis_4</td><td>analysis_4</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Correlations between brain response to emotional faces and TAS-20 total score&quot;.</td></tr>
<tr><td>25281889_analysis_5</td><td>AN&gt;NE negative correlations with TAS-20-DDF</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;AN&gt;NE negative correlations with TAS-20-DDF&quot;.</td></tr>
<tr><td>25281889_analysis_6</td><td>analysis_6</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Correlations between brain response to emotional faces and TSIA-DDF&quot;.</td></tr>
<tr><td>25281889_analysis_7</td><td>analysis_7</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Correlations between brain response to emotional faces and TSIA-DDF&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25281889_1</td><td>AN &gt; NE; socialcommunication</td><td>25281889_analysis_1</td><td>analysis_1</td><td>0.263</td><td>1.000</td><td>0.779</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>25281889_2</td><td>FE &gt; NE; socialcommunication</td><td>25281889_analysis_2</td><td>analysis_2</td><td>0.211</td><td>1.000</td><td>0.763</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>25281889_3</td><td>HA &gt; NE; socialcommunication</td><td>25281889_analysis_0</td><td>analysis_0</td><td>0.263</td><td>1.000</td><td>0.779</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25640962</strong> | Pred included: 5 | Manual included (accepted matches only): 4 | Correct overlaps: 4 | Match statuses: accepted=4, uncertain=1, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25640962/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> (IC &gt; NG ∩ ego &gt; allo) (conjunction analysis); socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25640962_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Main effect of Gesture (IC&gt;NG)&quot;.</td></tr>
<tr><td>25640962_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Egocentric (ego) as opposed to allocentric (allo) orientation elicited activations in a neural network encompassing the right-hemispheric supramarginal gyrus, the inferior parietal gyrus and the postcentral gyrus.&quot;</td></tr>
<tr><td>25640962_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Allocentric as opposed to egocentric actor orientation further elicited activations in the left middle and inferior occipital gyri.&quot;</td></tr>
<tr><td>25640962_analysis_3</td><td>analysis_3</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Two clusters of enhanced neural responses were found...encompassed the bilateral ACC as well as the left mid orbital gyrus.&quot;</td></tr>
<tr><td>25640962_analysis_4</td><td>analysis_4</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;The interaction analysis...revealed enhanced neural responses in the bilateral SMA extending to the left superior medial gyrus and the right middle cingulate cortex.&quot;</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25640962_1</td><td>(IC &gt; NG ∩ ego &gt; allo) (conjunction analysis); socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>25640962_2</td><td>(IC-allo&gt;NG-allo)&gt;(IC-ego&gt;NG-ego); socialcommunication</td><td>25640962_analysis_4</td><td>analysis_4</td><td>0.122</td><td>1.000</td><td>0.737</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>25640962_3</td><td>(IC-ego&gt;IC-allo)&gt; (NG-ego&gt;NG-allo); socialcommunication</td><td>25640962_analysis_3</td><td>analysis_3</td><td>0.114</td><td>0.800</td><td>0.594</td><td>uncertain</td><td>high_coord_match</td></tr><tr><td>25640962_4</td><td>IC &gt; NG; socialcommunication</td><td>25640962_analysis_0</td><td>analysis_0</td><td>0.211</td><td>1.000</td><td>0.763</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>25640962_5</td><td>allo &gt; ego; socialcommunication</td><td>25640962_analysis_2</td><td>analysis_2</td><td>0.200</td><td>1.000</td><td>0.760</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>25640962_6</td><td>ego &gt; allo; socialcommunication</td><td>25640962_analysis_1</td><td>analysis_1</td><td>0.200</td><td>1.000</td><td>0.760</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25929599</strong> | Pred included: 5 | Manual included (accepted matches only): 5 | Correct overlaps: 5 | Match statuses: accepted=5, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25929599/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25929599_analysis_0</td><td>Incongruent &gt; Congruent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met. Construct evidence span: &quot;automatic imitation task with facial stimuli (SAMT)&quot;.</td></tr>
<tr><td>25929599_analysis_1</td><td>Happy (Incongruent &gt; Congruent) masked inclusively with Happy (Incongruent &gt; Congruent) &gt; Angry (Incongruent &gt; Congruent)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met. Construct evidence span: &quot;happy facial expressions&quot;.</td></tr>
<tr><td>25929599_analysis_2</td><td>Angry (Incongruent &gt; Congruent) masked inclusively with Angry (Incongruent &gt; Congruent) &gt; Happy (Incongruent &gt; Congruent)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met. Construct evidence span: &quot;angry facial expressions&quot;.</td></tr>
<tr><td>25929599_analysis_3</td><td>Out-group (Incongruent &gt; Congruent) masked inclusively with Out-group (Incongruent &gt; Congruent) &gt; In-group (Incongruent &gt; Congruent)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met. Construct evidence span: &quot;out-group faces (Black/White) presented&quot;.</td></tr>
<tr><td>25929599_analysis_4</td><td>In-group (Incongruent &gt; Congruent) masked inclusively with In-group (Incongruent &gt; Congruent) &gt; Out-group (Incongruent &gt; Congruent)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met. Construct evidence span: &quot;in-group faces presented in SAMT&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25929599_1</td><td>Angry (Incongruent &gt; Congruent) masked inclusively with Angry (Incongruent &gt; Congruent) &gt; Happy (Incongruent &gt; Congruent); socialcommunication</td><td>25929599_analysis_2</td><td>Angry (Incongruent &gt; Congruent) masked inclusively with Angry (Incongruent &gt; Congruent) &gt; Happy (Incongruent &gt; Congruent)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25929599_2</td><td>Happy (Incongruent &gt; Congruent) masked inclusively with Happy (Incongruent &gt; Congruent) &gt; Angry (Incongruent &gt; Congruent); socialcommunication</td><td>25929599_analysis_1</td><td>Happy (Incongruent &gt; Congruent) masked inclusively with Happy (Incongruent &gt; Congruent) &gt; Angry (Incongruent &gt; Congruent)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25929599_3</td><td>In-group (Incongruent &gt; Congruent) masked inclusively with In-group (Incongruent &gt; Congruent) &gt; Out-group (Incongruent &gt; Congruent); socialcommunication</td><td>25929599_analysis_4</td><td>In-group (Incongruent &gt; Congruent) masked inclusively with In-group (Incongruent &gt; Congruent) &gt; Out-group (Incongruent &gt; Congruent)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25929599_4</td><td>Incongruent &gt; Congruent; socialcommunication</td><td>25929599_analysis_0</td><td>Incongruent &gt; Congruent</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>25929599_5</td><td>Out-group (Incongruent &gt; Congruent) masked inclusively with Out-group (Incongruent &gt; Congruent) &gt; In-group (Incongruent &gt; Congruent);socialcommunication</td><td>25929599_analysis_3</td><td>Out-group (Incongruent &gt; Congruent) masked inclusively with Out-group (Incongruent &gt; Congruent) &gt; In-group (Incongruent &gt; Congruent)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26417673</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=2</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26417673/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Disgust &gt; Neutral; socialcommunication, Out-group &gt; In-group; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26417673_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;passive viewing of in-/out-group facial expressions&quot;.</td></tr>
<tr><td>26417673_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Excluded because this is a seed-based task-dependent connectivity (PPI) analysis, which fails the global exclusion criteria for inclusion.</td></tr>
<tr><td>26417673_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Excluded because this is a seed-based task-dependent connectivity (PPI) analysis, which fails the global exclusion criteria for inclusion.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26417673_1</td><td>Disgust &gt; Neutral; socialcommunication</td><td>26417673_analysis_1</td><td>analysis_1</td><td>0.148</td><td>0.023</td><td>0.061</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>26417673_2</td><td>Disgusted out-group-neutral out-group &gt; Disgusted In-group-neutral in-group; socialcommunication</td><td>26417673_analysis_0</td><td>analysis_0</td><td>0.047</td><td>1.000</td><td>0.714</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>26417673_3</td><td>Out-group &gt; In-group; socialcommunication</td><td>26417673_analysis_2</td><td>analysis_2</td><td>0.157</td><td>0.067</td><td>0.094</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26505303</strong> | Pred included: 4 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26505303/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Request &gt; Naming; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26505303_analysis_0</td><td>Words &gt; Faces (whole-brain random effects)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Participants were shown videos, in which the same critical utterances were used in different communicative contexts, to Name objects, or to Request them from communication partners.&quot;.</td></tr>
<tr><td>26505303_analysis_1</td><td>Request &gt; Naming (whole-brain random effects; p &lt; 0.05 FDR-corrected)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;the neural correlates of speech acts, that is, the actions performed by using language&quot;.</td></tr>
<tr><td>26505303_analysis_2</td><td>Request &gt; Naming</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;understanding of utterances as Requests was accompanied by activation in bilateral premotor, left inferior frontal and temporo-parietal cortical areas&quot;.</td></tr>
<tr><td>26505303_analysis_3</td><td>Naming &gt; Request</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;The comprehension of different speech acts performed with the same words in closely matched interactive settings led to significantly different brain activation patterns.&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26505303_1</td><td>Request &gt; Naming; socialcommunication</td><td>26505303_analysis_2</td><td>Request &gt; Naming</td><td>1.000</td><td>0.000</td><td>0.300</td><td>unmatched</td><td>coord_count_mismatch, low_coord_high_name, low_total_score, name_only_signal</td></tr><tr><td>26505303_2</td><td>Words &gt; Faces; socialcommunication</td><td>26505303_analysis_0</td><td>Words &gt; Faces (whole-brain random effects)</td><td>0.553</td><td>1.000</td><td>0.866</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 27375449</strong> | Pred included: 1 | Manual included (accepted matches only): 3 | Correct overlaps: 1 | Match statuses: accepted=3, uncertain=1, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/27375449/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>27375449_analysis_0</td><td>Angry &gt; Joyful session</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Excluded because the analysis does not specifically measure social communication as defined (missing inclusion criteria: SOCIAL_COMMUNICATION_I1, SOCIAL_COMMUNICATION_I2).</td></tr>
<tr><td>27375449_analysis_1</td><td>Grasping &gt; Faces</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TN</span></td><td></td><td>Excluded because the contrast (Grasping &gt; Faces) does not target social communication/reception of facial communication (missing inclusion criteria: SOCIAL_COMMUNICATION_I1, SOCIAL_COMMUNICATION_I2).</td></tr>
<tr><td>27375449_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because the analysis does not specifically measure social communication as defined (missing inclusion criteria: SOCIAL_COMMUNICATION_I1, SOCIAL_COMMUNICATION_I2).</td></tr>
<tr><td>27375449_analysis_3</td><td>Faces &gt; Grasping</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Faces &gt; Grasping&quot;.</td></tr>
<tr><td>27375449_analysis_4</td><td>analysis_4</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Excluded because the analysis does not specifically measure social communication as defined (missing inclusion criteria: SOCIAL_COMMUNICATION_I1, SOCIAL_COMMUNICATION_I2).</td></tr>
<tr><td>27375449_analysis_5</td><td>Angry &gt; Joyful run</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because one or more global exclusion criteria apply (ROI/seed-based connectivity analyses).</td></tr>
<tr><td>27375449_analysis_6</td><td>Angry grasping &gt; Joyful grasping</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because one or more global exclusion criteria apply (ROI/seed-based connectivity analyses).</td></tr>
<tr><td>27375449_analysis_7</td><td>P &lt; 0.01 FWE corrected</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because one or more global exclusion criteria apply (ROI/seed-based connectivity analyses).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>27375449_1</td><td>Angry &gt; Joyful session; socialcommunication</td><td>27375449_analysis_0</td><td>Angry &gt; Joyful session</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27375449_2</td><td>Faces &gt; Grasping; socialcommunication</td><td>27375449_analysis_3</td><td>Faces &gt; Grasping</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>27375449_3</td><td>Grasping &gt; Faces; socialcommunication</td><td>27375449_analysis_1</td><td>Grasping &gt; Faces</td><td>1.000</td><td>0.556</td><td>0.689</td><td>uncertain</td><td>coord_count_mismatch</td></tr><tr><td>27375449_4</td><td>Interaction analysis between grasping and neutral grasping; socialcommunication</td><td>27375449_analysis_4</td><td>analysis_4</td><td>0.235</td><td>1.000</td><td>0.771</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29221830</strong> | Pred included: 6 | Manual included (accepted matches only): 6 | Correct overlaps: 6 | Match statuses: accepted=6, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29221830/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29221830_analysis_0</td><td>Collaborative &gt; Arbitrary</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met. Construct evidence span: &quot;retrieved and produced the labels aloud during a communicative task in the MRI scanner&quot;.</td></tr>
<tr><td>29221830_analysis_1</td><td>Individual &gt; Arbitrary</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met because the retrieval was performed during a communicative task and responses were produced aloud to a partner. Construct evidence span: &quot;retrieved and produced the labels aloud during a communicative task in the MRI scanner&quot;.</td></tr>
<tr><td>29221830_analysis_2</td><td>Collaborative &gt; Individual</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met because retrieval occurred in a communicative production task and contrasts assess differences tied to collaborative communication. Construct evidence span: &quot;retrieved and produced the labels aloud during a communicative task in the MRI scanner&quot;.</td></tr>
<tr><td>29221830_analysis_3</td><td>Arbitrary &gt; Individual</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>The retrieval task was communicative (director spoke aloud to a matcher) and thus meets social communication criteria despite the contrast focusing on arbitrary vs individual learning. Construct evidence span: &quot;retrieved and produced the labels aloud during a communicative task in the MRI scanner&quot;.</td></tr>
<tr><td>29221830_analysis_4</td><td>Individual &gt; Collaborative</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met; the task required verbal production to a communicative partner and contrasts probe differences tied to collaborative communication. Construct evidence span: &quot;retrieved and produced the labels aloud during a communicative task in the MRI scanner&quot;.</td></tr>
<tr><td>29221830_analysis_5</td><td>Arbitrary &gt; Collaborative</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met; retrieval occurred in a communicative production task and the contrast involves collaboratively learned labels. Construct evidence span: &quot;retrieved and produced the labels aloud during a communicative task in the MRI scanner&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29221830_1</td><td>Arbitrary &gt; Collaborative; socialcommunication</td><td>29221830_analysis_5</td><td>Arbitrary &gt; Collaborative</td><td>1.000</td><td>0.946</td><td>0.962</td><td>accepted</td><td>high_coord_match</td></tr><tr><td>29221830_2</td><td>Arbitrary &gt; Individual; socialcommunication</td><td>29221830_analysis_3</td><td>Arbitrary &gt; Individual</td><td>1.000</td><td>0.979</td><td>0.985</td><td>accepted</td><td>high_coord_match</td></tr><tr><td>29221830_3</td><td>Collaborative &gt; Arbitrary; socialcommunication</td><td>29221830_analysis_0</td><td>Collaborative &gt; Arbitrary</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29221830_4</td><td>Collaborative &gt; Individual; socialcommunication</td><td>29221830_analysis_2</td><td>Collaborative &gt; Individual</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29221830_5</td><td>Individual &gt; Arbitrary; socialcommunication</td><td>29221830_analysis_1</td><td>Individual &gt; Arbitrary</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>29221830_6</td><td>Individual &gt; Collaborative; socialcommunication</td><td>29221830_analysis_4</td><td>Individual &gt; Collaborative</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29740753</strong> | Pred included: 3 | Manual included (accepted matches only): 3 | Correct overlaps: 3 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29740753/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29740753_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;emotion processing network&quot;.</td></tr>
<tr><td>29740753_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;emotion processing network&quot;.</td></tr>
<tr><td>29740753_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;interaction effect of modality and emotion&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29740753_1</td><td>Emotion &gt; Modality; socialcommunication</td><td>29740753_analysis_1</td><td>analysis_1</td><td>0.286</td><td>1.000</td><td>0.786</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>29740753_2</td><td>Modality &gt; Emotion; socialcommunication</td><td>29740753_analysis_0</td><td>analysis_0</td><td>0.214</td><td>1.000</td><td>0.764</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>29740753_3</td><td>Modality X Emotion; socialcommunication</td><td>29740753_analysis_2</td><td>analysis_2</td><td>0.214</td><td>1.000</td><td>0.764</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 30272134</strong> | Pred included: 2 | Manual included (accepted matches only): 2 | Correct overlaps: 2 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/30272134/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>30272134_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because the analysis does not meet the global whole-brain group-level map requirement (GLOBAL_I2 missing).</td></tr>
<tr><td>30272134_analysis_1</td><td>(BIMODAL &gt; UNIMODAL FACES) ∩ (BIMODAL &gt; UNIMODAL VOICES)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;multisensory integration of fearful face and voice in the rpSTS&quot;.</td></tr>
<tr><td>30272134_analysis_2</td><td>INCONGRUENT &gt; CONGRUENT</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;greater response to incongruent &gt; congruent stimuli in the rpSTS&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>30272134_1</td><td>(Bimodal &gt; Unimodal faces) ∩ (Bimodal &gt; Unimodal Voices); socialcommunication</td><td>30272134_analysis_1</td><td>(BIMODAL &gt; UNIMODAL FACES) ∩ (BIMODAL &gt; UNIMODAL VOICES)</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>30272134_2</td><td>Incongruent &gt; Congruent; socialcommunication</td><td>30272134_analysis_2</td><td>INCONGRUENT &gt; CONGRUENT</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 31090126</strong> | Pred included: 2 | Manual included (accepted matches only): 1 | Correct overlaps: 1 | Match statuses: accepted=1, uncertain=1, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/31090126/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>31090126_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;dynamic facial expressions versus dynamic mosaics&quot;.</td></tr>
<tr><td>31090126_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TP</span></td><td>manual+ (accepted), correct</td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;dynamic facial expressions versus dynamic mosaics&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>31090126_1</td><td>(expression &gt; mosaic) × laterality; socialcommunication</td><td>31090126_analysis_1</td><td>analysis_1</td><td>0.136</td><td>1.000</td><td>0.741</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>31090126_2</td><td>expression &gt; mosaic; socialcommunication</td><td>31090126_analysis_0</td><td>analysis_0</td><td>0.207</td><td>0.959</td><td>0.733</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>
</details></section><section id="bucket-false-positive"><details class="bucket" open><summary><h2>False Positive (37)</h2></summary><p><strong>Match status totals:</strong> accepted=0 | uncertain=6 | unmatched=63</p>
<details class="doc-card">
  <summary><strong>PMID 29330483</strong> | Pred included: 6 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29330483/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29330483_analysis_0</td><td>Female &gt; Male Pictures</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;greater activity for female pictures in occipital and occipitotemporal cortices, with ... fusiform cortex, potentially suggesting face or body processing&quot;.</td></tr>
<tr><td>29330483_analysis_1</td><td>Bisexual Women: Female &gt; Male Pictures</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;greater activity in visual cortices for female relative to male pictures, including fusiform cortex&quot;.</td></tr>
<tr><td>29330483_analysis_2</td><td>Bisexual Women: Male &gt; Female Pictures</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because there is no clear evidence this contrast indexes social communication specifically (e.g., faces/explicit auditory communication). Missing inclusion criteria: SOCIAL_COMMUNICATION_I1, SOCIAL_COMMUNICATION_I2.</td></tr>
<tr><td>29330483_analysis_3</td><td>Homosexual Women: Female &gt; Male Pictures</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;activations throughout the visual system, with additional clusters in occipitotemporal cortices&quot; (face/body perception relevant to social communication reception).</td></tr>
<tr><td>29330483_analysis_4</td><td>Female &gt; Male Videos</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;activity in bilateral superior temporal cortices, likely indicating an auditory confound ... vocalizations were present in female erotic videos&quot; (auditory social communication).</td></tr>
<tr><td>29330483_analysis_5</td><td>Male &gt; Female Videos</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because there is no clear evidence this contrast indexes social communication specifically (no auditory/face-processing emphasis reported). Missing inclusion criteria: SOCIAL_COMMUNICATION_I1, SOCIAL_COMMUNICATION_I2.</td></tr>
<tr><td>29330483_analysis_6</td><td>Bisexual Women: Female &gt; Male Videos</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;activations were greater for female (relative to male) stimuli in superior temporal cortices&quot; (auditory/social communication features).</td></tr>
<tr><td>29330483_analysis_7</td><td>Bisexual Women: Male &gt; Female Videos</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because there is no clear evidence this contrast indexes social communication specifically (auditory/face processing not emphasized). Missing inclusion criteria: SOCIAL_COMMUNICATION_I1, SOCIAL_COMMUNICATION_I2.</td></tr>
<tr><td>29330483_analysis_8</td><td>Homosexual Women: Female &gt; Male Videos</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;activity in superior temporal cortices&quot; (auditory/social communication related to vocalizations in female videos).</td></tr>
<tr><td>29330483_analysis_9</td><td>Homosexual Women: Male &gt; Female Videos</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because there is no clear evidence this contrast indexes social communication specifically (no auditory/face-processing emphasis reported). Missing inclusion criteria: SOCIAL_COMMUNICATION_I1, SOCIAL_COMMUNICATION_I2.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <p>No manual-to-auto match diagnostics for this document.</p>
  </details>
  <details class="inner-accordion"><summary>PMC full text available (PMCID 5766543)</summary><p><strong>Title:</strong> Neural Correlates of Sexual Orientation in Heterosexual, Bisexual, and Homosexual Women</p><details><summary>Abstract</summary><pre class="paper-text">We used fMRI to investigate neural correlates of responses to erotic pictures and videos in heterosexual (N = 26), bisexual (N = 26), and homosexual (N = 24) women, ages 25–50. We focused on the ventral striatum, an area of the brain associated with desire, extending previous findings from the sexual psychophysiology literature in which homosexual women had greater category specificity (relative to heterosexual and bisexual women) in their responses to male and female erotic stimuli. We found that homosexual women’s subjective and neural responses reflected greater bias towards female stimuli, compared with bisexual and heterosexual women, whose responses did not significantly differ. These patterns were also suggested by whole brain analyses, with homosexual women showing category-specific activations of greater extents in visual and auditory processing areas. Bisexual women tended to show more mixed patterns, with activations more responsive to female stimuli in sensory processing areas, and activations more responsive to male stimuli in areas associated with social cognition.</pre></details><details><summary>Body</summary><pre class="paper-text">## Introduction 
  
Studies using physiological measures have found that women tend to have non-specific patterns of genital arousal . That is, in contrast to men, women tend to show similar degrees of arousal to erotic stimuli depicting either sex. For example, heterosexual women have generally shown equivalent arousal to both erotic stimuli featuring men and erotic stimuli featuring women. This has been repeatedly demonstrated with vaginal photoplethysmography . This pattern has also been found using less direct measures such as looking time , pupil dilation , and fMRI . Notably, homosexual women’s arousal patterns are more category-specific than heterosexual women’s, although less so than men’s . 

The fact that women’s sexual arousal patterns are less category-specific than men’s has been interpreted as a potential contributor to gender differences in “erotic plasticity” , which Baumeister has defined as “the extent to which sex drive is shaped by social, cultural, and situational factors.” 

Baumeister offered three lines of evidence when he initially proposed that women may have greater erotic plasticity compared with men: (1) women show larger effects of social and cultural factors on sexual attitudes, desire, and behavior; (2) sexual attitude-behavior consistency is lower in women than in men; (3) individual women exhibit more variation in sexual behavior across time than men. Women’s less specific arousal patterns may also contribute to their increased “sexual fluidity” , which Diamond has defined as an individual’s “capacity for situation-dependent flexibility in sexual responsiveness, which allows individuals to experience changes in same-sex or other-sex desire across both short-term and long-term time periods” . 

One might hypothesize that arousal patterns of bisexual women should be similar to the non-specific arousal patterns of heterosexual women; however, studies of women’s arousal patterns have mostly neglected to include bisexual women. Heterosexual women’s arousal does not appear to favor erotic stimuli of either sex, and thus may be considered to reflect a bisexual pattern. (We do not mean to imply that heterosexual women are confused or in denial about their “real preferences”; rather, the findings in need of explanation are why heterosexual women show non-heterosexual arousal patterns in the laboratory). The implication of women’s non-specific arousal patterns for their sexual orientations is difficult to interpret. Most women, like most men, behave and identify heterosexually . However, men are more likely than women to identify as completely heterosexual or completely homosexual, and women are more likely than men to identify as bisexual or “mostly heterosexual” . 

If arousal patterns are similar between heterosexual and bisexual women, the question remains what distinguishes the two groups. One possibility, supported by some research, is that bisexual women tend to have greater sexual motivation, which may increase the likelihood of exploring a capacity for attraction to both sexes . Or, bisexual women may be more aware than heterosexual women of their non-specific arousal , which could partially contribute to bisexual sexual motivation. Alternatively, bisexual women may be more likely than heterosexual women to interpret their non-specific arousal states in sexual or romantic terms. 

It is also possible that bisexual women’s arousal patterns differ from those observed in heterosexual women. Consistent with this possibility, recent studies suggest that women with bisexual interests tend to be more aroused by female than by male erotic stimuli . Perhaps for some women with female-biased arousal patterns, this bias can motivate non-heterosexual feelings, behavior, and identity. 

Interpretations of non-specific arousal patterns in women are further complicated by the fact that female genital arousal exhibits relatively low correlations with subjectively reported sexual arousal, in contrast to the high correlations observed in men . Discrepancies between existing genital and subjective measures indicate that some women may report substantial subjective arousal without substantial genital arousal, and vice versa. It has also been suggested that non-specific arousal patterns may not indicate affective responses to erotic stimuli, but may instead reflect a kind of protective preparatory response . 

Neuroimaging assessments may shed light on the neural systems that are involved in responding to a given paradigm. Functional magnetic resonance imaging (fMRI) is a neuroimaging approach that allows for the indirect assessment of brain activity by tracking ratios of oxygenated and deoxygenated blood a proxy for neural firing. When used in the context of presenting erotic stimuli, this non-invasive neural measure could provide a converging line of evidence for interpreting the genital and subjective arousal findings described above. In this study, we used fMRI to specifically focused on the “reward system” in order to address the question: to what extent is there an affective significance to findings from the literature on women’s sexual orientation and genital arousal? 

The part of the “reward system” that we focused on is the ventral striatum, a dopamine-sensitive area of the brain that is a reliable measure of reward-related processing–and in particular, wanting and “incentive motivation” –including with respect to sexual orientation . Most neuroimaging studies of sexual response have focused on men , but the ventral striatum has also been found to reliably activate in studies of women’s responses to erotic stimuli . However, until now, no studies have measured neural responses to erotic stimuli in bisexual women. 

The present investigation primarily focused on two hypotheses: (1) Homosexual women may show greater category-specificity than non-homosexual women in brain activity, as suggested by the genital arousal literature; (2) Bisexual women may show larger biases towards female stimuli, compared with heterosexual women. We tested these hypotheses with respect to subjective and neural responses to erotic pictures and erotic videos. We used two different kinds of erotic stimuli because of their potentially non-overlapping strengths and weaknesses. Erotic pictures may be particularly well-suited for assessing the initial appraisal of sexual stimuli, but their brevity may not reflect the kinds of experiences that drive sexuality in the real world. Erotic videos may allow for the measurement of more intense states, but their extended duration may also provide opportunities for self-regulatory efforts to modify erotic responses. 


## Method 
  
### Participants 
  
Participants were 26 heterosexual women, 26 bisexual women, and 24 homosexual women, recruited from a variety of publicly-posted and online advertisements seeking (paid) volunteers for a neuroimaging study of sexual orientation and arousal. Bisexual women were required to have had at least two previous sexual partners and one romantic partner (of three months or greater duration) of each sex. Homosexual and heterosexual participants all met these criteria with respect to their respective preferred sexes. 

After responding to advertisements, participants were screened for inclusion using online questionnaires. Participants provided information about sexual orientation, sexual interests, and personality, in addition to answering screening questions relevant to medical eligibility for fMRI research. Participants were required to be right handed, non-claustrophobic, free from ferromagnetic implants, and not currently taking psychiatric medications. Participants were informed of the risks and nature of the study and agreed to participate in all portions of the research. This study was approved by the Institutional Review Board of Northwestern University and carried out in accordance with its guidelines. Informed consent was obtained from each participant for every portion of the study in which they participated. 

Participants’ sexual orientation was assessed using self-reported identities (i.e. “Homosexual”/“Gay”, “Bisexual”/“Bi”, “Heterosexual”/“Straight”), as well as with a modified Kinsey score, which asked participants about their sexual fantasies throughout adulthood as well as in the past year. The scale ranged from 0 to 6, with 0 corresponding to an exclusively heterosexual orientation and 6 corresponding to an exclusively homosexual orientation. Responses to questions about adulthood and about the past year were averaged to create a Kinsey score for each participant. The average Kinsey score was 0.8 for heterosexual women (  SD   = 0.7,   range   = 0–2), 2.63 for bisexual women (  SD   = 0.7,   range   = 2–4.5), and 5.2 for homosexual women (  SD   = 0.68,   range   = 4–6). 

Participants’ ages ranged from 21 to 46 years old. Mean ages were 29.7 for heterosexual women (  SD   = 5.86,   range   = 25–46), 30.27 for bisexual women (  SD   = 6.41,   range   = 21–48), and 29 for homosexual women (  SD   = 3.12,   range   = 25–38). The sample of 76 participants was racially and ethnically diverse, with 23 non-Caucasian participants including two Latina participants, ten African-American participants, four Asian-American participants, and seven participants who identified otherwise or who identified as multiethnic/multiracial. Groups did not significantly differ either with respect to age (  F  (2,73) = 0.348,   p   = 0.708) or ethnicity (c (2, N = 76) = 2.94, p = 0.23). We also confirmed that ethnicity did not significantly impact responses to the erotic stimuli. 


### Stimuli and Procedure 
  
Subjects experienced two experimental paradigms in the scanner: first erotic pictures were shown (over a period of ~21 minutes), and then erotic videos were shown (over a period of ~19 minutes) after a brief rest period. Picture stimuli were shown before video stimuli for all participants in an attempt to promote stimulus engagement. That is, it was assumed that potentially less intense stimuli might be better presented earlier in the experimental session while attentional resources are highest. Further, there was concern that first showing more intense stimuli would reduce engagement with subsequent stimuli. As such, pictures and videos stimuli were not counterbalanced with respect to each other. 

Participants watched stimuli while laying down with a combination of earplugs (to minimize scanner noise) and over-ear headphones (for video sound and communication with experimenters). Images were displayed via projector onto a wall, which was made viewable to participants via an angled mirror placed above the eyes. 

#### Erotic pictures paradigm 
  
The present study employed a subset of the picture stimuli used in Safron   et al  .  and Sylva   et al  . . Pictures depicted a nude man, a nude woman, or a same-sex couple (i.e., either two men or two women) engaged in explicit sexual contact. Erotic stimuli featuring both individual nudes and same-sex pairs engaging in explicit sexual interaction is common in research on sexual arousal and sexual orientation , which is not the case when stimuli featuring male-female couples is presented. However, erotic stimuli featuring explicit sexual activity in same-sex couples tends to be substantially more arousing compared with pictures of single nudes . Such stimuli are similar to pictures of nude individuals, in the sense that only men or women, but not both, are depicted in a given picture. Thus, sexual arousal induced by them is relatively unambiguous in terms of the gender to which participants are responding. 

In each of two 10.5-minute runs (ordering counterbalanced), participants viewed 40 erotic pictures featuring male models and 40 erotic pictures featuring female models. Each picture was shown for 3.5 seconds, followed by a variable-duration fixation cross presented for either 1.5, 6.5, or 11.5 seconds. Variable-duration baselines were utilized for superior deconvolution of the BOLD signal in a rapid event-related design for fMRI (in which evoked signals are never allowed to return to baseline levels). During the presentation of each picture, participants used buttons held in their right hands to rate that image on a scale of −2 to +2 (respectively: “strongly disliked,” “disliked,” “liked,” “strongly liked”), with no option of 0 for neutral ratings. Neutral options for ratings were not provided for the sake of consistency with previous research using the same stimuli. Note: Subjective ratings of pictures were lost for some participants due to a button-box equipment error. 


#### Erotic videos paradigm 
  
Following picture assessment, participants were shown six video clips depicting individual masturbating men and six video clips depicting individual masturbating women. Depicted individuals appeared sexually aroused but did not reach orgasm. To estimate baseline responses, six natural landscape videos were shown. 

In each of two 9.25-minute runs (ordering counterbalanced), videos were presented for 15 seconds each, followed by a 15-second distraction task requiring participants to indicate via button-press when a number in a series decreased by an interval other than seven. This task was intended to facilitate a return to emotional and physiological baseline. 15-second stimulus presentations were chosen as a desirable stimulation period in an fMRI block design, which can potentially be more sensitive than event-related designs . 

After leaving the scanner, participants viewed the videos once more and provided ratings of each clip. Videos were rated using a 5-point scale for degree of sexual appeal, ranging from “not at all” (0) to “very much” (4), with a midpoint of “somewhat” (2).’ 



### fMRI signal extraction methods 
  
#### Image acquisition 
  
A Siemens Trio 3 T magnet and 12-channel RF head coil were used to collect T2*-weighted gradient-recalled EPI images from the whole brain (32 3-mm slices with a 0.99-mm interslice gap; TR = 2500 ms; TE = 20 ms; flip angle = 80°; FOV = 200 × 220 mm, 120 × 128 acquisition matrix). Slices were taken along the plane connecting the anterior and posterior commissures, with a 1.72 mm × 1.72 mm × 3.99 mm resolution, with more refined axial dimensions intended to produce less distortion and signal dropout in sub-cortical areas, although possibly at the expense of signal-to-noise ratio. During each picture run, 250 whole-brain volumes were collected, and during each video run, 220 whole-brain volumes were collected, with the first four volumes discarded to account for initial magnetization effects. For anatomical localization, a structural MRI scan consisting of T1-weighted images was conducted after the testing runs (160 1-mm axial slices; TR = 2.1 ms; TE = 4.38 ms; flip angle = 15°; FOV = 220 mm; 256 × 192 matrix). 


#### Image pre-processing 
  
Image pre-processing and analysis was performed using SPM 12b (Wellcome Trust Centre for Neuroimaging, London, UK), and implemented in Matlab v 8.1.604 (The MathWorks Inc., MA, USA). 

Functional (EPI) volumes were first corrected for slice timing. Each participant’s volumes were then registered to the mean slice, after which the registered volumes were resliced, used to create a mean resliced image, and then co-registered to the structural (T1) image. All EPI images, including the mean resliced image, as well as the structural (T1) scans were then spatially normalized to Montreal Neurological Institute (MNI) space, and re-sampled to 3 × 3 × 3 mm (27 mm ) resolution. Normalized functional images were then smoothed to an 8 mm full-width-at-half-maximum Gaussian kernel. 


#### Signal to noise ratio and head coverage exclusions 
  
To exclude participants with poor signal due to either head motion or scanner conditions, average signal-to-noise ratio (SNR) over time was calculated for each subject (after preprocessing, using a mask that included only voxels with appreciable EPI signal). The SNR ratio for each voxel (mean divided by standard deviation) was averaged across all voxels in the brain . Participants whose picture data SNR was less than one standard deviation below the mean were excluded from picture analyses. Similarly, participants whose video data SNR was less than one standard deviation below the mean were excluded from video analyses. 

Based on these criteria, fourteen participants (five heterosexual, five bisexual, and four homosexual) were excluded from fMRI and subjective picture analyses, and sixteen participants (six heterosexual, six bisexual, and four homosexual) were excluded from fMRI and subjective video analyses. After exclusions were performed for SNR, we included a total of twenty-one heterosexual women, twenty-one bisexual women, and twenty homosexual women in fMRI picture analyses. Video analyses after SNR exclusion included eighteen heterosexual women, eighteen bisexual women, and twenty homosexual women. To check the validity of our SNR criterion, head motion plots were visually inspected for all participants (Parrish,   et al  . ). Excluded participants had highly variable head positions as compared to included participants. An additional validity-check was performed using evoked responses to erotic pictures minus a fixation-cross baseline. Excluded participants had substantially reduced activity in visual cortices as compared to included participants. 

An additional thirty-two participants (twelve heterosexual, twelve bisexual, and eight homosexual) were excluded from subjective picture rating analyses due to insufficient subjective data resulting from a button-box equipment error. Five participants (three bisexual and two homosexual) were excluded from subjective video analyses for the same reason. Thus, after exclusions were performed for insufficient subjective data, we included a total of nine heterosexual women, nine bisexual women, and twelve homosexual women in subjective picture analyses, and twenty heterosexual women, seventeen bisexual women, and eighteen homosexual women in subjective video analyses. 

For whole-brain analyses, mean functional scans were individually examined to identify participants with substantial cutoffs in head coverage. As a result, one heterosexual female who had substantial frontal lobe cutoff was excluded from whole-brain analyses in addition to those participants excluded for SNR. 


#### First-level analyses 
  
For both the video and picture assessments, a standard general linear model (GLM)  was used in identifying hemodynamic changes for each participant, and a high-pass filter (cutoff 128 s) was used to remove low-frequency temporal noise. 

Estimated average activity was calculated for each participant’s separate responses to male pictures, female pictures, male videos, and female videos (contrasted with fixation cross for pictures and neutral nature scenes for videos). These estimates were used for region of interest analyses. For whole-brain analyses, estimated average activity was also calculated for each participant’s response to male compared with female pictures and videos. For both the picture and video assessments, each participant’s responses to each stimulus contrast of interest were concatenated within stimulus type, using data from both the 1  and 2  runs. 

Ventral striatum region of interest analyses. An a priori region of interest (ROI) analysis was performed on the ventral striatum—centered on the nucleus accumbens—as this was the area most likely to indicate desire. The ventral striatum and hypothalamus are the only two areas that have been shown to be specifically associated with sexual (as opposed to general) arousal . We focused on the ventral striatum because it likely has higher validity for reflecting sexual incentive value compared with the hypothalamus, which contains a variety of nuclei with heterogeneous functions (including sexual arousal) that would be difficult to disambiguate with the limited spatial resolution of 3 T fMRI. 

The ventral striatum ROI mask used in the present study was drawn on an MNI template brain using the WFU PickAtlas toolbox for SPM 8 . It was anatomically defined as a dilated intersection of the ventral anterior caudate and putamen. The resulting ventral striatum ROI is shown in Fig.  .   
Mask used as the ventral striatum (VS) ROI, drawn using an average brain in the WFU PickAtlas toolbox for SPM 8. MNI coordinates displayed: x = 0, y = 17, z = −8. 
  

Estimates of average ventral striatum activity for each participant were extracted using the MarsBar toolbox for SPM8 . Extracted ventral striatum ROI data were analyzed using JMP Pro v11 (SAS Institute, Cary, NC). 



### Planned contrasts and within-group tests 
  
We constructed separate dependent variables for each combination of stimulus type (i.e. picture or video) and response type (i.e., subjective or ventral striatum activation) by subtracting response to female stimuli from response to male stimuli. That is, we constructed dependent variables for 1) subjective response to pictures, 2) subjective response to videos, 3) ventral striatum activation to pictures, and 4) ventral striatum responses to videos, each of which reflected responses to male stimuli minus responses to female stimuli. We refer to this as the Male-Female contrast. 

Because there were three groups (i.e., heterosexual, homosexual, and bisexual women), two orthogonal between-groups contrasts were constructed to examine what we believe to be the most interesting pair of independent questions based on previous literature . The first question was whether homosexual women differed from the other two groups in their Male-Female contrasts. The second question was whether bisexual women differed from heterosexual women in their Male-Female contrasts. The use of orthogonal planned contrasts allowed us to test these hypotheses with maximum statistical power while simultaneously minimizing the number of overall comparisons. 

Within-group t-tests were also performed separately in each group in order to characterize relative responding to male and female stimuli. 


### Whole-brain analyses 
  
Finally, we examined overall patterns of differential activation in response to male compared with female erotic stimuli across the entire brain. If bisexual and heterosexual women have less specific arousal patterns, then they are likely to exhibit less extensive differential activity between male and female stimuli compared with the activity patterns expected for homosexual women. 

Tests of average group responses to stimulus conditions were performed using one-sample contrasts. Each group (heterosexual women, bisexual women, and homosexual women) was tested individually for clusters of greater activity for male stimuli compared with female stimuli, and female stimuli compared with male stimuli, using a corrected statistical threshold (p &lt; 0.05 FWE). 

For these analyses, cluster reports were generated in SPM. Peak activations and cluster extents (extent threshold k = 5) were visually examined as overlays on slice and render maps. Neuroanatomical descriptions were determined based on agreement between two trained investigators, and checked against designations from the WFU Atlas (Maldjian   et al  ., 2003). 


### Data availability statement 
  
The datasets generated and analyzed during the current study are available from the corresponding author on request. 



## Results 
  
### Between-group planned contrasts 
  
As previously described, planned comparisons for the ventral striatum ROI were conducted via multiple regression using two orthogonal between-groups contrasts: one comparing homosexual women with heterosexual and bisexual women, and one comparing heterosexual with bisexual women. Separate analyses were conducted for each of the Male-Female contrasts (i.e., responses to female stimuli subtracted from responses to male stimuli). Results are presented in Table  .    
Planned contrasts comparing women of different orientation groups. 
  
*Significant p-value &lt; 0.05. **Signifcant p-value &lt; 0.01. 

***Significant p-value &lt; 0.001. 
    
Within-group male – female (male minus female) stimuli difference scores for subjective ratings and ventral striatum (VS) responses, by sexual orientation. Difference scores are defined as a participant’s average response to stimuli depicting males minus average response to stimuli depicting females. Points represent individual participants. Horizontal bars indicate group means and 95% confidence intervals of the means. Horizontal lines at 0 indicate no difference between ratings to erotic stimuli depicting each sex. (  a  ) Difference scores for subjective ratings of picture stimuli. (b) Difference scores for VS activation evoked by picture stimuli. (c) Difference scores for subjective ratings of video stimuli. (d) Difference scores for VS activation evoked by video stimuli. ***p &lt; 0.001, **p &lt; 0.01, *p &lt; 0.05. 
  

#### Homosexual versus non-homosexual women 
  
Subjective ratings. Compared with non-homosexual women, homosexual women had significantly more negative (i.e., gynephilic) Male-Female contrasts for both pictures (p = 0.015) and videos (p &lt; 0.001). That is, homosexual women showed a greater preference for pictures and videos of females relative to males, compared with both bisexual and heterosexual women. 

Ventral striatum activation patterns. Homosexual women had significantly more female-biased ventral striatum responses compared to non-homosexual women for pictures (p = 0.002), but not videos. 


#### Bisexual versus heterosexual women 
  
We compared heterosexual and bisexual women’s subjective and ventral striatum responses to erotic pictures and videos, and observed only one significant difference: for video stimuli, bisexual women had significantly more female-preferring subjective responses than did heterosexual women (p = 0.026). 



### Within-group tests comparing responses to male and female erotic stimuli 
  
Figure   (showing the distribution of Male-Female contrasts for the three groups) shows that heterosexual women exhibited a non-significant trend (p = 0.079) towards favoring female erotic pictures compared with male erotic pictures, and had no differentiation between stimulus sex for other tests. Bisexual women also did not subjectively differentiate among stimulus types based on sex, although they did exhibit (non-significant) marginal female-favoring ventral striatum scores for picture (p = 0.063) and video (p = 0.054) stimuli. Homosexual women, in contrast to heterosexual and bisexual women, showed clear favoring of female stimuli as assessed by subjective liking of pictures (p &lt; 0.001), appeal ratings of videos (p &lt; 0.001), as well as in ventral striatum responses to pictures (p = 0.003) and non-significantly for ventral striatum responses to videos (p = 0.073). Note that these results are presented descriptively. Inferences about differences among the three groups depend on the tests presented in Table  . 


### Whole brain tests comparing responses to male and female erotic stimuli 
  
Note: Activation patterns are described in greater detail in the discussion, with interpretations of possible functional significances. 

#### Picture stimuli 
  
Comparing activation to female versus male erotic pictures, heterosexual women exhibited relatively greater activity for female pictures in occipital (i.e., visual) and occipitotemporal cortices, with no brain areas showing significantly greater activation for male pictures (Fig.  ; Table  ). Bisexual women also showed greater activity in visual cortices for female relative to male pictures, but they showed greater activity for male pictures in other areas including supramarginal and angular gyri, as well as the posterior cingulate. Homosexual women exhibited significant activations for female compared with male pictures in visual cortex, parietal lobes, and parahippocampal cortex, but with no brain areas showing significantly greater activation for male pictures.   
Differential brain activations towards male and female pictures in heterosexual, bisexual, and homosexual women. Whole brain activations are shown for the male picture minus female picture contrasts (with brain activation evoked by viewing neutral stimuli subtracted from activations toward the erotic pictures). Height threshold is set at p &lt; 0.05 FWE with a cluster threshold of k = 5. Axial slice 31, sagittal slice 50, and coronal slice 38 are shown for all groups. 
    
Differential whole-brain activations in response to male vs. female pictures. 
  


#### Video stimuli 
  
When viewing female compared with male erotic videos (Fig.  ; Table  ), all groups showed activity in bilateral superior temporal cortices, likely indicating an auditory confound in which more extensive and substantial vocalizations were present in female erotic videos . However, this effect appeared to vary by sexual orientation, with homosexual women showing the most extensive and robust evoked activity (peak T = 14.22) compared with heterosexual (peak T = 11.71) and bisexual women (peak T = 8.83). In the opposite direction of greater responses to male compared with female erotic videos, heterosexual and bisexual (but not homosexual) women exhibited activations in occipital cortices. While all groups had greater activity towards male videos in (anterior) superior parietal cortices, these activations appeared to be more extensive and robust in bisexual women (peak T = 11.55) compared with heterosexual (peak T = 7.64) and homosexual women (peak T = 7.99).   
Differential brain activations between male and female videos in heterosexual, bisexual, and homosexual women. Whole brain activations are shown for the male video minus female video contrasts (with brain activation evoked by viewing neutral stimuli subtracted from activation toward the erotic videos). Height threshold is set at p &lt; 0.05 FWE with a cluster threshold of k = 5. Axial slice 37, sagittal slice 61, and coronal slice 38 are shown for all groups. 
    
Differential whole-brain activations in response to male vs. female videos. 
  




## Discussion 
  
In this fMRI study of female sexual orientation—the first to include bisexual women—we extended several key findings from the sexual psychophysiology literature . Using the ventral striatum as a neural measure of incentive motivation, we demonstrated that homosexual women have greater gender bias in their responses to male and female erotic stimuli. 

### Main findings: subjective and ventral striatum responses to male and female erotic stimuli 
  
Direct comparisons of bisexual and heterosexual women revealed no significant differences, with the exception of bisexual women having more gynephilic subjective responses to erotic videos. However, bisexual and heterosexual women did not differ with respect to their ventral striatum responses toward these stimuli. When contrasted to bisexual and heterosexual women, homosexual women showed distinctly greater bias toward female stimuli in both their subjective responses to videos and pictures, and also in their ventral striatum responses to pictures. In sum, our planned contrast findings are consistent with the genital arousal literature in which more category-specific responses were observed in homosexual women . 

Another set of tests, comparing male vs. female stimuli within each group, revealed that neither bisexual nor heterosexual women were significantly biased toward stimuli depicting males or stimuli depicting females. This was true both in ventral striatum response and in subjective arousal, for both picture and video stimuli. Homosexual women, however, were uniquely gynephilic (i.e., female-preferring), with significantly greater responses to female stimuli for subjective responses to pictures, subjective responses to videos, and ventral striatum responses to pictures. This gynephilic bias in homosexual women was consistent with our direct comparisons and previous literature. 

Our findings are only partially consistent with observations from the genital arousal literature in which homosexual and bisexual women both had gynephilic responses, but where heterosexual women had non-specific responses . We found significant biases in ventral striatum responses toward female stimuli among homosexual women, but with more indifferent patterns among heterosexual and bisexual women. However, with one exception—bisexual women showing more gynephilic subjective responses to erotic videos than did heterosexual women, in a direct comparison—heterosexual and bisexual women’s patterns of results did not differ significantly. 

Our a priori tests in the ventral striatum allowed us to explore whether women of different sexual orientations also exhibited different degrees of incentive motivation toward male and female erotic stimuli. But fMRI also provides the ability to look at activation patterns across the entire brain, potentially allowing for a more detailed characterization of the neural systems involved. Below we review activation patterns for each group in viewing male compared with female erotic stimuli, along with some reverse inferences as to their functional significance. 


### Whole brain responses to erotic pictures 
  
For heterosexual women viewing erotic pictures, activity was greater for female relative to male stimuli bilaterally in lateral occipital cortices, likely indicative of visual attention , as well as in right-lateralized fusiform cortex, potentially suggesting face or body processing .   In no brain areas did heterosexual women have significantly greater activation for male relative to female erotic pictures  . Rather, they seemed to have a somewhat gynephilic pattern of visual attention, consistent with results from eye-tracking and looking-time studies in which heterosexual women attended to erotic characteristics of female pictures . 

Bisexual women showed more activity in response to female (relative to male) erotic pictures throughout the visual system, including fusiform cortex, which (as described above) is often associated with perception of faces and bodies . Patterns were similar to those observed in heterosexual women (and presumably with similar functional significances), but with larger spatial extents of activation. Although bisexual and heterosexual women were not directly contrasted, this more extensive visual activation could be taken as support for somewhat greater gynephilic interest on the part of bisexual women, consistent with ventral striatum activation patterns. 

For bisexual women viewing erotic pictures, activity was greater for male relative to female stimuli in posterior midcingulate and right retrosplenial cingulate cortices, potentially suggesting greater perceptual salience and emotional memory for male erotic stimuli . Additional male-biased activations were identified bilaterally in supramarginal and angular gyri, indicating processes relating to mental imagery, or possibly mentalizing . 

Thus, in contrast to heterosexual participants, bisexual women showed greater activity towards male (relative to female) erotic pictures in affect-related brain areas. In this way, it seems that it would be overly simplistic to say that bisexual women are similar to heterosexual women, but with the addition of gynephilic interest. Rather,   bisexual women seem to have greater responses to both male and female erotic stimuli, depending on the brain area being considered  . Patterns of greater overall responsiveness are consistent with suggestions that bisexual women may be distinguished by having overall greater degrees of sexual motivation relative to heterosexual women . 

It is also notable that bisexual women uniquely showed greater activations to male stimuli in areas of the brain implicated in higher-order cognition, including mentalizing. Speculatively, these activations could be related to more complex processing of sexual motivation in bisexual women . To the degree that these activation patterns in bisexual women actually specifically reflect social cognition, the question remains open as to why this may be more likely to be observed in bisexual but not heterosexual or homosexual women. 

For homosexual women viewing erotic pictures, greater activations for female (relative to male) stimuli extended throughout the visual system, with additional clusters in occipitotemporal cortices. Clusters in the right inferior precuneus may have indicated mental imagery , and clusters in posterior parahippocampal cortex may have indicated either memory encoding or retrieval .   For homosexual women, no brain areas had significantly greater activation for male relative to female erotic pictures. Thus, homosexual women were the only group that exhibited an overall pattern of differential brain activity (between male and female sexual stimuli) greater only for pictures depicting their preferred gender  . 


### Whole brain responses to erotic videos 
  
For heterosexual women viewing erotic videos, activity was greater for female relative to male stimuli in bilateral superior temporal cortices likely indicating an auditory confound deriving from more extensive and substantial vocalizations being present in female erotic videos . Activity was greater for male relative to female videos in posterior occipital cortex, likely indicating enhanced visual attention . Further clusters (greater for male compared with female videos) in the inferolateral postcentral gyrus and parietal somatosensory association areas may have indicated awareness of bodily sensations, possibly related to sexual imagery . 

For bisexual women viewing erotic videos, activations were greater for female (relative to male) stimuli in superior temporal cortices, likely indicating the same auditory-related activity present in heterosexual women. Bisexual women’s brain activity was greater for male (relative to female) erotic videos in occipital cortex, likely indicating visual attention . Male-biased activations in somatosensory cortices may have indicated processing of bodily sensations , and further activations in bilateral superior parietal lobules, premotor and supplementary motor cortices, and right supramarginal gyrus may have indicated mental imagery or possibly mirroring with the actors shown in the videos . 

Similar to the findings for erotic pictures,   bisexual women were unique in the degree to which male videos produced activations in brain areas associated with more abstract (and possibly complex) processing  . Again, the significance of this pattern remains unclear. 

For homosexual women viewing female relative to male erotic videos, activity in superior temporal cortices likely indicated the same auditory-related processing observed in heterosexual and bisexual women, albeit more robustly and extensively, consistent with enhanced attention to emotionally salient stimulus features. When viewing male relative to female erotic videos, activations in the right somatosensory cortex may have indicated processing of bodily sensations , which may have been either positive or negative in valence. Thus, while emotionally associated brain areas did not exhibit differential activations for videos,   homosexual women’s particularly strong engagement of auditory cortices for female stimuli provided yet further evidence of uniquely gender-biased responding, relative to heterosexual and bisexual women  . 


### Comparisons with previous findings 
  
Few studies have investigated the category-specificity of brain activity in non-heterosexual women. Ponseti   et al  .  found that both heterosexual and homosexual women showed gender-specific patterns of brain activity in multiple areas, including the ventral striatum. Sylva   et al  .  also found some evidence for category-specific responding in women, although not in the ventral striatum, and without specifically testing whether or not heterosexual or homosexual women differed in their responses. 

The patterns observed Ponseti   et al  .  stand in contrast to the present investigation in which homosexual women tended to be the only group showing strongly category-specific responses to erotic stimuli. One possible interpretations for their findings of category-specific responses in all women was the unusual nature of the stimuli (i.e., close-up images of male and female genitalia, isolated from interpersonal contextual factors) . As suggested by Chivers (2017) , it may be the case that sex and gender cues can produce specific responses in heterosexual women, but that these are usually trumped by contextual factors in driving arousal responses in women. The stimuli utilized in the present study contained contextual factors (e.g. body posture, facial expression) that are more typical of those found in the genital arousal literature. 

However, it should be noted that the present study did not find support for greater category-specificity in homosexual women across all stimulus conditions. Rather, planned contrasts in the ventral striatum only revealed significant group differences between homosexual and non-homosexual women for erotic pictures. There were no significant differences in ventral striatum response between homosexual and non-homosexual women for erotic videos (even though subjective evaluations of those stimuli did significantly differ across the groups). 

This pattern of differing results for pictures versus videos may be related to differences in how individuals respond to these stimuli, limitations of our video paradigm, or both. While erotic videos may theoretically allow for the assessment of qualitatively different states of sexual response, it may be the case that incentive motivation is greatest when stimuli are first presented, but then diminishes with longer stimulus presentations . Additionally, erotic pictures may have been more effective at driving ventral striatum responses due to factors such as unpredictably varied presentation times of preferred stimuli contributing to larger magnitude reward-prediction errors . 


### Limitations 
  
One limitation of nearly all studies of erotic responses in women—including this one—is a failure to control for hormonal conditions or contraceptive usage. By default, it can generally be assumed that most women were not measured within the ovulatory window, when responses to erotic stimuli might be greatest . Additionally, a number of women may have been using hormonal contraceptives. Measuring women’s responses outside of the fertile phase of their cycles—or while they were using hormonal contraceptives —may have yielded a restricted range of arousal responses. However, the specificity of erotic responding has not been shown to be influenced by menstrual cycle in previous studies of genital arousal . 

Another source of potential limitations may have been the nature of the stimuli used. Though our stimuli were pilot-tested and rated by individuals of different sexual orientations in order to confirm that they would appeal to a broad participant sample, it is never possible to ensure that common stimuli will evoke the responses intended. This may be especially true for something as emotionally salient and individual as sexual arousal. Thus, it is possible that category specificity patterns could appear to be different if stimuli better reflected participants’ subjective preferences. This is a limitation of many studies of sexual responding, although data gleaned from more individualized stimulus sets are difficult to interpret. 

One more aspect of the stimuli that is difficult to control for is sensory details that are inherently different between male and female stimuli. Differences in actors’ vocalizations (for videos), actors’ body positions (for both videos and pictures), and actors’ body motions (in the videos) were present (on average) between male and female stimuli. These features are difficult to control for and could conceivably lead to differences in both subjective and neural responding when viewing male vs. female stimuli, especially in more primary sensory areas of the brain such as visual and auditory cortices. However, such differences may also serve to reinforce the gendered nature of the stimuli and improve their correspondence with real-world experiences and real-world arousal. 



## Conclusions 
  
Though the neural data presented here align with previously-observed patterns in women’s genital and subjective arousal, much remains unknown about the relationship between arousal patterns, orientation, and the development of sexual motivation towards particular sexes in women. Our study supports past findings indicating that women tend not to have strongly category-specific responses to erotic stimuli, with homosexual women showing somewhat greater specificity than heterosexual and bisexual women. Future research should explore the extent to which women’s non-specific sexual response contributes to erotic plasticity (i.e., change with context) and sexual fluidity (i.e., change over time) .</pre></details></details>
  <details class="inner-accordion"><summary>Coordinate-relevant source tables (2)</summary><details class="inner-accordion"><summary>Table 2 (Tab2) - Differential whole-brain activations in response to male vs. female pictures.</summary><div class="table-html"><table-wrap id="Tab2" position="float" orientation="portrait"><label>Table 2</label><caption><p>Differential whole-brain activations in response to male vs. female pictures.</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="1" rowspan="1">R/L</th><th colspan="1" rowspan="1">Region</th><th colspan="1" rowspan="1">BA</th><th colspan="1" rowspan="1">MNI</th><th colspan="1" rowspan="1">voxels</th><th colspan="1" rowspan="1">peak T</th></tr></thead><tbody><tr><td colspan="6" rowspan="1">
<italic toggle="yes">Heterosexual Women</italic>
</td></tr><tr><td colspan="6" rowspan="1">    Female &gt; Male Pictures</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">lingual gyrus, inferolateral occipital</td><td colspan="1" rowspan="1">18, 19</td><td colspan="1" rowspan="1">(−33 −76 −10)</td><td colspan="1" rowspan="1">21</td><td colspan="1" rowspan="1">8.01</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">fusiform gyrus</td><td colspan="1" rowspan="1">37</td><td colspan="1" rowspan="1">(30 −67 −7)</td><td colspan="1" rowspan="1">26</td><td colspan="1" rowspan="1">7.81</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">inferolateral occipital, fusiform gyrus</td><td colspan="1" rowspan="1">19, 37</td><td colspan="1" rowspan="1">(42 −70 −16)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.78</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">fusiform gyrus</td><td colspan="1" rowspan="1">37</td><td colspan="1" rowspan="1">(30 −58 −10)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.59</td></tr><tr><td colspan="6" rowspan="1">    Male &gt; Female Pictures: no differential activations</td></tr><tr><td colspan="6" rowspan="1">
<italic toggle="yes">Bisexual Women</italic>
</td></tr><tr><td colspan="6" rowspan="1">    Female &gt; Male Pictures</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">inferior occipital cortex, middle occipital gyrus, lingual gyrus</td><td colspan="1" rowspan="1">18, 19</td><td colspan="1" rowspan="1">(36 −70 −10)</td><td colspan="1" rowspan="1">86</td><td colspan="1" rowspan="1">10.68</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">19</td><td colspan="1" rowspan="1">(48 −64 −10)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.96</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">fusiform gyrus</td><td colspan="1" rowspan="1">37</td><td colspan="1" rowspan="1">(33 −55 −13)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.15</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">inferolateral occipital, middle occipital gyrus</td><td colspan="1" rowspan="1">19, 18</td><td colspan="1" rowspan="1">(−39 −85 −7)</td><td colspan="1" rowspan="1">138</td><td colspan="1" rowspan="1">9.07</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">18, 19</td><td colspan="1" rowspan="1">(−30 −88 5)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">8.47</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">inferior occipital gyrus, primary visual cortex, lingual gyrus</td><td colspan="1" rowspan="1">18, 17</td><td colspan="1" rowspan="1">(−24 −94 −4)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">8.06</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">occipital cortex, middle occipital gyrus</td><td colspan="1" rowspan="1">19</td><td colspan="1" rowspan="1">(30 −79 17)</td><td colspan="1" rowspan="1">43</td><td colspan="1" rowspan="1">9.03</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">occipital cortex, middle occipital gyrus</td><td colspan="1" rowspan="1">19</td><td colspan="1" rowspan="1">(30 −82 26)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.38</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">inferior occipital cortex, lingual gyrus</td><td colspan="1" rowspan="1">18</td><td colspan="1" rowspan="1">(−24 −85 −13)</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">8.22</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">primary visual cortex, cuneus</td><td colspan="1" rowspan="1">17</td><td colspan="1" rowspan="1">(15 −100 −4)</td><td colspan="1" rowspan="1">12</td><td colspan="1" rowspan="1">8.09</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">18</td><td colspan="1" rowspan="1">(42 −82 −1)</td><td colspan="1" rowspan="1">27</td><td colspan="1" rowspan="1">8.05</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">18</td><td colspan="1" rowspan="1">(27 −85 2)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.62</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">18</td><td colspan="1" rowspan="1">(33 −91 8)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">6.86</td></tr><tr><td colspan="2" rowspan="1">    Male &gt; Female Pictures</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1" /></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">angular gyrus, supramarginal gyrus</td><td colspan="1" rowspan="1">39, 40</td><td colspan="1" rowspan="1">(−51 −64 41)</td><td colspan="1" rowspan="1">21</td><td colspan="1" rowspan="1">9.37</td></tr><tr><td colspan="1" rowspan="1">      R/L</td><td colspan="1" rowspan="1">posterior cingulate</td><td colspan="1" rowspan="1">23</td><td colspan="1" rowspan="1">(0 −22 35)</td><td colspan="1" rowspan="1">10</td><td colspan="1" rowspan="1">8.23</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">angular gyrus</td><td colspan="1" rowspan="1">39</td><td colspan="1" rowspan="1">(48 −61 35)</td><td colspan="1" rowspan="1">27</td><td colspan="1" rowspan="1">7.94</td></tr><tr><td colspan="1" rowspan="1">       R</td><td colspan="1" rowspan="1">supramarginal gyrus</td><td colspan="1" rowspan="1">40</td><td colspan="1" rowspan="1">(51 −61 44)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.75</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">retrosplenial cingulate</td><td colspan="1" rowspan="1">30</td><td colspan="1" rowspan="1">(15 −52 29)</td><td colspan="1" rowspan="1">6</td><td colspan="1" rowspan="1">7.68</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">supramarginal gyrus</td><td colspan="1" rowspan="1">40</td><td colspan="1" rowspan="1">(57 −49 35)</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">7.38</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">supramarginal gyrus</td><td colspan="1" rowspan="1">40</td><td colspan="1" rowspan="1">(−36 −61 44)</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">7.08</td></tr><tr><td colspan="6" rowspan="1">
<italic toggle="yes">Homosexual Women</italic>
</td></tr><tr><td colspan="6" rowspan="1">    Female &gt; Male Pictures</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">19</td><td colspan="1" rowspan="1">(−27 −82 14)</td><td colspan="1" rowspan="1">139</td><td colspan="1" rowspan="1">10.01</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">18, 19</td><td colspan="1" rowspan="1">(−33 −88 −1)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">8.99</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">middle occipital gyrus, primary visual cortex</td><td colspan="1" rowspan="1">18, 17</td><td colspan="1" rowspan="1">(−18 −97 2)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">8.57</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">19</td><td colspan="1" rowspan="1">(33 −79 14)</td><td colspan="1" rowspan="1">89</td><td colspan="1" rowspan="1">9.83</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">inferior lateral occipital cortex</td><td colspan="1" rowspan="1">19</td><td colspan="1" rowspan="1">(42 −85 2)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">8.19</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">middle occipital gyrus</td><td colspan="1" rowspan="1">19</td><td colspan="1" rowspan="1">(33 −70 8)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.78</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">fusiform gyrus, posterior paraphippocampal gyrus</td><td colspan="1" rowspan="1">37</td><td colspan="1" rowspan="1">(33 −52 −10)</td><td colspan="1" rowspan="1">36</td><td colspan="1" rowspan="1">9.56</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">fusiform gyrus, middle occipital gyrus</td><td colspan="1" rowspan="1">18</td><td colspan="1" rowspan="1">(33 −70 −13)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">8.03</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">primary visual cortex</td><td colspan="1" rowspan="1">17</td><td colspan="1" rowspan="1">(18 −94 −1)</td><td colspan="1" rowspan="1">11</td><td colspan="1" rowspan="1">8.56</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">fusiform gyrus, lingual gyrus, posterior parahippocampal gyrus</td><td colspan="1" rowspan="1">37</td><td colspan="1" rowspan="1">(−33 −61 −7)</td><td colspan="1" rowspan="1">26</td><td colspan="1" rowspan="1">8.45</td></tr><tr><td colspan="1" rowspan="1">       L</td><td colspan="1" rowspan="1">fusiform gyrus</td><td colspan="1" rowspan="1">37</td><td colspan="1" rowspan="1">(−39 −61 −13)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.62</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">precuneus, occipitoparietal</td><td colspan="1" rowspan="1">7</td><td colspan="1" rowspan="1">(24 −73 41)</td><td colspan="1" rowspan="1">6</td><td colspan="1" rowspan="1">7.18</td></tr><tr><td colspan="6" rowspan="1">    Male &gt; Female Pictures: no differential activations</td></tr></tbody></table></table-wrap></div></details><details class="inner-accordion"><summary>Table 3 (Tab3) - Differential whole-brain activations in response to male vs. female videos.</summary><div class="table-html"><table-wrap id="Tab3" position="float" orientation="portrait"><label>Table 3</label><caption><p>Differential whole-brain activations in response to male vs. female videos.</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="1" rowspan="1">R/L</th><th colspan="1" rowspan="1">Region</th><th colspan="1" rowspan="1">BA</th><th colspan="1" rowspan="1">MNI</th><th colspan="1" rowspan="1">voxels</th><th colspan="1" rowspan="1">peak T</th></tr></thead><tbody><tr><td colspan="6" rowspan="1">
<italic toggle="yes">Heterosexual Women</italic>
</td></tr><tr><td colspan="6" rowspan="1">    Female &gt; Male Videos</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">superior temporal gyrus, primary and secondary auditory cortex</td><td colspan="1" rowspan="1">22, 41, 42</td><td colspan="1" rowspan="1">(−57 −25 8)</td><td colspan="1" rowspan="1">124</td><td colspan="1" rowspan="1">11.71</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">superior temporal gyrus, primary and secondary auditory cortex</td><td colspan="1" rowspan="1">22, 41, 42</td><td colspan="1" rowspan="1">(−42 −31 11)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">10.15</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">superior temporal gyrus</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">(−66 −28 8)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">8.99</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">superior temporal gyrus, primary and secondary auditory cortex</td><td colspan="1" rowspan="1">22, 41, 42</td><td colspan="1" rowspan="1">(54 −16 −1)</td><td colspan="1" rowspan="1">48</td><td colspan="1" rowspan="1">10.42</td></tr><tr><td colspan="6" rowspan="1">    Male &gt; Female Videos</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">primary visual cortex, lingual gyrus</td><td colspan="1" rowspan="1">17, 18</td><td colspan="1" rowspan="1">(−9 −82 2)</td><td colspan="1" rowspan="1">30</td><td colspan="1" rowspan="1">10.14</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">inferolateral postcentral gyrus</td><td colspan="1" rowspan="1">3</td><td colspan="1" rowspan="1">(60 −16 29)</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">7.94</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">superior parietal lobule</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">(33 −49 62)</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">7.64</td></tr><tr><td colspan="6" rowspan="1">
<italic toggle="yes">Bisexual Women</italic>
</td></tr><tr><td colspan="6" rowspan="1">    Female &gt; Male Videos</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">superior temporal, primary and secondary auditory cortex</td><td colspan="1" rowspan="1">22, 41, 42</td><td colspan="1" rowspan="1">(−54 −10 5)</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">8.83</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">superior temporal gyrus</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">(63 −25 2)</td><td colspan="1" rowspan="1">8</td><td colspan="1" rowspan="1">7.26</td></tr><tr><td colspan="6" rowspan="1">    Male &gt; Female Videos</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">superior parietal lobule, extending into supramarginal gyrus</td><td colspan="1" rowspan="1">7, 5, 40</td><td colspan="1" rowspan="1">(36 −46 59)</td><td colspan="1" rowspan="1">211</td><td colspan="1" rowspan="1">11.55</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">postcentral gyrus</td><td colspan="1" rowspan="1">3, 1, 2</td><td colspan="1" rowspan="1">(36 −37 53)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">11.27</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">postcentral sulcus</td><td colspan="1" rowspan="1">1, 2</td><td colspan="1" rowspan="1">(33 −31 41)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">9.51</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">postcentral gyrus, postcentral sulcus</td><td colspan="1" rowspan="1">3, 1, 2</td><td colspan="1" rowspan="1">(−36 −37 56)</td><td colspan="1" rowspan="1">25</td><td colspan="1" rowspan="1">8.45</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">superior parietal lobule</td><td colspan="1" rowspan="1">5, 7</td><td colspan="1" rowspan="1">(−33 −49 59)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">7.55</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">supplementary motor area</td><td colspan="1" rowspan="1">6</td><td colspan="1" rowspan="1">(30 −10 59)</td><td colspan="1" rowspan="1">12</td><td colspan="1" rowspan="1">8.14</td></tr><tr><td colspan="1" rowspan="1">       L</td><td colspan="1" rowspan="1">supplementary motor area</td><td colspan="1" rowspan="1">6</td><td colspan="1" rowspan="1">(−24 −13 62)</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">7.73</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">cuneus</td><td colspan="1" rowspan="1">17</td><td colspan="1" rowspan="1">(−9 −82 2)</td><td colspan="1" rowspan="1">9</td><td colspan="1" rowspan="1">7.6</td></tr><tr><td colspan="6" rowspan="1">
<italic toggle="yes">Homosexual Women</italic>
</td></tr><tr><td colspan="6" rowspan="1">    Female &gt; Male Videos</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">superior temporal gyrus</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">(51 −10 2)</td><td colspan="1" rowspan="1">578</td><td colspan="1" rowspan="1">14.22</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">primary and secondary auditory cortex, superior temporal gyrus</td><td colspan="1" rowspan="1">41 42, 22</td><td colspan="1" rowspan="1">(54 −19 5)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">13.91</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">superior temporal gyrus</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">(60 −1 −4)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">13.26</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">superior temporal gyrus</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">(−63 −19 2)</td><td colspan="1" rowspan="1">247</td><td colspan="1" rowspan="1">12.7</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">primary and secondary auditory cortex</td><td colspan="1" rowspan="1">41, 42</td><td colspan="1" rowspan="1">(−45 −25 8)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">11.97</td></tr><tr><td colspan="1" rowspan="1">      L</td><td colspan="1" rowspan="1">superior temporal gyrus</td><td colspan="1" rowspan="1">22</td><td colspan="1" rowspan="1">(−66 −28 5)</td><td colspan="1" rowspan="1" /><td colspan="1" rowspan="1">10.99</td></tr><tr><td colspan="6" rowspan="1">     Male &gt; Female Videos</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">postcentral gyrus</td><td colspan="1" rowspan="1">3</td><td colspan="1" rowspan="1">(33 −34 47)</td><td colspan="1" rowspan="1">7</td><td colspan="1" rowspan="1">7.99</td></tr><tr><td colspan="1" rowspan="1">      R</td><td colspan="1" rowspan="1">postcentral sulcus</td><td colspan="1" rowspan="1">2</td><td colspan="1" rowspan="1">(42 −28 41)</td><td colspan="1" rowspan="1">5</td><td colspan="1" rowspan="1">7.76</td></tr></tbody></table></table-wrap></div></details></details>
</details>


<details class="doc-card">
  <summary><strong>PMID 29890323</strong> | Pred included: 8 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29890323/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29890323_analysis_0</td><td>emotional &gt; neutral video clips - Cluster 1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;emotional &gt; neutral video clips&quot;.</td></tr>
<tr><td>29890323_analysis_1</td><td>emotional &gt; neutral video clips - Cluster 2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;emotional &gt; neutral video clips&quot;.</td></tr>
<tr><td>29890323_analysis_2</td><td>emotional &gt; neutral video clips - Cluster 3</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;emotional &gt; neutral video clips&quot;.</td></tr>
<tr><td>29890323_analysis_3</td><td>emotional &gt; neutral video clips - Cluster 4</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;emotional &gt; neutral video clips&quot;.</td></tr>
<tr><td>29890323_analysis_4</td><td>neutral &gt; emotional video clips</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;neutral &gt; emotional video clips&quot;.</td></tr>
<tr><td>29890323_analysis_5</td><td>Modulation of BOLD-response by intra-individual variation of Z-EA scores (threshold-free cluster enhancement pFWE &lt; 0.05)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Modulation of BOLD-response by intra-individual variation of Z-EA scores&quot;.</td></tr>
<tr><td>29890323_analysis_6</td><td>analysis_6</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;correlation between BOLD-response and the participants&#x27; ratings of the target&#x27;s emotional intensity&quot;.</td></tr>
<tr><td>29890323_analysis_7</td><td>analysis_7</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;correlation between BOLD-response and the participants&#x27; ratings of the target&#x27;s emotional intensity&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <p>No manual-to-auto match diagnostics for this document.</p>
  </details>
  <details class="inner-accordion"><summary>PMC full text available (PMCID 6057276)</summary><p><strong>Title:</strong> Tracking emotions in the brain – Revisiting the Empathic Accuracy Task</p><details><summary>Abstract</summary><pre class="paper-text">Many empathy tasks lack ecological validity due to their use of simplistic stimuli and static analytical approaches. Empathic accuracy tasks overcome these limitations by using autobiographical emotional video clips. Usually, a single measure of empathic accuracy is computed by correlating the participants&#x27; continuous ratings of the narrator&#x27;s emotional state with the narrator&#x27;s own ratings. 

In this study, we validated a modified empathic accuracy task. A valence-independent rating of the narrator&#x27;s emotional intensity was added to provide comparability between videos portraying different primary emotions and to explore changes in neural activity related to variations in emotional intensity over time. We also added a new neutral control condition to investigate general emotional processing. In the scanner, 34 healthy participants watched 6 video clips of people talking about an autobiographical event (2 sad, 2 happy and 2 neutral clips) while continuously rating the narrator&#x27;s emotional intensity. 

Fluctuation in perceived emotional intensity correlated with activity in brain regions previously implicated in cognitive empathy (bilateral superior temporal sulcus, temporoparietal junction, and temporal pole) and affective empathy (right anterior insula and inferior frontal gyrus). When emotional video clips were compared to neutral video clips, we observed higher activity in similar brain regions. Empathic accuracy, on the other hand, was only positively related to activation in regions that have been implicated in cognitive empathy. 

Our modified empathic accuracy task provides a new method for studying the underlying components and dynamic processes involved in empathy. While the task elicited both cognitive and affective empathy, successful tracking of others&#x27; emotions relied predominantly on the cognitive components of empathy. The fMRI data analysis techniques developed here may prove valuable in characterising the neural basis of empathic difficulties observed across a range of psychiatric conditions. 
   Highlights  
  
Activity in affective and cognitive empathy related regions during emotional videos. 
  
Activity in similar regions related to changes in perceived emotional intensity. 
  
Only regions implicated in cognitive empathy were associated with empathic accuracy. 
  
No difference between video clips that did and did not elicit affect sharing. 
  
Empathic accuracy related to self-rated perspective-taking but not empathic concern.</pre></details><details><summary>Body</summary><pre class="paper-text">## Introduction 
  
Empathy, has been defined as “an emotional response [… which] is similar to one&#x27;s perception […] and understanding […] of the stimulus emotion, with recognition that the source of the emotion is not one&#x27;s own.” ( , page 150). Empathy is crucial for successful social interaction as it allows the individual to predict others&#x27; actions, emotions and intentions ( ). Deficits in empathic processing have been reported in psychiatric disorders such as autism spectrum disorder (ASD), schizophrenia, borderline personality disorder and bipolar disorder ( ). Identifying the neural substrates of empathy in healthy populations is important for understanding conditions that are characterised by empathic difficulties. In neuroscience, the concept of empathy is considered to include separate affective (sharing others&#x27; emotion) and cognitive (understanding others&#x27; emotion) components (for example,  ;  ). Previous research has identified distinct clusters of brain regions involved in affective empathy: medial/anterior cingulate cortex (MCC, ACC), anterior insula (AI) ( ;  ), and supplementary motor area (SMA) ( ). Within the broader domain of social cognition, cognitive empathy overlaps with the affective component of Theory of Mind (ToM) or mentalising, namely the capacity to infer other people&#x27;s thoughts, emotions and intentions without necessarily sharing them ( ). A recent meta-analysis of 144 fMRI studies using ToM tasks ( ) identified the medial prefrontal cortex (mPFC), medial orbitofrontal cortex (mOFC), ACC, precuneus, temporal pole (TP), posterior superior temporal gyrus (pSTS) and temporoparietal junction (TPJ) and inferior frontal gyrus (IFG) as key regions for mentalising. 

However, prior research on the neural mechanisms of empathy has often lacked ecological validity. Studies have often used simplistic stimuli that differ greatly from the complex cues that individuals have to process in real-life situations ( ,  ). Moreover, most studies focus on empathy for pain, while only a few studies have evaluated other emotions (e.g. disgust, happiness, sadness;  ;  ). In addition, empathy has mostly been operationalised as a static trait ( ). However, in the real world empathy fluctuates dynamically ( ). These fluctuations can happen spontaneously because of changes in internal state or in response to shifts in external circumstances, such the emotional intensity and expressivity of others. 

In the current study, we addressed these limitations of previous research by modifying an existing paradigm, the Empathic Accuracy Task (EAT;  ), that incorporates more naturalistic stimuli and reflects the dynamic nature of empathy. Participants (perceivers) watch video clips in which another person (target) describes an emotional autobiographical event. Perceivers continuously rate the target&#x27;s emotion while watching the clips (via button pressing). The EAT measures how   accurately   the perceiver infers changes in the target&#x27;s emotional states by correlating the perceiver&#x27;s ratings with the target&#x27;s ratings of their own emotions (see   for a detailed description).   found that empathic accuracy was associated with higher activation in both affective (i.e. inferior parietal lobule (IPL)) and cognitive (i.e. mPFC) empathy networks. In a recent study of adolescents, empathic accuracy related positively to activation in cognitive empathy or mentalising regions (mPFC, TPJ, STS) and negatively to activation in regions implicated in affective empathy (IPL, ACC, AI;  ). 

In the current study, new video clips were created and the EAT was modified in the following important ways: First, video clips depicted discrete primary emotions (happy, sad, angry, frightened) and participants rated changes in the targets&#x27; emotional intensity (instead of valence) to ensure comparability across different emotions and higher construct validity. Second, we introduced well-matched neutral video clips that acted as a control condition. In this condition, targets described their bedroom. This control condition allowed us to examine the neural correlates of emotion processing irrespective of empathic accuracy. Third, as empathy is a dynamic process, perceivers need to be able to continuously identify changes in the intensity of the target&#x27;s emotional state. We therefore utilised an analysis approach that tracked changes in the target&#x27;s emotional intensity throughout each video clip, in addition to deriving a single index of empathic accuracy (averaged across the clip). Fourth, we included ratings from participants regarding how they felt after watching each video to gain a better understanding of how the neural correlates of EA are influenced by cognitive and affective empathy. Finally, to validate the EAT, we related task performance to self-reported trait empathy and IQ as well as acquiring a normative data set with participants who completed the EAT outside of the scanner. 

The aim of this study was to validate a modified version of the Empathic Accuracy Task, using a staged analysis approach which replicates analyses presented previously in the literature, but which also included additional comparisons. First, we contrasted the blood-oxygen-level dependent (BOLD) responses to emotional and neutral clips to explore correlates of complex and multi-sensory emotional processing during extended clips rather than single emotional images. Second, we validated our emotional intensity rating scale by analysing the neural correlates of intra-individual variations in empathic accuracy. Third, we explored neural correlations with variations in perceived emotional intensity over time, thus capitalising on the availability of continuous ratings throughout each video clip. 

Given the results of prior neuroimaging studies of empathy and mentalising, we had the following hypotheses:   
At the group level, increased BOLD responses would be observed in brain regions previously linked to empathy and mentalising when participants watched targets describe emotional versus neutral events. 
  
There would be positive correlations between intra-individual variations in empathic accuracy and BOLD responses in these regions. 
  
We predicted positive correlations between fluctuations in perceived emotional intensity and BOLD responses in these regions during emotional video clips. 
  


## Methods 
  
### Participants 
  
#### fMRI study 
  
Forty-seven healthy participants aged between 20 and 30 years, fluent in English and with no history of neurological illness, took part in the study. Six participants were excluded from the analysis due to current or recurrent episodes of mental illness as assessed by the Mini International Neuropsychiatric Interview ( ). Five further participants were excluded because of excessive head movement or poor task performance (&lt;2 SD in empathic accuracy (EA) scores) and two participants had incomplete questionnaire data. The final dataset included 34 subjects (19 females, mean age: 24.0 years, SD: 2.7 years). The study received ethical approval from the Camberwell - St. Giles NHS Research Ethics Committee (14/LO/0477) and the University of Southampton Ethics Committee. 


#### Normative data collection 
  
To create a normative data set for the EAT and to validate the stimuli used in the fMRI task, an additional 73 healthy participants completed the EAT outside the MRI scanner. The same inclusion criteria as described above were applied. After excluding 13 participants due to current or recurrent episodes of mental illness, the final dataset included 60 healthy participants (36 females, mean age: 25.2 years, SD: 2.9 years). This aspect of the study was approved by the University of Southampton Ethics Committee. 



### Tasks and stimuli 
  
#### Video acquisition 
  
Eleven native English-speaking students from the University of Southampton acted as targets (8 females, mean age: 20.1 years, SD: 1.64 years). Before filming they were asked to recall a specific autobiographical event (happy, sad, angry or frightened), in which they remembered feeling a strong emotion. Each target wrote a short summary of each event and rated its overall emotional intensity on a 9-point scale (from 1, ‘no emotion’ to 9, ‘very strong emotion’). For the emotional stimuli, only events with a rating of 5 or above were filmed. Each target provided one video clip for each emotion and one clip in which they described their bedroom (neutral condition). An adapted emotion elicitation strategy, which involved imagining being in the situation, was used before filming to reinstate the affective states the targets had felt during the events ( ). They were advised to refrain from making specific reference to their affective state (e.g. happy) but were allowed to use generic descriptions (e.g. upset) or descriptions of bodily symptoms (e.g. shaking). All targets were filmed from the shoulders upwards, in front of a black background, for standardisation purposes. Each clip lasted between 83 and 140 s (mean = 100.3, SD = 15.2). After filming each clip, targets watched the video and continuously rated their emotional intensity using the same 9-point scale as above. Ratings were made by using arrow keys on the keyboard to move a coloured square on the scale (this shifted by one point per button press). Starting point for all ratings was “1”. 

For the fMRI study, the 6 video clips that were selected (one happy, one sad and one neutral video, featuring one female and one male target) were those which received high EA and target expressiveness scores in a pilot study with 13 participants (7 male, mean age: 21.54 years, SD: 2.37 years). A description of the target&#x27;s gender, the emotional condition, the clip length and the target&#x27;s rating of emotional intensity experienced during each clip is presented in  . For pre-training and volume adjustment, one additional sad, one neutral and two happy clips were added (depicting different targets from the main experiment). For the data collection outside the MRI scanner, 27 expressive video clips were selected (7 happy clips, 7 sad clips, 3 angry clips, 3 frightened clips and 7 neutral clips) as well as two happy clips and one sad clip for pre-training purposes. The task and instructions for filming stimuli are available on request.   
Video clips displayed in order of presentation during the Empathic Accuracy Task with target&#x27;s gender, emotional condition and length of the video clip and targets&#x27; average ratings of their own emotional intensity. 
  Table 1   


#### Empathic accuracy task (EAT) 
  
Participants were instructed to continuously rate the perceived emotional intensity of the target ( , top) using the same 9-point scale as above (from 1, ‘no emotion’ to 9, ‘very strong emotion’). In the fMRI study, participants used a button box to provide ratings. In the non-imaging study, participants used the computer&#x27;s arrow keys. The default rating at the start of each video clip was no emotion (i.e. rating of 1). Following each clip, participants were asked: (1) which emotion the target felt most strongly (cognitive empathy: options of “happy”, “angry”, “surprised”, “sad”, “frightened” and “no emotion”); and (2) which emotion they themselves felt most strongly (i.e., affective empathy: same response options as above).   
 Schematic representation of the Empathic Accuracy task and continuous rating scale data.   Top: example of a video clip and rating scale in the Empathic Accuracy Task. The target&#x27;s identity has been disguised in this image. Bottom: Illustration of fluctuations in the   target&#x27;s   emotional intensity, as rated by the target (blue) and an example participant&#x27;s ratings (green). An Empathic Accuracy (EA) score was computed by correlating the participant&#x27;s ratings and the target&#x27;s ratings for each video clip. 
  Fig. 1   


#### Interpersonal reactivity index 
  
The Interpersonal Reactivity Index (IRI) is a widely-used self-report questionnaire that measures dispositional empathy using four subscales: fantasy (FS), empathic concern (EC), perspective taking (PT) and personal distress (PD;  ). 


#### Wechsler abbreviated scale of intelligence, Second Edition 
  
The Wechsler Abbreviated Scale of Intelligence, Second Edition (WASI-II;  ) is a widely-used and reliable test of general intelligence. 



### Procedure 
  
#### fMRI study 
  
The EAT was part of the testing protocol of the English and Romanian Adoptees&#x27; Brain Imaging Study (for further details, see  ). Participants gave written informed consent to participate in the study. All participants completed the MINI and WASI-II, and an online survey, which included the IRI. Participants received pre-training on the fMRI tasks prior to the scan, during which they were familiarised with the EAT and the scanning environment. After observing the experimenter demonstrating how to rate one happy clip, participants rated two clips (one sad, one happy) themselves, while lying in a mock scanner. In the actual EAT experiment, participants watched and rated the 6 video clips in a fixed order ( ). The task took approximately 12 min. Participants were reimbursed for around 6 h of their time with a £100 Amazon voucher. 


#### Normative data collection 
  
For the non-scanning study, participants gave written consent to participate. For pre-training, participants first watched the experimenter rate one happy clip before rating two practice video clips themselves. They then watched and rated 27 video clips in randomised presentation order, in a quiet testing room. This lasted approximately 40 min. Participants also completed an online survey, which included the IRI. Participants were reimbursed for their time with a £15 Amazon voucher. 



### Behavioural data analysis 
  
Participants&#x27; and targets&#x27; ratings were analysed using Matlab 8.2.0 (The MathWorks Inc., Natick, Massachusetts, United States) and SPSS (Version 22, IBM Corp., Armonk, New York, United States). All ratings were separated into 2 s bins and one time-weighted average rating was calculated for each bin. We then tested for correlations between the participants&#x27; and targets&#x27; ratings ( , bottom). The resulting Pearson&#x27;s correlation coefficient for each video clip and each participant is referred to as the EA score. As expected, the variance of the ratings was low for neutral clips. EA scores were therefore only calculated for emotional video clips. EA scores were then r-to-Z transformed to allow comparison between correlation coefficients ( ,  ). 

#### Behavioural analysis of fMRI sample 
  
Paired t-tests examined whether Z-transformed EA scores, affective and cognitive empathy scores differed between happy and sad video clips. Moreover, paired t-tests were performed to test for differences in the average ratings of the target&#x27;s emotional intensity between emotional and neutral as well as happy and sad video clips. A paired   t  -test was also used to test whether Z-EA scores differed between video clips that elicited “affect sharing” (participants reported feeling the same emotion as the target) compared to those that did not (participants reported a different emotion or no emotion). In addition, Pearson correlations were conducted to test for relationships between mean Z-EA scores, the IRI subscales and IQ. 


#### Behavioural analysis of normative data sample 
  
To examine whether the video clips presented in the fMRI study induced Z-EA scores comparable to those in the non-scanning sessions, two Pearson correlations were performed within the normative data sample. Considering happy and sad video clips separately, we examined the correlation between Z-EA scores based on the two video clips presented in the scanner and Z-EA scores based on all seven video clips from the respective emotional category. Moreover, intra-individual standard deviations were calculated based on (1) the four emotional video clips presented in the scanner and (2) all 20 emotional video clips. These were then compared with a paired   t  -test. 



### fMRI data acquisition 
  
Functional images were acquired on a General Electric MR750 3.0 T MR scanner with a 12-channel head coil. A T2*-weighted gradient echo, echo-planar imaging sequence was used, which covered 41 axial slices and recorded 347 vol acquired sequentially, descending (TR/TE 2000/30 ms, flip angle 75°, 64 × 64 matrix, 3 mm thick, field of view (FoV) = 247 mm). To facilitate fMRI data registration and normalisation, we also acquired a T1-weighted Magnetization Prepared Rapid Gradient Echo MPRAGE image (TR/TE 7312/3.02 ms, flip angle 11°, 256 × 256 matrix, 1.2 mm thick, 196 sagittal slices, FoV = 270 mm). 


### fMRI data analysis 
  
We used SPM12 for pre-processing and subject-level (first level) analyses (Wellcome Department of Cognitive Neurology, Institute for Neurology, London, UK). FSL was utilised for cerebrospinal fluid (CSF) regression and statistical nonparametric permutation inference at the group level (second level) with “randomise” ( ; FMRIB Analysis Research, Oxford Centre for Functional MRI of the Brain, Oxford, UK). 

#### Preprocessing 
  
After reorientation, the EPI files were first slice-time corrected (middle slice as reference). Images were then realigned to the first image and subsequently to the time series mean. The mean EPI image was co-registered to the T1-weighted image to allow for normalisation. The structural files were segmented and the resulting grey matter, white matter and CSF files were used to create a common group-specific template using group-wise DARTEL registration ( ). This template was then employed to normalise the functional EPI files to MNI space. This step simultaneously resampled volumes (1.5 mm isotropic) and applied spatial smoothing (Gaussian FWHM kernel of 8 mm). Finally, for each participant, the time course signal of a CSF mask (top 5% from DARTEL CSF component) was extracted in native space. 


#### Emotional vs neutral video clips 
  
At the first level of analysis, each participant&#x27;s pre-processed data were modelled as a block design using a general linear model framework. We included 3 separate regressors (happy, sad, neutral) encoding the predicted BOLD response associated with video presentation, formed by convolution of the canonical haemodynamic response function (HRF) with boxcars delimiting the video presentation. 

We identified regional estimates of BOLD response associated with watching and rating the video clips. Separate parameter estimates for mean response during the emotional (happy and sad) and neutral category compared to the implicit baseline were produced. At the group level, in a random-effects model, paired t-tests were performed to identify clusters that were differentially activated when watching emotional video clips compared to neutral clips. Moreover, happy and sad clips were compared using paired t-tests. 


#### Intra-individual variation in empathic accuracy 
  
In accordance with  , Z-EA scores for each participant and each video clip were added as parametric modulators at the first level of analysis. On the group level, one sample t-tests were performed, to test whether the BOLD response during emotional video clips was modulated by intra-individual variations in Z-EA scores. 


#### Correlation with emotional intensity ratings 
  
We examined how the BOLD time series correlated with the participant&#x27;s ratings of the target&#x27;s emotional intensity. Scans were split and a model was fitted to each emotional video clip in turn. The continuous ratings of the target&#x27;s emotional intensity for each 2 s bin as rated by the participant were entered as regressors of interest. At the group level, one-sample t-tests assessed whether the relationship between BOLD response and changes in the emotional intensity ratings was significantly observed in any brain region across the group. 


#### Exploratory analysis: impact of affect sharing 
  
To examine differences in BOLD response for video clips that induced affect sharing compared to those that did not, we conducted an exploratory post-hoc analysis. We included the 20 participants who showed affect sharing in response to some, but not all video clips in order to be able to create 3 separate conditions in the first level in a block design (shared, non-shared, neutral). For each participant, emotional videos that induced affect sharing (participants reported to have the same emotion as the target) were included in the shared condition, while emotional videos that did not elicit affect sharing (participants reported to have a different emotion than the target or no emotion) were modelled in the non-shared condition. Separate parameter estimates for mean response during affect shared, non-shared and neutral video clip presentation compared to the implicit baseline were calculated. At the group level, paired t-tests were performed to identify clusters that were differentially activated when watching video clips that induced affect sharing compared to non-shared clips. 


#### Movement, scanner drifts and multiple comparisons correction 
  
As well as the regressors described above, all analyses included seven movement parameters (six standard parameters as well as volume-to-volume movement) as nuisance regressors. For each volume-to-volume movement exceeding 1 mm, an additional regressor was included marking the location of that volume and those immediately adjacent (for a summary of volume-to-volume movement see  ). The CSF regressor was also included as a nuisance regressor. To control for task-related hand movement artefacts, button presses were included as condition of no interest. To investigate the effect of controlling for button presses, we additionally repeated all analyses without including this condition. Moreover, we compared button presses during emotional video clips with button presses during neutral video clips as separate conditions to ensure that activity relating to emotion processing was not partialled out. 

Data were high pass filtered with a threshold of 209 s, which corresponds to twice the length of the longest video clip, to control for scanner drifts. 

Results reported are based on Family-Wise Error (FWE) corrected threshold-free cluster enhancement (TFCE:   p   &lt; 0.05 ( )). For each significant cluster, the peak activations with a minimum inter-peak distance of 20 voxels are reported to account for the wide-spanning clusters found in our analyses. 




## Results 
  
### Behavioural data 
  
#### Behavioural analysis of the fMRI sample 
  
On average, participants had high EA scores (mean   r   = .75, mean intra-individual standard deviation (iSD) = .35, range = .13 to .97). Fisher&#x27;s Z-transformed (Z-)EA scores were slightly, but significantly, lower for sad video clips (mean Z-EA = 0.97, SD = 0.21) than happy ones (mean Z-EA = 1.16, SD = 0.19;   t   (33) = 5.17,   p   &lt; .001). As expected, participants&#x27; average ratings of the target&#x27;s emotional intensity were higher for emotional than for neutral video clips (mean emotional = 5.18, mean neutral = 1.75,   t   (33) = 15.29,   p   &lt; .001), with higher ratings for sad compared to happy ones (mean sad = 5.49, mean happy = 4.87,   t   (33) = 3.02,   p   &lt; .01). 

On average, participants correctly inferred the target&#x27;s emotion in 90.4% of clips (emotion identification, SD = 15.1%), with no difference between happy and sad clips (  t   (33) = −0.33,   p   = .74). They also reported experiencing the same emotion as the target for the majority of the emotional video clips (affect sharing, mean = 72.8%, SD = 28.5%), with a higher degree concordance for sad (mean = 79.4%, SD = 32.8%) compared to happy clips (mean = 66.2%, SD = 31.9%;   t   (33) = 2.5,   p   &lt; .05). 13 participants shared the target&#x27;s emotion in every emotional video clip while one participant did not show affect sharing in any of the clips. For the remaining 20 participants who showed a mix of affect sharing and non-sharing, Z-EA scores did not differ for videos that elicited affect sharing (mean Z-EA = 1.09, SD = .24) compared to those that did not (mean Z-EA = 1.06, SD = .33,   t   (19) = .36,   p   = .72). 

Additionally, we found a positive correlation between participants&#x27; mean Z-EA scores and IRI perspective-taking (  r   = .48,   p   &lt; .01). No significant correlations were found between mean Z-EA scores and the other IRI subscales or estimated IQ (all   ps   &gt; .09). 

Note that while we used Pearson&#x27;s product-moment correlation, alternative methods for assessing agreement are available such as the intraclass correlation coefficient. EA scores derived using this measure were highly correlated (r = 0.89) with Pearson&#x27;s correlations. We chose the latter for two reasons. First, we were able to confirm our findings after partialling out dependency over time of the ratings (data not shown) and second, we wished to maintain compatibility with previous studies using similar tasks that also based estimates of inter-rater agreement on Pearson&#x27;s correlations. 


#### Behavioural analysis of the normative data sample 
  
The analysis showed that the mean Z-EA scores for the video clips presented in the fMRI study were strongly positively correlated with Z-EA scores for the seven clips presented in the normative data study (happy:   r   = .82,   p   &lt; .001; sad:   r   = .77,   p   &lt; .001). Furthermore, the intra-individual standard deviation of the four emotional video clips presented in the scanner (mean iSD = .36) did not differ from the individual standard deviation across all 20 emotional video clips presented outside the scanner (mean iSD = .39,   t   (59) = −1.64,   p   = .11). 



### fMRI data 
  
#### Emotional vs. neutral video clips 
  
Group-level analysis revealed a higher BOLD response during emotional compared to neutral clips in a large cluster spanning multiple regions, with peak activations in bilateral occipital poles and inferior lateral occipital cortex ( a,  ). The cluster included bilateral posterior and anterior superior temporal cortex (STC), as well as bilateral temporal pole (TP), bilateral planum temporale and bilateral posterior temporoparietal junction (pTPJ). Higher activation was also seen in right inferior frontal gyrus (IFG; including pars triangularis and opercularis), with the cluster extending into right anterior insular cortex (AI) and right putamen. A second cluster showed higher activation in supplementary motor area (SMA). While participants were watching neutral compared to emotional video clips, activation was higher in left superior lateral occipital cortex, left posterior cingulate cortex (PCC) and left precuneus. Significant activation was similar, albeit more widespread, when not controlling for button presses (see  ). Moreover, when analysing the button press condition separately for emotional and neutral video clips, no brain regions showed significant differences between both button press conditions.   
 Neural substrates of changes in empathy.   a) Significant brain activations when viewing emotional video clips compared to neutral ones. b) Regions significantly positively (red) and negatively (blue) modulated by variations in empathic accuracy (Z-EA scores). c) top: Brain areas significantly positively correlated over time with the participants&#x27; ratings of the target&#x27;s emotional intensity. bottom: BOLD response (after first level regression) of significant clusters (blue) and participant&#x27;s ratings of the target&#x27;s emotional intensity (green) of one exemplary participant. Key: STC - superior temporal cortex, TP - temporal pole, TPJ - temporoparietal junction, IFG - inferior frontal gyrus, SMA - supplementary motor area, aMCC - anterior midcingulate cortex. 
  Fig. 2     
Significant clusters and their peak activations for the contrasts emotional &gt; neutral video clips and neutral &gt; emotional video clips (threshold-free cluster enhancement   p   &lt; 0.05). 
  Table 2   

To explore differences between the different emotion conditions, we also directly compared happy and sad video clips. Activation in the bilateral STC was higher during happy compared to sad clips, while the right paracingulate gyrus and right precuneus showed higher activation during sad video clips (see   and  ). 


#### Intra-individual variation in empathic accuracy 
  
Participants&#x27; intra-individual variations in Z-EA scores were positively related to activation in clusters spanning the bilateral STC, planum temporale, TP and pTPJ, left hippocampus and left amygdala. Activity in the bilateral inferior lateral occipital cortex and fusiform cortex was also positively related to Z-EA scores ( b,  ). Activation in the bilateral paracingulate gyrus and right frontal pole as well as the right middle frontal gyrus was significantly negatively modulated by Z-EA scores.   
Significant clusters and their peak activations for the modulation of BOLD-response by intra-individual variation of Z-EA scores (threshold-free cluster enhancement   p   &lt; 0.05). 
  Table 3   


#### Correlation with emotional intensity ratings 
  
While watching emotional video clips, participants&#x27; fluctuations in ratings of the targets&#x27; emotional intensity were positively correlated over time with changes in BOLD response in multiple brain regions ( c,  ). Associations were found in multiple clusters including bilateral posterior STC, bilateral TP, bilateral IFG (including pars triangularis and opercularis), bilateral SMA, bilateral middle and superior frontal cortices, right anterior midcingulate cortex (aMCC), right AI, bilateral amygdala, bilateral putamen as well as pTPJ and right temporal occipital and anterior temporal fusiform cortex. Emotional intensity ratings and BOLD-response were negatively correlated in the in the bilateral superior lateral occipital cortex, PCC, and precuneus.   shows a binarised overlay of significant clusters in the different analyses.   
Binarised overlay of activations related to a) emotional compared to neutral video clips, b) variation positively related to empathic accuracy and c) positive correlation with emotional intensity. 
  Fig. 3     
Significant clusters and their peak activations for the correlation between BOLD-response and the participants&#x27; ratings of the target&#x27;s emotional intensity (threshold-free cluster enhancement   p   &lt; 0.05). 
  Table 4   


#### Exploratory analysis: impact of affect sharing 
  
For emotional video clips, there were no significant differences in BOLD response between clips that elicited, versus those that did not elicit, affect sharing (i.e. participants reported experiencing the same emotion as the target after providing their continuous ratings). 




## Discussion 
  
We used a modified version of the EAT to study neural substrates of empathic accuracy and to gain a better understanding of its underlying components. We demonstrated that fluctuations in participants&#x27; perceived emotional intensity ratings are correlated with activation in a network of brain regions previously implicated in empathy and broader aspects of social cognition (i.e., mentalising). More specifically, consistent with our first hypothesis, we observed increased activation in brain regions associated with empathy and mentalising when participants watched emotional compared to neutral clips. Supporting our second hypothesis, we found a positive correlation between intra-individual variations in empathic accuracy and the temporal lobe, “mentalising” regions of the same network. Confirming our third hypothesis, we found a correlation between fluctuations in ratings of the targets&#x27; perceived emotional intensity over time and activity in these same regions. This network of brain regions appears not only to have a general role in emotion and empathic processing but is also sensitive to   variations   in the intensity of others&#x27; emotions. 

The superior temporal sulcus (STS), temporoparietal junction (TPJ), and temporal pole (TP) have consistently been associated with mentalising ( ). In our study, these areas were more active with higher EA, i.e. when participants were more accurate at tracking the target&#x27;s emotion. Beyond this, we could also show these regions are sensitive to fluctuations in perceived emotional intensity of others. The STS is thought to facilitate mentalising by interpreting social aspects of observed biological motion ( ,  ) and the region has been implicated in EA ( ,  ). The TPJ is involved in inferring other people&#x27;s temporary mental states ( ) while the TP&#x27;s role in mentalising is thought to involve the integration of multimodal information and recollection of social scripts ( ;  ). Combined, these brain regions are involved in distinct emotional and cognitive processes that are required to perform our modified EAT: they are integral for the successful tracking of others&#x27; emotional intensity and correlate positively with intra-individual variations in EA. 

The anterior insula (AI), anterior midcingulate cortex (aMCC), inferior frontal gyrus (IFG) and supplementary motor area (SMA) have previously been implicated in empathy tasks and are associated with the affect sharing component of empathy (or affective empathy) ( ). Together these regions are implicated in the emotional processing of the modified EAT stimuli. Most importantly, we could show for the first time that their activity tracks the perceived emotional intensity of others. However, activity in these brain regions was not sensitive to changes in EA and thus seems more tied to the subjective perception of other&#x27;s feelings. 

This suggests it is the time-series variation in activation in the temporal lobe regions (STS, TPJ, TP) that might be informative for accurately tracking other people&#x27;s emotions, while activation in the frontal regions (AI, ACC, IFG, SMA) represents a different emotion processing component that does not vary with changes in EA ( ). This is consistent with previous studies on EA, which showed either no correlation between EA and activity in the above frontal regions ( ) or, in the case of adolescents, a negative correlation between EA and ACC and AI activation ( ). Furthermore, we could not replicate an association between EA and activity in the inferior parietal lobe, a region implicated in motor imitation and previously interpreted as an affective processing component of EA ( ). Taken together, these findings provide evidence that EA is more closely related to the concept of cognitive empathy and mentalising than affective empathy and emotion sharing. The role of EA in cognitive but not affective empathy is further supported by the positive correlation between EA scores and the perspective-taking scale of a well-established self-report measure of empathy (the IRI) but not with other more affective subscales such as empathic concern. Moreover, participants&#x27; average EA scores did not differ between videos where they shared the same emotion as the target compared to those were they did not, which again suggests that emotion sharing is neither necessary for, nor facilitates, EA. 

Even if EA does only relate to cognitive but not affective empathy, the EAT as a task successfully elicited affective empathy in most of our participants – they reported sharing the target&#x27;s emotion in 73% of the emotional video clips. However, there were no significant differences in brain activity when rating videos where participants shared the same emotion compared to videos where they did not. This further supports our hypothesis that the higher activation in aMCC, AI, SMA and IFG during emotional clips is associated with more basal, empathy-independent aspects of emotion processing. 

Higher activation of the bilateral STS could also be seen during happy compared to sad video clips, while the right paracingulate gyrus was more highly activated during sad video clips. This is in line with our behavioural findings of, on average, higher EA scores during happy video clips, which suggest more successful tracking and mentalising of the target&#x27;s emotion, while sad video clips induced higher rates of affect sharing among participants. The paracingulate gyrus has previously been implicated in affective empathy ( ). 

During the modified EAT, participants rated fluctuations in emotional intensity rather than valence as this allowed a comparable rating scale across different distinct emotions. Furthermore, previous literature suggests distinct neural correlates for processing emotional intensity and valence ( ), with the amygdala being associated with intensity and the orbitofrontal cortex with valence. In agreement with this, we found that bilateral activation of amygdala but not the orbitofrontal cortex covaried with the emotional intensity of the targets. Unexpectedly activation in the precuneus – a region implicated in self-referential processing ( ) – was stronger during neutral versus emotional clips and correlated negatively with emotional intensity ratings. The precuneus is associated with visual-spatial imagery ( ,  ) and is a component of the default mode network ( ). Higher activation during the neutral videos in which participants described their bedroom, might be explained by higher visual-spatial imagery and an increased tendency for mind-wandering during these less engaging parts of the task ( ). 

Empathy is a complex and dynamic process, which requires multiple higher order functions ( ) such as emotion recognition, multimodal sensory integration, self-other distinction and continuous processing of valence and intensity information. Compared to other commonly used empathy tasks, the modified EAT used a more naturalistic setting to examine which brain regions track fluctuations over time in perceived emotional intensity of others and intra-individual variations in empathic accuracy. Previous studies in the empathy and mentalising literature have largely focused on simplistic stimuli (e.g. static images of hands in painful situations). Compared to these earlier studies, we found that regions that have been separately implicated in mentalising and empathy were all involved in performing the modified EAT. However, only brain regions previously associated with mentalising were found to covary with EA, while regions previously implicated in classic affective empathy paradigms were positively correlated with the emotional intensity of others but were not sensitive to changes in EA. In this more naturalistic and complex task, it seems that an interplay between brain networks associated with mentalising and empathy enables the accurate tracking of other&#x27;s emotions. Furthermore, these regions were sensitive to fluctuations in perceived emotional intensity of others, which serves as a potential mechanism for successful communication between these networks to achieve empathic accuracy. 

A possible limitation of our study was the lower number of emotional video clips in comparison to previous studies on EA ( ,  ). This study was conducted within the framework of a larger project, and thus the scanning time was limited. However, we showed that our chosen video clips led to very similar EA scores relative to those obtained with the larger dataset of 27 video clips in the norm sample. More importantly, the intra-individual variation across videos was also comparable to that seen for the full set of video clips. 

The study had a number of strengths. The original EAT ( ) represented an important advance in empathy research, as it was the first task to utilise naturalistic stimuli and assess EA in an fMRI context. In this modified EAT, the stimuli used for fMRI purposes had been validated in a separate behavioural study. Moreover, we added a neutral control condition, which allowed us to identify brain regions that are generally more active during emotional video clips irrespective of empathic accuracy. Future studies could employ this paradigm to study psychiatric populations with empathy deficits (e.g., adolescents with Conduct Disorder;  ). By additionally taking the neutral control condition into account, one could examine whether emotional clips were ‘neutral-like’ in those with low EA scores. For future studies, it would be worth considering incorporating neutral videos with varying topics other than bedroom descriptions to ensure continued engagement throughout the task (see   for possible examples). Furthermore, we introduced the measurement of emotional intensity rather than valence, which is more closely related to the concept of empathy. This also made the video clips of different emotions comparable and allowed a more fine-grained analysis of changes over time in activation related to the emotional intensity of others. Together, we propose that the three analysis techniques used in this study, should be employed in conjunction to allow a comprehensive study of empathic accuracy and its different components. 

In conclusion, we provide the first evidence that the modified EAT is a suitable paradigm for studying empathy and its underlying components. We show that, while the modified EAT successfully induces both affective and cognitive empathy, EA relies more on cognitive empathy than affect sharing. The neutral control condition and the valence-independent rating scale represent valuable additions to the task. The fMRI data analysis techniques developed and described here may prove valuable in characterising differences between healthy participants and participants with psychiatric conditions associated with empathy deficits. 


## Funding 
  
This work was funded by a project grant from the   to ESB, MM and GF (MR/K022474/1). 


## Declaration of interest 
  
We do not have any financial, institutional or other relationships that might lead to a conflict of interest.</pre></details></details>
  <details class="inner-accordion"><summary>Coordinate-relevant source tables (3)</summary><details class="inner-accordion"><summary>Table 2 (tbl2) - Significant clusters and their peak activations for the contrasts emotional &gt; neutral video clips and neutral &gt; emotional video clips (threshold-free cluster enhancement pFWE &lt; 0.05).</summary><div class="table-html"><table-wrap id="tbl2" position="float" orientation="portrait"><label>Table 2</label><caption><p>Significant clusters and their peak activations for the contrasts emotional &gt; neutral video clips and neutral &gt; emotional video clips (threshold-free cluster enhancement <italic toggle="yes">p</italic><sub>FWE</sub> &lt; 0.05).</p></caption><alt-text id="alttext0035">Table 2</alt-text><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" colspan="1">Cluster</th><th rowspan="2" colspan="1">Anatomical region</th><th rowspan="2" colspan="1">Hemisphere</th><th rowspan="2" colspan="1">Cluster size</th><th colspan="3" rowspan="1">MNI coordinates [mm]<hr /></th><th rowspan="2" colspan="1">Peak-level <italic toggle="yes">t</italic></th></tr><tr><th colspan="1" rowspan="1">x</th><th colspan="1" rowspan="1">y</th><th colspan="1" rowspan="1">z</th></tr></thead><tbody><tr><td colspan="8" align="left" rowspan="1"><bold>emotional &gt; neutral video clips</bold><hr /></td></tr><tr><td rowspan="11" align="left" colspan="1">1</td><td align="left" colspan="1" rowspan="1">Occipital Pole</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">9901</td><td align="left" colspan="1" rowspan="1">20</td><td align="left" colspan="1" rowspan="1">−94</td><td align="left" colspan="1" rowspan="1">−2</td><td align="left" colspan="1" rowspan="1">7.33</td></tr><tr><td align="left" colspan="1" rowspan="1">Inferior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−32</td><td align="left" colspan="1" rowspan="1">−90</td><td align="left" colspan="1" rowspan="1">−6</td><td align="left" colspan="1" rowspan="1">6.86</td></tr><tr><td align="left" colspan="1" rowspan="1">Anterior Superior Temporal Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">52</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">−18</td><td align="left" colspan="1" rowspan="1">6.21</td></tr><tr><td align="left" colspan="1" rowspan="1">Occipital Pole</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−16</td><td align="left" colspan="1" rowspan="1">−94</td><td align="left" colspan="1" rowspan="1">12</td><td align="left" colspan="1" rowspan="1">5.94</td></tr><tr><td align="left" colspan="1" rowspan="1">Inferior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">40</td><td align="left" colspan="1" rowspan="1">−70</td><td align="left" colspan="1" rowspan="1">−4</td><td align="left" colspan="1" rowspan="1">5.1</td></tr><tr><td align="left" colspan="1" rowspan="1">Posterior Superior Temporal Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">56</td><td align="left" colspan="1" rowspan="1">−28</td><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">4.57</td></tr><tr><td align="left" colspan="1" rowspan="1">Insular Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">28</td><td align="left" colspan="1" rowspan="1">16</td><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">4.39</td></tr><tr><td align="left" colspan="1" rowspan="1">Temporal Occipital Fusiform Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">40</td><td align="left" colspan="1" rowspan="1">−50</td><td align="left" colspan="1" rowspan="1">−16</td><td align="left" colspan="1" rowspan="1">4.15</td></tr><tr><td align="left" colspan="1" rowspan="1">Frontal Operculum Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">48</td><td align="left" colspan="1" rowspan="1">16</td><td align="left" colspan="1" rowspan="1">0</td><td align="left" colspan="1" rowspan="1">4.02</td></tr><tr><td align="left" colspan="1" rowspan="1">Occipital Fusiform Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−36</td><td align="left" colspan="1" rowspan="1">−70</td><td align="left" colspan="1" rowspan="1">−16</td><td align="left" colspan="1" rowspan="1">4.01</td></tr><tr><td align="left" colspan="1" rowspan="1">Occipital Pole</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−10</td><td align="left" colspan="1" rowspan="1">−100</td><td align="left" colspan="1" rowspan="1">−14</td><td align="left" colspan="1" rowspan="1">3.44</td></tr><tr><td rowspan="4" align="left" colspan="1">2</td><td align="left" colspan="1" rowspan="1">Anterior Superior Temporal Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">2243</td><td align="left" colspan="1" rowspan="1">−52</td><td align="left" colspan="1" rowspan="1">−6</td><td align="left" colspan="1" rowspan="1">−14</td><td align="left" colspan="1" rowspan="1">5.32</td></tr><tr><td align="left" colspan="1" rowspan="1">Posterior Supramarginal Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−56</td><td align="left" colspan="1" rowspan="1">−44</td><td align="left" colspan="1" rowspan="1">14</td><td align="left" colspan="1" rowspan="1">4.45</td></tr><tr><td align="left" colspan="1" rowspan="1">Middle Temporal Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−44</td><td align="left" colspan="1" rowspan="1">−32</td><td align="left" colspan="1" rowspan="1">−2</td><td align="left" colspan="1" rowspan="1">3.85</td></tr><tr><td align="left" colspan="1" rowspan="1">Planum Temporale</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−60</td><td align="left" colspan="1" rowspan="1">−20</td><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">3.48</td></tr><tr><td align="left" colspan="1" rowspan="1">3</td><td align="left" colspan="1" rowspan="1">Supplementary Motor Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">250</td><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">60</td><td align="left" colspan="1" rowspan="1">5.04</td></tr><tr><td align="left" colspan="1" rowspan="1">4<hr /></td><td align="left" colspan="1" rowspan="1">Temporal Pole<hr /></td><td align="left" colspan="1" rowspan="1">L<hr /></td><td align="left" colspan="1" rowspan="1">6<hr /></td><td align="left" colspan="1" rowspan="1">−46<hr /></td><td align="left" colspan="1" rowspan="1">18<hr /></td><td align="left" colspan="1" rowspan="1">−26<hr /></td><td align="left" colspan="1" rowspan="1">3.53<hr /></td></tr><tr><td colspan="8" align="left" rowspan="1"><bold>neutral &gt; emotional video clips</bold><hr /></td></tr><tr><td align="left" colspan="1" rowspan="1">1</td><td align="left" colspan="1" rowspan="1">Superior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">1014</td><td align="left" colspan="1" rowspan="1">−34</td><td align="left" colspan="1" rowspan="1">−80</td><td align="left" colspan="1" rowspan="1">40</td><td align="left" colspan="1" rowspan="1">6.59</td></tr><tr><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">Superior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−44</td><td align="left" colspan="1" rowspan="1">−84</td><td align="left" colspan="1" rowspan="1">22</td><td align="left" colspan="1" rowspan="1">5.86</td></tr><tr><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">Posterior Cingulate Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">207</td><td align="left" colspan="1" rowspan="1">−4</td><td align="left" colspan="1" rowspan="1">−38</td><td align="left" colspan="1" rowspan="1">40</td><td align="left" colspan="1" rowspan="1">8.99</td></tr><tr><td align="left" colspan="1" rowspan="1">3</td><td align="left" colspan="1" rowspan="1">Precuneus Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">86</td><td align="left" colspan="1" rowspan="1">−14</td><td align="left" colspan="1" rowspan="1">−60</td><td align="left" colspan="1" rowspan="1">14</td><td align="left" colspan="1" rowspan="1">6.2</td></tr><tr><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">Superior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">54</td><td align="left" colspan="1" rowspan="1">36</td><td align="left" colspan="1" rowspan="1">−76</td><td align="left" colspan="1" rowspan="1">42</td><td align="left" colspan="1" rowspan="1">5.32</td></tr><tr><td align="left" colspan="1" rowspan="1">5</td><td align="left" colspan="1" rowspan="1">Lingual Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">34</td><td align="left" colspan="1" rowspan="1">−38</td><td align="left" colspan="1" rowspan="1">−10</td><td align="left" colspan="1" rowspan="1">5.49</td></tr><tr><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">Planum Temporale</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">30</td><td align="left" colspan="1" rowspan="1">−30</td><td align="left" colspan="1" rowspan="1">−20</td><td align="left" colspan="1" rowspan="1">5.46</td></tr></tbody></table></table-wrap></div></details><details class="inner-accordion"><summary>Table 3 (tbl3) - Significant clusters and their peak activations for the modulation of BOLD-response by intra-individual variation of Z-EA scores (threshold-free cluster enhancement pFWE &lt; 0.05).</summary><div class="table-html"><table-wrap id="tbl3" position="float" orientation="portrait"><label>Table 3</label><caption><p>Significant clusters and their peak activations for the modulation of BOLD-response by intra-individual variation of Z-EA scores (threshold-free cluster enhancement <italic toggle="yes">p</italic><sub>FWE</sub> &lt; 0.05).</p></caption><alt-text id="alttext0040">Table 3</alt-text><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" colspan="1">Cluster</th><th rowspan="2" colspan="1">Anatomical region</th><th rowspan="2" colspan="1">Hemisphere</th><th rowspan="2" colspan="1">Cluster size</th><th colspan="3" rowspan="1">MNI coordinates [mm]<hr /></th><th rowspan="2" colspan="1">Peak-level <italic toggle="yes">t</italic></th></tr><tr><th colspan="1" rowspan="1">x</th><th colspan="1" rowspan="1">y</th><th colspan="1" rowspan="1">z</th></tr></thead><tbody><tr><td colspan="8" align="left" rowspan="1"><bold>Positively related to Z-EA scores</bold><hr /></td></tr><tr><td rowspan="7" align="left" colspan="1">1</td><td align="left" colspan="1" rowspan="1">Posterior Superior Temporal Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">9036</td><td align="left" colspan="1" rowspan="1">−62</td><td align="left" colspan="1" rowspan="1">−26</td><td align="left" colspan="1" rowspan="1">10</td><td align="left" colspan="1" rowspan="1">9.88</td></tr><tr><td align="left" colspan="1" rowspan="1">Planum Temporale</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−38</td><td align="left" colspan="1" rowspan="1">−34</td><td align="left" colspan="1" rowspan="1">14</td><td align="left" colspan="1" rowspan="1">9.17</td></tr><tr><td align="left" colspan="1" rowspan="1">Temporal Pole</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−54</td><td align="left" colspan="1" rowspan="1">−2</td><td align="left" colspan="1" rowspan="1">−2</td><td align="left" colspan="1" rowspan="1">7.02</td></tr><tr><td align="left" colspan="1" rowspan="1">Hippocampus</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−20</td><td align="left" colspan="1" rowspan="1">−14</td><td align="left" colspan="1" rowspan="1">−20</td><td align="left" colspan="1" rowspan="1">6.50</td></tr><tr><td align="left" colspan="1" rowspan="1">Inferior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−44</td><td align="left" colspan="1" rowspan="1">−72</td><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">6.03</td></tr><tr><td align="left" colspan="1" rowspan="1">Posterior Temporal Fusiform Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−38</td><td align="left" colspan="1" rowspan="1">−42</td><td align="left" colspan="1" rowspan="1">−26</td><td align="left" colspan="1" rowspan="1">4.67</td></tr><tr><td align="left" colspan="1" rowspan="1">Occipital Fusiform Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−20</td><td align="left" colspan="1" rowspan="1">−90</td><td align="left" colspan="1" rowspan="1">−18</td><td align="left" colspan="1" rowspan="1">4.61</td></tr><tr><td rowspan="2" align="left" colspan="1">2</td><td align="left" colspan="1" rowspan="1">Planum Temporale</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">2421</td><td align="left" colspan="1" rowspan="1">64</td><td align="left" colspan="1" rowspan="1">−16</td><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">7.37</td></tr><tr><td align="left" colspan="1" rowspan="1">Planum Temporale</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">34</td><td align="left" colspan="1" rowspan="1">−28</td><td align="left" colspan="1" rowspan="1">14</td><td align="left" colspan="1" rowspan="1">4.93</td></tr><tr><td rowspan="2" align="left" colspan="1">3<hr /></td><td align="left" colspan="1" rowspan="1">Inferior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">2315</td><td align="left" colspan="1" rowspan="1">46</td><td align="left" colspan="1" rowspan="1">−66</td><td align="left" colspan="1" rowspan="1">0</td><td align="left" colspan="1" rowspan="1">7.80</td></tr><tr><td align="left" colspan="1" rowspan="1">Occipital Fusiform Cortex<hr /></td><td align="left" colspan="1" rowspan="1">R<hr /></td><td colspan="1" rowspan="1"><hr /></td><td align="left" colspan="1" rowspan="1">22<hr /></td><td align="left" colspan="1" rowspan="1">−88<hr /></td><td align="left" colspan="1" rowspan="1">−8<hr /></td><td align="left" colspan="1" rowspan="1">5.37<hr /></td></tr><tr><td colspan="8" align="left" rowspan="1"><bold>Negatively related to Z-EA scores</bold><hr /></td></tr><tr><td rowspan="3" align="left" colspan="1">1</td><td align="left" colspan="1" rowspan="1">Paracingulate Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">275</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">22</td><td align="left" colspan="1" rowspan="1">48</td><td align="left" colspan="1" rowspan="1">4.11</td></tr><tr><td align="left" colspan="1" rowspan="1">Frontal Pole</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">10</td><td align="left" colspan="1" rowspan="1">62</td><td align="left" colspan="1" rowspan="1">36</td><td align="left" colspan="1" rowspan="1">4.01</td></tr><tr><td align="left" colspan="1" rowspan="1">Paracingulate Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−6</td><td align="left" colspan="1" rowspan="1">44</td><td align="left" colspan="1" rowspan="1">30</td><td align="left" colspan="1" rowspan="1">3.81</td></tr><tr><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">Middle Frontal Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">31</td><td align="left" colspan="1" rowspan="1">36</td><td align="left" colspan="1" rowspan="1">14</td><td align="left" colspan="1" rowspan="1">32</td><td align="left" colspan="1" rowspan="1">4.42</td></tr></tbody></table></table-wrap></div></details><details class="inner-accordion"><summary>Table 4 (tbl4) - Significant clusters and their peak activations for the correlation between BOLD-response and the participants&#x27; ratings of the target&#x27;s emotional intensity (threshold-free cluster enhancement pFWE &lt; 0.05).</summary><div class="table-html"><table-wrap id="tbl4" position="float" orientation="portrait"><label>Table 4</label><caption><p>Significant clusters and their peak activations for the correlation between BOLD-response and the participants' ratings of the target's emotional intensity (threshold-free cluster enhancement <italic toggle="yes">p</italic><sub>FWE</sub> &lt; 0.05).</p></caption><alt-text id="alttext0045">Table 4</alt-text><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" colspan="1">Cluster</th><th rowspan="2" colspan="1">Anatomical region</th><th rowspan="2" colspan="1">Hemisphere</th><th rowspan="2" colspan="1">Cluster size</th><th colspan="3" rowspan="1">MNI coordinates [mm]<hr /></th><th rowspan="2" colspan="1">Peak-level <italic toggle="yes">t</italic></th></tr><tr><th colspan="1" rowspan="1">x</th><th colspan="1" rowspan="1">y</th><th colspan="1" rowspan="1">z</th></tr></thead><tbody><tr><td colspan="8" align="left" rowspan="1"><bold>Positive correlation with participants' emotional intensity ratings</bold><hr /></td></tr><tr><td rowspan="17" align="left" colspan="1">1</td><td align="left" colspan="1" rowspan="1">Posterior Superior Temporal Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">24492</td><td align="left" colspan="1" rowspan="1">58</td><td align="left" colspan="1" rowspan="1">−16</td><td align="left" colspan="1" rowspan="1">0</td><td align="left" colspan="1" rowspan="1">9.56</td></tr><tr><td align="left" colspan="1" rowspan="1">Posterior Middle Frontal Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">62</td><td align="left" colspan="1" rowspan="1">−36</td><td align="left" colspan="1" rowspan="1">0</td><td align="left" colspan="1" rowspan="1">8.26</td></tr><tr><td align="left" colspan="1" rowspan="1">Temporal Pole</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">58</td><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">−16</td><td align="left" colspan="1" rowspan="1">8.19</td></tr><tr><td align="left" colspan="1" rowspan="1">Planum Temporale</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−64</td><td align="left" colspan="1" rowspan="1">−14</td><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">8.05</td></tr><tr><td align="left" colspan="1" rowspan="1">Putamen</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">26</td><td align="left" colspan="1" rowspan="1">−92</td><td align="left" colspan="1" rowspan="1">−6</td><td align="left" colspan="1" rowspan="1">7.4</td></tr><tr><td align="left" colspan="1" rowspan="1">Temporal Pole</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−56</td><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">−10</td><td align="left" colspan="1" rowspan="1">7.04</td></tr><tr><td align="left" colspan="1" rowspan="1">Middle Frontal Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">48</td><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">38</td><td align="left" colspan="1" rowspan="1">6.92</td></tr><tr><td align="left" colspan="1" rowspan="1">Middle Temporal Gyrus, temporooccipital part</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">46</td><td align="left" colspan="1" rowspan="1">−56</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">6.49</td></tr><tr><td align="left" colspan="1" rowspan="1">Temporal Occipital Fusiform Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">40</td><td align="left" colspan="1" rowspan="1">−46</td><td align="left" colspan="1" rowspan="1">−16</td><td align="left" colspan="1" rowspan="1">6.06</td></tr><tr><td align="left" colspan="1" rowspan="1">Temporal Occipital Fusiform Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−46</td><td align="left" colspan="1" rowspan="1">−64</td><td align="left" colspan="1" rowspan="1">−28</td><td align="left" colspan="1" rowspan="1">5.7</td></tr><tr><td align="left" colspan="1" rowspan="1">Insular Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">38</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">−20</td><td align="left" colspan="1" rowspan="1">5.49</td></tr><tr><td align="left" colspan="1" rowspan="1">Middle Temporal Gyrus, temporooccipital part</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−64</td><td align="left" colspan="1" rowspan="1">−44</td><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">5.31</td></tr><tr><td align="left" colspan="1" rowspan="1">Inferior Frontal Gyrus, pars triangularis</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">56</td><td align="left" colspan="1" rowspan="1">28</td><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">5.04</td></tr><tr><td align="left" colspan="1" rowspan="1">Temporal Pole</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−44</td><td align="left" colspan="1" rowspan="1">20</td><td align="left" colspan="1" rowspan="1">−26</td><td align="left" colspan="1" rowspan="1">4.93</td></tr><tr><td align="left" colspan="1" rowspan="1">Occipital Fusiform Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−30</td><td align="left" colspan="1" rowspan="1">−82</td><td align="left" colspan="1" rowspan="1">−18</td><td align="left" colspan="1" rowspan="1">4.87</td></tr><tr><td align="left" colspan="1" rowspan="1">Planum Temporale</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−40</td><td align="left" colspan="1" rowspan="1">−36</td><td align="left" colspan="1" rowspan="1">10</td><td align="left" colspan="1" rowspan="1">4.84</td></tr><tr><td align="left" colspan="1" rowspan="1">Amygdala</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−18</td><td align="left" colspan="1" rowspan="1">−6</td><td align="left" colspan="1" rowspan="1">−14</td><td align="left" colspan="1" rowspan="1">4.78</td></tr><tr><td rowspan="2" align="left" colspan="1">2</td><td align="left" colspan="1" rowspan="1">Supplementary Motor Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">1735</td><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">66</td><td align="left" colspan="1" rowspan="1">6.85</td></tr><tr><td align="left" colspan="1" rowspan="1">Anterior Midcingulate Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">14</td><td align="left" colspan="1" rowspan="1">38</td><td align="left" colspan="1" rowspan="1">3.74</td></tr><tr><td rowspan="2" align="left" colspan="1">3</td><td align="left" colspan="1" rowspan="1">Precentral Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">1714</td><td align="left" colspan="1" rowspan="1">−40</td><td align="left" colspan="1" rowspan="1">−8</td><td align="left" colspan="1" rowspan="1">56</td><td align="left" colspan="1" rowspan="1">5.64</td></tr><tr><td align="left" colspan="1" rowspan="1">Superior Frontal Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−24</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">72</td><td align="left" colspan="1" rowspan="1">4.96</td></tr><tr><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">Postcentral Gyrus</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">206</td><td align="left" colspan="1" rowspan="1">−48</td><td align="left" colspan="1" rowspan="1">−26</td><td align="left" colspan="1" rowspan="1">40</td><td align="left" colspan="1" rowspan="1">4.05</td></tr><tr><td align="left" colspan="1" rowspan="1">5<hr /></td><td align="left" colspan="1" rowspan="1">Putamen<hr /></td><td align="left" colspan="1" rowspan="1">R<hr /></td><td align="left" colspan="1" rowspan="1">173<hr /></td><td align="left" colspan="1" rowspan="1">18<hr /></td><td align="left" colspan="1" rowspan="1">10<hr /></td><td align="left" colspan="1" rowspan="1">6<hr /></td><td align="left" colspan="1" rowspan="1">4.67<hr /></td></tr><tr><td colspan="8" align="left" rowspan="1"><bold>Negative correlation with participants' emotional intensity ratings</bold><hr /></td></tr><tr><td rowspan="7" align="left" colspan="1">1</td><td align="left" colspan="1" rowspan="1">Cuneus Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td align="left" colspan="1" rowspan="1">10193</td><td align="left" colspan="1" rowspan="1">10</td><td align="left" colspan="1" rowspan="1">−86</td><td align="left" colspan="1" rowspan="1">24</td><td align="left" colspan="1" rowspan="1">6.42</td></tr><tr><td align="left" colspan="1" rowspan="1">Posterior Cingulate Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">−34</td><td align="left" colspan="1" rowspan="1">38</td><td align="left" colspan="1" rowspan="1">5.48</td></tr><tr><td align="left" colspan="1" rowspan="1">Precuneus Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−4</td><td align="left" colspan="1" rowspan="1">−66</td><td align="left" colspan="1" rowspan="1">16</td><td align="left" colspan="1" rowspan="1">5.3</td></tr><tr><td align="left" colspan="1" rowspan="1">Superior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">38</td><td align="left" colspan="1" rowspan="1">−74</td><td align="left" colspan="1" rowspan="1">22</td><td align="left" colspan="1" rowspan="1">5.25</td></tr><tr><td align="left" colspan="1" rowspan="1">Precuneus Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">−12</td><td align="left" colspan="1" rowspan="1">−58</td><td align="left" colspan="1" rowspan="1">34</td><td align="left" colspan="1" rowspan="1">4.82</td></tr><tr><td align="left" colspan="1" rowspan="1">Lingual Gyrus</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">26</td><td align="left" colspan="1" rowspan="1">−52</td><td align="left" colspan="1" rowspan="1">−4</td><td align="left" colspan="1" rowspan="1">4.66</td></tr><tr><td align="left" colspan="1" rowspan="1">Superior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">R</td><td colspan="1" rowspan="1" /><td align="left" colspan="1" rowspan="1">44</td><td align="left" colspan="1" rowspan="1">−64</td><td align="left" colspan="1" rowspan="1">46</td><td align="left" colspan="1" rowspan="1">3.99</td></tr><tr><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">Superior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">466</td><td align="left" colspan="1" rowspan="1">−38</td><td align="left" colspan="1" rowspan="1">−70</td><td align="left" colspan="1" rowspan="1">32</td><td align="left" colspan="1" rowspan="1">4.69</td></tr><tr><td align="left" colspan="1" rowspan="1">3</td><td align="left" colspan="1" rowspan="1">Temporal Occipital Fusiform Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">121</td><td align="left" colspan="1" rowspan="1">−24</td><td align="left" colspan="1" rowspan="1">−56</td><td align="left" colspan="1" rowspan="1">−12</td><td align="left" colspan="1" rowspan="1">3.23</td></tr><tr><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">Superior Lateral Occipital Cortex</td><td align="left" colspan="1" rowspan="1">L</td><td align="left" colspan="1" rowspan="1">32</td><td align="left" colspan="1" rowspan="1">−50</td><td align="left" colspan="1" rowspan="1">−74</td><td align="left" colspan="1" rowspan="1">26</td><td align="left" colspan="1" rowspan="1">3.77</td></tr></tbody></table></table-wrap></div></details></details>
</details>


<details class="doc-card">
  <summary><strong>PMID 30349467</strong> | Pred included: 6 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/30349467/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>30349467_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;participants reported their ability to lead or follow...transmit/receive information while dancing with a partner&quot;.</td></tr>
<tr><td>30349467_analysis_1</td><td>Leading versus Following — header (Whole-group / Leaders only / Followers only)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;transmit/receive information while dancing with a partner&quot;.</td></tr>
<tr><td>30349467_analysis_2</td><td>Leading &gt; Following — Whole group</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;ability to transmit/receive information while dancing with a partner&quot;.</td></tr>
<tr><td>30349467_analysis_3</td><td>Following &gt; Leading (whole group)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;pSTS...multisensory perception of biological motion&quot;.</td></tr>
<tr><td>30349467_analysis_4</td><td>Leading versus following correlated with skill as a leader — Activation</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;STG and insula&quot; (regions implicated in processing social/auditory and interoceptive cues relevant to communication).</td></tr>
<tr><td>30349467_analysis_5</td><td>Leading versus Following correlated with leader skill - Deactivation</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because the deactivation segment does not provide evidence of social-communication processing (missing SOCIAL_COMMUNICATION_I1).</td></tr>
<tr><td>30349467_analysis_6</td><td>Deactivation: Leading versus Following correlated with follower skill</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;pSTS and TPJ&quot; (regions implicated in perception of biological motion and social signals).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <p>No manual-to-auto match diagnostics for this document.</p>
  </details>
  <details class="inner-accordion"><summary>PMC full text available (PMCID 6186800)</summary><p><strong>Title:</strong> Role-Specific Brain Activations in Leaders and Followers During Joint Action</p><details><summary>Abstract</summary><pre class="paper-text">Much of social interaction in human life requires that individuals perform different roles during joint actions, the most basic distinction being that between a leader and a follower. A number of neuroimaging studies have examined the brain networks for leading and following, but none have examined what effect prior expertise at these roles has on brain activations during joint motor tasks. Couple dancers (e.g., dancers of Tango, Salsa, and swing) are an ideal population in which examine such effects, since leaders and followers of partnered dances have similar overall levels of motor expertise at dancing, but can differ strikingly in their role-specific skill sets. To explore role-specific expertise effects on brain activations for the first time, we recruited nine skilled leaders and nine skilled followers of couple dances for a functional magnetic resonance imaging study. We employed a two-person scanning arrangement that allowed a more naturalistic interaction between two individuals. The dancers interacted physically with an experimenter standing next to the bore of the magnet so as to permit bimanual partnered movements. Together, they alternated between leading and following the joint movements. The results demonstrated that the brain activations during the acts of leading and following were enhanced by prior expertise at being a leader or follower, and that activity in task-specific brain areas tended to be positively correlated with the level of expertise at the corresponding role. These findings provide preliminary evidence that training at one role of a joint motor task can selectively enhance role-related brain activations.</pre></details><details><summary>Body</summary><pre class="paper-text">## Introduction 
  
Much joint action between two people involves the contrastive roles of leader and follower ( ). For example, when two people move a sofa, the front person is often the one who navigates the joint movement as well as the one who determines the speed at which the two people move, while the back person responds to these movement-cues and attempts to coordinate his/her actions with the front person. However, the experimental literature that examines joint action in the lab does not give consideration to individual differences, for example the fact that people may be predisposed toward being a leader or follower based on their personality traits or life experiences ( ). In typical studies of joint action, people are randomly assigned to being a leader or follower (or both) of a joint task without assessing individual differences in task expertise that may exist between them. This applies to studies of both experts ( ;  ) and non-experts ( ;  ;  ;  ). This may be problematic since many studies demonstrate that expertise has an effect on behavioral performance and brain activations across many domains ( ;  ;  ). 

An interesting solution to this problem is to examine couple dancers, such as Tango dancers, since such people engage in extensive training to develop expertise at one specific role in the dance, thereby making the assessment of leading/following experience on joint action quite feasible. Leaders and followers of a couple dance have similar overall levels of motor expertise at dancing, but they can differ strikingly in their role-specific skill sets, such that dancers of one role are often unable to dance the opposite role. This applies not merely to the movement patterns themselves, but to the   coordination   skills required for leading (e.g., force conveyance) and following (e.g., responsiveness to force cues). While previous neuroimaging studies have looked separately at the topics of leading/following and expertise, the current study–which is a follow-up analysis to a previously published study from our lab ( )–represents a first attempt at examining   role-specific expertise   at leading and following, doing so using trained leaders and followers of couple dances. The principal aim of the study is to identify role-specific brain activations, namely leading-related activations in trained leaders compared to non-leaders, and following-related activations in trained followers compared to non-followers. 

Previous studies of leading and following have tended to emphasize the networks for leading, more so than those for following. For example, studies of interactive imitation have compared the initiation and imitation of visual actions within the same group of participants, and have highlighted an initiation network involved in self-monitoring, willed action, and decision making ( ;  ;  ;  ). Studies of auditory-entrainment tasks, such as finger tapping, have studied expert leaders or individuals who spontaneously emerge as leaders with in the context of the study, and have similarly identified a network involved in decision making, movement initiation, and self-processing ( ;  ;  ). These studies have provided either no results or inconsistent findings regarding following or expert followers. In a previous publication from our lab ( ), we characterized the networks for leading and following during a joint-action task with physical interaction, using the same dancer participants as those employed in the present study. In accordance with the previous literature, we found that leading showed a motor- and self-oriented profile, engaging areas associated with motor planning, spatial navigation, sequencing, action monitoring, and error correction. In contrast, following showed a far more sensory- and externally oriented profile, revealing areas involved in somatosensation, proprioception, motion tracking, social cognition, and outcome monitoring. However, while that study compared the act of leading with the act of following, it did not assess the influence of prior expertise at being a leader or follower on the brain activations. That was the major objective of the current follow-up analysis, namely to examine role-specific expertise. 

It is well-established that expertise can influence both the structure and function of the brain. There is now a vast literature devoted to various forms of motor, perceptual, and cognitive expertise (reviewed in  ). A general finding of such studies is that brain activations and gray matter volume are enhanced in experts, as compared to non-experts, in areas that process the skills that underlie a person’s domain of expertise ( ;  ;  ). For example, with regard to perceptual tasks, trained musicians and other auditory experts show enhanced effects in auditory cortex ( ,  ;  ;  ), while visual experts show effects in visual cortex ( ,  ;  ). In the motor domain, effects are found in cortical and subcortical motor and premotor areas involved in motor execution, control, planning, and representation ( ;  ). Motor experts, such as athletes, dancers, and musicians, additionally demonstrate changes in perceptual and cognitive areas associated with their trained skills ( ). For example, sensorimotor coupling is enhanced in musicians and athletes ( ;  ). In addition, activations in the action-observation network [including premotor cortex (PMC), superior parietal lobule (SPL), and inferior parietal lobule (IPL)] are enhanced when dancers view specific dance patterns that they are expert in ( ), or when athletes view sports actions that they are expert in ( ), as compared to when the same people view dances or sports movements that they are not trained in.   suggested that this effect was due to motor training, rather than the associated perceptual training. Expertise, in addition to producing enhancements in processing, has also been linked to decreases in the overall number of activated foci in neuroimaging studies, especially in attentional and cognitive-control networks, suggesting an enhancement in automaticity of processing for the trained skill ( ;  ). The “two stage expertise hypothesis” ( ;  ) suggests that short-term training leads to enhancements of brain activations for the trained skill, while long-term training and skill mastering lead instead to decreases or reorganizations in brain activations. 

While previous neuroimaging studies have looked at leading/following and expertise in isolation, no study thus far has combined the two issues, which is the principal objective of the present study. As mentioned above, couple dancers are an ideal cohort for exploring role-specific expertise in leading and following, since they spend many years developing expertise at typically just one of the two roles of the dance. As a result, expert leaders are usually unskilled followers, and vice versa, while both groups have comparable levels of overall motor expertise at the dance. More specifically, leader expertise during couple dancing requires the generation of a motor plan for both the self and the partner, and the efficient conveyance of signals to the partner, while follower expertise requires the tracking of information coming from the leader and its interpretation to construct either an identical or complementary movement pattern in real time. 

In order to assess the effect of role expertise on brain activations during an ecologically valid joint-action task, we carried out an exploratory follow-up analysis to our previous publication that looked at leading and following ( ) in order to examine the effects of role-specific expertise on brain activations. In the previous study, skilled leaders and followers of couple dances performed both a leading and following task in a magnetic resonance imaging (MRI) scanner in interaction with an experimenter standing next to the bore of the magnet. The participant and experimenter were in physical contact at their hands, and alternated between being the leader and follower of joint improvised bimanual movements. The principal aim of the study was to compare brain activity during the acts of leading and following. The current study follows up on those results using the same dataset in order to examine the effects of individual differences on the brain activations, in particular an individual’s expertise at a given role of the dance. The aim was to look for role-specific brain activations, in other words leading-related activations in trained leaders compared to non-leaders (i.e., followers), and following-related activations in trained followers compared to non-followers (i.e., leaders). Based on the literature cited above demonstrating that experts show enhancements in task-specific brain areas compared to non-experts when performing the same tasks, we predicted that leaders, as compared with non-leaders, would show an enhancement of leading-related activations when leading (only), and likewise that followers, as compared with non-followers, would show an enhancement of following-related activations when following (only). Given that we were not able to effectively rule out the influence of gender on dance role in our design, the results need to be viewed as exploratory. 


## Materials and Methods 
  
### Participants 
  
Eighteen participants (nine of each gender) took part in this study after giving their written informed consent in accordance with the Hamilton Integrated Research Ethics Board, who approved the study (St. Joseph’s Healthcare, R. P. #12-3777). They received monetary compensation for their participation. None of them had a past history of neurological or psychiatric disease. An inclusion criterion for the study was that participants have at least 2 years of experience at one or more kinds of couple dances involving leading and following (e.g., Argentine Tango, Salsa, Swing, and Ballroom). Male participants (40.7 ± 14.9 years old) had a mean dance experience of 8.7 ± 7.2 years, principally as leaders, although one male had significant experience as a follower as well. Female participants (40.2 ± 12.3 years old) had a mean dance experience of 5.6 ± 2.9 years, principally as followers, although two females had significant experience as leaders as well. 

On the day of the experiment, participants reported their ability to lead or follow a couple dance using a scale from 0 to 100, where 0 corresponds to no expertise at leading or following, and 100 corresponds to a very high level of expertise at leading or following. Each person did separate ratings for leading and following skill, with results shown in   Figure   . We explained to participants that these scales emphasized the ability to transmit/receive information while dancing with a partner, rather than the ability to perform complex or stylistic movements. Males reported a mean leading ability of 69.8 ± 17.7 (one male was at 35 and the rest ranged from 60 to 90). Likewise, females reported a mean following ability of 77.2 ± 8.3 (ranging from 70 to 90). With regards to the complementary skill, males reported a mean following ability of 33.7 ± 21.6; the male with significant following experience reported his following ability at 78, while all the others males rated it at between 8 and 50. Females reported a mean leading ability of 28.9 ± 25.2; both females with significant leading experience reported their leading ability at 70, while all other females rated themselves at between 5 and 40. Correlations between leading ability, following ability, years of experience at dancing, and age showed that leading ability, but not following ability, correlated with the number of years of experience (  Table   ). Anecdotal evidence suggests that leading skill requires a greater amount of time and effort to achieve than does following skill, which may explain the exclusive correlation of leading skill with years of experience. Since leading and following ability were not anti-correlated in the analysis, participants designated as “leaders” in this study were comprised of all the participants who were primarily trained as leaders for at least 2 years (i.e., all the of males) plus the two participants who, although primarily trained as followers, had significant leading experience and a strong leading ability (two females). Those designated as “followers” were comprised of all the participants who were primarily trained as followers for at least 2 years (i.e., all of the females) plus one participant who, although primarily trained as leader, had significant following experience and a strong following ability (one male). Thus, three participants belonged in both groups. This division was used in only the first set of analyses (see below). 
  
Self-report scales for skills as a leader and follower of couple dances. The   x  -axis shows the self-rating scale for leader skill (left panel) and follower skill (right panel) for couple dancing, where 100 is the highest rating. The   y  -axis of each graph shows the number of participants, from the pool of 18, who rated themselves at the various levels of skill for each role. Female participants are color-coded red and males are color-coded blue, both here and in   Figures  ,   . Participants designated as “leaders” in this study were comprised of all the males plus the two females with strong leading ability, while those designated as “followers” were comprised of all the females plus the male with strong following ability. Leaders are color coded as purple here and in   Figures  –  , whereas followers are color coded as pink here and in   Figures  –   (not to be confused with the color coding of gender). 
    
Correlation between age, years of couple-dance experience, and self-reported leading and following skill. 
    

### Procedure 
  
While the participant was lying supine in the MRI scanner, an experimenter (LASC) stood next to the bore of the scanner in order to have physical contact with the participant’s two hands. The participant’s forearms were fastened to the side of their body such that only their wrists, hands and fingers were able to move. Participants’ hands (palms up) were always below the experimenter’s hands (palms down), so that the participants’ hands could not be passively moved. The experimenter had significant experience both as a follower and a leader of couple dances. Together, the participant and experimenter performed highly controlled joint hand movements in all three planes of motion, alternating between leading and following the joint movement during different task-epochs of the scan. The movement patterns were improvised, rather than pre-learned, in order to maintain an ongoing requirement for motor planning during leading and a comparably heightened sense of responsiveness during following. No external cuing of tempo or rhythm was done with a metronome or with music. Participants performed all conditions with their eyes closed, and were instructed about which task to perform by means of pre-recorded verbal cues delivered through MRI-compatible headphones. Each condition was performed in a random order six times in blocks of 28 s. 

Complete methods and details concerning fMRI acquisition and image analysis, including participant training, are described in  . Briefly, the functional MRI imaging parameters were 2000 ms TR, 35 ms TE, 90° flip angle, 39 axial slices, 4 mm slice thickness, 0 mm gap, 3.75 × 3.75 mm in-plane resolution, 64 × 64 matrix, and 240 mm field of view. An automatic shimming procedure was performed before each scan to minimize inhomogeneities in the static magnetic field. For each of the three functional scans, 216 volumes–corresponding to 12 epochs of 28 s task + 8 s rest–were collected over 7’12”, resulting in a total of 648 volumes. Two magnetic field maps (5 ms then 8 ms TE) with the same imaging parameters as the fMRI were acquired in order to unwarp the data. Unwarping was performed with the relaxation method of “anatabacus”, a plugin in BrainVoyager, in order to correct for non-rigid deformations. In addition, the head-motion parameters were included as nuisance regressors in the analysis. Functional and structural images were processed using BrainVoyager QX 2.8. Coordinate tables were computed using NeuroElf. 


### Analysis 
  
We first performed qualitative analyses on three groups to assess if there were any differences between being a leader and being a follower. Specifically, we carried out three random-effects analyses for the bidirectional contrast “Leading versus Following” (1) for the whole group of 18 participants, (2) for the 11 leaders only, and (3) for the 10 followers only. These were performed at a two-tailed statistical threshold of   p   &lt; 0.005 uncorrected with a cluster-level correction of   k   = 28 voxels determined with Alphasim (family-wise error   p   &lt; 0.05) in NeuroElf. The conjunction of [Leading &gt; Rest] ∩ [Following &gt; Rest] was also performed on these three groups in order to serve as a reference for the general network of brain areas activated by the movement tasks, irrespective of role. It was performed at a two-tailed statistical threshold of   p   &lt; 0.005 uncorrected with a cluster-level correction of   k   = 49 voxels determined with Alphasim. 

Since qualitative differences were found (see Results section), we tested further for the effect of role by performing whole-brain regression analyses on the full group of participants (  n   = 18). We chose to perform statistical regression analyses instead of a direct statistical comparison between leaders and followers for two reasons. First, we consider role expertise to be a continuous trait, rather than a dichotomous one. Dancers can belong to both groups if they are trained at both leading and following. Thus a binary distinction would have led to a “male versus female” contrast, rather than a “leader versus follower” contrast. Second, the number of participants in each group was small (  n   = 10 and 11 for leaders and followers, respectively), whereas the regression involved the full group of 18 participants. Because of the small number of participants in the analysis and because of the small number of female leaders and male followers in the cohort, we consider this an exploratory study. Future studies will need to examine larger numbers of participants who have both leading and following skills, although such dual training tends to be limited to professional teachers of a dance. 

For the whole-brain regression analyses, the self-reported values of leading and following skill were used as covariates in two separate analyses to regress the betas values of the contrast “Leading versus Following”. These regressions were also performed at a two-tailed statistical threshold of   p   &lt; 0.005 uncorrected with a cluster-level correction of   k   = 25 voxels, determined with Alphasim. However, this threshold led to null results, and so we reported the activation at a less stringent threshold of   p   &lt; 0.025 uncorrected with a cluster-level correction of k = 46 voxels, determined with Alphasim. We note that these results should be interpreted with caution and need to be replicated in future analyses. In order to examine the influence of gender, the mean beta value of each activated cluster was extracted for each participant and regressed against his/her corresponding leading or following skill. 



## Results 
  
In order to identify the basic sensorimotor network involved in performing our joint bimanual tasks, we carried out the conjunction of [Leading &gt; Rest] ∩ [Following &gt; Rest], with results shown in   Figure    and Talairach coordinates reported in   Table   . This shared network between leading and following consisted of a widespread sensorimotor cortical (primary motor and somatosensory cortex) and subcortical (thalamus and cerebellum) network, as well as the supplementary motor area (SMA), midcingulate cortex (MCC), SPL, inferior frontal gyrus (IFG), IPL (including the secondary somatosensory cortex [SII] and extending to the insula), and inferior temporal gyrus (ITG), extending to the middle temporal gyrus (MTG). Except for the ITG, which was present in leaders only, this network was found in both leaders and followers. 
  
Shared network for leading and following. The figure shows the results of the conjunction [Leading &gt; Rest] ∩ [Following &gt; Rest] in leaders only (left panel) and followers only (right panel),   p   &lt; 0.005 uncorrected (  k   = 49 voxels). With the exception of the inferior temporal gyrus, the activated network is similar in both followers and leaders. CB, cerebellum; IFG, inferior frontal gyrus; IPL, inferior parietal lobule; ITG, inferior temporal gyrus; MCC, middle cingulate cortex; SMA, supplementary motor area; SMC, sensorimotor cortex; SPL, superior parietal lobule; and Th., thalamus. 
    
The shared network for leading and following. 
    
We next wanted to explore our question of interest, namely whether there was evidence for role-specific activations, in other words activations found only in skilled individuals while performing the role they are trained in. This would reveal whether leaders and followers engage different brain resources during leading and following. As shown in   Figure    and   Table   , we first qualitatively compared three types of analyses of the “Leading &gt; Following” contrast (cyan clusters) and “Following &gt; Leading” contrast (yellow clusters): the whole group of 18 participants; only the leaders (a subset of 11 participants); and only the followers (a subset of 10 participants). Overall, the leaders-only analysis showed basically the same network for leading as the whole group, but no brain areas for following. Likewise, the followers-only analysis showed basically the same network for following as the whole group, but only the dorsolateral prefrontal cortex (DLPFC) for leading (Note that only role-specific activations are labeled in the   Figure   ). 
  
Role-specific brain activations. The figure shows an analysis of the bidirectional “Leading versus Following” contrast in three groupings: the whole group of 18 participants; only the leaders (a subset of 11 participants); and only the followers (a subset of 10 participants). Contrasts are performed at   p   &lt; 0.005 uncorrected (  k   = 28 voxels). The top panel is the midsagittal view, the lower left panel is the left hemisphere, and the lower right panel is the right hemisphere. Each panel is set up as a triad, with the whole group at the top and the restricted analyses of leaders-only and followers-only below that. Cyan clusters and outlines reflect the contrast of “Leading &gt; Following”, whereas yellow clusters and outlines reflect the reverse contrast of “Following &gt; Leading”. In order to facilitate the visualization of role-specific activations, we use colored outlines to represent whole-group activations that are missing in either the leaders-only or the followers-only analyses. More specifically, cyan outlines are regions of whole-group activation that are present in the leaders-only analysis, but not the followers-only analysis, while yellow outlines are regions of whole-group activation that present in the followers-only analysis, but not the leaders-only analysis. The leaders-only analysis shows the same network for leading as the whole group, but no brain areas for following. The followers-only analysis shows the same network for following as the whole group, but only the cerebellum and dorsolateral prefrontal cortex for leading. Only role-specific activations are labeled in this figure. Leading network: CMA: cingulate motor area; PMC, premotor cortex; SMA, supplementary motor area; and SPL, superior parietal lobule. Following network: PCC, posterior cingulate cortex and TPJ, temporo-parietal junction. 
    
Leading versus following in the whole group, the leader-only group, and the follower-only group. 
    
Regarding the leading task, role-specific activations that were found exclusively in skilled leaders (cyan activations in   Figure    in both the leaders-only and whole-group brains that correspond with the cyan outlines in the followers-only brain) were observed in the SMA and cingulate motor area (CMA; top panel), SPL (right and left hemispheres in the lower panels), and PMC(left hemisphere). In addition, while leading, leaders showed a more extended premotor activation than the whole-group, especially in the right hemisphere (  Table   ). 

Regarding the following task, role-specific activations that were found exclusively in skilled followers (yellow activations in   Figure    in both the followers-only and whole-group brains that correspond with the yellow outlines in the leaders-only brain) were observed in the posterior cingulate cortex (PCC; top panel), temporo-parietal junction (TPJ; right and left hemispheres in the lower panels), and parahippocampal cortex (PHC, not shown). In addition, while following, followers showed activity in the posterior superior temporal sulcus (pSTS) that was not present in the whole group (  Table   ). To summarize, the networks associated with leading and following seemed to be more strongly engaged by experts at the corresponding role than non-experts at that role. 

We followed up on these qualitative analyses with whole-brain regressions in which the self-reported expertise at being a leader or follower (see   Figure    above) was used as the covariate for the contrast of leading versus following. Activations for these analyses were only found at a more lenient threshold, but are still reported since they are consistent with both our hypotheses and the qualitative analyses reported above. However, the results should be interpreted with caution.   Figure    shows the regressions with leader skill, and   Figure    shows the regressions with follower skill. The regions where activations during the leading task correlated with leader skill included the SMA, pre-SMA, dorsal PMC (dPMC), superior temporal gyrus (STG), and insula (  Figure    top panel,   Table   ). The regions where activations during the following task correlated with follower skill include the PCC, TPJ, pSTS, and mPFC (  Figure    top panel,   Table   ). For each cluster, the coefficient of determination (  R  ) of the regression of the mean beta value against leader and follower skill is shown in   Tables  ,   , respectively. 
  
Regression of brain activation with leader skill in the whole group of participants. The top panel of this figure shows brain activity that correlates with the contrasts “Leading &gt; Following” (cyan activations) and “Following &gt; Leading” (yellow activations). Contrasts are performed at   p   &lt; 0.02 uncorrected (  k   = 25 voxels). Brain areas for “Leading &gt; Following” that correlate with leader skill include the dorsal premotor cortex (dPMC), insula (Ins.), superior temporal gyrus (STG), and supplementary motor area (SMA). Almost no areas for the contrast “Following &gt; Leading” correlate with leader skill (see   Table   ). The lower plots show mean beta values extracted from the SMA, dPMC, posterior insula and STG against leader skill, where female participants are shown with red dots and male participants with blue dots. Activity for leading increased with increasing leader skill, and this seems to be independent of gender. 
    
Regression of brain activation with the follower skill in the whole group of participants. The top panel of this figure shows brain activity that correlates with the contrasts “Leading &gt; Following” (cyan activations) and “Following &gt; Leading” (yellow activations). Contrasts are performed at   p   &lt; 0.02 uncorrected (  k   = 25 voxels). Brain areas for “Following &gt; Leading” that correlate with follower skill include the medial prefrontal cortex (mPFC), posterior parietal cortex (PCC), posterior superior temporal sulcus (pSTS), and temporo-parietal junction (TPJ). No areas appeared for the contrast “Leading &gt; Following” correlate with follower skill (see   Table   ). The lower plots show mean beta values extracted from the TPJ, PCC, mPFC, and pSTS against follower skill, where female participants are shown with red dots and male participants with blue dots. Activity for following increased with increasing follower skill, and this seems to be independent of gender. 
    
Leading versus following correlated with skill as a leader. 
      
Leading versus following correlated with skill as a follower. 
    
Examples of how the mean beta value in these regions covaries with leader and follower skill are shown in the bottom panels of   Figures  ,   , respectively. The results provide some evidence that activity in these regions might depend on the level of expertise. However, they in no way rule out a gender effect, either alone or in interaction with expertise, and so the results have to be seen as preliminary. In the dPMC and STG (  Figure   , bottom panels), activity for the contrast of “Leading &gt; Following” increased with leader skill, but a male with low leader skill had a low activity, whereas females with high leader skill had a high activity. Other areas that correlated with leader skill had the same trend (not shown). Similarly, in the mPFC and TPJ (  Figure   , bottom panels), activity for the contrast “Leading &gt; Following” decreased with follower skill (that is, “Following &gt; Leading” activity increased with follower skill), but a male with high follower skill had a low activity, similar to females with high follower skill. Other areas that correlated with follower skill had the same trend (not shown). Future studies will be needed to fully exclude the influence of gender on the expertise effects observed here. Hence, the current study must be seen as a pilot study that gives a first glimpse at role-specific expertise effects without being able to effectively factor out the influence of gender. 


## Discussion 
  
This current exploratory study examined for the first time the effect of expertise at the coordinative skills involved in leading and following on brain activations during a joint-action task in a realistic setting. Its results provide support for the existence of role-specific brain activations during joint actions. In particular, we observed that leading-related activations were enhanced in leaders compared to followers when both groups performed the leading task, and that following-related activations were enhanced in followers compared to leaders when both groups performed the following task. Additionally, we showed that leading-related brain regions in the whole group of participants tended to correlate with expertise at being a leader, whereas following-related brain regions tended to correlate with expertise at being a follower. Another way of conceptualizing these results is that the skilled leaders hardly engaged any areas during following that were not already engaged during leading; likewise, the skilled followers hardly engaged any areas during leading that were not already engaged during following. This might explain the null results found in some previous studies when comparing following with leading ( ). These results suggest that expertise at one role of a joint-action task can enhance brain activations for the trained role compared to the untrained role. Hence, not only do the results support the existing literature on expertise effects for motor tasks, but they extend it for the first time to the contrastive roles of leader and follower in joint actions. 

The major finding of the initial qualitative analysis (  Figure   ) was that the brain networks that we observed for leading and following in the whole group seemed to be mainly supported by prior experience at being a leader or follower. In particular, skilled followers strongly engaged the mentalizing and social networks (PCC, TPJ, and STS) while following, which is consistent with a view of following as a process of adapting to one’s partner or as inferring knowledge from one’s partner ( ;  ;  ;  ;  ;  ). In contrast, skilled leaders strongly engaged networks for motor control and planning (SMA, CMA, PMC, and cerebellum) and for spatial navigation and exploration (SPL) while leading, which is consistent with the requirements of the leading role ( ;  ;  ;  ;  ). Interestingly, both skilled leaders and skilled followers activated the DLPFC during leading, which implies that self-initiation and action selection ( ;  ;  ) are probably the most important characteristics of leading, regardless of expertise. 

By performing whole-brain regressions with leading or following skill, we treated being a leader or follower as a continuous trait, rather than a dichotomous one. Although we did not find any activity using our   a priori   threshold, the activations observed at a more lenient threshold were consistent with both our hypotheses and the qualitative results, and are thus reported as exploratory findings. We observed that distinct brain areas tended to correlate with the level of self-reported expertise at being a leader or a follower, respectively. The areas that correlated with follower skill were principally components of the following network, such as the mPFC, PCC, TPJ, and pSTS. Thus, the more that someone is trained at following, the more that s/he will recruit brain regions of the mentalizing and social networks, which might indicate more attention to, or more efficient processing of, social stimuli (i.e., cues coming from the leader) and the mental states of others (i.e., their intentions and action plans). Another characteristic of followers is their ability to track their partner’s movements or other signaling cues so as to produce either imitative or complementary movements. Along these lines, the pSTS has been specifically implicated in the multisensory perception of biological motion ( ;  ), indicating that a trained follower might be specialized in analyzing information coming from the partner’s movement, not least haptic information emanating from body contact ( ). 

In contrast to this profile for following, the areas that tended to correlate with leader skill were mainly part of the leading network, including premotor areas (pre-SMA, SMA, and PMC). Other areas that tended to correlate with leader skill were the insula and STG. This network is quite similar to the one shown to be activated by motor experts in the meta-analysis of  . In addition, all of the areas associated with leader skill in the present study have been previously shown to be involved in improvisation ( ). Since leading requires the ability to improvise movements, we can assume that the better a person is at leading, the better s/he can improvise a motor plan for both the self and the partner, and thus the more s/he recruits premotor areas and the STG. However, it has also been shown that improvisational expertise (in musicians, for example) is related to a deactivation in the DLPFC, TPJ, IFG, and insula ( ;  ), which has been interpreted as indicating an automation of cognitive processing and a greater focus on internal processes during improvisation ( ). The absence of deactivations in these regions in our study can potentially be explained by the fact that our use of a joint task may have precluded the adoption of an internal focus by the participants when leading. Indeed, a study of joint improvisation also found an activation increase in the DLPFC, pre-SMA, and STG ( ), which is quite similar to a situation of improvising with a dance partner when leading. 

Overall, the study integrates two issues in the cognitive neuroscience of motor performance, first the contrast between leading and following, and second the influence of individual differences in motor expertise on brain activations. As mentioned in the Introduction, many experimental studies of joint action randomly assign people to being a leader or follower of a joint task ( ;  ;  ;  ;  ). However, in Western dance culture, people are generally assigned these roles based on their gender, with men tending to be assigned the role of leader in couple dances. Thus, in contrast to a study of piano duetting ( ), for example, people come to a dance study like ours with years of experience at just one role of the joint task. This provides us with the unique ability to examine individual differences in joint action based not on random factors but on role-specific training. Previous studies of expertise processing have demonstrated enhanced brain activations in experts compared to non-experts ( ,  ;  ,  ;  ;  ;  ;  ;  ;  ;  ). However, this has often has been investigated using non-motor tasks, even in motor experts like professional ballet dancers ( ). We have instead probed this using a motor task, with the added benefit of doing this using a joint-action task. The integration of these two issues is that we were able to examine the contrast between leading and following–as per studies of joint action–but to incorporate the factor of prior motor experience, as per studies of expertise processing. The results revealed a clear overlap between these two issues, such that the brain activations during the acts of leading and following were enhanced by prior expertise at being a leader or follower, and that activity in task-specific brain areas tended to be positively correlated with the level of expertise at the corresponding role. In other words, we were able to demonstrate   role-specific enhancements   in brain activation. 

### Limitations 
  
Given that this study was a first attempt to examine the effect of role expertise on brain activations during joint action, we are aware that it has a number of significant limitations. First, we were limited in our ability to measure behavioral performance during task production in the scanner due to an absence of MRI-compatible technologies such as motion capture at our imaging center. Thus, we cannot determine if the differences between leaders and followers seen in the study are due to trait-related differences in activation or behavioral differences as well. The joint-action task performed in this study was quite simple and involved very small hand movements. Hence, it did not require any type of specialized skill, which would foster similar performance in the two groups. In addition, the experimenter was the sole interaction partner for all of the participants in the study and was thus a controlled factor in the interaction. However, the absence of a technology like motion capture means that we are unable to rule out behavioral differences between participants as a source of the results. Further research taking advantage of MRI-compatible technologies will be required to explore this issue. 

Second, the qualitative analyses showed an interesting pattern that was confirmed by the whole-group regression at a more lenient threshold, but not at a standard threshold. Hence, the effects seem to be small. Although the observed activations at the less stringent threshold were consistent with our expectations based on previous studies, the results of this study should be taken with caution and need to be replicated, preferentially with a larger cohort and a wider spread of skill levels. In addition, the skill levels that were used to regress the brain data were self-report data. They might thus have been subject to self-report biases and inaccuracies. However, no objective measure of leadership and/or followership skills exists in the literature. Given the preliminary results of this study, it would be worthwhile to develop such measures in future. Such measures could be used to see if the results of the present study could be replicated based on people’s role expertise in some other motor skill outside of dancing, or even on people’s natural predispositions to be a leader or follower, as related to personality traits and life experiences, rather than the specialized skill of dance training. 

Finally, and importantly, we are unable to rule out gender as a factor in determining the role-specific effects in our study, and hence the results need to be seen as quite preliminary. While the leader and follower groups were not exclusively of one gender, they did have a majority of one gender. Given the evidence for gender effects on a diversity of perceptual, cognitive, and motor tasks ( ;  ;  ;  ;  ), further studies will be required to assess a gender contribution to our results with trained couple dancers. Given the paucity of female leaders and male followers in the world of couple dancing, perhaps the only approach that will be able to address the limitations of the current study is a training study. A study that crosses gender with role during a several-month training program of leading or following for some joint-action task could permit a disentangling of the relative effects of gender and expertise. If female leaders and male followers showed the same role-specific effects as in the current study, this would argue against a gender interpretation in favor of expertise   per se  . Such a study could also reveal potential gender effects as well. 



## Conclusion 
  
This study is the first to look at the influence of prior individual training at being a leader or follower on the brain activations occurring during the acts of leading and following, thereby assessing the effect of role expertise during naturalistic joint action. Our major finding was that leaders and followers do not seem approach leading and following in the same way at the neural level, with leaders engaging more brain resources during leading, and followers during following, thus reflecting role-specific activations. Additionally, we showed that activity in leading-related brain regions tended to correlate with expertise at being a leader, and likewise that activity in following-related brain regions tended to correlate with expertise at being a follower. These findings highlight the fact that the acts of leading and following might be skill-specific, and thus that prior experience at these roles should be assessed when studying leading and following during joint action. However, given our inability to disentangle gender from dance role, the current results must be seen as preliminary. A training study that crosses gender with role will probably be required to truly distinguish dance role from gender. 


## Author Contributions 
  
LC ran the experiment and analyzed the data. LC and SB conceived the experiment, analyzed the results, and wrote the manuscript. 


## Conflict of Interest Statement 
  
The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</pre></details></details>
  <details class="inner-accordion"><summary>Coordinate-relevant source tables (4)</summary><details class="inner-accordion"><summary>Table 2 (T2) - The shared network for leading and following.</summary><div class="table-html"><table-wrap id="T2" position="float" orientation="portrait"><label>Table 2</label><caption><p>The shared network for leading and following.</p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="center" colspan="5" rowspan="1">Leaders only (<italic toggle="yes">n</italic> = 11)</th><th valign="top" align="center" colspan="5" rowspan="1">Followers only (<italic toggle="yes">n</italic> = 10)</th></tr><tr><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" colspan="5" rowspan="1"><hr /></th><th valign="top" align="left" colspan="5" rowspan="1"><hr /></th></tr><tr><th valign="top" align="left" rowspan="1" colspan="1">Area</th><th valign="top" align="left" rowspan="1" colspan="1">BA</th><th valign="top" align="left" rowspan="1" colspan="1">Hemisphere</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">k</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Max</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">k</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Max</th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">SMC</td><td valign="top" align="left" rowspan="1" colspan="1">1,3,4,5,6,40</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">33</td><td valign="top" align="center" rowspan="1" colspan="1">-40</td><td valign="top" align="center" rowspan="1" colspan="1">58</td><td valign="top" align="center" rowspan="1" colspan="1">1356</td><td valign="top" align="center" rowspan="1" colspan="1">17.01</td><td valign="top" align="center" rowspan="1" colspan="1">30</td><td valign="top" align="center" rowspan="1" colspan="1">-37</td><td valign="top" align="center" rowspan="1" colspan="1">61</td><td valign="top" align="center" rowspan="1" colspan="1">1149</td><td valign="top" align="center" rowspan="1" colspan="1">16.54</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">SMC</td><td valign="top" align="left" rowspan="1" colspan="1">2,3,4,5,6,40</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-39</td><td valign="top" align="center" rowspan="1" colspan="1">-43</td><td valign="top" align="center" rowspan="1" colspan="1">52</td><td valign="top" align="center" rowspan="1" colspan="1">1419</td><td valign="top" align="center" rowspan="1" colspan="1">17.67</td><td valign="top" align="center" rowspan="1" colspan="1">-39</td><td valign="top" align="center" rowspan="1" colspan="1">-37</td><td valign="top" align="center" rowspan="1" colspan="1">55</td><td valign="top" align="center" rowspan="1" colspan="1">1135</td><td valign="top" align="center" rowspan="1" colspan="1">18.19</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">IFG</td><td valign="top" align="left" rowspan="1" colspan="1">6,13,44</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">54</td><td valign="top" align="center" rowspan="1" colspan="1">2</td><td valign="top" align="center" rowspan="1" colspan="1">19</td><td valign="top" align="center" rowspan="1" colspan="1">174</td><td valign="top" align="center" rowspan="1" colspan="1">5.86</td><td valign="top" align="center" rowspan="1" colspan="1">54</td><td valign="top" align="center" rowspan="1" colspan="1">8</td><td valign="top" align="center" rowspan="1" colspan="1">7</td><td valign="top" align="center" rowspan="1" colspan="1">108</td><td valign="top" align="center" rowspan="1" colspan="1">8.05</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">SMA/MCC</td><td valign="top" align="left" rowspan="1" colspan="1">6, 24, 31</td><td valign="top" align="left" rowspan="1" colspan="1">RH/LH</td><td valign="top" align="center" rowspan="1" colspan="1">3</td><td valign="top" align="center" rowspan="1" colspan="1">-13</td><td valign="top" align="center" rowspan="1" colspan="1">52</td><td valign="top" align="center" rowspan="1" colspan="1">610</td><td valign="top" align="center" rowspan="1" colspan="1">14.68</td><td valign="top" align="center" rowspan="1" colspan="1">0</td><td valign="top" align="center" rowspan="1" colspan="1">-22</td><td valign="top" align="center" rowspan="1" colspan="1">49</td><td valign="top" align="center" rowspan="1" colspan="1">683</td><td valign="top" align="center" rowspan="1" colspan="1">12.14</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">IPL/SII</td><td valign="top" align="left" rowspan="1" colspan="1">13,40,41</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">48</td><td valign="top" align="center" rowspan="1" colspan="1">-28</td><td valign="top" align="center" rowspan="1" colspan="1">25</td><td valign="top" align="center" rowspan="1" colspan="1">294</td><td valign="top" align="center" rowspan="1" colspan="1">7.26</td><td valign="top" align="center" rowspan="1" colspan="1">45</td><td valign="top" align="center" rowspan="1" colspan="1">-34</td><td valign="top" align="center" rowspan="1" colspan="1">31</td><td valign="top" align="center" rowspan="1" colspan="1">108</td><td valign="top" align="center" rowspan="1" colspan="1">6.82</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">IPL/SII</td><td valign="top" align="left" rowspan="1" colspan="1">13, 22,40</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-51</td><td valign="top" align="center" rowspan="1" colspan="1">-28</td><td valign="top" align="center" rowspan="1" colspan="1">19</td><td valign="top" align="center" rowspan="1" colspan="1">240</td><td valign="top" align="center" rowspan="1" colspan="1">9.52</td><td valign="top" align="center" rowspan="1" colspan="1">-48</td><td valign="top" align="center" rowspan="1" colspan="1">-34</td><td valign="top" align="center" rowspan="1" colspan="1">19</td><td valign="top" align="center" rowspan="1" colspan="1">314</td><td valign="top" align="center" rowspan="1" colspan="1">9.36</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">SPL</td><td valign="top" align="left" rowspan="1" colspan="1">7</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">24</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">58</td><td valign="top" align="center" rowspan="1" colspan="1">197</td><td valign="top" align="center" rowspan="1" colspan="1">7.06</td><td valign="top" align="center" rowspan="1" colspan="1">24</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">55</td><td valign="top" align="center" rowspan="1" colspan="1">166</td><td valign="top" align="center" rowspan="1" colspan="1">6.52</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">SPL</td><td valign="top" align="left" rowspan="1" colspan="1">7</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-24</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">58</td><td valign="top" align="center" rowspan="1" colspan="1">453</td><td valign="top" align="center" rowspan="1" colspan="1">10.52</td><td valign="top" align="center" rowspan="1" colspan="1">-27</td><td valign="top" align="center" rowspan="1" colspan="1">-55</td><td valign="top" align="center" rowspan="1" colspan="1">58</td><td valign="top" align="center" rowspan="1" colspan="1">268</td><td valign="top" align="center" rowspan="1" colspan="1">9.76</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">ITG</td><td valign="top" align="left" rowspan="1" colspan="1">37</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">51</td><td valign="top" align="center" rowspan="1" colspan="1">-58</td><td valign="top" align="center" rowspan="1" colspan="1">-8</td><td valign="top" align="center" rowspan="1" colspan="1">117</td><td valign="top" align="center" rowspan="1" colspan="1">6.45</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">ITG</td><td valign="top" align="left" rowspan="1" colspan="1">19, 37</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-48</td><td valign="top" align="center" rowspan="1" colspan="1">-58</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">93</td><td valign="top" align="center" rowspan="1" colspan="1">6.30</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Thalamus</td><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">15</td><td valign="top" align="center" rowspan="1" colspan="1">-25</td><td valign="top" align="center" rowspan="1" colspan="1">10</td><td valign="top" align="center" rowspan="1" colspan="1">105</td><td valign="top" align="center" rowspan="1" colspan="1">7.03</td><td valign="top" align="center" rowspan="1" colspan="1">0</td><td valign="top" align="center" rowspan="1" colspan="1">-16</td><td valign="top" align="center" rowspan="1" colspan="1">16</td><td valign="top" align="center" rowspan="1" colspan="1">49</td><td valign="top" align="center" rowspan="1" colspan="1">6.73</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Thalamus</td><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-15</td><td valign="top" align="center" rowspan="1" colspan="1">-19</td><td valign="top" align="center" rowspan="1" colspan="1">10</td><td valign="top" align="center" rowspan="1" colspan="1">139</td><td valign="top" align="center" rowspan="1" colspan="1">7.41</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Cerebellum</td><td valign="top" align="left" rowspan="1" colspan="1">Vermis</td><td valign="top" align="left" rowspan="1" colspan="1">RH/LH</td><td valign="top" align="center" rowspan="1" colspan="1">-3</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">-17</td><td valign="top" align="center" rowspan="1" colspan="1">308</td><td valign="top" align="center" rowspan="1" colspan="1">10.74</td><td valign="top" align="center" rowspan="1" colspan="1">3</td><td valign="top" align="center" rowspan="1" colspan="1">-58</td><td valign="top" align="center" rowspan="1" colspan="1">-14</td><td valign="top" align="center" rowspan="1" colspan="1">163</td><td valign="top" align="center" rowspan="1" colspan="1">7.72</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Cerebellum</td><td valign="top" align="left" rowspan="1" colspan="1">Culmen/Declive</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">15</td><td valign="top" align="center" rowspan="1" colspan="1">-49</td><td valign="top" align="center" rowspan="1" colspan="1">-17</td><td valign="top" align="center" rowspan="1" colspan="1">164</td><td valign="top" align="center" rowspan="1" colspan="1">9.53</td><td valign="top" align="center" rowspan="1" colspan="1">12</td><td valign="top" align="center" rowspan="1" colspan="1">-46</td><td valign="top" align="center" rowspan="1" colspan="1">-17</td><td valign="top" align="center" rowspan="1" colspan="1">104</td><td valign="top" align="center" rowspan="1" colspan="1">6.19</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Cerebellum</td><td valign="top" align="left" rowspan="1" colspan="1">Culmen/Declive</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-21</td><td valign="top" align="center" rowspan="1" colspan="1">-49</td><td valign="top" align="center" rowspan="1" colspan="1">-20</td><td valign="top" align="center" rowspan="1" colspan="1">140</td><td valign="top" align="center" rowspan="1" colspan="1">10.20</td><td valign="top" align="center" rowspan="1" colspan="1">-15</td><td valign="top" align="center" rowspan="1" colspan="1">-52</td><td valign="top" align="center" rowspan="1" colspan="1">-17</td><td valign="top" align="center" rowspan="1" colspan="1">144</td><td valign="top" align="center" rowspan="1" colspan="1">8.87</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Cerebellum</td><td valign="top" align="left" rowspan="1" colspan="1">Tuber/Declive</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">42</td><td valign="top" align="center" rowspan="1" colspan="1">-58</td><td valign="top" align="center" rowspan="1" colspan="1">-23</td><td valign="top" align="center" rowspan="1" colspan="1">94</td><td valign="top" align="center" rowspan="1" colspan="1">7.03</td><td valign="top" align="center" rowspan="1" colspan="1">45</td><td valign="top" align="center" rowspan="1" colspan="1">-58</td><td valign="top" align="center" rowspan="1" colspan="1">-20</td><td valign="top" align="center" rowspan="1" colspan="1">156</td><td valign="top" align="center" rowspan="1" colspan="1">7.86</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /></tr></tbody></table><table-wrap-foot><attrib><italic toggle="yes">Talairach coordinates for the conjunction of Leading and Following compared to rest (<italic toggle="yes">p</italic> &gt; 0.005 uncorrected, <italic toggle="yes">k</italic> = 49 voxels). IFG, inferior frontal gyrus; IPL, inferior parietal lobule; ITG, inferior temporal gyrus; SII, secondary somatosensory cortex; SMA, supplementary motor area; SMC, sensorimotor cortex; and SPL, superior parietal lobule.</italic></attrib></table-wrap-foot></table-wrap></div></details><details class="inner-accordion"><summary>Table 3 (T3) - Leading versus following in the whole group, the leader-only group, and the follower-only group.</summary><div class="table-html"><table-wrap id="T3" position="float" orientation="portrait"><label>Table 3</label><caption><p>Leading versus following in the whole group, the leader-only group, and the follower-only group.</p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="center" colspan="5" rowspan="1">Whole-group (<italic toggle="yes">n</italic> = 18)</th><th valign="top" align="center" colspan="5" rowspan="1">Leaders only (<italic toggle="yes">n</italic> = 11)</th><th valign="top" align="center" colspan="5" rowspan="1">Followers only (<italic toggle="yes">n</italic> = 10)</th></tr><tr><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" colspan="5" rowspan="1"><hr /></th><th valign="top" align="left" colspan="5" rowspan="1"><hr /></th><th valign="top" align="left" colspan="5" rowspan="1"><hr /></th></tr><tr><th valign="top" align="left" rowspan="1" colspan="1">Area</th><th valign="top" align="center" rowspan="1" colspan="1">BA</th><th valign="top" align="left" rowspan="1" colspan="1">Hemisphere</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">k</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Max</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">k</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Max</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">k</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Max</th></tr></thead><tbody><tr><td valign="top" align="left" colspan="2" rowspan="1"><bold>Activations: Leading &gt; Following</bold></td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   pre-SMA</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="left" rowspan="1" colspan="1">RH/LH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">3</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">58</td><td valign="top" align="center" rowspan="1" colspan="1">29</td><td valign="top" align="center" rowspan="1" colspan="1">5.24</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   SMA</td><td valign="top" align="center" rowspan="1" colspan="1">4,6</td><td valign="top" align="left" rowspan="1" colspan="1">RH/LH</td><td valign="top" align="center" rowspan="1" colspan="1">-4</td><td valign="top" align="center" rowspan="1" colspan="1">-4</td><td valign="top" align="center" rowspan="1" colspan="1">59</td><td valign="top" align="center" rowspan="1" colspan="1">81</td><td valign="top" align="center" rowspan="1" colspan="1">5.97</td><td valign="top" align="center" rowspan="1" colspan="1">-3</td><td valign="top" align="center" rowspan="1" colspan="1">-13</td><td valign="top" align="center" rowspan="1" colspan="1">64</td><td valign="top" align="center" rowspan="1" colspan="1">109</td><td valign="top" align="center" rowspan="1" colspan="1">6.28</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   CMA</td><td valign="top" align="center" rowspan="1" colspan="1">24</td><td valign="top" align="left" rowspan="1" colspan="1">RH/LH</td><td valign="top" align="center" rowspan="1" colspan="1">-6</td><td valign="top" align="center" rowspan="1" colspan="1">8</td><td valign="top" align="center" rowspan="1" colspan="1">37</td><td valign="top" align="center" rowspan="1" colspan="1">47</td><td valign="top" align="center" rowspan="1" colspan="1">4.84</td><td valign="top" align="center" rowspan="1" colspan="1">0</td><td valign="top" align="center" rowspan="1" colspan="1">2</td><td valign="top" align="center" rowspan="1" colspan="1">40</td><td valign="top" align="center" rowspan="1" colspan="1">85</td><td valign="top" align="center" rowspan="1" colspan="1">8.41</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   PMC</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">21</td><td valign="top" align="center" rowspan="1" colspan="1">-4</td><td valign="top" align="center" rowspan="1" colspan="1">55</td><td valign="top" align="center" rowspan="1" colspan="1">145</td><td valign="top" align="center" rowspan="1" colspan="1">8.01</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   PMC</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-26</td><td valign="top" align="center" rowspan="1" colspan="1">-13</td><td valign="top" align="center" rowspan="1" colspan="1">54</td><td valign="top" align="center" rowspan="1" colspan="1">51</td><td valign="top" align="center" rowspan="1" colspan="1">4.36</td><td valign="top" align="center" rowspan="1" colspan="1">-30</td><td valign="top" align="center" rowspan="1" colspan="1">-16</td><td valign="top" align="center" rowspan="1" colspan="1">64</td><td valign="top" align="center" rowspan="1" colspan="1">32</td><td valign="top" align="center" rowspan="1" colspan="1">5.71</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   DLPFC</td><td valign="top" align="center" rowspan="1" colspan="1">8,9</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-40</td><td valign="top" align="center" rowspan="1" colspan="1">29</td><td valign="top" align="center" rowspan="1" colspan="1">38</td><td valign="top" align="center" rowspan="1" colspan="1">98</td><td valign="top" align="center" rowspan="1" colspan="1">7.35</td><td valign="top" align="center" rowspan="1" colspan="1">-48</td><td valign="top" align="center" rowspan="1" colspan="1">32</td><td valign="top" align="center" rowspan="1" colspan="1">31</td><td valign="top" align="center" rowspan="1" colspan="1">46</td><td valign="top" align="center" rowspan="1" colspan="1">5.84</td><td valign="top" align="center" rowspan="1" colspan="1">-39</td><td valign="top" align="center" rowspan="1" colspan="1">44</td><td valign="top" align="center" rowspan="1" colspan="1">34</td><td valign="top" align="center" rowspan="1" colspan="1">76</td><td valign="top" align="center" rowspan="1" colspan="1">7.08</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   DLPFC</td><td valign="top" align="center" rowspan="1" colspan="1">9</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">-36</td><td valign="top" align="center" rowspan="1" colspan="1">23</td><td valign="top" align="center" rowspan="1" colspan="1">25</td><td valign="top" align="center" rowspan="1" colspan="1">30</td><td valign="top" align="center" rowspan="1" colspan="1">6.91</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   SPL</td><td valign="top" align="center" rowspan="1" colspan="1">7</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="center" rowspan="1" colspan="1">-73</td><td valign="top" align="center" rowspan="1" colspan="1">42</td><td valign="top" align="center" rowspan="1" colspan="1">70</td><td valign="top" align="center" rowspan="1" colspan="1">6.39</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="center" rowspan="1" colspan="1">-73</td><td valign="top" align="center" rowspan="1" colspan="1">49</td><td valign="top" align="center" rowspan="1" colspan="1">47</td><td valign="top" align="center" rowspan="1" colspan="1">7.56</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   SPL</td><td valign="top" align="center" rowspan="1" colspan="1">7</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-16</td><td valign="top" align="center" rowspan="1" colspan="1">-73</td><td valign="top" align="center" rowspan="1" colspan="1">36</td><td valign="top" align="center" rowspan="1" colspan="1">84</td><td valign="top" align="center" rowspan="1" colspan="1">5.44</td><td valign="top" align="center" rowspan="1" colspan="1">-18</td><td valign="top" align="center" rowspan="1" colspan="1">-79</td><td valign="top" align="center" rowspan="1" colspan="1">43</td><td valign="top" align="center" rowspan="1" colspan="1">48</td><td valign="top" align="center" rowspan="1" colspan="1">6.34</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   Cerebellum</td><td valign="top" align="center" rowspan="1" colspan="1">Tuber</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">47</td><td valign="top" align="center" rowspan="1" colspan="1">-65</td><td valign="top" align="center" rowspan="1" colspan="1">-17</td><td valign="top" align="center" rowspan="1" colspan="1">37</td><td valign="top" align="center" rowspan="1" colspan="1">5.00</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" colspan="2" rowspan="1"><bold>Deactivations: Following &gt; Leading</bold></td><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   PCC</td><td valign="top" align="center" rowspan="1" colspan="1">7,31</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">3</td><td valign="top" align="center" rowspan="1" colspan="1">-54</td><td valign="top" align="center" rowspan="1" colspan="1">23</td><td valign="top" align="center" rowspan="1" colspan="1">129</td><td valign="top" align="center" rowspan="1" colspan="1">-5.36</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">3</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">31</td><td valign="top" align="center" rowspan="1" colspan="1">92</td><td valign="top" align="center" rowspan="1" colspan="1">-11.12</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   TPJ</td><td valign="top" align="center" rowspan="1" colspan="1">39,40</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">45</td><td valign="top" align="center" rowspan="1" colspan="1">-59</td><td valign="top" align="center" rowspan="1" colspan="1">25</td><td valign="top" align="center" rowspan="1" colspan="1">28</td><td valign="top" align="center" rowspan="1" colspan="1">-5.33</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">48</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">31</td><td valign="top" align="center" rowspan="1" colspan="1">89</td><td valign="top" align="center" rowspan="1" colspan="1">-8.86</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   TPJ</td><td valign="top" align="center" rowspan="1" colspan="1">39,40</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-53</td><td valign="top" align="center" rowspan="1" colspan="1">-63</td><td valign="top" align="center" rowspan="1" colspan="1">23</td><td valign="top" align="center" rowspan="1" colspan="1">105</td><td valign="top" align="center" rowspan="1" colspan="1">-5.70</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   STS</td><td valign="top" align="center" rowspan="1" colspan="1">19,39</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">48</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">16</td><td valign="top" align="center" rowspan="1" colspan="1">92</td><td valign="top" align="center" rowspan="1" colspan="1">-10.18</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   STS</td><td valign="top" align="center" rowspan="1" colspan="1">37,39</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">-51</td><td valign="top" align="center" rowspan="1" colspan="1">-52</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">66</td><td valign="top" align="center" rowspan="1" colspan="1">-5.94</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   aSTG</td><td valign="top" align="center" rowspan="1" colspan="1">13,22</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">57</td><td valign="top" align="center" rowspan="1" colspan="1">-16</td><td valign="top" align="center" rowspan="1" colspan="1">-2</td><td valign="top" align="center" rowspan="1" colspan="1">72</td><td valign="top" align="center" rowspan="1" colspan="1">-9.70</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   Temporal pole</td><td valign="top" align="center" rowspan="1" colspan="1">38</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">-48</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">-23</td><td valign="top" align="center" rowspan="1" colspan="1">30</td><td valign="top" align="center" rowspan="1" colspan="1">-8.09</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   PHC</td><td valign="top" align="center" rowspan="1" colspan="1">30,36</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">17</td><td valign="top" align="center" rowspan="1" colspan="1">-33</td><td valign="top" align="center" rowspan="1" colspan="1">0</td><td valign="top" align="center" rowspan="1" colspan="1">39</td><td valign="top" align="center" rowspan="1" colspan="1">-4.72</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">42</td><td valign="top" align="center" rowspan="1" colspan="1">-40</td><td valign="top" align="center" rowspan="1" colspan="1">1</td><td valign="top" align="center" rowspan="1" colspan="1">28</td><td valign="top" align="center" rowspan="1" colspan="1">-6.13</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   PHC</td><td valign="top" align="center" rowspan="1" colspan="1">28</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-21</td><td valign="top" align="center" rowspan="1" colspan="1">-16</td><td valign="top" align="center" rowspan="1" colspan="1">-6</td><td valign="top" align="center" rowspan="1" colspan="1">103</td><td valign="top" align="center" rowspan="1" colspan="1">-5.76</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">-30</td><td valign="top" align="center" rowspan="1" colspan="1">-22</td><td valign="top" align="center" rowspan="1" colspan="1">-11</td><td valign="top" align="center" rowspan="1" colspan="1">67</td><td valign="top" align="center" rowspan="1" colspan="1">-7.52</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">   Thalamus</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1">21</td><td valign="top" align="center" rowspan="1" colspan="1">-25</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">59</td><td valign="top" align="center" rowspan="1" colspan="1">-6.72</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /></tr></tbody></table><table-wrap-foot><attrib><italic toggle="yes">Talairach coordinates for the contrast “Leading versus Following” in the whole group, leaders only, and followers only (<italic toggle="yes">p</italic> &gt; 0.005 uncorrected, <italic toggle="yes">k</italic> = 28 voxels). aSTG, anterior superior temporal gyrus; CMA, cingulate motor area; DLPFC, dorsolateral prefrontal cortex; PCC, posterior cingulate cortex; PHC, parahippocampal cortex; PMC, premotor cortex; SMA, supplementary motor area; SPL, superior parietal lobule; STS, superior temporal sulcus; and TPJ, temporo-parietal junction.</italic></attrib></table-wrap-foot></table-wrap></div></details><details class="inner-accordion"><summary>Table 4 (T4) - Leading versus following correlated with skill as a leader.</summary><div class="table-html"><table-wrap id="T4" position="float" orientation="portrait"><label>Table 4</label><caption><p>Leading versus following correlated with skill as a leader.</p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><thead><tr><td valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1">Area</th><th valign="top" align="center" rowspan="1" colspan="1">BA</th><th valign="top" align="left" rowspan="1" colspan="1">Hemisphere</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">k</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Max</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">R</italic><sup>2</sup></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Activation</bold></td><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">pre-SMA</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="center" rowspan="1" colspan="1">8</td><td valign="top" align="center" rowspan="1" colspan="1">58</td><td valign="top" align="center" rowspan="1" colspan="1">55</td><td valign="top" align="center" rowspan="1" colspan="1">0.73</td><td valign="top" align="center" rowspan="1" colspan="1">0.37</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">SMA</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">12</td><td valign="top" align="center" rowspan="1" colspan="1">-7</td><td valign="top" align="center" rowspan="1" colspan="1">55</td><td valign="top" align="center" rowspan="1" colspan="1">184</td><td valign="top" align="center" rowspan="1" colspan="1">0.81</td><td valign="top" align="center" rowspan="1" colspan="1">0.46</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">dPMC</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">36</td><td valign="top" align="center" rowspan="1" colspan="1">-1</td><td valign="top" align="center" rowspan="1" colspan="1">37</td><td valign="top" align="center" rowspan="1" colspan="1">46</td><td valign="top" align="center" rowspan="1" colspan="1">0.66</td><td valign="top" align="center" rowspan="1" colspan="1">0.49</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">Insula</td><td valign="top" align="center" rowspan="1" colspan="1">13</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">33</td><td valign="top" align="center" rowspan="1" colspan="1">-25</td><td valign="top" align="center" rowspan="1" colspan="1">28</td><td valign="top" align="center" rowspan="1" colspan="1">101</td><td valign="top" align="center" rowspan="1" colspan="1">0.71</td><td valign="top" align="center" rowspan="1" colspan="1">0.50</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">STG</td><td valign="top" align="center" rowspan="1" colspan="1">41,22</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">54</td><td valign="top" align="center" rowspan="1" colspan="1">-28</td><td valign="top" align="center" rowspan="1" colspan="1">10</td><td valign="top" align="center" rowspan="1" colspan="1">62</td><td valign="top" align="center" rowspan="1" colspan="1">0.66</td><td valign="top" align="center" rowspan="1" colspan="1">0.48</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Deactivation</bold></td><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">Cingulate</td><td valign="top" align="center" rowspan="1" colspan="1">13,13</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-21</td><td valign="top" align="center" rowspan="1" colspan="1">-34</td><td valign="top" align="center" rowspan="1" colspan="1">28</td><td valign="top" align="center" rowspan="1" colspan="1">87</td><td valign="top" align="center" rowspan="1" colspan="1">-0.74</td><td valign="top" align="center" rowspan="1" colspan="1">0.37</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">Lingual</td><td valign="top" align="center" rowspan="1" colspan="1">19</td><td valign="top" align="left" rowspan="1" colspan="1">LH</td><td valign="top" align="center" rowspan="1" colspan="1">-33</td><td valign="top" align="center" rowspan="1" colspan="1">-58</td><td valign="top" align="center" rowspan="1" colspan="1">-2</td><td valign="top" align="center" rowspan="1" colspan="1">46</td><td valign="top" align="center" rowspan="1" colspan="1">-0.72</td><td valign="top" align="center" rowspan="1" colspan="1">0.30</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /></tr></tbody></table><table-wrap-foot><attrib><italic toggle="yes">Talairach coordinates for the contrast “Leading versus Following” in the whole group correlated with the covariate “leader skill” (<italic toggle="yes">p</italic> &gt; 0.025 uncorrected, <italic toggle="yes">k</italic> = 46 voxels). <italic toggle="yes">R</italic><sup>2</sup> is the coefficient of determination of the regression of the cluster’s mean beta value against leader skill. dPMC, dorsal premotor cortex; SMA, supplementary motor area; and STG, superior temporal cortex.</italic></attrib></table-wrap-foot></table-wrap></div></details><details class="inner-accordion"><summary>Table 5 (T5) - Leading versus following correlated with skill as a follower.</summary><div class="table-html"><table-wrap id="T5" position="float" orientation="portrait"><label>Table 5</label><caption><p>Leading versus following correlated with skill as a follower.</p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><thead><tr><td valign="top" align="left" rowspan="1" colspan="1" /><th valign="top" align="left" rowspan="1" colspan="1">Area</th><th valign="top" align="center" rowspan="1" colspan="1">BA</th><th valign="top" align="left" rowspan="1" colspan="1">Hemisphere</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">x</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">y</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">z</italic></th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">k</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Max</th><th valign="top" align="center" rowspan="1" colspan="1"><italic toggle="yes">R</italic><sup>2</sup></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Activation</bold></td><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /><td valign="top" align="center" rowspan="1" colspan="1" /></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Deactivation</bold></td><td valign="top" align="left" rowspan="1" colspan="1">PCC</td><td valign="top" align="center" rowspan="1" colspan="1">7,31</td><td valign="top" align="left" rowspan="1" colspan="1">RH/LH</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="center" rowspan="1" colspan="1">-55</td><td valign="top" align="center" rowspan="1" colspan="1">37</td><td valign="top" align="center" rowspan="1" colspan="1">78</td><td valign="top" align="center" rowspan="1" colspan="1">-0.75</td><td valign="top" align="center" rowspan="1" colspan="1">0.30</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">mPFC</td><td valign="top" align="center" rowspan="1" colspan="1">9,10</td><td valign="top" align="left" rowspan="1" colspan="1">RH/LH</td><td valign="top" align="center" rowspan="1" colspan="1">6</td><td valign="top" align="center" rowspan="1" colspan="1">47</td><td valign="top" align="center" rowspan="1" colspan="1">22</td><td valign="top" align="center" rowspan="1" colspan="1">64</td><td valign="top" align="center" rowspan="1" colspan="1">-0.73</td><td valign="top" align="center" rowspan="1" colspan="1">0.27</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">pSTS</td><td valign="top" align="center" rowspan="1" colspan="1">19,39</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">42</td><td valign="top" align="center" rowspan="1" colspan="1">-61</td><td valign="top" align="center" rowspan="1" colspan="1">13</td><td valign="top" align="center" rowspan="1" colspan="1">90</td><td valign="top" align="center" rowspan="1" colspan="1">-0.75</td><td valign="top" align="center" rowspan="1" colspan="1">0.61</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /><td valign="top" align="left" rowspan="1" colspan="1">TPJ</td><td valign="top" align="center" rowspan="1" colspan="1">39,40</td><td valign="top" align="left" rowspan="1" colspan="1">RH</td><td valign="top" align="center" rowspan="1" colspan="1">48</td><td valign="top" align="center" rowspan="1" colspan="1">-52</td><td valign="top" align="center" rowspan="1" colspan="1">43</td><td valign="top" align="center" rowspan="1" colspan="1">72</td><td valign="top" align="center" rowspan="1" colspan="1">-0.72</td><td valign="top" align="center" rowspan="1" colspan="1">0.48</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" /></tr></tbody></table><table-wrap-foot><attrib><italic toggle="yes">Talairach coordinates for the contrast “Leading versus Following” in the whole group correlated with the covariate “follower skill” (<italic toggle="yes">p</italic> &gt; 0.025 uncorrected, <italic toggle="yes">k</italic> = 46 voxels). <italic toggle="yes">R</italic><sup>2</sup> is the coefficient of determination of the regression of the cluster’s mean beta value against follower skill. mPFC, medial prefrontal cortex; PCC, posterior cingulate cortex; pSTS, superior temporal sulcus; and TPJ, temporo-parietal junction.</italic></attrib></table-wrap-foot></table-wrap></div></details></details>
</details>


<details class="doc-card">
  <summary><strong>PMID 31142792</strong> | Pred included: 2 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/31142792/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>31142792_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Increased responses to faces before treatment&quot;.</td></tr>
<tr><td>31142792_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Decreased responses to faces before treatment&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <p>No manual-to-auto match diagnostics for this document.</p>
  </details>
  <details class="inner-accordion"><summary>PMC full text available (PMCID 6541618)</summary><p><strong>Title:</strong> Behavioural and Neural Responses to Facial Disfigurement</p><details><summary>Abstract</summary><pre class="paper-text">Faces are among the most salient and relevant visual and social stimuli that humans encounter. Attractive faces are associated with positive character traits and social skills and automatically evoke larger neural responses than faces of average attractiveness in ventral occipito-temporal cortical areas. Little is known about the behavioral and neural responses to disfigured faces. In two experiments, we tested the hypotheses that people harbor a disfigured is bad bias and that ventral visual neural responses, known to be amplified to attractive faces, represent an attentional effect to facial salience rather than to their rewarding properties. In our behavioral study (N = 79), we confirmed the existence of an implicit ‘  disfigured is bad  ’ bias. In our functional MRI experiment (N = 31), neural responses to photographs of disfigured faces before treatment evoked greater neural responses within ventral occipito-temporal cortex and diminished responses within anterior cingulate cortex. The occipito-temporal activity supports the hypothesis that these areas are sensitive to attentional, rather than reward properties of faces. The relative deactivation in anterior cingulate cortex, informed by our behavioral study, may reflect suppressed empathy and social cognition and indicate evidence of a possible neural mechanism underlying dehumanization.</pre></details><details><summary>Body</summary><pre class="paper-text">## Introduction 
  
Physical appearance has a profound impact on a person’s life. Beautiful people are preferred and enjoy many advantages compared to average-looking people . While conceptually orthogonal, the correlation of attractiveness and positive character traits indicates the prevalence of a ‘beautiful is good’ stereotype . This stereotype might be innate . Attractive people are seen as more trustworthy, socially competent, dominant, better adjusted, more capable in school and work, and also receive greater rewards and lesser punishments than their average looking peers . Adults and children ascribe desirable personality traits to attractive faces of adults and children and discriminate against unattractive faces even if they are friends and family members . Attractiveness and trustworthiness judgments are consistent across cultures  and are made extremely quickly . Longer exposure to a face does not attenuate these biases and instead only consolidates people’s confidence in a judgement already made . Attractiveness also highly influences visual exploration of faces . 

In this study we examine a corollary to the ‘beautiful is good’ stereotype, that an automatic ‘disfigured is bad’ stereotype also exists. People with facial disfigurement are stigmatized and are often targets of discrimination. Looking at disfigured faces makes observers feel less happy, less in control, less dominant, and more aroused . People with facial disfigurements are not only perceived as less attractive and less likely to be selected as romantic partners, they are also thought of as having unfavourable personality traits (e.g., lack of emotional stability, conscientiousness), internal attributes (e.g., unhappiness, lower intelligence), social qualities (e.g., untrustworthiness, unpopularity)  and are treated poorly in social interactions . In popular culture, facial disfigurement is often used to distinguish good and evil characters . Well known examples of disfigured villains are Scar in the   Lion King   (large facial scar over left eye), Freddy Krueger in   Nightmare on Elm Street   (3rd degree burns and exposed tissue), the   James Bond   villains Le Chiffre (facial scar over left eye), Emilio Largo (missing eye), Ernst Stavro Blofeld (large scar over right eye covering most of his right side of the face), and Alec Trevelyan (facial burn scars), Elle Driver in   Kill Bill   (missing eye), Two Face in the   Batman   Universe (acid scars covering the left side of his head), Hopper in   A Bug’s Life   (scar covering right eye), and the Duchess from   Alice in a Wonderland   (Macrocephaly). This ‘disfigurement is bad’ stereotype is only partially explained by lower attractiveness of disfigured faces . 

Attractiveness of faces –and therefore attribution of a’beauty is good’ stereotype- is highly correlated with typicality or statistical averageness of faces . In addition to being statistical averages of groups, attractive faces are also symmetric . Both facial symmetry and averageness are considered markers of physical health and influence peoples’ choices of partners . Disfigured faces are neither typical nor average, and are usually not symmetric. They often deviate substantially from the norm. If proximity to the norm predicts positive social attributions, being ‘different’ could lead to negative evaluations. Disfigured faces might be linked to unfavourable personality traits, internal attributes, and social qualities because they are less typical and deviate from the population average. The association of disfigurement with negative attributes probably drives stigmatization and discrimination of disfigured people in social, academic, and professional contexts . The stigmatization and discrimination of disfigured people likely contributes to low self-esteem  and long term mental health concerns similar to other stigmatized groups that are subject to dehumanization . Dehumanization deprives a person or a group of people of positive human qualities and has been shown for several stigmatized groups such as homeless people and drug addicts . Dehumanization is used as a propaganda tool in political conflicts . The strongest predictors of dehumanization are hypothesized to be perceived competence and warmth . Faces rated lowest on both competence and warmth most robustly evoke dehumanization - including feelings of disgust and lack of empathy . 

Neuroimaging studies show that seeing attractive faces evokes brain responses in reward, emotion, and visual areas compared to seeing faces of average attractiveness . Attractive faces produce activations in areas associated with reward, like the nucleus accumbens , and orbitofrontal cortex . Moreover, attractiveness correlates with increased activations in areas associated with emotion, empathy, and social cognition like the anterior cingulate cortex and medio-prefrontal cortex  the latter being particularly active in tasks in which people are not making explicit attractiveness judgements . Different regions of the prefrontal cortex are selectively responsive to either attractive or unattractive faces  which is consistent with findings that ventral medio-prefrontal cortex processes stimulus value attributes in coordination with higher order visual areas like fusiform gyri and semantic processing areas (posterior superior temporal sulcus) . Orbital frontal  and medial prefrontal cortices  seem to process both aesthetic and moral values and may represent the biological link between these two kinds of evaluation . 

Left and right amygdala seem to be sensitive to both attractive  and unattractive faces . These non-linear effects for extremes at either end of the attractiveness spectrum suggest that amygdala activation reflects sensitivity to valence intensity rather than positive or negative valence per se . In line with the valence processing hypothesis for the functional role of amygdala, increased activation in the amygdala (bilaterally) is linked to untrustworthiness of faces . A meta-analysis of brain activations to attractiveness and trustworthiness suggests that activation of amygdala and adjacent nucleus accumbens is driven by extremes and atypicality . There is some tentative evidence that face typicality can also account for the activations in medio-prefrontal and anterior cingulate cortex . The authors note that the brain networks activated in response to extremes of attractiveness and trustworthiness are remarkably similar to brain networks that process positive and negative emotions . 

In addition to increased brain activations in reward and emotion areas, attractive faces also evoke larger neural responses in selective visual processing areas within ventral occipito-temporal cortex (such as the fusiform face area) as compared to faces of average attractiveness . These areas remain sensitive to facial attractiveness even when subjects are engaged in tasks in which attractiveness judgements are not queried explicitly. These observations have previously been interpreted as evidence that these areas also process rewards. While a reward response is one possible explanation for this amplified neural response to attractive faces, it is also possible that this reflects sensitivity to the saliency of attractive faces . If this alternate hypothesis is true, other salient features, such as disfigurement, should lead to similarly amplified neural responses in visual processing areas. 

Viewing faces of stigmatized groups fails to activate brain regions associated with empathy and social cognition . Krendl and colleagues reported increased activation in anterior insula and amygdala which correlated with self-reported disgust in response to viewing faces of stigmatized groups . The lack of activation in empathy and social cognition regions of the brain is postulated to be a neural correlate of dehumanization . 

Appearance clearly affects how people are viewed and treated by others. The same mechanisms that benefit attractive people in social interaction, put unattractive people at an unfair disadvantage. The effects of discriminating against people with facial disfigurement seem to extend beyond the specific effects of lower overall attractiveness and may tie in more with the pattern of results that have been shown with stigmatized groups. 

The goal of the present study was to test the behavioural and brain responses to facial disfigurement and investigate whether surgical treatment mitigates these responses. In two experiments, we used a set of photograph pairs of patients with different types of facial disfigurements before and after surgical treatment of the disfigurement. In experiment one we tested if people harbour implicit biases against disfigured faces and if such implicit biases were different from consciously aware self-reported explicit biases. In a follow up functional MRI (fMRI) study, we tested differential automatic brain responses to the same picture pairs when naïve participants were engaged in an unrelated cover task. We hypothesized that people have negative biases against faces with disfigurement. For the neural responses to facial disfigurement we tested competing hypotheses: visual cortices respond to rewards per se, or visual cortices respond to salience. In addition, we expected disfigured faces to show selective responses in emotion and valence areas such as anterior insulae and amygdalae and anterior cingulate and lateral or medial prefrontal areas in line with the research reviewed above. 


## Results and Discussion 
  
The behavioural experiment (N = 79, see method section for details) consisted of an implicit association test  (IAT) and an explicit bias questionnaire (EBQ) to test the hypothesis that people have a negative bias for disfigured faces. For the IAT, we used a stimulus set of photographs of real patients taken before and after treatment for disfigurement. The EBQ consisted of 11 questions which query conscious biases against people with facial disfigurements (see   https://osf.io/ca2u9/   for all items and data). We found no indication of an explicit bias. However, we did find that non-disfigured faces were preferred in the IAT (see Fig.  ). This bias was particularly robust for men, consistent with previous findings . Prior exposure to disfigured faces did not modulate the implicit bias of individuals.   
Female respondents demonstrate significantly less, although still strong, implicit preference for non-disfigured faces than male respondents. Male respondents show a moderate explicit preference for non-disfigured faces while women show no explicit preference. Error bars indicate 95% confidence intervals. 
  

We used the same set of photographs of people before and after surgical treatment that we used in the IAT in the fMRI study (N = 31). Participants viewed these photographs and engaged in a gender judgement task. We measured neural responses to facial disfigurement to test competing hypotheses of reward versus salience in visual areas like fusiform face area. If these visual areas respond to rewards, then non-disfigured faces compared to disfigured faces would show increased activity in visual areas linked to face processing. If these visual areas respond to salience, then we should find the opposite results; disfigured faces compared to non-disfigured faces should show increased activity in these areas. Because people with facial disfigurement are likely treated as an outgroup , neural patterns in response to disfigurement should be similar to previous findings investigating other stigmatized groups . We predicted decreased activation in areas linked to social cognition such as medio-prefrontal cortex and anterior cingulate cortex, as well as increased activations in areas linked to disgust and negative emotion like anterior insula and amygdala. 

We found that images of people with facial disfigurement, as compared to images of the same faces after surgical treatment, evoked greater neural responses within ventral occipito-temporal cortex, particularly bilateral fusiform gyri (see Fig.  ), and right inferior frontal cortex. This observation confirms the hypothesis that face processing and adjacent areas respond automatically to the salience of faces, rather than their attractiveness or rewarding properties per se.   
Increased activations (red yellow) and deactivations (blue-green) in response to faces before treatment. Results were corrected for multiple comparisons by familywise error correction at p &lt; 0.05 with Monte Carlo permutation testing in SnPM with a combined cluster-voxel threshold (cluster defining threshold p &lt; 0.001, T &gt; 3.3852). 
  

In addition to increased responses in visual areas, we found decreases in neural response amplitude to disfigured faces in the medial anterior cingulate gyrus extending towards medial prefrontal cortex (see Figs   and  ), as well as in a region stretching from right cuneus to the right calcarine gyrus and right lingual gyrus. This finding is similar to previous observations of neural responses to other stigmatized outgroups such as drug addicts and homeless people  and could reflect suppression empathy and mentalizing or increased demands in cognitive control, e.g. inhibition of staring at the area of lesion or inhibition of inappropriate social behaviour like obvious avoidance. Both possible hypotheses are not mutually exclusive and could be linked to the increased activation in the left inferior frontal gyrus - a region linked to cognitive control.   
Increased activations (red yellow) and deactivations (blue-green) in response to faces before treatment. Results were corrected for multiple comparisons by familywise error correction at p &lt; 0.05 with Monte Carlo permutation testing in SnPM with a combined cluster-voxel threshold (cluster defining threshold p &lt; 0.001, T &gt; 3.3852). 
  

In previous studies, increased amygdala activation has been reported to both positive and negative valence of faces . Moreover, studies investigating the brain responses to extreme outgroups like homeless people and drug addicts find activations in anterior insula where it is typically interpreted as a disgust response . We did not find statistically significant activations in amygdala and anterior insula. It is possible that this lack of effect is because of our smaller stimulus sample or that the difference between before and after stimulus pairs is not large enough to produce statistically significant results in this before-after contrast of the same face. 

In sum, we found that people have implicit negative biases against faces that are disfigured, without being aware of harbouring such biases. Disfigured faces evoke greater neural responses in ventral occipito-temporal and right inferior frontal regions as compared to non-disfigured faces. This finding refutes the hypothesis that attractiveness and reward per se drives automatic ventral cortical responses and instead confirms the idea that ventral occipito-temporal regions are sensitive to the salience of faces. 

Moreover, disfigured faces evoke lower neural responses in the anterior cingulate and medio-prefrontal cortex, as well as some visual areas. This result is similar to previously reported neural responses to stigmatized outgroups like homeless people and drug addicts . In agreement with this research, we speculate that the de-activation of these brain areas upon seeing disfigured faces as opposed to the same faces after surgical treatment possibly reflects an inhibition of empathy and mentalizing or inhibition of socially inappropriate behaviour. The medial anterior cingulate gyrus and the adjacent medial prefrontal cortex are core areas of the theory of mind and empathy networks  and are crucial for inferring other’s beliefs, feelings, and mental states. Together with previous behavioural research showing a clear association of negative personality traits and our findings of an implicit bias against disfigured faces, we take these response patterns as neural evidence for stigmatization. Future research should investigate if the de-activation of anterior cingulate cortex represents a consistent neural marker for dehumanization of people with disfigured faces or if it reflects social adaptive behaviour to people who deviate from the norm. 

The emphasis of attractiveness, its association with positive attributes and robustness of these associations across cultures  highlights the pervasive effect of attractiveness in social interaction. People who fall towards the lower end of the attractiveness spectrum are disadvantaged or even subject to discrimination and social isolation as in the case of facial disfigurement. Encouragingly, our findings suggest that surgical treatment of disfigurement mitigates the negative effects of disfigurement. Our findings highlight the importance of recognizing that we implicitly and automatically regard flawed faces as flawed people and that corrective surgery confers social and psychological benefits to people with facial disfigurement. Alternative prevention strategies against discrimination of disfigured people and effective support for people with facial conditions should be explored. 


## Methods 
  
### Implicit association test (IAT) and explicit bias questionnaire (EBQ) 
  
#### Participants 
  
80 participants were recruited via an online recruiting system for psychology experiments at the University of Pennsylvania (55 female, 25 male, mean age = 23 years, SD = 6.4, range 18–56). The sample size was determined based on estimates suggested by a meta-analysis on attitudes towards individuals with disabilities as measured by an IAT . Prior to participation, participants were informed that the task was about categorising faces and words but were naïve to the fact that some of those faces might be disfigured. Participation was voluntary, and participants received money as compensation. Study procedures were approved by the Institutional Review Board (IRB) at the University of Pennsylvania (Protocol #806447). IRB approval was in accordance with the International Conference on Harmonization and the Belmont report. All participants gave written informed consent. 

One participant was excluded from the data analysis for the IAT because more than 10% of the total test trials were unreasonably fast (&lt;300 ms). After data exclusion, the data of 79 participants went into the final analysis (55 female, mean age = 23 years, SD = 6.4, range 18–56). 


#### Procedure 
  
Task order between the IAT and the EBQ was counterbalanced so that half of the participants completed the IAT first, and half of the participants completed the EBQ first. Participants were seated in a testing room, in front of a testing laptop. After having been briefed on the order of the tasks, participants gave written informed consent. The entire experiment took about 30 minutes. 

The IAT  was designed using E-Prime software and was modelled after the IATs from   Project Implicit   (  https://implicit.harvard.edu  ). A total of 16 words were used for the IAT: 8 were positive words (attractive, happy, approachable, friendly, adore, lovely, spectacular, excellent), and 8 were negative words (ugly, evil, sickening, rotten, disaster, disgust, pain, despise). 

Participants completed the EBQ as a survey on Qualtrics. Questions were modelled after the Project Implicit and Changing Faces explicit questionnaires . The questionnaire included 11 questions asking about participants’ prior exposure to and conscious biases against people with facial disfigurement. Participants responded on a scale ranging from 1 to 7 (see   https://osf.io/ca2u9/   for details). 


#### Pictures 
  
Images consisted of photographs of patients with facial disfigurements before and after corrective surgery. These photos were collected from craniofacial and dental surgery atlases and compilations of plastic surgery results. The disfigured faces were photos of the individuals before treatment that were affected by one of the following disfigurements: carcinoma, hyperpigmentation, birthmark, scar or small wound, facial paralysis, isolated weight loss, bone disfigurement, or facial trauma. The non-disfigured faces were photographs of the same individuals after treatment (see   https://osf.io/ca2u9/   for all stimulus pairs). Pre-treatment and post-treatment photographs were cropped (to show only faces, with some hair and neck) and colour-corrected to match in size and coloring . The stimulus set consisted of 28 faces, of which 22 were female and 6 were male. 16 of the faces were oriented frontally, 10 were oriented in a three-quarters portrait view, and 2 were profiles (see   https://osf.io/ca2u9/  ). 


#### Implicit association test and explicit bias measure results 
  
Explicit scores range from −3 to +3, with zero indicating no relative preference for non-disfigured vs. disfigured faces. Positive scores indicate a preference for non-disfigured faces, and negative scores indicate a preference for disfigured faces. We found a significant implicit preference for non-disfigured faces (mean difference score = 0.90; SD = 0.58; min = −0.26; max = 2.00;   t   = 13.80; 95% CI = 0.77 to 1.03; p &lt; 0.001; Cohen’s   d   = 1.55). This effect was particularly strong for male respondents (see Table   for details, see Fig.  ). Participants showed no significant explicit preference for non-disfigured vs. disfigured faces (mean explicit score = 0.01; SD = 0.51; min = −1.50; max = 1.08.168;   t   = 0.17; 95% CI = −0.11 to 0.12; p = 0.866; Cohen’s   d =   0.02). Prior exposure had no effect on bias for either the IAT or the EBQ. There was a small to moderate correlation between implicit and explicit scores that was, however, not statistically significant (Pearson’s correlation coefficient, r = 0.22; p = 0.052) making it difficult to draw conclusions as to whether people are aware of their biases.   
Implicit preferences for non-disfigured vs. disfigured faces for all participants by gender. 
  
IAT D scores range from −2 to +2, with zero indicating no relative preference for non-disfigured vs. disfigured faces. Positive scores indicate an implicit preference for non-disfigured faces while negative scores indicate an implicit preference for disfigured faces. D scores were interpreted according to specific, conservative break points based on Cohen’s   d  : ±0.15 (‘slight’ bias), 0.35 (‘moderate’ bias), 0.65 (‘strong’ bias). 

Cohen’s   d   is a standardized effect size, interpreted as   d   of 0.2 = small effect,   d   of 0.5 = medium effect, and   d   ≥ 0.8 = large effect. 
  



### FMRI experiment 
  
#### Participants 
  
We recruited 34 healthy right-handed college students from University of Pennsylvania (24 females, 10 males). Age of participants ranged from 18–35 years. Participants had normal or corrected to normal vision and no prior history of psychiatric or neurological disease. Before participation in the study, each individual gave informed consent approved by the IRB at the University of Pennsylvania (Protocol #806447) in accordance with the International Conference on Harmonization and the Belmont report. 

The data of three participants was excluded from the final analysis. One dataset was excluded because of technical failure which stopped the stimulus presentation halfway through the experiment. Two other datasets were excluded because of synchronization problems between experimenter laptop and the scanner triggers. The data of 31 participants entered the final analysis (22 females, 9 males). 

The EBQ for the participants in the fMRI experiment showed that about half of the participants have a close friend or family member with either a facial disfigurement or a disability. Exposure to people with facial disfigurement was normally distributed in the sample, and most participants reported no to slight preference for non-disfigured over disfigured people (22/28 data entries, 5 missing values). 


#### Procedure and stimulus presentation 
  
The experiment consisted of one session. Participants were presented with 28 pictures of faces in randomized order and were asked to decide whether the displayed face was male or female. Half of the presented pictures were photographs of patients before treatment, and half after treatment. The pictures were identical to the ones used in the behavioural experiment (IAT, see above). Stimuli were presented using E-prime software by projecting them onto a screen using a projector outside the MR scanner room, which could be seen by participants through a mirror mounted over the head coil. Each picture was presented for 6 seconds. Responses were recorded with a 2-button response device. After the experiment, a high-resolution anatomical scan (~7 min) was conducted. After the scanning session, participants were taken out of the scanner and completed the EBQ for disfigurement on a testing computer outside the scanner room. This test was identical to the EBQ in the online sample reported above. 


#### fMRI data acquisition and pre-processing 
  
Images of blood-oxygen level dependent (BOLD) changes were acquired with a 3 T Siemens Magnetom Prisma scanner (Erlangen, Germany) with a 64-channel head coil. We used cushions to minimize participants’ head movement. We used two localizing scans and auto-alignment. Functional images were acquired using a standard BOLD sequence (TR: 2000 ms, TE: 30 ms, flip angle: 60 degrees, voxel size: 2.0 × 2.0 × 2.0 mm, 81 slices). High resolution (0.8 × 0.8 × 0.8 mm) structural (anatomical) images were acquired using an SPC T1 GRAPPA sequence . Data were pre-processed using the Matlab toolbox SPM12 (  http://www.fil.ion.ucl.ac.uk/spm  ). Images were motion corrected and registered to the first image of the scanning block. The mean of the motion-corrected images was co-registered with the individual participants’ anatomical scan. The anatomical and functional scans were spatially normalized to the standard MNI template. Finally, all data were spatially smoothed using an isotropic 8 mm full width at half maximum (FWHM) Gaussian kernel. 


#### fMRI data analysis 
  
At the single-subject level, statistical analysis was performed using a general linear model. The motion estimates of the motion correction algorithm were modelled as regressors of no interest to account for head motion. We performed a whole-brain group analysis by directly contrasting the mean activations per condition in a non-parametric design with SnPM (  https://warwick.ac.uk/fac/sci/statistics/staff/academic-research/nichols/software/snpm  ). Results were corrected for multiple comparisons with a combined voxel-cluster level threshold by familywise error correction at p &lt; 0.05 with Monte Carlo permutation testing. 

In addition to the whole brain group analysis, we performed an item-wise region of interest control analysis to test if the effects in the group analysis are driven by specific items. The two clusters were defined by the group contrasts in the whole brain analysis and consisted of one area comprising of the two large occipital activation clusters, and one comprising the (de-)activation cluster in the anterior cingulate cortex. Mean values for these two regions were extracted for each subject and item. The mean values were normalised with the individual subject’s mean activation in this area to create relative difference scores per subject and item. The data for the item-wise analysis were analysed with linear mixed effect models in RStudio. We built one base model for each dependent variable (occipital cluster activation, anterior cingulate cluster activation) that included condition (pre or post surgery picture) as a predictor and subject and item as random factors with random intercepts. We tested for both random factors whether including random slopes for the condition would improve the model fit and tested interactions with gender and EBQ responses with the best base model (see   https://osf.io/ca2u9/   for details). 


#### FMRI sample results 
  
Participants performed at ceiling for the gender judgment task. 

An ANOVA analysis of the reaction time data in the gender judgement task in the scanner revealed no differences in reaction times between before and after treatment pictures (F  = 0.56, p = 0.45, see Fig.  ) and no differences for item (F  = 1.26, p = 0.17) and no interaction between item and face type (F  = 1.06, p = 0.38).   
Reaction times for gender judgement task per item split by face type. Error bars display 95% confidence intervals. 
  

We found increased activations in temporo-occipital regions encompassing bilateral middle occipital and fusiform gyrus, left inferior occipital gyrus, as well as right inferior temporal and right inferior frontal gyrus (Fig.  ; see Table   for details). An area in the medial anterior cingulate cortex and an area in the right calcarine gyrus showed significant decrease in activation in response to faces before surgery (Fig.  ; see Table   for details). All clusters statistically significant at p &lt; 0.05 FWE at the cluster level corrected by Monte Carlo permutation testing (cluster forming threshold p &lt; 0.001 per voxel).   
Increased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing. 
    
Decreased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing. 
  

The ROI analysis controlling for random effects of items and subjects confirmed the results of the whole brain analysis (see Figs   and  , see   https://osf.io/ca2u9/   for analysis code and full statistical details). Whether the picture of a person was presented from before or after surgery had a significant effect on the BOLD activation level in the anterior cingulate cluster (β = −0.15, s.e. = 0.05, t = −2.95), as well as the occipital cortex (β = 0.17, s.e. = 0.03, t = 5.31). Neither gender of the participant, any of the EBQ measures (see Tables   and   for descriptive statistics), or the gender of the depicted person was found to be related to BOLD activation level differences.   
Itemwise mean activation in the occipital cortex. Stimulus items that do not follow the general activation pattern are Item 2, 7, 12, 25, and 28. 
    
Itemwise mean activation in the anterior cingulate cortex. Stimulus items that do not follow the general activation pattern are Item 1, 25, and 28. 
    
Summary of the EBQ responses I. 
    
Summary of the EBQ responses II. 
  



 ## Data Availability

The datasets generated and analysed during the current study will be made available without restriction on Open Science Framework (DOI 10.17605/OSF.IO/CA2U9) upon acceptance of the article for publication, https://osf.io/ca2u9/. https://osf.io/ca2u9/</pre></details></details>
  <details class="inner-accordion"><summary>Coordinate-relevant source tables (2)</summary><details class="inner-accordion"><summary>Table 2 (Tab2) - Increased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing.</summary><div class="table-html"><table-wrap id="Tab2" position="float" orientation="portrait"><label>Table 2</label><caption><p>Increased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing.</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="1" rowspan="1">Location</th><th colspan="1" rowspan="1">k</th><th colspan="1" rowspan="1">T-max</th><th colspan="1" rowspan="1">x</th><th colspan="1" rowspan="1">y</th><th colspan="1" rowspan="1">z</th></tr></thead><tbody><tr><td colspan="1" rowspan="1">left lateral occipital gyrus/BA 18</td><td colspan="1" rowspan="1">3442</td><td colspan="1" rowspan="1">8.08</td><td colspan="1" rowspan="1">−28</td><td colspan="1" rowspan="1">−98</td><td colspan="1" rowspan="1">8</td></tr><tr><td colspan="1" rowspan="1">right lateral occipital gyrus/BA 18</td><td colspan="1" rowspan="1">2377</td><td colspan="1" rowspan="1">6.98</td><td colspan="1" rowspan="1">34</td><td colspan="1" rowspan="1">−90</td><td colspan="1" rowspan="1">2</td></tr><tr><td colspan="1" rowspan="1">right inferior frontal gyrus/BA 44</td><td colspan="1" rowspan="1">230</td><td colspan="1" rowspan="1">5.02</td><td colspan="1" rowspan="1">42</td><td colspan="1" rowspan="1">8</td><td colspan="1" rowspan="1">26</td></tr></tbody></table></table-wrap></div></details><details class="inner-accordion"><summary>Table 3 (Tab3) - Decreased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing.</summary><div class="table-html"><table-wrap id="Tab3" position="float" orientation="portrait"><label>Table 3</label><caption><p>Decreased responses to faces before treatment, familywise error corrected with Monte Carlo permutation testing.</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="1" rowspan="1">Location</th><th colspan="1" rowspan="1">k</th><th colspan="1" rowspan="1">T-max</th><th colspan="1" rowspan="1">x</th><th colspan="1" rowspan="1">y</th><th colspan="1" rowspan="1">z</th></tr></thead><tbody><tr><td colspan="1" rowspan="1">left and right anterior cingulate cortex/BA 24</td><td colspan="1" rowspan="1">765</td><td colspan="1" rowspan="1">4.92</td><td colspan="1" rowspan="1">−2</td><td colspan="1" rowspan="1">36</td><td colspan="1" rowspan="1">10</td></tr><tr><td colspan="1" rowspan="1">right calcarine gyrus/BA 18</td><td colspan="1" rowspan="1">247</td><td colspan="1" rowspan="1">4.10</td><td colspan="1" rowspan="1">6</td><td colspan="1" rowspan="1">−88</td><td colspan="1" rowspan="1">12</td></tr></tbody></table></table-wrap></div></details></details>
</details>


<details class="doc-card">
  <summary><strong>PMID 14980212</strong> | Pred included: 3 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=3</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/14980212/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Affective &gt; Neutral faces; socialcommunication, Cooperator &gt; Neutral faces; socialcommunication, Defector &gt; Neutral faces; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>14980212_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for social communication (face viewing and implicit social judgments). Construct evidence span: &quot;faces of cooperators&quot;.</td></tr>
<tr><td>14980212_analysis_1</td><td>Cerebral Foci of Activation for Intentional versus Nonintentional Cooperator Faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for social communication (face viewing with social significance). Construct evidence span: &quot;cooperator faces introduced as intentional agents&quot;.</td></tr>
<tr><td>14980212_analysis_2</td><td>Cerebral Foci of Activation for Intentional versus Nonintentional Cooperator Faces - Other Brain Regions</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for social communication (face perception contrasts reported). Construct evidence span: &quot;cooperator faces introduced as intentional agents&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>14980212_1</td><td>Affective &gt; Neutral faces; socialcommunication</td><td>14980212_analysis_0</td><td>analysis_0</td><td>0.286</td><td>0.462</td><td>0.409</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>14980212_2</td><td>Cooperator &gt; Neutral faces; socialcommunication</td><td>14980212_analysis_1</td><td>Cerebral Foci of Activation for Intentional versus Nonintentional Cooperator Faces</td><td>0.296</td><td>0.000</td><td>0.089</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>14980212_3</td><td>Defector &gt; Neutral faces; socialcommunication</td><td>14980212_analysis_2</td><td>Cerebral Foci of Activation for Intentional versus Nonintentional Cooperator Faces - Other Brain Regions</td><td>0.268</td><td>0.000</td><td>0.081</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 15006683</strong> | Pred included: 1 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/15006683/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>15006683_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met: the task involves viewing social interactions with face and auditory cues. Construct evidence span: &quot;video clips depicting everyday social interactions&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <p>No manual-to-auto match diagnostics for this document.</p>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 16055351</strong> | Pred included: 1 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=7</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/16055351/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Anger &gt; Neutral (AN + NA) &gt; (NN); socialcommunication, Anger to be attended &gt; to be ignored; socialcommunication, Anger to-be-attended &gt; Neutral; socialcommunication, Anger to-be-ignored &gt; Neutral; socialcommunication, anger to be ignored &gt; to be attended; socialcommunication, spatial attention to left ear &gt; right ear; socialcommunication, spatial attention to right ear&gt; left ear; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>16055351_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;BOLD responses were increased for angry vs. neutral prosody&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>16055351_1</td><td>Anger &gt; Neutral (AN + NA) &gt; (NN); socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>16055351_2</td><td>Anger to be attended &gt; to be ignored; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>16055351_3</td><td>Anger to-be-attended &gt; Neutral; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>16055351_4</td><td>Anger to-be-ignored &gt; Neutral; socialcommunication</td><td>16055351_analysis_0</td><td>analysis_0</td><td>0.205</td><td>0.000</td><td>0.062</td><td>unmatched</td><td>low_total_score, missing_coords_on_one_side</td></tr><tr><td>16055351_5</td><td>anger to be ignored &gt; to be attended; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>16055351_6</td><td>spatial attention to left ear &gt; right ear; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>16055351_7</td><td>spatial attention to right ear&gt; left ear; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 17071110</strong> | Pred included: 1 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=3, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/17071110/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Retaliation interaction with low CU &gt; High CU; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>17071110_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TN</span></td><td></td><td>Excluded because the condition involves scale observation/anticipation rather than face/prosody viewing or explicit communication. Missing local inclusion criteria: SOCIAL_COMMUNICATION_I1, SOCIAL_COMMUNICATION_I2.</td></tr>
<tr><td>17071110_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TN</span></td><td></td><td>Excluded because the retaliation condition is primarily decision-making/response-selection rather than explicit social communication (faces/expressive reception). Missing local inclusion criteria: SOCIAL_COMMUNICATION_I1, SOCIAL_COMMUNICATION_I2.</td></tr>
<tr><td>17071110_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;common activation in the dorsal mPFC and bilateral STS&quot; (STS involvement in perception of socially relevant movements/expressions).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>17071110_1</td><td>Retaliation &gt; Watching opponent; socialcommunication</td><td>17071110_analysis_1</td><td>analysis_1</td><td>0.146</td><td>0.750</td><td>0.569</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>17071110_2</td><td>Retaliation interaction with low CU &gt; High CU; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>17071110_3</td><td>Watching opponent &gt; Retaliation; socialcommunication</td><td>17071110_analysis_0</td><td>analysis_0</td><td>0.244</td><td>0.842</td><td>0.663</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>17071110_4</td><td>Watching opponent &gt; Retaliation (conjunction); socialcommunication</td><td>17071110_analysis_2</td><td>analysis_2</td><td>0.182</td><td>0.900</td><td>0.685</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 17627852</strong> | Pred included: 1 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=4</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/17627852/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Communication &gt; Description; socialcommunication, Communication &gt; control; socialcommunication, Description &gt; control; socialcommunication, Familiar communication &gt; unfamiliar communication; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>17627852_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>The analysis directly measures communicative speech production versus description (productive social communication). Construct evidence span: &quot;communicative speech production&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>17627852_1</td><td>Communication &gt; Description; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>17627852_2</td><td>Communication &gt; control; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>17627852_3</td><td>Description &gt; control; socialcommunication</td><td>17627852_analysis_0</td><td>analysis_0</td><td>0.154</td><td>0.389</td><td>0.318</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>17627852_4</td><td>Familiar communication &gt; unfamiliar communication; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 17964185</strong> | Pred included: 1 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=1, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/17964185/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>17964185_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;all face stimuli were colored front-facing photographs with direct gaze&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>17964185_1</td><td>(peer vs. celebrity) x (positive vs. non-positive); socialcommunication</td><td>17964185_analysis_0</td><td>analysis_0</td><td>0.167</td><td>0.903</td><td>0.682</td><td>uncertain</td><td>high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18514546</strong> | Pred included: 1 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=2</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18514546/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Other &gt; high-level baseline; socialcommunication, Self &gt; high-level baseline; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18514546_analysis_0</td><td>SELF versus high-level baseline</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;viewed synthetic emotional faces expressing either fear or anger&quot;.</td></tr>
<tr><td>18514546_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Excluded because this is an ROI-based correlation analysis (extracted parameter estimates correlated with BEES) rather than a group-level whole-brain voxelwise task map.</td></tr>
<tr><td>18514546_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because this analysis is a between-group contrast (gender differences / interaction), which is disallowed by the global exclusion criteria.</td></tr>
<tr><td>18514546_analysis_3</td><td>analysis_3</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because this analysis is a between-group contrast (gender differences / interaction), which is disallowed by the global exclusion criteria.</td></tr>
<tr><td>18514546_analysis_4</td><td>analysis_4</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because this analysis is a between-group contrast (gender differences / interaction), which is disallowed by the global exclusion criteria.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18514546_1</td><td>Other &gt; high-level baseline; socialcommunication</td><td>18514546_analysis_1</td><td>analysis_1</td><td>0.172</td><td>0.102</td><td>0.123</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>18514546_2</td><td>Self &gt; high-level baseline; socialcommunication</td><td>18514546_analysis_0</td><td>SELF versus high-level baseline</td><td>0.877</td><td>0.071</td><td>0.313</td><td>unmatched</td><td>low_coord_high_name, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18633846</strong> | Pred included: 7 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=3</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18633846/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Interaction [( Individual gaze + Social No-gaze) - (Individual No-gaze + Social gaze)];socialcommunication, [( Social gaze + Individual gaze) - ( Social No-gaze + Individual No-gaze)]; socialcommunication, [(Individual gaze + Social No-gaze) - (Individual No-gaze + Social Gaze); socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18633846_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;main effect of gaze [(Social Gaze + Individual Gaze) – (Social No-gaze + Individual No-gaze)]&quot;.</td></tr>
<tr><td>18633846_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;right IFG, the amygdala, and the posterior superior temporal sulcus (pSTS)&quot;.</td></tr>
<tr><td>18633846_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;presence/absence of gaze&quot;.</td></tr>
<tr><td>18633846_analysis_3</td><td>analysis_3</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;gaze direction is a potent social cue&quot;.</td></tr>
<tr><td>18633846_analysis_4</td><td>analysis_4</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;pSTS activity...sensitive to the context in which the gaze shift is perceived&quot;.</td></tr>
<tr><td>18633846_analysis_5</td><td>analysis_5</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;gaze cues still have a special salience for adults&quot;.</td></tr>
<tr><td>18633846_analysis_6</td><td>analysis_6</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Direct or aveted eye gaze&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18633846_1</td><td>Interaction [( Individual gaze + Social No-gaze) - (Individual No-gaze + Social gaze)];socialcommunication</td><td>18633846_analysis_1</td><td>analysis_1</td><td>0.125</td><td>0.000</td><td>0.037</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>18633846_2</td><td>[( Social gaze + Individual gaze) - ( Social No-gaze + Individual No-gaze)]; socialcommunication</td><td>18633846_analysis_5</td><td>analysis_5</td><td>0.094</td><td>0.250</td><td>0.203</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>18633846_3</td><td>[(Individual gaze + Social No-gaze) - (Individual No-gaze + Social Gaze); socialcommunication</td><td>18633846_analysis_0</td><td>analysis_0</td><td>0.146</td><td>0.058</td><td>0.085</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18633856</strong> | Pred included: 2 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18633856/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18633856_analysis_0</td><td>Angry &gt; Happy</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;shifted his gaze to make eye contact and simultaneously changed his expression&quot;.</td></tr>
<tr><td>18633856_analysis_1</td><td>Happy &gt; Angry</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;shifted his gaze to make eye contact and simultaneously changed his expression&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <p>No manual-to-auto match diagnostics for this document.</p>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 19733672</strong> | Pred included: 2 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/19733672/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>19733672_analysis_0</td><td>Movie scenes theory of mind (ToM) &gt; movie scenes physical inference (PI)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;occipitotemporal cortex bilaterally (BA 17/18)&quot;.</td></tr>
<tr><td>19733672_analysis_1</td><td>Silent answer theory of mind (ToM) &gt; silent answer physical inference (PI)</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because the silent-answer contrast indexes internal explicit mentalizing rather than perceptual/communicative reception (missing SOCIAL_COMMUNICATION_I1 and SOCIAL_COMMUNICATION_I2).</td></tr>
<tr><td>19733672_analysis_2</td><td>MC answer theory of mind (ToM) &gt; MC answer physical inference (PI)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;superior temporal sulcus (STS) bilaterally&quot;.</td></tr>
<tr><td>19733672_analysis_3</td><td>analysis_3</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because T-PICA is a multivariate ICA/tensor decomposition rather than a group-level univariate voxelwise task-evoked statistical map required by GLOBAL_I2; GLOBAL_E2 applies.</td></tr>
<tr><td>19733672_analysis_4</td><td>analysis_4</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because T-PICA is a multivariate ICA/tensor decomposition rather than a group-level univariate voxelwise task-evoked statistical map required by GLOBAL_I2; GLOBAL_E2 applies.</td></tr>
<tr><td>19733672_analysis_5</td><td>analysis_5</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because T-PICA is a multivariate ICA/tensor decomposition rather than a group-level univariate voxelwise task-evoked statistical map required by GLOBAL_I2; GLOBAL_E2 applies.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <p>No manual-to-auto match diagnostics for this document.</p>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 20188190</strong> | Pred included: 4 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=2</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/20188190/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Gender &gt; Preference; socialcommunication, Preference &gt; Gender; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>20188190_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;subjects viewed faces and made appraisals of whether or not they liked the face&quot;.</td></tr>
<tr><td>20188190_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;subjects viewed faces and made appraisals of whether or not they liked the face&quot;.</td></tr>
<tr><td>20188190_analysis_2</td><td>Preference &gt; Gender</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Preference task, subjects viewed faces and made appraisals of whether or not they liked the face&quot;.</td></tr>
<tr><td>20188190_analysis_3</td><td>Gender &gt; Preference</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;subjects viewed faces and made appraisals of whether or not they liked the face&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>20188190_1</td><td>Gender &gt; Preference; socialcommunication</td><td>20188190_analysis_3</td><td>Gender &gt; Preference</td><td>1.000</td><td>0.000</td><td>0.300</td><td>unmatched</td><td>low_coord_high_name, low_total_score, missing_coords_on_one_side, name_only_signal</td></tr><tr><td>20188190_2</td><td>Preference &gt; Gender; socialcommunication</td><td>20188190_analysis_2</td><td>Preference &gt; Gender</td><td>1.000</td><td>0.000</td><td>0.300</td><td>unmatched</td><td>low_coord_high_name, low_total_score, missing_coords_on_one_side, name_only_signal</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 21249224</strong> | Pred included: 1 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/21249224/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>21249224_analysis_0</td><td>Brain areas showing increased activity in response to the social interaction condition.</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;social intentions carried by whole-body motion&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <p>No manual-to-auto match diagnostics for this document.</p>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 21600991</strong> | Pred included: 1 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/21600991/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Retrieval of social context &gt; Retrieval of self-generation; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>21600991_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;participants alternately generated sentences to construct a meaningful story narrative&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>21600991_1</td><td>Retrieval of social context &gt; Retrieval of self-generation; socialcommunication</td><td>21600991_analysis_0</td><td>analysis_0</td><td>0.147</td><td>0.000</td><td>0.044</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 22174872</strong> | Pred included: 3 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/22174872/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>22174872_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;EPC in general (pooling across simple and complex emotion relative to neutral trials), is supported by a temporo-frontal network&quot;.</td></tr>
<tr><td>22174872_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;processing of prosodic stimuli conveying simple and complex emotion&quot;.</td></tr>
<tr><td>22174872_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;activations in the right and left superior frontal gyrus (BA 9/32) extending towards medial regions&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <p>No manual-to-auto match diagnostics for this document.</p>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23599165</strong> | Pred included: 5 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=7</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23599165/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Match &gt; Unrequited; socialcommunication, Mismatched (Rejection + Unrequited) &gt; matched (Match + Disinterest); socialcommunication, Partners who were given a no &gt; those given a yes; socialcommunication, Partners who were given a yes &gt; those given a no; socialcommunication, Rejection &gt; Disinterest; socialcommunication, Unsigned prediction errors from RL model; socialcommunication, Yes (Match + Unrequited) &gt; No (Rejection + Disinterest); socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23599165_analysis_0</td><td>Yes (Match + Unrequited) &gt; No (Rejection + Disinterest)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;the partner&#x27;s decision was displayed below the face&quot;.</td></tr>
<tr><td>23599165_analysis_1</td><td>Match &gt; Unrequited</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;this contrast controlled for the partner&#x27;s decision—yes in both cases&quot;.</td></tr>
<tr><td>23599165_analysis_2</td><td>Rejection &gt; Disinterest</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;partner&#x27;s decision&quot;.</td></tr>
<tr><td>23599165_analysis_3</td><td>Mismatched (Rejection + Unrequited) &gt; matched (Match + Disinterest)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;mismatched decisions ... elicited activation in left pSTS&quot;.</td></tr>
<tr><td>23599165_analysis_4</td><td>Partners who were given a yes &gt; those given a no</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;the appearance of partner&#x27;s face&quot;.</td></tr>
<tr><td>23599165_analysis_5</td><td>Partners who were given a no &gt; those given a yes</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Contrast highlights TPJ (theory-of-mind) rather than facial communication/reception contrasts; missing local inclusion criteria SOCIAL_COMMUNICATION_I2/SOCIAL_COMMUNICATION_I1.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23599165_1</td><td>Match &gt; Unrequited; socialcommunication</td><td>23599165_analysis_1</td><td>Match &gt; Unrequited</td><td>1.000</td><td>0.063</td><td>0.344</td><td>unmatched</td><td>low_coord_high_name, low_total_score</td></tr><tr><td>23599165_2</td><td>Mismatched (Rejection + Unrequited) &gt; matched (Match + Disinterest); socialcommunication</td><td>23599165_analysis_3</td><td>Mismatched (Rejection + Unrequited) &gt; matched (Match + Disinterest)</td><td>1.000</td><td>0.189</td><td>0.432</td><td>unmatched</td><td>coord_count_mismatch, low_coord_high_name, low_total_score</td></tr><tr><td>23599165_3</td><td>Partners who were given a no &gt; those given a yes; socialcommunication</td><td>23599165_analysis_5</td><td>Partners who were given a no &gt; those given a yes</td><td>1.000</td><td>0.000</td><td>0.300</td><td>unmatched</td><td>low_coord_high_name, low_total_score, name_only_signal</td></tr><tr><td>23599165_4</td><td>Partners who were given a yes &gt; those given a no; socialcommunication</td><td>23599165_analysis_4</td><td>Partners who were given a yes &gt; those given a no</td><td>1.000</td><td>0.122</td><td>0.385</td><td>unmatched</td><td>low_coord_high_name, low_total_score</td></tr><tr><td>23599165_5</td><td>Rejection &gt; Disinterest; socialcommunication</td><td>23599165_analysis_2</td><td>Rejection &gt; Disinterest</td><td>1.000</td><td>0.000</td><td>0.300</td><td>unmatched</td><td>low_coord_high_name, low_total_score, name_only_signal</td></tr><tr><td>23599165_6</td><td>Unsigned prediction errors from RL model; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>23599165_7</td><td>Yes (Match + Unrequited) &gt; No (Rejection + Disinterest); socialcommunication</td><td>23599165_analysis_0</td><td>Yes (Match + Unrequited) &gt; No (Rejection + Disinterest)</td><td>1.000</td><td>0.000</td><td>0.300</td><td>unmatched</td><td>low_coord_high_name, low_total_score, name_only_signal</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23684882</strong> | Pred included: 2 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=5</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23684882/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> (IMIO &gt; CTO) ∩ (IMIE &gt; CTE); socialcommunication, (S-IMIO&gt;NS-IMIO) &gt; (S-CTO &gt; NS-CTO); socialcommunication, [(S-IMIO &gt; NS-IMIO) &gt; (S-CTO &gt; NS-CTO)] &gt; [(S-IMIE &gt; NS-IMIE) &gt; (S-CTE &gt; NS- CTE)]; socialcommunication, [(S-IMIO &gt; S-CTO) + (S-IMIE &gt; S-CTE)] &gt; [(NS-IMIO &gt; NS-CTO) + (NS-IMIE &gt; NS-CTE)]; socialcommunication, [S (IMIO + CTO + IMIE + CTE) &gt; NS (IMIO + CTO + IMIE + CTE)]; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23684882_analysis_0</td><td>Local maxima &gt; (IMI O &gt; CT O ) ∩ (IMI E &gt; CT E )</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;imitate the gesture presented (IMI)&quot;.</td></tr>
<tr><td>23684882_analysis_1</td><td>Local maxima &gt; (S-IMI O &gt; NS-IMI O ) &gt; (S-CT O &gt; NS-CT O )</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;(S-IMIO &gt; NS-IMIO)&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23684882_1</td><td>(IMIO &gt; CTO) ∩ (IMIE &gt; CTE); socialcommunication</td><td>23684882_analysis_0</td><td>Local maxima &gt; (IMI O &gt; CT O ) ∩ (IMI E &gt; CT E )</td><td>0.720</td><td>0.013</td><td>0.225</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>23684882_2</td><td>(S-IMIO&gt;NS-IMIO) &gt; (S-CTO &gt; NS-CTO); socialcommunication</td><td>23684882_analysis_1</td><td>Local maxima &gt; (S-IMI O &gt; NS-IMI O ) &gt; (S-CT O &gt; NS-CT O )</td><td>0.779</td><td>0.000</td><td>0.234</td><td>unmatched</td><td>coord_count_mismatch, low_coord_high_name, low_total_score, name_only_signal</td></tr><tr><td>23684882_3</td><td>[(S-IMIO &gt; NS-IMIO) &gt; (S-CTO &gt; NS-CTO)] &gt; [(S-IMIE &gt; NS-IMIE) &gt; (S-CTE &gt; NS- CTE)]; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>23684882_4</td><td>[(S-IMIO &gt; S-CTO) + (S-IMIE &gt; S-CTE)] &gt; [(NS-IMIO &gt; NS-CTO) + (NS-IMIE &gt; NS-CTE)]; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>23684882_5</td><td>[S (IMIO + CTO + IMIE + CTE) &gt; NS (IMIO + CTO + IMIE + CTE)]; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23813661</strong> | Pred included: 9 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23813661/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23813661_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;meaningful compared with scrambled videos&quot;.</td></tr>
<tr><td>23813661_analysis_1</td><td>1. Contingent &gt; Mirrored</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Contrast measures reception of nonverbal communicative interactions (contingency). Construct evidence span: &quot;contingent compared with mirrored dyads&quot;.</td></tr>
<tr><td>23813661_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Contrast set evaluates communicative interaction features (contingency). Construct evidence span: &quot;Main effects of movement contingency&quot;.</td></tr>
<tr><td>23813661_analysis_3</td><td>2. Mirrored &gt; Contingent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Contrast pertains to perception of nonverbal interactive dynamics (mirrored vs contingent). Construct evidence span: &quot;mirrored compared with contingent dyads&quot;.</td></tr>
<tr><td>23813661_analysis_4</td><td>analysis_4</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Analysis measures social communicative features of the stimuli (contingency). Construct evidence span: &quot;Main effects of movement contingency&quot;.</td></tr>
<tr><td>23813661_analysis_5</td><td>1. Rigid &gt; Smooth</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Contrast involves perception of nonverbal communicative kinematics (rigid vs smooth). Construct evidence span: &quot;rigid compared with smooth movements&quot;.</td></tr>
<tr><td>23813661_analysis_6</td><td>analysis_6</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Analysis addresses communicative aspects of motion (fluency and interaction). Construct evidence span: &quot;Main effects of movement fluency and interaction&quot;.</td></tr>
<tr><td>23813661_analysis_7</td><td>2. Interaction: (Contingent &gt; Mirrored) &gt; (Smooth &gt; Rigid)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Interaction addresses communicative dynamics (contingency × fluency). Construct evidence span: &quot;interaction evaluating brain regions more responsive to contingent than to mirrored videos when the motion was smooth&quot;.</td></tr>
<tr><td>23813661_analysis_8</td><td>analysis_8</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Analysis evaluates communicative motion features and interaction effects. Construct evidence span: &quot;Main effects of movement fluency and interaction&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <p>No manual-to-auto match diagnostics for this document.</p>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 24936688</strong> | Pred included: 3 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=3</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/24936688/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Status Level &gt; baseline; socialcommunication, Status Type &gt; baseline; socialcommunication, Status Type x Status Level &gt; baseline; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>24936688_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;presented with photographs of faces paired with a colored background&quot;.</td></tr>
<tr><td>24936688_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;presented with photographs of faces paired with a colored background&quot;.</td></tr>
<tr><td>24936688_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;presented with photographs of faces paired with a colored background&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>24936688_1</td><td>Status Level &gt; baseline; socialcommunication</td><td>24936688_analysis_0</td><td>analysis_0</td><td>0.185</td><td>0.000</td><td>0.056</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>24936688_2</td><td>Status Type &gt; baseline; socialcommunication</td><td>24936688_analysis_1</td><td>analysis_1</td><td>0.189</td><td>0.000</td><td>0.057</td><td>unmatched</td><td>low_total_score</td></tr><tr><td>24936688_3</td><td>Status Type x Status Level &gt; baseline; socialcommunication</td><td>24936688_analysis_2</td><td>analysis_2</td><td>0.147</td><td>0.000</td><td>0.044</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25315788</strong> | Pred included: 2 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25315788/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25315788_analysis_0</td><td>B. Searchlight-based MVPA: happy versus sad</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;text messages&quot;.</td></tr>
<tr><td>25315788_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;text messages&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <p>No manual-to-auto match diagnostics for this document.</p>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25534111</strong> | Pred included: 1 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=4</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25534111/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> (IJA - IJAc) with (RJA - RJAc); socialcommunication, (IJA − IJAc) − (RJA − RJAc); socialcommunication, IJA &gt; IJAc; socialcommunication, RJA &gt; RJAc; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25534111_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;direct and then averted gaze&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25534111_1</td><td>(IJA - IJAc) with (RJA - RJAc); socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>25534111_2</td><td>(IJA − IJAc) − (RJA − RJAc); socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>25534111_3</td><td>IJA &gt; IJAc; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>25534111_4</td><td>RJA &gt; RJAc; socialcommunication</td><td>25534111_analysis_0</td><td>analysis_0</td><td>0.200</td><td>0.400</td><td>0.340</td><td>unmatched</td><td>low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25716010</strong> | Pred included: 3 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=1, unmatched=10</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25716010/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Fear +  happy &gt; neutral; socialcommunication, Neutral &gt; fear +  happy; socialcommunication, Fear + neutral &gt; happy; socialcommunication, Fear &gt; happy +  neutral; socialcommunication, Happy &gt; fear + neutral; socialcommunication, Interactive fear &gt; individual fear; socialcommunication, Interactive fear &gt; individual fear +  individual neutral &gt; interactive neutral; socialcommunication, Interactive fear &gt; individual fear + interactive happy &gt; individual happy; socialcommunication, Interactive fear &gt; individual fear + interactive neutral &gt; individual neutral; socialcommunication, Interactive neutral &gt; individual neutral; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25716010_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;emotional facial and bodily expressions&quot;.</td></tr>
<tr><td>25716010_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;activated networks related to the perception, execution and integration of action and emotion&quot;.</td></tr>
<tr><td>25716010_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;interactive fearful crowds activated a specific network of brain areas&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25716010_1</td><td>Fear +  happy &gt; neutral; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>25716010_10</td><td>Neutral &gt; fear +  happy; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>25716010_11</td><td>interactive &gt; individual; socialcommunication</td><td>25716010_analysis_1</td><td>analysis_1</td><td>0.182</td><td>0.882</td><td>0.672</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>25716010_2</td><td>Fear + neutral &gt; happy; socialcommunication</td><td>25716010_analysis_0</td><td>analysis_0</td><td>0.312</td><td>0.389</td><td>0.366</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>25716010_3</td><td>Fear &gt; happy +  neutral; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>25716010_4</td><td>Happy &gt; fear + neutral; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>25716010_5</td><td>Interactive fear &gt; individual fear; socialcommunication</td><td>25716010_analysis_2</td><td>analysis_2</td><td>0.154</td><td>0.500</td><td>0.396</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>25716010_6</td><td>Interactive fear &gt; individual fear +  individual neutral &gt; interactive neutral; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>25716010_7</td><td>Interactive fear &gt; individual fear + interactive happy &gt; individual happy; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>25716010_8</td><td>Interactive fear &gt; individual fear + interactive neutral &gt; individual neutral; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>25716010_9</td><td>Interactive neutral &gt; individual neutral; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25729358</strong> | Pred included: 6 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25729358/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25729358_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;the sender sends a message to the receiver&quot;.</td></tr>
<tr><td>25729358_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;sending a false message with the intention to deceive&quot;.</td></tr>
<tr><td>25729358_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;sophisticated deception through telling the truth&quot; (communicative message exchange).</td></tr>
<tr><td>25729358_analysis_3</td><td>analysis_3</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;delineating the two forms of deception&quot; (differences in communicative strategy).</td></tr>
<tr><td>25729358_analysis_4</td><td>analysis_4</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;genuine truth trials... sender sent the true message with the expectation that the receiver believes her&quot; (communicative exchange).</td></tr>
<tr><td>25729358_analysis_5</td><td>analysis_5</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;parametric analysis modeling the incentive to deceive for simple deception trials&quot; (modulation of communicative deception).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <p>No manual-to-auto match diagnostics for this document.</p>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25911123</strong> | Pred included: 2 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25911123/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25911123_analysis_0</td><td>Response to why &gt; how questions for all stimulus categories</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;photographs of emotional facial expressions&quot;.</td></tr>
<tr><td>25911123_analysis_1</td><td>Stronger response to why &gt; how questions for social than for nonsocial stimuli</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;why &gt; how effect for emotional expressions and intentional actions&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <p>No manual-to-auto match diagnostics for this document.</p>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 25996424</strong> | Pred included: 6 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=1, unmatched=5</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/25996424/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> averted gaze &gt; eye contact; socialcommunication, averted gaze x incongruent &gt; averted  gaze x congruent; socialcommunication, congruent gaze cues &gt; incongruent gaze cues; socialcommunication, eye contact x congruent &gt; averted gaze x congruent; socialcommunication, incongruent gaze cues &gt; congruent gaze cues; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>25996424_analysis_0</td><td>Eye Contact &gt; Averted Gaze</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FP</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;faces depicting eye contact vs. averted gaze&quot;.</td></tr>
<tr><td>25996424_analysis_1</td><td>Averted Gaze &gt; Eye Contact</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;faces looking away from each other vs. faces looking at each other&quot;.</td></tr>
<tr><td>25996424_analysis_2</td><td>Congruent Gaze Cues &gt; Incongruent Gaze Cues</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Congruent Gaze Cues &gt; Incongruent Gaze Cues&quot;.</td></tr>
<tr><td>25996424_analysis_3</td><td>Incongruent Gaze Cues &gt; Congruent Gaze Cues</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Incongruent Gaze Cues &gt; Congruent Gaze Cues&quot;.</td></tr>
<tr><td>25996424_analysis_4</td><td>Eye Contact congruent &gt; Averted Gaze congruent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;congruent trials when faces had depicted eye contact vs. averted gaze&quot;.</td></tr>
<tr><td>25996424_analysis_5</td><td>Averted Gaze incongruent &gt; Averted Gaze congruent</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;incongruent vs. congruent trials when faces had depicted averted gaze&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>25996424_1</td><td>averted gaze &gt; eye contact; socialcommunication</td><td>25996424_analysis_1</td><td>Averted Gaze &gt; Eye Contact</td><td>1.000</td><td>0.019</td><td>0.313</td><td>unmatched</td><td>coord_count_mismatch, low_coord_high_name, low_total_score</td></tr><tr><td>25996424_2</td><td>averted gaze x incongruent &gt; averted  gaze x congruent; socialcommunication</td><td>25996424_analysis_5</td><td>Averted Gaze incongruent &gt; Averted Gaze congruent</td><td>0.961</td><td>0.000</td><td>0.288</td><td>unmatched</td><td>low_coord_high_name, low_total_score, name_only_signal</td></tr><tr><td>25996424_3</td><td>congruent gaze cues &gt; incongruent gaze cues; socialcommunication</td><td>25996424_analysis_2</td><td>Congruent Gaze Cues &gt; Incongruent Gaze Cues</td><td>1.000</td><td>0.224</td><td>0.457</td><td>unmatched</td><td>low_coord_high_name, low_total_score</td></tr><tr><td>25996424_4</td><td>eye contact &gt; averted gaze; socialcommunication</td><td>25996424_analysis_0</td><td>Eye Contact &gt; Averted Gaze</td><td>1.000</td><td>0.450</td><td>0.615</td><td>uncertain</td><td>coord_count_mismatch</td></tr><tr><td>25996424_5</td><td>eye contact x congruent &gt; averted gaze x congruent; socialcommunication</td><td>25996424_analysis_4</td><td>Eye Contact congruent &gt; Averted Gaze congruent</td><td>0.958</td><td>0.118</td><td>0.370</td><td>unmatched</td><td>coord_count_mismatch, low_coord_high_name, low_total_score</td></tr><tr><td>25996424_6</td><td>incongruent gaze cues &gt; congruent gaze cues; socialcommunication</td><td>25996424_analysis_3</td><td>Incongruent Gaze Cues &gt; Congruent Gaze Cues</td><td>1.000</td><td>0.000</td><td>0.300</td><td>unmatched</td><td>low_coord_high_name, low_total_score, name_only_signal</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26235682</strong> | Pred included: 2 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26235682/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26235682_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;received positive and negative reputations from the same and opposite genders&quot;.</td></tr>
<tr><td>26235682_analysis_1</td><td>(Positive &gt; Neutral) inclusively masked with (Negative &gt; Neutral)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;received positive and negative reputations from the same and opposite genders&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <p>No manual-to-auto match diagnostics for this document.</p>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26262561</strong> | Pred included: 1 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26262561/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26262561_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;directional gaze of political personages&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <p>No manual-to-auto match diagnostics for this document.</p>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26365506</strong> | Pred included: 1 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26365506/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26365506_analysis_0</td><td>Self-referential &gt; social</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Contrast does not index social communication measures (e.g., faces &gt; non-faces or explicit communication/reception tasks). Missing local inclusion criteria: SOCIAL_COMMUNICATION_I1, SOCIAL_COMMUNICATION_I2.</td></tr>
<tr><td>26365506_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;This contrast revealed activations in the bilateral TPJ, extending into the extrastriate body area (EBA) and posterior superior temporal sulcus (pSTS)&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <p>No manual-to-auto match diagnostics for this document.</p>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26567160</strong> | Pred included: 3 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26567160/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26567160_analysis_0</td><td>Attitude &gt; Age</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global criteria met and the task involves viewing and evaluating faces (facial communication). Construct evidence span: &quot;evaluate the trustworthiness of faces&quot;.</td></tr>
<tr><td>26567160_analysis_1</td><td>Trust &gt; Age</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Task involves perception of faces and judgments of facial trustworthiness (receptive facial communication). Construct evidence span: &quot;evaluate the trustworthiness of faces&quot;.</td></tr>
<tr><td>26567160_analysis_2</td><td>Distrust &gt; Age</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Contrast involves viewing faces and making social-evaluative judgments (facial communication). Construct evidence span: &quot;evaluate the trustworthiness of faces&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <p>No manual-to-auto match diagnostics for this document.</p>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26803059</strong> | Pred included: 5 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26803059/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26803059_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global inclusion criterion GLOBAL_I2 (group-level whole-brain univariate task-evoked map) cannot be confirmed for this analysis (description ambiguous: &quot;= 10.&quot;). Missing inclusion criteria: GLOBAL_I2.</td></tr>
<tr><td>26803059_analysis_1</td><td>EFE &gt; no EFE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;emotional facial expressions (EFE)&quot;.</td></tr>
<tr><td>26803059_analysis_2</td><td>No EFE &gt; EFE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;absence of EFE&quot; which modulates reception of facial/affective cues.</td></tr>
<tr><td>26803059_analysis_3</td><td>Correlation of differential activation EFE &gt; no EFE with RT reduction by EFE, P &lt; 0.001 (uncorrected); k = 10</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;differential activation EFE &gt; no EFE&quot; (face/affect reception relates to social communication).</td></tr>
<tr><td>26803059_analysis_4</td><td>Correlation of differential activation no EFE &gt; EFE with RT reduction by EFE</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;no EFE &gt; EFE&quot; (modulation of face/affect processing relevant to social communication).</td></tr>
<tr><td>26803059_analysis_5</td><td>analysis_5</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;interaction between affective ToM demand and EFE&quot; (face-driven communication cues).</td></tr>
<tr><td>26803059_analysis_6</td><td>analysis_6</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because this analysis is a PPI (seed-based/effective connectivity), which meets GLOBAL_E2 and is therefore ineligible.</td></tr>
<tr><td>26803059_analysis_7</td><td>analysis_7</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because this analysis is a correlation with PPI effects (seed-based connectivity), which meets GLOBAL_E2 and is therefore ineligible.</td></tr>
<tr><td>26803059_analysis_8</td><td>analysis_8</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because this analysis is a correlation with PPI effects (seed-based connectivity), which meets GLOBAL_E2 and is therefore ineligible.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <p>No manual-to-auto match diagnostics for this document.</p>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26812250</strong> | Pred included: 11 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26812250/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26812250_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Negative vs. positive performance feedback&quot; (auditory social feedback).</td></tr>
<tr><td>26812250_analysis_1</td><td>(A) Emotional empathic (EE) &gt; emotional unempathic (EN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Emotionally empathic comments induced activity...&quot; (processing of auditory verbal empathic statements).</td></tr>
<tr><td>26812250_analysis_2</td><td>(B) Unempathic (EN + CN) &gt; empathic (EE + CE) — boundary: cn)&gt;empathic (ee</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;All unempathic comments combined... processed in left superior temporal gyrus&quot; (auditory/verbal social communication processing).</td></tr>
<tr><td>26812250_analysis_3</td><td>(C) Cognitive unempathic (CN) &gt; cognitive empathic (CE)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Cognitively unempathic comments activated...&quot; (processing of verbal cognitive-empathy statements).</td></tr>
<tr><td>26812250_analysis_4</td><td>(D) Empathic (EE + CE) &gt; high level baseline</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Empathic interventions ... activity in right postcentral gyrus and left cerebellum&quot; (processing of verbal empathic interventions).</td></tr>
<tr><td>26812250_analysis_5</td><td>(E) Emotional empathic (EE) &gt; high level baseline</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Emotionally empathic interventions... activated ... left middle temporal gyrus&quot; (processing auditory/verbal empathic content).</td></tr>
<tr><td>26812250_analysis_6</td><td>(F) Cognitive empathic (CE) &gt; high level baseline</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Cognitively empathic interventions... responded in right postcentral gyrus and left cerebellum&quot; (processing of verbal paraphrasing/cognitive empathy).</td></tr>
<tr><td>26812250_analysis_7</td><td>(A) Emotional (EE + EN) &gt; cognitive (CE + CN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;All emotional interventions... activated left and right superior temporal gyrus&quot; (auditory/verbal social communication differences).</td></tr>
<tr><td>26812250_analysis_8</td><td>(B) Emotional empathic (EE) &gt; cognitive empathic (CE)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Emotionally empathic interventions (EE &gt; CE) resulted in activity in the mOFC&quot; (differential processing of verbal empathic content).</td></tr>
<tr><td>26812250_analysis_9</td><td>(C) Emotional unempathic (EN) &gt; cognitive unempathic (CN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Emotionally unempathic interventions (EN &gt; CN) activated left/right superior temporal gyrus&quot; (auditory/verbal processing of unempathic statements).</td></tr>
<tr><td>26812250_analysis_10</td><td>(D) Cognitive unempathic (CN) &gt; emotional unempathic (EN)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Cognitively unempathic interventions (CN &gt; EN) activated right MFG&quot; (differential processing of verbal unempathic statements).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <p>No manual-to-auto match diagnostics for this document.</p>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26892859</strong> | Pred included: 1 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26892859/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26892859_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;videos of posers expressing positive, negative, and neutral statements&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <p>No manual-to-auto match diagnostics for this document.</p>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 26908320</strong> | Pred included: 2 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=6</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/26908320/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Black &gt; White faces: A. Increased activation with less differentiation disparity; socialcommunication, Black &gt; White faces: A. Increased activation with less racial trust disparities; socialcommunication, Black &gt; White faces: A. Increased activation with more differentiation disparity; socialcommunication, Black &gt; White faces: A. Increased activation with more racial trust disparities; socialcommunication, Black &gt; White faces: B. Increassed connectivity with dorsolateral prefrontal seed (24, 42, 21) with less differentiation disparity; socialcommunication, Black &gt; White faces: B. Increased connectivity with orbitofrontal cortex (18, 66, 0) with less racial trust disparity; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>26908320_analysis_0</td><td>Black &gt; White faces: covariate analyses (racial trust disparity)</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;viewing Black and White faces&quot;.</td></tr>
<tr><td>26908320_analysis_1</td><td>Covariate analyses: racial differentiation disparity predicted by neural response to Black &gt; White faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;viewing Black and White faces&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>26908320_1</td><td>Black &gt; White faces: A. Increased activation with less differentiation disparity; socialcommunication</td><td>26908320_analysis_1</td><td>Covariate analyses: racial differentiation disparity predicted by neural response to Black &gt; White faces</td><td>0.468</td><td>0.000</td><td>0.140</td><td>unmatched</td><td>low_total_score, missing_coords_on_one_side</td></tr><tr><td>26908320_2</td><td>Black &gt; White faces: A. Increased activation with less racial trust disparities; socialcommunication</td><td>26908320_analysis_0</td><td>Black &gt; White faces: covariate analyses (racial trust disparity)</td><td>0.699</td><td>0.000</td><td>0.210</td><td>unmatched</td><td>low_total_score, missing_coords_on_one_side, name_only_signal</td></tr><tr><td>26908320_3</td><td>Black &gt; White faces: A. Increased activation with more differentiation disparity; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>26908320_4</td><td>Black &gt; White faces: A. Increased activation with more racial trust disparities; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>26908320_5</td><td>Black &gt; White faces: B. Increassed connectivity with dorsolateral prefrontal seed (24, 42, 21) with less differentiation disparity; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>26908320_6</td><td>Black &gt; White faces: B. Increased connectivity with orbitofrontal cortex (18, 66, 0) with less racial trust disparity; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29324862</strong> | Pred included: 18 | Manual included (accepted matches only): 0 | Correct overlaps: 0 | Match statuses: accepted=0, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29324862/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29324862_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;haptic cues used to convey a partner’s intentions&quot;.</td></tr>
<tr><td>29324862_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;haptic interaction ... dynamic social communication&quot;.</td></tr>
<tr><td>29324862_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;haptic channel ... allows individuals to coordinate their actions&quot;.</td></tr>
<tr><td>29324862_analysis_3</td><td>analysis_3</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;haptic cues ... dynamic social communication&quot;.</td></tr>
<tr><td>29324862_analysis_4</td><td>analysis_4</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;haptic exchange ... interpersonal coordination&quot;.</td></tr>
<tr><td>29324862_analysis_5</td><td>analysis_5</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Leading ... convey forces to partner; Following ... respond to haptic cues&quot;.</td></tr>
<tr><td>29324862_analysis_6</td><td>analysis_6</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;a haptic information channel that allows individuals to coordinate their actions&quot;.</td></tr>
<tr><td>29324862_analysis_7</td><td>analysis_7</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;STG and pSTS involvement in transforming sensory info into temporally-organized motor actions and social motion perception&quot;.</td></tr>
<tr><td>29324862_analysis_8</td><td>analysis_8</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;cerebellum and lateral cerebellum in error correction and coordination during partnered movement&quot;.</td></tr>
<tr><td>29324862_analysis_9</td><td>analysis_9</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;IFG and STG involvement in signaling and transforming sensory info for partner coordination&quot;.</td></tr>
<tr><td>29324862_analysis_10</td><td>analysis_10</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;aIPL and SPL involved in sensorimotor mapping of self and other during partnered movement&quot;.</td></tr>
<tr><td>29324862_analysis_11</td><td>analysis_11</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;exchange of haptic cues and signalling intentions between partners&quot;.</td></tr>
<tr><td>29324862_analysis_12</td><td>analysis_12</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;nucleus accumbens and caudate involved in outcome monitoring and social reward during Following/Mutual&quot;.</td></tr>
<tr><td>29324862_analysis_13</td><td>analysis_13</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;IFG and PMC involved in action signalling and coordination with partner&quot;.</td></tr>
<tr><td>29324862_analysis_14</td><td>analysis_14</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;exchange of forces and haptic signals to guide partner movement&quot;.</td></tr>
<tr><td>29324862_analysis_15</td><td>analysis_15</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;STG (area Spt) transforms sensory information into temporally-organized motor actions for partner coordination&quot;.</td></tr>
<tr><td>29324862_analysis_16</td><td>analysis_16</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;ventral striatum (nucleus accumbens) activity linked to social reward during mutual interaction&quot;.</td></tr>
<tr><td>29324862_analysis_17</td><td>analysis_17</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because this contrast (improvisation/self-initiation) is not primarily a social-communication task; missing inclusion criteria: SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>29324862_analysis_18</td><td>analysis_18</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because improvisation contrasts here are not directly measuring social communication processes. Missing inclusion criteria: SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>29324862_analysis_19</td><td>analysis_19</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because the contrast is not a social communication task per se; missing inclusion criteria: SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>29324862_analysis_20</td><td>analysis_20</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because this analysis focuses on improvisation and motor generation rather than social communication processes. Missing inclusion criteria: SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>29324862_analysis_21</td><td>analysis_21</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because cerebellar improvisation coordinate is not a social-communication metric; missing inclusion criteria: SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>29324862_analysis_22</td><td>analysis_22</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because this improvisation/self-initiation frontal analysis is not a social-communication task. Missing inclusion criteria: SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>29324862_analysis_23</td><td>analysis_23</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because this parietal improvisation/self-initiation analysis is not assessing social communication processes. Missing inclusion criteria: SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>29324862_analysis_24</td><td>analysis_24</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;search for areas associated with signalling movement intentions to a partner&quot;.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <p>No manual-to-auto match diagnostics for this document.</p>
  </details>
  
  
</details>
</details></section><section id="bucket-false-negative"><details class="bucket" open><summary><h2>False Negative (7)</h2></summary><p><strong>Match status totals:</strong> accepted=12 | uncertain=9 | unmatched=15</p>
<details class="doc-card">
  <summary><strong>PMID 15528097</strong> | Pred included: 0 | Manual included (accepted matches only): 1 | Correct overlaps: 0 | Match statuses: accepted=1, uncertain=0, unmatched=4</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/15528097/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Embarrassment &gt; Neutral; socialcommunication, Embarrassment &gt; guilt; socialcommunication, Guilt &gt; Embarrassment; socialcommunication, Guilt &gt; Neutral; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>15528097_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Analysis does not measure social communication (no face or gaze or communicative signal processing contrasts). Missing inclusion criteria: SOCIAL_COMMUNICATION_I1, SOCIAL_COMMUNICATION_I2.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>15528097_1</td><td>Embarrassment &gt; Neutral; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>15528097_2</td><td>Embarrassment &gt; guilt; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>15528097_3</td><td>G &gt; N masked E &gt; N; socialcommunication</td><td>15528097_analysis_0</td><td>analysis_0</td><td>0.214</td><td>1.000</td><td>0.764</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>15528097_4</td><td>Guilt &gt; Embarrassment; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr><tr><td>15528097_5</td><td>Guilt &gt; Neutral; socialcommunication</td><td></td><td></td><td>0.000</td><td>0.000</td><td>0.000</td><td>unmatched</td><td>unassigned_by_global_matching, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 18501639</strong> | Pred included: 0 | Manual included (accepted matches only): 2 | Correct overlaps: 0 | Match statuses: accepted=2, uncertain=0, unmatched=6</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/18501639/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Face (simple effect) [Ff–Sf]; socialcommunication, Face (simple effect) [Sf+Ff–2Cf masked by Sf–Cf, and Ff–Cf]; socialcommunication, Face (simple effect) [Sf–Ff]; socialcommunication, Main effect [(Ff+Fn)–(Sf+Sn) masked by Ff–Sf and Fn–Sn]; socialcommunication, Main effect [(Sf+Ff+Sn+Fn)–2(Cf+Cn) masked by Sf–Cf, Ff–Cf, Sn–Cn, and Fn–Cn]; socialcommunication, Name (simple effect) [Sn+Fn–2Cn masked by Sn–Cn, and Fn–Cn]; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>18501639_analysis_0</td><td>Main effect [(Sf + Sn)-(Ff + Fn) masked by Sf-Ff and Sn-Fn]; ROI Face: S &gt; C, S &gt; F</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Excluded because the contrast does not directly measure Social Communication (missing inclusion criteria SOCIAL_COMMUNICATION_I2).</td></tr>
<tr><td>18501639_analysis_1</td><td>Main effect [(Sf + Sn)-(Ff + Fn) masked by Sf-Ff and Sn-Fn]; ROI Face: S &gt; C, S &gt; F; ROI Name: C &gt; S, C &gt; F</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Excluded because the contrast does not directly measure Social Communication (missing inclusion criteria SOCIAL_COMMUNICATION_I2).</td></tr>
<tr><td>18501639_analysis_2</td><td>Main effect [(Sf + Sn)-(Ff + Fn) masked by Sf-Ff and Sn-Fn]; ROI Face: C &gt; F, S &gt; F</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Excluded because the contrast does not directly measure Social Communication (missing inclusion criteria SOCIAL_COMMUNICATION_I2).</td></tr>
<tr><td>18501639_analysis_3</td><td>Main effect [(Sf + Sn)-(Ff + Fn) masked by Sf-Ff and Sn-Fn]; ROI Face: S &gt; C, S &gt; F</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Excluded because the contrast does not directly measure Social Communication (missing inclusion criteria SOCIAL_COMMUNICATION_I2).</td></tr>
<tr><td>18501639_analysis_4</td><td>analysis_4</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Excluded because the contrast does not directly measure Social Communication (missing inclusion criteria SOCIAL_COMMUNICATION_I2).</td></tr>
<tr><td>18501639_analysis_5</td><td>analysis_5</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Excluded because the contrast does not directly test Social Communication processes (missing inclusion criteria SOCIAL_COMMUNICATION_I2).</td></tr>
<tr><td>18501639_analysis_6</td><td>analysis_6</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because the contrast indexes familiarity (self+friend vs unfamiliar) rather than Social Communication per se (missing inclusion criteria SOCIAL_COMMUNICATION_I2).</td></tr>
<tr><td>18501639_analysis_7</td><td>Common activation to self and friend, relative to unfamiliar person: S &gt; C, F &gt; C</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Excluded because the contrast indexes familiarity rather than Social Communication processes (missing inclusion criteria SOCIAL_COMMUNICATION_I2).</td></tr>
<tr><td>18501639_analysis_8</td><td>analysis_8</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because the contrast indexes familiarity rather than Social Communication processes (missing inclusion criteria SOCIAL_COMMUNICATION_I2).</td></tr>
<tr><td>18501639_analysis_9</td><td>analysis_9</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because the contrast indexes familiarity rather than Social Communication processes (missing inclusion criteria SOCIAL_COMMUNICATION_I2).</td></tr>
<tr><td>18501639_analysis_10</td><td>analysis_10</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because the contrast indexes familiarity rather than Social Communication processes (missing inclusion criteria SOCIAL_COMMUNICATION_I2).</td></tr>
<tr><td>18501639_analysis_11</td><td>analysis_11</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Excluded because the contrast indexes familiarity rather than Social Communication processes (missing inclusion criteria SOCIAL_COMMUNICATION_I2).</td></tr>
<tr><td>18501639_analysis_12</td><td>analysis_12</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because the contrast indexes familiarity rather than Social Communication processes (missing inclusion criteria SOCIAL_COMMUNICATION_I2).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>18501639_1</td><td>Face (simple effect) [Ff–Sf]; socialcommunication</td><td>18501639_analysis_5</td><td>analysis_5</td><td>0.211</td><td>0.667</td><td>0.530</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>18501639_2</td><td>Face (simple effect) [Sf+Ff–2Cf masked by Sf–Cf, and Ff–Cf]; socialcommunication</td><td>18501639_analysis_1</td><td>Main effect [(Sf + Sn)-(Ff + Fn) masked by Sf-Ff and Sn-Fn]; ROI Face: S &gt; C, S &gt; F; ROI Name: C &gt; S, C &gt; F</td><td>0.644</td><td>0.000</td><td>0.193</td><td>unmatched</td><td>low_total_score, name_only_signal</td></tr><tr><td>18501639_3</td><td>Face (simple effect) [Sf–Ff]; socialcommunication</td><td>18501639_analysis_0</td><td>Main effect [(Sf + Sn)-(Ff + Fn) masked by Sf-Ff and Sn-Fn]; ROI Face: S &gt; C, S &gt; F</td><td>0.368</td><td>0.250</td><td>0.285</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>18501639_4</td><td>Face specific (interaction) [(Sf+Ff–2Cf)–(Sn+Fn–2Cn) masked by Sf+Ff–2Cf]; socialcommunication</td><td>18501639_analysis_11</td><td>analysis_11</td><td>0.095</td><td>1.000</td><td>0.729</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>18501639_5</td><td>Face specific (interaction) [(Sf–Ff)–(Sn–Fn) masked by Sf–Ff]; socialcommunication</td><td>18501639_analysis_4</td><td>analysis_4</td><td>0.113</td><td>1.000</td><td>0.734</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>18501639_6</td><td>Main effect [(Ff+Fn)–(Sf+Sn) masked by Ff–Sf and Fn–Sn]; socialcommunication</td><td>18501639_analysis_2</td><td>Main effect [(Sf + Sn)-(Ff + Fn) masked by Sf-Ff and Sn-Fn]; ROI Face: C &gt; F, S &gt; F</td><td>0.737</td><td>0.000</td><td>0.221</td><td>unmatched</td><td>coord_count_mismatch, low_total_score, name_only_signal</td></tr><tr><td>18501639_7</td><td>Main effect [(Sf+Ff+Sn+Fn)–2(Cf+Cn) masked by Sf–Cf, Ff–Cf, Sn–Cn, and Fn–Cn]; socialcommunication</td><td>18501639_analysis_7</td><td>Common activation to self and friend, relative to unfamiliar person: S &gt; C, F &gt; C</td><td>0.257</td><td>0.333</td><td>0.310</td><td>unmatched</td><td>low_total_score</td></tr><tr><td>18501639_8</td><td>Name (simple effect) [Sn+Fn–2Cn masked by Sn–Cn, and Fn–Cn]; socialcommunication</td><td>18501639_analysis_3</td><td>Main effect [(Sf + Sn)-(Ff + Fn) masked by Sf-Ff and Sn-Fn]; ROI Face: S &gt; C, S &gt; F</td><td>0.593</td><td>0.000</td><td>0.178</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23378834</strong> | Pred included: 7 | Manual included (accepted matches only): 2 | Correct overlaps: 0 | Match statuses: accepted=2, uncertain=9, unmatched=1</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23378834/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> Novel landmarks &gt; Famous faces; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23378834_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;person memory&quot;.</td></tr>
<tr><td>23378834_analysis_1</td><td>Faces &gt; Landmarks</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Faces vs. Landmarks&quot;.</td></tr>
<tr><td>23378834_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because the analysis description does not specify a face or social-communication contrast (e.g., Faces &gt; non-faces); missing local inclusion criterion SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>23378834_analysis_3</td><td>analysis_3</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TN</span></td><td></td><td>Excluded because the analysis description does not specify a face or social-communication contrast; missing local inclusion criterion SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>23378834_analysis_4</td><td>analysis_4</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because no face vs non-face or other social-communication contrast is specified; missing local inclusion criterion SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>23378834_analysis_5</td><td>Landmarks &gt; Faces</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because the contrast is not a face &gt; non-face contrast and instead privileges landmarks; missing local inclusion criterion SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>23378834_analysis_6</td><td>analysis_6</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TN</span></td><td></td><td>Excluded because no face vs non-face or social-communication contrast is specified; missing SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>23378834_analysis_7</td><td>Famous faces &gt; Novel faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Famous faces &gt; Novel faces&quot;.</td></tr>
<tr><td>23378834_analysis_8</td><td>analysis_8</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TN</span></td><td></td><td>Excluded because the analysis description does not specify a face or social-communication contrast; missing SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>23378834_analysis_9</td><td>Novel faces &gt; Famous faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Novel faces&quot;.</td></tr>
<tr><td>23378834_analysis_10</td><td>analysis_10</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TN</span></td><td></td><td>Excluded because no face or social-communication contrast is specified in the description; missing SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>23378834_analysis_11</td><td>Novel faces &gt; Novel landmarks</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Novel faces vs. novel landmarks&quot;.</td></tr>
<tr><td>23378834_analysis_12</td><td>analysis_12</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TN</span></td><td></td><td>Excluded because no face vs non-face contrast or social-communication task is specified; missing SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>23378834_analysis_13</td><td>Novel landmarks &gt; Novel faces</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because the contrast is not a face &gt; non-face comparison and does not measure social communication; missing SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>23378834_analysis_14</td><td>analysis_14</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TN</span></td><td></td><td>Excluded because no face vs non-face contrast is specified in the description; missing SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>23378834_analysis_15</td><td>Famous faces &gt; Novel landmarks</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Famous faces &gt; Novel landmarks&quot;.</td></tr>
<tr><td>23378834_analysis_16</td><td>analysis_16</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TN</span></td><td></td><td>Excluded because no face vs non-face or similar social-communication contrast is specified; missing SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>23378834_analysis_17</td><td>Novel landmarks &gt; Famous faces</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Excluded because the contrast is not a face &gt; non-face comparison that would measure social communication; missing SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>23378834_analysis_18</td><td>analysis_18</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because the description does not specify a face or social-communication contrast; missing SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>23378834_analysis_19</td><td>analysis_19</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because the regions listed correspond to place processing and not face/social communication; missing SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>23378834_analysis_20</td><td>analysis_20</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because the entry lists low-level visual regions and lacks a face/social-communication contrast; missing SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>23378834_analysis_21</td><td>Famous landmarks &gt; Novel landmarks</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Excluded because the contrast does not involve faces or social communication; missing SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>23378834_analysis_22</td><td>Novel landmarks &gt; Famous landmarks</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Excluded because the contrast does not involve faces or social communication; missing SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>23378834_analysis_23</td><td>analysis_23</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TN</span></td><td></td><td>Excluded because no face vs non-face contrast is specified in the description; missing SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>23378834_analysis_24</td><td>Familiar faces &gt; Novel faces</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">-</span></td><td></td><td>Global and local inclusion criteria are met for this construct. Construct evidence span: &quot;Facesfriends vs. Facesnovel&quot;.</td></tr>
<tr><td>23378834_analysis_25</td><td>analysis_25</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-good">TN</span></td><td></td><td>Excluded because the description does not specify a face or social-communication contrast; missing SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>23378834_analysis_26</td><td>analysis_26</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Excluded because the description does not indicate a face vs non-face or social-communication contrast; missing SOCIAL_COMMUNICATION_I1.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23378834_1</td><td>Faces &gt; Landmarks; socialcommunication</td><td>23378834_analysis_3</td><td>analysis_3</td><td>0.296</td><td>0.688</td><td>0.570</td><td>uncertain</td><td>coord_count_mismatch</td></tr><tr><td>23378834_10</td><td>Novel landmarks &gt; Famous faces; socialcommunication</td><td>23378834_analysis_17</td><td>Novel landmarks &gt; Famous faces</td><td>1.000</td><td>0.100</td><td>0.370</td><td>unmatched</td><td>coord_count_mismatch, low_coord_high_name, low_total_score</td></tr><tr><td>23378834_11</td><td>Novel landmarks &gt; Famous landmarks; socialcommunication</td><td>23378834_analysis_23</td><td>analysis_23</td><td>0.222</td><td>0.889</td><td>0.689</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>23378834_12</td><td>Novel landmarks &gt; Novel faces; socialcommunication</td><td>23378834_analysis_14</td><td>analysis_14</td><td>0.250</td><td>0.857</td><td>0.675</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>23378834_2</td><td>Familiar faces &gt; Novel faces; socialcommunication</td><td>23378834_analysis_25</td><td>analysis_25</td><td>0.167</td><td>0.833</td><td>0.633</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>23378834_3</td><td>Famous faces &gt; Novel faces; socialcommunication</td><td>23378834_analysis_8</td><td>analysis_8</td><td>0.175</td><td>0.800</td><td>0.613</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>23378834_4</td><td>Famous faces &gt; Novel landmarks; socialcommunication</td><td>23378834_analysis_16</td><td>analysis_16</td><td>0.195</td><td>0.933</td><td>0.712</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>23378834_5</td><td>Famous landmarks &gt; Novel landmarks; socialcommunication</td><td>23378834_analysis_21</td><td>Famous landmarks &gt; Novel landmarks</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>23378834_6</td><td>Famous ∩ Familiar faces; socialcommunication</td><td>23378834_analysis_26</td><td>analysis_26</td><td>0.235</td><td>1.000</td><td>0.771</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>23378834_7</td><td>Landmarks &gt; Faces; socialcommunication</td><td>23378834_analysis_6</td><td>analysis_6</td><td>0.370</td><td>0.857</td><td>0.711</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>23378834_8</td><td>Novel faces &gt; Famous faces; socialcommunication</td><td>23378834_analysis_10</td><td>analysis_10</td><td>0.216</td><td>0.750</td><td>0.590</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr><tr><td>23378834_9</td><td>Novel faces &gt; Novel landmarks; socialcommunication</td><td>23378834_analysis_12</td><td>analysis_12</td><td>0.200</td><td>0.833</td><td>0.643</td><td>uncertain</td><td>coord_count_mismatch, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 23722983</strong> | Pred included: 0 | Manual included (accepted matches only): 3 | Correct overlaps: 0 | Match statuses: accepted=3, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/23722983/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>23722983_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Local inclusion criteria not met: missing SOCIAL_COMMUNICATION_I1 and SOCIAL_COMMUNICATION_I2.</td></tr>
<tr><td>23722983_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Local inclusion criteria not met: missing SOCIAL_COMMUNICATION_I1 and SOCIAL_COMMUNICATION_I2.</td></tr>
<tr><td>23722983_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Local inclusion criteria not met: missing SOCIAL_COMMUNICATION_I1 and SOCIAL_COMMUNICATION_I2.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>23722983_1</td><td>Buzz effect; socialcommunication</td><td>23722983_analysis_2</td><td>analysis_2</td><td>0.143</td><td>1.000</td><td>0.743</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>23722983_2</td><td>Intention effect; socialcommunication</td><td>23722983_analysis_0</td><td>analysis_0</td><td>0.170</td><td>1.000</td><td>0.751</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>23722983_3</td><td>Salesperson effect; socialcommunication</td><td>23722983_analysis_1</td><td>analysis_1</td><td>0.286</td><td>1.000</td><td>0.786</td><td>accepted</td><td>exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 28477977</strong> | Pred included: 1 | Manual included (accepted matches only): 1 | Correct overlaps: 0 | Match statuses: accepted=1, uncertain=0, unmatched=4</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/28477977/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  <p><strong>Unmatched manual analyses:</strong> group &gt; no laughter; socialcommunication, group &gt; single laughter; socialcommunication, self &gt; other; socialcommunication, single &gt; no laughter; socialcommunication</p>
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>28477977_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>The contrast (SELF minus OTHER) indexes self-related processing rather than social communication; missing local inclusion criterion SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>28477977_analysis_1</td><td>analysis_1</td><td class="decision-cell"><span class="decision-pill decision-include">+</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>This contrast involves auditory social signals (laughter) and meets criteria for social communication (receptive auditory stimuli). Construct evidence span: &quot;Group minus No laughter&quot;.</td></tr>
<tr><td>28477977_analysis_2</td><td>analysis_2</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>This interaction reflects action-outcome contingency and striatal reward signals rather than communication-specific receptive/expressive processing; missing local inclusion criterion SOCIAL_COMMUNICATION_I1.</td></tr>
<tr><td>28477977_analysis_3</td><td>analysis_3</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Excluded because one or more global exclusion criteria apply (seed-based connectivity/PPI analysis).</td></tr>
<tr><td>28477977_analysis_4</td><td>analysis_4</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-na">UNMATCHED</span></td><td></td><td>Excluded because one or more global exclusion criteria apply (seed-based connectivity/PPI analysis).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>28477977_1</td><td>SELFGroup−SELFNo &gt; OTHER Group–OTHERNo; socialcommunication</td><td>28477977_analysis_2</td><td>analysis_2</td><td>0.116</td><td>1.000</td><td>0.735</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr><tr><td>28477977_2</td><td>group &gt; no laughter; socialcommunication</td><td>28477977_analysis_3</td><td>analysis_3</td><td>0.160</td><td>0.026</td><td>0.066</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr><tr><td>28477977_3</td><td>group &gt; single laughter; socialcommunication</td><td>28477977_analysis_0</td><td>analysis_0</td><td>0.121</td><td>0.000</td><td>0.036</td><td>unmatched</td><td>low_total_score, missing_coords_on_one_side</td></tr><tr><td>28477977_4</td><td>self &gt; other; socialcommunication</td><td>28477977_analysis_1</td><td>analysis_1</td><td>0.140</td><td>0.000</td><td>0.042</td><td>unmatched</td><td>low_total_score, missing_coords_on_one_side</td></tr><tr><td>28477977_5</td><td>single &gt; no laughter; socialcommunication</td><td>28477977_analysis_4</td><td>analysis_4</td><td>0.133</td><td>0.021</td><td>0.055</td><td>unmatched</td><td>coord_count_mismatch, low_total_score</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 28931014</strong> | Pred included: 0 | Manual included (accepted matches only): 2 | Correct overlaps: 0 | Match statuses: accepted=2, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/28931014/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>28931014_analysis_0</td><td>Fingerspelling &gt; Letter</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Although fingerspelling is communicative, this analysis probes phonological maintenance (working memory) rather than social communication measures (receptive/expressive social signals). Missing local inclusion criteria: SOCIAL_COMMUNICATION_I1, SOCIAL_COMMUNICATION_I2.</td></tr>
<tr><td>28931014_analysis_1</td><td>Letter &gt; Fingerspelling (modality-specific activations during maintenance)</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Although letters and fingerspelling are communicative forms, this analysis probes phonological maintenance (working memory) rather than social communication measures (receptive/expressive social signals). Missing local inclusion criteria: SOCIAL_COMMUNICATION_I1, SOCIAL_COMMUNICATION_I2.</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>28931014_1</td><td>Fingerspelling &gt; Letter; socialcommunication</td><td>28931014_analysis_0</td><td>Fingerspelling &gt; Letter</td><td>1.000</td><td>1.000</td><td>1.000</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr><tr><td>28931014_2</td><td>Letter &gt; Fingerspelling; socialcommunication</td><td>28931014_analysis_1</td><td>Letter &gt; Fingerspelling (modality-specific activations during maintenance)</td><td>0.576</td><td>1.000</td><td>0.873</td><td>accepted</td><td>exact_coord_set, high_coord_match</td></tr></tbody></table></div>
  </details>
  
  
</details>


<details class="doc-card">
  <summary><strong>PMID 29039129</strong> | Pred included: 0 | Manual included (accepted matches only): 1 | Correct overlaps: 0 | Match statuses: accepted=1, uncertain=0, unmatched=0</summary>
  <p><a href="https://pubmed.ncbi.nlm.nih.gov/29039129/" target="_blank" rel="noopener noreferrer">PubMed full text page</a></p>
  
  
  <details class="inner-accordion" open>
    <summary>Parsed analyses and annotation reasoning</summary>
    <div class="table-wrap">
      <table>
        <thead>
          <tr>
            <th>Analysis ID</th>
            <th>Parsed Analysis Name</th>
            <th>Model Decision</th>
            <th>Matched Outcome</th>
            <th>Tags</th>
            <th>Model Reasoning</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>29039129_analysis_0</td><td>analysis_0</td><td class="decision-cell"><span class="decision-pill decision-exclude">-</span></td><td class="confusion-cell"><span class="confusion-pill confusion-bad">FN</span></td><td>manual+ (accepted)</td><td>Excluded because local inclusion criteria are not met: analysis does not target social communication (faces/emotion reception or production) contrasts (missing SOCIAL_COMMUNICATION_I1, SOCIAL_COMMUNICATION_I2).</td></tr>
        </tbody>
      </table>
    </div>
  </details>
  <details class="inner-accordion" open>
    <summary>Manual-to-Auto Match Diagnostics</summary>
    <div class="table-wrap"><table><thead><tr><th>Manual ID</th><th>Manual Name</th><th>Matched Auto ID</th><th>Matched Auto Name</th><th>Name Score</th><th>Coord Score</th><th>Combined</th><th>Status</th><th>Reason Codes</th></tr></thead><tbody><tr><td>29039129_1</td><td>Incongruent &gt; Congruent; socialcommunication</td><td>29039129_analysis_0</td><td>analysis_0</td><td>0.148</td><td>1.000</td><td>0.744</td><td>accepted</td><td>accepted_exact_coord_override, exact_coord_set, high_coord_match, low_name_with_exact_coords</td></tr></tbody></table></div>
  </details>
  
  
</details>
</details></section>
  
</body>
</html>
