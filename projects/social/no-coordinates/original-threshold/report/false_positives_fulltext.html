<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>False Positives at Fulltext Stage</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        .study {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 20px;
            margin-bottom: 20px;
            background-color: #f9f9f9;
        }
        .metadata, .screening, .content {
            margin-bottom: 15px;
            padding: 10px;
            border-left: 3px solid #3498db;
        }
        .metadata {
            border-left-color: #3498db;
        }
        .screening {
            border-left-color: #e74c3c;
        }
        .content {
            border-left-color: #2ecc71;
        }
        strong {
            color: #2c3e50;
        }
        .study-list {
            margin-top: 20px;
        }
        footer {
            margin-top: 40px;
            text-align: center;
            font-size: 0.9em;
            color: #7f8c8d;
        }
        
        /* Accordion styles */
        .accordion {
            background-color: #f1f1f1;
            color: #444;
            cursor: pointer;
            padding: 10px;
            width: 100%;
            border: none;
            text-align: left;
            outline: none;
            font-size: 14px;
            font-weight: bold;
            margin-top: 10px;
            margin-bottom: 10px;
            border-radius: 4px;
        }
        .accordion:hover {
            background-color: #ddd;
        }
        .accordion:after {
            content: ' \25BC'; /* Down arrow */
            font-size: 10px;
            color: #777;
            float: right;
        }
        .accordion.active:after {
            content: ' \25B2'; /* Up arrow */
        }
        .panel {
            padding: 0 18px;
            background-color: white;
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.2s ease-out;
            border: 1px solid #ddd;
            border-top: none;
            border-radius: 0 0 4px 4px;
        }
        .panel-content {
            padding: 15px;
        }
        .fulltext-content {
            white-space: pre-wrap;
            font-family: monospace;
            font-size: 12px;
            line-height: 1.4;
        }
    </style>
</head>
<body>
<script>
    function toggleAccordion(btn) {
        btn.classList.toggle("active");
        var panel = btn.nextElementSibling;
        if (panel.style.maxHeight) {
            panel.style.maxHeight = null;
        } else {
            panel.style.maxHeight = panel.scrollHeight + "px";
        }
    }
</script>
<h1>False Positives Papers at Fulltext Stage</h1>
<p>Total papers: 25</p>
<div class='study-list'>
<div class='study' id='study-1'>
<h2>1. PMID: 19620621</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> The Selectivity and Functional Connectivity of the Anterior Temporal Lobes</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Cereb Cortex</p>
<p><strong>Publication Year:</strong> 2009</p>
<p><strong>DOI:</strong> 10.1093/cercor/bhp149</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study that explicitly investigates person/social conceptual processing (fact-learning about people vs. buildings/hammers). Participants are healthy adults aged 20–32 (within 18–60). Imaging used whole-brain EPI coverage and whole-brain random-effects analyses and conjunctions; results and functional connectivity maps are reported across the brain (not ROI-only). The study is an original empirical fMRI study (not a review) and does not involve clinical or psychiatric populations. Therefore it meets all inclusion criteria and violates no exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
One influential account asserts that the anterior temporal lobe (ATL) is a domain-general hub for semantic memory. Other evidence indicates it is part of a domain-specific social cognition system. Arbitrating these accounts using functional magnetic resonance imaging has previously been difficult because of magnetic susceptibility artifacts in the region. The present study used parameters optimized for imaging the ATL, and had subjects encode facts about unfamiliar people, buildings, and hammers. Using both conjunction and region of interest analyses, person-selective responses were observed in both the left and right ATL. Neither building-selective, hammer-selective nor domain-general responses were observed in the ATLs, although they were observed in other brain regions. These findings were supported by “resting-state” functional connectivity analyses using independent datasets from the same subjects. Person-selective ATL clusters were functionally connected with the brain's wider social cognition network. Rather than serving as a domain-general semantic hub, the ATLs work in unison with the social cognition system to support learning facts about others. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (53824 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
It is now generally accepted that the representation of knowledge in the human brain depends on broadly distributed neural circuits that are differentiated by conceptual categories and their associated perceptual, motor, and affective properties ( ;  ;  ). At least 2 important questions remain unresolved, however. The first is whether a property-based model of the conceptual system is sufficient to support all conceptual phenomena (see   for a discussion of these issues). The second pertains to the systemic architecture linking these property regions. 

Recently, semantic hub models have grown in influence by offering answers to both of these questions ( ;  ). With regard to the first, these models assert that property circuits are necessary, but not sufficient to support conceptual knowledge; that in addition to property regions one must posit the presence of an amodal, domain-general representational hub. With regard to the second question, these models assert that the anterior temporal lobe is the domain-general hub through which property regions are connected. 

The anterior temporal lobes are regarded as the likely location of the semantic hub, largely on the basis of evidence from semantic dementia patients. Semantic dementia, a variant of frontotemporal dementia, is a progressive degenerative disorder characterized by damage to the anterior temporal lobes in its earliest stages, followed by widespread deterioration in more posterior temporal and frontal cortices ( ). Semantic dementia patients typically exhibit impaired performance on a variety of semantic memory tests across multiple categories of knowledge, whereas other cognitive abilities remain relatively intact ( ;  ;  ). Recent studies have shown that deficits in semantic dementia are more highly correlated with pathology along the lateral surface of the anterior temporal lobes, as compared with more medial temporal cortex ( ;  ;  ). 

Upon closer review, however, the neuropsychological evidence for an anterior temporal hub is not so clear as it might first appear. First, the pathology in semantic dementia is not restricted to the anterior temporal lobes. The pathology often extends up into frontal cortex (Hodges and Patterson 2007; Brambati et al. 2009). In addition, voxel-based morphometry demonstrates that semantic memory impairments in semantic dementia patients are as strongly correlated with pathology in the posterior fusiform as to pathology in the anterior temporal lobe ( ). Second, resection of the temporal lobes to treat intractable epilepsy does not lead to the catastrophic, domain-general semantic memory deficits one might predict if this region is the seat of conceptual knowledge ( ). Proponents of an anterior temporal hub argue that this simply reflects the fact that the surgery removes abnormal tissue that no longer serves its normal function due to pathology-related reorganization. Although this is undoubtedly true ( ), it is not, however, as if the surgery or damage to this region is without cognitive consequences. Anterior temporal resection, or damage due to conditions such as herpes encephalitis, is often associated with significant episodic memory deficits, as well as notable domain-specific semantic impairments typically including recognizing and naming famous and familiar people ( ;  ;  ;  ;  ;  ,  ;  ; Tsukiura et al. 2003). These findings suggest that the anterior temporal lobes support person-specific knowledge, with the left hemisphere being relatively more important for person naming. 

Given its prominent role in semantic hub models, one would expect a veritable mountain of neuroimaging evidence that the anterior temporal lobes are involved in conceptual processing. Significantly, the majority of imaging studies, whether using positron emission tomography (PET) or functional magnetic resonance imaging (fMRI), have not observed anterior temporal lobe activation during conceptual processing. Instead most find posterior temporal or frontal cortex activations (see  ;  ). To the extent that anterior temporal activation is observed during conceptual processing, it is usually in the context of social conceptual processing tasks ( , forthcoming; for review see  ) along with the medial prefrontal cortex (PFC), the posterior superior temporal sulcus (pSTS), the amygdala, and the precuneus; regions that are widely regarded as the brain's social cognition network ( ). For example, the anterior temporal lobe is frequently activated by theory of mind tasks ( ), as well as to famous and familiar faces (Sergent and Signoret 1992;  ;  ;  ;  ;  ;  ;  ;  ). The findings of   are of particular interest to the present study as they used a verbal fact recall task and observed that activity in the left anterior temporal lobe reflects recall of associations between names and faces, whereas right anterior temporal activity reflects recall of faces and person-related semantic information. 

Aside from the processing of social concepts, functional neuroimaging evidence for anterior temporal lobe involvement in conceptual processing has been inconsistent. Although this would seem to be a major challenge to the model, proponents of anterior temporal hub accounts cite 2 reasons for this dearth of evidence. First is the claim that fMRI is blind to the anterior temporal lobes ( ,  ). Relative to other brain regions, image quality in the anterior temporal lobes is degraded due to distortions of the magnetic field caused by air–tissue interfaces. Hub proponents have often addressed this problem by using PET imaging, which does not suffer from the same signal deficits, but with spatial resolution that is 2 to 3 times lower than that of most fMRI studies. Indeed, some PET studies have provided support for anterior temporal hub accounts by demonstrating anterior temporal activations during conceptual processing ( ;  ,  ;  ;  ;  ;  ). Additionally, a parallel literature has developed showing activation of the ATLs during sentence-level processing using both reading and auditory–verbal stimuli ( ;  ,  ;  ;  ;  ;  ,  ;  ). These studies often report that the ATL is activated for syntactically correct versus incorrect sentences that control for semantic content, thus indicating a potential role for the ATLs in the representation of syntax. 

A second argument put forth for why imaging studies of conceptual processing often do not find anterior temporal activation is that they employ tasks that require subjects to process concepts at a level that is too general to engage the region, or because they compare categories at different levels of specificity. By this account, the aforementioned person-knowledge effects in the anterior temporal lobes do not reflect social information processing per se, but rather the comparison of specific classification (e.g., famous faces) with more general classification (e.g., nonfamous faces, animals, tools) ( ;  ). 

Hub accounts claim that the anterior temporal lobes are the seat of human conceptual knowledge, storing amodal conceptual representations, irrespective of category. On the other hand, a different account asserts that the anterior temporal lobes are domain-specific and involved in the representation of person knowledge. Based on the issues and controversies described so far, directly testing these 2 accounts requires: 1) an fMRI study with adequate signal quality in the anterior temporal lobes; 2) processing of multiple object categories, at least one of which is people; 3) each processed at the same level of specificity; 4) with the same type of information across categories; and 5) a nonconceptual control condition. 

To meet these requirements, we used fMRI scan parameters optimized for imaging the anterior temporal lobes to study subjects while they learned facts about 4 different unfamiliar and unique people, places, and hammers, or performed a nonconceptual control task, in this case a Riser Letter Detection task. In the scanner, subjects were presented only written sentences describing the age, location, and occupation/usage of the people, places, and hammers, ensuring that all categories were processed at the same level of specificity and with the same types of information (e.g., see  ). If the anterior temporal lobes serve as a hub for domain-general conceptual processing, then we should expect to find anterior temporal lobe regions that respond equally to all 3 categories over and above the nonconceptual Riser Letter Detection Task control condition. If on the other hand the anterior temporal lobes are part of a domain-specific social information processing network, then we should expect to find anterior temporal regions that exhibit reliably greater activation for person information as compared with either building or hammer information. Additionally, if the social information processing account of the anterior temporal lobes is correct, then we should also expect that any person-selective regions in the anterior temporal lobes will exhibit reliable functional connectivity with the previously well-described social-processing circuit distributed throughout the brain. To test this last prediction, subjects also underwent a low-level Vigilance Task scan before performing the Fact Encoding Task scans. During this scan, subjects simply pressed a button whenever they saw a fixation mark change color, which occurred approximately once a minute. With this independent data set we were able to evaluate the entrained “resting-state” functional connectivity of the anterior temporal lobes. 
  
Examples of stimuli 
    

## Materials and Methods 
  
### Participants 
  
Twelve right-handed, native English-speaking volunteers were paid for their participation (7 females; age range, 20–32 years). All subjects completed health questionnaires and none reported a history of head injury or other neurological problems. In accordance with the National Institutes of Health Institutional Review Board protocols, all subjects read and signed informed consent documents. 


### Experimental Design 
  
Subjects performed 3 tasks while undergoing fMRI. During the first functional scanning run, subjects performed a simple Vigilance Task. In the subsequent 3 scanning runs, participants performed alternating blocks of the Fact-Learning Task and the Riser Detection Task. 

#### Person-Building-Hammer Fact-Learning Task 
  
Subjects were instructed to remember facts described by short sentences presented in black font against a white background. Each sentence described a fact about 4 unique but novel persons, buildings, or hammers, each labeled with a different proper name (see   for example stimuli). For each unique exemplar, subjects learned an age, location, and usage/occupation fact (e.g., “the gilbert building is forty-five years old”; “the gilbert building is located in baton rouge”; “the gilbert building is used for community meetings”). Our decision to have subjects learn the same attributes about the 3 different categories’ exemplars was motivated by our desire to have subjects process the 3 categories at the same level of specificity and using similar types of information. We believe this is important because hub proponents have claimed that greater item specificity leads to greater anterior temporal lobe activation ( ;  ). In addition, the stimulus sentences were balanced across categories for average number of words and letters per sentence. 

During the task instruction period prior to entering the scanner, subjects were presented with photographs of each unique entity and given its name but no other information. At the conclusion of the instruction period, subjects were again shown the photographs and asked to recall each exemplar's name. Subjects who were unable to recall the correct name upon seeing its photograph were given extra time to study the photo and learn the corresponding name. 

In the scanner, subjects only saw sentences; no pictures were presented. In each 18-s Fact-Learning Task block, subjects read sentences describing the 3 facts for a particular exemplar, each presented for 6-seconds. The presentation orders of sentences describing the individual exemplars were varied within and between categories, and presentation orders of the age, location, and usage/occupation facts were randomized within each block. Subjects were shown the 3 facts about an exemplar once during each run and 3 times over the course of the experiment. 

After being removed from the scanner, subjects were asked to first recall the critical information for each fact learned while in the scanner. They were presented with the same sentences they read in the scanner, but with the critical fact replaced with a blank space (e.g., “the gilbert building is located in _________”). After completing the recall trials, subjects were given a forced-choice recognition test for all facts. 


#### Entrained “Resting-State”/Vigilance Task 
  
To evaluate functional connectivity, we chose to use a simple vigilance task because it provides images of the brain's functional connectivity in a more constrained context than the typical “resting-state” scan, whereas keeping the subjects’ information processing load to a minimum. In the vigilance task subjects fixated a cross in the center of a grey background and pressed a button anytime the fixation mark changed colors (mean interchange duration = 60 s, range 30–90 s). These data provided an independent data set for exploring the functional connectivity of brain regions activated in the subsequent Fact-Learning Task scanning runs. 


#### Riser Detection Task 
  
Riser Detection letter strings were constructed by scrambling the letters used in the Fact-Learning Task, and contained the same number of spaces as the text strings in the Fact-Learning Task. By doing so, we controlled for the amounts of visual stimulation and visual scanning between the 2 tasks. There were 13 Riser Detection blocks in each scanning run. In each 18-s Riser Detection Task block subjects saw 3 letter strings, presented individually for 6 s in black font against a white background. The subjects’ task was to count the number of “riser letters” in nonword letter strings and press a button on a response box held in the right hand if the total was an odd number. Subjects were instructed that the letters b, d, f, h, k, l, and t are riser letters because they each have some portion that rises up above the tops of most other lower-case letters. This task is a modified version of the “feature detection task” used by  . 



### Imaging Details 
  
Stimuli were back-projected onto a screen at the head of the scanner and viewed by subjects via a mirror mounted on the head coil. Stimulus presentation and response collection both during scanning and the recall and recognition tests were controlled using Eprime (  www.pstnet.com  ). 

During the Vigilance Task scanning run, 140 echoplanar MR volumes depicting blood oxygenation level dependant (BOLD) contrast were collected with a 3T General Electric scanner. In each echoplanar image (EPI) volume 42 contiguous 3-mm thick slices were collected in the axial plane, ensuring whole-brain coverage (echo time [TE] = 27 ms, repetition time [TR] = 3500 ms, flip angle = 90°, voxel size = 2.3 mm × 2.3 mm × 3 mm). The 3 Fact-Learning Task runs used the same volume parameters, although 143 volumes were collected per run. High-resolution structural images were collected as the first and last scans in each session (TE = 6 ms, TR = 25 ms, flip angle = 15°, voxel size = 0.9 mm × 0.9 mm × 1.2 mm). A General Electric 8-channel send-receive head coil was used for all functional and structural scanning runs, with a SENSE factor of 2 used to minimize EPI distortions in anterior temporal regions while also reducing gradient coil heating over the course of the scan session. As demonstrated by measurements of temporal signal-to-noise (the ratio of the average signal intensity to the signal standard deviation), signal quality in the anterior temporal lobes was very good (see  ). 
  
Temporal signal-to-noise ratio (TSNR) maps showing EPI image quality over the anterior temporal lobes. The color gradient indicates the TSNR of the smoothed EPI time course data overlaid on the AFNI Talairach N27 atlas brain. TSNR was calculated by dividing the mean signal intensity at a voxel by the standard deviation of its signal time course. The color map is thresholded at a TSNR of 40, with all areas in red indicating a TSNR of at least 200. Simulations indicate that a TSNR of 40 (indicated in the map by light blue) is the minimum to reliably detect effects between conditions in fMRI data (Murphy et al. 2007). Note that virtually all of the anterior temporal lobes far exceed this threshold, with many anterior temporal regions exceeding a TSNR of 200. 
  
Prior to statistical analyses, image preprocessing was conducted using the AFNI software package ( ). The first MP–RAGE anatomical scan was coregistered to the second MP–RAGE, and the 2 were then averaged to produce a single high-quality anatomical image of the subject's brain. Next, each subject's EPI volumes were coregistered to the 130th volume of the final EPI scanning run, and smoothed in the axial plane with an isotropic 6-mm full width half max Gaussian kernel. Following application of slice time correction, and removal of the first 3 volumes from each run, EPI signal intensity measurements at each time point were normalized to reflect the percent signal change from the voxel's signal time course mean. 


### fMRI Statistical Analyses 
  
Multiple regression was used to analyze the Fact-Learning Task data. The regression model included one regressor for each of the 3 fact categories (people, buildings, and hammers) with the Riser Detection Task periods composing the signal baseline. The 3 task regressors were constructed by convolving a box-car function with a width of 18-s beginning at the onset of a condition's blocks with a gamma-variate function to adjust the predictor variable for the delay and shape of the BOLD response. In addition, regressors of no interest were included to account for each run's signal mean, linear, quadratic, and cubic signal trends, as well as 6 motion parameters (3 translations and 3 rotations). 

Subjects’ beta maps for each condition were then transformed to Talairach space, and resampled to a 2-mm isotropic resolution. Finally, a repeated measures random effects ANOVA was used on the aggregated group data to evaluate differences between conditions at the population-level. 

We used the conjunction analysis methods described by   to identify regions where the activity patterns across conditions conformed to domain-specific and domain-general response patterns. A domain-specific response was defined as a cluster of activity where a particular condition exhibited reliably greater activity than each of the other Fact-Learning Task conditions. For example, to qualify as a person-selective region, each voxel in a cluster of activity had to satisfy 2 separate statistical tests: person > building AND person > hammer. Because this conjunction assumes a particular directionality, each of the individual tests were thresholded at   P   < 0.05 one-tailed within the 3 regions of interest (ROIs) described below, and at   P   < 0.005 one-tailed outside the ROIs. As described by  , the conservative estimate of the probability of a conjunction is the   P  -value associated with the minimum statistic among the conjoined tests, which in this case is   P   < 0.05 one-tailed in the ROIs and   P   < 0.005 one-tailed outside the ROIs. To implement corrections for multiple comparisons at the   P   < 0.05 level, we used Monte Carlo simulations implemented in AFNI's AlphaSim to identify the required cluster-size threshold, given the voxel-wise probability and the volume in the statistical map (see below) separately for each of the tests in a conjunction. Because the clusters of activity for each test in a conjunction were corrected for multiple comparisons, and should thus be regarded as reliable, so too can the intersections between the clusters. Nevertheless, because it is possible that small areas of intersection between clusters from different statistical tests could be induced by spatial smoothing and resampling, we applied a small cluster-size threshold of at least 10 voxels (defined in the original scanning resolution) on all areas of conjunction. 

In contrast to the domain-specific clusters, domain-general clusters were defined as regions where responses for all 3 categories were reliably greater than the Riser Detection Task, but where activity did not differ between categories in the Fact-Learning Task. To this end, we used conjunction analyses similar to those used to identify domain-specific clusters. First we identified regions where each of the categories in the Fact-Learning Task responded reliably above the Riser Detection Task with a   P  -value of 0.05 one-tailed in the ROIs and   P  -value of 0.005 one-tailed outside the ROIs, again with each test corrected separately for multiple comparisons at the   P   < 0.05 level using cluster-size correction (see below). Importantly, the conjunction probability for domain-general clusters was equal to the conjunction probability of the domain-specific clusters. Finally, to remove regions showing a bias toward a particular category, a mask was applied to the data to remove all regions exhibiting a difference with   P   < 0.25 between any 2 categories in the Fact-Learning Task. Again, as with the domain-specific regions, a cluster-size threshold of at least 10 voxels was applied to all areas of conjunction to ameliorate concerns that smoothing or resampling induced the observed domain-general clusters. 

There were 3 region of interest volumes used in the cluster-size threshold calculations: the anterior temporal lobes, the posterior middle temporal gyrus, and the parahippocampal gyrus. The anterior temporal lobes were defined as all areas in the temporal lobes anterior to the limen insula ( ; located at approximately   y   = 3 in the left hemisphere and   y   = 5 in the right hemisphere of the AFNI Talairach N27 atlas brain). This ROI included only temporal cortex, and did not include any portion of the amygdala. Within the volume of this region, defined bilaterally, a cluster-size threshold for individual tests among the conditions was determined to be at least 1056 mm  (132 resampled voxels sharing at least one edge). The posterior middle temporal gyrus between   y   = −40 and   y   = −69 was selected as a ROI given its association with tool processing (for review see  ). Within this region, the cluster-size threshold was determined to be at least 1216 mm  (152 voxels sharing at least one edge). The parahippocampal gyrus was also selected as a ROI given its association with location representation ( ;  ). Within this region, the cluster-size threshold was determined to be at least 992 mm  (124 voxels sharing at least one edge). Finally, outside these 3 ROIs, clusters of activity had to exceed a size threshold defined by the volume of the brain minus the volumes of the 3 ROIs, rendering a cluster-size threshold of at least 848 mm  (106 voxels sharing at least one edge). (The cluster size threshold for the regions outside the ROIs is smaller than the cluster size threshold within the ROIs because the   P  -value threshold outside the 3 ROIs is more stringent by an order of magnitude;   P   < 0.05 vs.   P   < 0.005.) 

Functional connectivity analyses were implemented on the subjects’ Vigilance Task scanning run, with seed voxels determined by the highest average   t  -values across the statistical contrasts used in the group conjunction analyses. The connectivity analyses proceeded in the following manner. First, at the subject-level, multiple regression was used to model the run's signal mean, linear, quadratic, and cubic signal trends, as well as 6 motion parameter regressors. In addition, the average signal time course from the subject's ventricles was included to further account for global signal changes. The residual time course for each voxel was then used in the subsequent analyses. Time course residuals for the anterior temporal lobe seed voxels were then used as predictors in separate regression analyses, to produce a map of the correlations between each voxel in the brain and a given seed voxel. These   r  -values were then converted to   Z  -values using Fisher's   r  -to-  Z   transformation. Next, the subjects’   Z  -maps were included in a random effects, one-sample t-test to identify voxels whose means differed from zero with   P   < 0.0005. Finally, these statistical maps were corrected for multiple comparisons at the   P   < 0.05 level by applying a cluster-size threshold of at least 296 mm  (37 voxels sharing at least one edge). The resulting maps show brain regions where activity across subjects was reliably correlated with a seed-voxel's time course while subjects performed the Vigilance Task scanning run, a dataset that was independent of the Fact Encoding Task scanning runs. 



## Results 
  
### Behavioral Results 
  
Responses to color change events in the Vigilance Task were quick and accurate (RT: M = 614 ms, SD = 159 ms; detection accuracy: M = 70%, SD = 22%). In contrast, subjects found it difficult to provide responses on the Riser Detection Task within the allotted time for each trial (RT: M = 4768 ms, SD = 130 ms; detection accuracy: M = 26%, SD = 13%, responses occurring earlier than 2 standard deviations from the response mean were filtered out, as were responses occurring later than the 6-second trial duration). The riser detection accuracy scores reflect the fact that subjects had to perform the task under significant time constraints, rather than indicating that they were performing the task poorly. The letter strings presented to subjects were rather long because they were constructed by scrambling the fact-learning sentences, and as a result it was difficult for subjects to provide responses before the stimuli disappeared from the screen. 

After scanning, subjects demonstrated good recall of the information presented during the Fact-Learning Task (Person fact recall: M = 72%, SD = 17%; Building: M = 63%, SD = 17%; Hammer: M = 65%, SD = 21%). Although subjects recalled more person facts than building facts,   t  (11) = 4.31,   P   < 0.005, person and hammer fact recall were equivalent,   t  (11) = 1.13,   P   = 0.28, as was recall of building and hammer facts,   t  (11) = 0.38,   P   = 0.71. As with recall, recognition performance was good for all categories (Person fact recognition: M = 87%, SD = 17%; Building: M = 77%, SD = 17%; Hammer: M = 74%, SD = 24%). Although subjects recognized more person facts than hammer facts,   t  (11) = 2.55,   P   < 0.05, person and building fact recognition were not reliably different, t(11) = 1.88,   P   = 0.09, nor were recognition of building and hammer facts,   t  (11) = 0.49,   P   = 0.63. 


### The Anterior Temporal Lobes are Engaged while Acquiring Person Knowledge 
  
Two lateral anterior temporal regions exhibited person-selective responses (  A  ,  ). The 2 clusters, located bilaterally in homologous locations in the temporal pole and superior temporal gyri, responded more during person-fact encoding than during building-fact or hammer-fact encoding. Aside from these 2 regions, there were no other category-selective responses in the anterior temporal lobes. To demonstrate the robustness of the person-selective effects to a different voxel selection strategy ( ), and to assess whether statistical mapping was even necessary to observe person-selective responses in this region, we used an anatomical region of interest approach to examine the average response across all voxels in the anterior temporal lobe ROIs for each of the 3 conditions. As can be seen in   B  , person-fact encoding produced greater activation than either building- or hammer-fact encoding across the entirety of the left and right anterior temporal lobes, but no differences were observed between buildings and hammers (left anterior temporal: person > building,   t  (11) = 1.95, one-tailed   P   = 0.04; person > hammer,   t  (11) = 2.27, one-tailed   P   = 0.02; building versus hammer,   t  (11) = 0.65, 2-tailed   P   = 0.53; right anterior temporal: person > building,   t  (11) = 2.10, one-tailed   P   = 0.03; person > hammer,   t  (11) = 2.75, one-tailed   P   = 0.01; building versus hammer,   t  (11) = 1.14, 2-tailed   P   = 0.29). 
  
Anterior temporal lobe activations 
      
Person-selective responses in the anterior temporal lobes. (  A  ) person-selective clusters in the anterior temporal lobes identified using conjunction analyses. The rendered surfaces show the person-selective clusters in the left and right hemispheres where person > building AND person > hammer with   P   < 0.05 and cluster-size corrected for the volume of the anterior temporal lobes. (  B  ) Activity in the anterior temporal lobe ROIs. The rendered surfaces show the extent of the anterior temporal ROIs in the left and right hemispheres. The bar graphs demonstrate the average percent signal change across subjects in the left and right anterior temporal ROIs relative to the nonconceptual (riser detection) control task. In both ROIs, the responses to person-fact encoding were reliably greater than the responses to building- or hammer-fact encoding. Responses during building- and hammer-fact encoding were not different from each other. Error bars on bar charts in both panels indicate ±1 standard error of the subject means. 
  
No domain-general responses were observed anywhere in the anterior temporal lobes. In other words, there were no regions in the anterior temporal lobes where activity was equivalent for person, building, and hammer fact learning and where these 3 conditions produced reliably greater activation than the Riser Detection Task, our nonsemantic control condition. 


### Fact Encoding Effects Outside the Anterior Temporal Lobes 
  
Although the current experiment's focus is the function of the anterior temporal lobes, domain-specific and domain-general responses were observed in other brain regions ( ). 
  
Domain-specific and domain-general responses outside the anterior temporal lobes indentified using conjunction analyses. Domain-general responses (shown in gold) were observed in various regions outside the anterior temporal lobes, including the left inferior and superior frontal gyri, the left middle temporal gyrus, and the hippocampus. A hammer-selective cluster (shown in blue) was observed in the left middle temporal gyrus (L pMTG) immediately posterior to a domain-general cluster. More medially, building-selective clusters (shown in green) were observed in left and right middle occipital gyri. Person-selective clusters (shown in red) were observed along the midline in the medial PFC and the precuneus, among other regions. All clusters are corrected for multiple comparisons. 
  
#### Domain-Specific Encoding Effects 
  
Outside the anterior temporal lobes, person-selective encoding effects were observed in regions commonly implicated in social processing, including the medial PFC, precuneus and posterior cingulate, and the right pSTS. In addition, the superior parietal lobule was also activated bilaterally, as was the left insula (see  ). Contrary to our prediction, place-selective effects were not observed in the parahippocampal gyrus. Instead, large areas of place-selective activity were observed bilaterally in the lingual, cuneus, and middle occipital gyri, as well as the right cerebellum. Finally, as predicted, hammer-selective activity was observed in the left posterior middle temporal gyrus. 
  
Domain-specific and domain-general activations outside the anterior temporal lobes 
    

#### Domain-General Encoding Effects 
  
Although domain-general encoding effects were not observed in the anterior temporal lobes, other brain regions did exhibit these effects (see  ). For example, a large area of domain-general activation was observed to stretch from the left inferior frontal gyrus into the middle frontal gyrus. Additionally, domain-general activation was observed in the left hippocampus, the left middle temporal gyrus, left angular gyrus, and the right cerebellum. 



### Functional Connectivity: Anterior Temporal Person-Selective Regions are Part of the Wider Social Cognitive Network 
  
Further support for the person-selective nature of the anterior temporal lobes comes from functional connectivity analyses using independent data sets. We used the Vigilance Task scanning runs to examine the functional connectivity with the peak activations in the left and right anterior temporal person-selective clusters identified in the Fact-Learning Task. The left anterior temporal person-selective cluster was functionally connected with brain regions frequently implicated in social cognition, including the medial PFC, the pSTS, the amygdala, and the precuneus/posterior cingulate bilaterally, and in the left lateral portion of the fusiform gyrus ( ). In addition to the other social-processing regions, activity in the left anterior temporal person-selective cluster was tightly coupled with activity in the corresponding region in the right anterior temporal lobe. Finally, activity in the left anterior temporal person-selective region was correlated with activity in regions known to support more general information processing, including the left inferior frontal gyrus and the left hippocampus (see   Supplemental Table 1   for a complete list of regions functionally connected with the left anterior temporal seed voxel). As with the left hemisphere, activity in the right anterior temporal person-selective cluster was correlated with activity in regions previously implicated in social processing, including the medial PFC bilaterally, the amygdala bilaterally, the left posterior cingulate/precuneus, the left fusiform gyrus, and the left anterior temporal lobe ( ). In addition, this region was functionally connected with a host of more general information processing areas, including the left inferior frontal gyrus, the left perirhinal cortex, and the superior frontal gyrus bilaterally (see   Supplemental Table 2   for complete list). 
  
The person-selective clusters in the anterior temporal lobes are functionally connected with the wider social cognition network. Color overlays indicate clusters of functional connectivity with the anterior temporal seed voxels measured in the independent Vigilance Task scanning run. The left and right anterior temporal seed voxels were identified as those voxels in each hemisphere with the highest average   t  -value for the person > building and person > hammer   t  -maps in the Fact-Learning Task scanning runs. The depicted functional connectivity   t  -maps were obtained as follows. First, for each subject a Pearson correlation map was constructed showing correlation between each voxel and an anterior temporal seed voxel. Second, these   r  -maps were converted to   Z   score maps. Finally, these   Z  -maps were included in a random effects, one-sample   t  -test to identify voxels whose means differed from zero with   P   < 0.0005 and cluster-size corrected for multiple comparisons across the whole brain at   P   < 0.05. 
  


## Discussion 
  
### Person-Selectivity in the Anterior Temporal Lobes 
  
In the present study the anterior temporal lobes exhibited strong category-selectivity while subjects learned facts about people, relative to building- and hammer facts. The person-selective responses in the conjunction analyses were observed in nearly identical anterolateral regions of the superior temporal gyri and temporal poles in the 2 hemispheres. Domain-general effects were not observed in the anterior temporal lobes, although they were found in other brain regions, including the hippocampus and left inferior frontal gyrus. The absence of domain-general anterior temporal effects in our data cannot be due to poor signal quality because we observed statistically reliable clusters of activity in the lateral anterior temporal cortex, the anterior temporal region with the highest temporal signal-to-noise ratios in the present data ( ), and the area predicted to be the domain-general semantic hub based on pathology in semantic dementia ( ;  ;  ). 

Eschewing cluster mapping altogether, we evaluated separately for each hemisphere the average response of the entire temporal lobes anterior to the limen insula. Even when using this gross anatomical-ROI approach, the anterior temporal lobes responded selectively when encoding information about people. In both hemispheres, the response profile was highly person-specific, with little difference in the responses to buildings and hammers. 

The conjunction analysis was an extremely conservative measure requiring significantly greater activity for the person-fact learning than building-fact learning and greater activity for the person-fact learning than hammer-fact learning. Additionally, each of these tests independently had to reach significance after correction for multiple comparisons. The fact that we replicated the person-fact selectivity in the ROI analysis, which aggregated activity across the entire anterior temporal lobe, demonstrates the robustness of this effect. Including all the voxels in the anterior temporal lobe did not wash out the statistically reliable categorical effects observed in the conjunction analysis. 

The findings of the cluster-mapping and anatomical-ROI analyses were further strengthened by the functional connectivity profiles of the anterior temporal lobes, with the present study being the first to describe the functional connectivity of this region. The anterior temporal person-selective clusters, identified in the Fact-Learning Task scans, were found to be functionally connected with virtually the entire social cognition network, as measured during the independent Vigilance-Task scan. The functional connectivity findings reported here agree with tracer studies in the macaque, where strong anatomical connectivity is observed between the temporal pole and the amygdala, superior temporal gyrus, area TE (potential monkey homologue of human fusiform gyrus), and the medial frontal cortex ( ;  ). 

Given the results of the conjunction analyses, the anterior temporal ROI analyses, and the functional connectivity analyses on independent data, we can be confident that the person-selectivity observed in the anterior temporal lobes was not a product of the particular statistical-mapping procedure, or the particular task, or the particular stimuli presented to subjects, or even the particular seed voxel within the anterior temporal lobe. Rather the results appear to reflect this region's underlying function and connectivity within a network supporting social cognition. 


### Social Conceptual Processing in the Anterior Temporal Lobes 
  
Recently,   reported activation of the anterior superior temporal gyrus when subjects made meaning-relatedness judgments for social concepts. In the present study, the person-specific effects in the anterior temporal lobe stretched from the middle temporal gyrus up into the superior temporal gyrus. Given the differences in the paradigms and stimuli, it is remarkable how much agreement exists between our findings, and those reported by  . 

Zahn and colleagues observed a reliable difference between social and animal concepts in the superior temporal gyrus, with much weaker effects of each condition versus fixation in the middle temporal gyrus. They speculate that there may exist an inferior–superior gradient for multisensory versus abstract person-specific knowledge, with the former located in middle temporal gyrus, and the latter located in the superior temporal gyrus. Although this is one explanation for these findings, it is not the only explanation. Alternatively, it could be that the anterior temporal lobes are relatively more responsive to animate than inanimate entities, with the superior temporal gyrus being particularly responsive for human-animate attributes (such as the social abstract concepts used by Zahn et al.). By this account, we observed more inferior middle temporal activity, in addition to the superior temporal activity, because we compared animate to inanimate entities (e.g., people vs. buildings and hammers). This account also finds support in the both our ROI analyses using the entirety of the anterior temporal lobes, and in the functional connectivity findings, which showed correlated spontaneous fluctuations between our anterior temporal lobe person-selective regions and the wider social/animacy network. 

Yet another possibility is that in Zahn and colleagues’ data the signal quality might be poorer in middle temporal gyrus than in superior temporal gyrus. Zahn and colleagues only observed middle temporal activity in statistical comparisons that presumably have much higher contrast-to-noise ratios, namely the social and animal concepts versus a simple fixation baseline. Note, however, that this contrast does not control for many nonconceptual differences between the task performed by subjects (e.g., reading words and making meaning-relatedness judgments) and the fixation baseline condition. By this account, we may have observed more inferior effects, in addition to the superior temporal effects, because of better signal quality over this region (e.g., see   and refer to Imaging Details section). 

Although we are not certain which of the above-described explanations account for the differences between our findings and those reported by Zahn and colleagues, we strongly believe that the overall findings of the 2 studies exhibit significant agreement and are mutually supportive. 


### Person-Selectivity in the Anterior Temporal Lobes Does Not Simply Reflect Encoding Effort 
  
Given that subjects generally remembered more person facts than building or hammer facts, one might argue that the person selectivity in the anterior temporal lobes simply reflects encoding effort. There are at least 5 arguments against this account. First, not all brain regions responded selectively for person-fact encoding. Indeed, as just described, many regions responded selectively to other categories. This suggests that there was not a general encoding effort effect for the person facts. Second, regions such as the left inferior frontal gyrus and the hippocampus that would be expected to show a task difficulty or encoding effort effect do not exhibit selectivity for person-fact encoding, but rather responded in a domain-general fashion (e.g., responded equally to all categories). Third, given that we have much more experience learning new information about people, relative to buildings and hammers, it seems unlikely that one would find more activation for learning person facts relative to the other categories if the activity in this region is driven by encoding effort. Fourth, better person fact recall (vs. building fact recall) or recognition (vs. hammer fact recognition) does not guarantee differences between conditions at encoding. The recall and recognition differences could be entirely mediated by storage or retrieval processes. Finally, and perhaps most convincingly, using independent, non-task-related data we observed functional connectivity between the person-selective clusters in the anterior temporal lobes and the wider social cognition network, a finding that strongly supports our interpretation that the activation observed in this area reflects its role in social cognition, not encoding effort. 


### Domain-Specificity Outside the Anterior Temporal Lobes 
  
Outside the anterior temporal lobes, we observed other domain-specific effects. Encoding hammer facts selectively engaged a posterior region of the left middle temporal gyrus. This finding was predicted a priori, given that the region is consistently activated during conceptual processing of tool categories and tool-related verbs using both pictorial and linguistic stimuli (e.g.,  ;  ; for recent reviews see  ;  ;  ). Large place-selective responses occurred bilaterally in the cuneus and up into middle occipital gyrus. This region, near the transverse occipital sulcus, has been previously implicated in scene perception, navigation, and the representation of large-scale features (such as buildings) in the visual environment ( ;  ;  ). Finally, in addition to the anterior temporal lobes, learning facts about people elicited category-selective responses in other social cognition regions. Person-selective responses were observed in the medial PFC, a region that supports mentalizing about others’ mental states ( ;  ); the right pSTS, a region commonly implicated in the perception and conceptualization of biological motion ( ,  ); and the precuneus, a region implicated in social perspective-taking and representation of the self ( ). 


### Domain-General Responses 
  
We found no evidence for a domain-general hub in the anterior temporal lobes. This does not mean however that hub theories in general are incorrect. Rather, it only means that if a domain-general representational hub exists in the brain, it is not in the anterior temporal lobes. In fact, we did find domain-general areas. One region was a large area in left frontal cortex stretching from the inferior frontal gyrus up to the middle frontal gyrus. Based on findings from earlier research, this region serves as a control-center for conceptual processing, guiding retrieval and postretrieval selection of property information stored in posterior cortex, irrespective of category ( ;  ;  ). Similarly, domain-general responses were observed in the hippocampus, a region long known to support the acquisition of new knowledge ( ). It is unlikely that either of these regions serve as representational hubs in the sense previously attributed to the anterior temporal lobes. For example, although damage to the left inferior frontal gyrus results in word-finding deficits, it does not disrupt conceptual knowledge per se ( ;  ;  ). Similarly, although damage to the hippocampus greatly affects new learning, it does not result in conceptual deficits for previously acquired knowledge ( ). 

We also observed domain-general responses in the left middle temporal gyrus (immediately anterior to the domain-specific “hammer” cluster), the left angular gyrus, and the right cerebellum, all regions shown previously to be engaged when subjects learn new facts and associations ( ;  ). Of these regions, the left middle temporal gyrus may be of particular interest in future studies, as it is often implicated in domain-general conceptual processing ( ;  ). 


### Conceptual Processing during the Fact-Learning Task 
  
Semantic memory/conceptual processing involves retrieving information about objects and words that is not immediately available in a stimulus itself. This is perhaps most easily recognized in the case of conceptual processing for words, where the word itself is merely an arbitrary symbol, and so understanding its meaning necessarily requires attributions and inferences about the word's referent. A bedrock principle in cognitive psychology is that reading words automatically activates word meaning (e.g., consider the ubiquity of Stroop effects). Thus, reading the sentence stimuli in our task engaged our subjects’ conceptual systems. Given this, we simply needed to ensure that they actually read the sentence stimuli. To accomplish this we told subjects to remember the information they learned because their memory would be tested at the end of the study. 

Our task allowed us to directly compare 3 familiar categories for which subjects had a great deal of previously acquired conceptual knowledge, while being reasonably certain that subjects processed the categories at the same level of specificity and with the same amount of knowledge about the specific exemplars presented in the scanner. Although the specific exemplars were unfamiliar, subjects’ comprehension of the sentence stimuli meant that the task engaged retrieval of pre-existing category-knowledge. Good evidence for this comes from the neuroanatomical distribution of the activations we observed. Consider the person-fact learning condition. Learning facts about specific peoples’ occupations, ages, and places of birth activated regions previously demonstrated to represent biological motion (posterior STS;  ,  ), mentalizing about other's mental states (medial PFC;  ;  ), and social perspective-taking and representation of the self (precuneus;  ). The facts learned by subjects about a particular person did not contain references to that person's physical motions, their mental states, or social interactions, and thus these activations are neural signatures of conceptual inferences about the exemplars. Similarly, the hammer facts never described the hammers in motion, yet we can deduce that subjects were engaged in conceptual inference about the hammer exemplars because we observed activation in a region of the middle temporal gyrus known to represent nonbiological (tool) motion ( ). These activations further strengthen our confidence that the fact-learning task was successful at engendering conceptual processing, and warrants our claims about the anterior temporal lobe's role in conceptual processing. 

Because all 3 conditions required fact learning, comparisons among the categories should cancel-out domain-general conceptual processes, leaving only domain-specific conceptual processes. Now, in light of this, consider the claims of the domain-general semantic hub account, which asserts that the anterior temporal lobes are the domain-general hub of the human conceptual system irrespective of the task context through which conceptual information is accessed. In fact, hub models explicitly claim that the anterior temporal semantic hub is engaged in any and all varieties of conceptual processing tasks (e.g., see  ). If this is correct, then we should have observed greater anterior temporal lobe activation for all categories compared to the nonsemantic control task, and equivalent activations for all categories in our task. We did not. This leaves us with only 2 options. The first option is that the anterior temporal lobes are domain-specific for person knowledge during sentence comprehension, but the same tissue is domain-general in other task contexts (perhaps after consolidation from the hippocampus to the neocortex), and also exhibiting strong functional connectivity with the wider social cognition network. The second option is that the anterior temporal lobes are domain-specific for person knowledge regardless of the conceptual processing context, and also strongly functionally connected to the wider social cognition circuit. Option one assumes a remarkable switch in domain selectivity from one task context to another, and we can think of no evidence for such a switch either in the anterior temporal lobe or indeed anywhere else in the brain. Option 2 is also a more parsimonious account. 



## Conclusion 
  
Rather than serving as a domain-general conceptual hub, the anterior temporal lobes appear to support person knowledge. Using both typical statistical-mapping approaches, as well as gross anatomical-ROI analyses, we observed person-selectivity in both the left and right anterior temporal lobes. Further, in independent data sets these regions were functionally connected with the social cognition network. Future studies should seek to better understand the information content within the anterior temporal lobes. In this regard, it is important to note that there exists both neuropsychological and neuroimaging evidence that this regions plays a critical role in the representation of unique entities ( ;  ;  ;  ). The present study compared responses among different categories of unique entities, rather than between unique and nonunique entities. As such, it will be important for future studies to clarify the relationship between the unique entity findings, and the results reported here. 

More generally, the findings reported here help to clarify the architecture of the human conceptual system. As demonstrated in many earlier studies, conceptual knowledge is supported by a widely distributed network of property regions that represent in part the content of conceptual representations, as well as auxiliary regions such as the hippocampus and left inferior frontal gyrus that support memory acquisition and retrieval processes generally. The precise architecture of this system, namely the nodes through which regions are functionally connected, remains an important and controversial question. In the present study, no evidence was obtained in support of the claim that the anterior temporal lobe is a domain-general representational hub. Rather, the findings strongly suggest that the anterior temporal lobe is a component in a network supporting an important class of knowledge: social concepts ( ). Describing how the components of this and other conceptual processing networks connect and communicate is a major challenge for all neural theories of the human conceptual system. Developing a better understanding of both the functional and structural connectivity among these regions, and how these connections develop over the lifespan and change with experience, remains a critical and unfinished task. 


## Supplementary Material 
  
 Supplementary material   can be found at:   http://www.cercor.oxfordjournals.org/  


## Funding 
  
. 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-2'>
<h2>2. PMID: 31593216</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> A look at actions: direct gaze modulates functional connectivity of the right TPJ with an action control network</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Soc Cogn Affect Neurosci</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1093/scan/nsz071</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study in healthy adult participants (N=30, age range 19–41) performing a social task (responses to gaze shifts of virtual characters). Data were acquired with whole-brain BOLD fMRI and analyses report whole-brain activation results (cluster-forming threshold P<0.001 uncorrected, cluster FWE P<0.05) for main effects and interactions. Although a seed-based gPPI was conducted, the study also presents voxelwise, whole-brain results (and reports FWE-corrected PPI voxels), not limited to ROI-only analyses. Participants were healthy with no psychiatric/neurological disorders. The paper is an original empirical study (not a review/meta-analysis). Therefore it meets all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>   ABSTRACT  
Social signals such as eye contact and motor actions are essential elements of social interactions. However, our knowledge about the interplay of gaze signals and the control of actions remains limited. In a group of 30 healthy participants, we investigated the effect of gaze (direct gaze   vs   averted) on behavioral and neural measures of action control as assessed by a spatial congruency task (spatially congruent   vs   incongruent button presses in response to gaze shifts). Behavioral results demonstrate that inter-individual differences in condition-specific incongruency costs were associated with autistic traits. While there was no interaction effect of gaze and action control on brain activation, in a context of incongruent responses to direct gaze shifts, a psychophysiological interaction analysis showed increased functional coupling between the right temporoparietal junction, a key region in gaze processing, and the inferior frontal gyri, which have been related to both social cognition and motor inhibition. Conversely, incongruency costs to averted gaze were reflected in increased connectivity with action control areas implicated in top-down attentional processes. Our findings indicate that direct gaze perception inter-individually modulates motor actions and enforces the functional integration of gaze-related social cognition and action control processes, thereby connecting functional elements of social interactions. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (33873 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
The interdependency of gaze processing and motor actions plays a key role in our everyday social interactions. Underlining their joint functioning, empirical studies have revealed a strong overlap between brain areas that process hand and gaze movements (e.g.  ). Furthermore, it has been shown that social gaze impacts goal-directed movement precision ( ) as well as reaction speed ( ;  ). The latter, however, could not be observed in individuals with autism spectrum disorder ( ), who are also characterized by abnormalities in motor behaviors as well as the processing of eyes and observed movements ( ;  ). 

In social interactions, a specific role needs to be attributed to the perception of direct gaze, which reflexively attracts attention ( ;  ). Crucially, direct as compared to averted gaze has been described as a signal that conveys the intention to interact ( ). In line with this, empirical evidence suggests a facilitation effect of direct gaze on imitative behavior ( ;  ) as well as an attentional effect of gaze cues on manual responses to target stimuli ( ;  ). Yet, besides imitation and beyond attentional guidance of gaze, social interactions might require re-actions to gaze movements that are compatible but not identical with observed actions ( ). Still, how gaze interacts with action control processes on the behavioral and brain level and how the specific gaze context modulates functional connectivity between gaze and action control areas, particularly when tendencies towards spatial congruency need to be suppressed, remains unclear. Therefore, we systematically investigated how the perception of direct or averted gaze affects action control in the context of an fMRI-compatible and previously established spatial stimulus-response compatibility (SSRC) paradigm ( ;  ). Instead of using social and non-social stimuli as in previous studies, we realized a 2 × 2 factorial design by asking participants to generate button presses in a spatially congruent or incongruent manner (factor congruency: CON   vs   INCON) in response to gaze shifts produced by an anthropomorphic virtual character (VC), whose initial gaze position was either direct or averted (factor gaze: direct   vs   averted). As dependent variables, we measured task performance (accuracy) and reaction time (RT) as well as brain activity obtained via BOLD fMRI. 

In line with empirical evidence, incongruent compared to congruent reactions incur increased computational load and thus, lead to prolonged RTs and a decreased percentage of correct responses ( ;  ). Additionally, the incongruency effect should be reflected in an increased activation in a bilateral dorsal fronto-parietal network of frontal motor areas and superior parietal lobules, a network responsive to increased top-down attentional demands and need for increased action control ( ;  ). For the main effect of direct compared to averted gaze, we hypothesized brain regions sensitive to eye contact and gaze-related movements ( ;  ), namely the temporoparietal junction/posterior sulcus temporalis superior (TPJ/pSTS) and the fusiform gyrus, to show increased BOLD signal in response to direct gaze stimuli ( ;  ;  ). 

The main focus of this study was to investigate the interaction between the perception of gaze and mechanisms of action control. While some evidence suggests a general facilitation effect of direct gaze ( ,  ), in other studies, an association of direct gaze and accelerated reactions has only been found for compatible stimulus-response mappings ( ;  ;  ). On the brain level, both motor control areas such as the inferior frontal cortex as well as the gaze sensitive TPJ have been implicated in the interaction of gaze and motor control processes ( ;  ). Building on this, the present study tested whether the same brain regions are differentially recruited as representations of gaze-dependent incongruency costs. Furthermore, in light of evidence that indicates gaze-dependent functional connectivity changes of the TPJ/pSTS with an extended gaze perception network ( ) as well as multi-modal functional coupling of the right TPJ ( ), we expected gaze and action control networks to interact at the level of right TPJ connectivity, reflecting a differential integration of gaze-related and action control processes. Thus, in order to systematically investigate the relationship of gaze-specific incongruency costs in terms of functional connectivity, we conducted a psychophysiological interaction analysis and analyzed whether the interplay of the gaze context and action control demands modulates the functional connectivity between the right TPJ and an ‘action control network’, being composed of all action-associated brain regions as defined by a Neurosynth ( ) search including the search term ‘action’. In a context of direct gaze and an increased demand for action inhibition due to spatial incongruence, we expected to see increased functional coupling between our seed region, which was located in a functional cluster that has been related to social cognition ( ), and particularly the IFG, indicating an integration of gaze-related social cognition and action control ( ;  ;  ). 

In light of autism-related differences observed in the original version of our SSRC task ( ), we further obtained measures of autistic traits and hypothesized to replicate a positive relationship between autistic traits and gaze-specific incongruency costs. 


## Methods 
  
Thirty-two volunteers (15 females) participated in our study. Due to neurological and psychiatric conditions (sleeping disorder, ventricumegaly), two participants were excluded from all further analyses. The remaining 30 participants (14 females) had a mean age of 24 (s.d. = 5.08, range = 19–41), normal or corrected-to-normal vision, no history of neurological or psychiatric history and were right-handed as assessed by the Edinburgh Handedness Inventory ( ). The mean group autism quotient (AQ) ( ) was 14.99 (s.d. = 6.38, range = [6, 32]). All participants gave informed written consent and received a fixed monetary compensation of 30€. At the end of the experiment, participants were debriefed and thanked for their participation. The study protocol followed the guidelines of the Declaration of Helsinki and was approved by the ethics committee of the Ludwig-Maximilians-Universität München. 

### Experimental design and procedure 
  
The paradigm used in this fMRI study resembled an adapted version of previously used SSRC paradigm ( ;  ). Instead of asking participants to respond to the gaze movement of an anthropomorphic VC or the movement of a geometric symbol as in previous studies, VCs were always present. This allowed us to keep the social stimulus constant while now systematically manipulating exposures to direct compared to averted gaze. 
  
Experimental task. (  A  ) One of two female VCs demonstrating direct gaze in the congruent condition [indicated by the initial cue ‘GLEICH’ (German for ‘same’)]. The first gaze shift to the left requires a congruent left button press, the second gaze shift to the right a right button press. (  B  ) One of two male VCs demonstrating averted gaze in the incongruent condition [indicated by the initial cue ‘GEGEN’ (German for ‘opposite’)]. The first gaze shift to the left requires an incongruent right button press, the second gaze shift to the right a left button press. 
  
Before the experiment and before entering the fMRI scanner, participants received detailed instructions on the overall procedure and MRI safety. During the experiment, they were asked to respond as fast as possible to gaze shifts shown by the VC by pressing a right or left button using the right or left index finger, respectively. The experiment consisted of 24 blocks of 12 events each with 50% left- and 50% right-directional gaze shifts, realizing a 2 × 2 factorial design: congruent blocks were instructed by the initial cue ‘GLEICH’ (German for ‘same’) and required participants to respond to gaze shifts in a spatially compatible manner, i.e. pressing the ipsilateral button. The initial cue ‘GEGEN’ (German for ‘opposite’) introduced blocks of spatially incompatible responses, where participants had to press the contralateral button in response to a gaze shift, for instance the right button had to be pressed following a gaze shift to the left ( ). Each cue was presented once for 1500 ms at the beginning of each block of 12 gaze shifts and each block was followed by a jittered inter-stimulus interval of 15 to 17 s. During the experiment, participants did not receive any feedback on their performance. Besides the factor ‘congruency’, our second experimental factor ‘gaze’ was expressed by the VC either looking up (averted gaze) or facing the participant (direct gaze). Pixel coordinates and the timing of gaze shifts were identical over all conditions. In each block, male participants experienced one of two male VCs while female participants were confronted with one of two female VCs. The appearance of either of the two same sex VCs was equally likely. Stimuli were presented through the software package Presentation (Neurobehavioral Systems, Inc.; Version 18.1) on an fMRI compatible computer monitor (refresh rate = 59 Hz, resolution of 1024 × 768, viewable region of 500 mm × 380 mm) and were created manually in Poser 10 (Smith Micro Software, Inc., CA, USA). As stimuli of the present study differed from stimuli of previous studies, a pre-study was conducted to control for unbalanced stimuli preferences. Twelve volunteers (employees, 8 females) from the Max Planck Institute of Psychiatry rated all four VCs on a five-level Likert scale on attractiveness, valence, arousal and other characteristics (Supplementary Table S1). A repeated measures ANOVA using stimulus type (VC 1–4) and characteristics (Supplementary Table S1) revealed no significant effect of stimulus type (  F  [1,11] = 0.94,   P   = 0.43) or interaction effect on VC ratings,   F  (1,11) = 1.15,   P   = 0.10. All volunteers correctly indicated whether the VC demonstrated direct or averted gaze and whether the gaze was directed to the left or right. 


### Behavioral and questionnaire data preprocessing 
  
RTs, the dependent variable that expressed the behavioral outcome of action control, reflected the time frame between the onset of the gaze shift and the button press of the participant. We applied the following RT data preprocessing steps (e.g.  ;  ): trials with no answer, multiple answers or incorrect answers were categorized as error trials. Further, trials with responses two standard deviations from the participant-specific mean RT over all conditions were interpreted as anticipation error or missed response and also labeled as error trials. In total, 9.4% of all trials were error trials. In order to exclude uninformative task blocks, e.g. blocks in which participants missed the initial instructive cue, blocks with more than 25% error trials (> = 3 error trials/block) were not considered in subsequent analyses, resulting in an average exclusion of one block per participant (Supplementary Table S2 for details). Task performance reflected the mean percentage of correctly answered trials of all correct and error trials, which was calculated for each combination of experimental conditions. The AQ of participants was assessed in order to evaluate the relationship of autistic traits and gaze-specific incongruency costs. To conserve comparability of AQ scores, missing values (four participants did not fill in one item each) were interpolated over the individual sub-scale values of the respective item filling in the missing data point. 


### Behavioral data analyses 
  
Main effects and interaction effects of experimental conditions on task performance and RTs were tested by means of repeated measures 2 (gaze: direct   vs   averted) × 2 (congruency: congruent   vs   incongruent) ANOVAs. To test whether direct gaze modulates responses in the congruent or incongruent condition, we implemented post-hoc contrasts of conditions (direct_CON   vs   averted_CON; direct_INCON   vs   averted_INCON) as Bonferroni corrected paired two-sided   t  -tests. After calculating the RT incongruency costs, i.e. RT slowing in incongruent compared to congruent trials, we obtained the difference in RT incongruency costs between the direct and averted gaze condition (incongruency costs direct—incongruency costs averted) as a measure of direction and size of effect of gaze on RT incongruency costs. To further analyze the relationship of the difference in RT incongruency costs between the direct and the averted gaze condition, we correlated the measure with AQ scores. Here, due to non-normally distributed AQ scores (Shapiro–Wilk statistic = 0.93,   P   < 0.05), the non-parametric two-sided Spearman’s rank correlation statistic was used. 



## fMRI data analysis 
  
Participants completed the experiment inside a 3T MR scanner (MR750, GE, Milwaukee, USA). The procedure comprised a single functional run of 290 volumes of 40 slices (32-channel head coil, AC-PC-orientation, 96 × 96 matrix, 3 × 3 mm voxel size, 3 mm slice thickness, 0.5 mm slice gap). First, structural T1-weighted images were acquired [BRAVO FSPGR pulse sequence, 1 mm isotropic voxels, repetition time (TR) of 6.2 ms, echo time (TE) of 2.3 ms]. Second, during the experiment, T2 -weighted functional images were obtained by means of gradient echo planar imaging (TR of 2000 ms, TE of 20 ms, 90° flip angle) and the first four functional volumes we removed to control for non-equilibrium effects. FMRI data preprocessing and analysis were performed in SPM12 (Statistical Parametric Mapping Software, Wellcome Department of Imaging Neuroscience, London;   http://www.fil.ion.ucl.ac.uk  ) and included the following steps: functional images were spatially realigned to the mean functional image (rigid body transformation). Next, functional and structural images were co-registered. Both structural and functional images were spatially normalized to the Montreal Neurological Institute (MNI) template using tissue segmented T1-weighted anatomical images (BRAVO FSPGR pulse sequence, 1 mm isotropic voxels, TR of 6.2 ms, TE of 2.3 ms). Functional images were resliced to 2 × 2 × 2 mm voxel size. Finally, a 3D Gaussian Kernel with full width of half maximum of 8 mm was used for smoothing. 

All valid experimental blocks (RT data preprocessing) were modeled as epochs in a general linear model (GLM) with an average duration of 54 s (range 46–64 s). Experimental factors, i.e. ‘gaze’ (direct   vs   averted gaze) and ‘congruency’ (congruent   vs   incongruent) were captured in four different regressors of interest. Error blocks were modeled by a regressor of no interest. Our GLM design matrix further contained 26 confound regressors of no interest: the first 24 contained six z-standardized rigid body motion realignment parameters, their temporal derivatives and the squared values of both realignment parameters and derivatives ( ). Another two regressors captured confounding signal from white matter and cerebrospinal fluid. Here, we obtained a binarized mask from the respective segmented individual structural images using a 0.95 threshold in SPM’s image calculator (imcalc tool) and calculated the first principal component of the respective tissue type, explaining 85.42% (s.d. = 4.28%) and 79.11% (s.d. = 5.85%) of variance in the signal ( ). No global scaling was applied and low-frequency signal drifts were filtered out (128 s cutoff period). In order to correct for temporal autocorrelation of the data, voxel-wise maximum likelihood estimators were calculated ( ). 

Studying the effect of congruency and gaze as well as their interaction, BOLD signal during main effects and interactions of conditions were analyzed in a second-level flexible factorial design. A binarized group-specific explicit grey matter (GM) mask (sum of participant specific probability of GM > 0.05; imcalc tool) contained all voxels of interest. Besides our two experimental factors, we added a ‘subject’ factor, accounting for subject-specific heteroscedasticity, and implemented SPM’s default settings of unequal variances within each factor. In order to analyze the main effects of congruency and gaze, we contrasted congruent and incongruent as well as direct and averted gaze conditions [congruency: (direct_CON + averted_CON) > (direct_INCON + averted_INCON), (direct_INCON + averted_INCON) > (direct_CON + averted_CON); gaze: (direct_CON + direct_INCON) > (averted_CON + averted_INCON), (averted_CON + averted_INCON) > (direct_CON + direct_INCON)]. Statistical interactions of conditions were modeled as contrast of incongruency costs in the direct and averted gaze conditions [IA1: (direct_INCON > direct_CON) > (averted_INCON > averted_CON), IA2: (averted_INCON > averted_CON) >(direct_INCON > direct_CON)]. 
  
Behavioral measures  .   (  A  ) Mean percentage of correct responses and (  B  ) left panel: mean RTs; right panel: mean RTs for direct and averted gaze in the congruent condition. Light blue lines mark a decrease in RT from direct to averted; dark blue lines mark an increase. The light blue solid line represents the mean decrease in RTs from the direct to the averted gaze condition. Black horizontal lines represent the mean values, boxes represent the standard error of the mean (SEM), blue vertical lines the standard deviation (s.d.). 
  
Moreover, we conducted a generalized condition-specific psychophysiological interaction analysis ( ) to investigate the context-dependent functional coupling between gaze and action processing areas. Based on the available literature and a term-based meta-analysis in Neurosynth ( ), we identified a region typically labelled as right TPJ ( ) as the seed region for our gPPI analysis. The coordinates of our seed region [44, −52, 12] represented the peak coordinates in the brain map of the term ‘gaze’ (retrieved 2 October 2018 from   www.neurosynth.org  , z-score = 7.33) and were further situated in a functional sub-section of the right TPJ involved in social cognition ( ; Neurosynth, retrieved 3 June 2019, meta-analytic association of peak coordinates with terms ‘default network’, ‘mentalizing’). After creating a sphere of 6 mm radius in marsbar ( ; Supplementary Figure S1A), we extracted the first eigenvariate of our seed sphere and allowed actual ROIs to vary in size between participants, but restricted them to first level masks generated by SPM12. In order to investigate the context-dependent functional coupling of our right TPJ seed with brain areas involved in action control, we retrieved an associative ‘action’ mask from Neurosynth ( : retrieved 2 October 2018 from   www.neurosynth.org  ). After smoothing (3D Gaussian Kernel with full width of half maximum of 4 mm) and binarization (imcalc, i1 > 0.1, Supplementary Figure S1B), it was implemented as explicit mask in our second level analysis. Specifically, we were interested in the functional coupling of the right TPJ and the action network for the statistical interactions of our experimental conditions [IA1: (direct_INCON > direct_CON) > (averted_INCON > averted_CON)] and [IA2: (averted_INCON > averted_CON) > (direct_INCON > direct_CON)]. 

Statistical maps of the activation analysis are shown at a cluster-forming threshold of   P   < 0.001 (uncorrected) and a cluster threshold of   P   < 0.05 (FWE). In the psychophysiological interaction analysis,   P  -values were thresholded at   P   < 0.05 (FWE) at voxel level. The Anatomy Toolbox ( ; Version 2.2c) and the AAL atlas in MRIcron ( ) were used for functional localization and the Surf Ice software for brain visualizations (  https://www.nitrc.org/projects/surfice/  ). 


## Results 
  
### Behavioral results 
  
As expected, a repeated measures ANOVA focusing on the condition-specific performance revealed a significant main effect of congruency on the percentage of correct responses,   F  (29,1) = 32.09,   P   < 0.001, η  = 0.53. There was no main effect of gaze [  F  (29,1) = 1.80,   P   = 0.19, η  = 0.06] or an interaction effect of congruency and gaze on performance,   F  (29,1) = 1.27,   P   = 0.27, η  = 0.04 ( ). 

A second repeated measures ANOVA demonstrated a significant main effect of congruency also on RTs,   F  (29,1) = 134.71,   P   < 0.001, η  = 0.82. Neither did gaze impact participants’ RTs [  F  (29,1) = 1.30,   P   = 0.26, η  = 0.04] nor did the interaction effect of experimental conditions reach significance,   F  (29,1) = 3.88,   P   = 0.06, η  = 0.12 ( ). Post-hoc contrasts showed that congruent RTs were significantly higher in the direct gaze compared to the averted gaze condition,   t  (29) = 2.86,   P   < 0.01, R  = 0.22. Incongruent RTs, however, did not differ between gaze conditions,   t  (29) = 0.17,   P   = 0.87.   presents the condition-specific performance and RTs. 
  
Condition-specific RTs and accuracy. Brackets contain the standard deviation (s.d.). 
  
Condition-specific RT incongruency costs, i.e. the increase in RTs in incongruent compared to congruent trials, are displayed in  . On average, RTs of incongruent reactions increased by 48 ms (s.d. = 27 ms) in the direct gaze condition and by 56 ms (s.d. = 27 ms) in the averted gaze condition. Building on this, a two-sided Spearman’s rank correlation analysis indicated a significant negative correlation between AQ scores and the difference in RT incongruency costs for direct as compared to averted gaze,   rs  (28) = −0.40,   P   < 0.05 ( ). 
  
Condition-specific RT incongruency costs. Boxes represent the SEM. 
    
Linear association of AQ scores and the difference in RT incongruency costs (ranks) between experimental conditions (direct—averted). 
  

### fMRI results 
  
Applying a cluster-forming threshold of   P   < 0.001 (uncorrected) and a cluster threshold of   P   < 0.05 (FWE), incongruent contrasted to congruent trials [(direct_INCON + averted_INCON) > (direct_CON + averted_CON)] were associated with a differential increase in BOLD signal in the right inferior parietal lobule, left superior parietal lobule and right middle frontal gyrus ( ). For the reversed contrast [(direct_CON + averted_CON) > (direct_INCON + averted_INCON)], a large cluster of 2319 voxels emerged in the bilateral medial prefrontal cortex (MPFC), including voxels in the superior medial gyri, superior frontal gyri and the anterior cingulate cortices, spreading to the right medial cingulate cortex. Congruent compared to incongruent trials further elicited activation in the right IFG as well as the left cerebellum and posterior part of the left fusiform gyrus ( ). 
  
Main effects of conditions in the left (L) and right (R) hemisphere  .   (  A  ) Incongruent   vs   congruent, (  B  ) congruent   vs   incongruent, (  C  ) direct   vs   averted gaze. The cluster forming threshold was set to   P   < 0.001 (uncorrected), the cluster threshold to   P   < 0.05 (FWE) and cluster size (A) k > 414 voxels, (B) k > 287 voxels, (C) k > 638 voxels. [(A) SPL: superior parietal lobule, mFG: medial frontal gyrus; MFG: middle frontal gyrus (B) SFC: superior frontal cortex, FFG: fusiform gyrus, ACC: anterior cingulate cortex, MPFC: medial prefrontal cortex, CRBL: cerebellum; IFG: inferior frontal gyrus (C) lPS: intra-parietal sulcus]. 
  
During direct gaze   vs   averted gaze [(direct_CON + direct_INCON) > (averted_CON + averted_INCON)], increased signal was found in the right intraparietal sulcus ( ). The contrast of averted gaze   vs   direct gaze [(averted_CON + averted_INCON) > (direct_CON + direct_INCON)] did not show any suprathreshold activation. Similarly, significant clusters emerged in neither of the interactions of congruency and gaze [IA1: (direct_INCON > direct_CON) > (averted_INCON > averted_CON)] and [IA2: (averted_INCON > averted_CON) > (direct_INCON > direct_CON)] (Supplementary Table S3 for coordinates, T-values and cluster sizes). 

In our psychophysiological interaction analysis, we analyzed how the right TPJ was coupled with the action network for the interactions of the experimental factors, i.e. IA1 and IA2 (Supplementary Figure S2 and Table S4 for coordinates, T-values and cluster sizes of all PPI contrasts). Statistical maps were thresholded at   P   < 0.05 (FWE) at voxel level. Results demonstrated that for IA1, which represented increased BOLD incongruency costs for direct compared to averted gaze, the right TPJ showed context-dependent connectivity with the IFG and the right middle temporal gyrus ( , brown color map). For IA2, reflecting increased BOLD incongruency costs for averted compared to direct gaze, activation in the seed region was coupled to activation in a dorsal network of superior and inferior parietal lobules, pre- and postcentral gyri, temporal gyri, occipital gyri, left superior, posterior medial, middle and IFG, right paracentral gyrus, left putamen and right cerebellum ( , blue/green color map). 
  
Interaction effects in a psychophysiological interaction analysis in the left (L) and right (R) hemisphere  .   IA1 (brown): (direct_INCON > direct_CON) > (averted_INCON > averted_CON), IA2 (blue/green): (averted_INCON > averted_CON) > (direct_INCON > direct_CON). The results were FWE corrected at   P   < 0.05 voxel level. [IFG: inferior frontal gyrus, MTG: middle temporal gyrus MFG: middle frontal gyrus, PreCG: precentral gyrus, PostCG: postcentral gyrus, SPL: superior parietal lobule, OccG: occipital gyrus, CRBL: cerebellum, ITG: inferior temporal gyrus; pmFG: posterior medial frontal gyrus; ParaCG: paracentral gyrus]. 
  


## Discussion 
  
The present study investigated the effect of gaze perception on behavioral and neural correlates of action control of non-imitative re-actions. Our results demonstrate context-dependent functional integration of gaze and action control processes and our behavioral findings are in line with theories suggesting a relationship between gaze effects and autistic traits. 

As hypothesized, we found a significantly lower percentage of correct responses and longer RTs when participants had to respond in a spatially incompatible manner to the VCs’ gaze shifts ( ;  ;  ). Moreover, in line with a priori expectations, key regions of the so-called dorsal fronto-parietal attention network showed increased activation in incongruent as compared to congruent experimental blocks, possibly reflecting the increased need for top-down control ( ;  ). 

The opposite contrast, namely congruent   vs   incongruent, depicted increased brain activation in the left posterior fusiform gyrus and the MPFC. Given the lack of significant results in previous studies, we did not have specific hypotheses about the present contrast. A possible explanation for the brain activation found might be that similar to the sensitivity of the left fusiform gyrus towards faces and shapes ( ), MPFC activation has previously been found in response to spatially congruent gaze shifts, potentially representing occurrences of joint attention ( ). Hence, in a situation of low task difficulty, participants might have used free cognitive capacities to thoroughly process the social encounter with a VC ( ). Alternatively, representing a central hub of the default mode network, which is known as the task-negative network (e.g.  ), MPFC activation might indicate the occurrence of stimulus-independent thoughts that have been referred to as ‘day dreaming’ or mind wandering ( , Neurosynth, retrieved 3 June 2019: association of peak coordinates with terms ‘default mode’, ‘mentalizing’). Despite of the richness of literature on the decisive role of the IFG in response inhibition processes (e.g.  ), in the present contrast, the right IFG was activated during congruent blocks not requiring to withdraw from or cancel motor actions. Instead, the IFG might have come into play through holding representations of the CV’s gaze movements and hence, might have supported action understanding ( ;  ; Neurosynth, retrieved 3 June 2019: association of peak coordinates with terms ‘decision task, ‘comprehension’, ‘reappraisal’). Further, in light of its implication in gaze-grasping mappings ( ;  ), the IFG might have promoted a congruent button pressing by translating the gaze movement into a finger movement that corresponded to the direction of the gaze. Here, future research needs to clarify the specific role of the IFG during congruent task conditions. 

Direct compared to averted gaze was followed by increased brain activation in the right intraparietal sulcus, a region known to be involved in visuo-spatial aspects of action planning, the understanding of complex or irrational actions and the integration of visual and motor computations ( ;  ;  ). However, contrary to our hypotheses, direct gaze was not accompanied by increased activation in the right TPJ and fusiform gyrus—a result that might be caused by block design-induced habituation effects ( ). 

Incongruency costs describe the behavioral or neural cost of performing a spatially incompatible motor response. In the present study, we were interested in the differences in incongruency costs between the direct and averted gaze conditions. Contrary to our hypothesis, incongruent RTs did not differ between the direct and the averted gaze condition. As has been shown previously ( ), in a more difficult task situation, gaze did not have an impact on behavior. However, contrary to the reported facilitation of motor imitation with direct gaze, in our study, the translation of a gaze shift into a left- or right-handed button press was less time-consuming for averted gaze movements. Thus, our results indicate that the facilitation effect of direct gaze might not apply to non-imitative behaviors. Consistent with behavioral results, there was no interaction effect of experimental conditions at the brain level. 

The difference in RT incongruency costs between the direct and averted gaze condition represented a measure of the gaze-depended incongruency effect on reaction speed. A correlation analysis showed that high AQ values were associated with higher incongruency costs in the averted gaze condition, whereas the difference in incongruency costs between conditions diminished and even changed towards higher incongruency costs in the direct gaze condition with decreasing AQ scores. This result points towards inter-individual differences in the sensitivity towards social gaze, as a function of autistic traits. In this sense, individuals with low AQ scores might be more susceptible to the influence of direct gaze than individuals with higher AQ values. 

How the communication between the right TPJ and the action network changes depending upon the interplay of the experimental factors was addressed by means of a psychophysiological interaction analysis. Importantly, studies have indicated a functional partitioning of the right TPJ into an anterior and a posterior cluster: while the global functional integration of the anterior cluster suggests a mediating role in shifting from one functional brain state to another ( ), our ‘gaze’-associated seed region overlaps with the posterior TPJ cluster, implicated in social cognition, imagination and episodic memory retrieval ( ). As hypothesized, the context-dependent connectivity between our seed and the IFG, known to be involved in the integration of action inhibitory tendencies and motivational, emotional or social input (e.g.  ;  ; Neurosynth, retrieved 3 June 2019: association of peak coordinates with term ‘theory of mind’), was increased for incongruency costs in the context of direct gaze. As a consequence, the connection between the right TPJ and the IFG might reflect an upregulated exchange of gaze information and inhibitory control processes in the context of direct gaze. Moreover, in parallel to the association of our TPJ region to object or scenic imagination ( ), the IFG has been discussed not only to contribute to reactive but also proactive motor control ( ;  ). Accordingly, it would be possible that the IFG has been involved in preparing or anticipating a reorientation response that might have been supported by gaze-related input from the TPJ. In line with this post-hoc hypothesis, the right middle temporal gyrus has been indicated in mapping hypothetical motor actions to perceptual input ( ). 

Conversely, costs for reacting incongruently in the context of averted as compared to direct gaze movements were represented in increased functional connectivity between our seed region and major parts of the action network, predominantly in the left hemisphere and including the parietal lobules, the primary motor and sensory cortex, the frontal and temporal gyri. Besides belonging to the action network, the superior parietal and frontal regions are also relevant in top down attentional control processes ( ;  ) and have been shown activated in working memory tasks, during spatial attention towards or the planning of actions ( ). In summary, incongruency costs for averted gaze appear to manifest in more wide-spread connectivity that encompasses somatosensory motor areas. Incongruency costs for direct gaze, however, are reflected in increased connectivity with brain regions that are involved in both action control and social cognition. 

In conclusion, the results of the present study shed new light onto the neurobiology that underlies the specific role of direct gaze in social encounters: by increasing the connectivity of multimodal brain regions, the processing of direct gaze results in an integration of brains regions implicated in action control and social cognition. In this way, direct gaze could be seen as contributing to a comprehensive processing of the social situation that goes beyond a strongly stimulus-driven orientation. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-3'>
<h2>3. PMID: 30225341</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Motivation Modulates Brain Networks in Response to Faces Varying in Race and Status: A Multivariate Approach</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> eNeuro</p>
<p><strong>Publication Year:</strong> 2018</p>
<p><strong>DOI:</strong> 10.1523/ENEURO.0039-18.2018</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study collected BOLD fMRI while participants performed an impression-formation task (social processing of faces varying in race and socioeconomic status), meeting the social-related task requirement. The sample comprised healthy adult participants (final N=60 males, mean age 23.8 years), within the 18–60 range and with no indication of psychiatric/neurological patient samples. Analyses reported whole-brain multivariate (behavioral PLS) results with voxelwise bootstrap-ratio thresholds and cluster reporting (i.e., whole-brain results rather than ROI-only analyses). The study is an original fMRI investigation (not a review/meta-analysis). Therefore it satisfies all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Previous behavioral and neuroimaging work indicates that individuals who are externally motivated to respond without racial prejudice tend not to spontaneously regulate their prejudice and prefer to focus on nonracial attributes when evaluating others. This fMRI multivariate analysis used partial least squares analysis to examine the distributed neural processing of race and a relevant but ostensibly nonracial attribute (i.e., socioeconomic status) as a function of the perceiver’s external motivation. Sixty-one white male participants (  Homo sapiens  ) privately formed impressions of black and white male faces ascribed with high or low status. Across all conditions, greater external motivation was associated with reduced coactivation of brain regions believed to support emotion regulation (rostral anterior cingulate cortex), introspection (middle cingulate), and social cognition (temporal pole, medial prefrontal cortex). The reduced involvement of this network irrespective of target race and status suggests that external motivation is related to the participant’s overall approach to impression formation in an interracial context. The findings highlight the importance of examining network coactivation in understanding the role of external motivation in impression formation, among other interracial social processes. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (50096 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Significance Statement 
  
This multivariate fMRI analysis examined distributed neural processing as participants formed impressions of faces varying in race and status. Across all conditions, participants reporting greater external motivation to respond without racial prejudice showed reduced coactivation in brain regions believed to support emotion regulation, introspection, and social cognition. These results suggest that external motivation may calibrate how perceivers form impressions in an interracial context, irrespective of target race. The results from this analysis raise new questions that may not have readily emerged in studies relying on traditional behavioral and univariate fMRI analyses. 


## Introduction 
  
Race remains a contentious topic in the United States and around the world. Evaluations of others based on race and other features may depend on motivations to respond without prejudice ( ;  ). In contrast to individuals who intentionally cultivate a racially egalitarian self-concept (i.e., internally motivated), individuals who are motivated to avoid the social sanctions of expressing racial prejudice (i.e., externally motivated) can be especially uncomfortable when race is salient ( ;  ). These motivations are frequently assessed using the internal motivation scale (IMS) and the external motivation scale (EMS;  ). Potentially due to race-related discomfort ( ;  ), whites with high EMS scores typically engage in more effortful (albeit less efficient) self-regulation during intergroup interactions ( ;  ;  ;  ;  ;  ). High-EMS individuals also tend to avoid explicit mentions of race, focusing instead on nonracial categories or topics ( ;  ). In a recent fMRI study ( ), we examined neural responses to perceived race and socioeconomic status (SES) during impression formation as a function of white perceivers’ EMS scores. Findings from this original univariate analysis indicated that EMS modulated the processing of SES (but not race) in brain regions involved in person evaluation. To gain greater insight into this intriguing set of findings, we used a multivariate approach known as behavioral partial least squares (PLS) analysis ( ) to identify how brain networks may be modulated as a function of individual differences in perceiver motivation. 

In our original univariate analyses ( ), we found that EMS modulated responses to SES in the bilateral nucleus accumbens (NAcc) and ventromedial prefrontal cortex (VMPFC), consistent with the literature on status-based evaluations ( ,  ). Notably, high-EMS participants showed neural response patterns to SES that were difficult to reconcile with the largely positive evaluations of high SES (when considered independently of other dimensions) observed in the behavioral ( ;  ) and neuroimaging ( ,  ) literature. 

In the present analysis, we used behavioral PLS analysis to examine distributed neural responses to perceived race and SES as a function of white perceivers’ EMS scores. Behavioral PLS analysis is a data-driven method that allows for the identification of one or more latent variables (LVs) that reliably account for covariance between individual differences (e.g., EMS) and distributed patterns of neural responses to conditions of interest (e.g., targets varying in race and status;  ;  ;  ). Because this is a data-driven approach to brain–behavior correlations, behavioral PLS analysis allows for the identification of several potentially compatible LVs. One possibility is that brain–behavior correlations may differ qualitatively across conditions ( ). Based on our original analysis showing EMS-related modulation of neural responses to SES ( ), for example, EMS could correlate with increasing coactivation across a distributed network of brain regions when forming impressions of high-SES targets and with decreasing (or null) coactivation in a different network when forming impressions of low-SES targets. The converse is also possible. Although our original univariate analysis did not show a reliable relationship between EMS and localized neural responses to race (or the race-by-status interaction), it is nonetheless possible that EMS may predict distinct patterns of neural coactivation as a function of race in a multivariate analysis. For example, one study using multivoxel pattern analysis examined the neural representation of race in key regions of interest (ROIs) as white participants were assigned to one of two mixed-race groups and subsequently categorized members from both groups while in the scanner ( ). Although no effects of race were reported in the behavioral or univariate analyses, the authors did find that race was reliably decoded above chance in the visual cortex and the fusiform gyri but not in control regions (for a similar study using gender instead of race, see  ). This is particularly interesting because recent work has suggested that distributed neural responses to race are decoded more reliably in the fusiform gyri when race processing is incidental to the task (i.e., as in the present study) compared with when race processing is integral to the task ( ). A final possibility is that brain–behavior correlations are similar across all conditions ( ). In other words, EMS could increase or decrease the overall coactivation between brain regions irrespective of face race or SES, implying that EMS influences how participants approach the task overall. Although the data-driven nature of PLS analysis obviates the need to formalize a priori ROIs, we anticipated that any latent variables would likely implicate regions involved in person evaluation (VMPFC;  ;  ;  ;  ,  ) and the regulation of prejudice (e.g., cingulate cortex, lateral prefrontal cortex;  ;  ;  ). 


## Materials and Methods 
  
### Participants 
  
Eighty-two Chicago-area men passed the initial screening. Of the 82 eligible participants, 61 completed the study. The 21 eligible participants who did not complete the study either failed to complete the on-line battery of questionnaires or were unable to schedule a suitable time for the scanning session before achieving our intended quota for this study (  N   = 60). One participant was excluded from analyses as an outlier for IMS (a control variable), exceeding 3.5 SDs from the sample mean (see Results). The final sample comprised 60 male participants (mean age, 23.8 years; SD = 4.59 years). 


### Protocol 
  
#### On-line surveys 
  
Eligible participants completed a battery of questionnaires on-line before the day of their scan. Most of these measures were assessed for a large-scale resting-state fMRI investigation or an unrelated experiment completed immediately before the impression-formation task used for the present analysis. Although we provide an overview of pertinent measures for this report (see Experimental design and statistical analysis), full details are available in the open-access report from our previous analysis of the presented data ( ). 


#### Scanning session 
  
On the day of scanning, participants were instructed to arrive without having consumed drugs, including caffeine and alcohol. After signing consent and imaging center paperwork, the participant was photographed and completed brief surveys. Participants were then trained on the two tasks they would complete while in the scanner. The primary experimental task involved forming impressions of faces varying in race and ascribed status. An additional task, which served as a control task for the purpose of an analysis performed for the current study, involved explicitly rating (1) the attractiveness of a series of faces depicting white actors and models and (2) the likeability of a separate set of white actor faces based on their body of work. The faces of black actors and models were not used for this control task. 

Participants were first trained on the control task. They completed a practice block outside of the scanner in which they learned how they would be rating the actors and models while in the scanner. The practice block was a shortened version of the main experiment (one run with three blocks of 10 trials each), using actors and models that would not be presented in the scanner. After completing the full practice block for the control task, participants then learned about the main impression-formation task. The experimenter informed participants that the study investigated how people think of others varying in SES. SES was defined as follows: “Those who have the highest social status tend to have the most money, the most education, and the most respected jobs. Those who have the lowest social status tend to have the least money, the least education, and the least respected jobs or no job.” Following this definition, participants learned to associate colors with low- and high-status Americans (e.g., blue = low; orange = high). Status–color associations were counterbalanced across participants. 

To thoroughly learn status–color associations, participants completed simple association training blocks ( ;  ;  ). In an initial block of 10 trials, participants viewed a darkened silhouette over a colored background (i.e., orange or blue: five per status level), indicating by key press whether the silhouette was low status or high status based on the background color. Participants were informed of their cumulative accuracy on each trial (mean, 98.5%). Next, participants completed a block of 10 trials (5 per status level) in which they were asked what color represents low (or high) status. Participants were again informed of their cumulative accuracy on each trial (mean, 93.4%). 

Having learned the two status–color associations, participants briefly practiced the impression-formation task that they would complete while in the scanner (see Experimental design and statistical analysis). The experimenter first verbally confirmed that the participant learned the status–color associations and then explained that participants would no longer be categorizing targets as low or high in status for the impression-formation task. Instead, they would be forming quick overall impressions of male faces, taking into account all visually available information ( ). This was repeated for participants in the written instructions for the practice block of the impression-formation task. The procedure for the practice trial block was the same as the procedure reported for the experimental block. 

Once situated in the scanner, participants first completed two fMRI runs of the control task ( ). After this task, participants completed a brief task reminding them of the learned status–color associations and how to use the button box. All participants correctly recalled the status–color associations. After this reminder, participants completed two runs of the impression-formation task (each ∼4 min), followed by resting-state and anatomic scans, time permitting (total scan time, ∼1 h). On exiting the scanner, participants completed explicit stimuli ratings and judgments ( ). After this block of surveys, participants were compensated and debriefed. 


#### fMRI acquisition 
  
We used a Phillips dStream Achieva 3 T system and 32-channel head coil to acquire BOLD, T2* contrast-weighted echoplanar images (EPIs). With a 2000 ms repetition time and a 25 ms echo time, we acquired 34 oblique slices using an interleaved   z  -shim acquisition protocol ( ). Slices were 4 mm thick with a 0.5 mm gap, a 3 mm  in-plane resolution, 77° flip angle, and a 192 × 134 × 192 mm field of view. Slices were aligned to the anterior commissure–posterior commissure axis of each participant ( ). 



### Experimental design and statistical analysis 
  
#### Design and key measures 
  
The present analysis focuses on BOLD responses as participants formed impressions of targets varying in race and SES. We describe the impression-formation fMRI task design first, followed by the primary individual difference measures of EMS and IMS. 

##### Impression-formation task 
  
After a brief training session completed outside the scanner (see Protocol), participants learned to associate two colors with different status levels ( ). For example, blue conveyed high status, and orange conveyed low status. Status–color associations were counterbalanced across participants. 

The impression-formation task that participants completed during functional scanning adhered to a rapid event-related design ( ). Trials began with a black or white male face surrounded by a blue- or orange-colored frame over a black background. After 1500 ms, the face was replaced by a white fixation of a jittered duration (i.e., intertrial interval of 500, 2500, 4500, or 6500 ms). Participants formed a quick impression of each individual by the time the face disappeared or shortly thereafter. To signal they formed an impression, participants simultaneously pressed two keys, one per index finger. Participants were informed that their responses were not meant to indicate the content of their impressions, but merely to indicate that they had formed an impression. In each run of the impression-formation task, participants viewed 60 male faces divided evenly across conditions (for details on stimulus equating, see  ). Two reminder trials after the first and second thirds of the sequence required participants to identify the status level of a silhouette framed by either blue or orange. 

Faces from all four combinations of race (black, white) and status (low, high) were interspersed in a fixed pseudorandom sequence. To optimize fMRI design efficiency ( ), three fixed trial sequences were generated using optseq2 ( ). For further details on trial sequence design and optimization, see the study by  ). 


##### Control task 
  
The control task consisted of an event-related design with two functional runs. Full details on stimulus equating and counterbalancing have been reported (T.P.D., B.D.M., J.T.K., and J.C., unpublished observations). Images of actor faces and model faces were presented over two functional scans, with 30 unique white actors and 15 unique white models per functional scan. In each scan, participants rated half of the actors on attractiveness and the other half on the body of work. The models were rated only on their attractiveness. 

Before each block of the control task, participants viewed a prompt indicating the evaluative judgment and target group (e.g., How attractive are these models?). All trials began with a 1500 ms presentation of a face over a black background, followed by a 500 ms fixation. After 500 ms of fixation, the fixation cross changed from white to green, prompting participants to indicate their evaluation of the actor or model. Participants responded on a scale of 1 (very attractive/likable) to 4 (very unattractive/unlikable), with key mapping counterbalanced across participants. After 1000 ms, the green fixation changed back to white and remained for an additional 1000 ms. Jittering was implemented after each trial using 0, 2000, 4000, or 6000 ms fixations. 


##### Motivation to respond without racial prejudice 
  
This 10-item measure ( ) was administered on-line before the participant’s scheduled scan date. The EMS (Cronbach’s α = 0.874) included five items (e.g., “I try to act nonprejudiced toward black people because of pressure from others”). The IMS (Cronbach’s α = 0.764) also contained five items (e.g., “Being nonprejudiced toward black people is important to my self-concept”). Both motivations were measured on a 9 point scale from 1 = strongly disagree to 9 = strongly agree. EMS and IMS were uncorrelated in the final sample (  r   = 0.052,   p   = 0.694). Full details on the distributions of EMS and IMS are reported by  ). 


##### Postscan stimulus ratings 
  
Participants completed a measure of explicit likeability for each of the 60 male face stimuli viewed in the scanner during the impression-formation task. Faces were presented with the same status-associated colored backgrounds used in the scanner. Participants rated each face on a scale from 1 = extremely unlikeable to 9 = extremely likeable. 



#### Analyses of behavioral data 
  
For the sake of completeness, we report briefly on participants’ reaction times (RTs) during the impression-formation task, simultaneously testing whether reaction times show any relationship with EMS. Using a similar approach, we also explore whether EMS predicts postscan stimulus ratings of likeability. 

##### Reaction time analysis 
  
Because of device malfunctions, RTs were not recorded from four participants. Therefore, the RT analysis included only 56 participants. Any RTs <250 ms (<0.1% of all trials) and any trials where no response was provided (1.5% of all trials) were immediately excluded from analysis. We then subsequently trimmed any remaining RTs exceeding 3 SDs from the participant’s mean RT (0.4% of all trials). RTs were then log-transformed before analysis to reduce the natural skew of RT data. To test for effects in the speed of responses during the impression-formation task, we used a linear mixed-effects model in which log-transformed reaction times were predicted by target race, target status, and the participant’s EMS score. The model included a random intercept, all possible random slopes by participant, and all possible correlation parameters. 


##### Postscan likeability ratings and EMS 
  
Using a similar linear mixed-effects model, we analyzed postscan ratings of stimulus likeability as a function of target race, target status, and the participant’s EMS score. As in the analysis of RTs, the model included a random intercept, all possible random slopes by participant, and all possible correlation parameters. 



#### Analyses of fMRI data 
  
For the fMRI data, we first summarize the preprocessing parameters and GLM parameters as reported in the original univariate analysis of these data ( ). We then provide a detailed overview of the multivariate behavioral PLS analyses used in the present report. Additional supplemental analyses are also described. 

##### Preprocessing 
  
EPIs from each participant’s four runs (two per task) were preprocessed and analyzed at the first level using SPM8 (  www.fil.ion.ucl.ac.uk/spm  ), facilitated by a custom suite of scripts for fMRI analysis (  https://github.com/ddwagner/SPM8w  ). We first implemented slice-time correction ( ), using the 17th slice acquisition as the reference. Subsequently, we integrated the four repeated   z  -shim slices ( ). The resulting images from each participant were then unwarped and realigned to the participant’s mean EPI to correct for motion and motion-by-distortion interactions ( ). Images were subsequently normalized to the MNI template and smoothed with an 8 mm FWHM kernel ( ). 


##### GLM 
  
To estimate the BOLD responses for each condition, each trial was considered as an event, and the stimulus time series was convolved with the canonical hemodynamic response function. A GLM modeled scan sequences concatenated by task as a single session with regressors for each condition. For the race-status impression-formation task, we modeled four conditions (ordered as follows: high-status black, high-status white, low-status black, and low-status white). For the control task, we modeled three conditions (ordered as follows: attractiveness ratings for actors, body-of-work ratings for actors, and attractiveness ratings for models). For both task GLMs, regressors for the key conditions of interest were followed by regressors controlling for variance associated with: (1) reminder trials; (2) low-frequency drift (i.e., a linear trend); (3) session means (1 for scan 1, 0 for scan 2); (4) six movement parameters; (5) a constant across all scans; and (6) slow fluctuation of the signal (i.e., a standard set of harmonic regressors effectively serving as a 1/128 Hz high-pass filter). Contrast images reflecting the first-level effect of each condition versus baseline were used for PLS analyses ( ). 


##### Behavioral PLS analysis 
  
Behavioral PLS analysis is a data-driven method that allows for the identification of LVs that reliably account for covariance between individual differences on a behavioral measure (e.g., EMS) and one or more distributed patterns of neural responses to conditions of interest ( ). In other words, the goal of behavioral PLS analysis is to find weighted patterns (i.e., the LVs) characterized by maximal covariance between the behavioral and neural datasets. A description of this method given in considerable detail can be found in previous work ( ;  ;  ;  ). In this section, we first provide some detail on how the analysis is implemented followed by an overview of the benefits and limitations of behavioral PLS analysis. 


##### Analysis parameters 
  
In the present report, we use the same analysis procedure reported by   to examine the degree to which EMS predicts distributed neural responses to all conditions of interest in both the impression-formation and control tasks. To test the overall significance of each LV, a set of 2000 permuted samples was created by randomly reordering participants and condition labels (without replacement) in the voxelwise fMRI dataset, but conserving the original behavioral dataset (i.e., EMS scores). The same model used to generate the LV was subsequently applied to each permuted dataset, resulting in 2000 new covariance matrices. These covariance matrices embody the null hypothesis that there is no relationship between brain activity and behavioral data. Each covariance matrix was then subjected to singular value decomposition (SVD), resulting in a null distribution of singular values. The significance of the SVD of the original LV was ultimately assessed with respect to this null distribution. The   p   value was calculated as the proportion of the permuted singular values that exceeded the original singular value. For each significant LV, the reliability of brain–behavior correlations specific to each condition was tested using 95% confidence intervals ( ). These confidence intervals were generated using a 2000-sample bootstrapping test. Because the top and bottom bounds of the confidence intervals are derived from a bootstrap distribution, it is common for these bounds to be asymmetric relative to their corresponding estimates ( ). Indeed, when the underlying distribution is sufficiently skewed, it is possible for the correlation estimate to fall outside of its bootstrapped confidence interval. We report confidence intervals derived from the standard estimation procedure built into the PLS analysis toolbox (see   http://web.mit.edu/seven/src/PLS/Plscmd/pls_analysis.m  ). 
  
  A   , External motivation to respond without prejudice (EMS) emerged as a significant LV in behavioral PLS analysis. Brain–behavior correlations were similar across conditions.    B   , Patterns of whole-brain activity covarying with EMS are presented on lateral–anterior (left) and medial (right) views of the right hemisphere. All voxels with BSR ≥2.5 are displayed, irrespective of their respective cluster sizes. Note that the directionality of brain activity needs to be interpreted in conjunction with the plotted brain–behavior correlations in    A   . Increasingly positive BSRs in    B    indicate greater reliability of the negative brain–behavior correlations depicted in    A   . 
  
The reliability with which each voxel contributes to the LV (i.e., the “salience” of the voxel) was also determined with bootstrapping. A set of 2000 bootstrap samples was created by resampling participants (with replacement) within each condition. Each new covariance matrix was subjected to SVD as before, and the singular vector weights from the resampled data were used to build a sampling distribution of the voxel saliences from the original dataset. The purpose of a constructed bootstrapped sampling distribution is to determine the reliability of each salience; saliences that are highly dependent on which participants are included in the analysis will have wide distributions. A single index of reliability termed “bootstrap ratio” (BSR) is calculated by taking the ratio of the salience to its bootstrap estimated SE ( ). A BSR for a given voxel is large when the voxel makes a strong contribution to the LV and the bootstrap-estimated SE is stable across many resamplings. 

In the present study, voxel-specific BSR values were thresholded at the 95% confidence interval, corresponding to absolute BSR values exceeding 2.5. We used xjview (  http://www.alivelearn.net/xjview  ) to identify and report the clusters of ≥20 contiguous voxels showing BSRs at or above this threshold ( ,  ).
 
  
Results of behavioral PLS analysis using external motivation to respond without prejudice (EMS) 
      
Behavioral PLS analysis results from the supplemental analysis of the control task 
    

##### Benefits and limitations of PLS analysis 
  
Although other methods exist for examining changes in functional connectivity as a function of individual differences (e.g., psychophysical interaction, dynamic causal modeling), one of the primary advantages of behavioral PLS analysis relative to these methods is that behavioral PLS analysis maximizes coactivation at the whole-brain level without constraining analysis to correlations with a particular seed voxel or region ( ). Behavioral PLS analysis can result in differences in brain–behavior correlations across conditions ( ), albeit in a less subject-specific fashion than for more traditional analyses. This is because estimates for brain–behavior correlations are determined through a bootstrapping approach that collapses across participants. Therefore, behavioral PLS analysis can illustrate intercondition differences in at least two ways. First, confidence intervals for brain–behavior correlations in one or more conditions may contain zero. In this case, one can have little confidence that the condition containing zero in the confidence interval reliably contributes to the latent variable, unlike for the other conditions that do not contain zero in their confidence intervals. Second, confidence intervals across conditions may lie on opposite sides of zero. In this case, one can more strongly articulate a difference between conditions. Namely, conditions with positive (vs negative) brain–behavior correlations would be associated with opposite changes in coactivation in brain regions with large BSR values of the same sign (e.g., positive) as a function of the behavioral variable (e.g., EMS). 

Because behavioral PLS analysis is a data-driven approach, distributed neural responses that maximally covary with the behavioral data need not be condition specific as in the preceding examples. In fact, a significant LV could reflect neural responses that correlate with the behavioral data to a similar degree for all conditions ( ). In this case, supplemental analysis of a control task can provide additional information regarding the relative context specificity of brain–behavior correlations. For the present report, the control task served to determine whether the relationship between EMS and distributed neural coactivation in the impression-formation task, which systematically varies target race, would generalize to a different face evaluation task for which race is not a factor. Such generalization would suggest that findings from our analysis of interest (i.e., how EMS shapes neural coactivation when forming impressions of faces varying in race and status) are not task specific but rather are revealing of broader differences in the neural responses of individuals varying in EMS. 


##### Supplemental PLS analyses 
  
Because the EMS is thought to have different consequences depending on the perceiver’s IMS score ( ), we conducted a follow-up analysis that controlled for IMS by partialing out variance in the EMS accounted for by the IMS and using the residuals in behavioral PLS analysis. Because the mean IMS score was 7.64 (on a scale from 1 to 9), the original analyses of EMS assume a high-IMS participant sample. For all analyses, the pattern of findings was similar even after controlling for IMS. As noted here and in our previous work ( ), the limited range in IMS precludes the possibility of generalizing effects to individuals who are low in IMS (all participants scored above the midpoint of the scale). 

Finally, we also conducted a task PLS analysis of the fMRI data from the impression-formation task. Task PLS analysis differs in important ways from behavioral PLS analysis for which each LV represents (1) a correlation between an individual difference (e.g., EMS) and distributed neural activity across participants and (2) the spatial pattern of voxel activations that supports that profile. In task PLS analysis, each LV represents (1) differences between experimental conditions for each participant (interpreted as a contrast) and (2) the spatial pattern of voxel activity that supports that contrast. In other words, because task PLS analysis results in brain scores at the participant level, it allows for more formal tests of differences between conditions, albeit in the absence of any individual difference variables such as EMS. In the present analyses, we used task PLS analysis to test for latent variables accounting for the relationship between the 2 (race: black, white) × 2 (status: low, high) factorial design and distributed patterns of neural responses. The same permutation and bootstrapping parameters for behavioral PLS analyses were applied to the task PLS analysis. Because results failed to return any significant LV (all   p   > 0.11), we do not further report on the task PLS analysis. 




### Code accessibility 
  
Analyses of RT and postscan ratings were conducted in R ( ) using the lme4 ( ) and lmerTest ( ) packages. The code used to run preprocessing and GLM steps of the analysis was facilitated by SPM8 (  www.fil.ion.ucl.ac.uk/spm  ) and a custom suite of scripts for fMRI analysis (spm8w version r5236;   https://github.com/ddwagner/SPM8w  ). PLS analyses were conducted using a set of scripts based on an existing MATLAB-based PLS analysis toolbox (PLS Applications version 6.1311050:   http://pls.rotman-baycrest.on.ca/UserGuide.htm  ). All code used for analysis is available from the authors on request. Analyses were performed on a linux-based server (OS, Redhat Release 7) using Matlab 2012a. 



## Results 
  
### Reaction time data 
  
RTs were on average just under 1 s (mean RT = 977 ms; SD = 306 ms). Analyses revealed similar RTs irrespective of target race, target status, and EMS score. A marginal main effect of target status (  b   = 0.00673, SE = 0.00350, 95 CI% = [−0.000138, 0.0136],   t   = 1.920,   p   = 0.060) suggested a nonsignificant trend for faster responses when forming impressions of low-status (vs high-status) targets. All other effects were also nonsignificant (  p   > 0.24). 


### Postscan likeability ratings 
  
Postscan ratings of likeability revealed significant main effects of target race (  b   = 0.793, SE = 0.124, 95% CI = [0.550, 1.04],   t   = 6.385,   p   < 0.001) and target status (  b   = 0.413, SE = 0.106, 95% CI = [0.205, 0.621],   t   = 3.896,   p   < 0.001). These effects indicated greater likeability ratings for black (vs white) targets and high-status (vs low-status) targets, respectively. Consistent with the behavioral PLS analysis reported below, we observed a significant main effect of EMS (  b   = −0.175, SE = 0.0790, 95% CI = [−0.330, −0.020],   t   = −2.215,   p   = 0.031), with greater EMS scores associated with lower likeability ratings, irrespective of the race or status of the target. All other effects were nonsignificant (  p   > 0.19). 


### PLS analysis of the impression formation task 
  
Results revealed a significant effect of EMS as the first LV (  p   = 0.028), which explained 61.4% of the crossblock covariance. Across all conditions ( ), larger EMS scores were associated with reduced coactivation in regions that form part of the emotion regulation [rostral anterior cingulate cortex (rACC)], introspection [middle cingulate cortex (MCC)], and social cognition [dorsomedial frontal pole, dorsomedial prefrontal cortex (DMPFC), and temporal pole] networks ( ,  ). This relationship was not substantially impacted when controlling for IMS (first LV:   p   = 0.028, explaining 57.9% of crossblock covariance). Due to the similarity between these two analyses and the limited IMS variance in our high-IMS sample, all reported results are without controlling for IMS. Nonetheless, any differences that emerged between these two analyses are indicated in  . 


### PLS analysis of the control task 
  
Results revealed a significant effect of EMS as the first LV (  p   = 0.025), which explained 56.7% of the crossblock covariance. Notably, only the attractiveness conditions reliably contributed to the LV: model brain–behavior correlation = 0.4235, 95% CI = [0.4568, 0.7570]; actor brain–behavior correlation = 0.1466, 95% CI = [0.0740, 0.6331]. The confidence interval for ratings of actor likeability based on body of work contained zero: brain–behavior correlation = 0.0878, 95% CI = [−0.0025, 0.4718]. In the attractiveness conditions, larger EMS scores were associated with increased coactivation in a distributed network of regions largely localized to the visual cortex, cerebellum, and sensorimotor and lateral prefrontal areas ( ). Note that the directionality of this effect (i.e., EMS was associated with increased coactivation between brain regions) runs in the opposite direction to that observed in the impression-formation task (i.e., EMS was associated with decreased coactivation). 



## Discussion 
  
The present findings provided the first demonstration using PLS analysis that motivation can shape the recruitment of brain networks when forming impressions of others. Specifically, increasing EMS predicted reduced coactivation of regions involved in affect regulation (e.g., rACC), introspection (MCC), and social cognition (frontal pole, DMPFC, and temporal pole) when forming impressions of faces varying in race and social status. The components of the network emerging from the impression-formation task analysis are noteworthy in several respects. We discuss each set of regions separately in the following section. 

Notably, the supplemental analysis of the control task (i.e., explicit evaluations of white actors and models) provides some evidence that the negative relationship between EMS and coactivation in the aforementioned network of regions may be specific to social evaluations when race is a factor (i.e., as in the main impression-formation task). Although the supplemental analysis of the control task showed a positive relationship between EMS and coactivation of a network of regions that was distinct from the main task analysis, we nonetheless caution the reader that this difference may also reflect task differences other than the salience of race. For example, the main task involved privately forming impressions, whereas the control task required relatively more explicit and public ratings. 

Beyond providing insight into the potential neural underpinnings of EMS, the present findings are also noteworthy in that the network observed in the present analysis emerged in a relatively private context. Although previous work often indicates that high-EMS individuals are typically sensitive to experimental contexts in which they believe their responses are being monitored or will be made public ( ;  ;  ), the effects of the EMS are still observed even in a private context. For example, previous studies using both EEG ( ) and behavioral methods ( ) have also identified the effects of EMS on the endorsement/inhibition of stereotypes in private contexts. One possibility is that participants’ awareness that their brains were being scanned while forming impressions of black and white targets may have triggered externally motivated regulation (e.g., pipeline effects, see  ). Unfortunately, these present data do not allow us to directly test the extent to which external motivation was triggered by (erroneous) beliefs about scanners reading minds. It would be interesting in a future study to examine this possibility by scanning participants who have been deceived with information that individual preferences and tendencies can be inferred from brain data versus those who have been informed about the limitations of fMRI research. Informing participants during scanning that their responses will be private (vs made public) should have a similar effect. In summary, although the mechanism requires further study, our findings add to the existing behavioral and EEG literatures, suggesting that EMS may be associated with distinct neural underpinnings even when the central threat pertaining to EMS (i.e., the potential to be exposed as harboring racist tendencies) is minimized by the private nature of the impression-formation task. 

### rACC 
  
Although the present data do not directly speak to the relationship between rACC and affect regulation, the emergence of this region in the present analysis is interesting in light of earlier work that has more directly implicated the rACC (among other regions) in the regulation of negative affect ( ,  ) and prejudice ( ;  ;  ). The rACC and adjacent areas of the orbitofrontal cortex/VMPFC are thought to serve as a conduit for inhibitory signals from dorsomedial and lateral prefrontal regions en route to the amygdala ( ;  ;  ). Even in simple cognitive tasks, rACC is associated with enhanced processing of emotion-related stimuli ( ) and attempts to increase emotional responses to errors under low cognitive load ( ). In the context of race, the rACC has been implicated in the experience of guilt after learning about one’s own implicit prejudice. More specifically, in a high-IMS score sample, rACC activity to prejudice-indicative feedback increased as self-reported guilt decreased ( ), suggesting that the rACC may have been recruited spontaneously to downregulate the negative experience of guilt in the absence of an opportunity to effectively reduce their prejudice ( ). Such an interpretation is consistent with the recent suggestion that the rACC may play a special role in implicit emotion regulation—that is, regulation arising without conscious monitoring, immediate insight, or awareness ( ). 

As in previous work reporting multivariate analyses of race ( ;  ) and gender ( ) perception, response patterns differed from those we observed in our behavioral and univariate analyses ( ). Nonetheless, we note that the rACC region detected in the present PLS analysis overlaps partially with the medial prefrontal region detected in the whole-brain analysis of the same dataset ( ). This univariate analysis indicated that the overall larger response to high-status (vs low-status) targets reversed in high-EMS score individuals, specifically in a region involved in social evaluation (VMPFC, extending to rACC; compare with ROI analyses of VMPFC, NAcc, and amygdala). The brain–behavior correlations in   are consistent with this picture (i.e., indicating numerically larger decreases in coactivation in the rACC for high-status than for low-status targets. Together, these findings suggest that EMS score may be associated with changes in both the participant’s overall approach to the task (i.e., poorer coordination between key networks previously implicated in affect regulation, introspection, and social cognition) and the participant’s sensitivity to target attributes within the task (i.e., status level). Based on the partial anatomic overlap between the findings from these two complementary studies, it will be important to more closely examine the degree to which rACC may play a unique role in supporting both task-general and target-specific effects of motivation. We believe that a multianalysis approach such as the one used for the present dataset should guide such future investigations. 


### MCC 
  
In addition to the rACC, the MCC was also part of the overall network that decreased in coactivation as a function of EMS. Although the MCC is perhaps less frequently implicated in studies on motivation or affect regulation, several studies have tied activity in this region to introspection about one’s own internal states ( ;  ;  ) or unpleasant emotions ( ). In the present study, we observed decreased coordination between this region and areas previously implicated in affect regulation and social cognition as a function of increased EMS. On the basis of this finding, we speculate that increasing awareness of one’s own negative internal states (vis-à-vis neural substrates in the MCC) may play an important role in circumventing the regulatory difficulties experienced by high-EMS score individuals in an interracial context (see  ). In any case, the present finding highlights the MCC as an important ROI in future work on external motivation to respond without racial prejudice. 


### DMPFC and frontal/temporal poles 
  
Beyond the cingulate cortex, EMS was associated with diminished coactivation in regions previously implicated in social cognition, such as the medial prefrontal cortex (frontal pole and DMPFC) and temporal pole. In general, these regions often emerge in studies of impression formation and mentalizing ( ). The frontal pole in particular is thought to support recently evolved aspects of social cognition including the planning and monitoring of goal-directed actions ( ;  ). Recent work illustrates that the frontal pole can be divided into cytoarchitectonically and functionally distinct subregions. Meta-analyses have linked the dorsomedial subregion of the frontal pole (corresponding to the frontopolar region observed in the present study) to affective and social cognitive tasks ( ;  ). For example, this region appears to be sensitive to reputational outcomes for the self and close others ( ). In addition, analyses of functional connectivity have revealed that the dorsomedial frontal pole is functionally connected with a number of other key regions observed in this PLS analysis, including lateral temporal cortex, rACC, and middle/posterior cingulate cortex ( ;  ). 

In addition to the cingulate cortex and frontal pole, we also observed EMS-related decreases in coactivation between the DMPFC and temporal pole. Previous work has implicated these regions in general impression formation ( ;  ;  , ;  ) and the representation of evaluative and/or stereotypic person knowledge ( ;  ;  ), respectively. The EMS-related coactivation between DMPFC and the temporal pole (in addition to the rACC) overlaps considerably with the results observed in a recent study on race-based impression formation in the presence of evaluation-relevant person knowledge ( ). In that study, diminished activity was observed in the DMPFC, temporal pole, and rACC as high-IMS (vs low-IMS) participants formed impressions of black and white targets paired with evaluatively incongruent traits (i.e., positive and negative traits, respectively). This finding suggests that high-IMS (vs. low-IMS) individuals may be less sensitive to evaluative incongruence, resulting in diminished recruitment of regions involved in (affect-related) conflict regulation and impression formation. Notably, the present analysis indicates that these same regions (DMPFC, temporal pole, and rACC, among others) nonetheless exhibit sustained coactivation as high-IMS individuals form impressions of targets varying in race and other attributes (i.e., status). However, this coactivation between regions involved in emotion regulation and social cognition is diminished in individuals with higher levels of EMS. Together, the relationship between EMS and diminished coactivation in this social-cognitive network (in addition to regions involved in affect regulation and introspection) raises the possibility that high-EMS individuals may have been less engaged with the impression-formation task overall, despite also reporting high IMS. Future work is needed to more directly examine the relationships among coactivation in this network, task engagement, and potential mediators, such as negative affect arising from external concerns about implicit evaluative bias. 


### Relevance to the neuroscience of prejudice 
  
Previous neuroimaging work has implicated the frontal control network (including the ACC) in the regulation of prejudice in paradigms ranging from race-irrelevant spatial location tasks ( ;  ) to race-related fear learning ( ) and measures of implicit bias ( ;  ). In recent reviews, the ACC [i.e., dorsal ACC (dACC)] is typically considered to reflect monitoring for conflicts between internal desires to be egalitarian and an undesirable propensity for stereotypic or prejudiced responses ( ;  ;  ;  ). It bears mentioning that cingulate activity in the present analysis was localized to the rACC and the MCC. Although previous work on the neural substrates of prejudice regulation has focused primarily on the dACC, some have suggested on the basis of evidence from event-related potentials (ERPs) that rACC may be recruited to monitor for conflicts with external cues such as egalitarian norms ( ;  ). This possibility is consistent with the present finding that EMS (i.e., an external motivation) affected coactivation in a relatively rostral aspect of the ACC. 

Although this is one of the first fMRI studies to examine the effects of EMS on impression formation (but see  ;  ), previous work relying primarily on ERPs has long suggested that the ACC may be sensitive to perceiver motivations to respond without prejudice. Specifically, high-IMS individuals are thought to exhibit amplified conflict monitoring when race is salient ( ,  ), even when not explicitly instructed to control their racial bias ( ). Even at high levels of IMS, increasing EMS has been observed to diminish control-related ERPs, ultimately resulting in poorer regulation of racial prejudice ( ). This is consistent with the present observation (also in a high-IMS sample) that EMS reduced overall coactivation between a collection of regions previously implicated in both affect regulation (rACC) and social cognition (frontal pole, DMPFC, and temporal pole). 

Finally, it is imperative to note that the present study did not involve any revelations of prejudice; nor did it directly assess the regulation of negative affect. For this reason, it is difficult to determine what mechanism is mediating the effects of EMS on neural coactivation. Exploratory analyses of postscan stimulus ratings indicated a significant negative relationship between EMS and ratings of target likeability irrespective of target race or status, providing indirect support for the notion that high-EMS participants may be less predisposed to like others in the context of this interracial impression-formation task. The reason for this decline in likeability ratings as a function of EMS is unclear. It is possible that forming impressions of any individual in an interracial context is particularly uncomfortable for individuals with high EMS scores ( ;  ;  ;  ), resulting in lower overall likeability ratings. In summary, it will be important for future work to examine additional behavioral correlates of EMS to triangulate more precisely what psychological mechanism underlies the relationship between individual differences in EMS and the pattern of neural coactivation observed in the present study. Consistent with existing evidence that high EMS affects neural control mechanisms in participants concerned about appearing prejudiced ( ;  ), one possibility is that externally motivated concerns (e.g., about the scanner detecting one’s prejudice) may have diminished effective regulation of negative affect arising from conflicts between racial/class bias and intentions to form unbiased impressions ( ;  ). Alternatively, EMS may be associated with a diminished awareness of and/or propensity to regulate negative affect in the first instance. Further research is needed to differentiate between these and other possibilities. 


### Conclusion 
  
Using PLS analysis, we found that EMS diminished coactivation between brain networks previously implicated in affect regulation, introspection, and social cognition as high-IMS white perceivers formed impressions of targets varying in race and status. Notably, this EMS score-related decrease in coactivation was observed in all conditions, suggesting that EMS was associated with the way participants approached the impression-formation task as a whole rather than their responses to attributes of the targets, such as status (but compare with  ). The emergence of the rACC in the present analysis is noteworthy in light of previous work that has more directly examined the role of this region in prejudice regulation ( ;  ;  ). Moreover, together with the previous univariate analysis of the same dataset ( ), the present analysis suggests that the rACC may uniquely contribute to both task-specific and target-specific effects of motivation to respond without racial prejudice. Finally, the current findings also raise new questions regarding the relationship between self-reported levels of EMS and the psychological and neural mechanisms of prejudice regulation. 

In conclusion, the present PLS analysis provides insight above and beyond what was previously obtained using univariate analysis ( ), suggesting that EMS leads to decreases in coactivation in regions previously implicated in emotion regulation, introspection, and social cognition. Although the precise mechanism underlying this EMS-related decrease in coactivation across this network requires further study, we believe that this network and multivariate approach will be a fruitful starting point for research into the neural substrates of previously established relationships among EMS, race-related discomfort ( ;  ;  ;  ), and prejudice regulation ( ;  ;  ;  ;  ;  ;  ). 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-4'>
<h2>4. PMID: 23155450</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Effect of Intentional Bias on Agency Attribution of Animated Motion: An Event-Related fMRI Study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2012</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0049053</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is a whole-brain event-related fMRI study in healthy adult participants (N=12, mean age 25.2) who performed a social-related task (rating intentionality/agency of animated stimuli). The methods report whole-brain acquisition and SPM2-based whole-brain analyses with reported contrasts (high vs low intentionality) and activation maps across brain regions (STS, IFG, occipital areas, etc.). No ROI-only analyses, no clinical or disorder sample, and it is an original empirical fMRI study (not a review). All inclusion criteria are met and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Animated movements of simple geometric shapes can readily be interpreted as depicting social events in which animate agents are engaged in intentional activity. However, the brain regions associated with such intention have not been clearly elucidated. In this study, intentional bias was manipulated using shape and pattern animations while measuring associated brain activity using event-related functional magnetic resonance imaging (fMRI). Twenty-five higher-intention involved and twenty-five lower-intention involved animations were presented to participants. Behavioral results showed that the degree of agency attribution of the mental state increased as intentional involvement increased. fMRI results revealed that the posterior superior temporal sulcus (STS), inferior temporal gyrus (ITG), inferior frontal gyrus (IFG), premotor, temporal pole, supramarginal gyrus, and superior parietal lobule (SPL) were activated while participants viewed the high-intention animations. In contrast, occipital, lingual, and middle frontal gyri were activated while the participants viewed the low-intention animations. These findings suggest that as agent attribution increases, the visual brain changes its functional role to the intentional brain and becomes a flexible network for processing information about social interaction. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (29268 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Recent evidence from cognitive social neuroscience has accelerated our understanding of intricate social brain functions, including processes involving the perception of others and their apparent behavior. However, relatively little research has been conducted to evaluate agency and its role in intentional bias. Moreover, there is limited evidence regarding how the intentional brain can be differentiated from the visual brain. For example, some configural cues such as contingent movement of geometrical patterns trigger an agency or animacy detectors in the brain that can partially explain intentional agents such as other people's minds. 

We hypothesize that the specific intentional brain function of estimating others' mental states based on agency attribution is an extended version of the visual brain. This extension involves recruiting higher brain regions found in the temporo-parietal cortices like the superior temporal sulcus (STS)  . The social braininvolves consciousness of one's own and others' mental states, intentions, attitudes, beliefs and motives and, therefore, is closely related to the theory of mind (ToM) and intentional agents. The ToM requires the ability to estimate the intentional states of others. Estimating another's state of mind involves modeling the other person's intention, possibly by agency attribution and one's own past experience. 

Current social neuroscience studies suggest that the superior temporal sulcus (STS) and medial prefrontal cortex (MPFC) are likely essential components of the social brain region involved in intentional tasks. In order to examine this issue, we developed simple animations that manipulated intentional bias (higher- and lower-intention involved animations) by representing geometrical shapes as opposed to complex verbal or visual tasks. 

In their seminal research, Heider and Simmel (1944)   and Michotte (1963)   used simple moving geometrical patterns as intention-involving agents in a local environment (i.e., a house having walls and a door). In Heider and Simmel's classic experiment, observers were asked to interpret a moving-picture film in which three geometrical figures (i.e., a large triangle (“T”), a small triangle (“t”) and a circle (“c”)) moved in various directions. A rectangle (“house”) with a wall section that opened and closed as a door was also shown. In their original film sequence, the animation was as follows. When the door opened, “t” and “c” moved into the “house.” Then, “T” moved into the “house” and shut the door. Next, “T” and “t” fought and “T” won. Finally, “t” and “c” broke through the door and ran away from the house. This work suggests that moving shapes can simulate the actions of living beings and, therefore, can represent agents performing actions. Accordingly the moving shapes are perceived to have goals and to possess qualities of an intentional mind. Therefore, the moving shapes are likely observed as if they represent the intentional states of others. 

In his theory of interpersonal relations, Heider proposed that individuals perceive and create explanations for the behavior of other's, a process he called “attribution”  . Researchers have documented that higher-order cognition involving concepts such as causality and agency can be elicited by observing interactions, but not by observing the independent random movements of simple geometrical objects. If animations could possibly evoke mental state attributions based on intention, we propose that attributions of a mental state can be applied to animated objects. If this supposition is true, it would suggest that the neural substrate associated with understanding intentional events would include the same substrate (i.e., the STS) that becomes active when watching an interactive animated object in cooperation with other regions  . To date, however, there have been few empirical studies to investigate why and how these attributions are affected by animations containing objects with lower- or higher-intentional involvement. 

In mentalization studies in which the ability to estimate another's mind is required, the observer must infer and model the intentions of another person. In this type of paradigm, the observer models the behavior of the other person prospectively by using attributions that are represented as animated dots or cartoons. For example, Baron-Cohen et al. (1994)   found a rCB (regional cerebral blood flow) increase in the orbitofrontal cortex of the right hemisphere during the TOM task. Abel, Happe, and Frith, using two triangles moving around the screen in one of three ways (ToM-like, in a goal-directed way, or randomly), compared the attribution of the mental state in autistic children having less TOM than that of normal children, finding that the former used mentalizing (ToM-like) descriptions less often than the latter did  . 

In another study, Schultz et al. presented short animations to participants in which two moving disks appeared to be either interacting or moving independently from each other  . Using fMRI, they found that activation in the STS increased in proportion to the degree of correlation between the motion of two disks, and that an increase in correlation increased the amount of interactivity and animacy the observers attributed to the two disks. 

Perception of animacy also influences interactive behavior  . Recent fMRI studies using non-Heider & Simmel patterns showed that the STS is also activated by simple moving objects whose interactions appear causal or intentional   and that the STS is involved in the representation of observed intentional actions  . Saxe et al. presented a real movie of a human walking into a room with or without occlusion (e.g., bookcase), finding that the walking figure activated the right posterior STS, which appears to be sensitive to the relationship between the observed motion and local environment  . They further hypothesized that the right posterior STS is involved in the representation of observed intentional actions. 

In a study using PET, Castelli, Happe and Frith presented participants with a silent, computer-generated animation involving two simple geometric shapes (e.g., triangles) that resembled Heider and Simmel patterns  . They found that the STS, MPFC, and temporal regions, including the fusiform gyrus, temporal pole, and occipital gyrus, were activated. The investigators argued that these animations strongly evoked mental state attributions based on intentions and hypothesized that the ability to make inferences about another's mental state evolved from the ability to make inferences about another's apparent behavior. Their findings suggest that controlling the degree of intention from high to low evoked by animations that vary in attribution appears to be critical in this type of research. They had six adult participants observe an animation that involved two moving triangles that manipulated the degree of intention from high to low in three ways: 1) ToM-like, corresponding to high intention; 2) goal-directed, corresponding to intermediate intention; and 3) randomly, corresponding to low-intention intention. These stimuli could therefore be graded from random movements to goal-directed actions, and finally to complex intentional states. 

The primary goal of the current work was to evaluate the degree to which intentional bias could result in greater STS activation and less MPFC activation. Similar animations were used such that objects always stayed within the same local region. However, animations differed in terms of their movements. Specifically, some animations were designed to give a graded impression of either intentional-oriented interactions or mechanical-oriented movements  . In other words, a primary aim of our study was to describe how the social brain is influenced by animations that evoke high intention relative to less or no intention. We sought to replicate and extend the findings of Castelli et al.   using a larger sample and event-related technology, and by grading stimuli based upon random movements, goal-directed actions, and complex intentional states. 


## Methods 
  
### Participants 
  
Twelve healthy, right-handed participants (4 males and 8 females; mean age = 25.2) and fifteen separate participants (11 males and 4 females, mean age = 25.8) were recruited for the fMRI experiment and preliminary rating study, respectively. All had normal or corrected-to-normal vision, and were screened for the presence of current or past neurological and psychiatric disorder. 


### Ethics Statement 
  
The experiment was conducted in accordance with the guidelines of the ethical committees of the Brain Activity Imaging Center (ATR, Kyoto, Japan) and of Kyoto University. All individuals voluntarily participated in the study and provided their written, informed consent prior to study participation. 


### Procedure 
  
The animations used in the study was modeled on that of Heider and Simmel  .   depicts examples of the five-second animations (moving from left to right) used. Two or three triangles of different colors (blue, pink, and green) moved around on a black background. These triangles corresponded to the “t,” “c,” and “T” stimuli used in the Heider and Simmel animation. Additionally, the animation had a “house” with a gap on its side wall. 
   Typical animation strips from high- and low-intention groups, each 5 seconds in length from left to right.  
Three geometrical objects of different colors (blue, red, and green triangle) move around a black background containing a “house,” which has a gap on its side wall. Preceding the experiment, 2 sets of 25 animation movies each were developed that involve high- and low-intentionality groups. The movies varied in terms of the ratio of degree of attribution of mental states to animated pattern. For example, when the door opened, blue and red move into the “house”. Then, green moves into the “house” and shuts the door. Green and blue fights and green wins. Blue and red broke the door and they ran away from the “house” under the highest intentionality condition (rated 5.77), while figures move in parallel under the lowest intentionality condition (rated 1.79). 
  
The upper panel of   shows a high-intention-involved animation (rated 5.77 and corresponding to condition i = 1 in  ; see movies for details). In our preliminary study (see below), one participant reported a ToM-like story corresponding to the high-intention-involved animation as follows: “When the door of the ‘house’ opened, the blue and pink triangles moved in. Then, a green triangle moved in. Green and pink fought and green won. Blue and pink broke out of the ‘house’ and ran away. Based on this script, the two triangles were chased and persecuted by the green triangle and each triangl moved in an interactive way. 
   Samples of matched animation sequence from left to right with a 1 s interval between sequences.  
The upper panel depicts matched pairs (i = 9, r = 9; three triangles) and the lower panel depicts other matched pairs (i = 19, r = 19; two triangles). I = intention; R = random. 
  
The lower panel of   depicts a low-intention-involved animation (rated 1.79 and corresponding to condition r = 1 in  ; see movie file in detail). In our preliminary study (see below), a typical response to a story corresponding to one of the low-intention-involved animations as follows: “Triangles moved merely randomly or drifting without interaction”. By varying the motion path of the triangles, 25 different pairs consisting of one high- and one low-intentionality animation were designed for a total of 50 animations. Interactive motion (two triangles chased and persecuted by the third triangle) was varied by the experimente. In order to test the effect of the number of objects, we used three triangles in all but six pair in which the green triangle did not appear. The animations were created and encoded using Adobe Flash CS3 (30 flames per second, 320×320 pixel). 


### Preliminary study 
  
In the preliminary behavioral study, 15 participants rated each animation based on an intentionality score. The intentional score was rated using a Likert-type scale of 1 to 7 (1: not at all intentional; 7: highly intentional). Next we selected 25 “high” and 25 “low” intentionality animations. Observers were asked to rate intentionality between the blue object and the other objects based on their mutual actions. 

Pairs of high- and low-intention animations were created. Their paths of motion are shown in  . The highest-intention animation was created in a manner similar to the Heider and Simmel   pattern (  upper panel, which corresponds to i = 1 motion path in  ). The lowest intention (i.e., random) animation was made by simple drifting (  lower panel, which corresponds to r = 1 motion path in  ). We also made a series of different intermediate animation pairs for a total of 25 pairs ranging from (i = 1, r = 1) to (i = 25, r = 25), where i and r indicates intention and random, respectively. Thus, we matched animation to have a similar motion path length and time for all triangles within a pair. Based upon this design, it was expected that participants would judge the triangles in a pair (for example, i = 19, r = 19 shown in  ) to be somehow different from each other in terms of intentionality, while triangles in another pair (for example, i = 1(highest), r = 1(lowest) shown in   and  ) would be much different from each other Thus, we created a total of 25 graded steps of stimulus pairs. Of the 25 animations, the mean intentionality score was 5.77 in the “high” group and 1.79 in the “low” group. 

A two-way repeated-measures ANOVA (intention×animation number) revealed a significant main effect for intentionality [F(1,14) = 768.9,   p  <.001] and stimulus number [F(24,336) = 4.82,   p  <.001]. We also found significant interaction between intentionality and stimulus number [F(24,336) = 6.35,   p  <.001]. Multiple comparisons using Turkey's HSD revealed significant differences between high- and low-rated scores. Thus, we confirmed that the higher-rated group was significantly more sensitive to intention than the lower-rated group. T-tests comparisons between the number of objects (2 to 3 objects) found no differences in terms of intentionality. Based on these preliminary findings, we adopted all the stimulus objects tested for later experiments. 


### fMRI session 
  
No participants who participated in the preliminary study participated in the fMRI study. In an fMRI session, an animation was presented one second after a beep tone and an evaluation screen appeared which asked the participant to rate the level of intentionality from one (high) to four (low). Participants made ratings by choosing from two sets of four buttons (one set for each hand). One trial took 17 s, resulting in a total of length of 14 min 30 s for each session. For the first session, fifty moving patterns were presented in random order to participants in a counter-balanced manner. Twenty-five patterns were presented to the high group and to the low group, respectively. In the second session, up-down reversed patterns from the first session were presented. The presentation of normal and up-down reversed patterns was counter-balanced for each participant. In the preliminary study, we confirmed that participants could easily decide a response after reading the agent's intention 3 s after presentation. Therefore, the fMRI scan began 3 s after the animation presentation. 

Animations were back-projected onto a screen viewed through an angled mirror. The size of each animation was 11.5°×11.5°. In one session, participants observed 50 animations presented in random order. The length of each trial was 17 seconds. 


### fMRI data acquisition 
  
Whole brain images were acquired on a 1.5-T whole-body magnetic resonance imaging scanner (Shimadzu-Marconi Magnex Eclipse, Kyoto, Japan). Head motion was minimized with a forehead strap. Functional MRI was performed with a gradient echo-planer imaging (TR = 3000 ms, TE = 49 ms, flip angle = 90°, 5 mm slice thickness, FOV = 192 mm×192 mm, and pixel matrix 64×64). After the collection of functional images, T1-weighted images (154 slices with no gap) using a conventional spin echo pulse sequence (TR = 12 ms, TE = 5 ms, flip angle = 8°, FOV = 220 mm×220 mm, and pixel matrix 256×256) were collected for anatomical co-registration with the functional images. 

After image reconstruction, functional images were analyzed using SPM2 (Wellcome Department of Imaging Neuroscience, London, UK). Six initial images were discarded from the analysis to eliminate the non-equilibrium effects of magnetization. All functional images were corrected for between-slice timing differences in image acquisition and realigned to correct for head movement, which was less than 1 mm within runs. The functional images were normalized and spatially smoothed with an isotropic Gaussian filter (6 mm full-width at half-maximum). Low-frequency noise was removed by high-pass filtering (time constant = 128 s). We conducted the analysis using an event-related design. An onset of an event according to the data analysis occurred three seconds after an animation started based on the results of the preliminary study. 

Data were modeled by convolving the vector of expected neural activity with the canonical hemodynamic response function (HRF) included in SPM2 and modulated by ratings of intentionality (4-point scales: high for 4 and low for 1). Single-participant   t  -contrast images were then entered into second-level analysis using a random effects model for all participants. The levels of statistical significance for these analyses were set to   p  <0.001 (uncorrected). 



## Results 
  
Two contrasts were specified per single-participant analysis: 1) Low versus High and 2) High versus Low. Low-intention involves activations under participant's button press 1 (highest) and 2 (higher) and high-intention involves that of button press 3 (lowest) and 4 (lower). As shown in   and  , fMRI revealed activation of three main areas when participants observed 25 low-intention-involved animations (low>high): the left middle occipital areas including the calcarine sulcus/cuneus (BA17,18), the right lingual gyrus (BA18), and the right prefrontal gyrus in the middle prefrontal cortex (BA9). However, when participants observed 25 high-intention-involved animations and intentional bias was increased (high>low), the activated areas extended to include the bilateral posterior STS sulcus (BA22/37/39), the right temporal pole (BA38), the bilateral inferior frontal gyrus (BA47:IFG), the premotor (BA6), the inferior temporal gyrus (ITG), the left supramarginal gyrus, and the left superior parietal lobule (SPL). We did not find any activation in the MPFC ( ). 
   Brain activation regions for high→low-intention corresponding to the social brain (i.e., yellow area) and areas for low→high-intention corresponding to the perceptual brain (i.e., blue area).  
Event-related fMRI results showed that main activation areas occurred in three regions while participants observed low-intention animations: extrastriate cortices including calcarine sulcus and lingual gyrus (BA 17,18), and right middle frontal gyrus (BA9). During high-intention animations, activation of more widespread regions was observed, including: bilateral inferior frontal gyrus (BA47:IFG), premotor (BA6:PM), superior temporal sulcus (BA22/37/39: STS), inferior temporal gyrus(ITG), left supramarginal gyrus (SMG), left superior parietal lobule (BA 7: SPL), and right temporal pole (BA38:TP). 
     Brain region of activation for each contrast.        

## Discussion 
  
In this study, we sought to investigate the differential contributions of the areas involved in visual and intentional cognitive processes. Participants conducted tasks that required them to make social interpretations by looking at moving objects that were presented as low- or high-intentionally biased animations. By varying the stimuli, we varied the extent to which intentional cognitive processing was required, which facilitated the analysis of intentional and perceptual influences on various brain regions. 

Based upon event-related fMRI data, our results revealed activation of several visual areas including the calcarine sulcus/cuneus and the lingual gyrus (BA17, 18), which is near the fusiform gyru when the visual brain operated in a mechanical low-intention-involved context. The middle frontal gyrus is thought to maintain visual attention to groups of moving objects  . In contrast, the fusiform gyrus is believed to play a general role in the representation of visual stimuli that signify intent, independent of the visual form  . Our finding of activation in the lingual gyrus, which is near the fusiform gyrus corroborates with a previous study  . 

As shown in  , when the brain processes high-intention-involved interactive animations, activation in the posterior STS involving part of the supramarginal area increased. It has been demonstrated that the STS becomes activated while viewing animated geometrical figures portraying social interactions  ,  ,   and when evaluating the intentions of others. Using fMRI, Gobbini et al.   reported that social animations activated an extensive portion of the STS including areas in the posterior STS as well as the inferior parietal lobule. 

In an earlier PET study, Castelli et al.   presented animations that featured two characters (a large red triangle and a small blue triangle) moving on a framed white background similar to Heider and Simmel's pattern  . The investigators presented each participant with three types of animation: 1) ToM (two triangles bluffing one another); 2) goal-directed (two triangles dancing together); and 3) random (two triangles merely drifting). These animations were displayed for approximately 40 s over the course of 12 scans and divided into two consecutive counterbalanced blocks consisting of cued and uncued animations. These animations were designed to evoke mentalizing and elicited activity in the STS relative to a random motion condition. The design of the current study improved that done by Castelli et al. in two ways. First, intentional biases were manipulated continuously from highest to lowest by 25 matched pairs selected from 50 animations using ratings from the participants in a preliminary study. Second, an event-related design was introduced to avoid prior knowledge by using a shorter presentation duration (5 s). Based on our results, it is likely that intentional bias may be controlled more by the STS than by the MPFC, particularly when brain responses to high-intention-involved animations are compared with responses to low-intention-involved animations. 

The STS has been hypothesized to be closely connected to the perception of biological motion. Studies using transcranial magnetic stimulation   and magnetoencephalography   have shown that the simulation of human walking induced by moving dots selectively activates a brain area on the ventral bank in the occipital extent of the STS and the right temporo-parietal junction. Furthermore, such animations may be similar to the Heider and Simmel   paradigm. We show here that tasks tapping mentalization and agency attribution activated the same brain regions in the STS and temporo-parietal cortices including the supramarginal gyrus, inferior temporal gyrus, the temporal pole, and the SPL. One explanation for why we did not find activation in the MPFC is that we used an event-related design to avoid expectancy with a much shorter presentation time than the 30 s previously reported  . Expectancy cueing and longer presentation time could also yield possible contingent activations in the MPFC in addition to controlling intentional bias in the STS. It is highly possible, therefore, that higher-intention-involved animations, such as the fight between the blue and green triangle used in the current study, was perceived by the observer as though he/she was participating in the action against an antagonis. Indeed, humans may possibly detect intentions in shapes, even when those shapes change their motion to face another object  . 

Overall, we assumed that activation in the premotor cortex invoked a mirror system when a human acts and when the person observes the same action performed by anothe  . This system may be important for understanding the actions of other people, and that of the geometrical shapes in our animations. Some researchers also speculate that mirror systems may simulate observed actions, thus contributing to ToM skills  ,  . In the premotor area, a functional mirror system estimating others' intentions may contribute to activation of the IFG  . In the current study, significant increases of activation in the IFG were observed only when the animations were actively viewed with intention. Therefore, it is possible that the IFG monitors intentional thoughts in the STS. In contrast, activity in visual areas, including the lingual gyrus, which is near the fusiform gyrus, was only found in conditions requiring less intentional involvement and passive viewing. 

With close interconnections to the STS, the IFG and the temporal pole provide internally-represented self and other's mental states. Rather than the MPFC per se, it is the ventral side of the IFG, close to the orbitofrontal PFC and temporal pole, along with temporo-parietal-junction areas including the posterior STS and supramarginal gyrus  ) that are possible critical components for the representation of another's mental state. Saxe et al.   examined whether activation of the posterior STS, similar to the perception of intentionality, depends particularly on the contingency between an agent's motion and the environment by introducing short and long occlusions of a walking person's animation strip. They showed that right posterior STS activation occurred following the long occlusion (i.e., when a person remained hidden for a few seconds before re-emerging). In the current study, we found activation in the same region; namely, the bilateral posterior STS, using simple geometric animations depicting high-intention-involved action. The present study suggests that the posterior STS is involved in constructing an abstract visual description of another agent's intentional actions, without engagement of the MPFC. Based on the present results, it is possible that incoming animated information is decoded perceptually and integrated with contextual interpretation; the constituent product of these two processes can be understood either in terms of perceptual- or intention-involved behaviors. 

In their examination of the neural correlates of mentalization, Vogeley et al. (2001)   used fMRI to investigate common and differential neural mechanisms underlying ToM and the self during the presentation of a verbal story, finding that a ToM task led to increased neural activity in the temporal pole, whereas the self-task led to increased neural activity in the right temporo-parietal junction involving the STS. Interestingly, our data corroborate theirs regarding the neural correlates of ToM despite the large differences in the methods employed. The ability to model another intentional mind using an animated patter could be an evolutionary innovation in the human social brain that developed from the perceptual brain. Further investigations are necessary in order to clarify this issue. 


## Conclusion 
  
To summarize, we investigated how the visual brain transitions to the social brain using event-related fMRI in the present study. Animations consisted of moving patterns evoking various mental states of attribution based on intentions. Among 25 pairs of animations, each participant rated the higher- and lower-intention animation according to their attribution of agency (i.e., internal or external). Results showed that activations of the posterior STS, ITG, IFG, premotor, temporal pole, supramarginal gyrus, and SPL occurred under high-intention–involved animations, whereas occipital, lingual, and middle frontal gyri were activated under lower-intention-involved animations. 

Findings of the present study suggest that as intentional stance increased, the portion of the social brain involving the representation of an agent's intentional actions became more activated. Thus, developing the capacity to model another's mind could be an evolutionary innovation in the human social brain that developed from the perceptual brain. Previous studies have implicated regions activated by higher intention in self-monitoring in the perception of biological motion and in the attribution of mental states, and regions activated by lower-intention in simple perceptual processing. In the present study, we report how the visual brain shifts to the social brain in an agency attribution experiment. We suggest that as agent attribution increases, the visual brain changes to the intention-assuming social brain and therefore possesses a flexible network for processing information about social interactions based on agency attribution. 


## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-5'>
<h2>5. PMID: 22062191</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Autism spectrum traits predict the neural response to eye gaze in typical individuals</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Neuroimage</p>
<p><strong>Publication Year:</strong> 2012</p>
<p><strong>DOI:</strong> 10.1016/j.neuroimage.2011.10.075</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study reports an fMRI experiment in healthy adult participants (N=18; ages 18–30) performing a social task (viewing and classifying faces with gaze/head manipulations). Whole-brain second-level analyses were conducted (reported at p<0.05 FDR whole-brain with cluster threshold) showing AQ-related activation across the social attention network. Participants were typical (no neurological/psychiatric disorders) and within the 18–60 age range. Although supplementary ROI analyses were performed, the primary reported results are whole-brain, not ROI-only. The paper is an original fMRI study (not a review/meta-analysis) and does not report clinical samples. Therefore it meets all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Autism Spectrum Disorders (ASD) are neurodevelopmental disorders characterised by impaired social interaction and communication, restricted interests and repetitive behaviours. The severity of these characteristics are posited to lie on a continuum extending into the typical population, and typical adults' performance on behavioural tasks that are impaired in ASD is correlated with the extent to which they display autistic traits (as measured by Autism Spectrum Quotient, AQ). Individuals with ASD also show structural and functional differences in brain regions involved in social perception. Here we show that variation in AQ in typically developing individuals is associated with altered brain activity in the neural circuit for social attention perception while viewing others' eye gaze. In an fMRI experiment, participants viewed faces looking at variable or constant directions. In control conditions, only the eye region was presented or the heads were shown with eyes closed but oriented at variable or constant directions. The response to faces with variable vs. constant eye gaze direction was associated with AQ scores in a number of regions (posterior superior temporal sulcus, intraparietal sulcus, temporoparietal junction, amygdala, and MT/V5) of the brain network for social attention perception. No such effect was observed for heads with eyes closed or when only the eyes were presented. The results demonstrate a relationship between neurophysiology and autism spectrum traits in the typical (non-ASD) population and suggest that changes in the functioning of the neural circuit for social attention perception is associated with an extended autism spectrum in the typical population. 
   Highlights  
► Autistic spectrum might extend to typically developing (TD) individuals. ► We studied TD individuals with varying Autism Spectrum Quotient (AQ). ► AQ correlated with BOLD response to viewing variable vs. constant eye gaze. ► AQ did not correlate with response to directional control stimuli. ► Neurophysiology and autism spectrum traits are associated in non-AS individuals. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (30795 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Autism spectrum disorders (ASD) are characterized by abnormal social interaction and communication, severely restricted interests and repetitive behaviour. ASD have a range of clinical phenotypes from mild to severe, however an even wider continuum of social-communicative ability has been proposed extending into the general or typical population ( ). Initial support comes from studies demonstrating that the degree of autistic traits measured by Autism Spectrum Quotient (AQ;  ), in both ASD and typical populations, is related to performance on behavioural tasks that show impairments in ASD, including self-focussed attention ( ), the ability to draw mentalistic inferences from the eyes ( ), and attentional cueing from eye gaze ( ). However, stronger evidence for a continuum extending into the typical population would involve a demonstration that the neural response to these sorts of social tasks or stimuli is related to typical participants' scores on the AQ. 

Neuroimaging has shown structural and functional impairments in ASD in ‘social’ brain regions involved in processing goal-directed actions and biological motion (superior temporal sulcus, STS), theory of mind (medial prefrontal cortex; mPFC and temporo-parietal junction; TPJ), and emotion (amygdala) (see reviews in  ). A number of these areas, together with components of the attention system, are recruited during gaze perception ( ), and we will refer to them as the ‘social attention’ network. Since individuals with ASD also show an abnormal neural response to gaze cues ( ), gaze perception provides a well-grounded model for studying neurophysiological correlates of the autistic spectrum in the general population. Our recent work in typical participants showing that individual differences in AQ predict changes in the structure and function of the posterior STS (pSTS), a central component of the social attention network, provides further reason to predict that a relationship between AQ and the social attention network might be found ( ). Specifically, this study found a reduction in white matter in pSTS of individuals with higher AQ scores. This was accompanied by an increased task-independent deactivation in high-AQ subjects, akin to ‘resting state’ activity, in the same area of pSTS. Here we investigate whether the BOLD response in the pSTS region, and wider components of the social attention network with which it is connected ( ), show a significant relationship with AQ in response to viewing gaze stimuli. This would provide the first direct evidence that individual variation in autism spectrum traits in typical participants impact on the neural correlates of social processing. We addressed this in the context of a functional magnetic resonance imaging (fMRI) study. 

Participants viewed epochs of faces gazing in ‘variable’ directions (i.e., left, direct, and right) or a constant direction (e.g., all left), implying rapid changes in their focus of attention or interest, or no change, respectively ( ). A second, control condition comprised ‘variable’ and ‘constant’ epochs of oriented heads with eyes closed, thus physical direction was again variable or constant but without concomitant changes in the faces' focus of attention and interest. ASD is known to impact primarily on the ability to draw mental inferences from social attention cues (e.g., that a person is   interested   in something to their left) rather than discrimination of their perceived physical direction ( ). Consequently, an effect of AQ on the social attention network was predicted to be most apparent for a comparison of the variable versus constant gaze conditions because mental inferences regarding the faces' should be greater for the rapidly changing foci of interest conveyed by the variable gaze condition relative to the constant gaze condition in which the focus of interest remained fixed. In contrast, we predicted that an effect of AQ should be absent for a comparison of the variable versus constant head conditions because heads with eyes closed convey directional information only. 

Our study also included a third ‘Eyes only’ condition in which gaze was again variable or constant but only the eyes were visible. For this condition we predicted a reduced or absent relationship with AQ for a comparison of the variable and constant conditions since previous research has shown that perception of gaze direction, or gaze following, is heavily influenced by the orientation of the head. For example, significant gaze cueing to the left (or right) has been reported using gaze cues in which the heads are rotated to the left (or right) and the gaze directed towards the observer ( ). Moreover, these effects were significantly larger than those observed using leftward (or rightward) oriented heads with their gaze oriented in the same direction as the heads. This suggests that the cueing effect is not dependent on the direction of the gaze alone, but is contingent on directional cues conveyed by the head   and   eyes. 


## Materials and methods 
  
### Participants 
  
Eighteen right-handed typical, healthy volunteers (4 males; aged 18 to 30 years; mean age = 24 years) with normal or corrected to normal vision participated in the study in return for payment. Individuals with a history of neurological or psychiatric disease or currently taking medication affecting the central nervous system were excluded. All provided written informed consent as a part of a protocol approved by the Suffolk Research Ethics Committee. Participants completed the AQ before scanning. This questionnaire contains 50 questions measuring the extent of autism spectrum characteristics, and has good test–retest reliability and internal consistency ( ). 


### Design and procedure 
  
Stimuli and design are summarized in  . The stimuli were prepared from 10 computer-generated faces (5 males and 5 females). Participants were shown three types of facial stimuli. A ‘Gaze’ condition comprised full-face views of faces with eyes oriented 25° left (L), 0° (direct), or 25° right (R). In a second ‘Heads’ condition, heads with eyes closed were oriented 25°L, 0°, or 25°R. In a third, ‘Eyes only’ condition, the gaze was again oriented 25°L, 0°, or 25°R, however, the majority of the head was masked leaving only the eyes visible. The facial stimuli were presented in 15 s epochs containing six presentations of one of the three facial stimulus types. The epochs were divided into two further conditions — ‘variable’ and ‘constant’. For example, in the ‘constant’ condition for the Gaze stimuli, all faces displayed the same gaze direction (i.e. all 25°L, all 0° or all 25°R), whereas the variable condition comprised continually changing gaze directions (i.e. 25°L, 0° and 25°R in random order). Similarly, the variable and constant conditions for the Heads and Eyes-only stimuli showed different or repeated head and gaze orientations. 

Each facial stimulus was presented for 2 s, followed by a 500 ms blank screen to prevent apparent motion. Consecutive faces never showed the same identity. The task was to categorize the gender of each face. Seven epochs of each category were presented. The order of epochs was fixed for each participant (e.g. gaze, heads, eyes-only, gaze …) counterbalanced across participants. The face epochs were interleaved with 10 s epochs of house images. This helped to reduce activation in the gaze network between face conditions and acted as a baseline condition. Note that houses were used in preference to a fixation (rest) condition because activation at rest varies between individuals with Autism and typical controls in brain areas associated with social processing, and is correlated with AQ in typical participants ( ). To reduce task switching, participants were also asked to categorize the gender (‘masculine’ vs. ‘feminine’) of the house stimuli. Pilot testing showed that participants were readily able to categorise houses with these labels. The total task duration was 33 min and 50 s. The stimuli were presented via an angled mirror above the participants' eyes. The mirror reflected images back-projected onto a translucent screen in the bore of the magnet behind the participants' head. All participants practised the task outside the scanner prior to the experiment. 


### Image acquisition and preprocessing 
  
MR imaging was performed with a 3-Tesla Tim Trio Magnetic Resonance Imaging scanner (Siemens, Germany) with a head coil gradient set at the MRC Cognition and Brain Sciences Unit. Whole-brain data were acquired with an echo-planar T2*-weighted (EPI) imaging sequence, sensitive to the blood–oxygen-level-dependent (BOLD) signal contrast (40 oblique slices, 3 mm slice thickness; TR = 2424 ms; TE = 30 ms; flip angle = 78°; FOV 192 mm; voxel size = 3 × 3 × 3 mm). The first 3 volumes were discarded to allow for equilibration effects. T1-weighted structural images were acquired at a resolution of 1 × 1 × 1 mm. Data were preprocessed and analyzed using SPM5 software (  www.fil.ion.ucl.ac.uk/spm/  ). The EPI images were sinc interpolated in time to correct for slice time differences and realigned to the first scan by rigid body transformations to correct for head movements. EPI and structural images were coregistered and normalized to the T1 standard template in MNI space (Montreal Neurological Institute (MNI) — International Consortium for Brain mapping) using linear and non-linear transformations, and smoothed with a Gaussian kernel of FWHM 8-mm. 


### Analysis of regional effects 
  
A random effects model was implemented using a two-stage process, of within (first level) and between (second level) subjects modelling, in turn. This random-effects analysis assessed effects on the basis of inter-subject variance and thus allowed inferences about the population that the participants were drawn from. For each participant we used a GLM to assess regionally specific effects of task parameters on BOLD indices of activation. The model included two experimental factors — stimulus type (Gaze, Heads, and Eyes-only) and presentation format (variable vs. constant); effects of no interest (realignment parameters) were also included to account for motion-related variance. Low-frequency signal drift was removed using a high-pass filter (cutoff 128 s) and AR(1) modelling of temporal autocorrelations was applied. 

The individual contrast images were generated using the following contrasts: i) variable versus constant gaze, ii) variable vs. constant heads, and iii) variable vs. constant eyes-only. The second level analyses used these contrast images in new GLMs with AQ as a regressor (plus a constant term), from which we generated statistical images, i.e. SPM-t maps, of voxels showing positive or negative relationships with AQ. With balanced designs at the first level (i.e. similar events for each subject, in similar numbers) this second level analysis closely approximates a true mixed effects design, with both within and between subject variance. A recent meta-analysis identified that perception of others' gaze engages a network of regions comprising the pSTS/TPJ, fronto-parietal attention system, amygdala, and dorsal medial prefrontal cortex ( ). The relationship between AQ and activation in this network was assessed with a threshold of p < 0.05 whole-brain FDR correction and minimum cluster size of 20 voxels. 



## Results 
  
### Behavioural data 
  
The distribution of the AQ scores was as follows: range = 7–33,   M   = 16.80,   SD   = 7.60. The mean accuracy for gender classification of faces was high (86%) and exceeded chance level (50%) for all task conditions,   p  s < 0.05. However, accuracy varied slightly across task conditions,   F  (2,34) = 5.50,   p   < 0.01, η  = 0.24 (  M   = 91%,   M   = 81%,   M   = 88%). As would be expected, accuracy for eyes-only condition was lower than that for the gaze (  p   < 0.01) or head (  p   < 0.01) conditions, for which the full face was visible; the gaze and head conditions did not significantly differ (  p   > 0.05). Median latencies for correct responses were also influenced by condition,   F  (2,34) = 34.48,   p   < 0.001, η  = 0.67 (  M   = 612 ms,   M   = 774 ms,   M   = 613 ms). Latency for eyes-only condition was longer than that for the gaze (  p   < 0.01) or head (  p   < 0.01) conditions, with no differences between the latter two conditions (  p   > 0.05). Neither the accuracy nor the response latency correlated with the AQ scores,   r  s < 0.3,   p  s > 0.4. Accuracy and RTs were not analyzed for the house trials because responses could not be categorised as correct and incorrect. 


### fMRI data 
  
The second-level contrasts for variable vs. constant gaze, variable vs. constant heads and variable vs. constant eyes-only (or vice versa) did not yield any significant effects. Consistent with our hypothesis, however, the variable vs. constant gaze comparison yielded significant positive correlations with the AQ ( ) in a number of regions of the gaze perception network, including right pSTS (50, − 50, 18,   T   = 4.38), intraparietal sulcus (IPS) (34, − 48, 60,   T   = 4.43), bilateral amygdala (left: − 26, − 8, − 12,   T   = 4.37; right: 26, − 4, − 14,   T   = 3.81) and right TPJ (52, − 58, 8,   T   = 4.38). Additional cortical clusters were observed in the vicinity of the MT/V5 (− 42, − 66, 2,   T   = 7.87) and inferior parietal lobule (IPL) and supramarginal gyrus (SMG) (− 42, − 30, 36,   T   = 4.35). Other regions that survived our a priori threshold are summarised in  . 

Following the request of one of the reviewers, a secondary ROI analysis (see Supplementary  ) using independently defined ROIs confirmed that AQ correlated significantly with BOLD response to gaze specifically in regions that prior studies have linked with gaze and face perception (OFA, FFA, pSTS, IPS and amygdala) as well as mentalizing (TPJ),   p   < 0.05 FWE small-volume corrected. In contrast to the gaze condition, AQ scores did not significantly correlate with activation to the variable vs. constant heads and variable vs. constant eyes-only conditions in any brain region, even at reduced threshold (  p   < 0.05, uncorrected). 

As the AQ can be split up into five subscales measuring different domains (social skills, attention switching, attention to detail, communication and imagination), we tested whether the scores for these domains would also show correlations with the variable versus constant gaze/heads/eyes only contrasts. The overall pattern was similar to that observed with the composite AQ score. Once again, the scales only correlated with the response to variable versus constant gaze, and not with variable versus constant heads or eyes-only. The correlations were also smaller in magnitude on average than those for the composite score. This may be because the range of the subscale scores is truncated in comparison with the composite AQ score. Subscales for attention to detail, imagination and social skills showed the largest correlations with the variable versus constant gaze contrast, while attention switching and communication showed the smallest correlations (see Supplementary  ). 

Finally, it is possible that the correlation between AQ scores and activation to variable versus constant gaze was due to an increased response to variable gaze, a decreased response to constant gaze, or both. To explore this further, we examined the correlation between AQ and i) responses to variable gaze vs. house stimuli and ii) constant gaze vs. house stimuli. This demonstrated that for the same regions as shown in  , AQ correlated   positively   with variable gaze versus houses and   negatively   with constant gaze versus houses ( ). 



## Discussion 
  
Our study shows that in typical individuals, the neural response to eye gaze across the social attention network (pSTS, TPJ, amygdala, IPS, SPL, and SMG) is closely related to the number of autism spectrum characteristics they display. The overlap between these AQ-dependent responses and the network for social attention identified by recent meta-analysis ( ) is illustrated in  . Although functional imaging studies have not revealed a specific neural marker of ASD, they have consistently shown abnormal functioning of a number of the same regions that showed AQ-dependent changes in BOLD response in the present study, namely the TPJ, STS and amygdala (see reviews in  ).   showed that relative to typical controls, individuals with ASD show less activation to eye gaze cues in areas such as the pSTS. At first sight then, it is surprising that we found a positive association between AQ and the hemodynamic response to variable versus constant gaze. However, our results accord with recent research showing that AQ scores in neurotypical individuals were   positively   related to the change in BOLD response in pSTS produced by a measure of task-independent deactivation ( ). The same study also showed that AQ was   negatively   correlated with white matter (WM) volume in a very similar region of pSTS (52, − 42 12) which also falls reasonably close to the region where the AQ-dependent pSTS responses were found in the present study (68, − 42, 24; Euclidian distance between the peaks = 20 mm). 

 suggested that the enhanced BOLD signal in high AQ participants might reflect a compensatory response for their reduced pSTS WM volume. A similar inverse relationship between WM integrity and increased BOLD response has been seen in the early stages of multiple sclerosis (MS), which is characterised by damage to WM tracts ( ). Notably, however, after a critical point of white matter deterioration   reduced   BOLD response is found in the later stages of this disease. We do not wish to draw parallels between ASD and degenerative disorders, but rather simply to highlight that the relationship between BOLD response and brain structure is not necessarily positive. It is therefore possible that white matter integrity is negatively correlated with autistic traits throughout the whole AQ range from typical individuals to those with ASD ( ), whereas the BOLD response to social stimuli might show an inverted u-shaped relationship with AQ scores. Hence, increased BOLD response in neurotypical individuals with higher AQ scores could reflect compensatory mechanisms as these individuals may require more cognitive resources to process gaze and other social cues than people with lower AQ scores. However, after some critical point in the AQ distribution (e.g. close to the clinical cut-off) this compensatory processing might fail, at which point, increasing AQ scores begin to show a   negative   association with BOLD responses, resulting in an inverted U-shaped association between AQ and BOLD when the full range of AQ scores are considered. Such an association could reconcile our findings with clinical studies showing decreased BOLD responses to social cues in ASD ( ). In line with this prediction, an inverted-u-shape relationship has already been observed between self-referential cognition and AQ, reflecting a positive association in controls and a negative association in people with ASD ( ). Future research involving both typical and ASD populations should therefore address whether the association between AQ and both the BOLD response and anatomical structure of pSTS across the entire AQ range. 

The above explanation is by no means the only possible factor that could underlie the positive relationship between AQ and BOLD response to eye gaze. As far as we are aware, the only previous study showing an abnormal BOLD response to a comparison of two gaze cues in people with ASD used a very different task in which a face directed its gaze towards or away from the position of an object in the display ( ), depending on the location of the object (i.e., the gaze was the same for both conditions). While Pelphrey and colleagues found reduced pSTS activation in individuals with ASD relative to controls, we cannot discount that people with autism might show increased activation in response to the variable versus constant Gaze conditions used in the current study. In this respect, the important result is that AQ scores were correlated with the activity of a network of regions implicated in gaze processing, rather than the direction of the correlation. 

Our study also suggests that the direction of the relationship between BOLD and AQ may be influenced by the nature of the stimuli. Relative to the house baseline, variable gaze showed a positive relationship with AQ, whereas constant gaze showed a negative relationship; indicating that the overall positive correlation was composed of positive and negative associations between AQ and activation to variable and constant gaze conditions, respectively. This may be explained by the relative extent to which processing variable and constant gaze engages the social attention network in low and high AQ participants. 

### Autism spectrum traits modulate the activity of the social attention network 
  
Hemodynamic response and AQ scores showed a positive correlation with a number of regions in the social attention network. Next, we deal the potential role of each. The pSTS region has been implicated widely in perception of social stimuli (as reviewed by  ), and its involvement in eye gaze perception is well documented ( ). However, recent studies point to its involvement in analyzing behavioural outcomes and intentionality of human actions ( ). Understanding intentions of others from social cues such as gaze is often impaired in autism ( ), and recent imaging studies have found that when compared to controls, individuals with ASD show an abnormal pSTS response to the perceived intentionality of gaze shifts ( ) or abstract shapes moving interactively with implied intentionality (such as chasing or teasing,  ). The present data from typical individuals accord with these results, as we observed the AQ-correlated pSTS response only for the gaze condition, in which the eyes convey a clear intention of looking at, or being interested in, various locations. All in all, these findings fit well with the proposal that functional changes in the pSTS region may underlie some of the social perception dysfunctions in ASD ( ). Interestingly, ROI analysis also confirmed that AQ modulated BOLD responses to gaze in the FFA (see supplementary  ). This accords with findings showing that FFA is involved in processing eye gaze ( ), and is in line with the proposal that the ventral face perception route may also significantly contribute to the processing of changeable facial cues (see reviews in  ) 

By contrast, AQ did not correlate with the change in BOLD response in the head condition in which the eyes were closed, thus conveying no intention of attending anywhere. Given that cueing effects from averted gaze are maximal when they are presented in the context of a full-face view of the head ( ), it is interesting that the correlation was also absent for the eyes-only condition where head direction information was not available. It is therefore possible that the present results reflect the activity of cells coding both head and gaze direction information, and their interactions with other components of the social attention network ( ). Alternatively, the eye region alone may constitute a less natural, ‘less social’ stimulus than gaze shown in the context of a fully visible head. 

It is also interesting to note that pSTS activation was not observed for the group-level analyses of variable vs. constant gaze or variable vs. constant eyes-only contrasts. Although many studies report pSTS activation in gaze perception tasks ( ), some don't ( ). Furthermore, even when effects are observed they tend to be small, suggesting variable evidence exists across subjects. On the basis of the present results showing AQ-dependent pSTS responses to gaze, AQ score might be a factor in determining whether or not the eye gaze perception systems respond to gaze stimuli. In other words, it is possible that the variability in AQ scores in the typical population may account for discrepant findings in the gaze perception literature. For example, relative increases and decreases in pSTS activation in participants scoring high and low on the AQ questionnaire respectively, as shown here, may result in no overall mean change in BOLD response in this region. In this respect, it is worth emphasising that the main effect of an experimental manipulation and its correlations with proxy variables, such as personality scores, measure different things and are statistically distinct. Main effects can occur in the absence of correlations, and vice versa (see review in  ). 

Although TPJ is not typically associated with gaze perception, it has been consistently linked with mentalizing or theory of mind processing ( ), and with directing attention to behaviourally salient events ( ). In the context of the present study, it seems plausible that the association between AQ scores and TPJ activation might reflect individual differences in the spontaneous tendency to draw mentalistic inferences from eyes, given that spatial reorienting (as indexed by the Posner cueing task) is typically intact in autism ( ). AQ was also correlated with activation in the vicinity of the motion-sensitive MT/V5 complex which has been proposed to constitute an initial stage in processing dynamic facial characteristics, including gaze shifts ( ). A magnetoencephalographic study has also shown that MT/V5 may extract social information conveyed by the eyes within 160 ms post-stimulus, as it shows stronger responses to faces that establish gaze contact rather than gaze aversion ( ). The AQ-dependent MT/V5 activation shows that autistic traits could influence even the very early, dynamic face processing stages. This raises the possibility that facial processing deficits observed in ASD (see  ) could be partially accounted for by deficits in extracting motion cues from faces, although this would need to be verified with studies of individuals with ASD. 

Several studies suggest that the amygdala's role in gaze perception relates to drawing mentalistic inferences from eyes ( ) and detecting or monitoring gaze contact ( ), but its exact contribution is currently unclear. ASD does not typically impair discrimination of others' gaze direction, but hampers the ability to infer others' mental states (e.g., intentions) from their gaze ( ). Taking this dissociation into account, the AQ-dependent amygdala activation found in the current study seems likely to reflect the amygdala's role in attaching social or affective salience to perceived gaze direction, rather than gaze direction encoding per se. The amygdala correlation with AQ is also consistent with Baron-Cohen's proposal that amygdala dysfunction could be one of the potential precursors to ASD ( ). 

Previous research has shown that circuits involved in visual attention are also engaged by viewing changes in gaze direction. The IPS forms part of the dorsal attention system which is thought to underlie attentional target selection ( ).   proposed that the IPS could also subserve attention orienting from seen gaze direction. In line with this proposal, single-unit recordings in macaques ( ) have indeed established that some neurons in the lateral intraparietal area (LIP; the lateral wall of the monkey IPS) increase their firing rate, while others reduce their firing rate, when the monkey views an image of a conspecific gazing towards the cell's response field. Similar effects are also observed when the monkey overtly looks at the corresponding locations, suggesting this regions' involvement in mirroring others' gaze. A number of behavioural studies in humans have found that viewing averted gaze triggers an involuntary shift of covert or overt attention towards the gazed-at location (for a review see  ). Although attention orienting was not measured behaviourally in our study, it is plausible that the AQ-dependent response in the IPS reflects the relationship between AQ and the tendency to imitate others' gaze behaviour ( ). In addition to the IPS, AQ-dependent activation of the IPL and SMG was also observed. The role of these regions in governing goal-directed shifts of attention is well established ( ), and a recent meta-analysis of fMRI studies on autism ( ) showed that individuals with ASD show reduced IPL and SMG activations in non-social attentional tasks. 

Finally, it must be noted that although there was a considerable overlap between the social attention network ( ) and AQ-modulated BOLD responses to gaze in the present study ( ), some of the activation foci clearly fall outside the social attention network. It is therefore possible that AQ also influences certain ‘gaze-independent’ neural mechanisms. However, this seems unlikely, given that AQ was not correlated with responses to variable versus constant heads and eyes-only conditions. Perhaps a more likely explanation is that AQ modulated responses in brain regions that are not part of the ‘core’ network for social attention perception, but are nevertheless recruited during certain gaze perception tasks such as the one used in the present study. 



## Conclusions 
  
We have shown that individual differences in autism spectrum traits in typical individuals are correlated with brain responses to observed shifts in gaze direction in key components of the brain circuit for eye gaze perception ( ), as well as those involved in inferring others' mental states ( ). Dysfunction in these same regions is also systematically observed in individuals with ASD. Our results therefore provide support for the existence of a broader autistic spectrum that extends into the typical population ( ). The data also demonstrate that neural processing of eye gaze is not fully homogenous across typical participants, as individual differences in social-cognitive processing styles indexed by AQ have a profound influence on the neural processing of eye gaze. Thus, in addition to furthering our understanding of the neurobiological basis of the extended autism phenotype, our results demonstrate that studies of eye gaze perception in typical individuals should take into account that a significant proportion of between-subject variance has a meaningful psychological basis. The identification of a cortical network influenced by AQ may be important in furthering our understanding of the neurobiological basis of deficits in the processing of social cues. Future studies on the development and functional connectivity of this network across the entire autism spectrum range could contribute to our understanding of neural markers of the development of ASD. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-6'>
<h2>6. PMID: 28855682</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> How spontaneous brain activity and narcissistic features shape social interaction</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Sci Rep</p>
<p><strong>Publication Year:</strong> 2017</p>
<p><strong>DOI:</strong> 10.1038/s41598-017-10389-9</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social-related processing: participants performed a social touch task (anticipation and performance of touching an animate human vs an inanimate mannequin). Participants were healthy adults (all right-handed males, age 21–33), within the 18–60 range and screened for neurological/psychiatric history. The paper reports whole-brain voxelwise analyses (paired-sample t-tests and covariate analyses with PNI) with FDR correction, and conjunction/whole-brain results are presented; although ROI analyses are included as secondary/exploratory work, the study does not rely solely on ROI results. It is not a review/meta-analysis and does not involve clinical populations. Therefore it meets all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
There is an increasing interest in how ongoing spontaneous brain activity and personality provide a predisposition for the processing of environmental demands. It further has been suggested that the brain has an inherent sensitivity to the social environment. Here we tested in healthy volunteers if spontaneous brain activity contributes to a predisposition for social behavior and how this is modulated by narcissistic personality features associated with poor interpersonal functioning. Functional magnetic resonance imaging included a resting state and an experimental paradigm focusing on the anticipation of actively touching an animate (human hand) versus an inanimate target (mannequin hand). The experimental task induced a significant modulation of neural activity in left postcentral gyrus (PostCG), right culmen and, co-varying with narcissistic features, in right anterior insula (AI). Neural activity in anticipation of the animate target significantly correlated with spontaneous activity during the resting state indexed by the Power Law Exponent (PLE) in PostCG and AI. Finally, the correlation between spontaneous and task-induced activity in AI was mediated by narcissistic features. These findings provide novel evidence for a relationship between intrinsic brain activity and social behavior and show how personality could contribute to individual differences in our predisposition to approach the animate world. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (36737 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Since the early infancy we act in a social environment where we need to distinguish between the animate and the inanimate . This suggests an inherent sensitivity of our brain to the social environment . Conspecifics are intentionally approached as being similar to our selves, with similar inner experiences . Correspondingly, social interactions induce neural activity in sensorimotor and affective circuits which allows us to predict and understand others’ sensory experiences . 

Moreover, our personality is shaped by early interactions with the animate world . The narcissistic personality trait reflects a predisposition for individual differences in social functioning being specifically associated with an inflated sense of self/self-centeredness and dysfunctional interpersonal functioning . On a psychological level, individuals with pathological narcissism may be capable of social processing, but are disengaged from it . 

However, neither the exact neural mechanisms of the brain’s predisposition for intersubjectivity nor the role of differences in personality features such as narcissism are clear, yet. 

Stimulus-induced neural activity has recently been traced to the brain intrinsic or spontaneous activity . Raichle  proposed that the brain maintains an intrinsic state of preparedness for anticipating or predisposing the demands placed continuously over time. Indeed, it has been shown that spontaneous activity modulates variability in task-induced activity in sensory cortices . 

The brain’s spontaneous activity as measured in the resting state (when a participant is awake but not involved in a specific task) shows a complex temporal structure characterized by long-range temporal correlations (LRTCs) . LRTCs are related to a higher time-lagged autocorrelation indicating that the past pattern of a system has a stronger influence on its future dynamics . Concerning functional magnetic resonance imaging (fMRI), previous studies showed that the power law exponent (PLE) can provide a robust and reliable measure of LRTC’s . Higher LRTC’s are indexed by a higher PLE, and imply stronger low-frequency Blood Oxygen Level Dependent (BOLD) signal fluctuations and higher glucose metabolism in the brain . 

Initial functional brain states defined in terms of LRTC’s could influence the processing of upcoming stimuli in the environment. Indeed, recent studies demonstrated that the degree of the spontaneous activity’s LRTCs predisposes the neural processing of motor  and sensory (i.e., auditory and visual)  stimuli. 

Departing from this background, the present study aims at 1) testing whether task-induced activity during social interaction can be predicted by the spontaneous activity of the brain; 2) to investigate how narcissistic individual differences could mediate the relationship between spontaneous and task induced activity. 

In addition to resting state functional magnetic resonance imaging (fMRI), we applied a social interaction fMRI task requiring participants to actively touch an animate (another individual) or inanimate target (a mannequin). Touch plays an incipient role in intersubjectivity , being involved in social interactions already during the earliest stages of life . Furthermore, somatosensory (e.g. postcentral gyrus, inferior parietal gyrus) and affective (e.g. anterior insula, cingulate and orbitofrontal cortices) circuits are involved both in our own experience of touch and in the perception of others being touched . 

The experimental paradigm focused specifically on the anticipation of animate versus inanimate touch, anticipation referring to the time window preceding the action while already neurally encoding the action including its target . Thus, anticipation reflects a transition phase from a resting state to actual social interaction characterized by the emergence of internally generated behavior without realizing any overt action. 

For data analyses, firstly, regions of interest (ROIs) were defined based on the fMRI task (anticipation of animate versus inanimate touch). Secondly, the resting state PLE was calculated for these ROIs and its association with task-induced brain activity was tested. Thirdly, it was investigated if spontaneous and task-induced activity showed neural overlap in their correlation with narcissism. Fourthly, it was tested if the relationship between spontaneous and task-induced activity was modulated by narcissism. 

We hypothesized that task induced activity in sensorimotor and affective brain regions in anticipation of touching the animate target, but not the inanimate target, co-varied with spontaneous activity in terms of LRTC’s during a preceding resting state period, whereas narcissistic features could modulate this relationship. 


## Methods 
  
### Participants 
  
Thirty-two right-handed male participants (age 21–33; Mean = 25.4; standard deviation = 2.82) were recruited in this study. All participants had normal or corrected-to-normal vision capabilities. None of the participants reported a history of neurological or psychiatric disease, or substance abuse. Written informed consent was obtained from all participants after full explanation of the study procedure, in line with the Declaration of Helsinki. Ethics Committee for Biomedical Research of the provinces of Chieti and Pescara approved the experimental protocol. Participants were paid. 


### Data acquisition 
  
fMRI data were acquired by a Philips Achieva MRI scanner at 3 T (See Supplementary Information for more details). All 32 subjects completed the resting state fMRI acquisition. Twenty one out of the 32 participants (age 21–30; Mean = 24.9; standard deviation = 2.45) also completed task fMRI acquisition. In addition to fMRI scanning, all 32 participants completed the Pathological Narcissism Inventory, a 52-item multidimensional self-report measure which was designed specifically to assess both grandiose (NG) and vulnerable (NV) narcissism in the healthy and pathological population . fMRI scanning details and additional information about the PNI can be found in the Supplementary Information. 


### Experimental Procedure and Materials 
  
#### Resting state-fMRI 
  
During the two resting state-fMRI runs (6 minutes each), participants were instructed to watch a white fixation cross presented on a black screen, think of nothing in particular and keep their eyes open (they were monitored through a video camera placed in the MRI room). 


#### Task-fMRI 
  
The experimental task is based on that used in previous research  and is described in detail in the Supplementary Information. Briefly, during the task fMRI runs (8 runs of 7.8 minutes each), the participant completed a series of touch and no-touch trials. Trial order was randomized. Each trial, either touch or no-touch, started with a visual cue (1000 ms) consisting of a black and white line drawing followed by an attendance signal (red cross for 3000 ms). The drawing indicated the target of the touch (what had to be touched by the participant), that is, an animate (the hand of another volunteer who was standing next to the scanner) or an inanimate target (a mannequin hand). In the no-touch trials (60%), the red cross became black indicating to do noting and wait for the next trial. In the touch trials (40%), the cross became green for 6000 ms and the touch needed to be performed with a brush covert with either velvet (inducing a pleasant sensation when brushing on someone’s skin) or sandpaper (inducing an unpleasant sensation when brushing on someone’s skin). 

Since it was not predictable for the participant whether he actually had to perform the touch after the attendance signal, he was forced to be prepared to touch either the animate or the inanimate target after every visual cue. Therefore, the no touch trials allowed to study the anticipation of touching the animate or the inanimate target without the presence of any overt movements of the participant. 

Thus, two main conditions could be distinguished: the anticipation of touching an animate target (48 trials) and the anticipation of touching an inanimate target (48 trials). 

This task essentially differs from the previous studies for various aspects: 1) by adding the affective component through the valence of the touch (pleasant and unpleasant) the intrinsic link between emotion, self-related processing and social interaction was more specifically considered; 2) a slow event-related fMRI design was used (ITIs = 14000/16000/18000 ms) instead of fast event-related fMRI design; 3) the task was preceded by resting state runs (two independent 6 min-task free fMRI scans acquired before any task) to study the relation between rest and task conditions. 


#### Task fMRI analysis 
  
Pre-processing procedures of the fMRI data were implemented in Analysis of Functional NeuroImages software  and are described in the Supplementary Information. 

The contrast of principal interest concerned the anticipation of touch an animate target versus the anticipation of touch an inanimate target (is there a difference in the anticipation of touching a human animate hand in contrast to an inanimate mannequin hand?). A whole brain voxelwise paired-sample t-test was performed according to a random effect model to compare neural activity related to the anticipation of touching the animate target and to the anticipation of touching the inanimate target. 

Additionally, to test whether individual differences in the neural activity during the task were related to narcissism, whole brain analyses were performed comparing the neural activity during the anticipation of touching the animate target or the inanimate target with baseline, while using the PNI subscales of NG and NV as covariates. 

Statistical thresholds for all group statistical maps were set at q < 0.05 after False Discovery Rate (FDR) correction to search for modulations of brain activity by the different targets. The coordinates of the voxel clusters showing statistically significant effects were compared with the Talairach atlas available in AFNI software to label them in terms of anatomically defined regions and Brodmann’s areas (BA). 

To explore whether there were statistically significant modulations of BOLD response for the performance of an animate target and an inanimate target touch (touch trials) in the regions of interest (ROIs) modulated by the anticipation of touch, we performed a ROI based analysis. Avoiding circularity in the analysis, individual beta values were extracted from the voxel clusters (ROIs) showing a significant effect regarding the above described whole brain analysis for the anticipation of touch, that is, the no-touch trials. Beta values for each of these independent ROIs were then calculated from the average signal time course of the voxels included in each ROI concerning the performance of touch, that is, the touch trials. A paired-sample t-test was performed on the beta values regarding performance of an animate target touch and an inanimate target touch to establish if there also was a significant difference in neuronal response during touch performance regarding the ROI’s previously associated with the anticipation of touch. 



### Resting-State fMRI Analysis: Power Law Exponent (PLE) 
  
Power Law Exponent (PLE) analysis, as a measure of the temporal structure of low-frequency fluctuations , was performed on the resting state fMRI runs . PLE is considered suitable for the measure of scale free dynamics of fMRI data . Comparing different methods for computing fMRI time series complexity, Rubin and colleagues  demonstrated power spectrum based methods such as PLE being among the most robust measures. 

Scale-free dynamics are mathematically characterized by a power spectrum following the formula P ∝ 1/f , where P is power, f is frequency, and β is called the “power-law exponent” . After pre-processing, the time course per voxel was normalized to zero mean and unit variance (z-value) . Using methods previously optimized for fMRI , the normalized power spectrum of the fMRI signal was computed for each voxel using AFNI program: 3dPeriodogram. Similar to Welch’s method, the power spectra of the two resting state runs were averaged to reduce noise caused by imperfect and finite data, in exchange for reducing the frequency resolution. The power spectrum of the BOLD signal was further smoothed with a Hamming window (HM) of 7 neighboring frequency bins (HM = 7) . The averaged power spectra across voxels within the a priori ROIs (left PostCG, right culmen and right AI established before on whole brain analysis comparing different targets during the anticipation of touch) were extracted for each participant. The power spectrum was fitted with a power-law function P ∝ 1/f  using a least-square estimation (in a log frequency by log power plot) in the frequency range of 0.01~0.1 Hz . Finally, the power-law exponent, β, of each participant’s ROI was defined as the slope of the linear regression of log-power on log-frequency. 

In addition, we performed three different control analysis:   
To test the goodness of fit for scale invariance in the fMRI signal from particular region of interests we adapted a goodness of fit test developed for testing power-law distributions  and used by other authors in fMRI studies . For each ROI, its time series were extracted for each subject and subjected to PLE analysis for the resting state runs. 1000 time series of fractional Gaussian noise (fGn) with the same length and standard deviation as the original ROI time series were generated. Fractional Gaussian noise is a parsimonious model of stationary scale-free dynamics . Each synthetic fGn time series was subjected to the same PLE analysis as the original resting state data. The p value is defined as the fraction of synthetic time series with standard deviations of residuals from best fit that is larger than the original standard deviations of residuals from best fit of the fMRI time series. The larger the p value, the more plausible the fGn model is for representing the original fMRI time series, and the better the fit of the original data to a scale-free distribution. The hypothesis that the fMRI signal is scale free is plausible if the resulting p‐value is greater than 0.1, otherwise it is ruled out . 
  
To confirm the robustness of our frequency domain analysis (PLE) we also independently calculated the Hurst exponent in the time domain with detrended fluctuation analysis (H-DFA)  as a control index and calculated their correlation. 

Specifically, DFA measures the scaling of the root-mean-square fluctuation of the integrated and linearly detrended signals, F(T), as a function of time window size, T. The fluctuation F(T) is of the form F(T) = T , where H is the scaling exponent. 
  
Finally, we applied different Hamming Windows (HM = 3, 5, 9, 15) on the PLE calculation to test if the correlation between resting state activity (PLE) and task induced activity could be affected by different smoothing parameters. 
  


### Relationship between resting-state activity and task induced activity 
  
To establish if there was an association between resting state activity (PLE) and task induced activity in the ROIs, we performed Spearman correlation analyses (participant-based) with a 95% confidence interval (CI) based on 1000 bootstrap samples between resting state activity (Beta values) and task-activity (Beta values) for either anticipation of animate target or inanimate target. Bonferroni correction for multiple comparisons was performed on the obtained correlation coefficients, such that only   p   values (before correction) were considered significant below p < 0.05/number of calculated correlations. 

In addition to bootstrapping, the correlation was also controlled for all leave-one-out cohorts (N analyses with N-1 participants where each participant is excluded at a time). 


### Conjunction analysis: resting state activity and task induced activity with narcissistic features as covariates 
  
It was tested if the relationship between spontaneous activity and task-induced activity is modulated by PNI scores. Firstly, a whole-brain, voxel-wise conjunction analysis was performed to establish whether there was an overlap between brain regions in which task-induced and spontaneous activity both co-varied with narcissistic features. A random effect analysis of the overlap between the two contrasts was based on the minimum statistic compared with the conjunction null . This method controls the false positive error for conjunction inference and tests for common activations by creating the intersection of statistical maps thresholded at a specific alpha rate. 

Subsequently, a ROI-based partial correlation analysis was performed using the voxel clusters in which both task-induced activity and PLE correlated with NG or NV as obtained by the conjunction analysis. Specifically, the pair-wise relationships between PNI scores, and task-induced activity (beta scores of task-induced activity during the anticipation of animate touch) and spontaneous activity (beta scores of resting state PLE) in the ROIs were analyzed, while controlling for the third variable. 



## Results 
  
### Task fMRI data analysis: anticipation of animate target versus anticipation of inanimate target 
  
A whole brain voxel-wise paired-sample t-test between anticipation of the animate target and the inanimate target (“no touch trials”) elicited a significant effect in left postcentral gyrus (PostCG) and right culmen (t = 3.965; p = 0.0005; FDR corrected q = 0.05) (Fig.  , Table  ).   
Task-induced activity: (  a  ) Group statistical maps of whole brain voxelwise t-test between anticipation of animate target vs. anticipation of inanimate target (t = 3.965; FDR corrected, q = 0.05). (  b  ) Graphs of Beta values and Standard Errors extracted from activation clusters depicted in (  a  ). 
    
Brain regions showing a modulation of BOLD response by different experimental conditions and statistical information for the direct contrast between the anticipation of the animate target versus the anticipation of the inanimate target (FDR corrected), for the direct contrast between the anticipation of the animate target versus baseline (FDR corrected) and for the conjunction whole brain analysis between anticipation of animate target vs. baseline with covariate PNI-NG ∩ Resting state PLE vs. baseline with covariate PNI-NG. 
  
LH = left hemisphere; RH = right hemisphere. C-Mass Coordinates refer to Talairach space. PNI = Pathological Narcissistic Inventory; NG = Narcissistic Grandiosity. 
  

A single subject analysis for the anticipation of animate vs. inanimate target in four randomly selected single participants elicited a significant effect in left PostCG (Supplementary Figure  ). 

Examining the graphs, specifically for the anticipation of touching an animate target, we observed no appreciable modulation of BOLD response, compared to baseline, in the left PostCG, whereas a suppression of BOLD response (deactivation) was detected in the right culmen. By contrast, for the anticipation of touching the inanimate target we observed an increased activation, compared to baseline, in the left PostCG, but no appreciable modulation of activity, compared to baseline in the right culmen. 

An exploratory ROI-based analysis yielded the opposite pattern during touch performance (Fig.  ). Specifically, we found a significant difference between the two conditions (touch of an animate target and touch of an inanimate target) both in the left PostCG (p = 0.001) and for the right culmen (p = 0.001). In detail, we observed a greater activation in left PostCG as well as in right culmen during the active touch of the animate target compared to the inanimate target.   
Task-induced activity: ROI based analysis on touch performance in activation clusters obtained by the whole brain voxelwise t-test on the “no touch trials” (touch anticipation; Fig.  ). Bars represent the mean beta value across subject and Standard Error. * indicates p < 0.001. 
  

Regarding the co-variance with PNI scores, voxel-wise, whole brain one-sample t-tests on the anticipation of touching the animate target (versus baseline) with NG and NV as covariates elicited a significant effect of NG on BOLD responses in the right anterior insula (AI) (t = 3.828; p = 0.0005; FDR corrected q = 0.05) (Fig.  ), while no significant modulation was reported for NV.   
Task-induced activity: Group statistical maps of a whole brain voxelwise t-test between anticipation of animate target vs. baseline with PNI-narcissistic grandiosity (NG) as covariate (t = 3.965; FDR corrected, q = 0.05). 
  

Confirming that the relationship between task-induced activity and PNI scores was specific for the animate target, the same analysis on the anticipation of touching the inanimate target (versus baseline) with NG and NV as covariates yielded no significant effects (t = 3.621; p = 0.001; uncorrected). 


### Correlation between PLE and task induced activity 
  
The PLE values across participants (n = 32) in the left PostCG (mean = 0.44; SD = 0.27), in right culmen (mean = 0.37; SD = 0.23) and in right AI (mean = 0.43; SD = 0.19) are in accordance with previous studies . 

Correlations between resting state PLE and task induced activity were calculated, that is, for task-induced activity in anticipation of the animate and the inanimate touch, in left PostCG, right culmen and right AI (Fig.  ).   
Scatter plots showing predictive power (Spearman correlation) of PLE during the resting state for individual task induced activity in PostCG, culmen and AI ROIs during the anticipation of touching the animate and the inanimate target.   p   values reported in the figure are Bonferroni corrected. 
  

A negative and significant correlation between resting state PLE and task induced activity during the anticipation of touch the animate target was observed in left PostCG (r = −0.684, p = 0.006 Bonferroni corrected; 95% CI Lower: −0.874 Upper: −0.332; S.E. = 0.141) and in right AI (r = −0.592, p = 0.03 Bonferroni corrected; 95% CI Lower: −0.822 Upper: −0.217; S.E. = 0.154), but not in right culmen (r = −0.142, p = 0.540 – p = 0.54, uncorrected; 95% CI Lower: −0.600 Upper: 0.283; S.E. = 0.231). 

The correlation between PLE and task induced activity was also controlled for all leave-one-out cohorts (N analyses with N-1 participants where each participant is excluded at a time) and this procedure didn’t affect significance of the correlation coefficients for PostCG (min: r = −0.699 p = 0.001; max: r = −0.550, p = 0.012) and for AI (min: r = −0.668 p = 0.001; max: r = −0.543, p = 0.013). 

No significant correlation between resting state PLE and task induced activity during the anticipation of touch the inanimate target was observed in left PostCG (r = −0.342, p = 0.130 95% CI Lower: −0.686 Upper: 0.152; S.E. = 0.211), right culmen (r = 0.175, p = 0.447; 95% CI Lower: −0.339 Upper: 0.641; S.E. = 0.244) and right AI (r = −0.514, p = 0.017; 95% CI Lower: −0.867 Upper: 0.019; S.E. = 0.236). 

Hotelling-Williams test  was performed to test the equality of two correlation coefficients obtained from the same sample, with the two correlations sharing one variable in common. The test resulted significant for PostCG (z = 2.736; p = 0.006) indicating that the correlation between beta of animate touch anticipation and resting state PLE was significantly stronger than the correlation between beta of inanimate touch anticipation and resting state PLE. The difference was not significant for AI (z = −0.421; p = 0.673) and culmen (z = −1.112; p = 0.266). 


### PLE control analyses 
  
(1) Simulating 1000 time series with a stochastic Gaussian process of known long-range temporal dependence, we first showed that the fMRI signal is scale-free by analyzing the goodness of fit indices (left PostCG p = 0.25; right AI p = 0.22; right culmen p = 0.23). Thus, PLE is a suitable measure to quantify the scaling exponent of the fMRI signal. 

(2) To further validate the PLE that based on the frequency-domain approach, we applied a time-domain method (DFA) to test for their correlation. As expected, we observed a strong correlation between the two measurements in all the ROIs (for left PostCG, r = 0.722, p = 0.00001; for right culmen, r = 0.804, p = 0.00001; for right AI, r = 0.762, p = 0.00001). 

(3) To test the robustness of our results, we applied different smoothing parameters to determine the PLE values, more specifically by varying Hamming window size (HW = 3, 5, 9 and 15). These analyses showed that the correlation of PLE and task induced activity in Post CG and AI for the anticipation of the animate target was not affected by different HMs (Table  ).   
Statistics of the correlation between the Resting state PLE and task induced activity (Beta) in Left Postcentral gyrus, Right Culmen and Right Insula for the Anticipation of the Animate target and Inanimate target. 
  
HM = Hamming window size; LH = Left Hemisphere; RH = Right Hemisphere. *p < 0.008 after Bonferroni correction for multiple comparisons. 
  


### Conjunction analysis and partial correlations between Narcissistic Grandiosity, Resting State PLE and task induced activity for the anticipation of the animate target 
  
Conjunction analysis showed that right AI activity co-varies with NG both during a resting state (spontaneous activity indexed by PLE) and during task-induced activity (BOLD responses to the anticipation of the animate target) (Fig.  ; t = 7.820; p = 0.00000001). The same analysis using NV as covariates yielded no significant effects (t = 2.750; p = 0.01; uncorrected).   
Conjunction contrast between the anticipation of the animate target vs. baseline with covariate Narcissistic Grandiosity and resting state vs. baseline with covariate Narcissistic Grandiosity. 
  

Since spontaneous activity, task-induced activity and NG score all co-varied in AI, partial correlation coefficients were calculated to provide more insight in their interrelationship. 

Partial correlation yielded a significant positive association between PLE and NG, while controlling for task-induced activity (r = 0.475; p = 0.03; 95% CI Lower: 065 Upper: 0.813; S.E. = 0.189), a significant negative association between NG and task induced activity, while controlling for PLE (r = −0.593; p = 0.006; 95% CI Lower: −0.839 Upper: −0.077; S.E. = 0.203), but no significant association between PLE and task induced activity, while controlling for NG (r = −0.129; p = 0.588; 95% CI Lower: −0.563 Upper: 0.423; S.E. = 0.260) (see Fig.  ).   
Partial correlations model showing the statistic of each correlation controlling for the effect of the third variable in the model. 
  



## Discussion 
  
In the present study, we aimed to investigate whether task activity induced by the anticipation of social behavior (touching an animate target) could be related to the spontaneous activity of the brain during a preceding resting state period, and if this relationship may be mediated by narcissistic traits, particularly NG and NV. 

The main results showed that task-induced activity during the anticipation of the animate target (but not of the inanimate target) in left PostCG and right AI negatively correlated with the degree of LRTCs during a preceding resting state: the stronger the PLE in spontaneous activity in left PostCG and AI, the weaker the BOLD response in the same regions for the anticipation of the animate target (see Fig.  ). Interestingly, neural activity in right AI consistently correlated with NG, both during the resting state (PLE) and during task performance (BOLD responses in anticipation of the animate target). Additionally, NG was found to modulate the relationship between spontaneous and task induced activity in the right AI. These data provide, to our knowledge for the first time, evidence for a relationship between intrinsic brain activity and the anticipation of social interaction as well as for how this relationship could be influenced by personality features.   
Proposed model of the study visualizing the relationship between intrinsic activity brain activity, task induced activity and the modulation by narcissistic traits. In this model the anticipation is considered as a transitional phase between internal and external where the individual is aware of the external stimuli and is generating internally the behavior without realizing any overt action. 
  

With respect to the rest-task relationship, the detected negative relationship between resting state and task-induced activity is consistent with previous studies showing that the temporal structure of intrinsic brain activity during a resting state can provide a predisposition that shapes our interactions with the world . 

Our finding that individuals with stronger LRTC’s in PostCG and AI during a resting state show weaker task-evoked BOLD responses in the same regions during the anticipation of animate interaction, suggests that an individual’s spontaneous brain state defined in terms of LRTC’s might predispose the preparedness for social stimuli in these brain regions. 

The result that only the activity induced by the anticipation of the animate target touch, but not of the inanimate target touch, correlates significantly with the temporal structure of the endogenous brain activity in PostCG and in AI is in line with the idea that other individuals are approached as entities with similar inner experiences as our self . Indeed, PostCG and AI have been associated with the perception of one’s own as well as others’ sensations and feelings . Moreover, behavioral results based on “similarity” and “spontaneous social awareness” ratings of touch performance (see Supplementary Figure  ) showed that there is a significant difference in approaching the other (i.e. the animate target) as an entity with similar characteristics of our self, compared to the mannequin. 

Hence, the detected relationship between the spontaneous activity and task-induced activity in PostCG and AI supports the hypothesis that others’ bodily experiences might be already internally formulated, as something related to one’s own experiences and that sensory and affective circuits contain a memory trace of it . This seems to be in line with the finding that bodily arousal, linked to psychophysiological states, is associated with spontaneous brain activity during the resting state . 

Regarding the relationship between the anticipation and the performance of animate and inanimate touch, PostCG and culmen differentiated between the anticipation of animate and inanimate touch. These regions overlap with those consistently reported in research on sensory anticipation and action prediction . According to research on sensorimotor prediction, such sensory activity anticipating the consequences of an action, like touching, may attenuate activity induced by sensory stimuli . 

Considering this literature, we suggest that a similar predictive mechanism supported by internal simulation may apply to the anticipation of others’ sensations induced by one’s actions . In agreement with this, anticipatory activity in PostCG and culmen showed weaker responses for animate touch anticipation, compared to inanimate touch anticipation, whereas an exploratory ROI-based analysis of BOLD responses during actual touch performance showed the opposite pattern of activity in these regions: increased activity during animate touch performance, compared to the inanimate touch performance. Accordingly, also Gazzola and colleagues  showed increased activity in SI during (passively perceived) affective social touch. Moreover, it is interesting to note that somatosensory activity in SI also supports subjective self-perception induced by tactile stimuli . 

Finally, concerning individual levels of narcissism, our data showed that activation specifically for the anticipation of the animate target negatively co-varies with NG in right AI. As evidenced by a conjunction analysis, also spontaneous activity correlated with NG in the same voxels in AI. Partial correlations were performed concerning the relationships between task-induced and spontaneous activity in this AI cluster, and NG. These correlations indicated that the relationship between neural activity in anticipation of the animate target and spontaneous activity during a resting state in AI is no longer significant when controlling for NG, while task-induced activity during the anticipation of the animate target and spontaneous activity during a resting state in AI independently correlate with NG. 

On the one hand, the positive correlation between NG and LRTC’s in AI during the resting state period may be interpreted as an increased preoccupation for the self, more specifically the bodily and interoceptive self  during a rest/mind-wandering period . For instance, recent imaging studies showed recruitment of the right anterior insula during tasks focusing on the self  . On the other hand, the negative correlation between NG and task activity elicited by the animate target in AI may be interpreted as a consequent reduced activity regarding other individuals. This hypothesis is also supported by the proposed role of AI as part of the salience network  in constituting a crossroad switch between the internal and the external activity of the brain . Fan and colleagues  specifically showed a decreased deactivation of AI during processing of emotional faces in individual high on narcissistic trait. The authors interpreted their data as indicative of an increased of self-focus and disengagement from empathic processing in narcissistic individuals. The present results extend these findings by showing that higher NG may be related to an increased internal predisposition accompanied by a motivation-based disengagement from social processing . 

Thus, these results provide further insight into how personality features may influence brain activity anticipating social interaction. We propose that narcissism could function as a factor mediating between internal processing, related to the self, and external sensory information related to the social world. 

Some limitations of the study have to be mentioned. Firstly, we studied the relationship between resting state fMRI and task-induced BOLD responses . It can be argued that this approach is correlational and not directly addresses rest-task interactions . However, because we were interested in how individual spontaneous brain activity patterns could constitute an a priori predisposition for social behavior, intrinsic activity during an independent resting state could be indicated as a more appropriate measure than pre-stimulus activity or background intrinsic activity during task-performance in this context. Nevertheless, further studies have to address direct rest-task interaction integrating these alternative measures that are highly informative for deepening the interaction between endogenous activity and task-induced responses. 

Secondly, it can be argued that AI is not a region primarily involved in the discrimination between the animate and the inanimate target. However, AI could be specifically related to grandiose (but not vulnerable) narcissistic features during both the resting state and the anticipation of the animate target. Since NG is characterized by self-serving focus and a motivational based disengagement, it could be speculated that this relation expresses a more general disengagement from the external world in high NG participants. Although this might be not primarily related to the qualification of the target, it possibly is more pronounced for social processing . Further studies would be necessary to clarify this issue more directly. 

Thirdly, our sample was not constituted by clinical individuals and further research has to expand this study to clinical samples of pathological narcissism. However, our data lend support to the concept of narcissism as a continuum between healthy and pathological forms reflecting adaptive and maladaptive personality organization, respectively . 

In conclusion, our research sheds a novel light on how social task activity can be related to the spontaneous activity of the brain and how this interaction may be modulated by individual personality differences. Future research will need to expand this study to modalities of social interaction other than touch, and to other relevant aspects of personality which may modulate our way to relate with our self and with other individuals. 


## Electronic supplementary material 
  




 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-7'>
<h2>7. PMID: 28592863</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Human cortical activity evoked by contextual processing in attentional orienting</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Sci Rep</p>
<p><strong>Publication Year:</strong> 2017</p>
<p><strong>DOI:</strong> 10.1038/s41598-017-03104-1</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Meets all inclusion criteria: (1) Task involved fMRI during a social-related task (attentional orienting using social gaze vs arrow cues and social voice vs tone contextual processing). (2) Participants were healthy adults (N=22; mean age 22.95 years, all right-handed; within 18–60). (3) Whole-brain analyses were conducted and reported (voxel-wise thresholds with FWE correction), with additional small-volume corrections; results are not limited to ROI-only analyses. Does not violate exclusion criteria: not a review/meta-analysis and participants are not clinical. Therefore the study should be included.</p>
<p><strong>Fulltext Confidence:</strong> 0.93</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
The ability to assess another person’s direction of attention is paramount in social communication, many studies have reported a similar pattern between gaze and arrow cues in attention orienting. Neuroimaging research has also demonstrated no qualitative differences in attention to gaze and arrow cues. However, these studies were implemented under simple experiment conditions. Researchers have highlighted the importance of contextual processing (i.e., the semantic congruence between cue and target) in attentional orienting, showing that attentional orienting by social gaze or arrow cues could be modulated through contextual processing. Here, we examine the neural activity of attentional orienting by gaze and arrow cues in response to contextual processing using functional magnetic resonance imaging. The results demonstrated that the influence of neural activity through contextual processing to attentional orienting occurred under invalid conditions (when the cue and target were incongruent versus congruent) in the ventral frontoparietal network, although we did not identify any differences in the neural substrates of attentional orienting in contextual processing between gaze and arrow cues. These results support behavioural data of attentional orienting modulated by contextual processing based on the neurocognitive architecture. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (47097 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
The ability to assess another person’s direction of attention is paramount in social communication. For example, we are able to identify a person’s focus based on their eye gaze, thus enabling an understanding of other people’s inner state (such as thoughts, beliefs, and desires) . Similar to eye gaze, non-social stimuli also play important roles in influencing attention, such as an arrow on a road sign. However, compared with eye gazes, non-social directional stimuli are not helpful when making conclusions regarding someone’s cognitive state, such as speculating about what a person wishes to do. 

Over the past two decades, cognitive psychologists have focused on comparing the role of directional gaze and arrow cues in attentional orienting. These studies have typically investigated attentional orienting based on gaze and arrow cues using a modified version of Posner’s cueing paradigm . For example, Friesen and Kingstone  presented non-predictive gaze cues at the centre of a screen prior to the presentation of a peripheral target (right or left). Before the onset of the target, a centrally presented directional cue (e.g., eye gaze) appears on screen. Under valid conditions, the cue will accurately indicate the subsequent target location, whereas under invalid conditions, the cue will indicate the opposite location. A rapid response to a validly cued target indicates an allocation of attention (i.e., orienting) to the target location prior to target onset. In contrast, a delayed response to an invalidly cued target occurs when the onset of the target at the opposite location, indicating a reorienting of attention to the target. Previous studies  have commonly demonstrated that arrow cues automatically trigger attentional shifts in the same manner as gaze cues. These studies have demonstrated that both gaze and arrow cues trigger attentional shifts when they are counterpredictive of a target location , facilitate response time when discriminating the target following the cue , have comparable sensitivity to object-based selection  and the stimulus onset asynchrony between the cue and target . 

Recent neuroimaging studies regarding attentional orienting have attempted to investigate differences in cortical activity between gaze and arrow cues. These studies have focused on two attentional networks (reviewed by ). The dorsal frontoparietal network, with regions centred around the intraparietal sulcus (IPS), superior parietal lobule (SPL)/Brodmann’s area (BA)5, 7, and frontal eye field (FEF)/BA8, may be responsible for orienting of attention to a validly cued target in the cueing paradigm, but also for reorienting attention to an invalidly cued target . The ventral frontoparietal network, with regions centred on the temporoparietal junction (TPJ)/BA39, 40, 22 and ventral frontal cortex (VFC)/BA44, 45, 47 (including parts of the middle frontal gyrus (MFG) and inferior frontal gyrus (IFG)), may only be responsible for reorienting attention. Most previous studies  have demonstrated that the differences in cortical activity associated with social gaze and arrow cues are quantitative rather than qualitative, although some studies  have reported evidence suggesting different mechanisms for these cues. For example, Tipper   et al  .  reported attentional orienting to both eye gaze and arrow cues engaged extensive dorsal and ventral frontoparietal networks, but the magnitude of activation differed between these networks. However, these studies only examined the differences between gaze and arrow cues under simple conditions (e.g. a dot or letter as the target). Given that Birmingham and Kingstone  suggested that the apparent difference in attentional orienting between gaze and arrow cues might be distinguished only when the cues were embedded in a rich environment, it is thus important to examine the differences between gaze and arrow cues under more complex conditions. 

Some studies have highlighted the importance of contextual processing (i.e., the semantic congruence between the cue and target) in attentional orienting when using arrows or eye gaze as cues. Previous studies  have demonstrated that attentional orienting is facilitated through contextual processing when using arrows as cues. For example, Ristic   et al  .  examined attentional orienting based on whether facial gaze and arrow cues could be triggered through the contextual processing of cue-target colour contingencies. The results indicated that attentional orienting elicited by an arrow rather than an eye gaze was sensitive to colour-congruent target stimuli; an attentional orienting effect for blue arrows was only evident for blue targets. However, other studies  have demonstrated that attentional orienting with facial gaze was facilitated through a strongly contextual relationship between the cue and target when there was congruence in meaning between the cue and target. For example, Bayliss   et al  .  reported that compared with disgusted faces, the gaze direction of happy faces more effectively oriented attention to pleasant targets. These findings indicated that participants could employ contextual information in attentional orienting by arrows or eye gaze cues to effectively capture important information, although the context effect might be observed only when targets are presented at a specific context of colour and emotion for gazes and arrows. These findings raised a question regarding whether attentional orienting differs between eye gaze and arrow cues when these cues were influenced through contextual processing. 

At a neural level, researchers have shown activity in the TPJ and superior temporal sulcus (STS)/BA21, 22 associated with contextual processing in attention. Geng and Vossel  reviewed previous evidence, indicating that the TPJ (anatomically, the TPJ is strictly defined as the cortex at the intersection of the posterior superior temporal, supramarginal, and angular gyri) was engaged in terms of “contextual updating” in attention. For example, Weidner   et al  .  demonstrated that cortical activity in TPJ increased when the contextual processing of the relationship between the cue and target was incongruent as opposed to congruent (i.e., when the target-defining dimension (orientation or colour) was incongruently rather than congruently cued). Moreover, Noppeney   et al  .  observed that the activity in STS increased when a sound or speech target was incongruent (e.g., a car picture paired with the spoken word ‘owl’) as opposed to congruent (e.g., a cat picture paired with the spoken word ‘cat’) with prior visual information. This finding indicated that context also modulated the activity of STS. Consistently, when a strong relationship was established between the target word and a word sound that had been previously presented, the results showed the enhanced activation for thematically related categories (e.g., picture + frame) and response suppression for taxonomically related categories (e.g., chair + armchair) in the left STS . In the present study, we focused on these brain regions to examine the influence of neural systems in relation to gaze and arrow cues through contextual processing focused on the relationship between the cue and target in attentional orienting. 

In the present study, we examined the neural activity of attentional orienting with social gaze and arrows as cues using Posner’s cueing paradigm. Based on a previous study , two sounds (a social voice and a tone) were manipulated as targets to determine the contextual relationship between cue and target; that is, social gaze and social voice and arrow and tone as congruent meaning conditions, and social gaze and tone and arrow and social voice as incongruent meaning conditions. The aims of this study are as follows: (1) We first wanted to examine whether the influence of neural activity in TPJ and STS differed between gaze and arrow cues in response to contextual processing of the relationship between cue and target. (2) Furthermore, given that previous studies  have characterised the functional mechanisms of the orienting and reorienting of attention (i.e., valid and invalid conditions) in dorsal and ventral frontoparietal networks, respectively, we considered it important to specifically investigate these functional mechanisms and how they were modulated through the contextual processing of the relationship between cue and target. Specifically, if different neural activity was observed for gaze and arrow in response to the contextual processing of cue-target, we would subsequently examine whether the neural activity for attentional orienting differed with contextual processing between gaze and arrow cues at the dorsal and ventral frontoparietal networks, respectively. In contrast, if no difference between gaze and arrow was evident, we would then examine only the influence of neural activity for attentional orienting by contextual processing in both gaze and arrow cues in these two attentional networks. 


## Methods 
  
### Participants 
  
This research was approved by the local ethics committee of Capital Medical University, Beijing, China. No foreseeable risk to the participants was present, and personal identifying information was not collected. Participants provided written informed consent and background information. All procedures complied with the ethical standards of the 1964 Declaration of Helsinki regarding the treatment of human participants in research. In total, 22 volunteers (9 women, 13 men; mean ± SD age, 22.95 ± 2.61 years) participated. All participants were right-handed, as assessed by the Edinburgh Handedness Inventory , and had normal or corrected-to-normal visual and auditory acuity. 


### Stimuli 
  
Visual and auditory stimuli were almost identical to those used in a previous behavioural study (at a sound level comfortable to each participant) . Previous studies have demonstrated that female faces are less resemblance to angry expressions than male faces, and male faces are perceived as less likeable  and more powerful . To avoid any differential influence of expression (e.g., anger), a Japanese female face with neutral expressions was used for this task (Fig.  ). The image was obtained from a previous study , in which the emotional intensity of facial stimuli with neutral expressions was assessed. The results confirmed that these facial images were considered neutral rather than emotional. Based on these findings, it is reasonable to propose that the female face image in the present study conveyed neutral facial expressions. Moreover, three versions of each face were produced: one version with a direction of gaze straight ahead, another version with the pupils averted leftward, and a third version with the pupils averted rightward. The faces measured approximately 4.7° wide and 6.9° high. For the arrow cue, a symmetrical arrow was presented as the cue stimulus, with an arrowhead at one end and a tail at the opposite end. The arrows measured 4.7° in width by 1.7° in height and were light grey.   
Illustration of the stimulus presentation. 
  

Furthermore, two types of auditory stimuli were presented as targets. One type was sampled from a woman: an/i/voice sound (F0 frequency of 300 Hz), which is similar to the /iy/sound in English. The other type was a pure tone of similar frequency to the F0 voice (300 Hz), which was produced using the Audacity software package (  ver. 1.3.13; Audacity store.com  ). The duration of the stimulus presentation was 150 ms. 


### Apparatus 
  
These stimuli were generated on a computer and presented to the participants via a custom-built, magnet-compatible audio-visual system during magnetic resonance (MR) scanning. To attenuate the acoustic noise that accompanies fMRI (functional magnetic resonance imaging) scanning, shooting earmuffs were used. Participants viewed visual stimuli on a back-projection screen. The auditory stimuli were identical to those presented in a previous study  via an air-conductive tube to participants. Presentation software (ver. 10.2; Neurobehavioral Systems) was used to generate auditory and visual stimuli on a Windows computer. In addition, the participants generated their responses using a keypad (Current Designs Inc., Philadelphia, PA, USA). 


### Procedures 
  
The sequence of stimulus presentation is shown in Fig.  . For each trial, a fixation cross was initially presented for 300 ms in the centre of the screen. A neutral stimulus with a straight eye gaze (gaze trail) or transverse lines (arrow trail) was subsequently presented at the location. After 350 ms, a cue stimulus (gaze or arrow) in the right or left direction was presented in the centre of the screen. The stimulus onset asynchrony (SOA) between the auditory target and cue was fixed to 200 ms. Subsequently, an auditory stimulus target (voice or tone sound) was presented in the left or right ear for 150 ms through headphones. Consistent with previous studies , the participants were asked to answer quickly and precisely whether or not they heard the auditory target on the left or right side of the headphones by pressing the corresponding key on the switch keypad using their dominant index or middle fingers, respectively. Response times (RT) were measured in each trial. A standard procedure for the Posner’s cueing paradigm removed cue stimuli before a target stimulus appeared on the display. However, when using a facial gaze as a cue, many studies e.g. refs   and   also implemented a modified cueing paradigm in which the cue remained on the screen until a response was obtained or a set time had elapsed. For this study, we designed a contextual processing condition between the cue and target. To establish a strong and obvious contextual relationship between the cue and target, the cue remained until a response was obtained or 1000 ms had elapsed. The targets appeared randomly on the same or opposite side of the cue direction when the cue was directed left or right. The target appeared at the cued location in 50% of the trials. The participants were told that the cue did not predict the target location and were instructed to fixate on the centre of the screen in each trial. 

The fMRI analysis relied on a within-subject three factorial design, with the cue condition (gaze or arrow), context condition (i.e., the congruence of meaning between the cue and target, which could be congruent (social gaze and social voice or arrow and tone) or incongruent (social gaze and tone or arrow and social voice)), with validity condition (valid or invalid) as the repeated factors. Sixty trials were performed under each condition. Our experimental design was based on a mixed block/event-related paradigm, facilitating a more complete utilisation of the BOLD signal and enabling a deeper interpretation of how the regions of the brain function on multiple timescales . Consistent with a previous study , alternating blocks of experimental trials of cue condition and blocks of baseline were presented. Within the condition blocks, congruence trials were presented in a pseudorandom event-related distribution. 


### MRI acquisition 
  
The images were acquired using a 3.0-T Trio Tim Scanner-vision whole-body MRI system (Siemens, Erlangen, Germany) to measure activation using a head coil. The functional images comprised 33 consecutive slices parallel to the anterior-posterior commissure plane, covering the entire brain. A T2*-weighted gradient-echo planar imaging (EPI) sequence was used with the following parameters: TR = 2000 ms, TE = 30 ms, flip angle = 90°, field of view = 220 × 220 mm, matrix size = 64 × 64, and voxel size = 3.4 × 3.4 × 3.5 mm . The slices covered most of the brain, including the entire temporal cortex, but excluding the most inferior parts of the cerebellum. We also acquired high-resolution isotropic T1-weighted images (TR = 1900 ms, TE = 2.52 ms, flip angle = 9°, field of view = 250 × 250 mm, 176 sagittal slices, voxel size = 1 × 1 × 1 mm ). 


### Behavioural data analysis 
  
The data were analysed using the SPSS software package (ver. 21.0). Incorrect responses (1.76% of the trials) and RT of less than 100 ms or more than 1000 ms were excluded from the RT analysis (1.18% of the trials), and trials in which a response occurred prior to the target onset were also excluded. The mean RT under conditions was calculated for each participant. The mean RT was analysed using a three-way analysis of variance (ANOVA) with cue (gaze, arrow), context (congruent, incongruent), and validity (valid, invalid) as within-participant factors. To examine whether an interaction was significant, if present, a follow-up simple main effect (i.e. assessing the effect of each independent variable at each level of the other independent variable) analysis was conducted to interpret the result. 


### Image data analysis 
  
Data preprocessing and statistical analyses were performed using the Statistical Parametric Mapping software package (SPM12; Wellcome Department of Cognitive Neurology, London, UK;   http://www.fil.ion.ucl.ac.uk/spm/software/spm12  ) implemented in MATLAB 2013b (Math Works). The functional images from each run were realigned using the first scan as a reference to correct for head movements. The movement parameters generated during spatial realignment indicated that all subjects moved less than 2 mm during the course of the trial. The T1 anatomical image was preprocessed using an intensity inhomogeneity correction. Then, T1 anatomical images were coregistered to the first scan of the functional images. Next, the coregistered T1 anatomical image was normalised to the Montreal Neurological Institute space using a unified segmentation-spatial normalisation approach . The parameters from this normalisation process were subsequently applied to each of the functional images. Finally, these spatially normalised functional images were resampled to a voxel size of 2 × 2 × 2 and were spatially smoothed in three dimensions using an 8-mm full-width-at-half-maximum Gaussian kernel. 

We used random-effects analyses  to identify significantly activated voxels exhibiting interesting effects. First, we performed a single-subject analysis . The BOLD response was modelled as the neural activity, convolved with a canonical haemodynamic response function (HRF), which yielded regressors in a general linear model (GLM) for each condition. We used a high-pass filter comprising a discrete cosine basis function with a cut-off period of 128 to eliminate the artefactual low-frequency trend. To correct the global fluctuation related to motion artefacts, global scaling was conducted. Serial autocorrelation, assuming an AR (1) (first-order autoregressive) model, was estimated from the pooled active voxels with a restricted maximum likelihood procedure and used to whiten the data and design matrix . 

The contrast images from the first-level analyses from all subjects were subsequently used for the second-level group statistics. First, for each participant, the data were best fitted at every voxel using a combination of effects of interest. These data were delta functions representing the onsets of the eight conditions, given by the crossing of our 2 × 2 × 2 factorial design: cue (gaze, arrow) × context (congruent, incongruent) × validity (valid, invalid), convolved with the SPM12 haemodynamic response function. Second, based on the behavioural results, a 2 × 2 × 2 (cue × context × validity) factorial ANOVA was used to investigate the relationship between behavioural results and brain activation. Based on a methods analysis , the statistical maps exhibited a spatial extent threshold at p < 0.05, family-wise error (FWE)-corrected for multiple comparisons, and an intensity threshold at p < 0.001, uncorrected for multiple comparisons at the whole-brain level was used to protect against false-positive activations. The peak voxels of clusters exhibiting reliable effects are reported in MNI coordinates. We had an a priori hypothesis regarding the activity of contextual processing in TPJ and STS, and the influence of contextual processing in dorsal and ventral frontoparietal networks. Based on anatomical masks using the WFU Pickatlas tool, a small-volume correction was also employed to the a priori regions of interest, attributed to the anatomical structures in left/right hemisphere of the STS with BA21, 22, the IPS and SPL with BA5, 7, the FEF with BA8, and the IFG with BA44, 45, 47, separately. Consistent with the whole-brain level, we used small-volume correction at a voxel spatial extent threshold at p < 0.05, FWE corrected, and an intensity threshold at p < 0.001, uncorrected for multiple comparisons. Finally, to quantify neural responses with the influence of attentional orienting under context conditions, we used the MarsBaR software package  to extract percentage changes in BOLD signals for congruent and incongruent contexts under valid and invalid conditions, averaged across voxels with given regions of interest (ROI) using spheres with a radius of 8 mm. Then, the means of the percent signal change (PSC) between the conditions were compared using repeated-measures ANOVA. All statistics were calculated using the SPSS software package (ver. 21). 



## Results 
  
### Behavioural results 
  
The data pertaining to errors did not reveal any significant main effect or interaction (all   p   > 0.05), thus indicating that the participants suffered no speed-accuracy trade-off (Table  ).   
Mean response times (ms), standard deviations, and percent errors (%E) as a function of cue, context, and validity. 
  

The mean RT under each condition are listed in Table  , and the mean differences in RT between the invalid and valid conditions are shown in Fig.  . A three-factor repeated-measures ANOVA was used to analyse the RT. The analysis revealed a main effect of cue (  F   (1, 21) = 12.412,   p   = 0.002,   η   = 0.371), with faster responses under the eye gaze (339.7 ms) versus arrow (351.3 ms) condition. In addition, we also observed a significant main effect of context (  F   (1, 21) = 8.213,   p   = 0.009,   η   = 0.281), with faster responses under congruent (341.3 ms) versus incongruent (349.7 ms) conditions, and validity (  F   (1, 21) = 25.247,   p   < 0.001,   η   = 0.546), with faster responses under valid (334.8 ms) versus invalid (356.2 ms) conditions.   
Response times (RT) results in attentional orienting. Mean (with SE) RT presented for valid and invalid conditions as a function of a cue type condition (gaze or arrow). **  p   < 0.01. 
  

A significant interaction of context × validity was observed (  F   (1, 21) = 4.907,   p   = 0.038,   η   = 0.189), but no significant interaction was detected for cue × context (  F   (1, 21) = 0.166,   p   = 0.688,   η   = 0.008), cue × validity (  F   (1, 21) = 0.048,   p   = 0.828,   η   = 0.002), or cue × context × validity (  F   (1, 21) = 0.108,   p   = 0.746,   η   = 0.005). 

The   post hoc   test revealed a significant difference between context conditions under invalid conditions (  p   = 0.004) but not under valid conditions (  p   = 0.182) with a faster response for congruent (349.9 ms) versus incongruent (362.5 ms) under invalid conditions, indicating an RT benefit for targets that match the context (e.g. social) of the cue under invalid conditions but not under valid conditions. This result suggests that the disengagement of attention from cued locations is facilitated through contextual processing. These findings demonstrated that attentional orienting is modulated through contextual processing only under invalid conditions, enabling the investigation of the neural substrates underlying the behavioural response of the contextual processing between the cue and target in attentional orienting induced by gaze and arrow cues. 


### Supplementary analysis of the influenced by the gender 
  
Because previous studies have reported that gaze-triggered orienting is different between genders (e.g., refs   and  ), we added gender (male, female) as between-participant factor to supplement the influence of the gender based on the main (3-way) ANOVA of RT data analysis, although 22 participants were recruited with gender unbalance including 9 women and 13 men. The results found a significant interaction between gender and the validity (  F   (1, 20) = 9.591,   p   = 0.006,   η   = 0.324) but not between gender and other factors (all   F   (1, 20) ≤ 2.54,   p   > 0.1). However, the   post hoc   test did not reveal a difference between genders under valid or invalid conditions (both   p   > 0.1), although a faster response was observed for valid compared with invalid conditions in both male (323.5 vs. 335.6 ms,   p   = 0.017) and female (351.1 vs. 386.0 ms,   p   < 0.001) participants. Thus, the results of the present study suggest that attentional orienting through contextual processing was not influenced by the gender of the participants. 


### fMRI results 
  
Next, based on the behavioural results, we investigated the patterns of brain activation associated with cross-modal attention. In the primary analysis, we performed 2 cue conditions (gaze, arrow) × 2 context conditions (congruent, incongruent) × 2 validity conditions (valid, invalid) repeated-measures ANOVA. 


### Main effects of cue, validity, and context 
  
In a whole-brain analysis, the gaze trials evoked significantly greater activity than arrow trials in a many clusters of voxels. One of these clusters included the fusiform gyrus (BA 19), extending from the extra-striate visual areas into the occipital and temporal cortices (Supplementary Fig.  , Table  ). In contrast, greater activity for arrow than for gaze trials was observed in the right hemisphere of temporal lobe, including the middle temporal gyrus (BA 37), and the left hemisphere of occipital lobe, including the middle occipital gyrus (BA 19) (Supplementary Fig.  , Table  ). These results were consistent with previous evidence , thus indicating that gaze versus arrow cues increased activation in various occipital and temporal areas, whereas the reverse contrast evoked activation in occipital regions. 

Furthermore, in a whole-brain analysis, invalid gaze and arrow cues evoked a significantly larger response than valid gaze and arrow cues in the left frontal hemisphere and the limbic system, including the inferior and middle frontal gyrus, and the anterior cingulate (Supplementary Fig.  , Table  ). These results were also consistent with those of a previous study  that revealed common activity in the IFG by conjunction analyses to response gaze and arrow cues in attentional orienting. However, activation was not observed by valid versus invalid gaze and arrow cues. 

To highlight the neural underpinnings of RT modulated through contextual processing, we examined the difference between congruent and incongruent contextual meanings of the cue-target. The results of the whole-brain analysis indicated that the congruent condition evoked a significantly smaller response than the incongruent condition in the left hemisphere parietal, including TPJ (BA 40). Additionally, anatomical region-based small-volume corrections revealed significant activation in the temporal lobe, including STS (BA21/22). (Fig.  , Table  ) These findings indicated that activity in left TPJ and STS regions was associated with the contextual processing of the cue-target, but this activation was not observed in the congruent versus the incongruent condition. Furthermore, to examine the differences between gazes and arrows in contextual processing, we investigated whether the neural activity in these regions differed between gaze and arrow cues. The results revealed no significant difference between gaze and arrow cues, indicating that comparable neural activity was elicited by contextual processing between gaze and arrow, thereby influencing valid and invalid orienting within attentional orienting. Next, we assessed the cue condition, focusing on its influence in contextual processing for both gaze and arrow cues in attentional orienting.   
In response to incongruent versus congruent context conditions, exploratory whole-brain analysis indicating that the left TPJ is significantly activated, and small-volume-correction analysis showing that the left STS is significantly activated based on an anatomical mask. A voxel-wise spatial extent threshold   p   < 0.05, FWE-corrected, and an intensity threshold   p   < 0.001, uncorrected, were used. 
    
Main effect of incongruent condition: incongruent > congruent. 
  
BA = Brodmann’s area; FWE = family-wise error; a voxel-wise spatial extent threshold at   p   < 0.05, FWE corrected, and an intensity threshold at   p   < 0.001, uncorrected. 
  


### Interaction of context and validity conditions 
  
A 2 (context: congruent, incongruent) × 2 (validity: valid, invalid) ANOVA was performed to investigate the influence of activation by the contextual relationship of cue-target in attentional orienting networks. The results of the whole-brain analysis revealed a significant interaction in left hemisphere TPJ (BA 40). Additionally, anatomical region-based small-volume corrections revealed significant activation in the left hemisphere IFG (BA 47) regions (Fig.  , Table  ).   
(  a  ) In response to the interaction between context and validity conditions, exploratory whole-brain analysis showing left TPJ significantly activated, and small-volume-correction analysis showing left IFG significantly activated based on an anatomical mask. A voxel-wise spatial extent threshold   p   < 0.05, FWE corrected, and an intensity threshold   p   < 0.001, uncorrected, were used. (b) Mean (±SE) and percent signal changes (PSC) in the left hemisphere TPJ and IFG regions are shown. These areas are overlaid on the mean normalised structural MRI from all subjects in this study. n.s:   p   > 0.05; **  p   < 0.01. 
    
Interaction between context and validity conditions. 
  
BA = Brodmann’s area; FWE = family-wise error; a voxel-wise spatial extent threshold at   p   < 0.05, FWE corrected, and an intensity threshold at   p   < 0.001, uncorrected. 
  


### ROI analysis 
  
The results of the interaction were expanded using an ROI-based analysis. Figure   and Table   present the location and pattern of the response in all ROIs in which a signal change was extracted. These responses were located in left TPJ and IFG regions. The PSC in these regions was analysed using a 2 (context: congruent, incongruent) × 2 (validity: valid, invalid) repeated-measures ANOVA. A significant interaction was observed in the left TPJ and IFG regions. Moreover, the post hoc test revealed that PSC was smaller when the contextual meaning of cue-target was congruent vs. incongruent in all regions under invalid conditions (all   p   < 0.05) but not under valid conditions (Fig.  , Table  ). These results indicated that the influence of contextual processing on the neural activity for attentional orienting was observed under invalid conditions but not under valid conditions.   
ROI results. 
  
ROIs represent previously examined areas that exhibited a significant interaction between context and validity conditions in a 2 × 2 ANOVA (with a voxel-wise spatial extent threshold at   p   < 0.05, FWE corrected, and an intensity threshold at   p   < 0.001, uncorrected).   *p   < 0.05, *  *p   < 0.01. 
  



## Discussion 
  
We examined attentional orienting by gaze and arrow cues under a localising task in which participants were asked to indicate whether the target (voice and tone) was heard on the left or right side of the headphones. The combination of cues and targets varied across trials, reflecting contextual relationship processing, where the contextual meaning of the cue-target was congruent (social gaze and social voice and arrow and tone) or incongruent (social gaze and tone and arrow and social voice). Although the behavioural results showed no difference between gaze and arrow cues, a RT benefit was observed for targets matching the context of the cue under the invalid condition. This finding suggested that a disengagement of attention from cued locations was facilitated through contextual processing. Previous studies  have demonstrated that attentional orienting can be influenced by contextual processing when targets were presented in a specific context (e.g., colour or emotion) for gaze or arrow cues. Compared with a previous study  in which attentional orienting based on a contextual effect for gaze and arrow was investigated in the context of colour (i.e., schematic white/black eyes as the cue and a black square as the target), the present study examined attentional orienting through contextual processing using facial gaze and voice, which seems to more closely resemble a real-world environment. Furthermore, although another study  examined attentional orienting through gaze cues influenced by emotional context for 80 different images (e.g., a chimney image) as targets, the present study only manipulated two sounds as targets, potentially easing the establishment of a pairing between the cue and target. That is, the pairing of gaze and voice was easily established, and arrow and tone represented the other pair. Thus, the present study observed attentional orienting through contextual processing when using gaze and arrow as cues. Based on these findings, the results of the present study extended those of previous studies , indicating that attentional orienting through centrally presented cues, irrespective of cue characteristics (e.g. social or non-social), could also be modulated by contextual relationship processing between the cue and target. 

Importantly, consistent with the behavioural results, the main analyses of fMRI data revealed that neural substrates were not different in response to the contextual relationship processing of cue-target for gaze and arrow cues. Previous studies  have revealed that neural substrates in the regions of the TPJ and STS were associated with contextual processing. Consistently, to highlight the neural underpinnings of RT modulated by contextual processing, the results of the present study also demonstrated that the left STS and bilateral TPJ were specifically involved in contextual processing under both gaze and arrow conditions. The results also indicated that these regions were weakly activated when the relationship of cue-target was congruent (the expected target matching the context of the cue) compared with incongruent (the expected target non-matching the context of the cue). We suggest that these regions may be the locations of an inhibitory mechanism, which enhanced neural activity to suppress the processing of incongruent predictions for targets from cue stimuli. Given that the activity of these regions did not differ between social gaze and arrow cues, we further suggest that a comparable neural system was elicited by contextual processing for gaze and arrow cues and further influenced the attentional process. This idea is consistent with previous studies  that demonstrated the differences in attention to social and non-social cues were quantitative rather than qualitative. 

Interaction analyses in behavioural results indicated that a different pattern of attentional orienting by contextual processing was elicited for valid and invalid conditions. That is, a RT benefit was observed for targets matching the context (e.g. social) of the cue under invalid conditions, but not under valid conditions. We propose that the different patterns between valid and invalid conditions may be influenced through the overlap of the time window between contextual processing and attentional orienting. Electrophysiological studies have demonstrated that the activity of temporal staging differed between valid and invalid conditions . These studies reported an amplitude enhanced at P1 (a positive component at occipital electrode sites between 70 and 100 ms post-target onset) in attentional orienting with gaze as the cue under valid versus invalid conditions, whereas a greater amplitude at P3 (a positive component at central/parietal/midline electrode sites between 300 and 500 ms post-target onset) was observed under invalid versus valid conditions. However, in previous studies , the N300 (a negative component at frontal electrode sites at approximately 300 ms) - N400 (a negative component at central/parietal electrode sites at approximately 400 ms) wave reflected an updating of context information. For example, Demiral   et al  .  observed a stronger N300-N400 effect elicited through a semantic context when the contextual scene was presented before the target in a spatial attention task. Given that the pattern of attentional orienting by contextual processing differed between valid and invalid conditions, we suggest that this finding may be influenced through associations with the activities of temporal staging between the influence of attentional orienting (i.e. the mechanism of valid and invalid conditions) and the contextual processing component. Compared with the early stage (70–100 ms) under valid conditions, the time window of processing overlapped with that of contextual information and attentional orienting under invalid conditions at a later stage (300–500 ms), in which these processes could be integrated to suppress a violation of expectancies (the expected target matching the context of the cue) when the contextual relationship of cue-target was incongruent. In addition, we speculated that varying SOA conditions may influence expectations, and the patterns of attentional orienting by contextual processing for valid and invalid conditions could be modulated in the present experiment. That is, if the target was presented at a short SOA prior to the expectation of the subject, then attentional orienting by contextual processing may not be influenced under valid or invalid conditions, whereas if the target was presented at a long SOA after the expectation of the subject, then attentional orienting by contextual processing might be influenced under invalid conditions. 

Furthermore, the results of the interaction analyses in fMRI also demonstrated the influence of contextual processing on neural activity for attentional orienting under invalid but not valid conditions. Such neural activities were observed in the left hemisphere TPJ and IFG, an area in the ventral frontoparietal network that may be responsible for invalidity orienting (for reviews, see refs   and  ). As mentioned above, analyses of the fMRI data revealed that the left STS and TPJ were involved in the contextual processing of the relationship between the cue and target. The activity in the left TPJ region overlapped in processing the contextual relationship of cue-target and invalidity orienting in attention. Additionally, consistent with the pattern of neural activity for contextual processing in the left STS and TPJ, we observed that when the relationship of cue-target was congruent versus incongruent based on ROI analyses, less activity was observed in all of these brain regions. This result suggests that from the left TPJ to the IFG in the ventral frontoparietal network, neural signals for contextual processing were transferred to invalidity orienting in attention, in which the intrinsic connection pathway is present among these regions . Compared with incongruent conditions, we suggest that the lower activity in the ventral frontoparietal network when the contextual processing of the relationship between cue and target is congruent under invalid conditions may reflect a disengagement of attention from cued locations at a lower cost, which is readily elicited. This idea may explain the behavioural data obtained under invalid conditions, indicating that a lower cost is associated with processing when the contextual processing of the relationship between the cue and target was congruent versus incongruent; thus, participants could disengage attention from the cued location to rapidly capture a target. 

### Implications of the present study 
  
Previous behavioural studies  had demonstrated that attentional orienting by gaze or arrow cues could be modulated through contextual processing. Consistent with these studies, the behavioural results in the present study also revealed that RT in attentional orienting was modulated through contextual processing. In particular, we observed that attentional orienting was modulated through contextual processing under invalid conditions. Given that the present study identified the influence of the neural substrates by contextual processing under invalid conditions in ventral frontoparietal networks, we suggest that this finding may account for the behavioural data regarding attentional orienting through contextual processing based on the neurocognitive architecture. 

In addition, a behavioural study demonstrated impaired attentional orienting when the cue-target relationship is weak (i.e., incongruent context) in individuals with autism spectrum disorder (ASD) , a finding that raises a question regarding whether individuals with ASD exhibit impairment of gaze-triggered attention because activity is impaired in the neural mechanism in the ventral frontoparietal network. Given that impaired gaze-triggered attention may impede and differentially affect the development of the ability to understand the mental state of another individual in social communication , we suggest that an atypical function in the ventral frontoparietal network, particularly in the processing of contextual information, may be associated with the atypical development of social cognition, further suggesting an important direction for future studies combining brain imaging and treatment interventions for social processing deficits in individuals with ASD. 


### Limitations 
  
First, we tested attentional orienting by contextual processing using gaze and arrow as cues with two types of targets (social voice and tone) under only visual-auditory cross-modal conditions. Given the complexity of real life, future studies should examine attentional orienting by contextual processing using two types of targets under visual-visual unimodal or visual-tactile cross-modal conditions in which attentional orienting by contextual processing may also play an important role. 

Second, the present study involved two types of contextually related cues and targets. In contrast with faces and voices, which are immediately paired in a congruent context, the pairing of the tone and arrow might be influenced through the increasing number of trials throughout the experiment. To evaluate this possibility, all experimental blocks were divided into two parts (first and last half of the block), and a four-factor repeated-measures ANOVA (block × cue × context × validity) was used to analyse the RTs. Given that a significant 4-way interaction was observed (  F   (1, 21) = 5.09,   p   = 0.04,   η   = 0.195), two 3-way repeated-measures ANOVA (block × cue × context) was performed under valid and invalid conditions separately. Although no significant interaction was detected for block conditions under invalid conditions, (all   p   > 0.1), we observed that the main effect of context (  F   (1, 21) = 11.74,   p   = 0.003,   η   = 0.36) was significant with faster response to congruent than incongruent conditions (349.0 vs. 361.5 ms), thus indicating that contextual processing between the cue and target was immediately established at both gaze and arrow pairings. However, under valid conditions, although we observed no significant main effect of context (  F   (1, 21) = 1.41,   p   = 0.25,   η   = 0.063), a significant interaction of block × cue × context was observed (  F   (1, 21) = 12.67,   p   = 0.002,   η   = 0.38). The   post hoc   test revealed a significant difference between context conditions (  p   = 0.045) with a faster response to congruent than incongruent conditions (327.4 vs. 346.9 ms) when using arrows as cues in the last half of the block, thereby indicating that attentional orienting by contextual processing could be influenced by increasing the number of trials throughout the experiment under valid conditions when the tone target was matched with arrow cue. In the present study, attentional orienting was modulated through contextual processing under invalid conditions. Thus, we suggest that this effect may be elicited through immediately established pairing between arrow and tone, rather than increasing the number of trials in the experiment. However, future studies should investigate the mechanism of how contextual processing is influenced by increasing the number of trials through the experiment. 

Finally, in the present study, we directly contrasted the context conditions by gaze and arrow cues in invalid and valid trials to reveal differences in attentional orienting. Previous studies  manipulated a neutral cue (e.g. direct gaze) as a baseline condition to examine differences in the neural mechanisms between valid and invalid attentional orienting conditions. However, compared with a non-directional arrow as a neutral cue, Engell   et al  .  suggested that a direct gaze, as a neutral cue, was perceived as directional rather than non-directional, which was problematic in terms of comparing social versus non-social cueing in an fMRI study. Future research should investigate the need for a baseline condition in which the neural gaze and arrow cues involve no spatial information and have the same effect on neural activity, such as closed eyes and non-directional arrows. 



## Conclusions 
  
In this study, we observed that the response time in attentional orienting by gaze and arrow cues was modulated through contextual processing between the cue and target when contextually congruent and incongruent under invalid conditions in behavioural studies. Additionally, on the neural level, activity in the left TPJ and STS was observed with attentional orienting by gaze and arrow cues in response to contextual processing of the relationship between the cue and target. However, we did not observe any difference in the neural substrates between social gaze and arrows by contextual processing in attentional orienting. This finding adds further evidence in support of the notion that the differences in attention to social and non-social cues are quantitative rather than qualitative. Importantly, both behavioural and fMRI results indicated that the influence of contextual processing on neural activity for attentional orienting occurred under invalid conditions. Such an increase was observed in the ventral frontoparietal network when the cue and target were incongruent rather than congruent. This finding may provide an explanation for the behavioural data regarding attentional orienting by contextual processing based on the neurocognitive architecture. 


## Electronic supplementary material 
  




 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-8'>
<h2>8. PMID: 20520767</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> The Brain Functional Networks Associated to Human and Animal Suffering Differ among Omnivores, Vegetarians and Vegans</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2010</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0010847</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study meets all inclusion criteria: it reports a task-based functional MRI study of social-related processing (empathy/social cognition while viewing human and animal suffering), enrolled healthy adult participants aged 18–60 (n=60, range 18–60), and presents whole-brain analyses (SPM2 whole-brain random-effects, FWE-corrected results and interaction analyses). It does not rely solely on ROI analyses, is not a review, and excludes clinical/psychiatric populations. Therefore it should be included in the review of fMRI studies of social processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Empathy and affective appraisals for conspecifics are among the hallmarks of social interaction. Using functional MRI, we hypothesized that vegetarians and vegans, who made their feeding choice for ethical reasons, might show brain responses to conditions of suffering involving humans or animals different from omnivores. We recruited 20 omnivore subjects, 19 vegetarians, and 21 vegans. The groups were matched for sex and age. Brain activation was investigated using fMRI and an event-related design during observation of negative affective pictures of human beings and animals (showing mutilations, murdered people, human/animal threat, tortures, wounds, etc.). Participants saw negative-valence scenes related to humans and animals, alternating with natural landscapes. During human negative valence scenes, compared with omnivores, vegetarians and vegans had an increased recruitment of the anterior cingulate cortex (ACC) and inferior frontal gyrus (IFG). More critically, during animal negative valence scenes, they had decreased amygdala activation and increased activation of the lingual gyri, the left cuneus, the posterior cingulate cortex and several areas mainly located in the frontal lobes, including the ACC, the IFG and the middle frontal gyrus. Nonetheless, also substantial differences between vegetarians and vegans have been found responding to negative scenes. Vegetarians showed a selective recruitment of the right inferior parietal lobule during human negative scenes, and a prevailing activation of the ACC during animal negative scenes. Conversely, during animal negative scenes an increased activation of the inferior prefrontal cortex was observed in vegans. These results suggest that empathy toward non conspecifics has different neural representation among individuals with different feeding habits, perhaps reflecting different motivational factors and beliefs. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (31724 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Social cognition includes mental processes necessary to understand and store information about the self and other persons, as well as interpersonal norms and procedures to navigate efficiently in the social world  . Basic abilities underlying social cognition include the perception and evaluation of social stimuli, the integration of perceptions with contextual knowledge, and finally the representation of possible responses to the situation. One of the hallmarks of social cognition in humans is the ability to understand conspecifics as beings like oneself, with intentional and mental lives like one's own  . Accordingly, human beings tend to identify with conspecifics and attribute mental states to them. Such abilities rely on the activity of several brain regions, including the frontal lobes (orbitofrontal cortex, medial prefrontal cortex, and cingulate cortex), the temporal lobes (including the amygdala), the fusiform gyrus, and the somatosensory cortices  ,  ,  . The majority of these regions is also critically involved in the processing of emotions  . This suggests that the merging between emotions and feelings experienced by oneself and those perceived in other individuals may be a key ingredient of social understanding, and it may play a major role in promoting empathy, prosocial behaviours, and moral norms  ,  . Moreover, empathic responses can be modulated by the subjective attitude held toward suffering individuals  , as well as by personal experience  . Several functional magnetic resonance imaging (fMRI) studies showed that observing the emotional state of another individual activates a neuronal network involved in processing the same state in oneself, whether it is pain, disgust, or touch ,  ,  . Empathy toward another person, which can be defined as the ability to share the other person's feeling in an embodied manner, has been related to recruitment of a network mostly including the somatosensory and insular cortices, limbic regions and the anterior cingulate cortex (ACC). Whereas cognitively inferring about the state of other person (known as theory of mind) has been associated with recruitment of medial prefrontal regions, the superior temporal sulcus and the temporo-parietal junction . 

A few investigations have also assessed whether affective links between people modulate their brain empathic responses to others, such as when these are loved ones or strangers , or when they are believed to be fair or unfair persons  ,  . The majority of previous studies attempting to characterize empathy-related responses did not separate empathy towards humans from that towards animals. Furthermore, in some studies, scenes showing animals were treated as a neutral condition. However, a recent study   that compared stimuli depicting human and non human animal targets demonstrated higher subjective empathy as the stimuli became closer in phylogenetic relatedness to humans (mammalian   vs  . bird stimuli), thus indicating that empathic response towards humans may generalize to other species. 

In this study, we postulated that the neural representation of conditions of abuse and suffering might be different among subjects who made different feeding choice due to ethical reasons, and thus result in the engagement of different components of the brain networks associated with empathy and social cognition. In details, we tested the hypothesis that the neural processes underlying empathy in vegetarians and vegans may not only operate for representations about humans but also animals, and thus vary between them and omnivore subjects. Vegetarians and vegans, who decided to avoid the use of animal products for ethical reasons, have a moral philosophy of life based on a set of basic values and attitudes toward life, nature, and society, that extends well beyond food choice. The earliest records of vegetarianism as a concept and practice among a significant number of people was closely connected with the idea of nonviolence towards animals and was promoted by religious groups and philosophers. The term veganism, which was coined from vegetarianism, acknowledges the intrinsic legitimacy of all sentient life and rejects any hierarchy of acceptable suffering among creatures. Veganism is a lifestyle that seeks to exclude the use of animals for food, clothing, or any other purpose  . The central ethical question related to veganism is whether it is right for humans to use and kill animals. Due to these differences of believes and behaviours, we also hypothesized that, in addition to a common shared pattern of cortical processing of human and animal suffering, vegetarians and vegans might also have functional architecture differences reflecting their different motivational factors and believes. 


## Results 
  
### Empathy assessment 
  
The Empathy quotient (EQ) score was significantly different between groups (p = 0.002). At post-hoc analysis, the EQ score was significantly higher in vegetarians in comparison with omnivore subjects (mean EQ score = 49.5, SD = 8.9 in vegetarians   vs  . 38.8, SD = 8.1 in omnivore; p = 0.001), and in vegans (mean EQ score = 44.6, SD = 9.8) in comparison with omnivore subjects (p = 0.04) ( ). The difference between vegans and vegetarians was not statistically significant. 
   Graph showing error bars of means and standard deviations of empathy quotient (EQ) score in the three groups of subjects.  
See text for further details. 
  

### Within-group fMRI results 
  
The observation of both human and animal negative valence scenes resulted in the recruitment of several brain areas involved in emotion and empathy in the three groups of subjects, including the anterior insula, basal ganglia, thalami, and several other cortical areas located in the occipital lobes, prefrontal and parietal cortices.   shows the brain patterns of activations in the three groups of subjects during the different experimental conditions.   summarizes the main results of within-group comparisons of the two experimental conditions. 
   Within-group analysis of activations.  
Cortical activations on a rendered brain from omnivore (A–H), vegetarian (I–R) and vegan (S–W) subjects during observation of pictures showing negative valence scenes of humans (A–D, I–N, S–V) or animals (E–H, O–R, Z–W) (within-group analysis, one-sample t tests, t = 3 for display purpose). Images are in neurological convention. 
     Within-group comparisons of human   vs  . animal negative valence picture view and vice versa in omnivore subjects, vegetarians and vegans (paired t test in each group, p<0.05 FWE-corrected).        

### Between-group fMRI results 
  
The patterns of activations during the neutral condition did not differ between groups. 


### Common regions of activations between vegetarians and vegans 
  
During human negative valence picture view, omnivore subjects had a more significant activation (p<0.05, FWE) of the bilateral middle temporal gyrus (MTG) (MNI space coordinates: 38, −58, 8, t value = 5.65; and −36, −76, 8, t value = 5.56) when compared to vegetarians and vegans. Compared to omnivore subjects, the entire sample of vegetarians and vegans had more significant activations (p<0.05, FWE) of the ACC (MNI space coordinates: 10, 22, 40; 10, 36, 28, and −4, 30, 36; t values = 5.65, 5.43, and 5.30), and the left inferior frontal gyrus (IFG) (MNI space coordinates: −48, 20, 0, t value = 5.56) ( ). 
   Results of the between-group comparisons of emotional (human and animal) negative valence picture views.  
Results are superimposed on a high resolution T1-weighted image in the standard MNI space, at a threshold of p<0.05 corrected for multiple comparisons. Areas activated during human picture view in vegetarians and vegans   vs.   omnivores are shown in yellow. Activations specific for vegetarians are shown in blue. Activations specific for vegans are shown in red. A: human picture view; B: animal picture view. Images are in neurological convention. 
  
During animal negative valence picture view, omnivore subjects had more significant activations (p<0.05, FWE) of the bilateral MTG (MNI space coordinates: −46, −62, 0, t value = 6.03; and 34, −74, 4, t value = 5.94), when compared to vegetarians and vegans. Compared to omnivore subjects, the entire sample of vegetarians and vegans had more significant activations (p<0.05, FWE) of the bilateral IFG (MNI space coordinates: −50, 14, −2, t value = 6.84; and 52, 14, −4, t value = 6.34), bilateral lingual gyrus (MNI space coordinates: 8, −80, −14, t value = 6.83; and −10, −78, −14, t value = 6.58), ACC (MNI space coordinates: 0, 24, 28; −2, 52, 8; t values = 5.76 and 5.51), posterior cingulate cortex (PCC) (MNI space coordinates: 0, −42, 26, t value = 5.87), left cuneus (MNI space coordinates: −2, −78, 24, t value = 5.83), and left middle frontal gyrus (MFG) (MNI space: −44, 46, 8, t value = 5.50) ( ). This analysis also showed that, compared to omnivores, vegetarians and vegans had a lower activation of the right amygdala (MNI space coordinates: 30, 2, −20, t value = 5.38). To better define amygdala behavior in the three groups of subjects, we analyzed its activations and deactivations during the two experimental conditions in each group (  and  ). This analysis revealed no significant activation neither deactivation (even when lowering the threshold for the statistical significance at a p<0.001, uncorrected) during animal picture view in this region in vegetarians and vegans. 
   Cluster maxima coordinates of activations/deactivations, at the within-group one sample t test analysis of the areas which showed a significant interaction between groups and conditions (p<0.001, uncorrected).        

### Different regions of activations between vegetarians and vegans 
  
We also directly compared the neural responses in empathy and emotion-related networks between omnivores, vegetarians, and vegans, using a masking procedure (See  ), to identify regions of specific activations of each group contrasted to the others. 

#### a) Vegetarians vs. omnivores and vegans 
  
Observation of human negative valence scenes resulted in a selective recruitment of the right IPL (BA40) (MNI space coordinates: 52, −50, 40, t value = 4.44) in vegetarians ( ). For animal pictures, activations specific to vegetarians were found in the ACC (MNI space coordinates: −2, 52, 10, t value = 5.02) and the right lingual gyrus (MNI space coordinates: 8, −84, −10, t value = 5.00) (p<0.05, FWE). 


#### b) Vegans vs. omnivores and vegetarians 
  
During human negative valence picture view, no cortical activation “specific” to vegans was found. During animal negative valence picture view, vegans activated the IFG bilaterally (MNI space coordinates: 54, 16, −6, and −46, 18, −2, t values = 4.88 and 4.67), and the left MFG (BA10) (MNI space coordinates: −46, 48, 4, t value = 4.29) ( ) (p<0.05, FWE). 



### Analysis of interaction 
  
To further explore the specificity of stimulus processing within the three groups of subjects, we performed an analysis of interaction between picture types (animal/human) and groups (omnivore/vegetarian/vegan). Results showed an interaction in the right amygdala (MNI space coordinates: 24, −10, −22) (greater increases to animal negative valence view in omnivores and to human negative valence view in vegans) ( ), the left amygdala (−22, −8, −28) (greater increases to human negative valence view in vegans) ( ), the ACC (MNI space coordinates: −2, 52, 10) (preferential increases to human negative valence view in omnivores, and to animal negative valence view in vegetarians) ( ); and the right IFG (MNI space coordinates: 52, 20, −8) (selective responses to animal negative valence view in vegans) ( ). 
   Interactions between stimuli (animal/human) and groups (omnivore/vegetarian/vegan).  
An interaction was found in the right amygdala (A), indicating greater increase to animal negative valence picture view in omnivores and to human negative valence picture view in vegans. An interaction between “human pictures” and “vegan group” was also found in the left amygdala (A). An interaction was found in ACC (B) between the “omnivore group” and “human pictures”, as well as between “vegetarian group” and “animal pictures”; and in the right IFG between “animal pictures” and “vegan group” (C). Foci of activations are shown on a high-resolution T1-weighted image in the standard MNI space. Plots indicate activation changes detected in the three groups during the two experimental conditions in each of these regions. Images are in neurological convention. 
  
 summarizes the behavior, in terms of activations/deactivations, at the within-group one sample t test analysis of the three main areas which showed a significant interaction between groups and conditions (i.e., amygdala, IFG, and ACC). 


### Analysis of correlations 
  
During human negative valence picture view, no correlation was found between EQ score and fMRI activity in the three groups of subjects of the study. 

During animal negative picture view, significant correlations (p<0.001) were found between EQ score and: 
  
activation of the left MTG (r = 0.87), ACC (r = −0.76) and the bilateral IFG (right IFG: r = −0.71, left IFG: r = −0.89) in omnivores; 
  
activation of the left IFG (r = 0.92), the left MFG (r = 0.68), and the right MTG (r = −0.75) in vegetarians; 
  
activation of the bilateral lingual gyrus (right lingual gyrus: r = 0.69, left lingual gyrus: r = 0.75) and the left IFG (r = 0.78) in vegans. 
  


## Discussion 
  
The first main finding of this study was the demonstration of a common functional architecture of emotional processing in vegetarians and vegans. In particular, while omnivores are characterized by a greater activation of the bilateral posterior MTG during both human and animal negative valence scenes, vegetarians and vegans have constantly an higher engagement of empathy related areas while observing negative scenes, independently of the species of the individuals involved, which is characterized by an increased recruitment of the ACC and the IFG. Increased activation in the ACC and left IFG in vegetarians and vegans during human and animal suffering view is likely to reflect a stronger empathic response in the first two groups. 

Remarkably, vegetarians and vegans have an higher engagement of empathy related areas while observing negative scenes regarding animals rather than humans, with the additional recruitment of the mPFC, PCC, and some visual areas. ACC has been associated with alert states, self awareness and pain processing  , whereas mPFC and PCC activations are frequently observed in conditions involving representation of the self and self values  . The PCC is also thought to be involved in memory and visuospatial processing  , particularly in relation to emotions and social behavior  . PCC is consistently activated when subjects have to judge the valence of emotionally salient words or episodic memories, with the strongest responses seen when unpleasant stimuli are presented  . 

The notion that empathic response might differ among vegetarians, vegans and omnivores, and that such a response might vary during viewing of human and animal sufferance is at least partially supported by the results of EQ assessment in the three groups of subjects and by the analysis of correlation between EQ scores and fMRI findings, which showed a direct relationship between the EQ score and left IFG recruitment during animal suffering view in vegetarians and vegans, whereas in omnivores such a relationship was inverse. 

The pattern of increased recruitment of empathy-related areas in vegetarians and vegans during animal suffering view was also associated with a reduced activation of the right amygdala in comparison to omnivores. The amygdala responds to various kinds of aversive stimuli, most strongly fearful and threatening scenes   and, to a lesser extent, to those associated with disgust  . Remarkably, the within-group analysis during animal picture view, showed the absence of signal changes (in terms of activations and deactivations) within the amygdala in vegetarians and vegans, suggesting a down-regulation of amygdala response from areas located in the frontal lobes, in an attempt to regulate emotion through cortical processes in these subjects. 

The second main finding of this study is the demonstration of strong functional architecture differences between the vegetarians and vegans during observation of negative scenes. During human suffering viewing, activations specific to vegetarians were located along the IPL. The IPL is involved in bodily representations that distinguish the self from the other  , and was found to be more activated when pictures of mutilations were presented than when contamination or neutral pictures were shown , which suggests a stronger effect on the somatosensory system in observers exposed to the former than the latter conditions. 

More critically, for animal pictures, activations specific to vegetarians were found in the ACC and the lingual gyrus, whereas activations specific to vegans were found in the bilateral IFG and the left MFG. Our data, therefore, point to differential ACC responses to animal suffering for vegetarians, a region highly interconnected with limbic and prefrontal structures that is thought to play a key role in normal and dysfunctional emotional self-control as well as social behaviour  . ACC activation has been related to awareness of emotional material, attention to emotional stimuli  , and rating of affect intensity. In a meta-analysis study, Phan et al.   found that emotional tasks with explicit cognitive components (e.g., recognition or evaluation of emotional stimuli and biographic material) engaged specifically the ACC as compared to passive emotional conditions. The ACC has also been associated with alertness and attention, notably in terms of response control and during painful stimulation  . The recruitment of this region in vegetarians might therefore correspond to their distinctive behavioral response to pictures of animal suffering, e.g., enhanced attention and empathic pain  , or increased self control and monitoring  . On the other hand, the activation of the inferior prefrontal cortex (IFG) seen in vegans during animal suffering, which is consistent with a role of such a region in different emotional tasks  , may be related to aspects of cognitive control during emotion processing. Notably, right IFG is critically involved in inhibitory processes during both cognitive   and emotional   conditions. In addition, even if the existence of the mirror-neuron system (MNS) in humans is still controversial, the IFG is also considered to be part of such a system, since these regions are often activated during action observation, motor learning and imitation of action  . Activation of MNS areas has been shown to increase during social interaction, as well as during observation and imitation of emotional faces  . The role of the MNS in social cognition is also supported by studies in patients with autism, who show a reduced recruitment of the MNS, and in particular of the IFG, during observation and imitation of facial expressions  . Our findings therefore suggest a distinctive pattern of empathic response and emotional control in vegans, mediated through the IFG and MFG. 

Between-group differences in stimuli processing were also confirmed by an analysis of interaction, which showed greater increases to animal negative valence view in omnivores and to human negative valence view in vegans in the amygdala, a preferential increase to human negative valence view in omnivores, and to animal negative valence view in vegetarians in the ACC, and selective responses to animal negative valence view in vegans in the right IFG. Intriguingly, an inverse correlation between amygdala response and activation in the right PFC and ACC has previously been shown during emotional tasks  . In humans, this system is thought to control and direct emotional responses through appraisal and evaluation of their experiences. Such an inverse correlation (i.e., decreased activation of the amygdala together with increased activations of the ACC and PFC) has also been demonstrated during “reappraisal”, which implies altering the meaning of a potentially emotion-eliciting situations in order to reduce their emotional impact  , suggesting that cortical networks of prefrontal regions can exert a cognitive modulation on emotion processing in the amygdala, particularly during intense emotional responses. An alternative hypothesis that has been considered is that limbic structures, such as the amygdala, might respond preferentially to emotive stimuli at a sensory level, and less likely to be engaged in the cognitive processing of emotional material  . 

Collectively, our results reveal that distinct brain responses are evoked by emotionally significant pictures of humans and animals in people with vegetarian and vegan feeding habits, as well as between vegetarians and vegans, suggesting that different motivational factors might underlie their preferences and moral attitudes. Vegetarians showed distinctive responses to negative valence scenes of animals in the ACC, but also to negative valence scenes of humans in the IPL, which might be consistent with greater empathic pain responses and/or enhanced attention in this group for these two conditions. On the other hand, the selective response of vegans to animals in the ACC (with reduced amygdala responses) might reflect a greater attribution of self-relevance   and a greater recruitment of emotional regulation mechanisms  ,   when viewing negative states of non-human beings, together with an enhanced activation of the motor MNS and inhibitory control processes mediated through the MFG and the IFG, respectively. By contrast, omnivores, showed greater responses to human negative valence scenes in the ACC (together with reduced amygdala activation), suggesting that self-relevance and emotion control mechanisms were more specifically engaged by viewing suffering conspecifics than suffering animal beings. 

Our study is the first to assess the neural correlates of empathy towards non conspecifics in people with different social norms, as reflected by their feeding habits. Our results converge with theories that consider empathy as accommodating a shared representation of emotions and sensations between individuals, allowing us to understand others  . They also led us to speculate that the neuronal bases of empathy involve several distinct components including mirroring mechanisms  , as well as emotion contagion and representations of connectedness with the self  . In addition, brain areas similar to those showing different emotional responses between groups in our study (such as the IFG and the mPFC) have also been found to be modulated by religiosity  , further supporting a key role of affect and empathy in moral reasoning and social values. 

This study is not without limitations. First, the use of neutral scenes as a “baseline” condition does not allow defining the neural response to suffering per se, since the response might be influenced by seeing humans or animals. Second, even if a questionnaire related to feeding habits and the EQ were obtained from all the study subjects, affective and cognitive responses during fMRI acquisition were not recorded. Clearly, further studies are warranted to confirm our results. 


## Materials and Methods 
  
The study was approved by the Ethics Committee of Scientific Institute and University Ospedale San Raffaele, Milan, Italy and a written informed consent was obtained from all subjects prior to study entry, according to the Declaration of Helsinki. 

### a) Subjects 
  
We studied 60 right-handed   healthy subjects (34 women, and 26 men, mean age = 37.7 years, range = 18–60 years), with different dietary habits. All subjects had normal or corrected-to-normal vision. We recruited 20 omnivore subjects (11 women and 9 men; mean age = 36.9 years, range = 22–60 years), 19 vegetarians (11 women and 8 men; mean age = 40.3 years, range = 23–60 years), and 21 vegans (12 women and 9 men; mean age = 36.3 years, range = 18–53 years). The groups did not statistically differ for sex and age. A questionnaire was filled in by all the subjects before fMRI acquisition to investigate feeding habits, reasons/motivations of the feeding choices, and the time elapsed from such a choice. All vegetarians and vegans reported to have made their feeding choice for ethical reasons. They had stable feeding habit since 3.8 years (SD = 8.7 years), and were recruited among vegetarian associations. Omnivore subjects were recruited by advertisement and none of them had been vegetarian or vegan before the study. Eight vegans had been vegetarians before becoming vegans. All the subjects were naïve about the goal of the study. None of the subjects had any history of neurological, major medical, or psychiatric disorders (including depression), and either alcohol or drug abuse. In addition, none of the subjects was taking any medical treatment at the time of fMRI assessment and all of them had a normal neurological examination. 


### b) Empathy assessment 
  
On the day of fMRI acquisition, subjects were evaluated with the EQ questionnaire  , a self-report questionnaire which has been developed to measure the cognitive and affective aspects of empathy. This questionnaire is widely used in clinical research  ,  , as well as in neuroscience studies  . The EQ comprises 60 questions: 40 questions tapping empathy, and 20 filler/control items. The 20 filler/control items have been included to distract the participant from a relentless focus on empathy. On each empathy item, a person can score 2, 1, or 0, so that the EQ has a maximum score of 80 and a minimum score of 0. To avoid response bias, approximately half of the employed items are worded to produce a “disagree” response and half to produce an “agree” response  . The EQ has a forced choice format, can be self-administered, and is straightforward to score because it does not depend on any interpretation. 


### c) Experimental design 
  
During fMRI, an event-related design was used. A program implemented with the Presentation software (  www.neuro-bs.com  , Version 9.70) presented in a random order a series of 150 pictures: 40 showed negative valence scenes related to humans, 40 negative valence scenes related to animals, and the remaining 70 showed “neutral” natural landscapes. Pictures were pseudo-randomized so that no more than two pictures of the same category were presented consecutively. Negative-valence scenes were taken from the International Affective Picture System  , newspapers, books, or magazines (all images were of high-quality resolution and taken in an electronic format). Scenes had to show the entire figure and not only the face of the subject/animal. Human and animal pictures were comparable in terms of valence and arousal rating. Non-IAPS pictures were validated in a group of 50 healthy subjects that did not participate in the fMRI experiment. To assess the three dimensions of pleasure, arousal, and dominance, the rating procedure by Lang was used  . 

Each trial began with a fixation cross presented in the centre of the screen for 3 sec, followed by the pictures, in a random order, presented for 2 sec followed by black screen. A variable interstimuls interval was used. Subjects were instructed to look at the scenes, without providing any specific response during fMRI acquisition. 


### d) fMRI acquisition 
  
Brain MRI scans were obtained using a 3.0 Tesla scanner (Intera Philips Medical Systems, Best, The Netherlands) with a gradient strength of 40 mT/m. Functional MR images were acquired using a T2*-weighted single-shot echo-planar imaging (EPI) sequence (echo time [TE] = 30 ms, flip angle = 85°, matrix size = 128×128, field of view [FOV] = 240 mm , repetition time [TR] = 3.0 seconds). During each functional scanning run, 151 sets of 40 axial slices, parallel to the AC-PC plane, with a thickness of 3 mm, covering the whole brain were acquired. Shimming was performed for the entire brain using an auto-shim routine, which yielded satisfactory magnetic field homogeneity. Head movements were minimized using foam paddings. 

On the same occasion, a brain dual-echo turbo spin echo sequence (TR = 3500 ms, TE = 24/120 ms; echo train length = 5; flip angle = 150°, 44 contiguous, 3-mm-thick, axial slices with a matrix size = 256×256 and a FOV = 240×240 mm ) was also acquired. 


### f) FMRI analysis 
  
FMRI data were analyzed using the statistical parametric mapping (SPM2) software. Prior to statistical analysis, all images were realigned to the first one to correct for subject motion, spatially normalized into the Montreal Neurological Institute (MNI) space, and smoothed with a 10-mm, 3D-Gaussian FWHM filter. 


### g) Statistical analysis 
  
Event-related paradigms for each condition were modelled on a voxel-by-voxel basis, using the general linear model and the theory of random Gaussian fields  . In each subject, a first-level design matrix was built, where motion parameters were used as regressors of no interest. Then, specific effects were tested by applying appropriate linear contrasts. For each subject, the following contrasts were defined: human negative valence images > neutral, and animal negative valence images > neutral. To test whether between-group differences in processing the neutral conditions might have influenced our results, the contrast assessing activations of neutral images was also defined. Significant hemodynamic changes for each contrast were assessed using t statistical parametric maps (SPMt). Then, a second level random effect analysis was performed to assess the main effects of the stimuli, differences between groups, and interactions between groups and conditions  , using an ANOVA model where groups and conditions were entered as separate factors (2×3 factorial design). To assess between-group similarities and differences in the brain patterns of activations, the following sets of linear comparisons were performed: 1) vegetarians and vegans, separately,   vs.   omnivores; 2) vegetarians and vegans, combined,   vs.   omnivores; 3) vegetarians   vs.   vegans, and vice versa. Common patterns of activations between vegetarians and vegans during a given contrast were identified by a conjunction analysis  . Regions of specific activations of each group contrasted to the other were identified by inclusively masking (uncorrected mask p value = 0.05) the relevant contrast from comparison 1 (e.g., vegetarians   vs.   omnivores) with the appropriate contrast from comparison 3 (e.g., vegetarians   vs.   vegans). 

Intra-group activations were evaluated using a one-sample t test and a paired t test, as appropriate. At this stage, task-related activations and deactivations were estimated. We report activations below a threshold of p<0.05 corrected for multiple comparisons (FWE). Within each region of statistical significance, local maxima of signal increase were determined and their locations expressed in terms of   x  ,   y  , and   z   coordinates into the MNI space. A 3D anatomical atlas was also used to increase confidence in the identification of the anatomical locations of the activated areas  . Using a linear regression analysis, the correlation of fMRI changes during task performance with EQ score was assessed (p<0.001, uncorrected). 

Demographic and behavioral data were compared using the SPSS software and an ANOVA model (version 13.0). 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-9'>
<h2>9. PMID: 22768085</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Neural Network Development in Late Adolescents during Observation of Risk-Taking Action</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2012</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0039527</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study meets all inclusion criteria: it used functional MRI during an action-observation task probing social/emotion-related processing (observation of risk-taking vs. safe actions), enrolled healthy participants aged 18–22 (within 18–60), and reports whole-brain SPM analyses (risk-taking vs. safe, conjunctions, and mediation) rather than ROI-only results. No psychiatric/neurological disorders were included. Therefore it is eligible for the review of fMRI studies of social-related processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Emotional maturity and social awareness are important for adolescents, particularly college students beginning to face the challenges and risks of the adult world. However, there has been relatively little research into personality maturation and psychological development during late adolescence and the neural changes underlying this development. We investigated the correlation between psychological properties (neuroticism, extraversion, anxiety, and depression) and age among late adolescents (  n   = 25, from 18 years and 1 month to 22 years and 8 months). The results revealed that late adolescents became less neurotic, less anxious, less depressive and more extraverted as they aged. Participants then observed video clips depicting hand movements with and without a risk of harm (risk-taking or safe actions) during functional magnetic resonance imaging (fMRI). The results revealed that risk-taking actions elicited significantly stronger activation in the bilateral inferior parietal lobule, temporal visual regions (superior/middle temporal areas), and parieto-occipital visual areas (cuneus, middle occipital gyri, precuneus). We found positive correlations of age and extraversion with neural activation in the insula, middle temporal gyrus, lingual gyrus, and precuneus. We also found a negative correlation of age and anxiety with activation in the angular gyrus, precentral gyrus, and red nucleus/substantia nigra. Moreover, we found that insula activation mediated the relationship between age and extraversion. Overall, our results indicate that late adolescents become less anxious and more extraverted with age, a process involving functional neural changes in brain networks related to social cognition and emotional processing. The possible neural mechanisms of psychological and social maturation during late adolescence are discussed. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (48242 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
 Late adolescence   is a unique and important period for human development. Erikson (1994) examined the concept of   identity   in relation to late adolescence  ,  . Although Erikson considered identity formation to be a life-long process, he emphasized late adolescence as a key stage in his developmental theory, constituting a particular critical development period when a sense of personal and social identity becomes integrated through ‘identity crisis’. Newman and Newman (2007, 2009) redefined Erikson’s criteria regarding developmental stages, dividing adolescence into early and late adolescence, such that late adolescence (18–24) is distinguished from adolescence (12–18)  ,  . Erikson theorized that identity develops when young people are given a psycho-social ‘moratorium’, referring to an opportunity in which they can experiment with different social roles before making permanent commitments to an occupation, to intimate relationships, to social groups and communities, and to a philosophy of life. This ‘moratorium’ period   closely corresponds to ‘college age’; attending college provides students with consciousness-raising experiences to learn about themselves and others through exposure to diverse perspectives, opinions, and ways of living  ,  ,  . Examining psychological changes in college-age late adolescents is valuable in elucidating the ongoing process of human identity integration or maturity  ,  ,  . 

Understanding the late adolescence period is also of particular importance because dynamic psychological changes, such as human identity integration or maturity, continue throughout this period, as social and affective instabilities are overcome. Contrary to a long-held assumption that the brain is largely mature by the end of childhood, recent neuroimaging studies have provided increasing evidence that adolescence involves profound brain growth and change  ,  . For example, increases in white matter volume have been reported throughout childhood and adolescence, particularly in the prefrontal and parietal cortices (e.g.,  ,  ,  ,  ,  ,  ,  . In addition, grey matter volume has been reported to increase in the prefrontal and parietal cortices during the preadolescent stage, followed by a steady decline during late adolescence  ,  . These findings indicate that brain development in adolescence is not linear, and that the brain volume of a typical early adolescent is measurably different to that of a typical late adolescent. In addition, these findings suggest that brain regions involved in planning, decision-making, cognitive reasoning, or controlling impulses and emotions undergo refinement through adolescence at least into a person’s twenties (i.e., late adolescence). 

In addition to the morphometric studies discussed above, behavioral techniques have been used to examine brain development during late and post adolescence. For example, a behavioral study using a mentalizing task requiring theory of mind and executive function reported that social abilities like ‘theory of mind’ continue to improve from adolescence to adulthood  , further suggesting that developmental changes continue throughout the late adolescent phase. Another study using a gambling task reported that the rate of risky choices did not significantly change between early (12–15 y.o.) and mid (15–18 y.o.) adolescence, but was significantly reduced in adulthood (25–35 y.o.)  . These findings indicate that a profound ‘shift’ in cognitive or emotional regulation ability during late adolescence may occur in the transition from adolescence to adulthood. Functional neuroimaging studies of mental-state attribution have reported decreases in frontal cortex activity between adolescence and adulthood  , providing further evidence that a developmental shift occurs during late adolescence, i.e., from adolescence to adulthood. A similar discrepancy between adolescence and adulthood has been observed in the neural correlates of emotional processing. For example, in processing fearful facial expressions, adolescents were found to exhibit a strong reliance on the emotional network in the brain, while adults tended to rely more on an attentional network  . In addition, adults, compared with adolescents, exhibited decreased activity in the hippocampus during the encoding of negative images  . In accord with the studies discussed earlier, this evidence indicates that late adolescence is important as a transitional period from adolescence to adulthood, involving the maturation of emotional regulation and cognitive processing in social situations. 

Several studies have reported the usefulness of a five-factor model that describes five distinct personality traits for parsing personality constructs in late adolescents  ,  ,  . Of the five factors, neuroticism and extraversion are of particular interest, as they are believed to be crucial for the development of healthy social interactions and to exert an over-arching influence on affect and mood. Extraversion is characterized by an increased tendency to be optimistic, and to experience positive emotions and enhanced sociability. Conversely, neuroticism is defined as an increased tendency to worry and to experience psychological distress, accompanied by negative affect and over-sensitivity to negative cues. Functional neuroimaging studies have demonstrated that task-evoked brain activity varies with neuroticism and extraversion scores in the prefrontal cortex and cingulate cortex  ,  ,  ,  ,  . Thus, these two personality traits are strongly associated with emotional experience and may modulate emotion-evoked brain activity  . 

Development of personality traits occurs not only in adulthood, but also in childhood and adolescence  . Neuroticism and extraversion are consistently included in personality models, including 3-factor and 5-factor models  ,  ,  . In addition, the two dimensions seem to be most related to age, educational level, and positive/negative life events from late adolescence to young adulthood  ,  ,  . A longitudinal study of college students reported that an increase in positive life events with age was associated with extraversion, while an increase in negative events was associated with neuroticism  . Another longitudinal study showed that extraversion in high school students predicted their experience of more positive life events over 4 years later in their college- or work-life, while their neuroticism predicted the experience of more negative life events  . These studies highlight the importance of understanding extraversion and neuroticism during late adolescence. 

Moreover, a meta-analysis of 92 longitudinal studies revealed that the largest changes in personality traits occurred between ages 18 and 30, and, specifically, that late adolescents typically become more socially dominant (a facet of extraversion) and less neurotic  . The study indicates that late adolescence is a critical period for the development of personality traits, showing that extraversion and neuroticism are influential for late adolescents in adapting to society as they mature. 

Recently, extraversion and neuroticism were also shown to impact on structural features of the prefrontal cortex in adult and elderly populations  ,  , suggesting that extraversion and neuroticism are related to structural brain development in the earlier stages of life. Low extraversion and high neuroticism are also associated with depression, anxiety  , and phobia  , which are all related to psychological and psychiatric problems frequently occurring in late adolescence  ,  . Neuroticism also predisposes individuals to develop chronic functional pain/pain disorders   and mood disorders  ,  , which are also common problems among late adolescents  ,  . The way in which adolescents become extraverted and less neurotic with regard to the challenging external environment during the late adolescent period is a developmental issue that has not been adequately addressed. Moreover, the neural correlates of this process are currently unclear. 

In a review study examining social and emotional development during late adolescence, depressive and anxiety symptoms were found to be predictive of changes in psychosocial functioning  . For example, rejection sensitivity (the tendency to anxiously expect, readily perceive, and intensely react to rejection) appears to be particularly salient in late adolescence as anxiety or angry expectation  , and was linked to a relative increase in adolescent depressive and anxiety symptoms  . Similarly, social anxiety was predictive of physical/psychological ‘dating aggression’ among late adolescents  . Moreover, healthy adolescents between 12 and 21 years old, who engaged in more extracurricular activities (i.e., participation in organized sports teams, clubs, etc.) and experienced higher quality family relationships, presented with significantly less depressive symptoms  . Since late adolescents face increasingly complex social situations, symptoms of depression and anxiety may be particularly damaging for the development of social competence. 

In the current study, we used functional magnetic resonance imaging (fMRI) to measure neural responses elicited by the observation of actions associated with a certain risk. Moreover, we investigated the influence of developmental differences of psychological properties among late adolescents. We administered psychological questionnaires to measure anxiety, depression, neuroticism, and extraversion, all of which play a crucial developmental role in the establishment of identity during late adolescence. During fMRI scanning, participants viewed hand movements associated with a risk of harm (risk-taking actions) or no risk of harm (safe actions). This task was designed to represent common situations involving potential risks in an everyday environment, providing an index of how late adolescents are likely to cope with potential risks in their social lives in the future. Late adolescence is a challenging period characterized by pervasive social role changes across many domains  ,  . Salient tasks of late adolescence include goals relating to friendship, academic success, and social conduct, giving way to occupational and romantic goals as late adolescents move into young adulthood  . The large number of changes faced in late adolescence make it an unstable time, but also reflects the explorations that take place during the late adolescent years. Many of the changes made by late adolescents are for the purpose of some new period of exploration, in love, work, or education. In accord with this notion, it is possible that a late adolescent’s level of tolerance of risk-taking actions may become entrenched as they are frequently confronted with challenging social situations during late adolescence. Here, we postulated that action observation of risk-taking would be a developmental indicator of motivation to overcome a broad range of difficulties in the world. Although teenagers are generally regarded as engaging in more ‘risky behavior’, such as binge drinking, cigarette smoking, having casual sex partners, violence and other criminal behavior etc  ,  ,  , it should be noted that in this study we do not use the term ‘risk-taking’ to refer to a tendency to such a ‘risky behavior’. Rather, we use ‘risk-taking’ to refer to a more positive concept, whereby adolescents confront and manage the difficulties facing them. 

Although this is an exploratory analysis, we hypothesized that late adolescents will become less anxious, less neurotic, less depressive, and more extraverted as they age, measured by the correlation between age and questionnaire scores, and that neural responses to the observation of risk-taking actions will be modified as adolescents become tolerant of risks in the external environment. Furthermore, we hypothesized that the developmental aspects of their tolerance to the external environment (measured as the correlation between questionnaire scores and age) will be mediated by changes of neural circuitry. These changes may involve the limbic or paralimbic systems (e.g., insula) or brainstem, which are central to the processing of affective information. In addition, the changes may also affect the prefrontal areas, which are important for emotional regulation. Activity in the anterior insula has been found to be associated with empathic maturity during the observation of emotional expressions among children  . This finding supports the notion that the insula is relevant to social functioning in everyday life. 


## Materials and Methods 
  
### Participants 
  
Twenty-five participants in their late adolescence took part in this experiment (12 females and 13 males, from 18 years and 1 month to 22 years and 8 months,   M   ±   SD   years: 20.60±1.09). All participants were undergraduate students and had normal or corrected-to-normal vision. All participants were right-handed (lateralization quotient for the right side of more than 90%) as assessed by the Edinburgh Handedness Inventory  . Written informed consent was given before participation in the study, which was specifically approved by the Institutional Ethical Review Board of the National Center of Neurology and Psychiatry, Japan. All participants were screened to rule out head trauma, the use of medication, history of neurological or psychiatric disorders, and other serious medical conditions. 


### Image Acquisition 
  
Images were acquired using a 1.5 T Magnetom Vision plus MRI scanner (Siemens, Erlangen, Germany). We acquired a unique high-resolution structural image (T1-weigthed anatomical images; 3D MP-RAGE sequence, repetition time; TR  = 11.4 ms, echo time; TE  = 4.4 ms, flip angle  = 15°, 256×256 matrix, slice thickness 1.25 mm) with 144 sagittal slices after the functional runs. Each functional run involved the acquisition functional echo-planar imaging (EPI) volumes (gradient-echo, TR  = 3,000 ms, TE  = 40 ms, field of view; FOV  = 192 mm, flip angle  = 90°, 64×64 matrix, slice thickness 3.5 mm), each with 36 interleaved slices approximately parallel to the anterior commissure-posterior commissure line. Stimuli were displayed on a screen positioned at the rear of the scanner, which the participant could comfortably see through a mirror mounted on the standard head coil. 


### Psychological Measures 
  
Prior to the fMRI session, participants completed the Maudsley Personality Inventory (MPI)  ,  , Spielberger State-Trait Anxiety Inventory (STAI)  ,  , and the Self-rating Depression Scale (SDS)  ,  . The MPI consists of 80 items, each assessing a constellation of traits, also providing a measure of personality along the neuroticism and extraversion scales. The STAI-trait is a self-report instrument of the longstanding quality of trait anxiety. The STAI-trait consists of 20 items, and high total scores indicate more trait anxiety. The SDS was developed as a self-administered measure of depression severity, with higher scores indicating more severe depression. The 20 items of the scale address each of the four most commonly found characteristics of depression: pervasive effects, physiological equivalence, other disturbances, and psychomotor activities. 


### Action Observation Stimuli and Procedure 
  
The action observation experiment involved two types of video clips, ‘risk-taking’ (video of a person’s hand performing an action with clear potential for causing harm to oneself) and ‘safe’ (showing a person’s hand performing an action with no clear danger) ( ). The stimuli are described in detail in  . It should be noted that the video clips were not created to convey the meaning of problematic behaviors among adolescents, such as using drugs or alcohol, driving drunk, smoking, unprotected sex, or other offensive or criminal activities. Rather, the video clips presented participants with situations involving common risks that most people are exposed to in everyday life. Each functional run began and ended with the presentation of a white fixation dot for 9 s. Between these two fixation periods, video clips from the two conditions were presented in alternating 21 s blocks. Each block consisted of a 21 s video clip, and each baseline consisted of a 9 s fixation period. Each block contained videos depicting three different risk-taking actions, or three different safe actions. Half of the blocks showed people performing actions from the right of the screen, and half from the left. Participants completed 10 blocks of each condition during a single scan. The order of presentation of the stimuli was determined according to an optimized random sequence for each block. The brightness of the screen, the intensity of contrast (luminance contrast and texture contrast), the velocity of hand actions, and the representation of objects were equalized for all task/control video clips. The total duration of the risk-taking video clip equaled the duration of the safe video clip (the length of each video clip was 7.0 s). Three functional runs, lasting 10 minutes each, were collected for each participant. The hand movements of participants were monitored by direct visual inspection and video-monitoring from the back of the fMRI tunnel. No visible movements were noted during the presentation of the experimental stimuli. 
   Examples of movies (risk-taking and safe).       Experimental conditions and Visual Analog Scale (VAS) score (100-0) for each condition.        

### Behavioral Measures 
  
After the scanning procedure, each participant was shown the video clips again, and asked to answer specific questions related to them. To test subjective evaluations of the degree of risk, participants were asked to rate their subjective experience of the video clips using a visual analog scale (VAS) (1) from feelings of risk to safety (i.e. to what extent did you feel alarmed while watching the video clip?) and (2) from feelings of anxiety to comfort (i.e. how anxious did you feel while watching the video clip?). 


### fMRI Data Analysis 
  
Image processing was carried out using statistical parametric mapping software (SPM8, the Wellcome Trust Centre for Neuroimaging, London, UK). The functional time series was motion corrected, slice timing corrected and smoothed with a Gaussian kernel of 8 mm full-width at half-maximum. The corresponding high-resolution structural image (the T1 image as the source image) was registered to the first EPI image as the reference image. The co-registered structural image was then transformed into standard anatomical space using the Montreal Neurological Institute structural template (MNI 152). These parameters were used to normalize all functional images. Following preprocessing, ‘Risk-taking’ and ‘Safe’ condition, and motion parameters (six realignment parameters) were entered as regressors. A high-pass filter (hpf) of 128 sec was also applied as regressors. The risk-taking and safe blocks were convolved with a hemodynamic response function without derivatives, and modeled as 21 s boxcar regressors. The 9 s fixation periods were modeled as implicit baseline blocks. Next, a first fixed level of analysis was computed subject-wise using the general linear model. The following T-contrasts were estimated: risk-taking, safe, risk-taking vs. safe, and safe vs. risk-taking. 


### Neural Response to Observation of Risk-taking versus Safe Actions 
  
To test our hypothesis that activation in areas related to action observation would be significantly enhanced when actions involved risk-taking, we compared activation in each condition using linear contrasts (risk-taking versus safe and safe versus risk-taking). The resulting set of voxel values for each contrast constituted a statistical parametric map of the   t   statistic SPM(  t  ). Anatomical localization was performed in MNI coordinates. Talairach coordinates (Talairach Daemon,   www.talairach.org/daemon.html  ) were used for anatomical localization to be compared with Brodmann areas  . Significant activations were defined using a lenient height-threshold of   p  <0.001, uncorrected, and an extent threshold of   k   = 10 (voxels), to reduce the risk of false negatives. Our use of cluster size thresholding combined with uncorrected   p   values was intended to adequately control for the prevalence of false positives  . This threshold suffices to eliminate speculation that effects observed in the primary parametric analysis are an artifact due to non-specific reductions in BOLD signal. 


### Neural Activity Associated with Age and Psychological Measures 
  
This analysis aimed to reveal the brain regions in which activity mediates the age-related change of psychological properties that are essential in individual maturity during late adolescence. In a second-level random-effect analysis, participant’s imaging data were regressed with psychological scores (neuroticism, extraversion, anxiety and depression) and age with a multiple regression analysis. The correlation map of neural responses to risk-taking action (the main SPM(  t  ) contrast of risk-taking vs. safe actions) with age and the correlation map of the same neural response with each of the psychological scores were calculated separately. A conjunction analysis was then performed to show overlapping areas of the two correlational maps: an age-related activation map and a personality-related map. 

Parameter estimates were extracted from the regions surviving the conjunction analyses that tested for statistical mediation using the INDIRECT macro for SPSS (  http://www.afhayes.com/  )  ,  ,  ,  . According to Baron and Kenny (1986), four steps are required to establish that neural activity in a particular region mediates the relation between age and psychological properties: (1) showing that age is associated with psychological properties; (2) showing that age is associated with neural activity in the region; (3) showing that neural activity in the region predicts psychological properties when controlling for age; and (4) showing that the relation between age and psychological properties is reduced when controlling for neural activity in the region. For a sample of 20–80 participants, statisticians recommend the use of bootstrapping methods for testing the statistical significance of mediation (rather than the Sobel test, which is appropriate for larger samples;  ,  . The current study used the bootstrapping approach outlined by Shrout and Bolger (2002), which provides a mean estimate of the indirect effect (i.e., the path through the mediator) and the associated 95% confidence interval. A confidence interval that does not contain zero indicates statistically significant mediation (  p  <0.05). Cook’s distance metric was used to test whether data from a few individuals unduly influenced the strength of the bivariate relationships. A value (age, psychological property, and neural activity) greater than 1 for a data point represents a statistical outlier  . No point had a Cook’s distance greater than 0.5, indicating that none of the correlations were dependent on statistical outliers. 



## Results 
  
### Behavioral Measures 
  
 shows descriptive features of psychological measurements (neuroticism, extraversion, anxiety-trait, and depression scores) and the correlation coefficients between these scores and age. The scores of neuroticism, anxiety, and depression were negatively correlated with age (  r   = −0.49, −0.56, and −0.54, respectively), and extraversion scores were positively correlated with age (  r   = 0.44), suggesting that the late adolescents became less neurotic, less anxious, less depressive, and more extraverted with age. These scores were used for the multiple regression analysis of neural responses, regressed with age and psychological variables. 
   Psychological assessment scores and correlation coefficients with age for each score.        
 shows the scores of subjective ratings using the visual analog scale for each video clip. To test the efficiency of the categorization of the stimuli in terms of risks, the scores of 1) participants’ subjective levels of risk-taking and 2) the extent to which they felt anxious when observing the stimuli were compared between the two within-participant categories (risk-taking and safe actions in video clips). The results indicated that participants experienced significantly stronger feelings of risk-taking and anxiety during the observation of risk-taking compared with safe actions (  F   = 151.16,   p  <0.001, and   F   = 93.73,   p  <0.001, respectively, using repeated-measures ANOVA). To validate the video clip task used in this study, we calculated the correlation coefficients of the subjective ratings of the feeling (“risky” and “anxious”) induced by the actions in the video clips with psychological assessments (correlation coefficients   r   are provided in the  ). The VAS scores of feeling “risky” about Risk-taking actions were positively correlated with anxiety (  r   = 0.41), and negatively correlated with extraversion (  r   = −0.42). VAS scores for feeling “anxiety” about Risk-taking actions were positively correlated with neuroticism and anxiety (  r   = 0.44 and 0.44, respectively), and negatively correlated with extraversion (  r   = −0.40). In contrast, VAS ratings for safe actions were not correlated with any psychological assessment. These results indicate that the video task in this study (the observation of risk-taking action) provides a suitable measure of the psychological factors of interest in this study, and can be used to examine important developmental processes in the late adolescence period. 
   Correlation coefficients between psychological assessments and subjective ratings (“risky” and “anxiety”) about the actions in video clips.        

### Neural Response to Risk-taking versus Safe Actions 
  
We compared the neural activation elicited by observing risk-taking versus safe actions across the whole brain ( ,  ). The results revealed that risk-taking actions elicited significantly stronger activation, mainly in the bilateral middle frontal gyrus (BA9/10), superior frontal gyrus/frontal pole (BA8/10), supramarginal gyrus (BA39/40), inferior parietal lobule (BA40), superior temporal gyri (BA22/39), middle occipital gyri (BA18/19), and cuneus (including the calcarine sulcus) (BA17/18/19) compared with safe actions. Additional areas of significant activation were also found in the left middle temporal gyrus (BA21/22), medial frontal gyri (supplementary motor area) (BA6), superior parietal gyrus/lobule (BA7), precentral gyrus (BA6), posterior cingulate (BA23), fusiform gyrus (BA37), lingual gyrus (BA17), insula (BA13), and declive. In the right hemisphere, we observed significant activation in the precuneus (BA7) and postcentral gyrus (BA2). No regions exhibited greater activation while viewing safe actions compared with risk-taking actions associated with risk. 
   Brain images of neural activity in response to the observation of the object-related hand movement task for risk-taking actions vs. safe actions.  
Statistical threshold for illustrating the clusters was   p  <0.001 uncorrected. The bar on the right shows the range of   t   scores for statistical parametric mapping. Calc. S, calcarine sulcus; FG, fusiform gyrus; FP, frontal pole; MFG, middle frontal gyrus; MTG, middle temporal gyrus; Occ, occipital cortex; SMA, supplementary motor area; SMG, supramarginal gyrus; SPG, superior parietal gyrus. 
  

### Neural Responses Mediating Relationship between Age and Psychological Properties 
  
Finally, we performed a conjunction analysis to reveal common brain activity that correlated both with age and psychological scores (neuroticism, extraversion, anxiety, and depression) ( ). A positive correlation between age and neural response to observation of risk-taking action [  r  ,   p  <.001] and a positive correlation with extraversion [  r  ,   p  <.001] were found to overlap in the insula [BA13,   r   = 0.70,   r   = 0.76], middle temporal gyrus [BA22,   r   = 0.68,   r   = 0.70, ], and precuneus [BA19,   r   = 0.67,   r   = 0.67]. A positive correlation with age [  r  ,   p  <.001] and a negative correlation with anxiety [  r  ,   p  <.001] were found to overlap in the angular gyrus/supramarginal gyrus [BA39,   r   = 0.68,   r   = −0.79, ], precentral gyrus [BA6,   r   = 0.67,   r   = −0.73, ], and red nucleus/substantia nigra [  r   = 0.66,   r   = −0.79]. Parameter estimates were extracted from the regions surviving the conjunction analysis. The parameter estimates were used in a series of analyses testing for statistical mediation. 
   Brain regions mediating association between psychological measurement and age.        
As shown in  , insula activation (BA13) mediated the relation between age and extraversion. This insula activation was positively associated with age and extraversion (age:   β   = 0.44; extraversion controlling for age:   β   = 0.41). The relationship between age and extraversion (  β   = 0.28) was reduced when controlling for activity in the insula (  β   = 0.22). Bootstrapping revealed that the insula significantly mediated the relation between age and extraversion (mean indirect effect  = 5.35, 95% confidence interval ranging from 0.37 to 11.78). The results indicate that, as late adolescents’ age, their neural responses to the observation of risk-taking actions increase in the insula and middle temporal, lingual, and precuneus areas. These changes were related to developmental changes of the participants’ psychological properties, such as increased extraversion. In particular, the insula significantly mediated the relation between age and extraversion. Also, age-related increases of neural activation in the angular gyrus, precentral gyrus, and red nucleus (and substantia nigra) were found to contribute to decreasing anxiety with age. 
   (A) Scatterplots of associations between insula activity (BA13, peak in MNI space: −40 −10 20) and age for the peak of the clusters surviving conjunction analysis with an independent regression of extraversion.  
Left panel: association between age and insula activity (  r   = 0.60,   p  <0.01). Right panel: association between extraversion and insula activity (  r   = 0.61,   p  <0.01). (B) Brain regions that mediated the relationship between age and extraversion. Parameter estimates (risk-taking > safe contrast) extracted at the region identified by conjunction analyses were independently regressed by age and psychological properties. Mediation tests were based on methods described by Shrout and Bolger (2002) and Baron and Kenny (1986). (a) Regression slope of age predicting neural activity; (b) regression slope of neural activity predicting extraversion, controlling for age; (c) regression slope of age predicting extraversion; (c’) regression slope of age predicting extraversion, controlling for neural activity. Bootstrapping was used to estimate indirect effects (Shrout & Bolger, 2002; see also Preacher & Hayes, 2004). A confidence interval that does not overlap with zero indicates statistically significant mediation. *Indicates significant difference from zero,   p  <0.05. Coordinates are given in MNI space. 
  


## Discussion 
  
The primary question motivating the present study was whether late adolescents become more extraverted, less neurotic, and less anxious as they age, and whether such changes might reflect increased tolerance to the challenges of the adult world. In addition, we also sought to test how brain function reflects developmental changes occurring in late adolescent psychology. 

The results revealed several major findings. First, we observed significant correlations between age and scores on psychological parameters that have been hypothesized to play central roles in the development of the late adolescent mind: younger people tended to become more extraverted and less neurotic, less anxious and less depressive with age during late adolescence, even within the small age range in our sample. Levels of neuroticism have been previously reported to decline with age until around age 80  . However, extroversion has also been found to decline with age  . Reports of the correlation of age with depression and anxiety are, however, inconsistent. While some studies have reported no age-related difference on the SDS and STAI among students aged 18–28  , another study reported correlations of anxiety and depression with age in a population with a mean age of 33.0 years  . To date, there has been no study reporting detailed changes of these psychological properties within a small age range in late adolescence. The robust association of age with neuroticism, extraversion, anxiety, and depression in our study indicates that the late adolescent mind undergoes dramatic changes within a short period of time. These changes appear to be unique and distinct from psychological changes that occur across the longer lifespan. Future studies with larger samples will be necessary for elucidating the nature of these dramatic changes in late adolescence. 

Analysis of the “risk vs. safe” contrast revealed neural activation in areas broadly associated with action recognition. These results indicate that observing risk-taking compared with safe actions in our task elicited neural activation in; 1) occipital visual areas including the calcarine sulcus and fusiform gyrus, which are related to lower-level processing of visual information and sending output information to the action recognition network; 2) the bilateral superior and inferior parietal regions, which have been implicated in action recognition and representation  ; 3) the posterior middle temporal gyrus, which is located in the middle of the ventral pathway and serves as a central node in the association of actions and meanings  ; 4) the supramarginal gyrus or inferior parietal area, widely considered to be homologous to the monkey parietal mirror neuron system, which is critical for encoding and recognition of gestures such as object–related postures and movements  ; 5) the posterior cingulate area associated with human awareness, self-reflection  , and memory retrieval  ,   etc. and 6) the frontal pole (superior frontal gyrus), which has been implicated in retrospective monitoring of observed actions that affect one’s future actions  ,  . Therefore the results suggest that the risk content of the observed action in the video clips enhanced the broad spectrum of visually-guided action recognition processing; the network of visual input and its processing appear to encode the meaning of the observed action and even the reflective or retrospective monitoring of the action’s outcomes. As a result, the risk-related content of the action enhanced a broad network associated with action recognition. This finding indicates that risk-taking situations may increase cognitive load in the entire action recognition system, commanding more attention to the actions shown in the video clips. One possible explanation for the result is that risky actions are relatively unusual and involve novelty, which may cause more brain activation. In the present study, however, it is unlikely that factors related to novelty exerted a substantial effect on brain activation, because the situations depicted in the video clips were not unusual. Rather, the videos depicted common situations that often occur in everyday life. In addition, the degree of novelty of the experimental stimuli was controlled using control video clips. Although we did not observe strong activation in affect-related brain areas, another explanation is that the present results reflect some affective impact on brain activation related to risk-taking context. For example, activation in the mirror neuron system while observing action can be enhanced by motivational and affective aspects of the observed action, (e.g.,  ). Thus the action recognition system may be modulated by the affective context of the risk-taking actions of observed actions. 

Alternatively, processing risky actions may require more cognitive resources, involving the estimation and monitoring of possible outcomes of observed actions (see  . This notion is in accord with our current finding that the frontopolar region was more engaged while observing risk-taking compared with safe actions. In addition, a previous study reported that the superior part of the frontal polar area exhibited stronger activation when participants thought about the future compared with when they thought about the past  . Moreover, human lesion studies have indicated that the frontal polar area may be involved in generating insights into one’s future  ,  ,  . On the basis of the current findings, taken together with previous evidence, we hypothesize that risk-taking actions require more cognitive resources to process, involving the estimation of action outcomes resulting in stronger activation in the frontopolar cortex. 

The posterior cingulate cortex (PCC) was also activated by risk-taking vs. safe actions. This region may be another center for risk-related brain activity, which has been suggested by previous animal studies. For example, it has been reported that PCC activation in monkeys is sensitive to risk in decision making tasks  . In addition, the PCC is reported to exhibit activation when monkeys make risky choices, and to become more active with greater perceived risk  . These reports are consistent with the present finding that the observation of risk-taking actions (compared to safe ones) activated the PCC. The PCC is reciprocally connected to parietal areas (action recognition network) and receives feedback input from the prefrontal cortex (see the review in  ), which is involved in estimating the possible outcomes of action. Activation in this area may have exhibited risk-related sensitivity, together with the other regions listed above. 

The main finding in the current study was that neural activation during the observation of risk-taking (compared with safe) actions was correlated with age and some psychological measures, especially, extraversion and anxiety. These results indicate that these psychological properties have important developmental components during late adolescence, and that these developmental changes are represented by brain activation related to the observation of risk-taking actions in the insula and the parietal-temporal-occipital association area (middle temporal gyrus, lingual gyrus, and precuneus). Furthermore, we found that the insula significantly ‘mediated’ the relationship between age and extraversion. 

The insula is a multifunctional cortical region involved in emotional processing  ,  ,  ,  ,  ,  , speech-motor function  ,  ,  ,  ,  ,  , aversive experience  , both physical (i.e. visceral and somatic pain) and emotional (i.e. affect and mood) experience  ,  ,  , conscious awareness (interoceptive awareness)  , and emotional awareness  . The insula also plays a critical role in the processing of risk-taking during decision-making  , suggesting that insula activity may also be modified by the risk-taking context of the observed action in our study. 

The present finding of a correlation between insula activity and extraversion is consistent with the results of a previous positron emission tomography (PET) study   showing that the blood flow of the insula cortex was correlated with extraversion. Introversion (low extraversion) is associated with anxiety through increased limbic activation (in the insular cortex and amygdala), and is affected by genetic factors  . A morphometric study also revealed that extraversion correlated positively with gray matter volume of the insula  . Importantly, a previous fMRI study   revealed that extraversion correlates with neural responses to   positive   word stimuli in the bilateral insula. It is possible that, although the insula response to observing risk-taking actions may reflect an elevated alertness to the risk of harm in the environment, the participants did not experience substantial negative affect, as would be the case if they suffered from severe neuroticism or anxiety/depression. Rather, participants may have been receptive to the new challenges evoked by the task, which could result in the relationship between insula activity and a personality trait relating to a more positive aspect of affect, i.e., extraversion. Although insula activity reflects the processing of arousal or novelty  ,  , this may be accompanied by positive affect to some extent. 

While insula activity is related to extraversion, the insula has also been found to exhibit developmental changes  ,  . A neuroimaging study revealed increased activation in the insula with age in response to a risk-taking task  . Studies of individuals with clinical or developmental disorders consistently show insular morphometric changes, such as gyrification   and reduction of the insular volume in Williams syndrome  , which further suggests developmental changes in the insula. The current finding of an age-related increase in insula activation may also support the notion that the level of affective (particularly positively-valenced) engagement in risk-taking action increases with age in late adolescence. Overall, the current results, which show a link between age and insula activity as well as a link between insula activity and extraversion, suggest that insula activity may ‘mediate’ the development of extraversion. 

Our results also revealed that activity in the posteromedial parietal cortex (including the precuneus) correlated positively with extraversion. Gamma et al., (2000) report a similar positive correlation between extraversion and rCBF in the precuneus, consistent with the current findings  . Extraversion is related to the active seeking of social or interpersonal engagement, and the precuneus is also related to processing social information and estimating interpersonal relationships. For example, the precuneus is activated during ‘forgivability’ judgments in social scenarios   and in the attribution of emotions to the self and others  . Moreover, a number of studies have identified that the precuneus is modulated by agency and intentions in action/movement recognition  ,  , and moral judgments  . The precuneus, in parallel with its social functions, shows age-related changes of brain activity during theory of mind tasks  ,  . The correlation between extraversion and activity in the precuneus, with its age-related changes, suggests that increased precuneus activation may mediate the process of late adolescents becoming increasingly extraverted and exhibiting improved social functioning with age. 

In the current study, as late adolescents aged, activity in the angular gyrus and precentral gyrus increased, and was negatively correlated with anxiety. In a previous fMRI study  , participants were told that an electrodermal stimulation could occur at any time (“threat”) or that no stimulation would occurs (“safe”). The results revealed stronger activity in the “safe” condition than in the “threat” condition in the angular gyrus and precentral gyrus. Thus, these regions may reflect enhanced perceptions of safety, consistent with the current finding of a negative correlation between the activity in these two regions and the level of anxiety. Simmons et al.   also reported reduced activity in the posterior superior temporal cortex adjacent to the angular gyrus in anxiety-prone participants compared with control participants during the observation of aversive images. Moreover, the more repetitively the emotional facial pictures were presented the stronger the neural activity was in the angular/posterior superior temporal gyrus and precentral gyrus, such that the activation in these areas correlated with participants becoming habituated to the emotional stimuli and becoming less anxious  . The precentral gyrus has dense connections with the angular gyrus  , and the angular gyrus and precentral gyrus have been reported to exhibit coactivation during a range of cognitive tasks, including lexical  ,   and calculation tasks  . These findings suggest the existence of a network involving these two areas. Moreover, both the angular gyrus and precentral gyrus are included in the default-mode network (DMN), a prominent large-scale brain network that exhibits strong activity during the resting state and deactivation during cognitively demanding tasks  ,  . We propose that maturation of a network including the angular gyrus and precentral gyrus may play an important role in stabilizing affective states during late adolescence. 

Several limitations of the current study should be considered. First, the sample size was relatively small for studying personality-related factors. This may have reduced the statistical power of our analysis, potentially influencing the results. Additional studies with larger sample sizes and more detailed longitudinal behavioral and cognitive testing focusing on the developmental aspects of personality are required to verify these novel findings. Second, our mediation analysis design, consisting of three variables, may have omitted many other variables that influence both insula response and extraversion in the same direction, potentially resulting in a positive bias in the results. For example, it has been reported that empathic ability is correlated with insula activity  . In addition, some evidence suggests that empathic individuals are more likely to be extraverted  . Moreover, an independent variable can have multiple mediators, which would have been omitted in this design. These potential confounds are likely to affect mediators and dependent variables in the same way. Future studies should take into account other potential mediators. Third, the conjunction analysis shown in Supplementary   may contain false positives, meaning that the results should be corrected for multiple comparisons (e.g. Bonferroni correction). Applying the Bonferroni correction would increase the likelihood of false negatives, however. Since the current study is an exploratory examination, it may be appropriate to consider the statistical significances of conjunction analyses as preliminary values at this point. Additional studies using the Bonferroni correction will be needed to more rigorously test our hypothesis. Fourth, we found a negative correlation of age and anxiety with activation in the red nucleus/substantia nigra, but no significant effect of the main contrast (risk-taking vs. safe; in Supplementary  ). The substantia nigra contains dopamine-containing neurons  ,  . Moreover, the sequence planning and timing-related motor functions in the substantia nigra indicate dopaminergic gating of motor sequences  ,  . Future studies will be required to investigate this issue in more detail. Fifth, as shown in  , multiple correlation analyses were computed between psychological measurements. This may have led to significant effects due to chance in each correlation analysis, such as correlation coefficients between the subjective ratings of the two kinds of video and the four psychological measurements. Adopting a more conservative corrected alpha level, however, would increase the likelihood of false negative results. In the current study, we adopted a thresholding method (  p  <0.001, uncorrected, with 10 contiguous voxels) that was initially proposed more than a decade ago   and has been used in many fMRI studies. A number of alternative methods of correction for multiple comparisons currently exist (e.g.,  ,  ), and the thresholding method in our study is not the only one available. It is important to note that the present correlational analysis constitutes an exploratory finding. Future studies will be required to test whether the current data can be replicated. 

Overall, our findings indicate that late adolescents become less neurotic, less anxious, less depressive, and more extraverted as they age. These changes are associated with activity in brain regions related to social cognition and emotional processing. 


## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-10'>
<h2>10. PMID: 31729105</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Getting into sync: Data‐driven analyses reveal patterns of neural coupling that distinguish among different social exchanges</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Hum Brain Mapp</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1002/hbm.24861</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study used whole‑brain functional MRI (dual‑fMRI hyperscanning) while healthy adult participants (38 individuals; mean age 22.4, within 18–60) completed an interactive social task (cooperative, competitive, and control rounds of the Pattern Game). Analyses were whole‑brain and data‑driven (group ICA and inter‑subject correlation); results reported spatio‑temporal whole‑brain components and comparisons across conditions (not ROI‑restricted). Participants were healthy and not a clinical sample. The paper is original empirical research (not a review/meta‑analysis). Therefore it meets all inclusion criteria (fMRI during social task, healthy adults 18–60, whole‑brain results) and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
In social interactions, each individual's brain drives an action that, in turn, elicits systematic neural responses in their partner that drive a reaction. Consequently, the brain responses of both interactants become temporally contingent upon one another through the actions they generate, and different interaction dynamics will be underpinned by distinct forms of between‐brain coupling. In this study, we investigated this by “performing functional magnetic resonance imaging on two individuals simultaneously (dual‐fMRI) while they competed or cooperated with one another in a turn‐based or concurrent fashion.” To assess whether distinct patterns of neural coupling were associated with these different interactions, we combined two data‐driven, model‐free analytical techniques: group‐independent component analysis and inter‐subject correlation. This revealed four distinct patterns of brain responses that were temporally aligned between interactants: one emerged during co‐operative exchanges and encompassed brain regions involved in social cognitive processing, such as the temporo‐parietal cortex. The other three were associated with competitive exchanges and comprised brain systems implicated in visuo‐motor processing and social decision‐making, including the cerebellum and anterior cingulate cortex. Interestingly, neural coupling was significantly stronger in concurrent relative to turn‐based exchanges. These results demonstrate the utility of data‐driven approaches applied to “dual‐fMRI” data in elucidating the interpersonal neural processes that give rise to the two‐in‐one dynamic characterizing social interaction. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (41944 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## INTRODUCTION 
  
Social interactions unfold as a two‐in‐one dynamic (Koike, Tanabe, & Sadato,  ; Redcay & Schilbach,  ), whereby each individual's behavior is simultaneously an antecedent to and a consequence of their interaction partners' actions. At the level of the brain, this emerges through an indirect chain of interpersonal neural events; one interactant's brain responses initiate an action that, in turn, elicits systematic neural responses in their partner to drive a reaction. In this light, the particular dynamic of an interaction emerges through a reciprocal process of between‐brain contingencies, or “neural coupling” (Hasson & Frith,  ). Elucidating the patterns of neural coupling that underlie different forms of social exchange might therefore provide an interpersonal neural substrate of interactive behavior, but this requires the development of new paradigms and analytical techniques for social neuroscience research (Hasson & Honey,  ; Schilbach et al.,  ; Zaki, Bolger, & Ochsner,  ). In response to this, a new wave of “two‐person” or “in situ” social neuroscience has emerged (Hari, Himberg, Nummenmaa, Hämäläinen, & Parkkonen,  ; Kasai, Fukuda, Yahata, Morita, & Fujii,  ; Redcay & Schilbach,  ; Schilbach et al.,  ), whereby the brains of two or more individuals are measured simultaneously while they interact with one another. Such “hyperscanning” allows researchers to explore how social interactions take shape through real‐time processes of interpersonal neural coupling. 

Hyperscanning has been performed successfully with functional magnetic resonance imaging (fMRI), electroencephalography (EEG), functional near‐infrared spectroscopy, and magnetoencephalography (for reviews, see Babiloni & Astolfi,  ; Scholkmann et al.,  ). With these techniques, studies have revealed various patterns of neural coupling elicited during social interaction; while temporally contingent brain responses are observed between interactants during verbal and non‐verbal communication (Ahn et al.,  ; Bilek et al.,  ; Pérez, Carreiras, & Duñabeitia,  ), between‐brain synchrony or “alignment” (Hasson & Frith,  ) is reported during cooperative and competitive joint‐action tasks (e.g., Cheng, Li, & Hu,  ; Sänger, Müller, & Lindenberger,  ; Shaw et al.,  ; Toppi et al.,  ). Interestingly, brain regions implicated in social cognitive processes feature frequently in patterns of neural coupling across various types of social interaction, presumably reflecting the mutual recruitment of mechanisms that permit the transmission and encoding of social information. Within the temporo‐parietal junction (TPJ), for example, brain responses become synchronized and/or contingent between interactants during economic exchanges (Jahng, Kralik, Hwang, & Jeong,  ; Tang et al.,  ; Zhang, Liu, Pelowski, Jia, & Yu,  ), verbal and non‐verbal communication (Bilek et al.,  ,  ; Kinreich, Djalovski, Kraus, Louzoun, & Feldman,  ; Rojiani, Zhang, Noah, & Hirsch,  ; Wilson, Molnar‐Szakacs, & Iacoboni,  ), and cooperative joint‐action tasks (Abe et al.,  ). This is perhaps unsurprising given the putative role of the TPJ in inferring the intentional and motivational states of others (Bardi, Six, & Brass,  ; Carlson, Koenig, & Harms,  ; Eddy,  ; Frith & Frith,  ), a process that is essential for interacting successfully with others. 

Experimental paradigms employed in hyperscanning studies often confound multiple forms of social exchange, however, making it impossible to identify the discrete patterns of neural coupling associated with different types of interactive behavior. In a theoretical framework proposed by Liu and Pelowski ( ), social interaction is suggested to comprise three distinct dimensions: interaction structure (concurrent or turn‐based actions), goal structure (cooperative or competitive goals), and task structure (tasks achieved independently or interdependently). As such, to advance our understanding of how different patterns of neural coupling give rise to interactive behavior, we must first delineate among these dissociable dimensions (Konvalinka & Roepstorff,  ). Recently, our team adapted for hyperscanning research, an interactive task capable of such delineation, in which pairs of players either co‐operate or compete with one another in a turn‐based or concurrent manner to reconstruct a geometric pattern (Špiláková, Shaw, Czekóová, & Brázdil,  ). Employing this task within a dual‐fMRI hyperscanning study, we revealed brain responses in both interactants that were contingent upon the immediately preceding behavior of their co‐player. Furthermore, these brain responses dissociated among discrete dimensions of the interaction; we observed greater inter‐reactive brain responses during co‐operative exchanges within regions implicated in social cognition, while competitive exchanges elicited stronger brain reactions within neural systems involved in motor planning and updating. This demonstrated the potential for hyperscanning to elucidate patterns of interpersonal brain events underlying different forms of social exchange. 

A number of questions emerged from these results; however, first, in an event‐related design, we applied general linear modeling to identify brain signals in each player that reflected direct reactions to a specific aspect of their co‐player's behavior—namely, the end point of their preceding action. As such, we observed interpersonal brain–  behavior   contingencies rather than brain‐to‐brain coupling. It remains to be seen, then, whether patterns of between‐brain coupling between co‐players on this task also differentiate between dissociable dimensions of social exchange. Second, by modeling brain responses to a discrete, predefined element of the players' behavior, we captured interpersonal brain–behavior relationships during an isolated snapshot of the entire social exchange. This offers limited insight into the interpersonal brain events that unfold dynamically throughout a sustained interaction, through which the nature of the exchange takes shape. 

Data‐driven techniques have been developed to provide an alternative way of analyzing hyperscanning data, offering a means to address these outstanding questions. By evaluating dual‐fMRI data in a model‐free, hypothesis‐free manner, whereby no a priori assumptions are made, these techniques are more appropriate for the non‐linear, unpredictable dynamic of naturalistic social exchange (Nastase, Gazzola, & Keysers,  ). Recently, Bilek et al. ( , 2017) demonstrated how two such data‐driven techniques can be combined to investigate neural coupling during social interaction. With group‐independent component analysis (gICA), one can extract spatio‐temporal patterns of brain responses from a set of continuous recordings acquired from multiple interacting dyads. By assessing the dyad‐specific time‐course along which a given pattern is expressed, it is then possible to identify the common element of all exchanges to which those brain responses are associated; for example, one pattern might represent brain responses elicited during all instantiations of co‐operative interactions, while another relates more closely to competitive exchanges. With a second model‐free analytical technique—inter‐subject correlation (ISC) analysis (Hasson, Nir, Levy, Fuhrmann, & Malach,  )—we can then investigate whether the time‐course of neural signals within these data‐defined patterns of interaction‐specific brain responses are correlated, or aligned, between pairs of interacting individuals throughout a sustained interaction. 

To examine whether dissociable patterns of neural coupling emerged during different forms of social exchange, in the present study, we applied gICA‐informed ISC analysis to dual‐fMRI data acquired from pairs of interactants performing our interactive task. Driven by our previous findings, we expected different patterns of neural alignment to delineate among co‐operative and competitive exchanges. Furthermore, we predicted stronger alignment during concurrent relative to turn‐based exchanges, given that players must monitor and adapt to their co‐players' behavior in real‐time during the former, giving rise to temporally coupled inter‐brain contingences. 


## METHODS 
  
### Participants 
  
The analyses presented below were applied to a subset of the data collected under Špiláková et al. ( ); specifically, 19 pairs of individuals who underwent the exact same dual‐fMRI protocol—a necessary requirement for the analytical procedure. These 38 healthy individuals were recruited from Brno, Czech Republic. The mean age of this sample was 22.44 (  SD   = 1.90) years. Participants were paired into 19 same‐sex dyads (11 male–male) matched on self‐evaluated handedness (34 right handers), age (mean difference = 5.79 [  SD   = 4.29] months) and education (highest qualification). The individuals comprising a pair met for first time at the scanning facility on the day of the experiment and were instructed together about the task and experimental procedure. The study was approved by the Research Ethics Committee of Masaryk University, and all participants gave their informed consent prior to the scanning procedure. Participation was rewarded with 200 CZK (approximately €8). 


### The pattern game 
  
The pattern game is an interactive task developed originally by Decety et al. ( ), which we have adapted recently for hyperscanning research (Špiláková et al.,  ). In this game, two players either cooperate or compete with one another over recursive rounds to recreate patterns made up of blue and yellow tokens. Each player is assigned the color blue or yellow, which identifies them throughout the entire game. Prior to each round, players are shown an instruction that allocates one to the role of Builder and the second to either Helper, Hinderer, or Observer (referred to collectively as Other; e.g., “Blue builds, Yellow helps”). While the task of the Builder is always to recreate the pattern as fast as possible, the characteristics of the patterns mean that they can do so more easily with assistance from the Other. The role assigned to the Other then defined one of three conditions: during   Cooperation   rounds, they work with the Builder to help them reconstruct the pattern; in   Competition   rounds, they must work against the Builder and attempt to hinder them from achieving this. In   Control   rounds, the Other is instructed to simply observe the Builder recreating the pattern. Players alternated between the role of Builder and Other on each round. 

Players made their moves by placing tokens sequentially into specific locations of a playing board. Each round began with one of the players' tokens presented on either side of the monitor above the playing board, and using a four‐button controller they moved it leftward or rightward to a desired columnar location before dropping it into the lowest empty row. On each round, both players could place up to five tokens within a time limit of 25 s. The round ended if (a) the pattern was recreated successfully, (b) both players had placed all of their tokens, or (c) 25 s had elapsed. The experiment consisted of two blocks of 48 pseudorandomized rounds: 16   Cooperative  , 16   Competitive  , and 16   Control  . In the first block, participants took turns to place their tokens sequentially (  Turn‐Based   condition). In the second, players were free to place their tokens simultaneously (  Concurrent   condition). Throughout a round, the Builder's token was always in the lower row, closer to the playing board; as such, if both players attempted to place their token at the same columnar position simultaneously, the Builder's token always dropped to the lowest row with the Other's token positioned above it. Figure   presents an overview of the task, which was programmed in MATLAB (v2018b, The MathWorks, Inc.) using the Cogent 2000 toolbox (developed by the Cogent 2000 team at the FIL and the ICN, and John Romaya at the LON at the Wellcome Department of Imaging Neuroscience; RRID:SCR_015672). 
  
Snapshots of stimuli during the Turn‐based Co‐operation (a) and Competition (b) rounds, and Concurrent Co‐operation (c) and Competition (d) rounds. In all examples, the Builder is assigned to the same color as the target pattern (i.e., yellow in a and d, blue in b and c), and scores by placing tokens in locations that recreate the pattern (indicated by solid red lines). The Other is assigned to the opposing color (blue in a and d, yellow in b and c), and scores by placing their tokens in locations that serve to help or hinder the Builder (dashed red lines); since the latter is achieved by placing tokens within the pattern space, thereby obstructing the Builder, the scoring location of Others and Builders are the same in Competitive rounds (solid red lines) 
  

### MRI data acquisition 
  
Brain imaging was performed using two identical 3T Siemens Prisma scanners located within the same facility, both equipped with a 64‐channel HeadNeck coil. First, we acquired high‐resolution whole‐brain T1‐weightened anatomical images (MPRAGE; TR/TE/TI = 2300/2.33/900 ms; flip angle = 8°; field of view = 252 mm × 224 mm; in‐plane matrix size = 252 × 224; slice thickness = 1 mm; 240 sagittal slices; iPAT GRAPPA accel. factor = 2; phase encoding = A>P; no fat suppression; acquisition time = 317 s). Functional time series were then recorded in two runs, each containing 570 volumes (approximately 20 min) acquired after four dummy scans—the turn‐based block was always followed by the Concurrent block. Blood‐oxygen‐level dependent (BOLD) images were obtained with T2*‐weighted echo planar imaging, with parallel acquisition (i‐PAT GRAPPA accel. factor = 2; 34 axial slices; TR/TE = 2000/35 ms; flip angle = 60°; field of view = 204 mm × 204 mm; in‐plane matrix size = 68 × 68; slice thickness = 4 mm; 34 axial slices; phase encoding = A>P). Axial slices were acquired in interleaved order, each one oriented parallel to a line connecting the base of the cerebellum to the base of orbitofrontal cortex to ensure whole‐brain coverage. A single external programmable signal generator (Siglent SDG1025,   http://www.siglent.com  ) initiated the acquisition sequence of both scanners to ensure maximal synchronization (mean asynchrony in volume acquisition = 1.69 [  SD   = 0.65] ms). Likewise, a single computer was used to present synchronized experimental stimuli to both scanners, and to record the timings of radio frequency pulses. 


### Neuroimaging data analysis 
  
The pre‐processing and analysis of functional and structural brain images was performed using various utilities within FMRIB's software library (Jenkinson et al.,  ; SCR_002823). gICA was performed using the GIFT toolbox for MATLAB (v2.0e;   http://mialab.mrn.org/software/gift  ; Calhoun, Adali, Pearlson & Pekar,  ), and ISC analyses were performed with in‐house scripts written and executed in MATLAB (v2018b, The MathWorks, Inc.). 

#### Pre‐processing 
  
For each pair, we obtained four time series (two for each participant—one acquired during the   Turn‐Based   block, the other during the   Concurrent   block) that were pre‐processed independently in the following manner: First, slice‐timing correction for interleaved slice acquisition was applied to the functional images, and each time‐series was detrended and high‐pass filtered across time (Gaussian‐weighted least‐squares straight‐line fitting; sigma = 50.0 s) and spatially smoothed with a 5‐mm full‐width half‐maximum Gaussian kernel. Motion correction was then performed with MCFLIRT (Jenkinson et al.,  ). To remove any residual motion artifacts, or signal caused by physiological noise (e.g., heart rate and respiration), we performed single‐session Independent Component Analysis with MELODIC (Beckmann & Smith,  ) to identify 50 spatio‐temporal components of the BOLD signal. Artifactual components were identified automatically using the Spatially Organized Component Klassifikator (SOCK; Bhaganagarapu et al.,  ), and any signals corresponding to these problematic components were regressed out of the time‐series using   fsl_regfilt  . Since these artifactual components were orthogonal to the signal removed previously by the high‐pass filter, there was no re‐introduction of noise (Lindquist, Geuter, Wager, & Caffo,  ). In our pre‐processing pipeline, the components returned by MELODIC that were identified as artifactual and subsequently regressed out of the time series (the set of nuisance covariates) were drawn from data that had been high‐pass filtered already. Finally, with FLIRT, the time‐series were registered to a corresponding high‐resolution structural image using Boundary‐based Registration, and this, in turn, was registered linearly to the Montreal Neurological Institute (MNI)‐152 template (12 degrees of freedom). 


#### Group‐independent component analysis 
  
We performed gICA to identify common aggregate spatial maps across the entire samples that are expressed through unique time‐courses for each subject. An alternative approach is to allow for unique spatial maps but common time courses, but this is less appropriate for fMRI data (see Calhoun et al.  ). 

The input consisted of 76 functional brain images (38 participants [19 pairs] × 2 blocks [  Turn‐based   and   Concurrent  ]), each containing 570 volumes. Two data reduction steps were first performed: principle component analysis (PCA) was applied initially to each individual time‐series, resulting in a set of 68 components from each of the 76 time‐series, and subsequently to all the resulting components concatenated into one matrix. The second PCA resulted in a set of 20 spatially orthogonal principal components. The optimal number of components to be extracted from each of these PCAs was determined by computing the minimum description length (MDL). The MDL principle is a formal version of Occam's razor, which determines an appropriate model complexity by extracting the maximum amount of information from the data without overfitting (Sammut & Webb,  ). Next, spatial gICA was performed on these reduced data using the INFOMAX algorithm to identify group‐level components that were independent of one another (Langlois, Chartier, & Gosselin,  ). To ascertain the reliability of these spatial components, gICA was run 20 times and the resulting estimates were compared using ICASSO: each estimated independent component occupies one point in the signal space, and if a component is reliable then each run of the algorithm should produce one point in the signal space that is very close to the “real” component. Thus, reliable independent components correspond to clusters that are small and well separated from the rest of the estimates. In contrast, unreliable components correspond to points which do not belong to any cluster. A cluster quality index,   I  , is then used to evaluate what clusters are the most compact and isolated; this index is computed as the difference between the average intra‐cluster and average extra‐cluster similarities. Eventually,   I   is equal to one for an ideal cluster (Himberg, Hyvärinen, & Esposito,  ). This ICASSO analysis revealed that all 20 components achieved very high cluster quality indices over all iterations (  I   = .97–.98). This part of the gICA pipeline is illustrated schematically in Figure  a. 
  
Group‐Independent Component Analysis (gICA) pipeline. (a) Two data reduction steps were performed on the pre‐processed data: PCA was first applied to each individual time‐series, and then to all the time‐series concatenated into one matrix. Next, gICA was performed on these reduced data using the INFOMAX algorithm, revealing 20 reliable components. (b) After the removal of five artifactual components, the remaining 15 components were back‐reconstructed to the individual input time‐series. Applying multiple regression to the subject‐specific time‐series revealed four components that were expressed along a time‐series aligned with interaction‐specific conditions. Note: Magnifying glasses represent stages of data reduction 
  
After visual inspection of the reliable components emerging from ICASSO, five were identified as artifactual and excluded from further analyses (e.g., components reflecting heartbeat, white matter, and cerebrospinal fluid; see Figure S1). Since the remaining 15 components were extracted from time‐series acquired during cooperative   and   competitive exchanges, and in both turn‐based   and   concurrent interactions, each one could express all dimensions of interaction equally or a specific dimension/combination of dimensions independently. To identify components that reflected brain responses associated with each condition (  Co‐operation, Competition  , and   Control  ), we used the results of the PCA data‐reduction steps to back‐reconstruct each component to the individual input time‐series. This resulted in a time‐course for each component specific to each subject in each block. Multiple regression analysis was then computed: For each participant, the explanatory variables were their subject‐specific back‐reconstructed time‐course for each independent component, and the outcome variable was their unique task design for each condition within each block. This resulted in subject‐specific   β  ‐values for each of the three conditions during the   Concurrent   or   Turn‐based   block (six   β  ‐values for each participant for each component). These   β  ‐values were then compared using paired‐samples   t  ‐tests to identify interaction‐specific components; that is, components for which the back‐reconstructed time‐course for each participant fit their task design of the experimental conditions more than the   Control   condition (  β   > 0 and   β   >   β  ; or   β   > 0 and   β   >   β  ), and showed greater fit for either the   Cooperation   or   Competition   condition. For components to be selected, this had to be true in both concurrent and turn‐based condition. This procedure, illustrated in Figure  b, identified four interaction‐specific components. 


#### Inter‐subject correlation analysis 
  
Next, to calculate the degree of neural alignment in each condition we computed matrices of cross‐correlations between the back‐reconstructed time‐series of interaction‐specific components for each interacting pair, separately for the   Turn‐based   and   Concurrent   block (e.g., correlation between the time‐series of component #1 in the Blue player and component #2 in their Yellow co‐player, in the   Turn‐based   block). For each component, Pearson correlations were applied to the entire back‐reconstructed time‐series from within each block (570 volumes). The resulting correlation coefficients were transformed to   z  ‐values, and the median was used as a coupling coefficient. To determine the significance of the resulting coefficients, we performed a randomization test with 10,000 permutations: in each iteration, we randomly selected 38 non‐interacting pairs (retaining the role of each participant; e.g., component #1 in the Blue player of one pair, and component #2 from the Yellow player of a different pair) and computed a median z‐transformed coefficient as above. This produced a null distribution of correlations among non‐interacting pairs for each interaction‐specific component, against which the significance of coupling between each interacting pair was then compared (see Figure 4a). Pairwise comparisons among the four non‐artifactual, interaction‐specific components revealed significantly higher correlations among interacting compared with non‐interacting pairs after Bonferroni correction (α = .05/4 ). Finally, to assess whether differences existed in the strength of neural coupling between the   Concurrent   and   Turn‐based   interactions, for each interaction‐specific component, we compared the within‐pair correlation coefficients using a Wilcoxon sign‐rank test (e.g., the coefficients calculated for all interacting pairs for Component #1 in the   Turn‐based   block were compared with those calculated for all interacting pairs for Component #1 in the   Concurrent   block). This analysis is illustrated in Figure  . 
  
Inter‐subject correlation (ISC) pipeline. For the seven non‐artifactual interaction‐specific components resulting from gICA, ISCs were computed for interacting pairs and compared with those between non‐interacting individuals. Finally, for each component, the ISCs between interacting pairs were compared between the Turn‐based and Concurrent blocks 
  
While   I   obtained from ICASSO was >0.9 for each cluster (component), to ensure that the individual back‐reconstructed time‐series were stable even with a slight change in the spatial configuration of the component, we ran the gICA and subsequent post‐processing analysis five times with the exactly same parameters. In the following section, we report only the results that were replicated in each of these five iterations. 




## RESULTS 
  
gICA revealed one component that was related more strongly to instances of the   Cooperative   compared with the   Control   rounds (component 10 in Figure S1; referred to herein as Coop#1), while three were associated more strongly with   Competitive   than   Control   rounds (components 13, 14, and 18; referred to herein as Comp#1, Comp#2, and Comp#3, respectively). The spatial pattern of brain regions comprising Coop#1 included bilateral precunei, bilateral clusters centered on the superior temporal sulci (STS) but extending dorsally to the TPJ and ventrally to the fusiform gyri, bilateral dorso‐lateral prefrontal cortices, and the cerebellum. Interestingly, Comp#1 consisted entirely of brain responses localized to the cerebellum. Those encompassed by Comp#2, however, included right precuneus, right superior frontal gyrus extending into prefrontal cortex, right caudate nucleus, right parietal inferior gyrus, and left cerebellum. In Comp#3, the brain responses were present bilaterally in superior frontal gyri, anterior cingulate cortex (ACC), anterior insulae (AI), precunei, the cerebellum, and left precentral gyrus. These results are presented in Figure  a. 
  
Results of gICA‐informed ISC analyses. (a) Spatial maps of four components identified by group‐Independent Component Analysis (gICA), which were expressed in individual brains along time‐series that corresponded to instances of cooperative or competitive interactions. (b) The randomization test revealed that the back‐reconstructed time‐series for each component were correlated significantly more strongly (  p   < .05, Bonferroni corrected) between interacting compared with non‐interacting players. Histograms show the null‐distribution of median correlation coefficients across all non‐interacting pairs—the frequency (y‐axis) with which correlations of different strengths (x‐axis) were identified across all permutations. The red line presents the median correlation coefficient across all interacting pairs. (c) Comparisons between the correlation coefficients (y‐axis) for all interacting pairs between the Concurrent (CN) and Turn‐based (TB) blocks. Note: Components emerging from gICA are overlaid onto the Colin27 template (Holmes et al.,  ) in MNI space 
  
For each of these components, ISC analyses revealed that the back‐reconstructed time‐courses were correlated more strongly between interacting than non‐interacting pairs after (  p   < .05, Bonferroni corrected; see Figure  b). Furthermore, this measure of neural alignment between interacting dyads was significantly stronger during the   Concurrent   relative to the   Turn‐based   block for Coop#1 (mean coupling coefficient: CN = .31 [range = −.05–.51] vs. TB = .14 [range = −.02–.27];   W   = 187,   Z   = 3.70,   p   < .001), Comp#1 (mean CN = .13 [range = −.01–.30] vs. TB = .03 [range = −.07–.15];   W   = 161,   Z   = 2.66,   p   = .008) and Comp#3 (CN = .35 [range = .04–.45] vs. TB = .25 [range = .01–.40];   W   = 176,   Z   = 3.26,   p   = .001). For Comp#2, however, neural coupling did not differ significantly between blocks (CN = .29 [range = .03–.48] vs. TB = .33 [range = −.15–.44];   W   = 54,   Z   = ‐1.65,   p   = .09). These results are illustrated in Figure  c, and detailed further in Table S1. 


## DISCUSSION 
  
To investigate whether different patterns of neural coupling between individuals emerge during dissociable types of interaction, we analyzed dual‐fMRI “hyperscanning” data acquired from dyads engaged in a variety of interactions using a combination of two techniques: a data‐driven gICA and subsequent ISC. This gICA‐informed ISC analysis revealed a distinct spatio‐temporal pattern of brain response that followed a time‐course associated with co‐operative exchanges, and three independent patterns that corresponded more closely to competitive interactions. More importantly, the time‐courses of all these components were correlated significantly between pairs of interactants, and these distinct patterns of interpersonal brain‐to‐brain alignment delineated among concurrent and turn‐based exchanges. These results demonstrate the utility of data‐driven approaches applied to hyperscanning data in elucidating the interpersonal neural processes that give rise to the two‐in‐one dynamic characterizing social interaction. 

Appreciating fully the ability of gICA‐informed ISC analysis to distinguish among different dimensions of interpersonal interactions requires an evaluation of the analytical process: The inputs were time‐series acquired during both cooperative   and   competitive conditions, and in both turn‐based   and   concurrent interactions. As such, components emerging from the gICA could express all interaction dimensions equally, or a specific dimension/combination of dimensions independently. Indeed, multiple regression applied to the back‐reconstructed time‐series revealed that only four of the 15 non‐artifactual components were specific to either cooperation   or   competition. By examining correlations in the time‐series of these patterns across all players—both interacting   and   non‐interacting pairs—we were then able to identify patterns of neural alignment that were both specific to real interactions and distinguished between co‐operative and competitive exchanges performed in a concurrent or turn‐based manner. 

The collection of brain regions expressing interpersonal neural coupling during co‐operative exchanges, Coop#1, encompassed bilateral precunei, STS, TPJ, and the cerebellum. A substantial body of research has shown that the precuneus, STS, and TPJ comprise a network of brain regions co‐activated during experimental tasks requiring the attribution of mental states to others, such as desires, intentions, and beliefs (Bardi et al.,  ; Carlson et al.,  ; Eddy,  ). Based on its engagement during visuo‐spatial mental imagery (e.g., Ghaem et al.,  ; Hanakawa et al.,  ), and both implicit and explicit metalizing (for meta‐analytic reviews, see Schilbach et al.,  ; Wolf, Dziobek, & Heekeren,  ), it is believed that the precuneus is involved in the representation of others' perspectives (Cavanna & Trimble,  ). Similarly, the TPJ responds when individuals are required to infer another person's perspective when it differs from their own (e.g., Dumontheil et al.,  ; Mazzarella et al.,  ); that is, when distinctions must be made between self‐ and other representations (Lamm, Bukowski, & Silani,  ; Uddin, Molnar‐Szakacs, Zaidel, & Iacoboni,  ). 

Since co‐operative interactions require both individuals to act in line with a common goal and in a manner that complements their interaction partner's behavior (Sebanz, Bekkering, & Knoblich,  ), it is perhaps unsurprising to observe neural alignment throughout these brain systems; both individuals must attempt to predict their co‐player's intentions and expectations in order to modify their own actions accordingly (Hampton, Bossaerts, & O'Doherty,  ; Jara‐Ettinger, Baker, & Tenenbaum,  ; Kestemont et al.,  ; Kestemont, Vandekerckhove, Ma, Van Hoeck, & Van Overwalle,  ). Indeed, brain‐to‐brain synchronization within the TPJ and STS has been reported during economic exchanges (Jahng et al.,  ; Tang et al.,  ; Zhang et al.,  ), cooperative joint‐action (Abe et al.,  ), and communicative tasks (Hirsch, Zhang, Noah, & Ono,  ; Kinreich et al.,  ; Rojiani et al.,  ; Wilson et al.,  ). What is surprising, however, is the ability of a data‐driven analysis to identify spatio‐temporal patterns of brain response that delineate among social interactions along the goal dimension, and within which the strength of neural alignment differentiates between exchanges along the interaction dimension. 

The first pattern of neural responses elicited during competitive exchanges, Comp#1, consisted exclusively of the bilateral cerebellum. An expansive corpus of research into the functions of the cerebellum points to its primary role in sensory prediction and the formation of expectations through interactions with the environment (Leggio & Molinari,  ; Nixon,  ). Within this pattern, neural alignment was significantly stronger during concurrent than turn‐based competitive interactions. We suggest this reflects greater inter‐brain contingencies in visuo‐spatial processing mechanisms during real‐time interaction, whereby each player must simultaneously predict and adapt to the behavior of their partner. 

The second spatio‐temporal pattern of brain responses elicited during competitive exchanges that were aligned between interacting players, Comp#2, comprised brain regions localized primarily to the right hemisphere, including lateral prefrontal cortex, caudate nucleus, inferior parietal cortex, and precuneus, but also the left cerebellum. The inferior parietal cortex is considered a higher‐order brain area involved in the visuo‐spatial control of motor behavior (Culham, Cavina‐Pratesi, & Singhal,  ; Gallivan & Culham,  ). Given the abovementioned putative role of the cerebellum in similar motor‐related spatial processing, this pattern of neural alignment might index temporally coupled dependencies in visuo‐motor processes during competitive interactions. Interestingly, the caudate nucleus has been implicated in response switching (Grahn, Parkinson, & Owen,  ), and the concerted engagement of the precuneus and the caudate nucleus has been observed during the planning and generation of strategic moves during competitive interactive games (Wan et al.,  ). Taken together, interpersonal neural coupling within this collection of brain regions might reflect the mutual recruitment of processes involved in the monitoring of a co‐players behavior and subsequent updating of one's own motor actions to allow for flexible co‐adaption during competitive interactions. Importantly, while all spatio‐temporal patterns were relatively unresponsive during the control condition, in which participants simply viewed the actions of their co‐player, within this collection of brain regions we observed no significant differences in the strength of inter‐player neural coupling between concurrent and turn‐based competitive exchanges. This might reveal a pattern of alignment common to both forms of competitive interaction, allowing individuals to plan their next move on the basis of their co‐player's preceding action. 

The third pattern of brain responses expressing neural alignment between players engaged in competitive interactions, Comp#3, encompassed the superior frontal cortices, ACC, AI, precuneus, and cerebellum. This converges with the findings of Wilson et al. ( ), who report ISCs of brain function during verbal communication within the ACC, lateral frontal cortices, and the precuneus. A network of frontal activations incorporating the dorsal ACC and AI constitute the so‐called salience network, which is thought to be responsible for identifying behaviorally relevant stimuli. In a previous study, we observed a similar pattern of neural alignment within the dorsal ACC and AI between players involved in an interactive game of economic exchange; more specifically, inter‐brain alignment in these regions was associated with the degree of reciprocity expressed between players (Shaw et al.,  ). We interpreted this to reflect the mutual effort of players to modify their own behavior according to that of their opponent, a process necessary to compete successfully in an inter‐dependent context. In this light, stronger alignment with a neural saliency‐detection system during concurrent compared with turn‐based competitive exchanges might index a greater effort of both players to process and react dynamically to their opponent's moves; during concurrent exchanges, each player's actions present a continuous flow of salient information to their opponent, demanding more flexible co‐adaptation. 

Interestingly, all but one of these patterns shared a common feature—neural alignment within the precuneus. This brain region is connected reciprocally to many other parts of the brain, and is considered a member of the so‐called “rich club”—a group of neural hubs that are interconnected among themselves (van den Heuvel & Sporns,  ). Our results suggest that the precuneus plays a central role in various forms of inter‐dependent social exchange; it may provide a channel through which social information is transmitted interpersonally and relayed to other brain systems to permit adaptive responses during social interaction. It is also interesting that no pattern. 

These distinct patterns of brain coupling provide unique insights into the interpersonal neural processes that unfold during dissociable forms of social exchange. In three of the components identified by gICA (Coop#1, Comp#2, and Comp#3), ISCs between interacting pairs were strongest during concurrent exchanges. This converges with the results from neuroscientific investigations that have employed dual‐EEG to investigate patterns of between‐brain alignment during unconstrained interpersonal behavior (Dumas, Martinerie, Soussignan, & Nadel,  ; Dumas, Nadel, Soussignan, Martinerie, & Garnero,  ); greater inter‐brain coherence is reported among interactants engaged in self‐initiated, spontaneous interactions compared with exchanges that are guided externally by an experimenter—a distinction paralleling that between turn‐based and concurrent exchanges. Importantly, these results do not simply reflect the degree of similarity in motoric‐ or sensory‐related brain responses: First, inter‐brain covariance was significantly stronger between pairs of interacting co‐players compared with pairs of non‐interacting players selected at random. Second, such interaction‐specific between‐brain covariance was observed in both concurrent and turn‐based exchanges—this index of neural coupling was present even when individuals took turns to observe the actions of their co‐player before making a reactive response, but more so when the players reacted to one another concurrently. Third, we only extracted this index of neural coupling from within spatio‐temporal patterns of brain response that followed a time‐course aligned more with experimental than control rounds. During control rounds, one individual (the Builder) recreated a pattern without any help or hindrance from the Other, while the Other observed the Builder passively. Hence, ISCs were extracted from patterns of brain response elicited during inter‐dependent interactions, whereby the moves of each individual were mutually dependent upon their co‐player's actions. As such, stronger ISCs during concurrent compared with turn‐based exchanges presumably reflects greater interpersonal neural alignment as both players monitor, evaluate, and adapt to the behavior of their co‐player in real‐time. 

It is important to acknowledge that the results of the present study must be reproduced in larger samples before we can evaluate properly the utility of gICA‐informed ISC for hyperscanning research. A more rigorous evaluation of this analytical technique also requires the present results to be reproduced with other interactive paradigms, and with designs that overcome any potential limitations of the current study. For example, dyads in our experiment always performed a block of turn‐based interactions before a block of concurrent exchanges; since the concurrent condition added a level of complexity to turn‐based interactions, our intention was to minimize fatigue and maximize motivation between the first‐ and second‐half of the procedure. In doing so, however, we may have introduced order effects, and so our results require reproduction in other procedures for which such influences cannot exist. 

Future research should also examine whether the interaction‐specific patterns of neural coupling revealed here extend to more real‐world social situations. Hyperscanning permits social neuroscience to be conducted in ecologically valid contexts; Toppi et al. ( ), for example, used dual‐EEG to investigate inter‐brain events among aircraft pilots during flight simulations, revealing patterns of between‐brain coherence that differentiated between various cooperative scenarios. It would be interesting to see whether the same patterns of neural coupling that we have observed with our interactive experimental task delineate among social exchanges with real‐world implications. Studies should also investigate if the patterns of interaction‐specific coupling observed in the present study are modulated by characteristics that have been shown to alter between‐brain events; should they truly reflect the social aspects of interpersonal exchanges; they should be influenced by the sex of interactants (Cheng et al.,  ) and the language used during verbal interaction (Pérez et al.,  ). 


## Supporting information 
  
 ## DATA AVAILABILITY STATEMENT

Data are not shared, but can be made available upon request. </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-11'>
<h2>11. PMID: 22590530</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Regional Brain Responses in Nulliparous Women to Emotional Infant Stimuli</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2012</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0036270</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study meets all inclusion criteria: it used functional MRI while participants (healthy, right-handed nulliparous women aged 19–29) completed social-related tasks (viewing and listening to emotional infant faces and cries), so the task involves social/emotional processing. Participants were healthy adults within the 18–60 range and had no psychiatric or neurological disorders. Analyses report whole-brain results with family-wise error correction and whole-brain correlations (not ROI-only). The study is not a review/meta-analysis and does not include clinical populations. Therefore it is eligible for inclusion in the review of fMRI studies of social-related processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Infant cries and facial expressions influence social interactions and elicit caretaking behaviors from adults. Recent neuroimaging studies suggest that neural responses to infant stimuli involve brain regions that process rewards. However, these studies have yet to investigate individual differences in tendencies to engage or withdraw from motivationally relevant stimuli. To investigate this, we used event-related fMRI to scan 17 nulliparous women. Participants were presented with novel infant cries of two distress levels (low and high) and unknown infant faces of varying affect (happy, sad, and neutral) in a randomized, counter-balanced order. Brain activation was subsequently correlated with scores on the Behavioral Inhibition System/Behavioral Activation System scale. Infant cries activated bilateral superior and middle temporal gyri (STG and MTG) and precentral and postcentral gyri. Activation was greater in bilateral temporal cortices for low- relative to high-distress cries. Happy relative to neutral faces activated the ventral striatum, caudate, ventromedial prefrontal, and orbitofrontal cortices. Sad versus neutral faces activated the precuneus, cuneus, and posterior cingulate cortex, and behavioral activation drive correlated with occipital cortical activations in this contrast. Behavioral inhibition correlated with activation in the right STG for high- and low-distress cries relative to pink noise. Behavioral drive correlated inversely with putamen, caudate, and thalamic activations for the comparison of high-distress cries to pink noise. Reward-responsiveness correlated with activation in the left precentral gyrus during the perception of low-distress cries relative to pink noise. Our findings indicate that infant cry stimuli elicit activations in areas implicated in auditory processing and social cognition. Happy infant faces may be encoded as rewarding, whereas sad faces activate regions associated with empathic processing. Differences in motivational tendencies may modulate neural responses to infant cues. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (35644 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
During early development, pre-linguistic vocalizations, such as cries, and facial expressions are the primary means of infant communication. Both cries and facial expressions from the infant communicate salient information regarding their emotional states and needs and may elicit affection and nurturing from adults  . The interpretation and response to needs underlying infants’ sensory cues may significantly influence the infant’s development  ; thus, the processing of the emotional content of infant stimuli is of developmental significance. 

Utilizing auditory and visual sensory cues, functional magnetic resonance imaging (fMRI) studies have begun to examine mothers’ neural responses to emotional infant stimuli (e.g.,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ). Although auditory stimuli, like cries, may be experienced behaviorally differently than images of infants, considerable overlap is found in neural activation patterns  ,  . Specifically, regions such as the midbrain, hypothalamus, thalamus, basal ganglia, anterior cingulate cortex (ACC), and prefrontal cortex are commonly activated in fMRI studies of parental responses to infant cues, suggesting the involvement of motivation and reward circuitry  ,  . 

As individual differences in motivational tendencies may influence sensitivity to emotional stimuli and/or attachment processes, an exploratory examination of the relationship between brain activation patterns and individual differences in behavioral tendencies may be helpful in characterizing the neural responses to emotional infant stimuli. A prominent theory of behavioral tendencies predicts individual differences to engage or withdraw from emotionally or motivationally relevant stimuli  ,  . In this model, a behavioral activation system (BAS) exists to govern approach behavior toward rewarding stimuli, operating orthogonally to a behavioral inhibition system (BIS) that mediates withdrawal behavior from punishing stimuli. Measures such as the BIS/BAS scale   can be used to assess these tendencies. An improved understanding of how individual differences in behavioral inhibition and activation might relate to neural correlates of infant emotion processing could prove important in identifying features influencing adult-infant interactions. 

In addition to BIS/BAS, evidence suggests that other factors may influence neural responding to infant stimuli. For example, comparisons of different stages in parenting (e.g., two to four weeks postpartum versus three to four months postpartum) have revealed differential patterns of brain activation, suggesting that experience with an infant over the initial months postpartum likely involves significant changes in responsivity to infant cues  ,  . As the experience of parenting may influence responses to infant stimuli, it is necessary to investigate the neural responses to infant stimuli in nulliparous women. Such investigations are important as they will not only inform studies of maternal responses to infant stimuli and help characterize shifts in maternal brain function, but also provide insight into a large group of women with more variable experiences with, and propensities towards, infants. 

Therefore, in the current study, we sought to examine neural responses of nulliparous women to infant cries and faces of varying intensity and valence, respectively. Specifically, we investigated infant cries of differing distress (high, low) levels and infant faces of varying affect (happy, sad, neutral) in nulliparous women using fMRI. We hypothesized that both cry types, relative to a neutral auditory stimulus, would recruit regions previously implicated in response to cries, including the superior temporal gyrus (STG), insula, and cingulate cortices. Moreover, based on the perceived aversiveness of the cries, we predicted that high-distress cries, compared to low-distress cries, would be associated with relatively increased activity in these same regions. With regard to infant facial stimuli, we predicted that happy faces, compared to neutral ones, would activate regions associated with positive emotion and reward processing, including the ventral striatum and orbitofrontal cortex (OFC)  ,  ,  ,  ,  ,  . Sad faces, compared to neutral ones, were hypothesized to activate brain areas implicated in dysphoric and/or empathic responses such as the amygdala and cingulate cortex  . Using a BIS/BAS measure, we predicted that behavioral activation, which reflects responses to stimuli of reward and non-punishment  , would correlate with activations related to rewarding stimuli such as happy infant faces. We further predicted that behavioral inhibition, which is associated with heightened arousal, passive avoidance, and anxiety  , would correlate with regional brain activations related to more aversive stimuli, such as high- and low-distress cries. 


## Methods 
  
### Subjects 
  
Nineteen native-English-speaking, right-handed nulliparous women gave informed written consent and participated in this study approved by the Yale Human Investigation Committee. All research was conducted in accordance with the Declaration of Helsinki. One subject had excessive motion in multiple fMRI runs and was excluded from analyses; another subject completed only four of seven functional runs and was also excluded. The remaining 17 subjects were between the ages of 19 and 29 (M = 22.7, SD = 2.9) years and were in good health with no history of psychiatric or neurological disorders, and had normal or corrected-to-normal vision. Racial and ethnic composition consisted of ten Caucasian, two Asian-American, two African-American, one Pacific-Islander, and two Hispanic women. 

All subjects completed the BIS/BAS scale  , a 24-item valid and reliable self-report questionnaire rated on a 4-point scale (strong agreement to strong disagreement) measuring behaviorally aversive (i.e., behavioral inhibition) and appetitive (i.e., behavioral activation) motivations. The BIS/BAS factors into four subscales, with one factor assessing inhibition (BIS) and three factors assessing activation. The three BAS subscales assess the pursuit of appetitive goals (BAS drive), tendency to seek rewarding experiences (BAS fun-seeking), and responsiveness to reward (BAS reward-responsiveness). 


### Auditory Stimuli – Infant Cries 
  
Cry stimuli were generated from stimuli described previously  . Cries were elicited from infants between the ages of 27 and 32 days who were without serious illness at birth and during their one-month checkup. Cries were recorded in the infants’ homes before the infants were fed and required no additional external stimulation. Detailed information about the recording procedure is reported elsewhere  . We used four two-second segments generated by two infants. The cries were categorized as either high- or low-distress, resulting in both a high- and low-distress exemplar from both infants. We used two exemplars for each level of distress to avoid measuring differences associated with the physical properties of one particular cry. Prior to imaging, the distress level of the cries was verified by an independent group of ten nulliparous female participants (ages 19 to 24 years) who rated the cries on a scale of 1 (calm) to 10 (distressed). High-distress cries were rated as significantly more distressed (M = 8.06, SD = 1.3) than low-distress cries (M = 3.54, SD = .82) (  t   = 11.52,   p  <.0001). 

In addition to cries, subjects heard a “neutral” auditory stimulus, which consisted of a two-second segment of 1/f, or “pink” noise. Pink noise has a frequency of 1/f, indicating that the power spectral density is inversely proportional to the frequency. Pink noise was used as a neutral stimulus because it is not produced by a human and, as compared to white noise, is considered more naturalistic as it occurs in natural systems, speech, and music  . Additional information on the acoustic properties of the cries and neutral stimulus has been previously reported  . 


### Visual Stimuli 
  
Photographs of infant faces between the ages of five and ten months were adapted from Strathearn and McClure   and were previously used by our group  . Twenty-one images from each of the six infants, resulting in a total of 126 images, were balanced for both gender and race (Caucasian and African American). The infant-face images displayed happy, neutral, and sad affective states. The size, luminance, and contrast for all face stimuli were standardized, and faces were presented on a black background. Prior to imaging, face stimuli were rated by an independent group of 11 participants on a scale of 1 (happy) to 10 (distressed) to assess the perceived affect level. A repeated measures ANOVA of the infant-face ratings on the three emotions (happy, neutral, sad) was significant (  F  (2, 20) = 146.43,   p  <.001). Pairwise comparisons showed that happy faces (M = 2.19, SD = 0.75) were rated as significantly less distressed (Mean difference = −1.55, SD = 1.15,   p   = .006) than neutral faces (M = 3.74, SD = 1.43). Neutral faces were rated as significantly less distressed (Mean difference = −4.16, SD = 1.28,   p  <.001) than sad faces (M = 7.90, SD = 0.34). 


### Design 
  
Stimuli were presented using E-Prime software (Version 1.2; Psychology Software Tools Inc., Pittsburgh, PA). The auditory stimuli were delivered via headphones with no visual display. The visual stimuli were displayed foveally at the fixation point for 1000 ms and followed by a fixation cross. Subjects received seven functional runs, each consisting of 42 trials (six trials of each condition of interest and six one-back memory trials). The conditions of interest were high-distress cry, low-distress cry, pink noise, happy face, sad face, and neutral face. Trials of all conditions were presented in a counter-balanced succession. The duration of the inter-trial-interval (ITI) was jittered (4000–14000 ms) to allow event-related analysis and to minimize stimulus expectation. 

During each run, subjects were asked to attend to the stimulus sequence of faces and cries. A one-back memory task was included to maintain and assess subjects’ attention during the task and were modeled but not included in further analyses. On a small proportion of trials (14%), subjects were presented with a row of question marks and either a visual stimulus (infant face) was presented above the question marks or an auditory stimulus (cry or pink noise) was delivered via the headphones. The question marks cued the subject to make a yes/no decision via a stimulus response box as to whether the current stimulus was identical to the stimulus of the preceding trial (i.e., a one-back memory task). Analysis of catch trial data revealed a mean accuracy rate of 91.27±0.05% (mean ± SD). 


### Data Acquisition 
  
Data were acquired with a Siemens Trio 3T magnetic resonance imaging system (Siemens AG, Erlangen, Germany) using a standard 12-channel head coil. Localizer images were acquired for prescribing the functional image volumes, aligning the eighth slice parallel to the plane transecting the anterior and posterior commissures. Functional images were collected using a gradient echo, echoplanar sequence (repetition time [TR] = 2000 ms; echo time [TE] = 30 ms; flip angle [FA] = 80°, field of view [FOV] 20 cm×20 cm, 64×64 matrix, 3.4 mm 3.4 mm in-plane resolution, 4 mm slice thickness, 32 slices). Each stimulus run consisted of 163 volumes, including an initial rest period of 12 seconds (to achieve signal stability) that was removed from analyses. High-resolution structural images were also collected (sagittal MPRAGE acquisition, TR = 2530 ms; TE = 3.66 ms; FA = 7°; FOV = 25.6 cm×25.6 cm; number of excitations [NEX] = 256×256×1; 1 mm slice thickness, no gap; 176 slices). 


### Image Analysis 
  
Following prior published protocols  , functional data were preprocessed using SPM5 (Wellcome Functional Imaging Laboratory, London, United Kingdom). Preprocessing included slice-time correction to the first slice of each volume; SPM5’s two-pass realign-to-mean strategy, which ultimately realigns all functional images to a mean functional image; coregistration of the anatomical image and the average of these realigned functional images; coregistration of all functional images using the parameters obtained from coregistration of the mean image; application of the SPM Unified Segmentation process to the anatomical scan, using prior information from the International Consortium for Brain Mapping (ICBM) Tissue Probabilistic Atlas and estimation of non-linear warping parameters  ; warping the functional images to the Montreal Neurological Institute (MNI) template space; reslicing into isometric 3 mm×3 mm×3 mm voxels; and subsequent smoothing of functional images using a 6 mm Gaussian kernel. All functional runs were inspected for motion in excess of one voxel, for which one participant was excluded from the analysis. 

Once the functional images were preprocessed, first-level robust regression was performed using the standard general linear model but with iteratively reweighted least squares using the bisquare weighting function for robustness  ,  , as implemented in MATLAB 7.3 (Mathworks, Natick, MA; robust.m). Motion parameters and high-pass filter parameters were added as additional regressors of no interest. Once conditions were estimated using percent signal change for each participant, a second-level, random effects analysis was performed to estimate contrasts between conditions using NeuroElf (NeuroElf.net) and following our prior methods. To correct for multiple comparisons we then used a Monte Carlo simulation, which takes into account the voxel-wise and cluster-volume thresholds to establish family-wise error (FWE) correction. Only regions with corrected   p  <.05 (i.e., α<.05) threshold at an uncorrected voxel-level threshold of   p  <.01 at each tail and a cluster of 45 were considered to be significantly activated or deactivated in the whole-brain analysis. Whole-brain correlations were computed to assess the relationship between brain activation and behavioral inhibition and activation as assessed by the BIS/BAS. To adequately correct for the multiple comparisons conducted in the correlation analysis with multiple measures, we employed a conservative Bonferroni correction to both height and whole-brain level thresholds across 24 exploratory correlations. Clusters were considered significant at a FWE corrected   p  <.05 threshold and subsequently Bonferroni-corrected with a corrected   p  <.002 threshold (at an uncorrected voxel-level threshold of   p  <.0005 at each tail and a cluster of 17). Anatomical labels of all results were confirmed using the Talairach Daemon toolbox as well as manually, using a human brain atlas  . 



## Results 
  
### Brain Activations to Infant Cries 
  
When comparing low-distress cries to pink noise, increased activation was observed in bilateral STG, right middle temporal gyrus (MTG), bilateral precentral and postcentral gyri, right inferior parietal lobe (IPL), left superior and medial frontal gyri (SFG and MFG), left putamen and left claustrum. Relatively diminished activation was observed in left caudate and right MFG/OFC. When comparing high-distress cries to pink noise, increased activation was observed in bilateral STG, right MTG, right precentral and postcentral gyri, right SFG, right MFG, right inferior frontal gyrus (IFG), bilateral amygdala, and left culmen. Relatively diminished activation was observed in the right STG and right insula. When comparing high-distress cries to low-distress cries, diminished activation was observed in bilateral STG, right MTG, left IPL, right superior occipital gyrus, and left precuneus; no regions showed increased activation ( ;  ). 
   Regional Brain Activations during the Perception of Infant Cries.           Regional Brain Activations during the Perception of Infant Cries.  
Axial slices of regional brain activations for a) low-distress cries versus pink noise, b) high-distress cries versus pink noise, c) and high-distress cries versus low-distress cries. Color on T1 template images from SPM5 indicates significant increases (red color) and decreases (blue color) in BOLD signal. The right side of the brain is on the right. The number under each brain image indicates z-axis coordinates of the image in the MNI (Montreal Neurological Institute) template space. The only voxels displayed on the brain images are regions with corrected p<.05 threshold at an uncorrected voxel-level threshold of p<.01 at each tail and a cluster of 45. 
  

### Brain Activations to Infant Faces 
  
For happy versus neutral infant faces, greater activation was observed in left ventral striatum, left caudate head, left ventromedial prefrontal cortex (vmPFC)/OFC, and right IFG. Relatively diminished activation was observed in left cingulate gyrus, bilateral precentral gyrus, right SFG, right STG, left supramarginal gyrus, and left insula. For sad versus neutral infant faces, greater activation was observed in bilateral precuneus, left cingulate gyrus, right MTG, bilateral middle and inferior occipital gyri, right fusiform gyrus (FG), left precentral gyrus, left IPL, left lingual gyrus, right SFG, bilateral MFG, right IFG/OFC, and left ACC. Relatively reduced activation was observed in the left insula, left transverse temporal gyrus, and right STG. For happy versus sad faces, relatively greater activation during the presentation of sad faces was observed in the right IFG, bilateral FG, right STG, right supramarginal gyrus, right cuneus, left MTG, left middle occipital gyrus, right precentral gyrus, and right MFG; no regions demonstrated greater activation for the presentation of happy faces relative to sad faces ( ;  ). 
   Regional Brain Activations during the Perception of Infant Faces.           Regional Brain Activations during the Perception of Infant Faces.  
Axial slices of regional brain activations for a) happy versus neutral infant faces and b) sad versus neutral infant faces. Color on T1 template images from SPM5 indicates significant increases (red color) and decreases (blue color) in BOLD signal. The right side of the brain is on the right. The number under each brain image indicates z-axis coordinates of the image in the MNI (Montreal Neurological Institute) template space. The only voxels displayed on the brain images are regions with corrected p<.05 threshold at an uncorrected voxel-level threshold of p<.01 at each tail and a cluster of 45. 
  

### BIS/BAS Scores and Correlations with Brain Activity 
  
The mean ± SD scores of the 17 subjects on the BIS/BAS scale components were 22.12±2.76 for the BIS, 10.76±2.22 for BAS drive, 11.29±1.93 for BAS fun seeking, and 17.35±1.54 for BAS reward-responsiveness. These scores fall within the standard mean score range for healthy subjects  . 

The scores on the BIS and two BAS subscales (drive and reward-responsiveness) were correlated with brain activation contrasts. BIS scores positively correlated with right STG activity in both the comparisons of high-distress cries versus pink noise and low-distress cry versus pink noise. The BAS drive subscale scores inversely correlated with activations in the: 1) right putamen, right caudate extending into the thalamus, right lateral globus pallidus, and left medial globus pallidus in the contrast between high-distress cries and pink noise; and 2) left angular gyrus in the contrast between high-distress cries and low-distress cries. The BAS drive subscale scores positively correlated with right superior occipital gyrus in the contrast between sad and neutral faces. BAS reward-responsiveness scores inversely correlated with left precentral gyral activation in the contrast between low-distress cries and pink noise ( ;  ). 
   Regional Brain Activations during the Perception of Infant Cries and Faces Correlated with Behavioral Measures of Motivation as Assessed by BIS/BAS Subscales.           Regional Brain Activations during the Perception of Infant Cries and Faces Correlated with Behavioral Measures of Motivation as Assessed by BIS/BAS Subscales.  
a) Axial slice of regional brain response for low-distress cry versus pink noise that correlates with scores on the BIS scale. b) Axial slice of regional brain response for high-distress cry versus pink noise that correlates with scores on the BIS scale. c) Axial slice of regional brain response for high-distress cry versus pink noise that correlates with scores on the BAS drive scale d) Axial slice of regional brain response for sad versus neutral infant faces that correlates with scores on the BAS drive scale. e) Axial slice of regional brain response for low-distress cry versus pink noise that correlates with scores on the BAS reward-responsiveness scale. Color on T1 template images from SPM5 indicates significant increases (red color) and decreases (blue color) in BOLD signal. The right side of the brain is on the right. The number under each brain image indicates z-axis coordinates of the image in the MNI (Montreal Neurological Institute) template space. The only voxels displayed on the brain images are regions with corrected p<.002 threshold at an uncorrected voxel-level threshold of p<.0005 at each tail and a cluster of 17. 
  


## Discussion 
  
The current study used fMRI to examine the neural correlates of how nulliparous women respond to emotional infant stimuli, specifically cries of varying distress levels and facial expressions of varying affect. Overall, regions activated in response to cries in nulliparous women (e.g., the STG and MTG) are consistent with those identified in cry processing in previous studies of both non-parents and parents  ,  ,  . For the face stimuli, we observed different regional brain activations in response to sad and happy infant faces. Regions such as the vmPFC, OFC, and ACC, which are commonly activated in fMRI studies of parental responses to infant cues, demonstrated activation during the presentation of infant faces  ,  . Furthermore, neural responses to the cry and face contrasts correlated with self-reported measures of behavioral inhibition and activation suggesting that neural responses to infant stimuli vary as a function of motivational approach and avoidance tendencies. 

### Regional Brain Activations during the Perception of Low- and High-Distress Cries Relative to the Control Stimulus 
  
We found increased activation to low-distress cries relative to the control stimulus in bilateral STG, right MTG, right IPL, and bilateral precentral and postcentral gyri. Similarly, high-distress cries relative to pink noise identified increased activation in bilateral STG, right MTG, and bilateral precentral and postcentral gyri. Findings in STG and frontal cortices are common in fMRI paradigms utilizing infant cry stimuli and may reflect auditory processing and social cognition  ,  . Several fMRI studies have linked activations of STG and IPL to representations of others’ intentions and mental states  ,  . Thus, activation in these areas during the perception of cries may reflect an attempt to understand the emotional states associated with cries of varying distress levels. The STG has also demonstrated increased activity in response to angry speech relative to neutral speech  ,  . Therefore, activation in STG may reflect the aversive nature of the cries. 


### Regional Brain Activations during the Perception of Low- Relative to High-Distress Cries 
  
Nulliparous women demonstrated greater activation for low-distress relative to high-distress cries in bilateral STG, right MTG and left IPL. Increased activation in auditory-processing regions for low- relative to high-distress cries may reflect the greater acoustic variability in the low-distress cries. Specifically, low-distress cries tend to have more numerous shorter bouts whereas high-distress cries tend to have fewer bouts and fewer breaths (see Appendix for cry characteristics). Accordingly, low-distress cries might be considered more complex and may generate relatively increased STG and MTG activation. From a behavioral perspective, high-distress cries may produce more unequivocal responses in adults (e.g., “The infant is clearly distressed and needs immediate attention.”), whereas low-distress cries may produce more complex, and potentially ambiguous, behavioral responses as the adult attempts to understand the cries’ meanings (e.g., “How greatly distressed is the infant? Will the cries cease without my attention?”). The potentially equivocal nature of these responses may relate to the observed increased insular activation, which has been associated with decision-making processes and empathy  ,  . Additionally, the greater recruitment of brain regions during low-distress cries relative to high-distress cries may stem from differential previous experiences of the nulliparous women with infants, which was not assessed in this study. Further research on the relationship between specific acoustic properties of cries and the neural and emotional responses they generate is necessary for understanding the differential responses to cries of varying properties. 


### Regional Brain Activations during Viewing of Happy Faces 
  
Consistent with our hypothesis and findings from previous studies involving the processing of infant visual stimuli  ,  ,  ,  , viewing of happy infant faces compared to neutral ones engaged the OFC. The OFC contributes importantly to maternal “reward” circuitry  ,  , and increased activation in this region may reflect the rewarding nature of a happy infant face, which may help elicit care-giving behaviors. Considered a component of the brain’s “reward system,” the OFC receives ascending dopamine projections from the ventral tegmental area (VTA)  ,  . Studies with pleasant visual, tactile, and olfactory stimuli have found increased activation in the OFC that depends on the pleasantness rather than the intensity of stimulation  ,  . The OFC is therefore considered to have a critical role in representing the reward value of a stimulus. Greater activation for happy faces was also seen in the striatum, a structure receiving projections from the VTA and OFC   and implicated in reward-related learning and motivated behaviors  ,  ,  . The increased striatal activation in nulliparous women may relate to the coding of happy infant affect as a positive sensory cue. 


### Regional Brain Activations during Viewing of Sad Faces 
  
For the sad versus neutral face contrast, activation was observed in the precuneus, cuneus, and left posterior cingulate cortex (PCC). Both the precuneus and PCC have been implicated in the processing of sad adult faces   and show greater activation when adults evaluate their own or other’s emotional states  . A longitudinal neuroimaging study of depressed patients found differential brain activations according to depression status  , suggesting that areas involved in the discernment of negative affective facial expressions may relate to dysphoric response patterns. The PCC has also been implicated in stress responses  , suggesting that stress neurocircuitry may be activated by sad faces. Alternatively, the activation of the precuneus and PCC may indicate that nulliparous women engage in the attribution of emotion while viewing sad infant visual stimuli, as the PCC has been associated with evaluating the affective valence of external stimuli  , and the precuneus has been implicated in empathic processes  . 

Sad faces also activated the ACC, a region involved in the processing of emotional information  . Data implicate the ACC in attending to, and regulating, arousal associated with affective states  , as increased blood flow has been reported in dorsal and rostral regions of the ACC when attending to subjective emotional states and experiences  ,  . Regions along the border between the rostral ACC and the mPFC have been associated with theory of mind tasks, such as the ability to infer mental states of others  . The increased activation in ACC therefore suggests that the nulliparous women in this study may have engaged in social and emotive processing while viewing the sad infant facial stimuli. 


### Regional Brain Activations during Viewing of Sad-Relative-to-Happy Faces 
  
For the comparison of sad versus happy faces, the right IFG, bilateral FG, and right cuneus demonstrated increased activity. Both the IFG and FG have been widely implicated within circuitry involved in the processing of adult emotional faces and are considered as “core” regions of emotional face processing  ,  . The FG has been implicated in the processing of facial stimuli  , including in learning affective values of faces  , with greater FG activation observed to faces of negative affect  . The precuneus has also been implicated in the processing of adult emotional faces, particularly in response to sad faces  . Precuneus response to emotional faces appears influenced by individual genetic variation   suggesting the value of face perception investigations of individual differences. Together, the findings suggest that the neural underpinnings of infant emotional face processing share similarities with those underlying adult emotional face processing and that that individual differences are important to consider in the processing of facial stimuli. 


### Regional Brain Activations and Individual Differences in Behavioral Inhibition and Activation 
  
Our findings suggest that individual differences in motivational tendencies may influence neural correlates underlying the processing of infant emotional cues. Specifically, higher self-reported behavioral inhibition was related to greater activation in right STG during the perception of low-distress cries relative to pink noise, as well as high-distress cries relative to pink noise. The BIS measure assesses responsiveness to signals of negative outcomes, particularly tendencies to inhibit behavior that may result in undesirable consequences (e.g., “If I think something unpleasant is going to happen, I usually get pretty worked up.”). The recruitment of right STG during the perception of low- and high-distress cries preferentially in women with high BIS scores may therefore relate to the aversive nature of cries, with individuals more prone to behavioral inhibition demonstrating a greater STG response. 

Higher self-reported behavioral drive was associated with greater activation in the right superior occipital gyrus when viewing sad versus neutral faces. The occipital cortex, including the superior occipital gyrus, has been linked to affective processing, with occipital cortical activity correlating with poor social adjustment and impaired social cognition in individuals with psychotic disorders  . Thus, the current findings relating behavioral drive to superior occipital gyral activation during viewing of sad faces not only implicates a region implicated in social processing in a population often characterized by poor motivation drive and interpersonal difficulties, but also suggests that early visual processing may be particularly relevant to responses to sad infant facial cues in behaviorally driven individuals. 

In the current study, individuals with higher reward-responsiveness showed lower activity in the left precentral gyrus when listening to low-distress cries compared to pink noise. The precentral gyrus, involved in motoric responding, has been implicated in the processing of rewarding and aversive stimuli. For example, healthy subjects as compared to individuals with borderline personality disorder, a condition characterized by emotional dysregulation, showed greater recruitment of the precentral gyrus during responses to aversive as compared to neutral stimuli  . Healthy women but not those with bulimia nervosa showed increased activation of the precentral gyrus in anticipation and receipt of a milkshake reward  . Thus, these findings suggest that individual differences in precentral gyral activations to aversive and rewarding cues may have important clinical implications. The current findings suggest that individual differences in both approach and avoidance motivational tendencies are related to neural activations involved in attentional and emotional processing. The extent to which these behavioral and neural measures relate to specific aspects of adult-infant interactions requires additional investigation. 


### Limitations, Strengths, and Future Directions 
  
Several limitations exist. First, the facial stimuli were derived solely from infants. Future investigations involving facial stimuli from individuals of varying ages may be helpful in elucidating how brain responses may be modulated by the physical maturity of facial features being viewed. Furthermore, the cries were gathered solely from newborn infants, limiting the possibility of having a comparable happy auditory condition such as laughter. Additionally, the age difference of the infants used for the cry and face stimuli makes comparisons between the two sensory domains difficult. However, we did find increased activation in precuneus, right MTG, left precentral gyrus, and left IPL for sad faces relative to neutral ones, as well as for cries relative to pink noise. Future fMRI investigations are needed to continue identifying regions activated across these sensory modalities. Second, the subjects in the study were healthy nulliparous women of childbearing age. Information regarding subjects’ desire and plans to be in a caretaker role, as well as the degree of their present interaction with infants, may help to further account for individual differences in the processing of infant stimuli. Additionally, studies of childbearing women could examine how neural responses to infant affective cues may change in healthy mothers at varying times postpartum. Third, the study excluded men. Examination of similarly aged men and parents of both sexes could investigate potential influences of sex and parenthood, respectively. Fourth, the study involved healthy subjects. Future studies of mothers and nulliparous women in whom parent-child interactions may become impaired, such as during maternal depression and substance abuse, could help investigate processes of particular relevance to the health of vulnerable youth. Despite these limitations, the findings provide initial insight into the neural processing of infant cues in nulliparous women and how individual differences in motivational tendencies relate to brain responses to infant stimuli. 

In summary, the current study provides an initial examination of how emotional infant stimuli are perceived by healthy, nulliparous women. Cries of varying distress levels differentially recruited regions associated with auditory and empathic processing. With regard to the visual infant stimuli, our findings suggest that happy faces are encoded as rewarding stimuli in the brain, whereas sad faces induce increased activation in regions associated with empathic processing. The study is also the first to investigate appetitive and aversive motivational tendencies in relationship to the processing of infant emotional cues, and the findings suggest a relationship between individual differences in motivational tendencies and brain response patterns to infant cues. These findings also indicate the utility of this approach to investigate a broader range of individual differences with respect to neural activations and their clinical correlates in response to infant stimuli. 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-12'>
<h2>12. PMID: 30615116</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> I See Your Effort: Force-Related BOLD Effects in an Extended Action Execution–Observation Network Involving the Cerebellum</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Cereb Cortex</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1093/cercor/bhy322</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is a task-based fMRI study that examines action observation (watching another person exert force) and action execution, addressing social-related processing (understanding others’ actions/effort). Participants were healthy adults (final N=12; mean age 26±3.5), within the 18–60 inclusion age range. The study reports whole-brain voxel-wise analyses (SPM12 whole-brain GLM) and cerebellum-focused SUIT analyses, with cluster-level correction — not restricted to ROI-only results. It is an original empirical fMRI study (not a review/meta-analysis) and does not involve psychiatric or neurological patient groups. Therefore it meets all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Action observation (AO) is crucial for motor planning, imitation learning, and social interaction, but it is not clear whether and how an action execution–observation network (AEON) processes the effort of others engaged in performing actions. In this functional magnetic resonance imaging (fMRI) study, we used a “squeeze ball” task involving different grip forces to investigate whether AEON activation showed similar patterns when executing the task or observing others performing it. Both in action execution, AE (subjects performed the visuomotor task) and action observation, AO (subjects watched a video of the task being performed by someone else), the fMRI signal was detected in cerebral and cerebellar regions. These responses showed various relationships with force mapping onto specific areas of the sensorimotor and cognitive systems. Conjunction analysis of AE and AO was repeated for the “0th” order and linear and nonlinear responses, and revealed multiple AEON nodes remapping the detection of actions, and also effort, of another person onto the observer’s own cerebrocerebellar system. This result implies that the AEON exploits the cerebellum, which is known to process sensorimotor predictions and simulations, performing an internal assessment of forces and integrating information into high-level schemes, providing a crucial substrate for action imitation. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (45878 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Social behavior is based on understanding the actions of others and predicting appropriate reactions and subsequent interactions. In this context, perceiving the force applied to objects by others is crucial for understanding their intentions, for predicting the success of self-generated actions, and for dynamic movement control in interactions. However, there is still debate over the question of whether, when observing someone else performing an action, we mirror the actual movement dynamics or simply its goals ( ;  ;  ;  ;  ;  ;  ). Understanding, through observation, the force involved in movements performed by others can prime the force imparted during subsequent action executions (AE) ( ). The achievement of a better understanding of how force is represented in observation could facilitate and improve the clinical application of action observation (AO) in neurorehabilitation ( ;  ;  ). Although AE and observation have been studied using several techniques ( ;  ;  ;  ;  ), the neuronal processes involved in mirroring the motor effort of others have still not been fully explored. 

The most renowned imitation learning hypothesis claims that “mirror neurons” are activated by observation of actions performed by others ( ) and that the brain simulates the observed action by using the motor system as a forward model ( ;  ;  ;  ;  ), recruiting hierarchically organized brain circuits ( ;  ). On a broader perspective, the brain has been proposed to include a “mirroring system” which can understand the intentions of others from observing movements (“body” reading) and a “mentalizing system” which can infer the intentions of others reconstructing hypothetical events (“mind” reading) ( ;  ). In this context, even though magnetic resonance imaging (MRI) does not allow neuronal populations to be studied directly, functional MRI (fMRI), thanks to the blood-oxygenation-level-dependent (BOLD) effect ( ), can be used to study neuronal activation during both execution and observation of actions. fMRI studies ( ;  ;  ;  ) support the notion that, during observation of a complex motor task, the AE network (AEN) and the AO network (AON) combine to form an action execution–observation network (AEON), which provides the neural infrastructure for imitation learning. Although the “core AEON” structures are the premotor cortex and a limited number of parietal and temporal cortical areas ( ), it is now clear that the AEON also comprises the supplementary motor area and the inferior frontal gyrus, as well as large sections of the somatosensory and occipitotemporal cortices ( ). Furthermore, the cerebellum and basal ganglia have also been suggested to play a role in an extended circuit underlying action understanding ( ), to the point that the cerebellum is now considered to play a role as an adaptive predictor in AO ( ). This idea derives from the general theory of cerebellar functioning, wherein the cerebellum is seen as a forward controller in behavioral schemes that concern the interaction of the body with the external world, instructing the cerebral cortex in a predictive manner ( ;  ;  ;  ;  ). Moreover, a growing body of evidence from both lesion and fMRI studies ( ;  ;  ;  ;  ) suggests that the cerebellum plays a crucial role in action–perception coupling, coordinating the application of an appropriate force and its timing to generate movement, and thus operating in a forward mode ( ;  ;  ). On these bases, it can be hypothesized that predicting how to move by observation entails processing of force and involves an extended AEON that includes the cerebellum together with a complex set of cortical areas. 

In the present study, aiming to identify the network involved in force perception, we exploited a paradigm that recently showed how a complex set of linear and nonlinear BOLD responses are elicited in several brain regions, including the cerebellum, when varying the force applied to an object ( ;  ;  ). We used this grip-force (GF) squeeze ball paradigm to assess whether: 1) the AON presents both linear and nonlinear BOLD-GF associations during observation of the squeeze ball task; 2) the AEN and the AON share a common neural substrate, corresponding to the extended AEON; and 3) regions identified as part of the AEON exhibit linear and nonlinear BOLD-GF associations. The results of this work indeed support the existence of force-related BOLD effects not only in AE but also in the extended AEON, which includes the cerebellum. 


## Materials and Methods 
  
### Subjects 
  
A total of 14 right-handed healthy volunteers (9 females) were initially recruited for this study. However, 2 participants were excluded from further analysis: one who failed to follow the task instructions and another who presented head motion (translation in the   z   direction) >2 mm. The final sample thus comprised 12 subjects (7 females; mean age 26 ± 3.5 years). The handedness of each subject was evaluated using the Edinburgh handedness scaling questionnaire ( ); the mean laterality index was 82 (±16). All participants had normal or corrected-to-normal vision. No subject had a history of neurological or psychiatric disease. All the participants received a detailed explanation of the experimental procedures before participating in the experiment. The local research and ethics committee approved the study and all participants gave their written informed consent. 


### MRI Scanner and Scanning Sequences 
  
A 3 T Philips Achieva MR scanner (Philips Healthcare, Best, The Netherlands) with a 32-channel head coil was used to perform a 3D T1-weighted anatomical scan and 3 T2*-weighted echo-planner imaging (EPI) fMRI scans. The 3D T1-weighted sequence acquisition parameters were as follows: 3D inversion-recovery prepared gradient-echo (fast field echo) sequence with inversion time (TI) 824 ms, echo time (TE)/repetition time (TR) 3.1/6.9 ms, flip angle 8° and voxel size 1 mm isotropic. The fMRI acquisition parameters were: TR/TE 2.5/35 ms, 2.7 mm thick slices with interslice gap of 0.3 mm positioned axial-oblique to include the cerebellum, 3 × 3 mm  in-plane resolution, field of view 192 × 192 mm , SENSE factor 2, flip angle 90° and 200 repeated volumes. 


### Experimental Design 
  
All the participants completed 3 randomized event-related fMRI sessions (Fig.  ): AE, AO, and AO with visual cue (AOvc). In all cases, all the stimuli were projected onto the same white screen, which was kept in the same position throughout; short-sighted participants used nonmagnetic visual aid goggles. The 3 experimental sessions are described below. 
  
Experimental paradigm. The figure shows a pictorial representation of the 3 conditions that were used in the behavioral and fMRI sessions: (  A  ) action execution (AE), (  B  ) action observation (AO), and (  C  ) action observation with visual cue (AOvc). The stimuli are shown above the arrow whereas the activity of the subject is shown below the arrow. During fMRI, every session lasted 8:33 min and the trials were administered in a counterbalanced and randomized order. The active trials (each lasting 3 s) were repeated 75 times and were divided equally between the 5 grip forces. A rest time of 2–12 s was allowed between active trials. 
  

### Squeeze Ball Event-Related Paradigm 
  
This paradigm, previously described elsewhere ( ;  ;  ), consisted of a visuomotor event-related power grip task, in which the order and timing of trials and rest periods was optimized to introduce temporal jittering and randomization of the applied GF strength (see below). The task was performed using an MR-compatible sphygmomanometer inflation bulb (“squeeze ball”) connected to a computer suite (located outside the scanner room) running the fMRI paradigm presentation. Compression of the ball resulted in an air pressure measurement proportional to the force exerted, which was recorded at a sampling rate of 20 Hz. In all, 75 active trials were performed, divided equally into sets of 15 corresponding, respectively, to GF levels representing 20%, 30%, 40%, 50%, and 60% of the subject’s maximum voluntary contraction (MVC). MVC had previously been measured in each subject using the same force device (i.e., by asking the subject to continuously squeeze the power ball) and this value was used to set the GF target for each trial. 

Trials were performed in a counterbalanced and randomized order as obtained using the OptSeq optimization software ( ). The rest time between squeezing trials—this lasted between a minimum of 2 s and a maximum of 12 s, and was cued by a black crosshair located at the center of the screen—was also randomized to introduce temporal jittering between the task and data acquisition. Rest time accounted for 55% of the whole fMRI session (500 s). The visual cue used in the trials was a black static horizontal bar (presented for 3 s), which indicated the target GF level to reach. This cue was projected onto an MR-compatible white screen and shown together with an interactive colored bar, indicating the actual force level reached and thus providing real-time feedback to the subject about his/her own performance. The GF task was performed with the right (dominant) hand during the AE session. 

A female actor was also filmed while performing the task in the control room of the scanner suite. The resulting video showed her whole right hand and forearm, filmed against a plain colored background, with the palm facing up. While recording the task, the computer also recorded the visual feedback she received (i.e., the visual cue bar), which was used to create a further video (in which the cue bar was superimposed on the forearm and hand) to be used in the AOvc session. Premiere Pro CS5 (Adobe System Software, CA, USA) was used for video editing. 


### AO (AO and AOvc) Behavioral Sessions 
  
Before and after the fMRI sessions, subjects underwent behavioral sessions during which they were asked to watch the AO and AOvc videos (the order of presentation of the videos was randomized among subjects) and to verbally report their own perception of the GF, that is, 20%, 30%, 40%, 50%, or 60% of the MVC of the actor’s hand shown squeezing the ball in the video (perceived GF). These sessions served to test their recognition of the GFs observed, to saturate any learning effect before the actual fMRI experiment, and to test possible differences in learning effects between the pre- and post-MRI behavioral sessions. The purpose of running 2 AO behavioral sessions, AO and AOvc, was to assess whether GFs can be appreciated from subtle (and natural) cues alone—as in the AO condition (e.g., changes in the color of the hand with increasing effort and accompanying tendon contraction)—or whether subjects also need to see symbolic visual feedback, as in the AOvc condition. Performance accuracy was assessed for each of the 5 GF levels by calculating the number of correct answers and the mean difference between the perceived GF (pGF) and the GF actually applied by the actor during the video recording (aGF). 


### AE Training Session 
  
After the AO behavioral sessions, just before the fMRI one, subjects were trained using a 2-min paradigm having a design similar to the above-described event-related one, with GF levels ranging from 10% to 70% of their MVC. The training session involved practising the task outside the scanner bore. 


### AE Session 
  
Subjects performed the AE task following the visual instructions described above. Their feedback was recorded at a sampling rate of 20 Hz during the task. The data collected served to include subject-specific performance in the statistical analysis. 


### AO Session 
  
Subjects observed the video showing the right hand of the actor performing the squeeze ball task. They were asked to keep their gaze at the center of the projection screen indicated by a cross during rest periods, to relax, not to touch the squeeze ball, and to think about nothing throughout this fMRI recording session (as opposed to trying to guess the force or the next action). 


### AOvc Session 
  
The subjects received the same instructions as in the AO session. The only difference, compared with the AO condition, concerned the stimuli: the video again showed the actor’s right hand performing the squeeze ball task, but this time the image was overlaid with a translucent representation of the visual feedback that the actor had received during the recording of the video (thus an indication of her performance). This session was originally included as part of the behavioral study as it was unclear whether force perception demands some kind of visual feedback on the performance, such as that provided by the real-time bar (symbolic guided action observation). However, since the AO condition alone was found to be sufficient to disclose perception of force-related effects, the AOvc data were not considered further for the purposes of this study. 


### Data Analysis 
  
#### Behavioral Data Analysis 
  
The group mean accuracy of the subjects’ perceptions (pGF) was calculated overall by measuring all correct responses as a percentage of all perceived forces (at 20%, 30%, 40%, 50%, and 60% of MVC of the hand squeezing the ball in the video), and also separately for each of the following sessions: AO before MRI, AOvc before MRI, AO after MRI, and AOvc after MRI. A number of statistical tests were performed. First, we used paired sample   t  -tests to assess possible significant differences between ratings in the AO versus the AOvc sessions; that is, considering the mean accuracy of pGF in the 2 conditions (considering “AO before MRI” vs. “AOvc before MRI” and then “AO after MRI” vs. “AOvc after MRI”). Second, a repeated measures ANOVA with Bonferroni correction was implemented to investigate learning effects, that is, testing for different performances within the AO and the AOvc sessions (“AO before MRI” vs. “AO after MRI” and then “AOvc before MRI” vs. “AOvc after MRI”). A statistical threshold of   P   < 0.001 was considered significant. Finally, to characterize the challenging nature of the AO task, we assessed the correlation between the actor’s actual performance (i.e., the GF applied by the actor performing the task and recorded while filming) and the subjects’ perceptions of that GF (i.e., the pGF, as reported by each subject during the “AO before MRI” behavioral session), using the correlation coefficient (  r  ) and the significance level (  P  -value). The statistical analysis was performed using the Statistical Package for the Social Sciences (SPSS) software (version 21.0). 



### fMRI Data Analysis 
  
#### Whole Brain 
  
Image analysis was performed with SPM12 ( ), implemented in Matlab15b (Mathworks, Sheborn, MA), using conventional preprocessing steps: slice timing, realignment, coregistration, estimation of (nonlinear spatial) normalization parameters between the 3D T1-weighted volume and the standard SPM12 template, application of the normalization parameters to the fMRI EPI volumes, and smoothing with an 8 mm isotropic full-width half maximum (FWHM) Gaussian kernel. The GF trials were modeled as delta functions ( ) with parametric modulation according to GF. A general linear model (GLM) including polynomial expansions up to the fourth order was applied following the procedures described by Alahmadi et al. ( ;  ). As discussed in previous work, the polynomial expansion allows nonlinear relationships to be characterized in an unbiased way, by modeling a mixture of linear and nonlinear responses in a parsimonious fashion. Interpretation of the nonlinear order lends itself to hierarchical testing (e.g., second-order effects are interesting only after removing first-order effects) ( ) and neurophysiological studies have reported different response profiles that have distinct nonlinear forms ( ;  ;  ;  ). Moreover, polynomial expansions are the most common form of expansion (in the absence of boundary conditions) when estimating neurometric functions from imaging data ( ;  ). 

In our setting, the 0th order represents the main effect of hand gripping (executed or observed) compared with the rest condition, irrespective of the level of GF applied. The first order represents any linear dependency on GF level (executed or observed), while nonlinear orders represent more complicated neurometric functions such as U-shaped (second order), sigmoid (third order) and quadratic (fourth order) functions. The parametric modulation of the stick functions—encoding grip trials—with the polynomial expansion of GF produces stimulus functions that can then be convolved with a canonical haemodynamic response function for subsequent standard GLM analyses ( ). 

At the first level of analysis (within subject), the realignment parameters were included in the GLM as regressors of no interest ( ) and   t   statistics were used to test for the effects of each polynomial coefficient. The associated contrast images of each of the 5 polynomial coefficients were then entered into a second (between-subject) level analysis and tested with one-sample   t  -tests, following standard procedures. The same analysis pipeline was followed for the AE and AO sessions. In the AO session, the GF levels corresponded to those recorded from the actor’s performance. A voxel-wise threshold of   P   < 0.001 (minimum extent 5 voxels,   P  =   P   uncorrected for multiple comparisons) was used to define clusters. A threshold of   P   < 0.05 was applied to the spatial extent of clusters that survived multiple comparisons corrections. The anatomical designations of significant clusters were determined using the SPM Anatomy Toolbox (Version 2.2b). The same criteria were used for AE and AO sessions. 


#### SUIT 
  
The fMRI analysis pipeline, optimized for whole-brain analysis, can give suboptimal results in the cerebellum ( ). Therefore, to focus on the cerebellum, we used SUIT (spatially unbiased infratentorial template), a high-resolution atlas template of the human cerebellum and brainstem, which is part of the SPM12 software package ( ). The following steps were performed: 1) Extraction of each subject’s cerebellum and brainstem from their corresponding whole-brain 3D T1-weighted anatomical images; 2) Normalization of the anatomical images to the SUIT template using nonlinear deformations; 3) Re-slicing of the functional contrast images produced from the first-level analysis using the deformation produced from step 2) and masking out activation outside the region of interest (i.e., the cerebellum). The normalized cerebellum functional contrast images (of each polynomial order) from each subject were then smoothed with an 8 mm FWHM Gaussian kernel and submitted to a (between-subject) standard second-level random effects analysis, testing for increasingly higher-order nonlinear effects within the cerebellum with one-sample   t  -tests. Significant clusters were defined using a height threshold of   P   < 0.001 (and a minimum extent of 5 voxels). The anatomical designations of regionally specific effects were defined using a high-resolution probabilistic atlas defined within the SUIT template ( ). The resulting statistical parametric maps (SPMs) were projected on to the flat map of the cerebellum provided with the SUIT template ( ). 


#### Conjunction 
  
To identify, in terms of a parametric response to GF, the extended AEON, engaged both in AE and AO, we performed a simple conjunction analysis. This entailed testing for action observation effects at a corrected level of significance within a search volume defined by AE. 

We first used the SPM, testing for 0th order effects in order to localize the combined effect of AE and AO independently of GF, that is, to identify regions that showed a conjunction of AE/AO effects, irrespective of parametric force effects. We then identified regions that showed potential nonlinear responses to GF in both action observation and execution. In order to do so, we used a full factorial design and SPMs of the   F   statistic, testing for one or more significant polynomial coefficients in both execution and observation to obtain maps of the combined AE/AO force-related effect (FRE). Specifically, we used the SPMs of the   F   statistic, testing for a parametric effect of GF under AE (threshold   P  < 0.0001 for the whole brain analysis and   P   < 0.001 for the SUIT analysis) as a localizing contrast to define a search region within which to identify nonlinear effects under action observation (using the equivalent   F   contrast and a small volume correction to   P   < 0.05). Finally, we used the   F   statistic of the first-order effects to investigate the linear FRE and the   F   statistic of the higher-order effects to investigate the nonlinear FRE. 




## Results 
  
BOLD fMRI signals were recorded from 12 healthy subjects during one visuomotor and 2 visual tasks for the purpose of comparing brain activation under AE and AO conditions, when different GF levels are applied to an object (in this case a squeeze ball). 

### AO Behavioral Responses 
  
The behavioral performance, at group level, when watching the AO and AOvc videos, is shown in Fig.  . The accuracy of the perceived grip force (pGF) significantly differed between AO and AOvc, both before (  P   = 0.002) and after (  P   = 0.00008) the MRI session. Within the AOvc condition, pGF accuracy was higher after MRI (  P   = 0.003), while no significant differences were found in the AO condition (  P   = 0.955). As expected, GF recognition was higher in AOvc than AO (mean accuracy ± SD, 76 ± 22 and 39 ± 7, respectively), although at the end of the experiment, some subjects reported that the bar indicating levels of force (the visual cue) had not influenced their behavioral responses during AOvc. AO data showed a positive correlation between aGF and pGF (  r   = 0.98,   P   = 0.005) (Fig.  ), thus, confirming that the subjects were able to infer the actor’s movement in quantitative terms. Given that subjects correctly perceived the strength of the applied GF also when watching the AO video without the visual cue, subsequent analysis of fMRI data concerned only the AE and AO conditions. 
  
Group performance during action observation behavioral tasks. The box plot shows the relative accuracy (ACC) of force estimation in the different action observation (AO) and action observation with visual cue (AOvc) behavioral sessions (before and after the fMRI sessions). Significant differences between conditions are indicated (paired   t  -test). 
    
Relationship between applied and perceived grip force during the action observation behavioral task. The plot shows the relationship between grip force (GF) actually applied (aGF, i.e., GF presented on the video) and GF perceived (pGF, i.e., by the subjects watching the video) during the behavioral action observation (AO) task performed before and after fMRI recordings. The circles are individual subject responses and the line represents the group mean performance. A significant positive correlation was found between aGF and pGF (  R   = 0.98,   P   = 0.005). 
  

### Whole Brain—BOLD Effects 
  
Regionally specific effects for 0th (main effect), linear (+1st, −1st) and nonlinear (+2nd, +3rd, +4th, -3rd) order responses were detected, using whole-brain analysis, on AE and AO. Full data with figures and tables detailing significant effects (including coordinates,   T   values and cluster extents) are provided as  . AE activated many more regions than AO (Fig.  ), while both experimental conditions elicited regionally specific effects at 0th, −1st, and −3rd orders. Specifically, AO induced effects not only at the 0th order, but also at +3rd, 1st, and −3rd orders. These results reflect the presence of FRE during action observation. 
  
Whole-brain BOLD effects in action execution and observation. Brain maps at the group level corresponding to different orders of the BOLD-GF association in the action execution (AE, in red) and action observation (AO, in blue) conditions. The images show areas of activation at different orders. Note that both force-related and unrelated BOLD effects are found in the cerebral cortex and cerebellum. A threshold   P  < 0.001 (  k   ≥ 10;   P   =   P   uncorrected for multiple comparisons) was used for display purposes. The shape of the orthogonalised polynomial function that was fitted to the signals is shown for the (A) 0, (  B  ) +1st, (  C  ) +2nd, (  D  ) +3rd, (  E  ) +4th, (  F  ) −1st, and (  G  ) -3rd orders, to the right of the corresponding image showing significant clusters. In this and all the following figures, right is right and left is left. 
  

### Whole Brain Conjunction 
  
#### AE and AO Main Effect (0th Order) 
  
Several areas belonged to the extended AEON (in terms of a conjunction of zero order effects), and they included the occipital and temporal lobes, inferior and superior parietal cortices, precentral and postcentral gyri, inferior frontal gyrus, insula, thalamus and cerebellum. The occipitotemporal cluster extended into the cerebellar lobules VI and VII and cerebellar Crus I (Fig.   and Table  ). 
  
AEON: BOLD main effect. 3D whole-brain renderings of the main effects (0th order) in action execution (AEN), action observation (AON) and action execution–observation (AEON) networks. Note, in the AEON, the considerable overlap of effects in both the cerebral cortex and the cerebellum. Different thresholds were used for the 3 maps:   P   < 0.0001 (  k   ≥ 10;   P   =   P   uncorrected for multiple comparisons) was used for the AE condition;   P   < 0.05 (  k   ≥ 10;   P   =   P   uncorrected for multiple comparisons) was used for the AO condition; and   P   < 0.05 (  k   ≥ 10), with a small volume correction applied to the AO map, was used to obtain the AEON. 
  
  
AEON: main effect (0th order) 
    


#### Force-Related Effects (Linear and Nonlinear Orders) 
  
FREs (Fig.   A   and Table  ) were jointly expressed in several brain regions: supramarginal gyrus, calcarine gyrus, temporal gyrus, parietal lobe, insula, postcentral and precentral gyri, inferior frontal gyrus, middle cingulate cortex, posterior–medial and superior frontal cortices, rolandic operculum, lingual gyrus, basal ganglia, and cerebellum. A limited number of brain regions, that is, the precentral and postcentral gyri (Fig.   B  ), exhibited a linear FRE (+1st and −1st orders) in both AE and AO. The most prevalent joint FREs were nonlinear (+2nd, +3rd, +4th, −2nd, −3rd, −4th orders) and identified in the: supramarginal gyrus, angular gyrus, precentral and postcentral gyri, occipital lobe, inferior and middle temporal gyri, rolandic operculum, inferior and superior parietal cortices, inferior and middle frontal gyri, middle cingulate cortex, insula, thalamus and cerebellum (Fig.   C  ).
   
AEON: force-related BOLD effects 
    
  
AEON: force-related BOLD effects. 3D whole-brain renderings of the force-related effects: (  A  ) force-related effects (FRE), (  B  ) linear force-related effects (linear FRE), and (  C  ) nonlinear force-related effects (nonlinear FRE) in action execution (AEN), action observation (AON) and action execution–observation (AEON) networks. Note, in AEON, the prevalence of nonlinear associations in both the cerebral cortex and the cerebellum. Different thresholds were used for the 3 maps:   P   < 0.0001 (  k   ≥ 10;   P   =   P   uncorrected for multiple comparisons) was used for the action execution condition;   P   < 0.05 (  k   ≥ 10;   P   =   P   uncorrected for multiple comparisons) was used for the action observation condition; and   P   < 0.05 (  k   ≥ 10), with a small volume correction applied to the AO map, was used to obtain the AEON. 
  


### SUIT—BOLD Effects 
  
The AE condition detected more activated cerebellar regions than the AO one did (Fig.  ). In AE cerebellar specific effects were detected in lobule V and VIII (+1st order), lobule VI (0th and +4th orders), lobule VII (0th order), and Crus I (0th, +4th and −3rd orders). AO effects were observed in lobule VI (0th and −3rd orders), Crus I (0th order), and Crus II (+4th order). 
  
Cerebellar BOLD effects in action execution and observation. SUIT flat maps at the group level corresponding to different orders of the BOLD–GF association in action execution (AE) and action observation (AO) conditions. Note the force-related and main (0th order) BOLD effects in different cerebellar areas. In the images, areas of activation at different orders of effect are shown for both AE (in red) and AO (in blue). A SUIT flat map with labels of cerebellar lobules is shown in the bottom right corner. A threshold   P   < 0.001 (  k   ≥ 10;   P  =   P   uncorrected for multiple comparisons) was used for display purposes. 
  

### SUIT—Conjunction 
  
#### AE and AO Effect (0th Order) 
  
Lobules VI and VII and Crus I and II were jointly involved in AE and AO (Fig.  ). 
  
Cerebellar component of AEON: main BOLD effects. SUIT flat maps of the main effects (0th order) in the cerebellar component of the action execution (AEN), action observation (AON) and action execution–observation (AEON) networks. Note, in AEON, the extended involvement of posterior and lateral areas of the cerebellum. Different thresholds were used for the 3 maps:   P  < 0.001 (  k   ≥ 10;   P   =   P   uncorrected for multiple comparisons) was used for the action execution condition;   P   < 0.05 (  k   ≥ 10;   P   =   P   uncorrected for multiple comparisons) was used for the action observation condition; and   P   < 0.05 (  k   ≥ 10), with a small volume correction applied to the AON map, was used to obtain the AEON. 
  

#### Force-Related Effects (Linear and Nonlinear Orders) 
  
FREs were jointly identified in: Crus I and lobules V and VI (Fig.   A  ). A cluster in lobule V presented a linear FRE (+1st and −1st orders) while a nonlinear FRE (+2nd, +3rd +4th, −2nd, −3rd, −4th orders) was found in 2 clusters in lobule VI and IX (Fig.   B   and   C  , respectively). 
  
Cerebellar component of AEON: force-related BOLD effects. SUIT flat maps of the (  A  ) force-related effects (FRE), (  B  ) linear force-related effects (linear FRE), and (  C  ) nonlinear force-related effects (nonlinear FRE) in the cerebellar component of the action execution (AEN), action observation (AON) and action execution–observation (AEON) networks. Note, in AEON, the distribution of force-related BOLD effects over several cerebellar areas in the anterior and posterior cerebellum. Different thresholds were used for the 3 maps:   P   < 0.001 (  k   ≥ 10;   P  =   P   uncorrected for multiple comparisons) was used for the action execution condition;   P   < 0.05 (  k   ≥ 10;   P  =   P   uncorrected for multiple comparisons) was used for the action observation condition; and   P   < 0.05 (  k   ≥ 10), with a small volume correction applied to the AON map, was used to obtain the AEON. 
  



## Discussion 
  
In this study, we report for the first time the existence of force-related BOLD effects in an extended AEON involving cerebral and cerebellar regions that are both motor and associative in nature. These regions not only respond to observed and executed actions, but also share patterns of linear and nonlinear BOLD responses to parametric variations in GF. Linear BOLD–GF associations occurred in motor regions, while nonlinear BOLD–GF associations were found in regions specific to somatosensory state estimation, motor simulation and cognitive control. The cerebellum was found to be a key structure within the AEON, showing regional-specific correlations with force. These effects support the concept that the AEON extends to the cerebellum and to a set of cortical regions that are critical for imitation learning. The results are discussed and integrated with our current understanding of brain function in terms of the intrinsic functional connectivity of 7 fundamental networks (visual, somatomotor, ventral and dorsal attention, frontoparietal, limbic and default networks) ( ). 

### Behavioral Performance and Learning Effects 
  
The subjects were found to be able to evaluate visually the efforts of others. There are 3 considerations indicating that this ability was independent of learning during the test ( ). First, in order to saturate learning, all the subjects underwent AO training before the fMRI experimental sessions; this training is known to facilitate motor learning ( ;  ) and increase force production by optimizing motor neuron recruitment ( ). Second, the order of presentation of the AE, AO, AOvc sessions was randomized, thus limiting a potential variability in attentional load (e.g., induced by fatigue). Third, the accuracy in force detection was higher in AOvc than in the AO sessions. Therefore, independently of subject performance, the visual cue has a facilitator effect with respect to naturalistic stimulation (i.e., actual movement and changes in body parts during action), but the latter is nonetheless sufficient to perceive the intensity of another’s movements. 

It should be noted that in the AOvc condition we detected a learning effect, implying a facilitation of force recognition along trials. Moreover, we detected a higher variability of performance between participants in the AOvc compared with the AO condition; this might be due to attention being focused either on the visual cue or on the hand itself. However, the debriefing at the end of the experiment indicated that several participants had ignored the bar. For these reasons, we did not further consider the AOvc condition in our analysis. 


### BOLD Effects Elicited by AE and AO 
  
The BOLD effects elicited by AE occurred mostly in areas directly involved in motor planning, execution, and control ( ) (for a detailed description see Table  ). The main effect of AE was observed in premotor and sensorimotor cortices as well as in parietal, occipital and cerebellar cortices devoted to global sensorimotor processing ( ) and included in visual, dorsal attention and somatomotor networks, while a linear activation with force was found in primary motor cortex and anterior cerebellum, that actually do encode force ( ) and belong to the somatomotor network. Nonlinear relationships with GF were found in parietal, frontal, cingulate and insular cortices, and in thalamus, basal ganglia and cerebellum, which form large-scale loops involved in the control of fine precision grip forces and motor learning ( ;  ;  ). These loops could be linked with visual, ventral and dorsal attention, frontoparietal, somatomotor and default networks. Minor differences with previous squeeze ball studies ( ) could be related to the higher complexity of the present paradigm (which included behavioral training sessions and 3 different tasks).
   
Summary of BOLD effects for AEN, AON, and AEON 
    

The BOLD effects elicited by AO were recorded in an extended and distinctive set of occipital, parietal and frontal regions involved in motor but also sensory and cognitive processing (for a detailed description see Table  ). The main effect of AO was observed in the occipital and parietal regions related to motion perception and attention ( ;  ) that are considered to be part of the visual network and the ventral and dorsal attention networks. Linear responses with respect to GF occurred mainly in the postcentral gyrus, involved in processing proprioceptive and tactile representations of the manipulated object ( ) and included in the somatomotor network. Nonlinear responses with respect to GF occurred in occipital and temporal cortices and inferior parietal lobule, involved in object recognition ( ), inhibition of movement ( ), spatial focusing of attention ( ), and intention understanding ( ). These functions are supported by the inclusion of activated regions in the visual, dorsal attention and default networks. These components, either main or FREs, probably provide the substrate for the interpretation and simulation of the actions of others ( ), while actual movement is inhibited. 

The detection of specific nonlinear force-related BOLD effects in areas involved in AE or AO could imply complex task-related interplay of different neuronal populations (e.g., inhibitory and excitatory) within local networks. Understanding the biophysical basis of such nonlinearities will need realistic models and further investigation of neurovascular coupling under different conditions. 


### The Common Neural Substrate of AE and AO 
  
The AEON, identified as the voxels shared by AEN and AON, was observed in cerebral cortex, thalamus, basal ganglia, and cerebellum ( ) (for a detailed description see Table  ). The main effect of AEON was observed in occipital cortex, middle temporal gyrus, precentral and postcentral gyri, inferior and superior parietal lobules, insula, thalamus, and posterior cerebellum. These areas are involved in visual imagery of hand gestures, including visuospatial and motion processing ( ;  ), forward/inverse control for movement planning and execution, action style processing ( ), inhibition of motor execution to prevent imitative responses ( ). These are, indeed, the fundamental ingredients of motor planning based on observation of actions ( ). The activation of inferior and superior parietal lobules (which are part of the core mirror network) ( ) with occipital cortex, precentral and postcentral gyri and insula, suggest that AEON includes components from the visual, mirroring/somatomotor, ventral and dorsal attention networks. 

The AEON areas showing FREs were also extensively distributed in occipital cortex, superior temporal gyri, inferior and superior parietal lobules, precentral and postcentral gyri, inferior frontal gyrus, medial frontal gyrus, precuneus, cingulate gyrus, caudate, thalamus, and cerebellum. These areas are involved in the experience and observation of touch ( ), maintenance of spatial attention during goal-directed actions ( ;  ;  ), sensorimotor integration, and force amplitude generation and prediction ( ;  ). Moreover, the medial frontal gyrus is considered, with the temporoparietal junction, the “core network” of attribution of mental states ( ;  ) while the precuneus has been proposed to have a role in mental imagery to represent others’ perspective ( ). Therefore, FREs are particularly important in conferring the ability to detect the effort of others not just requiring the intervention of the mirroring/somatomotor, ventral and dorsal attention and frontoparietal networks but also of the mentalizing/default network. 

Interestingly, activation in the AEON areas was mostly nonlinear, while linear relationships with GF were found only in a restricted part of the precentral and postcentral cortices ( ) that are included in the mirroring/somatomotor network. Therefore, the AEON is engaged mainly in a nonlinear fashion during force processing. 


### Cerebellar Involvement in AEON 
  
The cerebellum is known to operate as a generalized forward controller ( ) that aids motor planning by predicting the sensory consequences of a motor act, such that a motor plan is coded in terms of an anticipatory sensory state ( ;  ;  ). In the present context, the sensory state would be provided by AO, and motor predictions would be based on internal cerebellar representations of the system (body and muscle) state ( ;  ). Thus, the cerebellum is well geared for simulating movements after receiving information about the movement of others, in terms of the appropriate sequence (timing) and force (gain) ( ;  ). 

The cerebellum is strongly interconnected with the cerebral cortex through 7 fundamental resting-state networks ( ). In particular,  ) clearly identified in the cerebellum distinct mirroring and mentalizing networks (as part of the larger somatomotor and default networks respectively) that were directly connected to homolog networks in the cerebral cortex. Confirming this network structure, Van Overwalle and colleagues reinterpreted their initial meta-analysis ( ) in terms of this network structure and found strong evidence for it ( ). In addition, a meta-analytical connectivity analysis revealed a strong distinction between anterior mirroring and posterior mentalizing areas in the cerebellum linked to classic mirror and mentalizing areas in the cerebral cortex ( ). This was confirmed by functional connectivity studies relating mentalizing and executive control functioning to the cerebellum ( ). Therefore, the cerebellum could also be involved in predicting the consequences and scope of other’s actions by reconstructing hypothetical events ( ;  ). 

It should be noted that, in our study, cerebellar responses were embedded in a larger cluster that included occipitotemporal areas. The combined activation in the AEON in lobules VI and VII and Crus I and II could be considered part of the ventral and dorsal attention, frontoparietal, and mentalizing/default networks compounded by the mirroring/somatomotor network from specific FREs ( ). Indeed, the linear FRE in lobules V, part of the mirroring/somatomotor network, reveals the involvement of cerebellum in motor functions ( ;  ;  ). The nonlinear effect in lobules VI and IX, part of both mirroring/somatomotor and mentalizing/default networks, would suggest the cerebellar involvement in the integration of motor processing and cognitive/emotional control ( ). 

Altogether, these effects confirm the cerebellar involvement in both mirroring and mentalizing networks. Moreover, these patterns of linear and nonlinear responses in the cerebellar components of the AEON are consistent with results showing that motor-generating areas respond linearly with GF, while associative and cognitive areas have a more complex relationship with GF. These response profiles may reflect distributed responses, mediated by connections that have been characterized structurally and physiologically in rodents, primates, and humans ( ;  ;  ;  ;  ;  ,  ). 


### High-Order Force–BOLD Relationships in the Cerebellum and Cerebral Cortex 
  
While a monotonic relationship between BOLD response and GF levels was found in primary motor areas (M1 and anterior cerebellum)—and could be related to the increased neuronal recruitment with increasing GF ( ;  )—nonlinearities were typically detected in areas implicated in multimodal integration and higher aspects of motor control (premotor, associative and sensory areas both in the cerebral cortex and the cerebellum), where a complex blend of signals converges to regulate motor output. It has been previously argued ( ) that second-order responses at intermediate force levels could be “metabolically optimal” and reflect more efficient processing in a motor regime requiring fewer corrective actions and less attention to sensory inputs. For example, nonlinearity may be due to fluctuation of attention levels modulating neural activity ( ). However, it should be appreciated that it is difficult to make detailed neurophysiological inferences based exclusively on fMRI signals. For example, nonlinearities (including nonlinear neuronal responses, nonlinear engagement of local inhibitory circuits, nonlinear mapping from neuronal activity to haemodynamic responses and finally, nonlinearities associated with the haemodynamic response function generating T2* signals) could arise at a number of different levels ( ;  ). The engagement of the underlying neuronal circuits, both in the cerebral cortex and the cerebellum, may benefit from further investigation using repetition-suppression fMRI paradigms ( ;  ) or multivoxel pattern analysis ( ) in conjunction with animal recordings and large-scale model simulations ( ). 


### Potential Limitations 
  
Despite the coherent functional framework emerging from this investigation, the relatively small number of subjects may affect its statistical power in detecting active areas. Although previous studies used similar numbers of subjects, a larger sample may be beneficial to confirm our findings. However, it is important to note that significant results obtained using a small sample usually mean that the effect size is large ( ). From a statistical point of view, the use of parametric models is an efficient way of accommodating nonlinear (neurometric) response functions within the established GLM framework ( ). However, given the concern that detection of active areas may have been reduced because of habituation due to multiple engagement in AO ( ), it would be useful to devise alternative paradigms in order to refine our AEON parametric characterization. 



## Conclusions 
  
The extended AEON identified in this fMRI study engages large-scale brain networks capable of remapping the visual detection of the actions, and also effort, of others onto the observer’s own motor system. These circuits, furnish not only understanding of other people’s goals, that is, the “mirror” effect ( ), but also the building blocks of executive control, impacting on various aspects of motor planning and programming, working memory, selective attention, and behavioral inhibition ( ;  ;  ;  ;  ;  ;  ). The cerebrocerebellar loops, using the motor system as a forward model ( ;  ;  ;  ;  ), could play a crucial role in sensorimotor prediction and internal simulation of movement. It has been suggested that the insular and cingulate cortices, activated in parallel to the sensorimotor loops, allow exteroception to be integrated with interoception ( ;  ;  ) and external observational cues to be transformed into internal sensorimotor plans. The identification of this extended AEON as a plausible substrate for imitation learning could facilitate and improve the clinical application of action observation in neurorehabilitation ( ;  ;  ). 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-13'>
<h2>13. PMID: 28455517</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Neural Activity while Imitating Emotional Faces is Related to Both Lower and Higher-Level Social Cognitive Performance</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Sci Rep</p>
<p><strong>Publication Year:</strong> 2017</p>
<p><strong>DOI:</strong> 10.1038/s41598-017-01316-z</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Meets all inclusion criteria: study uses functional MRI during a social-related task (imitate/observe emotional faces), participants are healthy adults aged 18–55 (screened with SCID; final imaging sample N=20), and analyses report whole-brain results (spatio-temporal PLS producing voxel maps and a GLM whole-brain analysis in SPM8). It is not an ROI-only analysis, not a review/meta-analysis, and does not report clinical/psychiatric participant results. Therefore it fits the meta-analysis objective of fMRI studies of social processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Imitation and observation of actions and facial emotional expressions activates the human fronto-parietal mirror network. There is skepticism regarding the role of this low-level network in more complex high-level social behaviour. We sought to test whether neural activation during an observation/imitation task was related to both lower and higher level social cognition. We employed an established observe/imitate task of emotional faces during functional MRI in 28 healthy adults, with final analyses based on 20 individuals following extensive quality control. Partial least squares (PLS) identified patterns of relationships between spatial activation and a battery of objective out-of-scanner assessments that index lower and higher-level social cognitive performance, including the Penn emotion recognition task, reading the mind in the eyes, the awareness of social inference test (TASIT) parts 1, 2, and 3, and the relationships across domains (RAD) test. Strikingly, activity in limbic, right inferior frontal, and inferior parietal areas during imitation of emotional faces correlated with performance on emotion evaluation (TASIT1), social inference - minimal (TASIT2), social inference - enriched (TASIT3), and the RAD tests. These results show a role for this network in both lower-level and higher-level social cognitive processes which are collectively critical for social functioning in everyday life. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (34238 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Social interactions are complex processes which are built upon the perception and understanding of the actions, intentions, and mental state of others. Social cognitive neuroscience has suggested a dichotomy between low-level processes such as understanding motor actions or emotional processing and higher-level processes such as inferring the mental states of others (e.g. theory of mind) or detecting deception and sarcasm. This apparent dichotomy between lower level and higher level social cognitive processes is supported by behavioral , neuroimaging  and lesion studies . Neuroimaging studies have primarily examined these processes with two approaches: using tasks relevant to the perception of and interaction with other people’s actions (action observation and imitation), and using tasks relevant to infer the beliefs and desires of the other person (mentalizing). Lower level social cognitive processes such as action interpretation have been associated with activation of a lateral frontal-parietal network, the putative human analogue to the mirror neuron system observed in monkeys . Higher-level social cognitive processes, such as theory of mind, have been associated with activation of cortical midline regions, including the medial prefrontal cortex, posterior cingulate cortex, and precuneus, as well as temporoparietal junction and temporal pole. This network is also known as the ‘mentalizing’ system. Dual processing models have been proposed in which the lateral fronto-parietal network supports relatively automatic processes such as identifying motor actions while the mentalizing network supports controlled processes of attributing actions to complex social causes . 

Most neuroimaging studies examining the lateral fronto-parietal network have made use of hand actions or other forms of simple motor stimuli . As such, the role of this system has been mainly considered in the context of perceiving gross motor actions. Some have taken the concept of mirroring one step further, by arguing that the lateral fronto-parietal network is important for emotional empathy by permitting humans to feel what others feel, and potentially to assess or interpret emotional cues and social behaviour . Investigating this issue may be best served by paradigms utilizing socially relevant stimuli as opposed to simple motor acts. One such paradigm is the imitation and observation of emotional faces, which has been shown to activate the lateral fronto-parietal ‘mirror’ network . This is consistent with the notion that activation of this network can play a role in allowing people to empathize by imitating emotions . Activity in the right IFG has been positively correlated with self-report measures of empathy in healthy children , and has been shown to be more active in normally developing children than those with autism , with activity in autistic children inversely correlated with social impairment. However, the IFG has also been implicated in some higher level social cognitive processes, specifically the inhibiting self-perspective in social judgements . Recent work has also shown structural changes in right fronto-parietal cortex in more socially impaired people with schizophrenia , a group of individuals in whom higher-level social cognitive processes such as theory of mind are more prominently affected . These findings raise the question of whether neural activation during basic mirroring tasks is related to higher-level social cognitive abilities. 

Meta-analysis of fMRI data has shown little overlap between activity in the brain regions associated with the mirroring and mentalizing systems across a range of tasks , and brain lesion studies have suggested a dissociation between mirroring and mentalizing regions . As such, mirroring and mentalizing were initially thought to represent dichotomous systems which function relatively independently, and the role of mirroring in higher-level social cognition is a contentious issue . However, there is a growing body of evidence that the mentalizing and mirroring systems may interact during more complex social cognitive processing, such as watching social videos . Co-activation of mentalizing and mirroring regions has also been noted when viewing agents performing irrational actions, suggesting aspects of the mentalizing system may facilitate interpreting unexpected actions . The mirroring and mentalizing system may work together during social cognitive processing, although a specific role of the mirror system in higher-level cognitive processing has yet to be established. 

The purpose of this study is to determine whether brain regions activated during a facial emotion mirroring task are related to lower-level social cognitive performance, higher-level social cognitive performance, or both. We utilized a process specific social mirroring task (the facial imitate/observe task ) inside the fMRI, along with a battery of objective out-of-scanner social tests ranging from basic emotional-perception tasks to complex higher level social cognitive tasks such as detection of lies or sarcasm. Brain-behavior relationships were examined using the spatio-temporal partial least squares (PLS), a non-parametric multivariate approach . PLS identifies latent variables (LVs), linear combinations of fMRI signal amplitude at each voxel across time and a design matrix which can consist of either experimental conditions or correlations across conditions with behavioral scores. Each LV expresses a pattern of the common covariance between the design and the fMRI data. PLS is designed to handle data with high collinearity while simultaneously capturing essential non-redundant relationships among the data , overcoming the confounding influence of collinear variables in traditional multiple regression . This makes PLS an excellent approach to uncover relationships between brain activity and a set of social cognitive scores which are likely highly interrelated. We hypothesized that a) consistent with previous studies, imitating emotional faces would activate the mirroring network, more prominently in the imitate than the observe condition, and b) neural activity during imitation of emotional faces specifically (rather than imitating neutral faces or observing faces) would be associated with both lower-level and higher-level social cognitive performance. 


## Results 
  
### Task Effects 
  
Task PLS is a multivariate model-free approach to identify spatial patterns which share relationships across the experimental conditions. A task PLS was run on the data to replicate previous task-based analysis, and examine the underlying pattern of task task-evoked spatial activity. PLS generated 6 LVs (as there were three trial types, emotional faces, neutral faces, and fixation, and two conditions, Imitate and Observe). Permutation analysis (see methods below) showed significance (p < 0.05) in the first three LVs, which accounted for 61.6%, and 14.5%, and 12.9% of crossblock covariance respectively (Fig.  ). LV 1 was related to viewing faces as opposed to fixation trials, and showed a pattern related to the lateral frontal-parietal network similar to the results of previous studies . LV 1 was related to viewing faces in general rather than distinguishing between emotional and neutral faces, demonstrating that this pattern of faces >fixation in the mirroring network is the dominant pattern of neural activity within this task analysis. LVs 2 and 3 explain some of the remaining variance in the data not accounted for the pattern presented in LV 1, representing interaction effects showing different patterns of activity across the Imitate and Observe conditions. LV 2 shows a large amount of overlap with LV 1, suggesting some of the variance within those regions is explained by aspects of both LVs 1 and 2. The majority of the variance explained by LV 1, but some additional variance within those voxels is explained by the pattern of emotional faces >neutral and fixation in Imitate and increased activity in fixation trials for Observe, as seen in LV 2. LV 3 represents an interaction in which the relative effects of neutral faces and fixation are different in the Imitate and Observe tasks.   
Results from the first latent variable using task PLS analysis. Data is shown for LV1, 2 and 3. The top panel shows the design pattern (the contribution of each condition to the LV). Error bars are 95% confidence interval derived from the bootstrap analysis. The bottom panel shows the voxel pattern from the first lag of the PLS analysis rendered on the cortex. Sagittal slices are shown for X = −10 (left) and X = 10 (right). Voxel intensity is displayed as bootstrap ratio, a measure of reliability of voxels within the LV. Red-yellow regions show the pattern described by the design pattern, while blue regions show the opposite pattern. 
  

For consistency and replication of previous studies, we also ran a general linear model (GLM) in SPM8. The GLM showed a similar pattern as in previous studies and LV1 of the task PLS (see supplementary methods and Supplementary Figure 1). 


### Behavioral PLS 
  
Behavioral PLS examined the relationships between patterns of activity in the brain and social cognitive test scores. Scores from six social cognitive tasks were included: the Emotion Recognition (ER40) , the Reading the Mind in the Eyes Test, RMET , the Relationships Across Domains test (RAD) , and the three subtests of the Awareness of Social Inference Test Revised (TASIT-R) . TASIT1 can be considered a test of lower-level social cognitive functioning, while TASIT2 and TASIT3 are high-level tests. The behavioral PLS generated 36 LVs, as there were six experimental conditions (emotional faces, neutral faces, and fixation, separately for Imitate and Observe, and six social cognitive tests). Overall permutation analysis showed significance in the first two LVs, which accounted for 23% and 13.2% of crossblock covariance respectively. However, the split-half permutation reliability analysis (see methods) demonstrated that the relationship between the design pattern and brain pattern was not reliable within LV 1 and as such it was not considered further. In LV 2, neural activity during imitation of emotional faces was positively correlated with RAD, TASIT1, TASIT2, and TASIT3 (Fig.  , top panel). Neural activity for Fixation and Neutral faces during Imitate, as well as Neutral faces during Observe, was negatively correlated with those same test scores. As such, LV 2 shows a pattern of correlations during the imitation of emotional faces related to performance on TASIT1, TASIT2, TASIT3, and RAD.   
LV 2 of the behavioral PLS results. (  A  ) Design pattern showing the pattern of correlations between brain signal for each during event type and each behavioral score within the voxel pattern. Error bars represent 95% confidence interval based off a bootstrapping analysis of 1000 iterations. (  B  ) Voxel patterns for each lag, displayed as bootstrap ratio on the MNI152 brain. Data is shown for two sagittal views as well as rendered onto the cortex (8 mm search depth) to better visualize cortical activity. Red-yellow shows a correlation pattern matching the design pattern (  A  ), while blue regions show the opposite pattern. Each lag represents a time point (TR) following stimuli onset (which occurred during ‘Lag0’). 
  

The pattern of brain activity in LV 2 (Fig.  , bottom panel) when imitating emotional faces in lag 1 showed a positive relationship with performance on TASIT1 TASIT2, TASIT3, and RAD. Activity was present in right pars opercularis (within inferior frontal gyrus), right and left supramarginal gyrus, right motor cortex, bilateral anterior temporal regions, fusiform gyrus, and parahippocampal cortex. Activity was also noted in right anterior/mid cingulate, right rolandic operculum, right putamen, and the cerebellum. Activity in lags 4 and 5, which positively correlated with social cognitive performance, was notably present in anterior temporal regions as well as in posterior middle and inferior right temporal gyri. Several regions showed negative relationships to the design pattern (thus greater fMRI activity while imitating emotional faces in individuals with poorer social cognitive performance), including the left inferior frontal gyrus (pars operculum and pars triangularis), and bilaterally in the basal ganglia (greatest in left putamen and right globus pallidus). 



## Discussion 
  
The behavioral PLS results of this study showed a robust relationship between neural activity during a process-specific imitate-observe task and both lower-level and higher-level social cognitive performance. While a growing number of studies using complex stimuli have noted co-activation of mirroring and mentalizing regions , co-activity cannot be taken to conclude that mirroring has a strong role in higher level social cognition. The novelty of our study is that we showed complex relationships of neural activity during a simple and process-specific mirroring task with performance on objective out-of-scanner assessments of higher-level social cognitive performance. In addition, the PLS approach allowed us to include several assessments in a single analysis, providing data driven evidence of which assessments best capture these brain-behaviour relationships. These behavioral relationships were specific to imitation of emotional faces, rather than neutral faces. Several regions outside the right fronto-parietal circuit, including left IFG and some mentalizing regions (e.g. TPJ), also showed negative correlations with social cognitive performance, suggesting either compensatory responses or over-activation in participants with poorer social cognition. 

These findings of a relationship between activity in a simple mirroring task and higher level social cognitive processing scores suggest a relationship for the mirror network in higher-order social cognitive processing including complex tasks. Effective mentalizing in humans although likely primarily reliant on classic mentalizing regions may be further subserved by mirroring regions . Given that the relationships elicited were noted in assessments involving interpretation of dynamic interactive video tasks including human actors, it may be that such relationships are only evoked when we consider social cognition as a process involving integrating information from multiple processing levels. The mirroring network may not be solely for understanding the intentions and physical goals of motor acts . Our findings add to the debate regarding the role of this network in social cognition . Several authors have argued that this network is important not only for imitation or action perception, but also for emotional empathy and possibly even in cognitive empathy (sometimes used interchangeably with theory of mind) , consistent with the theory of embodied simulation , despite debate to the contrary . Through the combination of a process-specific in-scanner task, more naturalistic and objective social cognitive tests, and the PLS multivariate framework, we were able to uncover essential brain-behavior relationships for which traditional task contrasts or linear regression analyses may be less sensitive. 

Higher level social cognitive processing involves concepts related to both theory of mind and cognitive empathy, both complex constructs which likely encompass several mental processes. To date, there is only limited evidence of overlap in neural activity between high-level tasks related to the mentalizing network and low-level tasks related to the mirroring network . However, task based analysis is often performed by contrasting conditions, and many mirroring tasks have utilized stimuli with little or no direct social relevance, or tasks designed to evaluate highly specific social cognitive processes which may not be well suited to capturing overlap within these systems . By moving away from an ‘overlapping activity’ perspective into an approach focused on brain-behavior relationships, we were able to demonstrate that activity in the mirroring network is correlated with higher-level social cognitive abilities. This combination of pairing a process-specific task paradigm with dynamic social cognitive measures may be a powerful approach for probing relationships between social cognitive networks and real-life social cognitive abilities. 

The behavioral PLS LV correlating neural activation during imitation of emotional faces with TASIT and RAD scores also included some regions which are often considered part of the mentalizing network. While these regions did not robustly activate during the task PLS, their presence in the behavioural PLS reflects activation during the imitate task that is relevant for social cognitive performance. Positive relationships with social cognition and emotional faces were observed in the temporal pole bilaterally, a region implicated in mentalizing and theory of mind  as well as in processing deception . Activity was also noted in the posterior region of the superior temporal sulcus, which may be of particular interest as this area has been implicated in both the mirroring/imitation network  and the mentalizing network . The superior temporal sulcus may serve as an integrative region, sharing information between these two networks  and/or as serving as a relay point for high level visual information . The superior temporal sulcus has also been implicated in analyzing dynamic facial features , perceiving biological motion , and gaze perception . As such, this region is involved with perceptual processes necessary for both low-level and high-level social cognition. It remains to be seen if this region may serve as an integrative hub between the mentalizing and mirroring networks, though the posterior superior temporal sulcus shares connectivity within both networks  and has been implicated as an important region in social cognitive impairment in autism . 

Studies showing increased connectivity between the right IFG (a critical hub of the mirroring network) and the mentalizing network provide evidence for functional communications between these networks . This connectivity between mirroring and mentalizing regions has been shown to be disrupted in autism , raising the possibility that disrupted social cognition in autism may be driven not only by localized effects within one of these systems but also as a network level disruption in how these systems interact. Likewise, social cognitive deficits are increasingly recognized as a core feature of schizophrenia, strongly related to overall functional outcomes . People with schizophrenia have been noted to show reduced right IFG activity when imitating emotional faces as well as opposite relationships between self-reported empathy and right IFG activity compared to controls . As social cognitive impairment is present at, or potentially preceding the onset of psychosis , it is possible this relatively brief imitate/observe in-scanner task may be useful as a potential early risk marker of the disease. 

We found that increased activity in the left IFG was associated with poorer social cognitive performance, as well as in clusters in the left medial frontal cortex and the TPJ . One study examining resting state network connectivity noted over-connectivity of the left IFG in the mirroring network in participants with autism, consistent with our finding that over activity in the left IFG is associated with poorer social cognitive performance . A number of regions outside the mirroring or mentalizing networks also showed a negative relationship with social cognitive performance, including the basal ganglia, thalamus, occipital cortex and superior colliculus. These regions may be involved in emotional face processing . We propose three possible explanations for the negative correlations between this pattern of neural activity when imitating emotional faces and social cognitive performance: 1) prolonged neural activity related to less efficient processing resulting in a greater magnitude of hemodynamic signal, as may be suggested by increased activity in regions associated with visual and face processing; 2) compensatory activity in which individuals with less efficient processing make greater use of the left IFG to compensate for lack of activity on the right (the compensatory hypothesis); or 3) over activity in the left IFG resulting in competition with right IFG, resulting in interference or an decrease in network coherence and deficits in social cognitive test performance (the dedifferentiation hypothesis). One possible explanation is that participants with poor performance may be attempting to compensate by activating aspects of the mentalizing system during lower-level social cognitive processing. It has been suggested that the anterior cingulate cortex, a region noted in the behavioral PLS, is involved in biasing activity towards either mentalizing or simulation . 

We did not find reliable relationships between the ER40 and RMET with neural activity to emotional faces. The ER40 and RMET rely on static images which fail to capture the full complexity of social cognitive processing, unlike the TASIT which requires interpretation of video scenarios of complex human interactions and the RAD which involves interpreting stories. It may be that more complex and process-general tests are required to more fully elicit relationships between activity in the simulation and mentalizing networks . Supporting this assertion, correlations between TASIT test scores and the observed voxel pattern in the PLS analysis were as high as 0.8, indicating a very strong relationship between mirroring network activity and social cognitive performance measured by TASIT1 (a lower-level task), as well as higher-level tasks TASIT2, and TASIT3. Some recent studies using more naturalistic higher-level social-cognitive paradigms, such as videos, have implicated IFG activity , and a small number of recent studies involving more complex social interaction tasks have noted co-activation in mirroring and mentalizing regions . 

Here we provide evidence that neural activation while imitating emotional faces is related to performance on dynamic and objective ‘real-life’ assessments of even the most complex social cognitive tasks. Given the relatively small sample size, further research expanding into a larger sample would be worthwhile to replicate and extend these findings. However, our findings suggest that patterns of neural activation during basic imitative behaviour may be a surrogate marker for highly complex social function in humans. The paradigm demonstrated here may be particularly useful for early identification studies in neurologic and psychiatric disorders with social cognitive impairment, and in intervention studies using ‘target engagement’ as a marker of early treatment response. 


## Methods 
  
### Participants 
  
Twenty-eight healthy adult participants were initially included in this study. Average age of participants was 34.3 ± 11.7 years, with 18 men and 10 women, 23 right-handed participants, and an average level of education of 15.1 ± 2.22 years. Participants aged 18 to 55 were included in the study. All participants completed the Edinburgh handedness Inventory and were administered the Structured Clinical Interview for DSM-IV disorders (SCID) to rule out possible psychiatric illness. Urine toxicology screening was performed to further ensure that no participant with a current substance use disorder was included in the study. Additionally, exclusion criteria included a first degree relative with a history of psychotic mental disorder, a history of head trauma resulting in unconsciousness, or a history of seizure or other neurological disorders. The protocol was approved by the research ethics board of the Centre for Addiction and Mental Health, University of Toronto, all research was conducted in accordance with the declaration of Helsinki and the tri-council policy statement on Ethic Conduct for Research Involving Humans. All participants gave informed consent, and signed an institutionally approved informed consent form, prior to any research procedures. 


### Social Cognitive Assessments 
  
The Emotion Recognition (ER40) task consists of 40 images of whole faces making emotional expressions, with participants selecting from four possible emotional responses . The Reading the Mind in the Eyes Test (RMET)  consists of 36 trials showing only the eyes of a black and white face, with four possible choices to describe what the person is feeling (e.g. amused, irritated, cautious, contemplative). The RMET is considered a test of empathic abilities as it measures the ability to judge emotional states from looking at the eyes. The Relationships Across Domains (RAD) test  presents 25 written vignettes of 2–4 lines followed by three statements which describe the behaviour of the male-female dyad from each vignette in domains of social life different from that vignette. Participants indicate if the behavior described in each statement is likely or unlikely to occur based on what was learned from the vignettes. The Awareness of Social Inference Test, Revised (TASIT) uses short video vignettes to measure emotional perception and theory of mind . The TASIT is divided into three parts. Part 1 (TASIT1) consists of 24 short videos of actors portraying different emotional states (happy, sad, fear, disgust, surprise, and anger). Part 2 (TASIT2; social inference – minimal) consists of 15 videos showing sincere or sarcastic interactions between two actors, followed by four questions relating to what the actors were thinking, doing, meaning to say, and feeling. TASIT2 is considered a test of theory of mind. TASIT part 3 (TASIT3; social inference – enriched) consists of 15 vignettes in which the speaker is making an assertion which is literally untrue, but can represent either sarcasm or an attempt at deception. Success in TASIT3 requires the ability to detect deception in social encounters. In total, six social cognitive scores were derived from these tests (ER40 reaction time, RMET, RAD TASIT1, TASIT2, and TASIT3). Age was regressed out of all social cognitive test scores. 


### MRI Scanning 
  
MRI scanning was conducted on a Discovery 3 T MR750 machine from General Electric at the Centre for Addiction and Mental Health. The Imitate/Observe task was part of a longer multimodal MRI protocol to which each participant consented. Each block of the task (Imitate and Observe) was collected in counter-balanced order as a separate echo-planar imaging scan, with TRs = 3 sec, TE 30 ms, voxel size 3 mm isotropic, 50 slices, 64 × 64 matrix with FOV = 192 mm, flip angle = 77, and 110 TRs per scan. The first 5 TRs were excluded prior to any preprocessing to allow for magnetic steady-state. 


### Imitate/Observe Task 
  
The participants performed an imitate/observe task as previously described  while being scanned. Participants were shown full-color photographs from an ethnically diverse set of 16 individuals (eight males and eight females) expressing five different facial expressions (fearful, sad, happy, angry, or neutral). During one scanning session, participants were instructed to imitate the expression on the faces (the   Imitate   session), while in the other session participants were instructed to observe the face (the   Observe   session). Each run consisted of 80 faces (16 per facial expression) plus 16 fixation trials presented in a pseudorandomized order determined using Optimize Design 11  to maximize contrast efficiency. Each trial lasted three seconds, with the faces presented for two seconds and a jittered ISI (500 ms to 1500 ms). The order of sessions (Imitate or Observe) was counter-balanced across participants. Participants practiced the task prior to MRI scanning and were instructed to minimize motion during the imitation, only using their facial muscles when matching the expressions. A video recording during the scan confirmed that all participants were following instructions (i.e. imitating during the imitate session but not during observe). 


### fMRI data analysis - Preprocessing 
  
The initial preprocessing stages were slice time corrected and motion corrected in SPM8 (Wellcome Department of Cognitive Neurology, London, UK). Individual sessions were subjected to single-session independent components analysis (ICA, from the MELODIC module in FSL 5.0.6). ICA reports were visually examined, and any ICAs which were clear artifacts were removed based on a set of established criteria. On a case by case basis where some large motions contaminated the ICAs, data ‘scrubbing’ was performed using a spline interpolation. Generally, two TRs were removed for each motion spike, and no more than three TRs were permitted per motion spike and a maximum of three motion spikes were removed from any scan. Of the 56 sessions (Observe and Imitate for the 28 participants) scrubbing was performed in 16 sessions. In nine of these cases (four Observe sessions and five Imitate sessions) scrubbing was not successful. Possible reasons for unsuccessful ‘data scrubbing’ include large movements exceeding three TRs, more than three large movements, or over 90% of ICA components classified as artifact after data scrubbing. These sessions were subsequently excluded from further analysis, leaving neuroimaging data from 20 of the original 28 individuals for final analysis. Data were then de-noised based on the selected noise ICA components using FSL 5.0.6 (reg_filt). Normalization into MNI space was done using SPM8, and images were smoothed with an 8 mm Gaussian kernel. 


### Partial Least Squares Analysis 
  
Patterns of task related activity and relationships between social cognitive test scores and BOLD signal were examined using spatio-temporal PLS , a multivariate approach which allows for detection of spatial patterns and dependant variables across the brain without the need for a-priori selected contrasts across experimental conditions. PLS is designed to handle data with high collinearity while capturing essential non-redundant relationships among the data , overcoming the confounding influence of collinear variables (e.g. cognitive tests) in traditional multiple regression. Additionally, PLS is also well suited to studying the relationships between numerous variables even in the presence of a relatively small sample, which is ideal for our purposes as it allows us to examine a range of social cognitive batteries. PLS produces latent variables (  LVs  ) relating patterns of experiment task activity or behavioral measures with spatial patterns of neural activity across time points (scans, referred to as    lags   , normalized to the scan in which the stimuli was presented, labeled as lag0). As a model free non-parametric approach, PLS is ideal to examine complex relationships amongst the battery of social cognitive scores and neural activity when imitating and observing emotional faces. 

A task-PLS analysis was conducted to replicate the regions of activity in the SPM8 GLM. Brain data from an 18 second window (corresponding to 6 lags) was normalized to the first lag (lag0) to create a data matrix for each condition, stacked across participants. Cross covariance was calculated between the data matrix and a design matrix consisting of vector of experimental conditions (in the task PLS, emotional faces, neutral faces, and fixation crosses, separately for Imitate and Observe). The resulting cross-covariance matrix was then decomposed using singular value decomposition, which created a set of orthogonal latent variables (  LVs  ) which optimally represent spatio-temporal relationships between voxels and experimental conditions. For each LV, a pattern of voxels at each lag value (the ‘brain pattern’) demonstrates the relationship with activity in the voxel at that lag and the ‘design pattern’ (representing the weights of each experimental event). Voxel weight is expressed as salience, which is proportional to the covariance of activity in that voxel and the design pattern expressed by that LV. 

Behavioral PLS was used to examine relationships between social cognition and neural activity. Behavioral PLS examines patterns of covariance between scores and neural activity for each trial type across lags. As such the design pattern is the correlation between the overall pattern of neural activity in each condition and each social cognitive score. For the behavioral PLS, neural activity to emotional faces, neutral faces, and fixation (separately for imitate and observe) was related to the six social cognitive test scores from our battery, deterministically producing 36 LVs. 

Statistical evaluation of each LV was performed using split-half permutation testing. A total of 500 permutations were run, with 100 split-half permutations within each. The overall permutation score determines if the effect represented by the LV is sufficiently strong to be differentiated from random noise, while the split-half analysis provides a measure of the stability of relationships between voxel patterns and design patterns in the data for each latent variable. As the permutations are performed at the level of the entire PLS analysis (rather than on individual LVs), multiple comparisons for the number of LVs is not necessary. In the split-half, the ‘BrainCorr’ value tests the reliability of the voxel pattern for a given design pattern associated with an LV, while ‘DesignCorr’ tests the reliability of a given voxel pattern for the behavioral pattern associated with that LV. Results are expressed as p-values. LV’s were considered significant if the overall permutation and at least one of the BrainCorr or DesignCorr was less than 0.05. A bootstrapping procedure with 1000 iterations was used to test if specific voxels were reliably related to the LV. A bootstrap ratio for each voxel was calculated as the voxel salience divided by its bootstrap standard error. A bootstrap ratio of 2.5 (corresponding to >95% reliability) was used to threshold all voxel pattern maps in PLS. 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-14'>
<h2>14. PMID: 30834300</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> What Makes Eye Contact Special? Neural Substrates of On-Line Mutual Eye-Gaze: A Hyperscanning fMRI Study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> eNeuro</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1523/ENEURO.0284-18.2019</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Meets all inclusion criteria: (1) Functional MRI was acquired while participants performed a social task (real-time mutual eye contact vs delayed REPLAY), directly addressing social processing; (2) Participants were healthy adults (N=32–34 analytic sample, mean age ~21.7–21.8), within the 18–60 range; (3) Analyses report whole-brain results (voxel-wise GLM with cluster-level FWE correction, whole-brain gPPI and voxel-to-voxel interbrain synchronization analyses) rather than ROI-only findings. Exclusion criteria not violated: not an ROI-only study, not a review/meta-analysis, and participants were healthy with no psychiatric/neurologic disorders. Therefore the study is appropriate for inclusion in the meta-analysis of fMRI studies of social-related processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>   Visual Abstract  
  
  
Automatic mimicry is a critical element of social interaction. A salient type of automatic mimicry is eye contact characterized by sharing of affective and mental states among individuals. We conducted a hyperscanning functional magnetic resonance imaging study involving on-line (LIVE) and delayed off-line (REPLAY) conditions to test our hypothesis that recurrent interaction through eye contact activates the limbic mirror system, including the anterior cingulate cortex (ACC) and anterior insular cortex (AIC), both of which are critical for self-awareness. Sixteen pairs of human adults participated in the experiment. Given that an eye-blink represents an individual’s attentional window toward the partner, we analyzed pairwise time-series data for eye-blinks. We used multivariate autoregression analysis to calculate the noise contribution ratio (NCR) as an index of how a participant’s directional attention was influenced by that of their partner. NCR was greater in the LIVE than in the REPLAY condition, indicating mutual perceptual–motor interaction during real-time eye contact. Relative to the REPLAY condition, the LIVE condition was associated with greater activation in the left cerebellar hemisphere, vermis, and ACC, accompanied by enhanced functional connectivity between ACC and right AIC. Given the roles of the cerebellum in sensorimotor prediction and ACC in movement initiation, ACC–cerebellar activation may represent their involvement in modulating visual input related to the partner’s movement, which may, in turn, involve the limbic mirror system. Our findings indicate that mutual interaction during eye contact is mediated by the cerebellum and limbic mirror system. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (52963 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Significance Statement 
  
Eye contact is a key element that connects humans during social communication. We focused on a previously unaddressed characteristic of eye contact: real-time mutual interaction as a form of automatic mimicry. Our results indicate that real-time interaction during eye contact is mediated by the cerebellum and limbic mirror system. These findings underscore the importance of the mirror system and cerebellum in real-time unconscious social interaction. 


## Introduction 
  
Automatic mimicry refers to unconscious or automatic imitation of movement ( ). It is a critical part of human social interaction because it is closely tied to the formation of relationships and feeling of empathy ( ). Automatic mimicry occurs when two or more individuals engage in the same behavior within a short window of time (e.g., facial expressions, body postures, laughter, yawning;  ). Automatic mimicry induces synchronous behavior through recurrent interaction ( ), thereby enabling spontaneous synchronization (e.g., clapping) and goal-directed cooperation ( ). 

Eye contact is one of the most salient types of automatic mimicry, as two people must be able to synchronize their eye movements to make eye contact ( ). Eye gaze provides a communicative signal that transfers information regarding emotional and mental states ( ). Eye contact, or mutual gaze, conveys the message, “I am attending to you,” thereby promoting effective communication and enhancing social interaction ( ;  ). 

Recent functional magnetic resonance imaging (fMRI) studies have revealed that eye contact activates the social brain, including the fusiform gyrus ( ;  ;  ), anterior superior temporal gyri ( ;  ), posterior superior temporal gyri ( ;  ;  ), medial prefrontal cortex ( ;  ;  ;  ), orbitofrontal cortex ( ;  ), and amygdala ( ;  ;  ; for review, see  ). The above-mentioned studies were conducted using single-participant fMRI data, contrasting the neural activation elicited by an eye-contact event with that elicited by an eye-aversion event. However, neural substrates underlying recurrent interaction during eye contact that result in the development of shared, pair-specific psychological states (e.g., attention and emotion) remain unknown. 

The mirror neuron system plays a role during mutual interaction through joint attention ( ;  ). The existence of two main networks with mirror properties has been demonstrated, with one residing in the parietal lobe and premotor cortex plus caudal part of the inferior frontal gyrus (parietofrontal mirror system), and the other formed by the insula and anterior medial frontal cortex (limbic mirror system;  ). The parietofrontal mirror system is involved in recognizing voluntary behavior, while the limbic mirror system is devoted to recognizing affective behavior ( ). We hypothesized that mutual interaction involving eye contact activates the limbic mirror system. 

This study aimed to elucidate the behavioral and neural representations of mutual interaction during eye contact using hyperscanning fMRI ( ). The neural activity associated with real-time eye contact was compared with that of non-real-time eye contact using a double-video system ( ). Eye contact is characterized by a two-way, behavioral stimulus-to-brain coupling, such that the behavior of a partner is coupled to the activation in the brain of the other ( ). Thus, face-to-face interaction through eye contact can be regarded as a mirrored reactive–predictive controller system consisting of two controllers ( ). We used eye-blink as a behavioral index of mutual exchange of communicative cues between two participants during eye contact. As the blinks of others can be easily recognized due to their relatively long duration (200–400 ms;  ), eye-blinks can provide social communication cues ( ). Further, blink rates change with internal states such as arousal, emotion, and cognitive load ( ;  ;  ). Finally, the timing of eye-blinks is associated with implicit ( ) and explicit ( ) attentional pauses in task content.   observed that eye-blinks of a listener and speaker were synchronized during face-to-face conversations, and concluded that eye-blinks define the attentional temporal window and that its synchronization reflects smooth communication between interactants through sharing of attention in the temporal domain. In this study, we used hyperscanning fMRI to analyze brain activation related to eye-blinks using the following different measures: activation, modulation of functional connectivity, and interbrain synchronization. 


## Materials and Methods 
  
### Participants 
  
Thirty-four volunteers participated in the experiment (20 men, 14 women; mean age ± SD, 21.8 ± 2.12 years). Participant pairs were determined before the experiment and consisted of participants of the same sex. None of the participants had met each other before the experiment. All participants except one were right handed, as evidenced by the Edinburgh Handedness Inventory ( ). None of the participants had a history of neurologic or psychiatric illness. The protocol was approved by the ethics committee of the National Institute for Physiological Sciences. The study was conducted in compliance with the national legislation and the Code of Ethical Principles for Medical Research Involving Human Subjects of the World Medical Association (Declaration of Helsinki). All participants provided written informed consent before the experiment. 


### Design and Procedure 
  
#### Experimental setup 
  
To measure neural activation during the on-line exchange of eye signals between pairs of participants, we used a hyperscanning paradigm with two MRI scanners (Magnetom Verio 3T, Siemens) installed side-by-side in parallel, sharing one control room and a triggering system ( ;  ). The top component of the standard 32-channel coil was replaced by a small four-channel flex coil (Siemens) attached with a special holding fixture (Takashima Seisakusho;  ;  ) to fully visualize the eye region. On-line grayscale video cameras were used during scanning to identify reciprocal face-to-face interaction (NAC Image Technology). The cameras captured images of each participant’s face, including the eyes and eyebrows. The captured images were in turn projected using a liquid crystal display projector (CP-SX12000J, Hitachi) onto a half-transparent screen that stood behind the scanner bed. The captured images were also entered into the picture delay system (VM-800, Sugioka System), which could output video delayed by an arbitrary amount of time. For analysis, video pictures used in the experiment were transferred to a video recording system (Panasonic). We recorded facial movement in AVI (audio video interleave) format (640 × 480 pixels, 30 frames/s). While the exact values varied depending on the participant’s head size, the screen stood ∼190 cm from the participants’ eyes, and the stimuli were presented at a visual angle of 13.06° × 10.45°. The delay between the capture and projection of the participants’ face was controlled using a hardware device (VM-800, Ito Co., Ltd.) connected between the video camera and projector. The delay was set at 20 s for the REPLAY condition and 0 s for the LIVE condition. The intrinsic delay of the on-line video system in this experimental setup was ∼100 ms. 


#### Experimental conditions 
  
We adopted a conventional blocked design for this study. Each run included three conditions: LIVE, REPLAY, and REST. During the LIVE condition, participants were presented with a live video of their partner’s face in real time ( ), allowing for the on-line exchange of information between the two participants. We instructed participants to gaze into the right or left eye of their partners and think about their partner as follows: what he/she is thinking about, what is his/her personality, how he/she is feeling. The participants were instructed not to exhibit explicit facial expressions such as laughing or grimacing. We also informed them that we will stop MRI scanning if they were not gazing into the partner’s eyes for an extended period of time. The REPLAY condition was identical to the LIVE condition, except that the participant watched a video picture of their partner’s face presented at a delay of 20 s. Therefore, there was no real-time interaction between the participants ( ). During the REPLAY condition, the participant was informed that all the videos they were watching represented their partner’s face in real time. During the REST condition (baseline), participants were required to gaze at the blank screen ( ). Although we monitored the participants to ensure that they do not fall asleep, two participants fell asleep during the experiment, and we had to restart the experiment after a short break. 
  
Experimental setup.    A   , LIVE condition: the face of Participant 1 is projected on the screen of Participant 2 in real time and vice versa, allowing a mutual exchange of information.    B   , REPLAY condition: the picture is projected on the screen with a 20 s delay; therefore, there is no mutual interaction between participants in real time.    C   , REST condition (baseline): no image is presented on the black screen.    D   , Sequence of presentation of the experimental conditions. 
  
Before starting the run, a live video of the partner was presented on the screen to confirm that an interactive partner was in the other scanner. Following confirmation, the video was turned off. The first run began with the REST condition for 30 s, followed by the LIVE, REPLAY, and REST conditions for 20 s each. After each 20 s presentation of the partner’s face, the screen was turned off for 1 s, and the condition was switched (e.g., from LIVE to REPLAY, REPLAY to REST;  ). The 1 s interval was designed to prevent participants from becoming aware of the difference between the LIVE and REPLAY conditions. The order of presenting the conditions was pseudorandomized. The conditions were switched manually during the fMRI run according to a predefined experimental design. Each run consisted of eight LIVE and eight REPLAY conditions. The total length of each run was 8 min and 30 s, and the entire scan consisted of four runs. Throughout the experiment, none of the participants exhibited any sudden display of emotions such as laughter. 

An interview following the experiment revealed that only one female pair realized that a delayed facial picture was presented in one of the conditions during the experiment; thus, the requirements of the experiment were not fulfilled in the pair. Data were analyzed from the remaining 32 participants (20 men, 12 women; mean ± SD age, 21.8 ± 2.03 years). 


#### MRI data acquisition 
  
Brain activation data were acquired using interleaved T2*-weighted, gradient echo, echoplanar imaging (EPI) sequences. Volumes consisted of 60 axial slices, each 2.0 mm thick with a 0.5 mm gap, covering the entire cerebral cortex and cerebellum. The time interval between two successive acquisitions of the same image [repetition time (TR)] was 1000 ms, with a flip angle of 80° and echo time (TE) of 30 ms. The field of view (FOV) was 192 mm, and the in-plane matrix size was 64 × 64 pixels. We used the multiband accelerated sequence developed at the University of Minnesota ( ), with the multiband factor set to 6. Thus, 510 volumes (8 min and 30 s) were collected for each run. For anatomic reference, T1-weighted high-resolution images were obtained using a three-dimensional magnetization-prepared rapid acquisition gradient echo (MPRAGE) sequence (TR = 1800 ms; TE = 2.97 ms; FA = 9°; FOV = 256 mm; voxel dimensions = 1 × 1 × 1 mm ) and a full 32-channel phased array coil. 



### Data analysis 
  
#### Behavioral data analysis 
  
##### Extraction of eye-blink time series 
  
Eye-blink was chosen as a behavioral index of interaction during mutual gaze ( ). We calculated the “motion energy” using the AVI video of the participant’s face during the task ( ) to evaluate the time series of eye-blinks. Due to technical difficulties with the video recording system, data from two pairs were unavailable. In total, video data of faces from 14 pairs (18 men, 10 women; mean ± SD age, 21.8 ± 2.17 years) were subjected to the analysis described below. 

 illustrates the procedure used to calculate the motion energy time series representing eye-blinks. First, the spatial window (400 × 100 pixels) of the AVI video was manually set to cover the eye area of each participant. Second, using the pixel intensity of the defined eye area, we obtained the motion energy index, which can detect the occurrence of motion only from a series of pictures ( ). The first-order difference in picture intensity was calculated frame by frame in each pixel, and the average of the absolute value of differences in each frame was calculated. This process was used to obtain motion energy values at specific time points. The calculation was repeated to obtain the motion energy time series reflecting eye-blinks during each run. Third, we divided the time series in each run into shorter subsections corresponding to the LIVE, REPLAY, and REST conditions. Although each condition lasted 20 s ( ), we analyzed only the final 15 s of each condition to minimize the effect of brightness instability (largely due to the procedure for switching conditions). We obtained eight time series for each condition of a single run. As each participant underwent four runs, 32 time series were obtained for each condition per participant. Finally, the effect of the linear trend in the data was removed using the “detrend” function implemented in MATLAB. The whole procedure was performed using a MATLAB script (MATLAB 14, MathWorks) developed in-house. 
  
Evaluation of the motion energy time series representing eye-blinks. The red dots indicate the timing of the detected eye-blink. 
  

##### Number of eye-blinks 
  
To determine whether the number of eye-blinks itself was influenced by differences in the type of task, we calculated the number of eye-blinks in the LIVE, REPLAY, and REST conditions using the extracted time series of motion energy. We first adapted the peak-detection function implemented in MATLAB, which automatically detected and marked the time point at which the eye-blink appeared to occur ( ). Next, we visually examined whether the detected time point was acceptable. Finally, we calculated the average number of eye-blinks in 1 block (  15   s) for each participant. All calculations were performed using a MATLAB script (MATLAB 2014) developed in-house. 


##### Causality analysis between eye-blink time series 
  
Several hyperscanning studies have used synchronization or correlation as an index of interaction ( ), neither of which can evaluate the directional effect. In this study, we used an Akaike causality model ( ;  ), which can delineate the causal direction and quantify its effect. The Akaike causality model uses a multivariate autoregressive (MVAR) model under the steady-state assumption and can quantify the proportion of the power-spectral density of an observed variable from the independent noise of another variable. The quantified causality, that is, the noise contribution ratio (NCR) index, is regarded as a measure of how one variable is influenced by another. In this study, we assumed that the eye-blink time series satisfies a steady-state assumption at least in one block. The NCR values were calculated as follows. 

First, an MVAR model was applied to a pair of time-series data,   x  (  t  ) and   y  (  t  ), using the linear sum of the history of the two time series, as follows: where the time series   and   correspond to the time series of the participant’s eye-blinks and that of the partner, respectively. In these equations,  ,  ,  , and   indicate AR coefficients, while   and   indicate the residual noise in the eye-blinks of the participant and partner, respectively. The AR order   N   defines the duration of the history. For each pair of time-series data, the AR order   N   was estimated to minimize the Akaike information criterion in the range from 1 to 10. Next, we estimated the power spectrum of the two time series based on the sum of the contributions of the   x  -specific noise (i.e.,  ) and   y  -specific noise (i.e.,  ). Here,   and   are frequency response functions, derived from Fourier transformation via an impulse response function, using a set of AR coefficients, while   and   indicate the variance of residual noise   and  , respectively. The  , an index reflecting how the participant’s eye-blinks   are influenced by the partner’s eye-blinks  , was calculated from the ratio of part of the spectral density of   contributed by   to the total spectral density of   at frequency   f  . Therefore,   can be expressed as follows: 

To assess how   is influenced by   across the whole frequency range, we mathematically integrated   NCR   values via trapezoidal numerical integration as follows: where   f   is the sampling frequency of the time series   and  . In this study,   f   was 30 Hz, based on the frame rate of the video data. We collected 32 time series for each condition. Therefore, our calculations yielded 32 ΣNCR values for each condition per participant. These 32 ΣNCR values were averaged to calculate one summarized ΣNCR value for each participant in each condition. Using the summarized ΣNCR, we applied statistical analyses to determine whether the influence of the partner differed between conditions. The entire procedure was performed using a MATLAB script (MATLAB 2014) written in-house. 

In this study, we calculated four ΣNCR values to assess how a participant’s eye-blink was influenced by that of the partner. Firstly, in the REST condition, participants could see nothing on the screen. Therefore, the ΣNCR value in the REST condition (i.e.  ) was regarded as a baseline of causal relationship. In the LIVE condition, the face of one participant was immediately projected on the screen, and the partner was able to see the face in real time. In this condition, we calculated ΣNCR between two participants’ time series (i.e.,  ).　The ΣNCR value represents how participants influence their partners when they mutually interact with each other in real time. Next, in the REPLAY condition, two types of causality were calculated as follows: first, the ΣNCR value between actual eye-blinks, like in the LIVE condition (i.e.,  ); and second, the ΣNCR value in the REPLAY condition representing how the eye-blinks projected on the screen has an influence on the actual eye-blink time series,  . While it is possible that a participant’s face receives influence from the delayed picture on the screen ( ), influence from an actual eye-blink to the screen (reverse influence) is theoretically absent. We also calculated the ΣNCR value (i.e.,  ). It represents how participants are influenced by a video picture, while there could be only unidirectional influence from the screen to actual eye-blinks. 


##### Estimation of statistical inferences and data visualization 
  
All statistical inference estimation for the behavioral data analysis was performed using R (RRID:  SCR_001905  ). We analyzed three types of behavioral measures. (1) The number of eye-blinks is highly influenced by the degree of attention ( ;  ;  ;  ;  ) and could reflect the differences across conditions. We tested the number of eye-blinks in three conditions using repeated-measures analysis of variance (ANOVA). (2) ΣNCR values: we have four ΣNCR values for each participant,   in the REST condition,   and   in the REPLAY condition, and   in the LIVE condition. The differences between them were assessed using repeated-measures ANOVA. (3) Enhanced ΣNCR values: in the REST condition, participants know there is no interaction with a partner as nothing is projected on the screen. Therefore, theoretically speaking, the REST condition could be regarded as a baseline condition. We calculated the increase in ΣNCR values (enhancement) by subtracting the   value from each of the ΣNCR values. Thus, we have three enhanced ΣNCR values for each participant:   and  . Repeated-measures ANOVA was used to test the differences between these values. In all ANOVA procedures, the effect size was measured using the generalized η  value ( ). In the   post hoc   pairwise analysis, estimated   p   values were adjusted using a Bonferroni correction. The confidence levels for   post hoc   pairwise analyses were calculated via the pairwise confidence intervals of  . The details of the statistical methods used in this behavioral data analysis are listed in  . All the graphs were prepared using the RainCloudPlots R-script ( ;   https://github.com/RainCloudPlots/RainCloudPlots  ), which could provide a combination of box, violin, and dataset plots. In the dataset plot, each dot represents a data point, respectively. Outliers were defined by 2 SDs and are represented in   by red diamonds. In the boxplot, the line dividing the box represents the median of the data, while the ends of the box represent the upper and lower quartiles. The extreme lines show the highest and lowest values excluding outliers defined by 2.0 SDs. 
  
Statistical analysis 
  


#### Neuroimaging analysis 
  
##### Image preprocessing 
  
The first 10 volumes (10 s) of each fMRI run were discarded to allow for stabilization of the magnetization, and the remaining 500 volumes/run (total of 2000 volumes/participant) were used for the analysis. The data were analyzed using statistical parametric mapping (SPM12, Wellcome Trust Center for Neuroimaging, London, UK; RRID:  SCR_007037  ) implemented in MATLAB 2014 (RRID:  SCR_001622  ). All volumes were realigned for motion correction. The whole-head T1-weighted high-resolution MPRAGE volume was coregistered with the mean EPI volume. The T1-weighted image was normalized to the Montreal Neurologic Institute (MNI) template brain using a nonlinear basis function in SPM12. The same normalization parameters were applied to all EPI volumes. All normalized EPI images were spatially smoothed in three dimensions using a Gaussian kernel (full-width at half-maximum = 8 mm). 


##### Estimation of task-related activation using univariate generalized linear modeling 
  
Because of technical difficulties, we could not acquire fMRI data from one pair. Therefore, we analyzed whole fMRI data acquired from 30 participants (18 men, 12 women; mean ± SD age, 21.7 ± 2.10 years). Statistical analysis was conducted at two levels. First, individual task-related activation was evaluated. Second, summary data for each participant were incorporated into a second-level analysis using a random-effects model ( ) to make inferences at a population level. 

In the individual-level analysis, the blood oxygenation level-dependent (BOLD) time series representing the brain activation of each participant was first modeled using a boxcar function convolved with a hemodynamic response function and filtered using a high-pass filter (128 s), while controlling for the effect of runs. Serial autocorrelation assuming a first-order autoregressive model was estimated from the pooled active voxels using the restricted maximum likelihood procedure and used to whiten the data ( ). No global scaling was applied. The model parameters were estimated using the least-squares algorithm on the high pass-filtered and whitened data and design matrix. Estimates for each of the model parameters were compared with the linear contrasts to test hypotheses regarding region-specific condition effects. Next, the weighted contrasts of the parameter estimate (i.e., LIVE > REST and REPLAY > REST) in the individual analyses were incorporated into the group analysis. Contrast images obtained via individual analyses represented the normalized task-related increment of the MR signal relative to the control condition (i.e., the REST condition) for each participant. 

In the group-level analysis, we investigated differences in brain activation between the LIVE and REPLAY conditions using these contrast images and the random-effects model implemented in SPM12. We analyzed these data using the paired   t   test. The resulting set of voxel values for each contrast constituted a statistical parametric map of the   t   statistic (SPM {t}).   T  he threshold for significance of the SPM {t} was set at   p   < 0.05 with familywise error (FWE) correction at the cluster level for the entire brain ( ). To control FWE rates using random field theory ( ), the height threshold was set at an uncorrected   p   value <0.001, which is conservative enough to depict cluster-level inference with the parametric procedure ( ). To validate the statistical inference with a parametric method, we also tested the statistical significance of activation using a nonparametric permutation test implemented in the SnPM13 toolbox (RRID:  SCR_002092  ;  ). We used the nonparametric paired   t   test with no variance smoothing; the number of permutations was set at 10,000. The SnPM toolbox did not yield statistical significance at all the voxels reported in SPM; thus, the   p   values for some voxels have not been listed in the tables. 


##### Generalized psychophysiologic interaction analysis 
  
Next, we performed generalized psycho-physiologic interaction (gPPI) analysis ( ;  ) using the CONN toolbox ( ; RRID:  SCR_009550  ) to reveal how effective connectivity from the LIVE- or REPLAY-specific regions (toward other brain regions) was altered between the LIVE and REPLAY conditions. For this purpose, we selected three clusters based on the LIVE > REPLAY contrast defined by the results of univariate generalized linear modeling (GLM) analysis ( ,  ) as seed regions for the gPPI analysis. We used conventional seed-to-voxel gPPI analysis in which the whole brain is the search area. The components associated with a linear trend, CSF, white matter (WM), and experimental tasks (i.e., LIVE and REPLAY effects) were removed from the BOLD time series as confounding signals. Using the residual time series, gPPI analysis was performed to evaluate whether the effective connectivity from the seed region was modulated by the task condition (i.e., the LIVE or REPLAY condition) at the individual level. This individual-level analysis produced contrast images representing the modulation of effective connectivity from the seed region. Up to this point, all procedures were conducted using the CONN toolbox. Finally, we used these contrast images and the random-effect model implemented in SPM12 to test whether any regions exhibited significant differences in effective connectivity between the LIVE and REPLAY conditions. Analyses were assessed at   p   < 0.05 with FWE correction at the cluster level. The height threshold to form each cluster was set at an uncorrected   p   value of 0.001. This relatively high cluster-forming threshold is enough to prevent the failure of a multiple-comparison problem in cluster-level statistical inference ( ;  ). We also listed statistical values estimated by the SnPM toolbox with a nonparametric permutation test. 
  
Behavioral analysis.    A   , The number of eye-blinks per block. We omitted the first 5 s of each block because of instability of the recorded video induced by task switching; the number of eye-blinks was therefore calculated based on the succeeding 15 s. Each dot represents a data point. In the boxplot, the line dividing the box represents the median of the data, the ends represent the upper/lower quartiles, and the extreme lines represent the highest and lowest values excluding outliers.    B   , ΣNCR values. The integral of the NCR of each condition across the whole frequency range was calculated.   is the ΣNCR from the time series of the participant’s facial movement to that of the partner during the LIVE condition.   is the ΣNCR from the time series of the participant’s facial movement to that of the partner during the REPLAY condition.   is the ΣNCR from the time series of the participant’s facial movement to that of the partner during the REST condition.   is the ΣNCR from the time series from the participant’s delayed facial movement on the screen to the partner’s time series during the REPLAY condition.    C   , Enhanced ΣNCR values from the REST condition. 
    
Regions exhibiting greater activation in the LIVE condition than in the REPLAY condition 
    

##### Interbrain synchronization analysis 
  
We tested for differences in the interbrain synchronization of the LIVE and REPLAY conditions using conventional voxel-to-voxel method used by previous hyperscanning fMRI studies that can identify interbrain synchronization of activation without any prior assumptions ( ;  ). We focused on the spontaneous fluctuation of BOLD signal that is unrelated to the task-related activation or deactivation ( ). First, the task-related activation/deactivation was removed from the BOLD time series using the GLM model implemented in the SPM12. This yielded 3D-Nifti files representing residual time series that are independent of task-related activation/deactivation compared with baseline (i.e., the REST condition). Second, we divided the original time series into three sub-time series based on the experimental design: LIVE, REPLAY, and REST conditions. Third, we concatenated sub-time series into one long time series. The length of the LIVE- and REPLAY-related residual time series was 640 volumes. Next, we calculated the interbrain synchronization between the voxels representing the same MNI coordinates (  x  ,   y  ,   z  ) in the two participants using the Pearson’s correlation coefficient. This computation was performed using a MATLAB script developed in-house. The correlation coefficient   r   was transformed to the standardized   z   score using Fisher’s   r  -to-  z   transformation. Finally, we obtained two 3D-Nifti images representing interbrain synchronization in the LIVE and REPLAY conditions per pair. 

We conducted the random-effects model analysis in SPM12 at the group level. The normalized interbrain synchronization images were used in the group-level analysis. Here, the paired   t   test was used to test the differences in interbrain synchronization between the LIVE and REPLAY conditions. The resulting set of voxel values for each contrast constituted a statistical parametric map of the   t   statistic (SPM {t}). The threshold for significance of the SPM {t} was set at   p   < 0.05 with FWE correction at the cluster level for the entire brain ( ); the height threshold was set at an uncorrected   p   value of 0.001. This cluster threshold is conservative enough to prevent failure in cluster-level inference ( ;  ). The statistical inference was also estimated by a nonparametric permutation test using the SnPM toolbox, like the GLM and gPPI analyses. Anatomic labeling was based on Automated Anatomic Labeling ( ) and the Anatomy toolbox version 1.8 ( ). Final images have been displayed on a standard template brain image (  http://www.bic.mni.mcgill.ca/ServicesAtlases/Colin27  ) using MRIcron (  https://www.nitrc.org/projects/mricron  ;  ). 





## Results 
  
### Behavioral index 
  
 shows the average number of eye-blinks per block. Repeated-measures ANOVA revealed a significant effect of condition ( , a;   F   = 13.1814,   p   < 0.0001, η  = 0.0354). A   post hoc   comparison with Bonferroni correction revealed that there were no significant differences in the number of eye-blinks between the LIVE and REPLAY conditions ( , d;   t   =2.3522,   p   = 0.0786, Bonferroni correction), while the number of eye-blinks was greater in the REST condition than in the LIVE ( , b;   t   =3.9464,   p   = 0.0015, Bonferroni correction) and REPLAY ( , c;   t   = 3.8499,   p   = 0.0021, Bonferroni correction) conditions. 

 N  ext, we compared the ΣNCR values using repeated-measures ANOVA ( ) and found a significant effect of condition was significant (  F   = 3.9830,   p   = 0.0295, η  = 0.03236;  , e). A   post hoc   comparison with Bonferroni correction revealed that there were significant differences between the   (  t   = 3.406,   p   = 0.0126;  , f),   (  t   =3.2934,   p   = 0.0168;  , h). Differences in the other pairs did not meet the threshold for statistical significance ( , g, i, j, k). To confirm that the outliers did not skew the parametric statistics, we recomputed the statistical values after removing outliers defined by two SDs rather than 1.5. Four subjects to whom the outlier data could be attributed in at least one of the four conditions were excluded from the analysis; the repeated-measures ANOVA therefore included a sample of 24. Even after removing the outliers, the repeated-measures ANOVA could replicate the significant effect of condition (  F   = 4.3334,   p   = 0.0074, η  = = 0.0785;  , l), as well as the significant differences between the   (  t   =3.0965,   p   = 0.0306;  , m), and between   (  t   = 3.0779,   p   = 0.0318;  , o). Differences in the other pairs did not meet the threshold for statistical significance ( , n, p, q, r). 

We also tested differences across enhanced ΣNCR values using repeated-measures ANOVA ( ) and found that the effect of condition was significant (  F   = 10.3784,   p   = 0.0002, η  = 0.03236;  , s). A   post hoc   comparison with Bonferroni correction revealed that there were significant differences between   and   (  t   = 3.4061,   p   = 0.0063;  , t), as well as between   and   (  t   = 3.2934,   p   = 0.0084;  , u). Differences in the other pair did not meet the threshold for statistical significance ( , v). We recalculated statistical inferences as raw NCR values without outliers to ensure that the outliers had no effect on the inferences. The stricter criteria for outliers remained 2 SDs, resulting in the removal of seven subjects from the analysis. Even after outliers were excluded from the analysis, we obtained qualitatively identical results: significant effect of condition (  F   = 7.9233,   p   = 0.0013, η  = 0.1330;  , w), and significant differences between   and   (  t   = 2.8343,   p   = 0.0306;  , x) and between   and   (  t   = 2.9034,   p   = 0.0265;  , y). Differences in other pairs did not meet the threshold for statistical significance ( , z). 

To test whether or not these enhancements of entrainment of eye-blinking is influenced by the number of blocks, we calculated the Akaike causality index for separate blocks of the experiment and applied the repeated-measures ANOVA (4 blocks × 4 conditions) to the ΣNCR data. We found a significant effect of conditions (  F  =3.9830,   p   = 0.0106, η  = 0.0132;  , aa). However, the effects of sessions (  F  =1.0351,   p   = 0.3816, η  = 0.0139;  , bb) and interaction (session × conditions;   F   = 1.8235,   p   = 0.0647, η  = 0.0128;  , cc) were nonsignificant. Therefore, in the following analysis of neuroimaging data, we combined data from the four blocks. 


### Brain activation in the LIVE and REPLAY conditions 
  
We used GLM analysis ( , dd, ee) to elucidate brain activation in the LIVE and REPLAY conditions. For the LIVE versus REPLAY contrast, we observed greater activation in the left cerebellar hemisphere (lobules VI, VII, and VIIIa), bilateral paravermis area (lobule XI;  ), and the pre-supplementary motor area (SMA) extending to the dorsal tier of the anterior cingulate cortex (ACC;  ). No significant differences in activation were observed in the REPLAY versus LIVE contrast. Detailed information regarding each cluster is outlined in  . 
  
Brain regions exhibiting significantly greater activation in the LIVE condition than in the REPLAY condition.    A   , Cerebellar activation is overlaid on the coronal planes of the SUIT template ( ;  ).    B   , The activation in the ACC is superimposed on the T1-weighted high-resolution anatomic MRI normalized to the MNI template space in the sagittal (left), coronal (middle), and transaxial (right) planes that crossed at (6, 12, 40) in the MNI coordinate system (in mm). SUIT, Spatially unbiased infratentorial template. 
  

### Results of the gPPI analysis 
  
The gPPI analysis ( , ff, gg) revealed that the effective connectivity from the ACC region toward the dorsal anterior insular cortex (dAIC;  ) was greater during the LIVE condition than during the REPLAY condition ( ,  ). No regions exhibited greater effective connectivity involving the pre-SMA-ACC regions in the REPLAY condition than in the LIVE condition. There was no modulation of effective connectivity involving cerebellar seed regions.
 
  
Regions exhibiting greater effective connectivity from the ACC in the LIVE condition than in the REPLAY condition. The area outlined in white is the dAIC ( ). X indicates the MNI coordinates (in mm). 
    
Regions exhibiting enhanced effective connectivity from the ACC in the LIVE condition 
    

### Interbrain synchronization 
  
 illustrates interbrain synchronization that is specific to the LIVE condition ( , hh, ii). It was found on the bilateral middle occipital gyrus (MOG). Detailed information about these clusters is described in  . No regions showed significant interbrain synchronization in the REPLAY condition compared with the LIVE condition. 
  
Regions exhibiting greater interbrain synchronization during the LIVE condition than the REPLAY condition. These areas are superimposed on a surface-rendered high-resolution anatomic MRI normalized to the MNI template viewed from the left and right. 
    
The regions exhibiting enhanced interbrain synchronization in the LIVE condition compared with REPLAY condition 
    


## Discussion 
  
This study aimed to elucidate the behavioral and neural representations of mutual interaction during eye contact by comparing the neural activity associated with real-time eye contact with that associated with non-real-time eye contact. Our findings suggest that mutual interaction/shared attention during eye contact is mediated by the cerebellum and the limbic mirror system. 

### Behavioral index 
  
In this study, causal analysis using an MVAR model ( ;  ) was performed to assess how an individual’s temporal attentional window is influenced by that of the partner ( ;  ;  ). Our results show that participants were more sensitive to the eye-blinks of a partner in the LIVE condition than in the REPLAY condition because none of the participants perceived the difference between the LIVE and REPLAY conditions. Thus, the experimental setup for our LIVE condition enabled a reciprocal feedback system through the visual modality. Our findings suggest that perceptual–motor interaction occurs during eye contact without conscious awareness. Previous researchers have argued that an essential component of real-time social interactions involves reciprocal coupling via perceptual–motor linkages between interacting individuals ( ;  ;  ;  ;  ). Our results extend this notion to the attention mediated by the minimal motion of blinking, which represents the temporal window of attention toward one’s partner. Interestingly, the influence from a partner was significantly greater when the information flow between two individuals was reciprocal ( ) than when it was unidirectional ( ). As the mutual interaction in real time evinced a significant effect on the partner’s eye-blink, this finding indicated that the mutual on-line interaction is critical to the influence of the other’s eye-blink. Feedback through the on-line mutual interaction may induce a nonlinear response, causing the subtle effect to be amplified ( ). 

This experiment can be regarded as a simplified version of the social contingency detection task originally reported by  . Social contingency is defined as the cause–effect relationship between one’s behavior and consequent social events ( ;  ) and is highly associated with a sense of self or one’s own body in infancy, developing a sense of reciprocity, and participation with others ( ), all of which are critical for typical development ( ;  ;  ;  ;  ). Several previous studies have investigated differences in mother–infant interactions between real-time bidirectional interaction and off-line unidirectional interaction ( ;  ;  ;  ). Even in adults, turn-taking behavior accompanying social contingency is likely to serve as experience sharing, which represents the basis of all social behaviors ( ;  ). Our results indicate that even a minimal task condition, such as mutual gaze, constitutes a reciprocal feedback system that can provide a basis for the detection of social contingency, promoting sharing of attention between partners ( ;  ). 


### Neural substrates of eye contact in real time 
  
Using a conventional GLM approach, we observed LIVE-specific activation in the cerebellum and ACC. The cerebellum plays a key role in error detection and processing of temporal contingency ( ;  ;  ), the latter of which is critical for real-time social communication ( ). The cerebellum is also critically involved in sensorimotor prediction ( ), especially in building predictions about the actual sensory consequences of an executed motor command. One previous fMRI study reported that the prediction error caused by sensory feedback is essential for acquiring internal forward models of movement control ( ). This prediction (forward model) is mainly used in the early stages of movement execution to maintain accurate performance in the presence of sensory feedback delays ( ), as well as in social interaction ( ). Considering that real-time social interaction can be regarded as a cross-individual sensorimotor loop ( ;  ), the cerebellum may receive visual afferents of the partner’s blink as sensory feedback for the prediction of one’s blink movement, to evaluate temporal contingency between the partners’ blinks. 

In humans, the ACC is located in the medial wall of the cerebral hemisphere, adjacent to the pre-SMA ( ). The ventral (limbic) tier occupies the surface of the cingulate gyrus, corresponding to Brodmann’s areas 24a and 24b, and subcallosal area 25. The dorsal (paralimbic) tier is buried in the cingulate sulcus, corresponding to Brodmann’s areas 24c and 32 (for review, see  ). The dorsal tier is involved in volitional motor control ( ;  ;  ). 

The ACC and cerebellum constitute a tightly connected corticocerebellar network. Recent functional connectivity analysis studies have demonstrated that distinct cerebellar seed regions in the anterior portion of the crus I exhibit functional connectivity with the dorsolateral prefrontal cortex, the rostral portion of the inferior parietal lobule, and a frontal midline region bordering the pre-SMA and ACC in healthy adults ( ;  ). Conversely, the ACC exhibits a negative correlation with the cerebellum ( ), possibly reflecting its hypothesized role in the inhibition of prepotent stereotyped responses ( ;  ). In terms of anatomic connectivity,   used diffusion MRI to demonstrate disruption of WM connectivity between the cerebellum and the cingulate cortex in individuals with Friedreich ataxia, an autosomal recessive disease involving degeneration of the spinal cord and cerebellum, thereby supporting the notion of reverse cerebellar diaschisis ( ). 

The corticocerebellar–thalamocortical circuit involving the cerebellum and ACC plays a role in attention. The cerebellum is involved in attention, including anticipation/prediction of the internal conditions for a particular operation, as well as the setting of specific conditions in preparation for that operation ( ;  ).   reported that patients with schizophrenia exhibited an attenuated response of the ACC and cerebellum to degradation of the target during a continuous performance task, paralleling their limited visual attentional resources. They also observed disruption in the pattern of task-related connectivity of the ACC to the prefrontal regions.   concluded that attentional impairments associated with schizophrenia could be attributed to the corticocerebellar–thalamocortical circuit, which includes the ACC and cerebellum. Considering the role of the ACC and cerebellum in sensorimotor and attentional control, the ACC–cerebellar network may constitute a reactive–predictive controller system ( ) by which one’s own attention-contingent motor output (that is, eye-blink) is modulated by the visual input of the partner’s movement. Under the mirror configuration during the LIVE condition, the reactive–predictive controllers in two individuals work to coordinate their own behavior with the partner’s. Thus, it closes the sensorimotor circuits across the individuals. 


### Enhanced connectivity between the ACC and AIC 
  
We observed enhanced effective connectivity from the ACC to the right dAIC in the LIVE condition than in the REPLAY condition. In the present study, no emotional processes were included in the task, suggesting that the enhancements in connectivity were related to recurrent interaction via eye contact. The ACC has a strong connection to the AIC ( ;  ), most prominently in the dAIC ( ), a central hub in which several different cognitive networks converge ( ;  ). The ACC–AIC network represents the portion of the limbic mirror system related to the recognition of affective behavior ( ;  ;  ). 

 proposed that the AIC and ACC represent the basis of self-awareness by constituting the input (AIC) and output (ACC) components of a system. In such a system, the integrated awareness of cognitive, affective, and physical states first generated by the integrative functions of the AIC are then re-represented in the ACC as a basis for the selection of and preparation for responses to inner or outer events.   regarded the AIC as the probable site for awareness, based on its afferent representation of “feelings” from the body, and the ACC as the probable site for the initiation of behaviors.   proposed a “like-me” framework for the understanding of others. He suggested that imitation enables the understanding of another mind based on an understanding of actions and their underlying mental states.   observed that pain empathy relies on neural structures that are also involved in the direct experience of that emotion [i.e., the limbic mirror system (ACC, AIC)]. This finding is consistent with the Simulation Theory, which proposes that “we understand other people’s minds by using our mental states to simulate how we might feel or what we might think in a given situation” ( ).   concluded that perceiving the states of another activates neural representations encoding each state when it is experienced personally. In the eye-contact state, participants are aware that they are attending to their partner during eye contact. Therefore, given that the ACC–AIC network represents self-awareness, its activation during real-time eye contact may represent a shared mental state (i.e., awareness involving the participant and partner) such as shared attention. This interpretation is consistent with a study by  , which demonstrated that autonomic arousal is enhanced by eye contact with a live human, but not with static images of faces. The authors argued that this might be due to the enhancement of self-awareness by the presence of another person. The results of our study suggest that the self-awareness is enhanced by the social contingency generated with live humans through the interaction of each other’s attentional windows via eye-blinks and that the regulation of self-awareness by interaction might be caused by the cerebellar–cerebral networks that tap into the limbic mirror system. 


### Interbrain synchronization 
  
By comparing the degree of interbrain synchronization between the LIVE and REPLAY conditions, we found an enhancement in the MOG region related to the LIVE condition. This region is in the lateral occipitotemproral cortex (LOTC) and is almost identical to the region that shows interbrain synchronization specific to the eye-contact state ( ). Previous studies suggest that the LOTC receives both sensory inputs of a partner’s behavior ( ) and efference copies of one’s own behavior ( ;  ). Therefore, the roles of the LOTC in supporting action perception and overt action performance are closely related. The LOTC may play a role in the human action observation network ( ) that is typically attributed to the frontoparietal mirror system ( ). Thus, the MOG region may conceivably receive information about self and other’s eye-blinks. 

Based on the electroencephalography (EEG) hyperscanning experiment of the mutual gaze between mothers and infants,   found interpersonal neural synchronization. They argued that the phase of cortical oscillations reflects the excitability of underlying neuronal populations to incoming sensory stimulation ( ), a possible mechanism for temporal sampling of the environment ( ). Interpersonal neural synchronization could increase within a dyad during the course of social interaction because each partner is continuously producing salient social signals (e.g., gaze) that act as synchronization triggers to reset the phase of his or her partner’s ongoing oscillations ( ). The present study showed neural synchronization in the LOTC, which receives both visual input of others’ actions and efference copies of one’s own actions. The salient social signals were sent to the partner through gaze or blink (defining the temporal attentional window), and the motor command corresponding to which is likely delivered to the LOTC as an efference copy. The eye-blink may, thus, act as a synchronization trigger. Therefore, the cross-individual neural synchronization of the MOG represents the alignment of the temporal pattern of attention, which may optimize communicative efficiency ( ). 


### Limitations and future directions 
  
The present study is subject to several limitations. First, concerning the hyperscanning fMRI experimental design, the very long mutual gaze condition was not ecological and may be quite different from conceptions of “mutual gaze” or “eye contact” informed by daily life. This is due to our use of a blocked design, the most effective way to detect brain activation. Also, the product of our experimental design, estimations of the temporal dynamics of eye-blink entrainment, brain activation, and interbrain synchronization, could not be performed. While we could not find a significant effect of session on the eye-blink entrainment in real-time eye contact, it is possible that the eye-blinking entrainments only occur in the very first phase of mutual gaze condition in one block. By refining the experimental and analytical design, we may further gain insight into the dynamics of interindividual interaction through eye-contact and interbrain synchronization. To explore the temporal dynamics of interbrain synchronization, we are currently conducting a hyperscanning simultaneous EEG-fMRI recording that could integrate the merits of the two neuroimaging methods ( ). As the present study demonstrated the efficacy of using Akaike causality analysis to evaluate dynamic mutual interaction, future studies applying this method to EEG data in ecological settings of normal and diseased populations are warranted. 

The present study is also limited by its capacity to find interbrain synchronization only between homologous regions, but not between nonhomologous regions (i.e., frontoparietal synchronization;  ). In our setting, two participants play identical roles in eye-to-eye communication; therefore, the resonance through interbrain closed loop might occur in the homologous regions. However, the interbrain effect may also occur between nonhomologous regions. To explore this possibility, an ROI analysis based on the precise parcellation of human cerebral cortex in a human connectome project may be the most suitable ( ). Future studies adapting this method could reveal the mechanism underlying the means by which two brains are wired through eye-to-eye communication without any conscious awareness. 


### Summary 
  
In the present hyperscanning fMRI study, we focused on real-time mutual interaction during eye contact. The open-and-close timing of the attentional window, defined by eye-blinks, was entrained to that of the counterpart during real-time mutual interaction. Our findings indicate that the social interaction is nonlinear, and the influence from the partner might be amplified by the nonlinearity during the real-time interaction. Corresponding with the nonlinearly amplified behavioral coordination, real-time interaction during eye contact was found to be mediated by the amplified activation of the cerebellum and the cingulate motor cortex. This was accompanied by enhanced connectivity within the limbic mirror system. These findings underscore the notion that real-time eye contact generates an emergent property of shared attention, which is mediated by a cerebellocerebral network inclusive of the limbic mirror system. 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-15'>
<h2>15. PMID: 32059228</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Hyperfunctioning of the right posterior superior temporal sulcus in response to neutral facial expressions presents an endophenotype of schizophrenia</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Neuropsychopharmacology</p>
<p><strong>Publication Year:</strong> 2020</p>
<p><strong>DOI:</strong> 10.1038/s41386-020-0637-8</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Study used fMRI while participants performed a social-cognitive task (neutral face processing, emotion recognition, affective ToM). Sample comprised healthy, screened adult participants with no history of mental/neurological disorder (consented, ethics-approved). Whole-brain analyses were conducted and reported (FWE-corrected results for task effects and group comparisons), not ROI-only. Exclusion criteria (psychiatric/neurological samples, reviews, ROI-only reporting) are not met. Age range not explicitly reported but participants were adult undergraduates/healthy adults and ethically consented; this creates minor uncertainty reflected in confidence <1.0. Overall meets all inclusion criteria for fMRI studies of social-related processing in healthy adults with whole-brain results.</p>
<p><strong>Fulltext Confidence:</strong> 0.85</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Deficits in social cognition have been proposed as a marker of schizophrenia. Growing evidence suggests especially hyperfunctioning of the right posterior superior temporal sulcus (pSTS) in response to neutral social stimuli reflecting the neural correlates of social-cognitive impairments in schizophrenia. We characterized healthy participants according to schizotypy (  n   = 74) and the single-nucleotide polymorphism   rs1344706   in ZNF804A (  n   = 73), as they represent risk variants for schizophrenia from the perspectives of personality traits and genetics, respectively. A social-cognitive fMRI task was applied to investigate the association of right pSTS hyperfunctioning in response to neutral face stimuli with schizotypy and   rs1344706  . Higher right pSTS activation in response to neutral facial expressions was found in individuals with increased positive (trend) and disorganization symptoms, as well as in carriers of the risk allele of   rs1344706  . In addition, a positive association between right–left pSTS connectivity and disorganization symptoms during neutral face processing was revealed. Although these findings warrant replication, we suggest that right pSTS hyperfunctioning in response to neutral facial expressions presents an endophenotype of schizophrenia. We assume that right pSTS hyperfunctioning is a vulnerability to perceive neutral social stimuli as emotionally or intentionally salient, probably contributing to the emergence of symptoms of schizophrenia. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (28623 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Social-cognitive impairments have been proposed to present a marker of schizophrenia [ – ]. The impairments occur in different domains of social cognition, ranging from deficits in neutral face processing [ ,  ], emotion recognition [ ], up to complex social-cognitive processes [ ], like inferring others’ mental states, known as theory of mind (ToM) [ ], and are highly important for social functioning [ ]. The association of these deficits to enhanced activity and connectivity of the right posterior superior temporal sulcus (pSTS [ ,  ]) makes aberrant pSTS functioning during social cognition a highly promising endophenotype candidate for schizophrenia. 

Several regions of the brain are central to social-cognitive processing, including amygdala, medial and inferior frontal cortex, insula, fusiform gyrus, as well as pSTS [ ,  ]. Most of these regions have been both found to be affected structurally [ ], as well as functionally [ ,  ] in schizophrenia. For investigating the neural correlates of social-cognitive impairments in schizophrenia, we [ ] developed a social-cognitive task that assesses several aspects of social cognition (namely neutral face processing (NFP), emotion recognition (ER), and affective ToM (aToM)) using facial expressions as stimuli. Applying this task, we found activation in key regions of social-cognitive processing in healthy participants [ ]. In addition, hyperactivity in the right pSTS during NFP, but not during aToM, was revealed in two independent samples of patients with schizophrenia [ ,  ]. Furthermore, we found hypoconnectivity between the right and left pSTS for aToM, and a relative hyperconnectivity between the right and left pSTS for NFP [ ]. Other authors also [ ,  ] showed hyperconnectivity of the pSTS in emotionally and intentionally neutral conditions of social-cognitive paradigms. Since the pSTS is a core area of social cognition and prominently involved in inferring other’s intentions [ ] (also Schmidt et al., unpublished data), increased pSTS activation during NFP might be interpreted as a vulnerability for false-positive perceptions of intentions, also called hypermentalizing [ ]. 

Imaging genetics studies with healthy participants and with relatives of patients with schizophrenia provided further evidence for aberrant pSTS functioning during social cognition as an endophenotype of schizophrenia. ZNF804A, a zinc-finger protein, presents an odds ratio of 1.08 (0.92–1.26 95% CI) for schizophrenia samples [ ]. One of its single-nucleotide polymorphisms (SNPs,   rs1344706  ) [ ,  ] was identified in whole-genome association studies as the first common genetic variant associated with schizophrenia [ ,  ].   Rs1344706   is involved in regulating gene expression [ ], and has been linked to executive functioning [ ] and social cognition [ ]. Imaging genetics findings from two healthy samples suggest that activity and connectivity of the STS and adjacent temporoparietal junction are associated with variation in   rs1344706   in a mentalizing task with sketches [ ,  ]. Further, healthy relatives of patients with schizophrenia showed aberrant activation in this task. Family members had reduced activation in the medial prefrontal cortex during mentalizing, but increased activation in the posterior cingulate cortex and right middle temporal gyrus. Interestingly, activation in right middle temporal gyrus during mentalizing correlated positively with self-reported paranoid ideation [ ]. These findings are exemplary of the approach to identify endophenotypes by investigating variations of traits of a disease in healthy participants. 

Schizotypy as part of the schizophrenia spectrum is a valuable construct that refers to personality structures spreading dimensionally throughout the population [ ,  ], but can also present as a personality disorder [ ]. Schizotypy can be characterized by a three-factor model of sub-threshold psychotic symptoms, including positive (e.g., ideas of reference), negative (e.g., no close friends), and disorganization symptoms (e.g., eccentric behavior). Several studies have consistently revealed an association between schizotypy and the development of a psychotic disorder (for a review please see ref. [ ]). A longitudinal study reported that 9% of an at-risk sample had a transition to schizophrenia within 12 months, and suggested self-reported schizotypy presenting the most reliable scale-based predictor [ ]. In addition, accumulating evidence points to schizotypy and schizophrenia having common genetic [ ], neuroanatomical [ ], and neurocognitive [ ] abnormalities, which again highlights the strong associations between schizotypy and schizophrenia. Importantly, as in schizophrenia, schizotypy has been associated with different kinds of social-cognitive deficits [ ,  ]. 

To date, only two fMRI studies have investigated the association between neural correlates of mentalizing and schizotypy in healthy participants. Both studies found right pSTS activity for mentalizing varying with schizotypy [ ,  ]. However, whereas one [ ] revealed negative symptoms to be positively related to right pSTS activation during mentalizing, the other [ ] showed a positive association with positive symptoms. In these studies, different tasks and accordingly different stimulus materials were used to investigate ToM, possibly explaining the divergent results. An even more general and crucial aspect when comparing social-cognitive studies, however, is not only the selection of stimulus material but also of the control condition (ranging from emotionally neutral analogs of the experimental condition to completely nonsocial conditions), which is usually subtracted from the higher-order social-cognitive process. Therefore, divergent findings in prior studies might be explained by differences in brain activation in the control condition between participants with and without schizophrenia risk. 

To summarize, deficits in social cognition are proposed to present a marker for schizophrenia [ ], and aberrant pSTS functioning during social cognition is a promising endophenotype of schizophrenia [ ,  ]. In this imaging genetics study, we applied a social-cognitive fMRI task [ ,  ] that assesses different social-cognitive processes, and has consistently revealed right pSTS hyperactivation during NFP, but not during mentalizing, in patients with schizophrenia [ ,  ]. We aimed at investigating whether we find in healthy participants a comparable activation and connectivity pattern as in schizophrenia, depending on the   ZNF804A rs1344706   risk allele, and schizotypy. This allowed us to assess possible pSTS hyperfunctioning unconfounded of medication status, or chronicity of disease. For both   ZNF804A rs1344706   risk allele and schizotypy, previous studies found a relationship to aberrant pSTS activation during mentalizing [ ,  ,  ,  ], but the response to neutral facial expressions was not investigated. We hypothesized that activation and connectivity of the right pSTS in response to neutral facial expressions in healthy participants is positively associated with (1) the risk allele of the   rs1344706   genotype and (2) higher self-reported schizotypy. 


## Materials and methods 
  
### Participants 
  
Of 81 healthy participants, seven were excluded for the present analyses: five due to low fMRI data quality, one due to a BDI-II [ ] score >18, and one due to schizotypy scores >3 SD above the group mean. For the genetics analyses, one additional participant was excluded because genotyping for rs1344706 was not possible. Therefore, we included 74 participants (40 females, see Table  ) in the behavioral and imaging analyses and 73 participants (39 females) for the imaging genetic analyses. Participants were grouped for the imaging genetics analysis for the existence of the risk allele of schizophrenia [ ]; ZNF804A genotype groups: 62 AA/CA (risk-allele carriers and 11 CC non-risk-allele carriers). All participants were of German ancestry, had higher school certificate, were right-handed, had normal or corrected-to-normal vision and no self-reported background of mental or neurological disorders, or drug abuse. In addition, participants reported having no relatives with psychotic disorders.   
Characteristics of the sample. 
  
 SPQ   schizotypal personality questionnaire,   AA/CA   indicates the risk-allele carriers,   CC   indicates the non-risk-allele carriers. 
  

Prior to the study, participants were informed about study procedure and purpose and gave their written informed consent. The study was approved by the local ethics board of the Medical Faculty Mannheim, University of Heidelberg. The data reported here are part of a larger study on the human mirror neuron system that involved a measurement containing simultaneous EEG-fMRI with three tasks (including an imitation task, an empathy task, and the social-cognitive task presented here), blood-taking and a series of questionnaires, including the Schizotypal Personality Questionnaire (SPQ [ ], details are presented in the Supplementary Text  ), and a second measurement with transcranial magnetic stimulation prior to fMRI. The results reported in this paper are based on the fMRI data of the first appointment. 


### Experimental paradigm 
  
We applied a modified version of the social-cognitive task that was used in earlier studies with patients with schizophrenia [ ,  ]. The paradigm was extended to four conditions, including three levels of social cognition [lower-level social cognition (NFP), ER, and higher-level social cognition (aToM)], and a nonsocial control condition. In each trial of the social-cognitive conditions, a statement preceded a facial expression. These statements described the facial expressions referring to physical features (gender or age) for NFP, the emotional state (fear or anger) for ER, or the possible intention (running away or blustering) for aToM. For NFP, only neutral facial stimuli were shown, for ER and aToM only emotional facial expressions. The facial stimuli were taken from the Karolinska Directed Emotional Faces set [ ]. Half of the stimulus persons were male, and the same persons were used for each of the social-cognitive conditions. For the control condition, prior to a geometric figure (a triangle or a circle) a statement describing the figure (e.g., “This is a circle”) was displayed. Task duration was around 8 min (details of timing and presentation can be found in Fig.   and Supplementary Text  ).   
The social cognition fMRI task. 
  


### Genotyping 
  
Genotypes for   ZNF804A SNP rs1344706   were extracted from whole-genome genotype data obtained using Illumina Global Screening array and following stringent quality control (see Supplementary Text  ). 


### Imaging data acquisition and analyses 
  
The study was conducted with a 3-Tesla Siemens Tim TRIO whole-body magnetic resonance tomography (Siemens Medical Systems, Erlangen, Germany; acquisition protocol can be found in Supplementary Text  ). Brain activity and connectivity analyses were conducted with SPM8 (Wellcome Department of Imaging Neuroscience, Institute of Neurology, London, UK). Data preprocessing contained slice-time correction, realignment, co-registration to the structural image, spatial normalization (MNI template) with resampling to a 3 × 3 × 3 mm voxel size, and spatially smoothing with an 8 mm full-width half-maximum kernel. The first-level analyses were achieved by a general linear model with four regressors (aToM, ER, NFP, and control), and six motion parameters, derived from the realignment procedure, as covariates. The hemodynamic response function was modeled to the onset times of the pictures. The time series was high-pass filtered using a 128 Hz function. From the model, linear combinations of the regressors built the contrasts of interest, including effects of each higher against the lower social-cognitive condition (aToM > ER, ER > NFP), and each condition against control (aToM >control, ER > control, NFP > control). Connectivity analyses were applied using generalized psychophysiological interactions (gPPI [ ]), as implemented in the gPPI toolbox (  http://www.nitrc.org/projects/gppi  ) with a functional mask of right STS as seed region, produced from our previous comparison between aToM and ER in 40 undergraduate students [ ] (details of the gPPI analysis are reported in Supplementary Text  ). 

For second-level analyses, significance threshold for exploratory whole-brain analyses was   p   < 0.05 FWE-corrected,   k   = 10. We conducted one sample   t   tests to analyze the effect of each social-cognitive condition, and a within-subject one-way analysis of variance (ANOVA) to identify the neural correlates of increased social-cognitive processing (contrast: [aToM > control] > [ER > control] > [NFP > control]). Regression analyses were conducted to explore the associations between the factors related to schizophrenia (schizotypy and the rs1344706 risk allele) and right pSTS activation, and connectivity for the different social-cognitive conditions. Region of interests were right and left pSTS, as derived from an earlier study [ ]. These masks were also applied in our studies on patients with schizophrenia [ ,  ]. The significance threshold for the ROI analyses was set to   p   < 0.05 small volume corrected (svc),   k   = 10. Behavioral data were analyzed with SPSS version 23. Differences between the social-cognitive conditions in reaction times (RTs) or accuracy were analyzed with repeated measures ANOVA, post hoc tests were conducted with paired-samples   t   tests. Pearson correlation was applied to investigate possible associations among task conditions, and to test the associations between schizotypy and task performance. We conducted independent sample   t   tests to test genotype effects on task performance, as well as to investigate differences in self-reported schizotypy, depending on genotype. 



## Results 
  
### Behavior 
  
Similar to our previous studies [ ,  ,  ], RTs and accuracy differed significantly between conditions, with the control condition being the easiest and aToM being the most difficult task condition. Neither genotype nor schizotypy significantly affected task performance (detailed behavioral results are reported in Supplementary Text   and Supplementary Fig.  ). In addition, no significant differences in self-reported schizotypy were revealed, depending on the risk allele (see Table  ). 


### Imaging 
  
Replicating the results from our previous studies [ ,  ], activation increased linearly from NFP over ER to aToM in regions of the “social brain”, including bilateral superior temporal gyrus covering pSTS, bilateral inferior frontal gyrus covering BA44 (Fig.  ; detailed results of task effects are presented in Supplementary Table  ). Whole-brain analyses of right pSTS connectivity differences between conditions were not significant across participants. ROI analyses revealed greater pSTS connectivity between hemispheres for aToM compared with ER at the trend level (peak voxel: −57, −49, 7;   t   = 3.37,   p   = 0.069 svc,   k   = 10).    Neural correlates of distinct social-cognitive processes.  
 a)   neural correlates of increasing social-cognitive demands [with the contrast: (affective theory of mind > control) > (emotion recognition > control) > (neutral face processing > control)];   b)   affective theory of mind (> emotion recognition);   c)   emotion recognition (> neutral face processing);   d)   neutral face processing (> control condition). Significance threshold is   p   < 0.05, FWE-corrected,   k   = 10. 
  

#### rs1344706 
  
ROI analyses revealed that risk-allele carriers compared with non-risk-allele carriers had increased right pSTS activation during NFP (> control; peak voxel: 63, −58, 13;   t   = 3.19,   p   = 0.042 svc,   k   = 10, Fig.  ). No significant differences in pSTS activation were found for ER and aToM, and also right–left pSTS connectivity during all task conditions did not differ between risk-allele carriers and non-risk-allele carriers. In addition, whole-brain analyses with the given significance threshold revealed no significant group differences, neither in the activation nor in the connectivity analyses.    Associations between functioning of right posterior superior temporal sulcus for neutral face processing and schizotypy as well as rs1344706 genotype.  
The first two scatter plots show positive correlations between activation in the right posterior superior temporal sulcus (pSTS) for neutral face processing (> control) and   a)   disorganization, as well as   b)   positive symptoms;   c)   positive association of disorganization with right-to-left pSTS connectivity for neutral face processing (> control);   d)   genotype effect of increased activation in the right pSTS for neutral face processing (> control). Significance threshold for display purposes is   p   < 0.005 uncorrected,   k   = 10. Note: rpSTS stands for right posterior superior temporal sulcus, lpSTS stands for left posterior superior temporal sulcus. 
  


#### Schizotypy 
  
There was a trend for a positive association between right pSTS activation for NFP (> control) and schizotypy sum score (peak voxel: 63, −55, 10;   t   = 3.01,   p   = 0.065 svc,   k   = 10). There was also a significant positive association between activation in right pSTS and disorganization symptoms (peak voxel: 57, −55, 7;   t   = 3.54,   p   = 0.018 svc,   k   = 10, Fig.  ), and at the trend level with positive symptoms (peak voxel: 63, −55, 10;   t   = 3.94,   p   = 0.077 svc,   k   = 10, Fig.  ). ROI analysis also revealed a significant positive correlation between disorganization symptoms and right–left pSTS connectivity during NFP (> control; peak voxel: −45, −70, 22;   t   = 3.60,   p   = 0.038 svc,   k   = 10, see Fig.  ). Neither for ER nor for aToM were significant associations between schizotypy and pSTS activation, or connectivity found. In addition, whole-brain analyses with the given significance threshold did not reveal any significant associations of schizotypy with task-related brain activation and connectivity. 




## Discussion 
  
This study aimed at investigating whether pSTS functioning during social-cognitive processing is an endophenotype for schizophrenia. Confirming our hypothesis, we found a positive association of right pSTS activation for neutral face processing with schizotypy (in particular disorganization, and positive symptoms on a trend level), and also with a risk allele for schizophrenia. Furthermore, connectivity between the right and left pSTS during neutral face processing was positively associated with disorganization symptoms. 

The pSTS is consistently found to be involved in inferring goals and intentions [ ,  ,  ,  ]. Across participants, we replicated our previous findings showing decreased performance and increased activation in pSTS and BA44 with increasing social-cognitive demands. With this, our results again highlighted the role of pSTS functioning for inferring others’ intentions [ ]. Importantly, increased right pSTS functioning in our participants with schizophrenia risk allele and subclinical symptoms of schizophrenia was present only for neutral face processing, but not for higher-order social-cognitive conditions. This supports our previous findings and conclusions that impairments in higher-order social cognition in schizophrenia might originate in impaired basic social-cognitive processes [ ,  ]. Our results are also consistent with further previous findings with patients with schizophrenia. A recent study reported not only increased pSTS activation in response to the emotionally and intentionally neutral control condition in their social-cognitive task but also increased pSTS connectivity [ ]. These results add to the idea that pSTS dysfunction for neutral social stimuli might be regarded as neural basis for hypermentalizing, which may constitute a vulnerability to the emergence of delusion [ ]. 

But how could this pSTS hyperfunctioning in response to neutral facial expressions cause symptoms of schizophrenia? Kapur [ ,  ] proposed that psychosis, particularly delusions, result from aberrant attribution of novelty and salience to objects and associations, and that faulty attributions of salience arise due to chaotic, context-inappropriate firing of dopamine neurons. Delusions have been suggested to represent a deficit in encoding the precision of predictions and prediction errors [ ], indicating a bottom-up inappropriate perceptual input; i.e., aberrant salience. Supporting this idea, our results revealed a positive association between self-reported symptoms of schizotypy, as well as between the presence of a risk allele for schizophrenia, and activation in the right pSTS for neutral faces, and unveiled a positive association between disorganization and right-to-left pSTS connectivity. This might indicate that people with higher positive symptoms and a genetic risk for schizophrenia might be prone to perceive neutral faces as emotionally or intentionally salient. Whether these inappropriate perceptual inputs lead to delusions in turn could depend on how individuals interpret these false perceptions, pointing to the importance of a top-down cognitive explanation to delusions [ ,  ], and the impact of disorganization. When the cognitive explanation is interfered or interrupted due to executive dysfunction, the accumulating experiences of aberrant salience might gradually increase confusion and result in delusional ideas that are based on overinterpretation of emotions and intentions to neutral social stimuli. 

Together, our findings add to the perspective that delusions probably derive from dynamic interactions between bottom-up erroneous perception and top-down cognitive deficits, caused by increased responsiveness to emotionally and intentionally neutral social stimuli [ ]. Since all of our participants were without a history of mental disorders, we found alterations only on the level of neural functioning. Further studies with large patient samples that allow the analysis of subgroups are needed to investigate the validity of the proposed mechanisms in schizophrenia. 

Importantly, aberrantly high pSTS functioning in response to neutral social stimuli seems to be not “only” a marker of schizophrenia, but an endophenotype of schizophrenia according to the criteria characterizing an endophenotype proposed by Gottesman and Gould [ ]: (1) the endophenotype is associated with illness in the population: aberrant right pSTS functioning is consistently observed in patients with schizophrenia in response to stimuli and situations without emotional, or intentional meaning [ ,  ,  ,  ,  ,  ]. Our current results show a comparable neural pattern in healthy participants with increased proneness to schizophrenia, illustrating an association of right pSTS dysfunction with schizophrenia symptoms also in healthy participants. (2) The endophenotype is heritable: in line with previous studies showing aberrant pSTS functioning in schizophrenia risk-allele carriers [ ,  ], we found increased right pSTS activity in response to the neutral condition in   rs1344706   risk-allele carriers, possibly reflecting one aspect of the heredity of the right pSTS dysfunction. (3) The endophenotype should be state-independent: we found the neural pattern first in schizophrenia out-patients who were remitted from positive pathology [ ], then in in-patients with schizophrenia [ ], now even in healthy participants carrying the psychosis allele, suggesting that right pSTS dysfunction might represent a state-independent neural pattern for schizophrenia. (4) Within families, endophenotype and illness co-segregate: increased engagement of right pSTS varied with positive symptoms in patients with schizophrenia’ relatives [ ], suggesting that right pSTS dysfunction and schizophrenia symptoms co-segregate within families. However, studies systematically investigating differences in pSTS functioning between relatives of patients with schizophrenia are pending. (5) The endophenotype in affected family members is found at a higher rate in non-affected family members than in healthy participants: While hyperfunctioning was observed in relatives of patients with schizophrenia who reported positive symptoms, it is also found in non-affected family members at a higher rate than in healthy participants without familial risk for schizophrenia [ ]. In addition to the criteria initially proposed by Gottesman and Gould, a further criterion has been put forward [ ]: (6) the endophenotype should be a trait that can be measured reliably, and ideally is more strongly related with the disease of interest than with other psychiatric conditions: aberrant activation in the right pSTS was consistently revealed by our social-cognitive task in patients with schizophrenia [ ,  ] and also in the current study in healthy participants with increased schizophrenic proneness, but not in patients with borderline personality disorder [ ]. In addition, especially in patients with schizophrenia with paranoid symptoms, pSTS activity during a neutral condition was higher than in patients with autism [ ,  ], highlighting that dysfunction in right pSTS is not only a reliably assessable trait but might be specific to schizophrenia. Thus, there is extensive evidence supporting the idea that hyperfunctioning of pSTS to neutral social stimuli represents an endophenotype for schizophrenia. 

Despite the reported studies consistently finding genotype effects on brain activation and connectivity [ ,  ], they, like this study, tested only one risk SNP’s effect. In addition, since genetic penetrance is higher for endophenotypes than phenotypes [ ]; i.e., significant association between the risk allele and right pSTS functioning, but no significant association between the risk allele and schizotypy, several approaches would be of interest for future studies to validate our findings and to investigate the proposed mechanisms: (a) investigating the load of risk SNPs to reveal biological subcategories of schizophrenia [ ], (b) due to unequal distribution of risk-allele presence (only 11 participants homozygous for the non-risk allele), replication of the finding with pre-selection of participants depending on their genotype, (c) replicating the marginally significant association of positive symptoms and right pSTS activation with different approaches to assess schizotypy, such as the Oxford-Liverpool Inventory of Feelings and Experiences [ ], (d) targeting not only right pSTS activation and connectivity, but also of further regions that are central for social-cognitive processing (e.g., amygdala, MPFC). Besides, some previous studies only reported hypo-functioning in the pSTS with regard to schizophrenia in response to higher-level social cognition (such as ToM) [ ,  ]. Whether these studies would also reveal pSTS hyperfunctioning if the neutral condition was investigated remains an open question. However, investigating pSTS hyperactivation in participants with schizophrenia risk can be challenging, because no significant pSTS activation in response to the neutral conditions is found across all participants, pointing to small effect sizes that warrant moderate to large sample sizes to reveal the effects. Moreover, some studies suggest aberrations in left pSTS instead of the right pSTS presenting an intermediate phenotype for schizophrenia [ ,  ]. Perner et al. [ ] proposed that the left pSTS is linked to perspective differences for mental and nonmental objects, while the right pSTS is associated with mental states. Future studies should approach the question of laterality with a systematic variation of social-cognitive processing to clarify the functioning of this region in schizophrenia. 

Taken together, our findings point to right pSTS hyperfunctioning in response to neutral faces as an endophenotype of schizophrenia. We assume that right pSTS hyperfunctioning presents a vulnerability to perceive neutral social stimuli as emotionally or intentionally salient and suggest that bottom-up and top-down aberrations interact to cause delusions via deficient social perception. 


## Funding and disclosure 
  
This work was supported by the Heidelberg Academy of Science and Humanities. Zhimin Yan is supported by the Chinese Scholarship Council. The authors declare no conflict of interest. Open access funding provided by Projekt DEAL. 


## Supplementary information 
  




 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-16'>
<h2>16. PMID: 31157395</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Investigation of functional brain network reconfiguration during vocal emotional processing using graph-theoretical analysis</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Soc Cogn Affect Neurosci</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1093/scan/nsz025</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study meets all inclusion criteria: it reports task-based whole-brain fMRI during a social-related task (perception of vocal emotional speech, a form of social/emotional processing). Participants were healthy adults aged 20–35 (N=36), which falls within the 18–60 range. Analyses are whole-brain: data were parcellated using the Power-264 atlas and graph-theoretical metrics and whole-brain functional connectivity (PC and covariance) are reported; results are not limited to region-of-interest only. The paper is an original empirical fMRI study (not a review/meta-analysis) and does not involve psychiatric or neurological patient groups. Therefore all inclusion criteria are satisfied and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Vocal expression is essential for conveying the emotion during social interaction. Although vocal emotion has been explored in previous studies, little is known about how perception of different vocal emotional expressions modulates the functional brain network topology. In this study, we aimed to investigate the functional brain networks under different attributes of vocal emotion by graph-theoretical network analysis. Functional magnetic resonance imaging (fMRI) experiments were performed on 36 healthy participants. We utilized the Power-264 functional brain atlas to calculate the interregional functional connectivity (FC) from fMRI data under resting state and vocal stimuli at different arousal and valence levels. The orthogonal minimal spanning trees method was used for topological filtering. The paired-sample   t  -test with Bonferroni correction across all regions and arousal–valence levels were used for statistical comparisons. Our results show that brain network exhibits significantly altered network attributes at FC, nodal and global levels, especially under high-arousal or negative-valence vocal emotional stimuli. The alterations within/between well-known large-scale functional networks were also investigated. Through the present study, we have gained more insights into how comprehending emotional speech modulates brain networks. These findings may shed light on how the human brain processes emotional speech and how it distinguishes different emotional conditions. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (37745 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Emotion is one of the crucial cognitive factors that affect our daily life and social interaction. Various facial and vocal expressions convey the emotion during social interaction. Thus, comprehending these emotional expressions and their underlying neural mechanism is essential to modern society and to build new communication technologies. Several prior neuroimaging studies have aimed to elucidate the neural mechanism foremotional processing; however, most of them have studied emotion based on facial expressions and visual stimuli ( ;  ). Of late, several neuroimaging studies have focused on vocal emotion. Functional magnetic resonance imaging (fMRI) studies have shown that emotional prosody (especially emotions such as anger) consistently activates amygdala as well as numerous brain regions in the lateral temporal lobe and frontal lobe ( ;  ;  ;  ). Additionally, electrophysiological [electroencephalography (EEG) and magnetoencephalography (MEG)] studies using event-related potentials have strived to delineate the neural dynamics related to the effects of vocal emotions. For example,   suggested that valence information is decoded during early processing, while arousal effects occur at a later stage of processing. 

In addition to changes in regional brain activity, emotional perception may also alter the interregional functional connectivity (FC) as well as the brain network topology. At the connectivity level, studies have employed FC analysis and investigated reorganized FC induced by emotional processing ( ;  ;  ;  ;  ). At the network level, the recent advancement in computational approaches, especially graph-theoretical analysis, has provided the means to characterize the brain network topology ( ). Several studies have used graph-theoretical analysis to investigate the alteration of brain networks when interpreting facial emotional expressions that have shown significant changes of global efficiency and clustering coefficient (CC) compared with the resting state ( ;  ). Compared with regional functional activation, connectivity-based and network-based studies may help us gain more insights into the neural mechanism of emotion and learn how emotion may modulate the cognition states. Currently, a growing body of evidence supports the affective workspace hypothesis, suggesting that either positive or negative affective state is not necessarily associated with activating a specific set of regions ( ;  ). Alternatively, it can emerge as ‘brain state’ at the population level. Therefore, to strengthen the validity of this hypothesis, it is essential to understand how emotion-related cortical regions interact during processing of emotional information. 

Several studies have explored the alteration of network topology due to facial emotional expressions, but not much is known about the effects of vocal emotional stimuli on brain networks at connectivity and network topological levels. Therefore, to explore the vocal emotion and its underlying neural mechanism, this study has the following three objectives. First, we sought to examine the feasibility of graph-theoretical analysis on fMRI data with vocal emotional stimuli. Second, we sought to explore whether vocal emotional stimuli induce any alteration of brain networks—at both network topological and connectivity levels. We also investigated the differences within/between well-known large-scale functional networks. Third, we sought to investigate whether there is any difference in network topology between the resting state and the ones induced by vocal emotional stimuli. 


## Materials and methods 
  
### Participants 
  
A total of 36 healthy volunteers (27 male and 9 female) participated in our study. Furthermore, to reduce the risk of possible confounding factors, the participants were recruited based on several criteria: being free of any brain disease or major brain injury, age ranging between 20 and 35 years and a college or higher-level education to understand the vocal emotion stimuli pronounced in English. Furthermore, we only recruited right-handed subjects to exclude any potential variability due to handedness. The Institutional Review Board at National Health Research Institutes approved this study, and all volunteers provided informed consent. 


### Experimental stimuli 
  
The vocal emotion stimuli were generated from part of the USC IEMOCAP database ( ). The audio data from IEMOCAP database consist of recordings of scripted or spontaneous speech during dyadic interaction between a pair of voice actors. Naive raters rated each recording with attributes including valence, arousal and dominance with the continuous rank from 1 to 5. For our study, we used the scripted dialogs by a chosen male voice actor whose recordings yielded the highest variability in the speech attributes among all voice actors. From 639 segments spoken by the selected voice actor, we selected 251 voice segments as the stimuli for our experiments. 

We categorized the stimuli into two types of emotional attributes, namely, arousal and valence, and designed three conditions for each feature. Each experiment comprised six 5 min vocal emotion stimuli and a 1 min break between any two stimuli. For the arousal attribute, the conditions were categorized into low (value ≤ 2.5), medium (2.5 < value < 3.5) and high (3.5 ≤ value) levels. For the valence attribute, the conditions were negative (value ≤ 2.5), neutral (2.5 < value < 3.5) and positive (3.5 ≤ value) levels. For each condition, the speech segments with the given attribute and level were shuffled to remove any contextual information and were then concatenated to form a 5 min continuous vocal emotional stimulus. The participants were asked to pay attention to the speech-based stimuli without being informed of the purpose or the details of the experiment. 


### Image acquisition 
  
MR experiments were performed on a 3T MRI scanner (Prisma, Siemens, Erlangen, Germany) at National Taiwan University. Each scanning session included T1-weighted imaging (T1WI), resting-state fMRI (rs-fMRI) and task-evoked fMRI (t-fMRI) of all vocal emotional stimuli. The T1WI protocol was employed using a magnetization-prepared rapid gradient-echo sequence with repetition time (TR) of 2000 ms, echo time (TE) of 2.3 ms, inversion time (TI) of 900 ms, flip angle (α) of 8°, voxel size of 1 × 1 × 1 mm , matrix size of 256 × 256 and 192 slices. Each fMRI scan with blood oxygen level-dependent (BOLD) contrast was acquired using gradient-echo echo-planar imaging sequence with TR/TE of 3000/32 ms, α of 90°, voxel size of 2.5 × 2.5 × 3 mm , matrix size of 96 × 96, 40 slices and 100 repetitions. 


### Data pre-processing 
  
Before network analyses, all rs-fMRI and t-fMRI data sets were pre-processed using DPARSF toolbox ( ). The pre-processing procedures included the removal of the first 10 volumes, slice-timing correction, co-registration to T1WI, covariate regression of head motion, white matter signals and cerebrospinal fluid signals, nonlinear spatial normalization using T1WI, linear detrending and band-pass filtering (0.01–0.1 Hz). To estimate the FC over the whole brain, brain regions were parcellated using the Power-264 functional atlas ( ), which comprises 264 putative functional regions-of-interest (ROIs) associated to 13 large-scale functional networks and a group of unlabeled regions ( ). We also provide the region definitions used in Automated Anatomical Labeling (AAL) atlas ( ) and reported the corresponding anatomical locations of functional ROIs using the definitions by the AAL atlas. The averaged time series of each putative functional ROI defined in Power-264 functional atlas was derived by averaging the pre-processed rs-fMRI signals within the ROI. The pairwise between ROI FC was derived by quantifying the temporal dependency between two extracted averaged time series. We computed two types of FC measures—Pearson’s correlation (PC) and covariance (COV). It should be noted that the negative FCs were excluded in the following analysis, i.e. only positive FCs were used. Subsequently, we employed the orthogonal minimal spanning trees (OMSTs) method on constructed FC matrices to filter out spurious connections ( ;  ). Briefly, the OMSTs iteratively extract the minimal spanning trees from a given graph, and the filtered graph is the aggregate of OMSTs that maximizes the global efficiency subtracted by the wiring cost of the brain network. Compared with the conventional sparsity thresholding method based on either a given FC value or a network sparsity, the OMSTs method is parameter-free and more reproducible in group-wise or even individual-level brain network ( ;  ). 
  
Abbreviations of the large-scale functional networks defined in Power-264 functional atlas 
  

### Graph-theoretical analysis 
  
After applying OMSTs, the graph-theoretical analysis was employed to derive both nodal and global graph-theoretical network measures from the filtered FC matrices. The nodal network measures used in this study are degree centrality (DC), CC ( ), local efficiency (E ) ( ) and PageRank centrality (PR) ( ). In addition to investigating the network attributes at nodal scale, we also examined the network attributes at the global scale—the whole brain—using a set of global graph-theoretical network measures. The global network measures in our study includes characteristic path length ( ), global efficiency ( ), mean local efficiency ( ), mean clustering coefficient ( ), transitivity ( ) ( ), modularity ( ) and assortativity coefficient ( ) ( ), in addition to the network wiring cost ( ). We provided the detailed definitions of network measures in the  . One can also refer to a previous review article for more details ( ). We also performed an analysis of complementarity among different network measures and provided the discussion in the  . 


### Statistical analysis 
  
In this study, we sought to explore the topological reconfiguration of t-fMRI networks with vocal emotional stimuli and rs-fMRI networks. By categorizing these vocal emotional stimuli into multiple arousal and valence levels, we further investigated the relationship within and between these levels, as well as their differences with the resting-state condition. The comparisons were performed at nodal network, global network and FC levels. As for each well-known large-scale functional network, we calculated the averaged nodal measures across its member ROIs, the averaged intra-network FC and inter-network FC connecting to other functional networks. Except the above analyses, we also performed the analysis of common connections across all subjects for each specific arousal, valence or resting-state condition and discussed in the  . All statistical analyses of the FC and graph-theoretical network measures were performed using the paired-sample   t  -test. All significant levels were subsequently adjusted for multiple comparisons jointly across 264 ROIs and 6 pairs of conditions (either resting-state and 3 arousal levels or resting-state and 3 valence levels) using Bonferroni correction. 



## Results 
  
### Investigation on nodal network measures 
  
 shows the statistical comparisons of the nodal network measures among different t-fMRI and resting-state conditions. Note that we denoted the type of FC in superscripts for a given network metric in the following sections. For example,   denotes the DC calculated using PC as definition of FC. For t-fMRI with arousal stimuli, significantly reduced   of low-arousal condition was found in an ROI (in STG.R) within the auditory network by comparing with resting-state condition. However, no significant differences among those arousal and resting-state conditions were found by using all nodal network measures derived from COV. For t-fMRI with valence stimuli, significant differences of nodal network measures were only found between neutral- and negative-valence conditions. Compared to neutral-valence condition, our results show decreased   in one ROI (located between MOG.L and IOG.L) within the visual network,   in one ROI (between DCG and SMA.L) within the hand sensory/somatomotor network and   in three ROIs (one in IOG.R, one between ITG.R and IOG.R and one between CUN.R an PCUN.R) in visual network of negative-valence condition. 
  
The statistical comparisons of nodal network measures among different task-evoked, (a) arousal stimuli and (b) valence stimuli and resting-state conditions. All   P  -values were corrected for multiple comparison across the arousal–valence levels by Bonferroni correction (  P   < 0.01;   P   < 0.001). For each ROI, both of the corresponding network in Power-264 atlas and the corresponding regions in Automated Anatomical Labeling atlas were shown. Please see   for abbreviations of AAL region 
    
The statistical comparisons of global network measures among different task-evoked, (a) arousal stimuli and (b) valence stimuli and resting-state conditions. All   P  -values were corrected for multiple comparison across the arousal–valence levels by Bonferroni correction (  P   < 0.01;   P   < 0.001) 
  

### Investigation on global network measures 
  
 shows the statistical comparisons of the global network measures among different t-fMRI and resting-state conditions. For t-fMRI with arousal stimuli, the high-arousal condition showed increased  ,  ,   and   compared to mid-arousal condition. The decreased   was also found in high-arousal condition compared to mid-arousal condition. Compared to low-arousal condition, increased   was found in high-arousal condition. However, no significant between-condition difference of global network measures was found by utilizing  as definition of FC. For t-fMRI with valence stimuli, significant between-group differences of global network measures were found mainly in negative-valence condition compared to other valence or resting-state conditions. For utilizing COV as FC definition, the altered global network measures includes increased   and decreased   (compared to all other conditions), decreased  ,   and   (compared to resting-state and neutral-valence conditions). For utilizing PC as FC definition, decreased  ,  ,   and increased   (compared to neutral-valence condition) were found. No significant between-condition difference of  ,   nor   was found among all comparisons. 


### Investigation on interregional FC 
  
In addition to network metrics—either nodal or global—we also performed the between-condition comparisons of interregional FC (PC based and COV based). For arousal stimuli, significant between-condition differences were found by using PC-based FC, while no significant between-condition differences were found by using COV-based FC. Compared with resting-state condition, significantly reduced PC-based FC were found in either low- or high-arousal condition for Aud, SM.M, SM.H, DA, VA and Vis networks, as shown in  . For valence stimuli, significant between-condition differences were found by using both PC-based and COV-based FC. By comparing the resting-state and positive-valence conditions, the significantly different connection with PC-based FC was found between DA and DMN. Most of the significant between-condition differences were found to associated with reduced FC in negative-valence condition, including Vis-FP (resting-state > negative-valence; neutral-valence > negative-valence), Vis-DMN (resting-state > negative-valence), SM.H-Vis (neutral-valence > negative-valence), SM.M-CO (neutral-valence > negative-valence) and DA-Vis (neutral-valence > negative-valence). Two significantly different connections with increased FC in negative-valence condition were found in intra-DMN (resting-state < negative-valence) and SM.H-CO (positive-valence < negative-valence). For COV-based FC, a significantly different connection was found between DMN and Vis (negative-valence < neutral valence;  ). 
  
Significant changes of FC associated with arousal stimuli and resting state. Blue and red lines signify decrease and increase of connectivity in the latter condition compared with the former condition, respectively. For having a better visualization, the ROIs are reordered and colored according to their correspondence to the large-scale functional networks. Please see   for the abbreviations of the functional networks. Note that we excluded CB in the illustration. All FCs are corrected for multiple comparisons across arousal levels using Bonferroni correction. 
    
Significant changes of FC associated with valence stimuli and resting state. Blue and red lines signify decrease and increase of connectivity in the latter condition compared with the former condition, respectively. For having a better visualization, the ROIs are reordered and colored according to their correspondence to the large-scale functional networks. Please see   for the abbreviations of the functional networks. Note that we excluded CB in the illustration. All FCs are corrected for multiple comparisons across valence levels using Bonferroni correction. 
  

### Investigation on large-scale functional networks 
  
 shows the statistical comparisons of averaged nodal network measures within well-known large-scale functional networks among different conditions. No significant difference was found in the arousal condition. In contrast, significant differences of averaged nodal network measures were found to be mostly associated with negative-valence condition. Compared with the neutral-valence condition, decreased averaged nodal network measures were found in negative-valence condition, including   and   in SM.H,   in DMN and  ,   and   in Vis for both FC definitions. Additionally, increased   in MR and decreased   in Vis were found in negative-valence condition by comparing with the neutral-valence and resting-state conditions, respectively.   shows the inter-network and intra-network comparisons of FCs. The alterations of FCs were only found in t-fMRI with valence stimuli, and most of them were associated with the negative-valence condition. A total of five inter-network alternations of PC-based FC were found, including VA-Sub (resting-state < positive-valence), CO-DA (positive-valence < negative-valence), Sub-FP (positive-valence < negative-valence), Aud-SM.M (neutral-valence > negative-valence) and Vis-DA (neutral-valence > negative-valence). In contrast, the only intra-network alteration was found in Vis (neutral-valence > negative-valence) by using COV-based FC. 
  
The statistical comparisons of averaged nodal network measures within large-scale functional networks among different task-evoked and resting-state conditions. All   P  -values were corrected for multiple comparison across the arousal–valence levels by Bonferroni correction (  P   < 0.01;   P   < 0.001). 
    
Significant changes of averaged intra-network or inter-network FCs with respect to the 12 large-scale functional networks (without CB and unlabeled) associated with the valence stimuli and resting state. Both PC- and COV-based FCs were investigated. Blue and red lines signify decrease and increase of connectivity in the latter condition compared with the former condition, respectively. For having a better visualization, the ROIs are reordered and colored according to their correspondence to the large-scale functional networks. Please see   for the abbreviations of the functional networks. All FCs are corrected for multiple comparisons across valence levels using Bonferroni correction. 
  


## Discussion 
  
Our study demonstrates that perception of emotional speech could modulate brain network topology in several cortical regions associated with emotion processing. We also found the altered global network topology among different task-based and resting-state conditions. Beyond regional level, we further investigated the alterations of network metrics and FCs within/between large-scale functional networks and reported our findings. To our knowledge, this is the first study that investigates the effects of vocal emotional stimuli on brain network topology using graph-theoretical analysis of fMRI data. These findings may shed light on how the human brain processes emotional speech and how it distinguishes different emotions. In the following sections, the results from our analysis and their interpretations are elaborated. Also, the limitations of the experimental design and data interpretation are discussed. 

### Task-related alterations in nodal network measures 
  
Results for valence stimuli revealed a tendency that the network topology was significantly altered under the negative-valence condition compared with that of neutral valence or resting state, suggesting that the negative-valence stimuli may modulate or reorganize the brain network. In addition, we should note that alterations of averaged network measures in the large-scale functional networks are highly consistent with that by investigating individual ROIs, further supporting our findings. One interesting finding from the experiments with valence stimuli was that the reductions of functional segregation (  and  ) were observed in the visual network. These alterations were observed in several individual ROIs in visual network and from investigating the averaged measures in visual network. A meta-analytic review by   has reported that a group of visual sub-regions would be activated under visual emotional stimuli. Furthermore, we hypothesized that these visual sub-regions could be stimulated by not only visual stimuli but also other modalities. A similar hypothesis has been introduced in an fMRI study by   in which activation in CUN was observed under attended anger prosody compared with neutral or unattended anger prosody. Therefore, we speculated that the alteration of network topology may be resulted from the complex cross-modal interactions during emotional processing. One possible explanation about cross-modal interactions in our case is the visual mental imagery triggered by the speech stimuli. A previous fMRI study showed that the mental imagery evokes greater emotional response than verbal representation ( ). Another fMRI study by   also revealed that the visual imagery is crucial for sentence comprehension. Essentially, the theory of multimodal mental imagery has been supported by a growing body of evidence. For instance, an fMRI study by   showed that using silent visual speech stimulus (facial videos during speech overlaid with written pronunciation) could activate primary auditory cortex. Other than visual mental imagery, a few studies have also reported different kinds of cross-modal interactions during emotional processing.  ,   have reported that visual attention could be modulated by anger prosody. Another EEG study by   also showed that the cross-modal prediction of emotion exists in the multimodal processing of audiovisual emotion. Based on these previous studies, we could suggest that a similar cross-modal interaction mechanism to alter the network topology might also be revealed in visual sub-regions. However, a more sophisticated experimental design in further study would be needed to verify our speculation. 

We also observed significantly reduced nodal functional segregation (  and  ) in the sensorimotor network by comparing negative-valence and neutral-valence conditions. These alterations were found in one ROI in the hand sensorimotor network and by investigating the averaged network measure of the mouth sensorimotor network. Consistently, previous studies have also reported the association of sensorimotor network with speech, language and emotional processing ( ;  ;  ). A study using transcranial magnetic stimulation suggested the role of supplementary motor area in movement control triggered by emotional stimuli ( ). An fMRI study showed that the vocal emotion was associated with the BOLD responses in emotion, attention and sensorimotor circuits, in addition to the inter-subject synchronization within somatosensory and supplementary motor cortices ( ). Intense emotion can trigger corresponding physiological and bodily response through sensorimotor and visceral nervous systems ( ;  ;  ). Therefore, it is reasonable to speculate that the alterations in sensorimotor network were likely due to the increased demand for physiological and bodily emotion response. 


### Task-related alterations in global network measures 
  
Our results showed that vocal emotional stimuli altered not only nodal network measures but also global network measures. For arousal stimuli, significant increases of functional integration (increased   and decreased  ) and segregation (increased  ,  , and  ) were found in high-arousal condition compared with low- and mid-arousal conditions. For valence stimuli, significantly reduced functional integration and segregation were found in negative-valence condition compared with all the other conditions (neutral valence, positive valence and resting state). We hypothesized that the brain network for processing emotional speech with high-arousal condition might intrinsically exhibit distinct level of functional integration and segregation as compared with other conditions or resting state. In this case, the brain network under high-arousal condition may show higher degree of integration and segregation, while the task-negative resting-state network is being suppressed. However, the brain network under low- or mid-arousal condition may be presented as a mixed pattern of task-positive and resting-state networks. Having different combinations of task-positive and resting-state networks may contribute to our speculation about the altered global network topology between high-arousal and the other two arousal levels. 

Similarly, the brain network to process the negative-valence vocal emotion stimuli may be characterized by reduction in network integration and segregation. Our results generally showed reduced network integration and segregation in negative-valence conditions compared with the resting state. Previous studies have attempted to understand the underlying mechanism and investigate the relationship between task-specific and resting-state networks further.   compared the global network measures of a task-general and meta-analytic coactivation network to a group-averaged resting-state network and reported reduced clustering, reduced modularity and increased efficiency. Recently,   used binarized PC matrix for studying the change of brain network topology under seven different kinds of functional tasks, which showed significant increases in global efficiency in all functional tasks compared with resting state. Another specific study by   investigated the network topology during the semantic matching task and resting state using binarized correlation matrices. Their results showed reduced global efficiency, reduced normalized global efficiency, increased E  and increased nodal centrality.   used alphabet recognition tasks and discovered reduced normalized CC compared with that of resting state. Although the experimental designs and targeted network measures of these previous studies do not converge in details, a general tendency that we could summarize from these studies is that most task-related networks would exhibit increased efficiency—in contrast to our findings. This controversy may arise from experimental designs, pre-processing of graph theoretical analysis, computation of network measures and statistical comparison approaches. A further study is needed to clarify these effects of data processing. 


### Task-related alterations in FC 
  
Our results also showed altered interregional FC in several connections. For arousal stimuli, reduced FC was mostly found in those connections associated with the auditory network, mostly involving superior temporal gyrus (STG). This finding may suggest that the reduced FC centered to these regions could be a result of configuration switching between resting-state and task-positive networks. Several sub-regions within STG, e.g. primary auditory cortex and Wernicke’s area, are known to be responsible for processing auditory and language information. Functionally, STG is responsible for language processing, which may also contribute to the altered FC under task-related conditions ( ;  ). In our current results, the altered FC related to STG may reflect that the patterns of network topology are different between vocal emotion modulation and resting state. However, our results cannot fully explain the association between STG and vocal emotional processing. Other than STG, we also observed that the   and   in TPOmid.R under high-arousal condition were significantly lower than those under mid-arousal condition. Interestingly, previous studies have suggested the temporal pole was associated with the social and emotional processing, including face recognition and theory of mind ( ;  ). Although the association between the temporal pole and vocal emotional processing is not clear yet, we could speculate that the arousal levels of vocal emotion stimuli may alter the network topology and result in altered nodal network characteristics in temporal pole. For valence stimuli, significantly reduced COV-based interregional FC and mean intra-network FC was found in several connections within the visual network by comparing negative-valence to neutral-valence conditions—consistent with our findings in the nodal network topology, further supporting our hypothesis of cross-modal mental imagery altering the network topology in visual-associated regions. We should note that the alterations of averaged network measures in the well-known large-scale functional networks and mean inter-network/intra-network FCs were highly consistent with those observed by investigating individual ROIs, especially in the visual and sensorimotor networks. The observations among large-scale functional networks further solidified our findings in FCs, nodal and global network metrics. 


### Investigation on complementarity of network measures 
  
Since we incorporated a series of nodal and global network metrics that may be used to quantify similar network topological characteristics in theory, it was of great interest to explore the complementarity between these network metrics. How they complement each other to form a more concrete delineation of the overall brain network topology would be beneficial for our current study. Thus, we also analyzed the similarity between different nodal network metrics using correlation analysis and also compared these between-metric similarities from two different pre-processing procedures, i.e. OMSTs and sparsity thresholding (see   for details). Our results generally showed that the network metrics used to characterize the same topological attribute could be highly correlated even if they have different theoretical definitions. For example, E  was calculated based on the shortest path length and CC was based on triangles; however, these two metrics were highly correlated in our case. Although these metrics were highly correlated, E  revealed more between-condition differences than other metrics that also measured the functional segregation in this study. We could summarize that, in our study, the network metrics for characterizing the same topological attribute could still provide complementary information, e.g. sensitivity to differentiate subtle alterations between conditions, even if they were highly similar in their quantities. It would be beneficial if all metrics were calculated and included in providing more insights into the complex brain network architectures. 


### A comparison between PC- and COV-based FC 
  
We also investigated the influence of two kinds of FCs—PC and COV—on brain network topology. Interestingly, it was revealed that the analyses using these two FCs could provide non-redundant information for depicting the brain networks under different task-related and resting-state conditions. For nodal network measures, PC and COV reflected the influences of arousal and valence stimuli on brain network topology, respectively. For global network measures, the influences of both arousal and valence stimuli were only revealed by COV. For FC, PC revealed most of the alterations induced by arousal stimuli, whereas COV revealed most of the alterations induced by valence stimuli. By definition, assuming two independent variables X and Y, PC(X,Y) is equivalent to COV(X,Y) divided by the products of the variances of those two variables ( ). In other words, the calculation of COV considers both the signal amplitudes and variations, while PC is a dimensionless measure that decouples the effect of the signal variations. Therefore, PC and COV could reflect different aspects of functional dependency in principle and then result in non-redundant observations. 

Here, we give two scenarios where the observations of PC and COV may not converge. In some cases where the alteration of signal variances is irrelevant to the stimulation, COV may show a lower significance level than PC due to the inclusion of signal variances. In other cases where the alteration of signal variances is highly relevant to the stimulation, COV may show a higher significance level than PC. Considering the nature of definitions, we speculate that the network modulation under arousal stimuli is less relevant to the alteration of signal variations, while network modulation under valence stimuli is mostly contributed by the alteration of the amplitude of signal fluctuations. To date, choosing optimal FC measures for graph-theoretical analysis remains challenging. Our study demonstrates that the use of multiple FC measures may be a better approach to address the complex network and could provide complementary perspectives on the task-related reconfiguration of a network. 


### Limitations 
  
In this investigative study, we have shown that the different levels of emotional speech stimuli may alter or modulate the brain networks on either a nodal or global scale. Although we suggest that brain network analysis could have the potential to resolve the vocal-emotion-induced topological changes, several limitations must be carefully discussed. The first limitation may come from the cultural difference between the volunteers who rated the emotional scales in the IEMOCAP data set and the participants involved in this study. The cultural difference arising from native languages and environmental factors may play a major role in comprehending the emotional speech, which might be the major confounding factor in this exploratory study. The second limitation is the design of vocal emotional stimuli, in which we tried to mimic the real-world scenarios. However, this experimental design might be too complicated to rule out some other mental confounding factors. Considering both limitations, one should use the speech database with the same native language as that of the participants involved in the experiments to investigate better the effects of vocal emotional stimuli on brain network topology. Furthermore, the scenarios of the functional stimuli should be divided into several simplified sections so one could investigate each phenomenon separately. Additionally, it is also worth noting that the method used in this study assumes a static topology under a given type of stimuli. However, it is highly likely that such an assumption does not hold—for brains are dynamic systems. Notably, several studies have also investigated how functional networks change and evolve with time using dynamic FC ( ;  ).   also performed whole-brain dynamic connectivity analysis for studying the effects of emotional speech on dynamic changes of brain networks. It is highly likely that considering the dynamic nature of the brain network would provide a more valid analysis and allow for studying dynamic changes in brain states. However, some careful analysis design is required to apply high-level network analysis to a dynamic network. Furthermore, the emotional stimuli used in our study were attributed to a simple two-dimensional model (i.e. arousal and valence). However, it is also possible to extract emotion-related features directly from the stimuli ( ). In fact, it has been shown that emotion recognition using EEG signals can be facilitated by incorporating features extracted from the stimuli ( ;  ;  ). Therefore, we postulated that by incorporating sound features extracted from the speech stimuli, we could achieve a more comprehensive analysis of various aspects of emotions during the speech. 



## Conclusions 
  
In this study, we investigated the modulation of brain networks under emotional speech perception using high-level graph-theoretical network measures. With the use of OMSTs approach and Power-264 functional atlas, we discovered that brain network exhibits significantly altered network attributes at global, nodal and connectivity levels, especially under emotional speech with high arousal or negative valence. We also investigated the alterations of network metrics and FCs within/between large-scale functional networks and found that most of alterations were associated with negative valence. To the best of our knowledge, this is the first study employing a graph-theoretical analysis of emotional speech perception. Although this is predominantly an investigative study, we have gained crucial insights into how comprehending emotional speech modulates brain networks. Additionally, this study provides directions for high-level network analysis on emotional speech comprehension or possibly other types of brain functions. 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-17'>
<h2>17. PMID: 27280153</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Topographical Organization of Attentional, Social, and Memory Processes in the Human Temporoparietal Cortex123</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> eNeuro</p>
<p><strong>Publication Year:</strong> 2016</p>
<p><strong>DOI:</strong> 10.1523/ENEURO.0060-16.2016</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study includes social-related tasks (theory-of-mind belief attribution and a social attribution-of-attention task) performed by healthy adult participants (mean ages ~19–23; no psychiatric/neurological disorders) within the 18–60 range. Data were acquired with whole-brain fMRI and analyses include whole-brain seed-to-voxel functional connectivity mapping (CONN toolbox) reporting network-level results beyond the TPJ. Although a localized ICA was applied within a TPJ mask to identify components, the study did not report only ROI-restricted outcomes — it presents whole-brain connectivity and network findings and task-related activation patterns relevant to social processing. Therefore it meets all inclusion criteria (social fMRI task, healthy adults 18–60, whole-brain results) and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
The temporoparietal junction (TPJ) is activated in association with a large range of functions, including social cognition, episodic memory retrieval, and attentional reorienting. An ongoing debate is whether the TPJ performs an overarching, domain-general computation, or whether functions reside in domain-specific subdivisions. We scanned subjects with fMRI during five tasks known to activate the TPJ, probing social, attentional, and memory functions, and used data-driven parcellation (independent component analysis) to isolate task-related functional processes in the bilateral TPJ. We found that one dorsal component in the right TPJ, which was connected with the frontoparietal control network, was activated in all of the tasks. Other TPJ subregions were specific for attentional reorienting, oddball target detection, or social attribution of belief. The TPJ components that participated in attentional reorienting and oddball target detection appeared spatially separated, but both were connected with the ventral attention network. The TPJ component that participated in the theory-of-mind task was part of the default-mode network. Further, we found that the BOLD response in the domain-general dorsal component had a longer latency than responses in the domain-specific components, suggesting an involvement in distinct, perhaps postperceptual, computations. These findings suggest that the TPJ performs both domain-general and domain-specific computations that reside within spatially distinct functional components. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (42879 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Significance Statement 
  
The temporoparietal junction (TPJ) is a major communication hub in the human brain. The exact pattern of overlap and separation of function in the TPJ has been difficult to study due to the complexity of its responses during many different kinds of tasks. We studied the activity in the TPJ during five behavioral tasks associated with attention, memory retrieval, and social cognition. We found that one zone in the TPJ was active in all five tasks, whereas other zones were active in a more task-specific manner. Our findings suggest that the TPJ is a site where multiple brain networks converge and interact, but that it also contains more functionally specific subregions. 


## Introduction 
  
Many theories have been proposed to explain the multitude of tasks that activate the temporoparietal junction (TPJ), which involve functions ranging from bottom-up attention to episodic memory retrieval and social cognition. For example, it has been suggested that the episodic memory activity in the TPJ is related to reflexive orienting to information retrieved from memory ( ;  ;  ), and that social cognition in the TPJ might depend on similar low-level information processing ( ). Other theories have postulated that the TPJ is a zone of convergence and integration, in which internal models of one’s environment, social context, or attentional state are maintained and updated ( ;  ;  ;  ;  ). Comparisons of activation patterns within single subjects have shown some separation but also zones of overlap. For example, topographic overlap has been reported between theory-of-mind and attentional reorienting activity ( ); between memory retrieval and attentional reorienting ( ); and among theory-of-mind, attentional reorienting, and biological motion ( ). However, functional heterogeneity has also been seen in both meta-analyses and within-subject fMRI studies, manifesting as the physical separation of processes, an ability of multivoxel pattern analysis to discriminate different tasks within regions of overlap, and distinct connectivity patterns of activation foci ( ;  ;  ;  ;  ). 

The great spatial variability of fMRI activations in the TPJ is perhaps not surprising given the intersubject heterogeneity in the TPJ, the limitations of normalizing individual brains into a common space, and the limitations of voxelwise analysis. One useful way of addressing TPJ function is careful within-subject analysis of task-related activity in high-resolution fMRI scans ( ;  ;  ;  ). Another possibility, explored in this study, is to use multivariate data-driven methods to work around the limitations of voxelwise analysis. We previously found that localized independent component analysis (local-ICA), which decomposes the fMRI signal in the TPJ into a linear mixture of spatiotemporal source processes, could be used to parcellate the TPJ into five to six subdivisions per hemisphere ( ). These components included bilateral posterior (TPJp), anterior (TPJa), dorsal (TPJd), and ventral (TPJv) regions, and a central right-biased region (TPJc). The time courses of the independent components (ICs) within the TPJ were correlated with distinct resting-state networks ( ), indicating that they represented functionally distinct processes. This method of local-ICA was robust across multiple independent subject cohorts ( ). 

We hypothesized that local-ICA, by isolating functional processes from noise and by providing IC time courses that can be analyzed for task relatedness, may be a powerful approach to study the distribution of processes in the TPJ. A primary goal of this experiment was to test a diversity of tasks that in the previous literature have been shown to evoke robust activity in the TPJ. This diversity of tasks allowed us to ask basic questions, such as the following: is the TPJ heterogeneous, with subareas that tend to be recruited in different tasks, or is it a site of convergence, with a generalized activity that is similar across a range of tasks? Or does the TPJ have some combination of properties, with some subregions showing task-specific activity and other subregions showing functional overlap? To pursue that goal, five tasks were chosen based on their prominent roles in the TPJ literature, and their diversity in terms of behavioral paradigm and cognitive function, although these tasks did not constitute an exhaustive list of all tasks that may be relevant. The tasks included (1) a social attribution-of-belief task ( ), (2) an old/new episodic memory retrieval task ( ), (3) an attribution-of-attention task ( ), (4) a Posner attentional reorienting task ( ), and (5) an oddball target detection task ( ). We analyzed the fMRI signal during these tasks by using local-ICA to decompose the signal within the temporoparietal cortex. Task-related ICs were identified using multiple regression analysis, and their network participation was mapped using functional connectivity analysis. This data-driven approach revealed a functional topography within the temporoparietal cortex that included zones of both task convergence and task specialization. 


## Materials and Methods 
  
The experimental approach consisted of four main steps. First, fMRI data were collected during behavioral tasks that in prior studies evoked activity in the TPJ ( ). Second, for each task, local-ICA was used on the group level to extract the dominant spatiotemporal TPJ processes in a data-driven manner. Third, the IC time courses from these task-specific ICAs were entered into mixed-effects multiple-regression analyses to identify components that were significantly task related. Fourth, all IC time courses were used for a functional connectivity analysis to map the network participation of each IC. 
  
Schematic representation of task designs.    A   , Theory-of-mind task. A story requiring either attribution of belief or reasoning about a photo was shown for 10 s, followed by a true/false question for 4 s. There were 20 trials in total.    B   , Episodic memory retrieval task. The task was divided over four runs, each consisting of an encoding phase (“E”) before the run began, and a retrieval phase (“P”; bottom). In the encoding-phase, subjects were asked to memorize words presented sequentially on the screen (33 words). In the retrieval run (25 old words intermixed with 50 new words and 25 fixation trials), subjects indicated with a button press whether a word was old or new. There were 400 trials in total.    C   , Attribution-of-attention task. An object with either negative or positive salience was presented on the right or left for 1 s (this example shows a car fire). After a 0.5 s interval, the face of a cartoon character was presented centrally for 2 s. Its gaze was directed either toward or away from the object (G+ or G−), and its emotional expression either matched or mismatched the valence of the object (E+ or E−). Subjects rated the character’s level of awareness of the object on a scale of 1 (not aware) to 3 (very aware). Four trial types were possible: G−E−, G+E+, G+E−, and G−E+. The trials in which the gaze and expression cues were inconsistent (G+E− and G−E+) were labeled as hard trials (for more details, see Materials and Methods). There were 384 trials in total.    D   , Attentional reorienting task. A central cue pointing right or left predicted the location of a target in 75% of trials. Subjects were asked to indicate which side the target appeared on. There were 200 trials in total.    E   , Target detection task. A visual standard stimulus (“OOOO”) was presented on the screen every 1.5 s. In 5% of trials, this was replaced by the target stimulus (“XXXX”). The subjects silently counted how many targets they saw. There were 480 trials in total. 
  
### Theory-of-mind task 
  
The theory-of-mind task was performed by 20 subjects (12 females; mean age, 22.6 ± 0.8 years old). The study was approved by the Princeton University Institutional Review Board. All subjects gave informed written consent, had normal or corrected-to-normal vision, and had no history of psychiatric or neurological disorders. 

We used a theory-of-mind localizer task from a study by  , which contrasts brain activations during the attribution of beliefs to people (belief trials) with activations during judgments about the contents of photographs, maps, or signs (photo trials;  ). The stimuli were provided by David Dodell-Feder, Nicholas Dufour, and Rebecca Saxe (  http://saxelab.mit.edu/superloc.php  ). This task was chosen because of its extensive use in theory-of-mind studies and its popularity as a TPJ localizer task ( ;  ;  ;  ). In each trial, the story was presented for 10 s, followed by a true/false question for 4 s and an intertrial interval (ITI) of 12 s. Participants responded to the questions using a button box. The task consisted of two runs of 10 trials each, and the order of stories was counterbalanced and equally distributed across the two runs. The BOLD response was modeled with a 14 s boxcar convolved with a standard hemodynamic response function (“waver” function; AFNI). A contrast between belief trials and photo trials is known to reveal activation in the TPJ and other theory-of-mind regions ( ). The reaction time was not significantly different in belief versus photo trials (mean ± SEM reaction time, 2.7 ± 0.10 and 2.6 ± 0.10 s, respectively;   p   = 0.18, paired   t   test). 


### Episodic memory retrieval task 
  
The episodic memory retrieval task was performed by 20 subjects, 1 of whom was excluded due to excessive movement (10 females; mean age, 22.3 ± 1.0 years). Subjects had normal or corrected-to-normal vision and no history of psychiatric or neurological disorders. 

The episodic memory task was an old/new task based on a study by  ;  ). The old/new paradigm was chosen because several studies have found TPJ activation with this contrast, and it has been part of meta-studies of functional overlap ( ;  ). The task consisted of four runs. Each run comprised a memory-encoding phase and a memory-retrieval phase. In the encoding phase, subjects were asked to memorize 33 words, which were presented on the screen 1 word at a time (word duration, 2 s; trial duration, 3 s). In the retrieval phase, a randomized collection of words was presented in the same manner. These included 25 words from the learning phase and 50 new words. Twenty-five fixation trials were also randomly interspersed in each run. Subjects were asked to indicate with a button press whether or not they remembered the word as being from the learning run. There was no overlap of words among the four runs. The contrast between successfully retrieved old words (old trials) and successfully rejected new words (new trials) has been shown to evoke TPJ activation ( ). The word list was derived from the SUBTLEXus 1.00 word frequency database ( ) and consisted of five-letter words with a frequency of 5–10 per million. The BOLD response was modeled with a boxcar time course convolved with a standard hemodynamic response function (waver function; AFNI). The average accuracy did not differ between the old and new trials (mean ± SEM accuracy, 81.8 ± 2.7% and 87.9 ± 2.9%, respectively;   p   = 0.13, paired   t   test). The reaction time for new trials was slightly longer than that for old trials (mean ± SEM reaction time, 993 ± 27 and 927 ± 23 ms, respectively;   p   = 0.0013, paired   t   test). 


### Social attribution of attention 
  
The attribution-of-attention task was chosen because it was previously found to evoke robust activity in the TPJ even in individual subjects ( ) and offers a contrasting approach to testing social cognition from the belief attribution task. In the present study, we used the data collected in our previous study ( ) and reanalyzed it for the present study. The task ( ) required subjects to rate the perceived level of awareness of a cartoon face (“Kevin”) for an object next to it. The direction of gaze of the face was manipulated (toward or away from the location of the object), and the emotional expression of the face either matched the valence of the object (e.g., a happy face paired with a cupcake or a frightened face paired with a house fire) or mismatched the valence of the object (e.g., a frightened face paired with a cupcake or a happy face paired with a house fire). Subjects rated Kevin’s level of awareness of the object on a scale of 1 (not aware) to 3 (very aware). When both the gaze and expression cues matched the object, subjects tended to rate Kevin as very aware (rating of 3). When both the gaze and expression cues mismatched the object, subjects tended to rate Kevin as unaware (rating of 1). When the cues to Kevin’s state of awareness were incompatible, with one cue suggesting awareness and the other suggesting unawareness, subjects tended to compromise between the two cues and rate Kevin’s awareness as intermediate (rating of 2). In the previous study, it was found that TPJ activity was significantly higher when subjects compromised between two incompatible cues to Kevin’s state of mind, presumably when the computation about Kevin’s state of mind was more difficult (“Hard trials”), and activity in the TPJ was significantly lower when the subjects used two compatible cues to Kevin’s state of mind, presumably when the computation about Kevin’s state of mind was easier (“Easy trials”). 

The details of the paradigm are described in a previous publication ( ). Briefly, the behavioral task consisted of eight runs of 48 trials each. Each trial started with a fixation cross for 0.5 s, followed by a picture of an object for 1 s. The fixation cross returned for 0.5 s, and then was replaced by a cartoon face for 2 s. The object was presented either to the left or right and had either positive or negative valence. The gaze of the cartoon figure was either averted from or directed at the object, and the expression was either happy or alarmed. In this way, the gaze could either match (Gaze+) or mismatch (Gaze−) the location of the object, and the expression could either match (Expr+) or mismatch (Expr−) the valence of the object (see examples in  ). Subjects were asked to indicate with one of three buttons whether the person was (1) not aware, (2) somewhat aware, or (3) very aware of the object. For the present study, we used data from the first 20 subjects of the total of 50 subjects from the previous study ( ; 8 females; mean age, 19.4 ± 0.4 years). The reason for analyzing a smaller subset of subjects was a limitation in memory on the compute cluster, which prevented a full 50-subject group level-ICA. Therefore, we chose to analyze the first 20 subjects in this task as an unbiased way of decreasing the computing requirements. We used the same regressors and contrast as in the previous study (described above), convolving the hard and easy trial types with a hemodynamic response function (waver function; AFNI) and testing the contrast hard versus easy. 


### Attentional reorienting task 
  
This task was performed by 20 subjects with normal or corrected-to-normal vision and no history of psychiatric or neurological disorders (11 females; mean age, 21.6 ± 0.6 years). 

Attentional reorienting was tested using a Posner task modeled closely on a previous study ( ;  ). This task was chosen to represent reorienting to invalidly cued targets, which is thought to be a major function of the TPJ ( ;  ;  ;  ). The task consisted of five runs of 40 trials each. Subjects were given one practice run inside the scanner before the experiment started. The fixation screen consisted of a black background with a red central fixation plus sign (+) and two peripheral square boxes with white outlines. The peripheral boxes were centered 7° from the fixation and were 3° across. At the start of a trial, the central plus sign turned green for a fixation period of 700 ms and was replaced by a central cue consisting of an arrow for 800 ms. The arrow pointed either left or right, in a randomized counterbalanced order. After a pretarget period of 0.5–2 s, the target (a white asterisk) was presented in one of the two peripheral boxes for 100 ms. The posttarget time was selected to make the total trial duration 4 s, after which the fixation plus sign turned red again for a randomized ITI of 0.5–7.5 s. Subjects responded with a button press to indicate whether the target was on the left or on the right. The direction of the central cue predicted the side of the target in 75% of trials (valid trials) and was mismatched in 25% of trials (invalid trials). Subjects were informed that the arrow would predict the target in the majority of trials. A contrast between invalid and valid trials has been reported to reveal activity in the right TPJ and the ventral attention network ( ). The BOLD response was modeled by convolving the stimulus timings with a gamma function. The reaction time for invalid trials was significantly longer than that for valid trials (mean ± SEM reaction time, 394 ± 16 and 362 ± 15 ms;   p   = 0.00007, paired   t   test). 


### Oddball target detection task 
  
This task was performed by 20 subjects, 1 of whom was excluded due to poor performance (10 females; mean age, 22.9 ± 1.0 years). The subjects had normal or corrected-to-normal vision and no history of psychiatric or neurological disorders. 

The target detection task was a simple visual oddball task based on the study by  ;  ). The oddball paradigm was chosen because it represents a nonspatial form of attentional reorienting that is often reported to cause TPJ activations ( ;  ). It consisted of four runs with 120 trials each. The standard stimulus was the letters “OOOO” presented centrally for 500 ms. The rare target stimulus consisted of the letters “XXXX” (4–7% of trials in each run) and was made task relevant by asking the subjects to report on how many targets they had seen after each run. A contrast between the target (target trials) and the standard stimuli (standard trials) was reported to evoke TPJ activity ( ). The BOLD response was modeled by convolving the stimulus timings with a gamma function. 


### Distribution of subjects across the five tasks 
  
For reasons of feasibility, every subject did not perform all tasks, which would have required a prohibitive number of hours and sessions for each subject. Instead, each task was analyzed separately. In effect, we performed five independent experiments. All statistical analyses were performed independently for each task, with no between-subjects statistical tests. The results are reported separately for each task and not used to draw conclusions about quantitative differences across tasks in the exact spatial location of ICs or the effect size of activity. In some cases, for tasks that required less run time, the same subjects participated in more than one task. Because of the separate analysis for each task, these overlaps in the subject pools are not of direct relevance to the analysis, but are nonetheless reported here. Fourteen subjects performed both the theory-of-mind task and the attentional reorienting task. Six subjects performed only the attentional reorienting task, and six subjects performed only the theory-of-mind task. Eighteen subjects performed both the episodic memory retrieval task and the target detection task. One subject performed only the episodic memory retrieval task, and one subject performed only the target detection task. For the social attribution-of-attention task, data from 20 subjects were used. In total across the five tasks, 66 subjects were tested. 


### Magnetic resonance imaging 
  
MRI images covering the whole cerebral cortex were acquired with a 20-channel receiver head coil on a Siemens Skyra scanner. Functional imaging used a gradient echo, echoplanar pulse sequence with a 64 × 64 matrix [27 axial slices; 4 mm thick; in-plane resolution, 3 × 3 mm; TR, 1.5 s; TE, 28 ms; flip angle (FA), 64°; generalized GRAPPA iPAT = 2. Anatomical imaging used an MP2RAGE sequence (256 × 240 matrix; TR, 5 s; TE, 2.98 ms; FA, 4°; 1 mm  resolution; GRAPPA iPAT = 3). The reanalyzed data from the previous study ( ) were acquired on the same scanner. The functional data were acquired with a 64 × 64 matrix (35 axial slices; 3 mm thick; in-plane resolution, 3 × 3 mm; TR, 2 s; TE, 30 ms; FA, 77°), and the anatomical data were acquired with an MPRAGE sequence (256 × 224 matrix; TR, 2.3 s; FA, 9°; and with 1 mm  [TE, 2.98 ms], 0.9 mm  [TE, 3.08 ms], or 1.1 mm  [TE, 2.93 ms] resolution). 


### Preprocessing of fMRI data 
  
Preprocessing was performed with AFNI ( ) and FSL ( ). The functional data were slice time corrected and motion corrected with FSL ( ), and then detrended (linear and quadratic) with AFNI. The data were spatially normalized to the FSL MNI-152 template with AFNI, and spatially smoothed with a Gaussian kernel (5 mm FWHM). We used an ICA-based strategy for automatic removal of motion artifacts (ICA-AROMA;  ). This toolbox runs single-session ICA with multivariate exploratory linear decomposition into independent components (MELODIC, FSL); and classifies motion-related ICs by assessing their high-frequency content, correlation with motion parameters, edge fraction, and cerebrospinal fluid fraction ( ). ICA-AROMA removes noise ICs from the fMRI data by calling the FSL command fsl_regfilt ( ). Such ICA-based denoising is effective in removing aberrant connectivity measures resulting from subject motion ( ;  ;  ). 


### Group-level ICA 
  
For each of the five tasks, the fMRI data were subjected to probabilistic ICA applied on temporally concatenated fMRI data, with all runs from all subjects concatenated into one matrix (MELODIC toolbox in FSL;  ). We performed the ICA decomposition separately for each task (instead of grouping the tasks into one ICA) because we did not want to assume that the ICA decomposition would be the same across task conditions. We applied the ICA to the voxels within a region of interest (ROI) mask that included the TPJ and surrounding cortex to ensure that all relevant ICs were detected in their entirety. The mask was constructed from the standard surface cvs_avg35_inMNI152 in Freesurfer, using mri_label2vol to combine multiple labels from the aparc.a2009s atlas into one mask (G_pariet_inf-Supramar, G_pariet_inf-Angular, G_temp_sup-Plan_tempo, G_temp_sup-Lateral, G_temp_sup-G_T_transv, S_interm_prim-Jensen, S_temporal_sup, S_temporal_transverse) and trimming temporal cortex voxels anterior to the postcentral sulcus. This mask allowed a parcellation of the whole temporoparietal region. The reason for using localized ICA is that it allows a finer parcellation of the region ( ;  ;  ), but the exact extent of the mask is not critical for the results. The fMRI data were decomposed into 20 ICs, which isolates the major functional processes in the region ( ). ICs were thresholded at   z   = 2.3 for visual inspection (mixture-model threshold of   p   < 0.5) and at   z   = 4 for the creation of winner-take-all maps for the figures. Time courses for the figures were derived from the ICA mixing matrix (demeaned and variance-normalized signal; arbitrary   y  -axis;  ). Event-related averaged waveforms were first calculated for each subject, and these were then averaged across subjects and presented as the mean ± SEM. 

Task-related ICs were identified using a mixed-effects multiple regression (subjects as random effects) in R version 3.0.3 (nlme package version 3.1-113;  ;  ), with the IC time courses as dependent variables and the predicted BOLD responses for each condition as independent variables (two trial types per task). The inclusion criteria for an IC to be accepted as task related were as follows: (1) a significant positive regression coefficient for the main condition of interest (“belief” trials in the theory-of-mind task; “old” trials in the episodic memory retrieval task; “hard” trials in the attribution-of-attention task; “invalid” trials in the attentional reorienting task; and “target” trials in the target detection task); and (2) a significant positive contrast in the general linear test (belief–photo; old–new; hard–easy; invalid–valid; target–standard). Any ICs located at the border of the mask outside the ROI were excluded (anterior superior temporal lobe, intraparietal sulcus, lateral fissure, postcentral sulcus, and anterior dorsal inferior parietal lobule). 

In fMRI experiments, one possible concern is that eye movement might affect the measured cortical activity. The TPJ is not typically active in relation to eye movement, unlike more ventral regions in the superior temporal sulcus and more dorsal regions in the intraparietal sulcus. However, it is still important to ensure that the experimental design minimizes the possibility of an eye movement confound. In all five experimental designs, the analysis for identifying task-related ICs relied on the correlation of the IC time courses to trial-specific models of the BOLD response. Because the trial types were matched and counterbalanced with respect to visual features and processing demands (e.g., story/word length, left vs right targets), eye movements should not have influenced the identification of task-related ICs. All five tasks used a fixation point where necessary to stabilize eye position and were otherwise counterbalanced across the critical comparisons. 


### Functional connectivity analysis 
  
The CONN toolbox 15.c in SPM 12 (  http://www.nitrc.org/projects/conn  ;  ) was used for seed-to-voxel connectivity analysis ( ) using the subject-specific IC time courses as seed time courses. Conventional bivariate correlation analysis was used, with a voxelwise threshold of   p   < 0.001 uncorrected and a cluster extent threshold of   p   < 0.05 (false discovery rate corrected). 



## Results 
  
We present the results from each of the five tasks separately and then discuss the comparison among the tasks. 

### Theory of mind 
  
The theory-of-mind task activated a bilateral posterior IC resembling TPJp in our previous studies ( , red). It also activated two lateralized dorsal components, in the region of the right and left TPJd ( , TPJd-R, purple, TPJd-L, blue). The TPJp activity was specific for the belief trials, with a large effect for the belief (“B”) condition ( , red bar), and no significant activity related to the photo (“P”) condition ( , gray bar). The activation patterns for TPJd-R and TPJd-L were distinct from that of TPJp, with lower specificity for the belief condition. TPJd-L showed some activity in photo trials, whereas the activity of TPJd-R was negatively related to photo trials ( , gray bars). 
  
ICs activated in the theory-of-mind task.    A   , Location of significant ICs shown as a winner-take-all map, created from   z  -score maps thresholded at   z   > 4.    B   , Regression coefficients for the belief (B) and photo (P) conditions for the three significantly task-related ICs.    C   , Event-related IC time courses for the belief condition during the 14 s story-plus-question block (black bar) for TPJp (red), TPJd-L (blue), and TPJd-R (purple). The   y  -axis is shown in arbitrary units.    D–F   , Connectivity patterns of the three task-related ICs obtained in the theory-of-mind task, as follows: TPJp (   D   ), TPJd-L (   E   ), and TPJd-R (   F   ). 
  
We extracted belief-related BOLD time courses from the three task-related ICs to examine the temporal properties of these processes. We found a latency difference between the posterior and dorsal components. While TPJp showed a typical BOLD response during the story stimulus (peak, 11 s), TPJd-R and TPJd-L showed a later onset and peak (peaks, 17-18 s), indicating involvement in a more delayed process compared with that of TPJp ( ). 

To further characterize these zones of activation and relate them to previously reported TPJ subdivisions ( ;  ;  ), we performed a functional connectivity analysis using the IC time courses as seed time courses. The most strongly and selectively recruited IC in the theory-of-mind task, TPJp, was connected with default-mode network regions, including precuneus, STS, and medial and lateral PFC ( ). This connectivity is similar to that of TPJp reported by others and us ( ;  ;  ), and similar to regions activated by theory-of-mind tasks ( ). TPJd-L and TPJd-R were connected with lateralized frontoparietal networks involving the inferior temporal lobe, lateral and superior frontal cortex, and precuneus ( ). These connectivity patterns also agree with the network participation of TPJd reported previously ( , termed “IPL”;  ). 


### Episodic memory retrieval 
  
The episodic memory task activated an IC in the right angular gyrus, which was also located in the region of TPJd-R ( ). Its activity was specific for memory retrieval ( ), and it showed an activity peak at 7 s after stimulus onset ( ). The IC was connected to the same right-lateralized frontoparietal network as the TPJd-R component activated by the theory-of-mind task (compare  ). 
  
ICs activated during episodic memory retrieval.    A   , Location of the significant IC created from a   z  -score map thresholded at   z   > 4.    B   , Regression coefficients for the old (O) and new (N) conditions for the significantly task-related IC.    C   , Event-related IC time course for the old condition for TPJd-R. The   y  -axis is shown in arbitrary units.    D   , Connectivity of TPJd-R. 
  
There was a left-lateralized component in a similar region that did not reach our statistical criteria. This IC, in the area of the TPJd-L, showed a significant old/new contrast, but it did not pass the statistical threshold for the old condition (β = 0.50,   p   = 0.026). Therefore, we did not include it here as a significantly activated IC. 


### Attribution of attention 
  
The attribution-of-attention task activated two spatially similar ICs in the region around the TPJd-R ( , TPJd-R, purple, TPJd-R 2, black). TPJd-R was more strongly activated than TPJd-R 2 ( ), but both were connected to the same right frontoparietal network ( ). The event-related time courses showed no difference in latency or shape, suggesting that these processes reflected erroneous splitting of a single process. The frontoparietal network was similar to the networks connected with TPJd-R in the theory-of-mind and episodic memory retrieval tasks.  shows the time courses of TPJd-R and TPJd-R 2 (peaks, 7 s). Because of the rapid presentation of stimuli in this task, the time course showed activity from the previous trial dropping, and then rising again in response to the current trial. 
  
ICs activated during social attribution of attention.    A   , Location of significant ICs shown as a winner-take-all map, created from   z  -score maps thresholded at   z   > 4.    B   , Regression coefficients for the hard (H) and easy (E) conditions for the two significantly task-related ICs.    C   , Event-related IC time courses for the hard condition for TPJd-R (purple) and TPJd-R2 (black). Due to the rapid trial presentation in this task, the signal was still returning to baseline at the beginning of the trial. The   y  -axis is shown in arbitrary units.    D   ,    E   , Connectivity of the task-related ICs, as follows: TPJd-R (   D   ) and TPJd-R 2 (   E   ). 
  

### Attentional reorienting 
  
The attentional reorienting task showed two significant ICs ( ). One was located in the region of the TPJd-R, and the other was located anterior to TPJd-R in a location close to TPJc reported previously ( ). Event-related BOLD time courses for TPJd-R and TPJc again showed a long-latency response in TPJd-R (peak, 7 s) compared with TPJc (peak, 4 s;  ). 
  
ICs activated during the attentional reorienting task.    A   , Location of significant ICs shown as a winner-take-all map, created from   z  -score maps thresholded at   z   > 4.    B   , Regression coefficients for the invalid (I) and valid (V) conditions for the two significantly task-related ICs.    C   , Event-related IC time courses for invalid trials for the TPJd-R (purple) and TPJc (orange). The   y  -axis is shown in arbitrary units and the arrow shows stimulus onset.    D   ,    E   , Connectivity of the task-related ICs, as follows: TPJd-R (   D   ) and TPJc (   E   ). 
  
The TPJd-R component was connected to the right frontoparietal control network ( ). TPJc was connected with regions in the ventral attention network, including the anterior cingulate cortex, anterior insula, and the inferior frontal cortex, and showed a strong bias toward the right hemisphere ( ). 


### Target detection 
  
The target detection task activated one IC matching the TPJd-R and one IC in the anterior supramarginal gyrus in the region labeled TPJa in our previous study ( ). The location of TPJd-R appeared to be located more posterior than in the other tasks ( ); however, it was connected with the same right frontoparietal network as the TPJd-R regions activated in the other tasks and in our previous study ( ). TPJa was connected to regions of the ventral attention network, including the right inferior frontal gyrus, anterior insula, and anterior cingulate cortex ( ). As in the theory-of-mind and attentional reorienting tasks, the event-related BOLD time course of TPJd-R showed a longer-latency response (peak, 7 s) compared with the early peak of TPJa (peak, 4 s;  ). 
  
ICs activated in the oddball target detection task.    A   , Location of significant ICs shown as a winner-take-all map, created from   z  -score maps thresholded at   z   > 4.    B   , Regression coefficients for the target (T) and standard (S) conditions for the two significantly task-related ICs.    C   , Event-related IC time courses for the target condition for the TPJd-R (purple) and TPJa (green). The   y  -axis is shown in arbitrary units and the arrow shows stimulus onset.    D   ,    E   , Connectivity of the task-related ICs, as follows: TPJd-R (   D   ) and TPJa (   E   ). 
  

### Summary 
  
The attentional reorienting and target detection tasks activated supramarginal regions (TPJc and TPJa, respectively) connected with the ventral attention network, whereas the theory-of-mind task uniquely activated the TPJp, which was connected with the default-mode network. All five tasks activated TPJd-R in the dorsal angular gyrus, which showed connectivity with the right-lateralized frontoparietal control network. The BOLD response of TPJd-R showed a longer latency than that of the other ICs activated in the same task. 



## Discussion 
  
The present findings show that the right dorsal TPJ is active during a range of tasks, including social, attentional, and memory tasks, whereas other TPJ zones are active in a more task-specific way (summarized in  ). The domain-specific TPJ processes in TPJp, TPJc, and TPJa showed a shorter-latency BOLD response compared with the domain-general process in TPJd, further strengthening the suggestion that the computations performed by these areas are distinct from each other. 
  
Simplified schematic summary of task activations. The task-related temporoparietal independent components from Figures 2–6 are shown in their approximate locations with black outlines, and their network connectivity is marked with matching colors but no outlines (see Figures 2-6 for the exact distribution and connectivity of the independent components). All tasks activated regions within the TPJd-R (purple area), which was connected with the right-lateralized frontoparietal network. The theory-of-mind task also activated TPJd-L (blue; connected with the left-lateralized frontoparietal network) and TPJp (red; connected with the default-mode network). The attentional reorienting task and the target detection task activated TPJc and TPJa, respectively (orange and green), which were connected with partially overlapping regions of the ventral attention network. 
  
### Separation of functions within the TPJ 
  
There was clear spatial separation of the theory-of-mind task (activating the TPJp), and the attentional reorienting and target detection tasks (activating the TPJc and TPJa, respectively). These TPJ regions were also connected to distinct networks. The TPJp was connected with classic theory-of-mind/default-mode regions, including precuneus and medial prefrontal cortex. The TPJc and TPJa were both connected with the ventral attention network. Thus, this study shows spatial separation of processes related to theory-of-mind and attentional reorienting. The spatial relationship between theory-of-mind and attentional functions has been debated in previous studies, but a general pattern of a more posterior locus for theory of mind has emerged ( ;  ;  ;  ). The clear separation observed here is likely made possible by linear decomposition of overlapping signals using ICA. The difference between TPJc and TPJa was more ambiguous, especially given their similar connectivity patterns. Attentional reorienting tasks and target detection tasks have generally been grouped together in meta-studies, but, when they were separated, a more anterior location of target detection activity compared with activity in attentional reorienting tasks was seen ( ), which is similar to the present findings. 

The dorsal location of activity in episodic memory retrieval in the present experiment was similar to the dorsal activations seen in previous studies ( ;  ;  ). However, episodic memory retrieval activity in old/new tasks is often dominantly expressed in the left hemisphere, in contrast to the right lateralization observed here. Our result does not exclude the possibility of relevant left-lateralized retrieval-related activity. First, the TPJd-R component showed strong functional connectivity to the left TPJd ( ), indicating involvement of the opposite hemisphere. Second, we observed a TPJd-L component that did not meet our strict inclusion criteria of a significant association with both the old condition and the old/new contrast. In a conventional analysis aiming to identify activity significant for the old/new contrast, regardless of the significance of the old trials, TPJd-L would have been identified as active. 


### A global role of the dorsal TPJ 
  
The TPJ has been suggested to be a hub or nexus in which multiple brain systems converge and communicate ( ;  ). In the current study, not the whole TPJ, but specifically the TPJd-R, the subdivision connected to the right frontoparietal control network, was recruited in all five tasks. These findings suggest that the TPJd may be a major site of functional convergence and interaction. 

An influential theory about TPJ function suggests that it is involved in postperceptual processes, such as the updating of internal models of the current context based on incoming sensory information ( ). It was suggested that stimuli that violate expectations in some way, such as invalidly cued targets, oddballs, or conflicting social cues, activate the TPJ for this reason ( ). In the memory domain, the TPJ has been suggested to be a buffer or convergence zone to manipulate or bind episodic memories ( ;  ;  ). An integrative function of the TPJ is also consistent with roles of the TPJ in representing the subjective experience of one’s own body ( ;  ) or one’s own state of awareness ( ;  ), functions that also rely on the integration of external stimuli with internal models. The TPJd is part of the frontoparietal control system, which is spatially interposed between the dorsal attention network and the default-mode network ( ) and serves a regulatory role in maintaining a balance between them ( ). This frontoparietal system has been suggested to be a “flexible hub” that rapidly adapts its brain-wide connectivity according to the current context and task demands ( ;  ;  ;  ;  ;  ;  ). The TPJd is thus positioned to play a central role in multiple interacting brain systems. 


### Limitations of findings 
  
An important limitation of this study is that it did not quantify the voxelwise differences across the five tasks in the spatial location of the TPJ ICs. Our data-driven method was effective in reducing TPJ fMRI data to the main spatiotemporal processes in the region, which allowed us to identify task-related activity with unprecedented power and clean separation. However, the TPJ heterogeneity and random starting parameters of the ICA algorithm make the method unsuitable for quantifying and comparing the exact coordinates of activity. The exact spatial configuration of group-level parcellations can differ for each subject cohort, as observed in our previous study ( ). Therefore, it is not known whether the slight spatial variability between the tasks was caused by anatomical heterogeneity, task-related activity, or variability of the ICA algorithm. For example, the heterogeneity observed in the localization of TPJd-R among different tasks may indicate that slightly different TPJd regions interact with the frontoparietal control network in different tasks, may reflect anatomical differences in TPJ organization among subject cohorts, and may reflect the random starting parameters of the ICA. 


### Conclusions 
  
We used localized ICA to study the TPJ during five behavioral tasks known to activate the region. Localized ICA can isolate spatiotemporal processes from each other and from the background noise, distilling the noisy fMRI data to a small number of processes and minimizing multiple comparisons. The local ICs can then be placed into brain-wide networks using functional connectivity analysis. If two ICs in different subject cohorts show similar connectivity, they are likely to be, if not functionally equivalent, at least very closely related. Using this method, we found that the TPJ contains both domain-specific and domain-general neural processes, which are separable in space and show distinct temporal properties. Processes specific to attentional reorienting and target detection were located in the supramarginal gyrus, and were associated with the ventral attention network. A posterior TPJ component specifically contained theory-of-mind activity and was connected with default-mode regions. A right-lateralized dorsal TPJ zone within the frontoparietal control network was activated across all the tested domains and showed a longer-latency BOLD response compared with the domain-specific processes. These findings strongly support the concept of the TPJ as a cognitive hub that mediates interactions among multiple brain networks, but also show that more functionally specific processes occur adjacent to the zone of convergence. 

 Note added in Proof   - The last name of 4th author was accidentally left off this article that was published on-line April 12, 2016, as an Early Release. The author line has since been corrected.
 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-18'>
<h2>18. PMID: 25946306</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Reading a Suspenseful Literary Text Activates Brain Areas Related to Social Cognition and Predictive Inference</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2015</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0124550</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Study reports whole-brain fMRI in healthy adult participants (N=23, ages 19–32) during a task involving reading a literary narrative and rating suspense. The neural effects of interest are explicitly social-cognition-related (activations in medial frontal cortex, temporo-parietal junction, theory-of-mind/mentalizing regions) and predictive inference during narrative processing, meeting the review objective of social-related processing. Imaging methods used whole-brain GLM analyses with cluster-level FWE correction and a separate (non-primary) ROI check for the amygdala; main results are whole-brain. Participants were healthy and within the 18–60 age range. The study is not a review/meta-analysis and does not report clinical populations or ROI-only results. Therefore it satisfies all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Stories can elicit powerful emotions. A key emotional response to narrative plots (e.g., novels, movies, etc.) is suspense. Suspense appears to build on basic aspects of human cognition such as processes of expectation, anticipation, and prediction. However, the neural processes underlying emotional experiences of suspense have not been previously investigated. We acquired functional magnetic resonance imaging (fMRI) data while participants read a suspenseful literary text (E.T.A. Hoffmann's “The Sandman”) subdivided into short text passages. Individual ratings of experienced suspense obtained after each text passage were found to be related to activation in the medial frontal cortex, bilateral frontal regions (along the inferior frontal sulcus), lateral premotor cortex, as well as posterior temporal and temporo-parietal areas. The results indicate that the emotional experience of suspense depends on brain areas associated with social cognition and predictive inference. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (41594 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
   
I could a tale unfold whose lightest word 

Would harrow up thy soul, freeze thy young blood, 

Make thy two eyes, like stars, start from their spheres, 

Thy knotted and combined locks to part 

And each particular hair to stand on end, 

Like quills upon the fretful porpentine. 
  
William Shakespeare,   Hamlet   (1.5.15–20) 
 
Spoken or written words can evoke powerful emotional responses. A prime example of this are stories. For millennia, generations of humans around the world have been moved, fascinated and entertained by stories, and oral traditions of storytelling may be as old as human language itself. Stories—factual or fictional—are omnipresent in human culture: Apart from their artfully refined role in literature (e.g., in novels, short stories, and many forms of poetry and drama), stories are told in a variety of other contexts, and the appeal of movies, songs, speeches, jokes, newspaper articles—and perhaps even scientific papers—often depends on their capacity “to tell a good story”. The human ability to understand, tell, and enjoy stories involves a multitude of cognitive and affective mechanisms including perception, attention, memory, reasoning, simulation of actions, emotion, and, naturally, language. Investigating story processing with modern neuroimaging methods can therefore provide insights into the neural signature of these mechanisms. 

Various neuroimaging studies have begun to tap into the brain mechanisms associated with story processing (for meta-analyses of story and text comprehension studies see [ ,  ]). Most of these studies focus on cognitive aspects of story processing, investigating, for example, neural activations in response to coherent narratives as opposed to unrelated sentences or words [ – ], comparing neural responses to written and auditory text presentations [ ], or probing memory encoding during story processing [ ]. 

Neuroscientific research on emotional responses to stories, however, is scarce, and only a few studies have specifically investigated the neuroaffective processes underlying story processing. An fMRI study by Wallentin et al. [ ] found that the emotional intensity experienced during auditory presentation of a story correlates with heart rate variability, activation of temporal cortices, the thalamus, as well as the amygdala, and that passages associated with positive valence are related to orbitofrontal cortex activations. Investigating emotional valence for short narratives, Altmann et al. [ ] showed that negative story valence is associated with increased activation of theory-of-mind-related brain regions (such as the medial frontal cortex and the temporo-parietal junction). More recently, Hsu et al. [ ,  ,  ,  ] provided fMRI evidence for the fiction feeling hypothesis [ ] stating that narratives with emotional content (in contrast to stories with neutral content) invite readers to empathize to a stronger degree with the protagonists, thus engaging the affective empathy network of the brain. These studies provide first evidence that investigating emotions evoked by narrative plots can offer new insights into neuroaffective brain processes. 

One component of emotional experience that is particularly relevant to story processing is suspense. Suspense is experienced in a huge variety of different contexts ranging from everyday life situations, sports, or gambling to different forms of media entertainment (e.g., film, television, literature, or music). Accordingly, suspense has been discussed by scholars from different disciplines such as literary science, film studies, or media psychology (for introductions, see [ – ]). Creating “the force that draws us through a narrative” [ ], suspense is the predominant emotional response elicited by many types of literary genres (e.g., thrillers, detective stories, spy novels, etc.), and the broad popularity of these genres illustrates the power of suspense to attract audiences and excite emotional responses. Suspense in narrative plots is closely intertwined with processes of prediction and anticipation which are triggered by explicit or implicit questions in the minds of the audience [ ], and which arise from the uncertainty regarding the outcome of the plot (cf. [ ,  ]). Plots of suspenseful novels or movies, for example, often involve conflicts and obstacles that the protagonists have to overcome, making the audience ponder over possible solutions to these conflicts and anticipate their eventual resolution. Predictive inferences during story processing have been found to be related to activation in inferior frontal and posterior temporal regions [ – ], and more generally, action and event prediction have been proposed to be supported by motor-related regions of the brain, in particular the lateral premotor cortex [ ]. Apart from adding to research on affective mechanisms involved in story processing, investigating neural responses to suspenseful narrative plots thus also promises insights into the brain structures associated with predictive inference. Moreover, suspense is closely related to processes of immersion, transportation, or absorption in media reception, such as reading [ ,  ,  ] or computer games [ ], which can be explained by the neurocognitive poetics model of literary reading [ ,  ]. 

At the text level, a suspense discourse organization involves an initiating event or situation, i.e., an event which potentially leads to significant consequences (either good or bad) for one of the characters in the narrative. The structural-affect theory of stories by Brewer and Lichtenstein [ ] states that the event structure must also contain the outcome of the initiating event, allowing to resolve the reader’s suspense. According to the model by Jacobs, the core affect systems “FEAR”, “ANGER”, or “CARE” described in Panksepp’s emotion theory [ ] are likely to be involved in this suspense building process, e.g., when a reader experiences suspense through vicarious fear, because a protagonist is in danger (especially when this danger is only known to the reader), which is mediated by processes of empathy and sympathy. Findings by Altmann et al. [ ] provided initial support for this assumption, indicating that short stories with negative content induce more affective empathy with the described characters in readers than neutral stories, as evidenced by increased brain activity in theory-of-mind and empathy-related areas (i.e., the medial frontal cortex, superior temporal sulcus, and temporo-parietal junction). Hsu et al. [ ] directly tested the model’s assumption and found that immersion (which at the experiential level is related to suspense; [ ]) is associated with activation of the mid-cingulate cortex and is higher for fear-inducing text passages describing protagonists’ pain or personal distress than for neutral passages. 

Although suspense can be measured at both the subjective-experiential (through questionnaires) and more objective behavioral and physiological levels, such as facial expressions, heart rate, or skin temperature [ ], at present, there are no neuroimaging results speaking directly to the issue of suspense in literary reading contexts. 

In the current study, we investigated the neural correlates of suspense experienced by readers during their first reading of a literary text. To this end, we acquired fMRI data while participants read a narrative (E.T.A. Hoffmann's “The Sandman”) subdivided into short text segments. After each segment, participants rated the level of suspense they had experienced while reading the segment. We then identified brain areas in which activation was related to the level of subjectively experienced suspense. Due to the dearth of previous research on neural correlates of subjectively experienced suspense, it was difficult to make specific predictions about brain regions involved in the experience of suspense. However, we were particularly interested in neuroaffective responses to suspenseful text segments. Previous fMRI research from the music domain has found ratings of musical tension—the musical “equivalent” of narrative suspense (cf. [ ,  ])—to be associated with activity changes in the lateral orbitofrontal cortex and the amygdala [ ]. Similarly, the violation, anticipation, and fulfillment of musical expectancies that mediate feelings of tension have been associated with amygdala [ ] as well as dorsal and ventral striatum activations [ ]. We expected suspense to be related to increased activity in similar brain structures associated with affective processing. In addition, based on the results reported by Altmann et al. [ ] and Hsu et al. [ ,  ], we explored whether suspense is related to activation in areas associated with theory-of-mind processing and mentalizing, i.e., the medial frontal cortex and the temporo-parietal junction [ – ]. Furthermore, based on the connection between suspense and predictive processes discussed above, we expected suspense to correlate with activation in brain areas associated with prediction (e.g., lateral premotor cortex). 


## Methods 
  
### Participants 
  
Right-handed German native speakers who were unfamiliar with the story and who enjoyed reading literature (according to self-reports) were recruited as participants for the experiment. Data from 23 participants (12 female, age range: 19–32 years,   M   = 24.1,   SD   = 3.9) were included in the analysis. Data from five additional participants were excluded because they did not finish reading within scanning time (four participants) or answered fewer than two of five control questions that were asked after the experiment correctly (one participant). All participants gave written consent and were compensated with 15 euros or course credit. The study was approved by the ethics committee of the Department for Educational Sciences and Psychology of the Freie Universität Berlin and was conducted in accordance with the Declaration of Helsinki. 


### Stimuli 
  
The narrative “Der Sandmann” (“The Sandman”) by E.T.A. Hoffmann was used as stimulus material. A prominent example of a Romantic narrative devoted to the darker sides of emotional life, the story relates events in the life of the student Nathaniel who—traumatized by the early death of his father—is haunted since childhood by the mysterious Sandman. The story was chosen because of its suspenseful character and uncanny atmosphere (famously discussed in Sigmund Freud's essay”The Uncanny”; [ ]). Importantly, the story features text passages inducing high as well as low suspense (as determined in a preceding pilot rating study), thus ensuring sufficient variability in the suspense ratings to use them as parametric regressor in the fMRI data analysis (see  ). The story was presented in German. To make it suitable for the experiment, the text was shortened (from 12,232 to 6,859 words) and some words that are now out of use and hence unfamiliar were replaced by more common ones to guarantee that participants comprehended the text. Special care was taken to ensure that the shortening of the text did not modify the plot or make the story less comprehensible. For the presentation in the MRI scanner, the story was partitioned into 65 segments of approximately equal length (  M   = 105.5 words per segment;   SD   = 26.1 words). Segmentation was done in such a way that the level of suspense varied across text segments but remained relatively constant within one text segment (  shows the segmented text used in the study). 


### Experimental procedure 
  
Participants read the story, segment by segment, while functional imaging data were recorded. The text was presented on a screen above participants' head via a magnet-compatible projection mirror system (the text was shown in a black font against a gray background). To make the reading experience as natural as possible, reading time was self-paced, i.e., participants decided how long each text segment was presented by pressing a button whenever they wanted to proceed (however, to avoid fatigue, scanning was stopped after a maximum of 60 minutes, and four participants who had not finished reading within this time were excluded from the analysis). After each text segment, participants rated how much suspense they had experienced during the preceding segment on a 10-point scale (ranging from “not suspenseful” to “very suspenseful”) using two buttons of an MRI-compatible response box. The rating screen was presented with a temporal jitter of 1.0–4.2 seconds after participants had finished reading the text segment. At the initial presentation of each rating screen, a random rating value was selected that had to be adjusted according to the experienced suspense using the two buttons (the initial random rating value was chosen to de-correlate the level of experienced suspense from the button presses during the rating). Using a third button, participants confirmed the rating and proceeded to the next text segment (the same button was used to proceed from the text segment to the rating; see  ). Participants were explicitly instructed to rate the suspense they subjectively experienced (not the suspense they thought the segment was supposed to evoke). To become familiar with the experimental task, participants completed a short practice trial (with a different text) before the actual experiment. Due to the self-paced reading times, the scanning duration varied between 28:05 and 53:52 min across participants (  M   = 42:55 min;   SD   = 7:33 min). 
   One trial of the experiment: a segment of the text was presented, followed by a rating screen on which the suspense experienced while reading the text segment was selected on a 10-point scale using two buttons (for moving the selected point on the rating scale to the left or right).  
Timing was self-paced, i.e., participants pressed a button in order to proceed to the next text segment / rating screen. A total of 65 text segments was presented during the experiment. 
  
To assess whether participants had read the text attentively, five multiple-choice control questions were asked after the experiment (in order not to influence the natural reading process, participants were not informed about this before the experiment). We also assessed participants' general reading habits (e.g., how many books they usually read per year, and what type of literature genres). We moreover acquired heart rate and respiration rate of the participants; however, due to technical failure, the heart and respiration data of some participants were not usable, and we therefore could not include them as control regressors in our fMRI analysis. 


### Image acquisition 
  
MRI data were acquired at the Dahlem Institute for Neuroimaging of Emotion at the Freie Universität Berlin using a 3 Tesla Siemens Magnetom TrioTim MRI scanner (Siemens AG, Erlangen, Germany). Before functional scanning, a high-resolution (1x1x1 mm) T1-weighted anatomical reference image was obtained using a rapid acquisition gradient echo (MP-RAGE) sequence. For the acquisition of functional data, a continuous echo planar imaging (EPI) sequence was used (37 slices; slice thickness: 3 mm; interslice gap: 0.6 mm; echo time: 30 ms; repetition time: 2 s; flip angle: 70°; 64x64 voxel matrix; field of view: 192x192 mm) with slice acquisition interleaved within the TR interval. To reduce susceptibility-induced image distortions and signal losses in areas such as the orbitofrontal cortex and the temporal lobes, the acquisition window was tilted at an angle of 30° to the intercommissural (AC-PC) line [ ,  ]. 


### Image processing and statistical analysis 
  
Data were analyzed using Matlab (MathWorks, Natick, USA) and SPM8 (Wellcome Trust Centre for Neuroimaging, London, UK). Prior to the statistical analysis of the data, functional images were realigned using a 6-parameter rigid body transformation, co-registered to the anatomical reference image, normalized to standard Montreal Neurological Institute (MNI) stereotaxic space using a 12-parameter affine transformation, and spatially smoothed with a Gaussian kernel of 6 mm full-width at half-maximum. Low-frequency noise and signal drifts were removed using a high-pass filter with a cut-off frequency of 1/256 Hz. We deliberately opted for this comparatively low cut-off frequency to avoid filtering out parts of the signal of interest (because readers' experience of suspense changes relatively slowly). Serial correlations between scans were accounted for using an autoregressive AR(1) model. 

A standard general linear model (GLM) approach was used for statistical analysis. Potential confounding factors were added as control variables to the model. The control variables included were “action”, “imageability”, arousal, valence, and average sentence length of each text segment. To determine the amount of action described in the text segments we acquired additional ratings from a different group of participants (  N   = 20, 13 female, age range: 20–33 years,   M   = 23.5,   SD   = 3.8) asking how eventful each segment was experienced during reading (ratings were given on a 7-point scale). The Berlin Affective Word List (BAWL-R; [ ]) was used to estimate imageability, arousal, and valence based on values of single words which were then averaged over all words from one text segment. Average sentence length (in words) of each text segment was added to control effects of working memory, assuming that longer sentences generally impose higher demands on working memory. Thus, the model included the following regressors: reading periods were modeled as block regressor; control variables (action, imageability, arousal, valence, and average sentence length) and individual suspense ratings were modeled as a parametric modulator [ ,  ] of the reading periods (suspense ratings were orthogonalized to the control variables); rating periods were modeled as block regressor; estimates of the motion correction parameters obtained during the realignment were added as regressors of no interest. All regressors (except for the motion correction parameters) were convolved with the standard hemodynamic response function, and model parameters were estimated using the restricted maximum likelihood approach implemented in SPM8. After model estimation, whole-brain statistical parametric maps (SPMs) were calculated for the contrasts   reading > rating   (assuming that it would be associated with typical activations of the reading network, this contrast mainly served as a sanity check of the data) and the parametric regressor   suspense   (and its inverse—  suspense  ). To obtain group level results, the contrast images of individual participants were entered into a second-level random effects analysis. To account for differences in reading times as well as in the general experienced suspensefulness of the text, total reading times and average suspense ratings of each participant over the complete text were added as control regressors into the second-level model. Activations with a   p-  value smaller than. 05 corrected for family-wise errors (FWE) at the cluster level (with a cluster-forming threshold of   p   <. 005) were considered significant (FWE-corrected cluster extent threshold: 210 voxels). Because this cluster thresholding procedure may miss smaller activation clusters, in particular activations in the amygdala which we expected to be related to suspense (see  ), we also performed a region of interest analysis in the left and right amygdala. The region of interest was defined using the probability maps of the amygdala as implemented in the SPM anatomy toolbox [ ,  ]; a statistical threshold of   p   <. 05 (FWE-corrected) was used for the region of interest analysis. 



## Results 
  
### Behavioral data 
  
 shows average suspense ratings for the story. Pearson's product-moment correlation coefficients between individual suspense profiles, averaged over all possible pairs of participants, revealed a moderate inter-participant agreement (  r   =. 31,   p   <. 05; because Pearson's correlation coefficients are not additive, a Fisher z-transformation was applied before averaging over correlation coefficients and the resulting z-value was then converted back into a correlation coefficient). Average reading time for one text segment was 29.98 s (  SD   = 12.04 s). No correlation between reading speed and suspense ratings (averaged over participants) was observed (  r   =. 08,   p   =. 55). Moreover, suspense ratings did not correlate with the lengths of the text segments (  r   = –.04,   p   =. 74). Correlation coefficients between suspense ratings and the control measures (i.e., action, imageability, arousal, valence, and sentence length) are reported in  . 
   Average suspense ratings (  N   = 23) and standard errors for each segment of the text.    

### Functional MRI data 
  
Comparing reading periods with rating periods (  reading > rating  ,  ) revealed bilateral activations in visual cortices, the entire superior temporal sulcus (with left hemispheric dominance), and anterior hippocampus (cornu ammonis). Moreover, left-hemispheric activations were observed in the precentral gyrus and fusiform gyrus. 
   Statistical parametric maps (  p   <. 05, cluster-level FWE-corrected, shown in neurological convention) for (A) the contrast   reading > rating   and (B) the parametric   suspense   regressor capturing participants' experience of suspense during reading.    
The suspense regressor (reflecting participants' individual experience of suspense) showed a medial frontal activation cluster, as well as in each hemisphere a lateral frontal and a posterior temporal cluster of activation ( ). More specifically, the lateral frontal activation clusters extended anteriorly along the IFS into the inferior frontal gyrus (IFG), and posterior-superiorly into the precentral sulcus and precentral gyrus (lateral premotor cortex). The temporal clusters covered the posterior part of the superior temporal sulcus (STS), extending into the temporo-parietal junction (TPJ). These temporal and temporo-parietal activations were more pronounced in the left than in the right hemisphere. No negative correlations with suspense were observed, and none of the analyses showed activity changes in the amygdala, nor the orbitofrontal cortex. For a complete list of activations see  . Significant activations for the parametric control regressors (action, imageability, arousal, valence, and sentence length) are reported in   and  . 
   GLM analysis: anatomical locations, peak MNI coordinates, T-values, and cluster sizes (number of voxels) of significant clusters for the   reading > rating   contrast and the parametric   suspense   regressor.        
The region of interest analysis for the suspense regressor in the left and right amygdala did not yield any significant activations. 


### Psychophysiological interactions (PPI) 
  
To investigate whether there is a relationship between suspense ratings and the functional connectivity patterns of brain areas associated with suspense, we also performed a   post hoc   PPI analysis [ ]. For this, we used the upper and lower quartiles of individual suspense ratings to dichotomize suspense ratings into high and low values which were used to test the interaction of suspense with the functional connectivity of voxels around the maxima of the five activation clusters reported above (i.e., left posterior STS, right IFS, left IFG, MFC, and right TPJ; for exact locations, see peak MNI coordinates of  ). The contrast high vs. low suspense was multiplied with the eigenvariate of the voxels within a sphere with the radius 3 mm around the peak activation voxel of each cluster to obtain the interaction term. We expected psychophysiological interactions of the regions related to suspense with limbic/paralimbic regions implicated in emotion (such as the amygdala and the orbitofrontal cortex, see  ). For the left IFG region, the PPI analysis showed significant activations in cerebellar and occipital regions as well as the posterior inferior temporal gyrus and premotor cortex. Moreover, suspense significantly modulated the functional connectivity between the MFC and bilateral occipital areas as well as parietal areas including the postcentral gyrus (see   and  ). For the other seed regions (left posterior STS, right IFS, and left TPJ), the PPI analysis did not yield significant results. 
   PPI analysis: anatomical locations, peak MNI coordinates, T-values, and cluster sizes (number of voxels) of brain areas in which suspense (high vs. low) significantly modulated the functional connectivity to the seed region.        


## Discussion 
  
In the present study, we investigated the neural correlates of suspense evoked by a literary text. For this, we acquired functional imaging data while participants read a suspenseful story subdivided into short text passages. After each text passage, a rating of subjectively experienced suspense was obtained. Suspense ratings correlated with blood oxygen level-dependent (BOLD) signal intensity in the medial frontal cortex, bilateral frontal regions along the inferior frontal sulcus (extending into the inferior frontal gyrus and premotor cortex) as well as posterior temporal and temporo-parietal regions bilaterally. 

Comparing reading periods with rating periods yielded activations in the left (and to a lesser degree right) superior temporal sulcus. Activation of these areas has previously been associated with semantic processing of written and spoken language in general (see [ ], for an overview) and story processing in particular [ ,  ]. Reading also activated the left fusiform gyrus or what has been termed the “visual word form area” which has previously been ascribed a specialized role in the processing of written words [ ,  ]. As could be expected, reading of the story thus evoked typical brain activations of a left-lateralized language and reading network. Moreover, reading was associated with increased activation in visual cortices, possibly reflecting the higher visual input during reading periods compared with rating periods. 

Suspense—as subjectively experienced by individual participants—was related to bilateral clusters of activation in the medial and dorsolateral prefrontal cortex, in particular the inferior frontal sulcus, the inferior frontal gyrus, and the precentral gyrus (lateral premotor cortex), as well as posterior temporal areas extending into the TPJ. Activations of posterior temporal regions, in particular the TPJ, have previously been related to social cognitive tasks such as perspective taking [ ] or theory-of-mind processing [ ,  ]. A meta-analysis investigating neural correlates of social cognition associated the TPJ with the inference of other people's goals and actions [ ], and TPJ activations have been repeatedly observed for story processing (e.g., [ ]; for a meta-analysis, see [ ]). Likewise, the medial frontal cortex, which also showed activation related to suspense, has been discussed as a key area associated with social cognition and theory-of-mind [ ]. For example, a study comparing theory-of-mind processing in cartoon tasks and story tasks found overlapping activity for both tasks in the medial frontal cortex [ ], coinciding with the activation found in the present study. Similarly, a study by Steinbeis and Koelsch [ ] reports medial frontal cortex activation when participants believed they were listening to music written by a composer as opposed to computer-generated music, underlining the role of the MFC in theory-of-mind processing and mental state attribution. As hypothesized in the aforementioned neurocognitive poetics model of literary reading [ ,  ], and supported by Hsu et al. [ ], activation of temporo-parietal and medial frontal areas could thus be due to readers adopting the perspective and inferring the mental states of the main characters of the story during emotionally engaging and suspenseful text segments. Suspenseful parts of a narrative plot (in particular the suspenseful text segments of the current experiment) often involve situations in which a main character of the story is facing situations of potential danger or threat. Following Zillmann's definition “that the experience of suspense in dramatic presentations derives characteristically from the respondent's acute, fearful apprehension about deplorable events that threaten liked protagonists” ([ ], p. 140), activation of the TPJ and MFC may reflect these fearful anticipations of upcoming events that depend on the ability to infer the mental states, goals, and actions of characters of the story. This is in line with connectivity studies indicating that the MFC (in particular its dorsal parts) and its connectivity with the TPJ are associated with the understanding of others' mental states [ ] (however, note that we did not find such a connectivity in our PPI analysis). Furthermore, suspense has been proposed to build on a disparity between the knowledge of a character and the knowledge of the reader or viewer (most notably discussed by Alfred Hitchcock [ ]; see also [ ]). This disparity of knowledge is often based on theory-of-mind processing (e.g., knowing that the characters don't know what one oneself knows) and could therefore account for the activation of theory-of-mind-related brain areas during suspenseful texts (however, this is rather speculative because the disparity of knowledge between characters and readers appears to be less relevant for building suspense in the specific text used in the present experiment). 

The posterior temporal activations associated with suspense (particularly the ones in the left hemisphere) also suggest that neural activity in lower-level language areas is influenced by suspense, as these areas have been associated with the cognitive processing of written words and texts, e.g., word recognition [ ,  ,  ], acoustic-phonetic processing [ ], mapping of orthographic to phonological representations [ ], and the integration of semantic information [ ]. However, whether suspense directly modulates lower-level language areas or whether suspenseful text segments tend to covary with linguistic features that could influence neural activation in lower-level language areas remains to be investigated more closely (see  ). 

In addition to the TPJ and MFC activations, suspense was associated with bilateral activations in inferior frontal regions extending into lateral premotor cortex in the precentral gyrus. The activation of premotor areas during the experience of suspense suggests a connection between suspense and neural processes of prediction and anticipation. As described previously, premotor cortex activations (particularly in ventrolateral parts) have consistently been reported for tasks involving action and event prediction (for reviews, see [ ,  ]), which is corroborated by studies showing that predictive processing of sequential information is impaired in patients with premotor lesions [ ], and that ventrolateral premotor activations are associated with the processing of biological as well as abstract non-biological stimulus sequences [ ]. Our results point to a possible role of the premotor cortex in predictive processes concerning upcoming events in a suspenseful narrative plot, thus supporting the conjecture that the premotor cortex is involved in general aspects of event prediction (regardless of whether these predictions require motor control or planning; see [ ]). Moreover, predictive inferences in the context of story processing have been associated with inferior frontal and posterior temporal activation: In a study by Jin et al. [ ], short “mini-stories” provoking predictive inferences (compared with non-predictive counterparts) were related to left IFG activations, and Virtue et al. [ ] found story passages that required active inferences (based on previous information given in the story) to be associated with activation in the right posterior STG and bilateral IFG. The inferior frontal and posterior temporal activations observed for suspense could therefore reflect predictive processes associated with inferences about the unfolding of events of the story. The involvement of predictive processes during suspenseful text segments could also provide an alternative explanation to the TPJ and MFC activations discussed above: Decety and Lamm [ ] argue that TPJ activations are not specific to theory-of-mind processing but reflect more domain-general mechanisms “involved in generating, testing, and correcting internal predictions about external sensory events” ([ ], p. 583), and similarly, MFC activations have been implicated in predictive inferences during text comprehension [ ,  ,  ,  ]. 

The close link between suspense and prediction is particularly interesting in light of Bayesian accounts of brain functioning such as predictive coding and free energy [ ,  ]. From the perspective of these theories—which postulate that perception, action, learning, and emotion [ ] are essentially based on the minimization of prediction errors, surprise, and uncertainty—suspense can be viewed as the emotional component reflecting this urge for uncertainty reduction. Novels, movies, television series and various other forms of media entertainment appear to take advantage of this fundamental principle of human cognition, thus accounting for their general appeal and popularity. However, apart from reflecting an urge for uncertainty reduction, suspense may involve other (neuro-)cognitive mechanisms. From a biological perspective, uncertainty should be associated with negative emotion (because an organism that is able to make accurate predictions about its environment should have an evolutionary advantage over organisms that are unable to make such predictions), and suspense should therefore primarily be experienced as negative (and only the resolution of suspense should have a positive valence). Yet, suspense—in particular in forms of media entertainment such as film, music, or literature—is often experienced as positive, and the emotional “thrill” associated with suspense experiences may be enjoyed for its own sake (especially when the context in which suspense is elicited is devoid of potentially negative real-life consequences, as in literature, film, or music; cf. [ ,  ]). This indicates that, apart from uncertainty, other factors may also play a role in suspense and determine whether it is experienced as positive or negative (for a more detailed discussion of this point, see [ ]). 

The bilateral activation clusters of the inferior frontal sulcus included the so-called inferior frontal junction (IFJ, cf. [ ,  ]). Located at the intersection of premotor, language, and memory areas, activations in this area have previously been reported in experiments involving cognitive control, task switching, or updating processes [ – ]. For example, a meta-analysis by Derrfuss et al. [ ] reports activation of the IFJ in experimental paradigms requiring the updating of task representations (e.g., task-switching paradigms, Stroop tasks, or n-back tasks). With regard to language processing, left inferior frontal regions have been associated with semantic encoding [ ,  ], semantic working memory [ ], semantic retrieval [ ,  ], or selection of information from semantic memory [ ]. On a more speculative note, the frontal activation clusters observed for suspense may therefore reflect the recruitment of cognitive control structures during suspenseful text segments, i.e., during passages when the reader's interest about the unfolding of events of the story is highest. Being “captured” by the story during episodes of high suspense may lead to the engagement of top-down control mechanisms that rely on the IFJ and that may optimize semantic processing of the content of the story. This is in line with dynamic causal modeling (DCM) studies showing that IFG regions coordinate temporal and parietal regions associated with lower-level language processing [ ,  ,  ]. 

The brain activations related to participants' experience of suspense partially overlap with brain activations associated with the emotional intensity of a story reported in the study by Wallentin et al. [ ]. Both suspense and emotional intensity appear to be related to bilateral inferior frontal and (posterior) temporal activations. However, there were also differences in activation patterns between the two studies: for emotional intensity, Wallentin et al. [ ] report activations of the right amygdala as well as the thalamus which we did not find for suspense; conversely, the medial frontal activations related to suspense were not found in the study by Wallentin et al. [ ]. Apart from differences between the concepts investigated (i.e., suspense vs. emotional intensity), the different activations may be due to other differences between the two studies. Whereas the study by Wallentin et al. [ ] relied on auditory presentation of the story, the present study made use of a self-paced reading paradigm. Moreover, the present study used individual suspense ratings acquired while participants read the story in the fMRI scanner, which came at the cost of repeatedly interrupting the story to collect the ratings, which may have impeded participants' full immersion into the fictional world of the story (see also  ). Last, the participants of the study by Wallentin et al. [ ] were familiar with the plot of the study, whereas they did not know the plot in the present study. 

### Limitations and outlook 
  
We also had expected suspense to be related to neural activity in limbic brain structures associated with emotional processing such as the amygdala or the striatum. This hypothesis was not confirmed. One aspect of our experiment that may have compromised the evocation of strong emotional responses was that participants had to shortly interrupt reading after each text segment to give the suspense ratings, which may have disrupted the immersive reading experience usually associated with natural reading of suspenseful texts. We had deliberately opted for these online suspense ratings to capture the suspense experience of each individual participant as accurately as possible (alternative methods of acquiring suspense ratings after participants have read the complete text—and hence without interrupting the reading process—or of using average suspense ratings of a different group of participants might have reflected individual suspense experiences during reading less accurately, thus decreasing the sensitivity of the statistical analysis). However, it remains to be investigated whether uninterrupted reading of a suspenseful text engages limbic brain structures associated with emotional processing. Using “stronger” stimulus material—for example, suspenseful movie scenes—may further facilitate the measurement of neural substrates of emotional responses related to suspense. 

Moreover, it may be objected that lower-level stimulus features may have confounded the brain activations observed for suspense. We accounted for possible confounds by including action, imageability, arousal, valence, and average sentence length of each text segment as control variables in the model. However, when investigating a high-level concept like suspense in a relatively naturalistic setting using a real text, controlling all possible low-level stimulus properties is unfeasible, and the possibility that results are influenced by these stimulus features can never be entirely excluded. For example, the IFG activations observed for suspenseful text segments could also be interpreted as reflecting effects of syntactic processing (cf. [ ]). We did not include syntactic complexity as a control variable because there is no straightforward measure quantifying syntactic complexity in natural language texts. However, increased syntactic processing during suspenseful text segments seems unlikely because the relationship between syntactic complexity and suspense in the text of the present experiment is rather negative, i.e., suspenseful text segments tended to feature more simple sentences (often a concatenation of simple main clauses with few embedded sentences) than less suspenseful segments. Nevertheless, controlling as many confounding variables as possible in future neuroimaging studies on suspense is highly desirable. This includes physiological parameters such as heart or respiration rate. 

Finally, we used only one text as experimental stimulus. Whether the results reported here generalize to other texts and domains (e.g., film) remains to be clarified by future research. 



## Conclusion 
  
Suspense is an important component of the emotional experience evoked by narrative plots (e.g., in literature, film, etc.). To our knowledge, this is the first study exploring the neural correlates of suspense during the reading of a literary text. Recording functional imaging data while participants read a suspenseful piece of literature, we found that individual ratings of suspense were related to activity in the medial frontal cortex, posterior temporal and temporo-parietal regions, as well as the dorsolateral prefrontal cortex along the inferior frontal sulcus including the IFG and premotor cortex. Our results indicate that text passages that are experienced as suspenseful engage brain areas associated with mentalizing, predictive inference, and possibly cognitive control. 


## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-19'>
<h2>19. PMID: 29813018</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Cognitive regulation alters social and dietary choice by changing attribute representations in domain-general and domain-specific brain circuits</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> eLife</p>
<p><strong>Publication Year:</strong> 2018</p>
<p><strong>DOI:</strong> 10.7554/eLife.31185</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Study includes an fMRI altruism task (dictator-game style) probing social decision-making (focus on partner/ethics), meeting the requirement of scanning humans during a social-related task. Participants are healthy adults (N=55 for altruism; mean age ~28, range within 18–60). Analyses report whole-brain results (searchlight MVPA, whole-brain group-level maps with FWE cluster correction, conjunctions), not limited to ROI-only findings (though some post-hoc ROI tests are reported). The paper is an original empirical fMRI study (not a review/meta-analysis) and does not involve psychiatric or neurological patient groups. Therefore all inclusion criteria are satisfied.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Are some people generally more successful using cognitive regulation or does it depend on the choice domain? Why? We combined behavioral computational modeling and multivariate decoding of fMRI responses to identify neural loci of regulation-related shifts in value representations across goals and domains (dietary or altruistic choice). Surprisingly, regulatory goals did not alter integrative value representations in the ventromedial prefrontal cortex, which represented all choice-relevant attributes across goals and domains. Instead, the dorsolateral prefrontal cortex (DLPFC) flexibly encoded goal-consistent values and predicted regulatory success for the majority of choice-relevant attributes, using attribute-specific neural codes. We also identified domain-specific exceptions: goal-dependent encoding of prosocial attributes localized to precuneus and temporo-parietal junction (not DLPFC). Our results suggest that cognitive regulation operated by changing specific attribute representations (not integrated values). Evidence of domain-general and domain-specific neural loci reveals important divisions of labor, explaining when and why regulatory success generalizes (or doesn’t) across contexts and domains. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (79776 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Choices often require us to weigh competing considerations. Does a decadent piece of cake merit the pounds we’ll put on afterwards? Should the pleas of a homeless person trump our own selfish needs? Empirical evidence suggests that the answer to these questions depends in part on a decision maker’s goals ( ) and can be affected by intentional control ( ;  ;  ). Cognitive regulation of decision making thus serves an important function in goal-directed behavior ( ), relying on attention, working memory, and executive control to promote particular, goal-congruent choices (e.g., eat healthier, be kinder). Cognitive regulation of decision making is an important technique in therapeutic interventions for problematic behaviors, including obesity ( ), addiction ( ), and other decision making disorders ( ). Previous findings have significantly advanced our understanding of the psychological and neural bases of cognitive regulation of decision making ( ;  ;  ;  ), yet important questions about its computational underpinnings remain. At what level of the processing stream does goal-dependent cognitive regulation change the typical trajectory of choice? Does it operate in the same manner in different contexts, or does it depend on the domain? Answering these questions has important ramifications for understanding when people succeed or fail to implement their regulatory goals during decision making, why some people seem to succeed more often than others, and whether there are neural targets for treatment or biomarkers to identify at-risk individuals. 

In studies of basic choice, weighted additive utility models have been used successfully to capture patterns in human behavior across a variety of domains ( ;  ). In these models, decision makers compute the decision value (DV) of each option as the weighted sum of its choice-relevant attributes   ( ;  ) and compare them to make a choice. Recent neuroscience work provides evidence in favor of this model, observing signals related to the value of specific attributes in distinct cortical and subcortical areas, for both social ( ;  ) and non-social choices ( ;  ). In turn, signals correlated with the overall, integrated decision value of an option have been observed in multiple regions, such as the ventromedial prefrontal cortex (VMPFC) and ventral striatum ( ;  ;  ;  ;  ;  ;  ). A key goal of neuroeconomics is to describe how these attribute and decision value computations change as a function of regulatory goals and contexts, and to link such changes to regulatory success. Here, we sought to address three important questions about this process. 

First, at what level does cognitive regulation operate to change value representations? Based on the neuroeconomic model outlined above, we hypothesized two possibilities. The   attribute-level   hypothesis suggests that cognitive regulation of decision making could alter value representations at a relatively low level, by amplifying or diminishing attribute representations directly in a distributed set of specific, dedicated attribute-coding areas, similar to attentional effects on visual object encoding ( ). Alternatively, the   integration-level   hypothesis suggests that cognitive regulation of decision making might operate at comparatively higher levels in centralized, domain-general value integration areas such as the VMPFC ( ;  ). 

Second, we aimed to explicitly test whether cognitive regulation alters value representations at the   same   level regardless of domain, or whether it differs as a function of attributes, goals or choice domain. For example, some attributes (such as taste) may be innate and prepotent, while other attributes (such as health or social considerations) may be more abstract or effortful to construct ( ;  ;  ). We sought to test whether these distinctions might affect where and how cognitive regulation operates to alter value representations during decision making. We also sought to determine whether this translates into distinct regulatory capacities as a function of regulatory goal or choice domain. 

Finally, we sought to shed light on whether information represented in VMPFC and dorsolateral prefrontal cortex (DLPFC) supports either attribute-level or integration-level changes in value during cognitive regulation of decision making. For example, some experimental evidence supports the idea that the DLPFC might represent more abstract attributes like health ( ;  ), and that regulatory control could modulate interactions between the DLPFC and VMPFC to change attribute weights in integrative decision value computations ( ;  ;  ;  ). However, several failures to observe changes in the VMPFC during cognitive regulation of decision making ( ;  ;  ) suggest the need to either measure value computation in a more sensitive way, or to identify alternate routes to behavioral change. 

Addressing these issues requires investigating regulatory control across multiple attributes and domains, using a sophisticated array of approaches for identifying changes in the representations of both specific attributes and integrated value signals. We used functional magnetic resonance imaging (fMRI) to measure brain responses while subjects completed two choice tasks, separated in time by up to 24 months ( ). Choices involved foods varying in healthiness and tastiness (food task) or monetary proposals varying in payoffs for subjects and an anonymous partner (altruism task). To mimic the kinds of cognitive reframing approaches that are often used in therapy for decision making disorders ( ;  ), both tasks asked subjects to adopt distinct regulatory goals designed to highlight different choice attributes (e.g., ‘focus on the food’s healthiness’, ‘focus on your partner’s feelings’). To pinpoint whether and how regulation altered specific attribute representations or integrative value computations at the behavioral and neural level, we combined a multi-attribute extension of the drift diffusion model (DDM) ( ;  ) with multivariate pattern analyses (MVPA) of neural responses ( ;  ). MVPA approaches to fMRI data exploit information encoded across multiple voxels and have been suggested to detect information that would be missed by conventional univariate analyses ( ). Past research on cognitive regulation has relied primarily on mass univariate approaches, which could account for some of the inconsistencies observed in the literature. Our study used MVPA to examine whether and how directed attention to specific goals affects the neural information content (i.e., decoding accuracies) for attribute values in different social and non-social decision contexts. We hypothesized that goal-dependent changes in neural decoding accuracies would match predictions on altered attribute weights from the behavioral computational model. We investigated where such changes occurred, whether they operate in generic or domain-specific manner, and whether they predicted specific aspects of regulatory success across individuals. 
   fMRI Paradigms and Choices.  
(  A  ) Food Task. Subjects chose between on-screen food items that varied in tastiness and healthiness and a neutral default food. Choices were made in ‘Natural’ [NC], ‘Focus on Health’ [HC], and ‘Focus on Taste’ Conditions [TC]. (  B  ) Altruism Task. Subjects chose between on-screen proposals that affected the payoff of themselves ($Self) and an anonymous partner ($Other) and a default option ($20 for both). Choices were made in ‘Natural’ [NC], ‘Focus on Ethics’ [EC], and ‘Focus on Partner’ Conditions [PC]. (  C  ) (  D  ). Bar plots illustrate condition-wise percentages of healthy (C) and generous (D) choices (M ± SD), and subject-specific scores (circles). *p < 0.05, corrected,  p < 0.05, uncorrected. (  E  ) Computational behavioral model (DDM). Choices (yes/no) are made when the sequential accumulation of noisy value information that unfolds over time crosses the predefined upper or lower threshold for choice. The relative decision value (RDV) at a point in time (t) is computed as the weighted sum of choice relevant attributes plus noise (ε) (i.e., RDV  = RDV + w  * Tastiness + w  * Healthiness + ε ). In the example displayed here, the value of a candy bar will tend to accumulate in a positive direction if the weight on Tastiness is high (blue line), yielding a choice in favor of a tasty but unhealthy item. However, the value of the food item is more likely to accumulate in a negative direction if the weight on Healthiness is high (brown line). Note that saying Yes can sometimes indicate a healthy choice, and sometimes an unhealthy choice. (RT = reaction times [sec]; figure adapted from [ ;  ]). 
 
   Drift diffusion model (DDM) fits to behavior in both choice tasks.  
(  A  ) Correspondence in the altruism task between observed acceptance rates (top) and response times (bottom) for different proposal types (bars) and model predictions (blue circles, determined using best-fitting parameters for each subject). On average, subject-level correlation between observed and predicted acceptance rates across trial types was generally quite high. (  B  ) Correspondence in the food task between observed and model-predicted acceptance rates (top) and response times (bottom) for foods of varying taste and healthiness (subject-specific ratings outside the scanner). For illustration purposes, for both tasks model fit to behavior is shown for eight bins created based on the displayed color scheme (right) for variations in choice-relevant attributes (increased attribute values from left to right). Thus, bar colors correspond to trials with specified combination of attributes. 
  
 

## Results 
  
### Behavior 
  
To identify how value computations change to accommodate regulatory goals, our analysis strategy proceeded in the several steps. First, on the behavioral level, we confirmed that regulatory goals resulted in altered choice behavior. We also used our computational behavioral models (multi-attribute drift diffusion models, DDMs) to link these alterations to amplification or suppression of the influence of specific choice-relevant attributes on choices. 

#### Choice behavior 
  
Choices in both tasks varied considerably by regulatory goal ( ). In the food task, subjects made choices in three conditions: Respond Naturally [NC] (‘respond as you naturally would’), Focus on Health [HC] (‘focus on the healthiness of the food when making the choice’), and Focus on Taste [TC] (‘focus on the tastiness of the food when making the choice’), implemented in interleaved blocks (see Appendix 1 – Instructions for regulatory conditions in both choice tasks for instructions). We defined a healthy choice as accepting the on-screen food if it was healthier than the default food (based on subject-specific healthiness ratings obtained outside of the scanner, see Materials and methods), and rejecting it otherwise. As expected, subjects made significantly healthier choices during HC (M ± SD: 78.83% ± 18.46) compared to both NC (44.31% ± 10.71) and TC (41.99% ± 11.46; paired t-tests: p’s < 0.001, Bonferroni corrected unless stated otherwise). They also made marginally less healthy choices during TC than NC (p = 0.043, uncorrected; repeated measures ANOVA across all conditions: F(2,35) = 97.01, p < 0.001). 

In the altruism task, subjects were instructed either to Respond Naturally [NC] (‘respond as you naturally would’), Focus on Ethics [EC] (‘focus on doing the right thing and consider the ethical or moral implications of your choice’), or Focus on Partner [PC] (‘focus on your partner’s feelings and how the other person is affected by your choice’) (see Appendix 1 – Instructions for regulatory conditions in both choice tasks for instructions). We defined an altruistic choice as accepting an on-screen proposal whose outcome (relative to the default) benefitted the other at a cost to the self, or rejecting one in which the subject stood to benefit but their partner did not. As expected, subjects made altruistic choices significantly less often under NC (28.71% ± 15.48) compared to EC (49.94% ± 16.22) or PC (66.97% ± 24.35; p’s < 0.001; F(2,35) = 65.96, p < 0.001) ( ). Altruistic choices were also significantly higher in PC than EC (p < 0.001), suggesting that directing attention to another persons’ feelings generally increased altruism more effectively than considering social and moral norms. Overall, these findings confirmed that regulatory goals resulted in altered choice behavior in the food task and the altruism task. 


#### Regulatory success 
  
Given the considerable individual heterogeneity in the extent of these changes, we also sought to understand whether this heterogeneity might be consistent across tasks and regulatory instructions. Regulatory success – defined as goal-consistent changes in percent healthy or altruistic choices ( ) (e.g., the increase in healthy choices during HC compared to NC) – covaried across tasks ( ). People who chose healthy foods more often when attending to a food’s healthiness also behaved more altruistically when focusing on pro-social attributes. These results did not depend on the delay between tasks (partial correlations controlling for delay of up to 24 months, M ± SD: 16.42 ± 8.66, range: 1 to 24) or differences in baseline responding   within   a particular condition: the percentage of healthy and altruistic choices during NC blocks of both tasks did not correlate (all p’s > 0.05, uncorrected). Instead, they were driven by choice behavior during regulation: healthy choice during HC correlated with altruistic choice in both EC (r = 0.45, p < 0.05) and PC (r = 0.66, p < 0.001). Overall, these findings indicate that an individuals’ regulatory success generalized across choice domains. We found no significant correlation of self-reported motivation to comply with instructions with regulation success in the food task (all p’s > 0.14, uncorrected) or the altruism task (all p’s > 0.16, uncorrected) (Appendix 1 – Self-reported motivation to comply with instructions and observed regulation-success). 
   Correlation of regulatory success (RS) in both choice tasks.      

#### Computational parameter estimates (DDMs) 
  
We hypothesized that changes in choice behavior could result either from increased weighting of goal-consistent attributes (e.g. healthiness in HC), decreased weighting of goal-inconsistent attributes (e.g. tastiness in HC), or both. We tested these possibilities by fitting multi-attribute DDMs to behavior, separately for each subject in each condition and task (see Appendix 1 – Drift diffusion model for details). Model fits to behavior indicated that we were able to capture both choices and RTs with high accuracy ( ). Supplemental analyses also confirmed that the DDM did not perform worse in capturing behavior during regulation conditions compared to natural choices (Appendix 1 – Drift diffusion model). To determine if regulatory goals altered weights assigned to distinct attributes, we computed repeated measures ANOVAs with regulatory goal as a within-subject factor, separately for each attribute. 

As predicted, regulatory goals in the food task changed the weights assigned to tastiness and healthiness (all F(2,35) ≥ 103.36, p’s < 0.001; see   for attribute-specific estimates; for complete list of model-estimates and RTs see  ). Healthiness influenced food choices   more   in HC, and   less   in TC, compared to NC ( , all p’s ≤ 0.001). By contrast, tastiness influenced food choices less in HC, compared to both NC (p < 0.001) and TC (p < 0.001) ( ). No differences emerged between NC and TC (p = 0.47, uncorrected, 2-tailed), suggesting that decision processes in TC likely resemble natural choice contexts. 
   Goal-dependent modulation of attribute value encoding.  
 Behavioral   weights (left column) assigned to attributes in food choices (  A  . Healthiness,   C  . Tastiness) or altruistic choices (  E  . $Self,   G  . $Other,   I  . Fairness) varied by regulatory goal (estimates of drift diffusion models, DDMs).   Neural   decoding accuracies of attribute values (right column) also varied across conditions in specific brain regions (  B  . Healthiness,   D  . Tastiness,   F  . $Self,   H  . $Other,   J  . Fairness) (p < 0.05, FWE corrected at cluster-level) (estimates of Support Vector Regression models, SVRs). Bars represent median estimates (blue = behavioral DDMs, red = neural SVRs; black boxes signify 25–75 percentile, lines illustrate the overall distribution), HC = Health Condition, NC = Natural Condition, TC = Taste Condition, PC = Partner Condition, EC = Ethics Condition, L = left hemisphere, R = right hemisphere, LPFC = Lateral Prefrontal Cortex, SFG = Superior Frontal Gyrus, MFG = Mid Frontal Gyrus, TPJ = Temporoparietal Junction, SFS = Superior Frontal Gyrus. 
 
   Goal-dependent modulation of neural value encoding in DMPFC ($Self) and Precuneus ($Other) in the altruism task.  
Panel displays average decoding accuracies for clusters where neural representations of attributes varied across regulation conditions for neural Support Vector Regressions (SVRs) (p<0.001, FWE corrected at cluster-level). Bars represent median estimates; black boxes signify 25–75 percentile, lines illustrate the overall distribution. HC = Health Condition, NC = Natural Condition, TC = Taste Condition, PC = Partner Condition, EC = Ethics Condition, L = left hemisphere, R = right hemisphere. 
  
    Model-estimated weights (w) assigned to choice-relevant attributes in the food task and altruism task (DDMs).    
Regulatory goals had a similarly dramatic influence on attribute weights in the altruism task (all F(2,48) ≥ 21.48, p’s < 0.001;  ). Subjects’ choices were swayed more strongly by their own monetary outcome ($Self) in NC compared to PC (p < 0.001) and marginally compared to EC (p = 0.059, uncorrected, 2-tailed) ( ). Moreover, the influence of their own payoffs on choices decreased more dramatically in PC than EC (p < 0.001). In contrast, estimated weights on the partner’s monetary outcome ($Other) increased for both pro-social regulatory conditions compared to NC (p’s < 0.001), with marginally higher weights in PC than EC (p = 0.013, uncorrected, 2-tailed) ( ). Fairness of proposed payouts (−1*|$Self - $Other|) influenced choices significantly less in NC compared to EC (p < 0.001), and marginally less compared to PC (p = 0.021, uncorrected, 2-tailed). Weight on fairness was also significantly higher in EC than PC (p < 0.001) ( ). Note that within-task results for the altruism task are reported for the slightly larger sample size of 49 subjects. Considering only the subset of subjects that also participated in the food task (N = 36) yielded comparable weights for attributes in altruistic choices ( ). Overall, the results suggest that regulatory goals changed choice behavior by both increasing weighting of goal-consistent attributes (e.g. healthiness in HC) and decreasing weighting of goal-inconsistent attributes (e.g. tastiness in HC). 



### Neural encoding of choice attributes and effects of regulation 
  
Next, we examined neural underpinnings of goal-consistent increases/decreases in the influence of attributes on altered choices in both tasks. This analysis step was designed to provide evidence for the effects of regulation at the attribute-level or integration-level. Both hypotheses suggest that changes in the influence of distinct attributes on choice should correspond to changes in neural encoding of those attributes. However, they make different predictions about   where   these changes should be observed. The attribute-level hypothesis predicts that attributes are encoded in attribute-specific brain areas and that regulation should result in changes to these local representations. By contrast, the integration-level hypothesis suggests that attribute-specific areas should encode attributes similarly   regardless   of the regulatory goal. Instead, altered representations should appear only within centralized brain regions associated with value-integration, such as the VMPFC, and should be detectable in a common signal associated with integrated values. We tested these distinct predictions by examining where attribute values were represented in the brain, and how these representations varied as a function of regulatory focus. We also explicitly tested whether the locus of effect differed across attributes (e.g. tastiness/healthiness, $Self/$Other/Fairness) or choice domain (e.g. social, non-social). 

#### Neural encoding of choice attributes and decision values across conditions 
  
Our behavioral results suggest that a weighted combination of different choice-relevant attributes captures behavior in both choice tasks ( ), implying that attribute information should be represented in the brain. However, the generality and specificity of this encoding has important implications both for theories about how different attributes are constructed, and how regulation operates to modulate their influence. We first sought to determine which brain regions reliably encoded trial-by-trial variation in a given attribute across experimental conditions and goals. Thus, this first set of decoding analyses tested   if   neural activation patterns encode attribute values, irrespective of whether one or several conditions drive this predictive information. To this end, we averaged the condition-specific decoding maps of an attribute for each subject and tested for brain regions that reliably predict values of the attribute at the group level. Consistent with predictions, information about each attribute could be decoded significantly above chance in multiple brain regions ( ), including the VMPFC, and, for some attributes, the DLPFC. This was also true for trial-by trial encoding of decision values (DVs, corresponding to observable choices in the altruism and food task). See   (main effects) for a complete list of results and details on the clusters in the (V)MPFC and DLPFC for the neural decoding of DVs. 
   Neural prediction of trial-wise attribute values in food choices and altruistic choices.      

#### Conjunction of neural representations of choice attributes 
  
Given the robust coding of individual attributes, we asked whether any brain regions encoded   all   attribute values across all contexts, as might be expected of domain-general areas contributing to value integration processes. A formal conjunction of all attribute-specific decoding maps (Healthiness, Tastiness, $Self, $Other, Fairness; thresholded at p < 0.05, FWE cluster-level correction, height threshold of p < 0.001) identified VMPFC ([MNI −6, 49, 1],  ) as well as a handful of other regions ( ). This suggests that the VMPFC contains information on trial-wise values of   all   choice-relevant attributes, consistent with its hypothesized importance for valuation and choice. 
   Conjunction of neural representations of attribute values.  
Multivariate response patterns in the VMPFC encoded trial-wise values of all choice-relevant food attributes (Tastiness, Healthiness) and altruistic attributes ($Self, $Other, Fairness) across regulation conditions, as indicated by a conjunction of attribute-specific decoding maps thresholded at p < 0.05, FWE corrected at cluster-level. 
 
   Conjunction of brain areas that encoded trial-by-trial values of all attributes.  
Attribute values for Healthiness, Tastiness, $Self, $Other, Fairness. Each attribute was thresholded at p < 0.001, cluster-level corrected, k = 10 voxels. Not displayed are clusters in the supplemental motor area ([MNI −3 26, 46], 43 voxels) and visual cortex ([MNI −28,–85, 32], 15 voxels, [MNI −21,–67, 40], 10 voxels). Coordinates refer to center of mass for the identified clusters in MNI space (Montreal Neurological Institute), R = right hemisphere. 
  

   Exploratory functional connectivity analyses.  
(  A  ) Region of the VMPFC (red) where increased connectivity with the DLPFC during Health vs. Natural and Taste focus conditions correlates with Δw Healthiness in Health vs. Natural and Taste Focus. The yellow region shows the VMPFC ROI defined by the conjunction of all attributes. Orange indicates overlap. Inset: DLPFC seed region. (  B  ) Region of the VMPFC (red) where decreased connectivity with the DLPFC during Partner and Ethics conditions compared to Natural predicted decreases in Δw $Self in Partner and Ethics vs. Natural condition. The yellow region shows the VMPFC ROI defined by the conjunction of all attributes. Inset: DLPFC seed region. (  C  ) Region of the Precuneus where increased connectivity with the VMPFC during Partner vs. Ethics conditions Δw $Other weight in Partner vs. Ethics trials. Yellow region shows the VMPFC ROI defined by the conjunction of all attributes. Inset: Precuneus seed region. All results are shown thresholded at p < 0.005 uncorrected. 
  
 

#### Goal-dependent representations of choice attributes and decision values 
  
Having confirmed that attribute values (and decision values) could be decoded from neural response patterns, we next asked whether, how and where neural information content changed as a function of regulatory goals. We hypothesized that altered behavioral weights of an attribute should be mirrored by changes in the neural encoding of that attribute as expressed in varying predictive accuracies. Crucially, these analyses allowed us to test whether goal-dependent change in neural encoding of attribute values occurs in attribute-specific regions or at a common neural locus regardless of attribute or domain. For each attribute, we used a repeated measures ANOVA implemented in SPM together with condition-specific decoding accuracy maps to test for changes in neural information on attribute values across conditions (see  ). This allowed us to identify brain regions where neural information content about an attribute, or decision values ( ), was enhanced or diminished in a way that matched behaviorally-estimated changes in attribute weighting (thresholded at p < 0.05, cluster-level corrected, height threshold of p < 0.001; see  ). 
   Goal-dependent coding of attribute values (left to right).  
For each participant, we created a spherical searchlight (left panel, black sphere) and extracted multi-voxel response patterns for every trial of a choice task (middle panel). Next, we trained a support vector machine (SVM) regression model with data of 8 runs (80 trials), using neural response patterns as features and trial-wise attribute values as labels (e.g. a food’s perceived tastiness). Test data consisted of data of the ninth run (10 trials) for which we predicted the trial-wise attribute values solely based on neural response patterns of these trials. The decoding accuracy (average of 9-fold cross-validation) was assigned to the central voxel of the sphere from which we extracted the neural data (right upper panel). This procedure was repeated for every measured voxel (left panel, dotted red line), yielding a whole brain accuracy map for an attribute, separately for each task condition and participant. Finally, at the group level (lower right panel), we used these whole-brain accuracy maps to test for brain regions where predictive information on an attribute was increased/decreased depending on the task condition, based on predictions of the behavioral computational model (DDM). (Note that condition-specific accuracy maps also allowed testing for main effects of neural encoding of an attribute (i.e. encodes attribute values), irrespective of whether one or several conditions drive the effect.). 
     Goal-dependent change of neural information content on attribute values.      
##### Healthiness 
  
Behavioral model-fitting suggests that healthiness was weighted more heavily in HC compared to both NC and TC ( ). Consistent with model-based predictions, decoding accuracies in the right lateral prefrontal cortex (LPFC) were higher when focusing on health [HC] compared to both other task conditions ([HC >NC], and [HC >TC]) and combined [HC > (NC, TC)];  ;  ). 


##### Tastiness 
  
Behaviorally, tastiness was represented less strongly in HC compared to NC and TC, with no significant differences between the latter ( ). Decoding accuracies in the right superior frontal gyrus (SFG), extending to the mid frontal gyrus (MFG), closely matched these predictions [(NC, TC) > HC] ( ). Neural representations of trial-wise tastiness were also significantly higher for separate comparisons of [NC > HC] and [TC > HC], but did not differ between NC and TC. Only two other regions (visual cortex and left motor cortex) followed this pattern ( ). 


##### $Self 
  
Estimates of the best-fitting behavioral parameters for $Self suggest that neural information representing subjects’ own benefits should decrease in both pro-social regulation conditions (PC and EC) compared to NC ( ). Formal tests of this pattern ([NC > (EC, PC)]) identified neural responses in both DMPFC ( ) and the MFG (p < 0.001, uncorrected;  ; for [NC] > [EC] significant at p < 0.05, cluster-corrected). 


##### $Other 
  
Based on the behavioral model we predicted that, compared to NC, the partner’s benefits should be represented more strongly when attending to either ethical implications or the other’s thoughts and feelings ( ). Surprisingly, no brain regions matched this precise pattern (for [(PC, EC) > NC], or [PC > NC], or [EC > NC], at p < 0.05, cluster-corrected). However, a comparison of [PC > EC] revealed that decoding accuracies in the bilateral precuneus and right temporoparietal junction (TPJ) ( ) ( ) were significantly more predictive of the others’ payoffs when goals focused on the partner compared to ethical implications. Supplemental ROI analyses within these two areas indicated that average predictive accuracies were significantly higher in PC than NC, partially confirming the prediction of amplified information for $Other [PC > NC] from the behavioral model ( ). 


##### Fairness 
  
Behaviorally, fairness of payoffs for self and partner influenced choices more strongly when attending to ethics [EC] and, to a lesser extent, the partner’s feelings [PC] ( ). Consistent with model-based predictions, decoding accuracies in the left superior frontal sulcus (SFS) predicted the degree of fairness more strongly in the two regulatory conditions compared to natural choice contexts ( ). Contrary to the model prediction, comparisons of [EC > PC] (and [PC > EC]) did not yield any significant results, suggesting that both regulation conditions increased neural representations of fairness considerations to a comparable level. 

Notably, repeated measures ANOVAs also allowed testing for changes in neural attribute representations or decision values that were   not   predicted by changes in the behavioral DDM estimates. These supplemental tests did not yield any further significant results (p < 0.05, FWE cluster-corrected). 


##### Decision values 
  
See   for details on goal-dependent coding of decision values in both tasks. Only two regions (motor cortex in food task [TC > HC], cerebellum in altruism task [EC >PC]) were found to be significant (p < 0.05, FWE cluster-corrected). We thus focused on goal-dependent changes in information content on attribute values. 



#### A common hub for cognitive regulation of attribute values in the DLPFC 
  
To determine whether any areas might serve as a common pathway for goal-dependent changes in encoding of choice attributes, we computed 2-, 3- and 4-way conjunctions of all clusters that showed modulations of predictive information across conditions ( ). A cluster in the MFG ( ), hereafter referred to as DLPFC, emerged in the 3-way conjunction of voxels that flexibly encoded attribute values for Healthiness, Tastiness, and $Self. We found no other areas showing such a convergence of attributes. 
   Domain-general locus of goal-dependent attribute coding.  
(  A  ) Conjunction of voxels in DLPFC that flexibly encoded attribute values of Healthiness, Tastiness, and $Self across conditions within the respective task (p < 0.05, FWE corrected at cluster-level). (  B  ) Cross-condition decoding analyses tested for shared neural code in the DLPFC conjunction area across attributes and regulatory goals. Multivariate SVR models were trained on data in one condition (e.g. Taste NC) and tested on another (e.g. Taste TC), and vice versa (2-fold cross-validation; within-cell sanity checks used split-half approach). Red illustrates significant cross-condition decoding, blue illustrates non-significant results (permutation tests, cutoff-values of 95th percentile of empirical null-distribution).   Within-attribute decoding   (yellow frames): similar neural codes in DLPFC encode values of an attribute across contexts/regulatory conditions (with the exception of 2 of 18 tests).   Cross-attribute decoding  : neural response patterns that encode values of one attribute don’t allow predicting values of another attribute (neither within-task [tastiness-healthiness] nor across tasks [tastiness-$Self, healthiness-$Self]), independent of contexts. This pattern of results indicates that goal-sensitive representations of attribute values in DLPFC rely on attribute-specific neural codes. 
  
This finding suggests that the DLPFC acts as a domain-general circuit for goal-sensitive value representations. But what does this convergence in the DLPFC signify? On the one hand, the DLPFC might encode a   unitary decision value signal   that is sensitive to current goals. While limited to a specific set of attributes, this would support the integration-level hypothesis. If this was the case, the same code that represents a food’s tastiness in the food task (e.g. when focusing on taste) should also permit decoding of other attribute values used in other contexts (i.e., healthiness when focused on health, $Self in natural settings of altruistic choice). On the other hand, the DLPFC might compute attribute-specific representations in a goal-sensitive manner. This hypothesis is more consistent with attribute-level modulation. In this case, encoding of attribute values in this region should be unique to each specific attribute (i.e. codes for one attribute should not permit decoding of other attributes). We tested these competing predictions in a post-hoc ROI-based analysis examining the extent to which neural codes for one attribute in one context (e.g. tastiness in TC) generalize across attributes and contexts (e.g. healthiness in HC). These post-hoc decoding analyses differ from the previous set of analyses: more specifically, to probe for shared neural code in the DLPFC, we trained the SVM regression model on data of one attribute in one condition and see if it allows predicting trial-wise values of   another   attribute in the same or different regulatory condition (and vice versa, 2-fold cross-validation). We also tested for common neural codes for the same attribute across regulatory contexts. 

Results most clearly supported the attribute-level hypothesis. While codes for each attribute (tastiness, healthiness, and $Self) in the DLPFC generally allowed for decoding of the same attribute in other conditions at significant or marginally significant levels, no attribute allowed for coding of a   different   attribute, regardless of condition ( ). This supports the idea that the DLPFC acts as a domain-general mechanism for representing different attributes in a goal-sensitive manner, using unique codes for each attribute. 


#### No evidence for goal-dependent coding of attribute values and decision values in the VMPFC 
  
The vmPFC has previously been suggested to encode attribute values as a function of their current relevance to choice control ( ). Notably, our analyses on the whole brain level did not reveal any significant variation of attribute value encoding in this area as a function of the regulatory goal. However, in light of previous evidence, we conducted a number of post-hoc ROI-analyses to probe in a more sensitive manner for goal-dependent value coding in the VMPFC (see Appendix 1 – ROI-based post-hoc tests to identify goal-consistent value coding in the VMPFC). While activation patterns in the VMPFC (as well as several other regions) reliably predicted overall decision values in both tasks, regulation failed to modulate decoding accuracies for decision value ( ) or for   any   specific attribute (Appendix 1 – ROI-based post-hoc tests to identify goal-consistent value coding in the VMPFC), and did not predict individual differences in regulatory success (Appendix 1 – ROI-based post-hoc tests to identify goal-consistent value coding in the VMPFC). 



### Individual differences in regulatory success 
  
Are some people   generally   more successful using cognitive regulation of decision making or does it depend on the choice domain? Why? To address these questions, we examined the generality and specificity of value representations and their role in regulatory success. In particular, we predicted that if regulatory success operates through common   domain-general   mechanisms, individual success in regulating the effects of one attribute should be correlated with regulatory success in modifying different attributes in completely different contexts. Consequently, neural responses within such a domain-general neural locus should predict individual differences in people’s regulatory success across domains. By contrast, to the extent that cognitive regulation of decision making operates at the attribute-level in a   domain-specific   manner, success regulating one attribute in one domain should be uncorrelated with regulatory success for other attributes in other domains. It should also be predicted by neural activation in distinct, non-overlapping brain regions. 

#### Regulatory success in goal-dependent attribute weighting 
  
Although our previous analyses suggested that regulatory success as measured by frequency of healthy and generous choices was correlated across participants, this analysis did not examine how such success relates to changes in specific attributes. Thus, to determine whether regulatory success operates through common channels across attributes and domains, we first tested using behavior whether subjects’ ability to modulate specific attribute weights (estimated in separate DDMs) was correlated across the two tasks. Consistent with the notion of a common neural mechanism (in DLPFC), successful reduction in the weight on selfish considerations (Δw $Self) in altruistic choices was correlated with successfully amplifying the weight on health considerations in food choices (e.g., r = 0.50, for Δw $Self [NC - PC] and Δw Healthiness [HC - NC], p < 0.05, corrected) and suppressing the weight of taste considerations in food choices (e.g., r = 0.45, Δw $Self [NC - PC] and Δw Tastiness [NC - TC], p < 0.05, corrected). Notably, however, enhancement of the weight on another person’s outcomes did   not   correlate with changes in other attributes (all p’s > 0.05, uncorrected). See   for detailed list of results. Overall, this pattern suggests that regulation may operate through both common and distinct channels as a function of specific attributes, a point we return to in the neural results below. 


#### Domain-general predictions of individual differences in regulatory success in DLPFC 
  
Our preceding neural decoding results support a model in which regulation alters specific attribute representations within domain-general brain areas for some attributes (e.g., tastiness, healthiness, $Self) and within domain-specific areas for other attributes (e.g., $Other, fairness). This idea may explain the specific pattern of correlations we observed in behavioral measures of regulatory success and makes a further prediction: if the integrity and flexibility of the DLPFC is only necessary for representing certain attributes in a goal-consistent manner, then responses in this region should predict regulatory success only for those attributes that converge in this area, while regulatory success for other attributes (e.g., $Other) should be predicted by other regions (e.g., TPJ or precuneus). We tested this hypothesis using a cross-subject decoding approach: in a nutshell, this decoding analysis tested whether multi-voxel activation patterns in an ROI (e.g. DLPFC) allowed predicting an individuals regulatory success in a choice task, solely based on the participants regulation-related neural activation patterns (see Materials and methods and Appendix 1 – Multivariate regression of individual differences in regulatory success for details). The analyses focused on an ROI in DLPFC (with supplemental tests for TPJ, precuneus, and VMPFC) and regulatory success scores defined both by changes in attribute weights and by percentage of goal-consistent choices. 

As hypothesized, regulation-related neural activation patterns in the right DLPFC conjunction area ( ) during the food task reliably predicted how well a subject decreased taste weights and increased health weights in food choices (Δw Tastiness [(NC, TC) - HC]: r = 0.51, p < 0.014, permutation test; Δw Healthiness [HC - (NC, TC)]: r = 0.42, p < 0.041). Predictions further improved when we focused on altered attribute weights for HC versus TC (Δw Tastiness [TC - HC]: r = 0.68, p = 0.002; Δw Healthiness [HC - TC]: r = 0.47, p = 0.014). Similar results were found when we predicted subject-specific changes in regulation success based on improved dietary choices (ΔHealthy Choices [HC - (NC, TC)]: r = 0.50, p = 0.016; ΔHealthy Choices [HC - TC]: r = 0.46, p = 0.027), demonstrating that regulation-related neural predictions extend to actual behavior with real consequences. 

Next, we asked whether neural activation patterns in the right DLPFC also predict individual differences in regulation success in the altruism task. Remarkably, neural patterns in DLPFC during   food   choices predicted subjects’ ability to reduce the weighting of their own monetary payoffs during   altruistic   choices separated in time by an average of 16 months from the food task (Δw $Self [NC - (EC, PC)]: r = 0.50, p = 0.015; Δw Self [NC - PC]: r = 0.55, p = 0.005; permutation tests). They also predicted increases in generous behavior when attending to pro-social attributes (ΔGenerous Choices [(PC, EC) - NC]: r = 0.63, p < 0.001; ΔGenerous Choices [EC - NC]: r = 0.44, p = 0.028; ΔGenerous Choices [PC - NC]: r = 0.63, p = 0.002). Supplemental analyses suggest that predictive information on altered generosity was driven by neural information on changes in the attribute encoded in the DLPFC ($Self) and not by other attributes of the altruistic choice task (e.g., $Other, fairness) (see Appendix 1 – DLPFC-based prediction of goal-consistent changes of generosity is driven by goal-consistent changes in attribute representations of $Self (but not $Other or Fairness)). We also confirmed that decoding accuracies were not correlated with the delay between both choice tasks (all p’s > 0.05, uncorrected), indicating that predictions of individual difference scores of regulatory success were unrelated to temporal delays between tasks. Complementary decoding analyses based on brain data obtained during altruistic choices revealed similar patterns, further supporting our findings ( ). 


#### Precuneus encodes individual differences in regulatory success in altruistic choice 
  
Strikingly, patterns in the DLPFC did not decode regulatory success for social attributes that were flexibly encoded in other regions of the brain (i.e., $Other, Fairness). A post-hoc analyses tested whether neural activation patterns that encoded values of $Other in a goal-consistent manner would allow predicting individual differences in regulatory success in the altruism task. We found that response patterns in the precuneus reliably predicted individuals’ altered generosity in the altruism task (ΔGenerous Choices [PC - EC]: r = 0.57, p = 0.002 [CI: −0.41, 0.38]; ΔGenerous Choices [(NC, PC) - EC]: r = 0.61, p = 0.004 [CI: −0.41, 0.41]), suggesting that domain-specific attribute coding contributes to individual differences in regulatory control. 


#### VMPFC does not encode individual differences in regulatory success 
  
Because of its hypothesized role in valuation, a post-hoc analyses also examined whether the VMPFC region that encoded all attributes predicted regulatory success in either choice task. However, local activation patterns in VMPFC were   not   predictive of regulatory success for any attribute (all p’s > 0.31). This result suggests that while this region may encode all choice-relevant attributes, it was not the locus for changes in value representation in this task. However, exploratory functional connectivity analyses provided subtle hints that the VMPFC could be indirectly related to regulatory success through its modulation of both DLPFC and precuneus (see   and Appendix 1 – Changes in functional connectivity with the VMPFC correlate with regulatory success for details). 




## Discussion 
  
Cognitive regulation of decision making represents a crucial tool for altering behavior to fit momentary goals (e.g. eat healthy, be kinder). Capitalizing on the strengths of behavioral model-fitting ( ) and the greater sensitivity of neural multivariate pattern analysis ( ), we demonstrate how regulatory goals modulate value representations at the level of choice-relevant attributes, supporting goal-consistent behavior. Unexpectedly, cognitive regulation of decision making did   not   reliably modulate value signals within the VMPFC. Instead, regulatory effects converged to modulate a subset of distinct attribute representations in both the social and non-social domain within a region of the DLPFC that has previously been implicated in value-based choice ( ;  ;  ). Cognitive regulation of decision making also altered attribute representations for specific   social   attributes in distinct areas, including TPJ and precuneus. This pattern of neural convergence and divergence was reflected by behavioral patterns of covariation in regulatory success across tasks, made more remarkable by the fact that they were measured anywhere from weeks to more than a year apart. Our results provide important and novel insights into the domain generality and specificity of cognitive regulation of decision making, explain when and why regulatory success generalizes across contexts and domains, and raise exciting new questions for exploration. 

### Attribute-level vs. integration-level effects of cognitive regulation of decision making 
  
Do goals (e.g. eat healthier, be kinder) influence construction of value by operating on distinct attribute representations, or by changing integration of these values in centralized, common-value regions of the brain? Our results provide three key pieces of evidence in favor of attribute-level value modulation by cognitive regulatory control. First, although the VMPFC contained reliable information on the values of   all   attributes and encoded overall decision values across social and non-social contexts, these signals showed   no   modulation by regulatory goal for any attribute or decision value and did not predict individual differences in regulatory success. Moreover, no other area showed a complete correspondence between behavioral and neural effects of regulation, arguing against a single, centralized locus for effects of cognitive regulation on decision making. Second, we observed goal-dependent representations of some attributes (i.e., others’ benefits) in distinct, specialized brain regions like the TPJ and precuneus. Third, although we observed converging effects of regulation for a subset of attributes in the DLPFC (including tastiness, healthiness, and self-related benefits), representations of these attributes utilized distinct, differentiated codes. Taken together, although our results do not preclude the possibility that in other contexts cognitive regulation of decision making might operate on a single, centralized value integration mechanism, they suggest that it may often operate by changing distinct attribute representations. 


### Domain-general vs. domain-specific effects of cognitive regulation 
  
If cognitive regulation of decision making is mediated by changes in distinct attribute representations, when might we expect regulatory success – or failure – to generalize across contexts and domains? Our results indicate that although the DLPFC used distinct codes to represent different attributes, it may nevertheless be a common denominator in regulatory success across domains. Behaviorally, goal-consistent shifts toward ‘virtuous’ behavior in one domain (i.e. healthier food choice) correlated with shifts in the other (i.e. more generosity). This covariation was driven by correlated changes in the behavioral weighting of   precisely   those attributes represented in the DLPFC (i.e., tastiness, healthiness, and self-related benefits), but not in attributes encoded elsewhere (i.e. other-related benefits, fairness). These findings are even more remarkable given delays of up to 24 months separating the two choice tasks (average 16 months), ruling out alternative explanations like memory, mood, or priming effects. Thus, the DLPFC may represent a stable individual resource permitting flexible representation of specific attributes according to current goals. 

At the same time, goal-consistent changes in pro-social attributes (e.g. others benefits) appeared in areas like the TPJ and precuneus, especially when focused on the partner’s thoughts and feelings. This accords with growing evidence linking these regions to   domain-specific   computations related to Theory of Mind (ToM) ( ;  ;  ) and representing others’ mental states and needs during social choice: for instance, activation patterns in the rTPJ were recently shown to encode individual differences in the level of ToM during altruistic choice ( ). Notably, activity in these regions did not encode other social attributes (e.g., fairness) or their goal-consistent changes. Moreover, focusing on ethical and normative reasons for giving (which may require less focus on others’ specific thoughts and feelings) increased altruistic choice, but actually   decreased   representations of the other’s payoffs in these regions. Thus, the TPJ and precuneus appear to encode features specifically related to representing others’ outcomes in a goal-sensitive manner, pointing to specialized loci of cognitive regulation in social choice domains. 


### The role of VMPFC and DLPFC in valuation and cognitive regulation 
  
Our study adds to a growing body of experimental work finding that behavioral effects of regulation can occur in the absence of corresponding changes to either overall levels of VMPFC response ( ;  ;  ), or VMPFC representation of specific attributes like taste ( ). They also raise the intriguing possibility that the flexibility of DLPFC attribute representations may be particularly important for compensating when regulation of the VMPFC fails, a finding also observed in other studies of cognitive regulation of decision making ( ). This raises an important question: what determines the capacity of the DLPFC to properly represent these different attributes? Intriguingly, exploratory connectivity results suggested that this may actually derive, at least in part, from functional interactions with the VMPFC area that represented all choice-relevant attributes, with the strength of connectivity between DLPFC and VMPFC correlating with regulatory success. Although speculative, this finding is consistent with research in both animals and humans suggesting that the VMPFC may modulate affective attribute representations in other areas ( ;  ). These results could also suggest that VMPFC represents an earlier stage in the value construction process, with DLPFC representations emerging more closely to response. Future work including the use of measures with higher temporal precision may help to elucidate when and how interactions between the VMPFC and DLPFC determine regulatory success in different contexts. 


### Explaining individual differences in regulatory success and failure 
  
Our study is the first to document goal-consistent changes for   all   choice-relevant attributes, across diverse choice domains, both within and across individuals, shedding light on when and why regulatory efforts may succeed or fail. Our findings point to important divisions in regulatory success as a function of choice attributes and domain: an individual who struggles both to resist cheesecake and ignore their own self-interest may nevertheless have little difficulty in harnessing regulation to represent others’ needs and use this as input into social choices. This has important implications in treatment for decision making disorders: if therapeutic interventions fail when focused on one attribute (e.g., be less selfish), a switch to strategies focused on other attributes (e.g., think more about others) might be more effective. Future work will need to explore the full range of domains and attributes in which regulation could play an important role (e.g., risk, intertemporal choice, etc.) in order to determine the extent to which regulatory effects vary or converge across attributes and domains. 

It is also worth noting that goal-consistent changes in attribute representations were generally exceptions rather than the rule.   Most   regions permitting attribute decoding showed   no   discernable change in representation of attributes as a function of goal. This may explain why regulatory success often feels so difficult: unregulated attribute representations in some areas (including the VMPFC) may continue to leak into choices, complicating regulatory success. It also argues against a trivial interpretation of our results that the changes we observed are simply uninteresting reflections of behavior: we observed highly specific and localized success-related changes in regions like DLPFC, TPJ, and precuneus, but not in other areas. This suggests that these regions may perform a special role in mediating the impact of regulatory goals on behavior. 


### Limitations and future directions 
  
We cannot completely rule out that regulatory affects on behavior and attribute representations might partly reflect differences in motivation to satisfy expectations of the experimenter. However, we note that the specific patterns of convergence and divergence in regulatory success argue against this interpretation of our results: we suspect that if this were the case, we would not have observed either the distinct profile of within-subject correlations in regulatory success for different attributes, or differences in their neural correlates. Nevertheless, further research will be needed to fully resolve the extent to which individual differences in regulatory success result from limits in motivation or limits on capacity. Work examining whether gray matter volume in either the DLPFC and VMPFC predicts regulatory success across individuals might help to resolve such issues ( ). Tying laboratory measures of regulation to real-world consequences also remains a necessary future step in understanding the significance of these findings. 

Our results also point to a number of other open questions and future directions. The implementation of a strictly data driven approach confirmed that several   a priori   hypothesized regions of interest such as the VMPFC or the DLPFC are crucial for implementing cognitive control of goal-directed choice. However, we cannot rule out that other brain regions not identified by the current analyses (e.g. the ventral striatum) also contribute to decision making during regulation. Indeed, we observed changes in attribute decoding in restricted, non-overlapping areas of visual and motor cortex for some but not all attributes, which might reflect non-causal changes in visual attention or motor preparation, but could also be important precursors to downstream changes in areas like the DLPFC, TPJ and precuneus. 

The close correspondence between neural patterns and model-estimated changes in behavioral weighting suggests that our information-based neural measure captured a critical aspect of changes in neural computations during goal-dependent behavior. However, further investigation is necessary to understand what separates attributes whose representations converged in DLPFC from those that did not. One exciting avenue for future research will be to identify the precise factors that determine whether and when the DLPFC acts as the site for cognitive regulation of value. Understanding this distinction may help to predict when an individual will show more global deficits in regulatory success and when those deficits will tend to stand apart from success or failure in other domains or contexts. 



## Materials and methods 
  
### Participants 
  
Fifty-five healthy volunteers (25 female, M ± SD: 28 years ± 5.02) participated in the altruism task. A subset (N = 37, 17 female, 29 years ± 5.24) also completed the food task. Sample size for both established fMRI tasks were selected based on previous successful implementations of the food task ( ) and the altruism task ( ). All subjects had normal or corrected-to-normal vision and were free of psychiatric or neurological history. Subjects received $20/hour for their participation, plus the money from a trial selected randomly at the end of the altruism task. They also received a randomly selected food item at the end of the food experiment that had to be consumed in the lab. The altruism data of five subjects and the food data of one subject were excluded from further analyses due to excessive movement (>3 mm/3degree). The altruism data of another subject was excluded from the analysis due to invariant choice behavior. All subjects gave written informed consent and Caltech’s Internal Review Board approved the study. 


### Tasks 
  
Subjects performed two separate fMRI tasks as part of a large-scale cross-sectional research project. Task order was fixed, with the food task completed on average 16 months (SD: ±8.66; range: 1–24) after the altruism task to specifically probe for common and distinct computations in non-social and social goal-dependent choices. 

#### Food task 
  
 The non-social fMRI task was a modified version of an established food task ( ). On every trial, subjects chose between one of 90 food items presented on-screen (4 s) and a default food chosen prior to scanning ( ). Subjects responded by pressing one of four buttons corresponding to ‘strong yes’, ‘yes’, ‘no’, ‘strong no’ (displayed at the bottom of the screen), using a button box placed in their right hand. The assignment of choice preferences to buttons was fixed throughout the task and the right-left orientation of the scale was counterbalanced across subjects. Inter-trial intervals varied from 1 to 4 s (average of 2 s), during which a white fixation cross was presented against a black background. After scanning, one trial was randomly drawn to determine what the subject would eat before leaving the lab. If subjects failed to respond within the 4 s of the selected trial either the on-screen or the default option was randomly chosen. 

Subjects made food choices under three conditions:   Respond Naturally   (‘respond as you naturally would’, [NC]),   Focus on Health   (‘focus on the healthiness of the food when making the choice’, [HC]), or   Focus on Taste   (‘focus on the tastiness of the food when making the choice’, [TC]) (see Appendix 1 – Instructions for regulatory conditions in both choice tasks for instructions). Importantly, subjects were explicitly instructed to always make the decision based on their preference, regardless of the condition. Every condition comprised nine blocks (with 10 trials per block), resulting in a total of 90 trials per condition. Prior to every block, detailed instructions appeared for 4 s. In addition, during food display, a short description (‘Respond Naturally’, ‘Focus on Health’, ‘Focus on Taste’) appeared at the top of the screen to remind participants of the current instruction. Each of the nine functional scanning runs contained one block of every condition (i.e., three task blocks per run), with the order of conditions randomized across runs and subjects. The only exception was the first task block, which was pre-assigned to ‘natural’ for every subject. Practice trials as well as a short quiz prior to scanning ensured that subjects understood the instructions for each condition and were comfortable with the timing of the task. 

Food items varied in their perceived tastiness and healthiness and included healthy snacks (e.g., apples, broccoli) and junk foods (e.g., candy bars, chips). Items were selected based on subjects ratings in a self-paced computerized task prior to scanning that assessed perceived tastiness (5-point Likert scale, ‘very untasty’ to ‘very tasty’) and healthiness (5-point Likert scale, ‘very unhealthy’ to ‘very healthy’) of 200 food items ( ;  ). Ninety food items were selected from this larger set to cover the range of health and taste ratings in a roughly uniform manner. In addition, for each subject we chose one default food that was perceived as neutral for taste and health. Each food item was presented once in each of three choice conditions, with presentation order randomized across blocks, functional runs, and subjects. To ensure the motivational saliency of the food items, subjects were asked to refrain from eating 4 hr prior to testing. Stimulus presentation was implemented using high-resolution color pictures (72 dpi) and Psychophysics Toolbox Version 3 ( ) together with Matlab (2014a). 


#### Altruism task 
  
The altruism task was an fMRI compatible version of the dictator game modified from ( ). On every trial, subjects were presented with a monetary proposal that affected their own ($Self) and another persons’ ($Other) monetary payoff ( ). Subjects had 4 s to chose between the on-screen proposal and a constant default allocation ($20 to both) by pressing one of the four response buttons (‘strong yes’, ‘yes’, ‘no’, ‘strong no’; direction counter-balanced across subjects). Payouts for self and other ranged from $0 to $40 and always involved a tradeoff between self and other (i.e. prizes for one individual were equal or less than the default, while prizes for the other individual exceeded the default). Thus, subjects always had to choose between acting altruistically (benefitting the other at a cost to oneself) or selfishly (benefitting oneself at a cost to the other) on every trial. At the end of the experiment, one trial was randomly selected and implemented according to the subjects’ choice. If subjects failed to respond within 4 s for this trial, both individuals received $0. 

Similar to the food task, subjects performed the task under three different conditions:   Respond Naturally   (‘respond as you naturally would’, [NC]),   Focus on Ethics   (‘focus on doing the right thing and consider the ethical or moral implications of your choice’, [EC]), or   Focus on Partner   (‘focus on your partner’s feelings and how the other person is affected by your choice’, [PC]). Subjects were reminded to always make their choice based on their preference, regardless of the condition. Conditions were implemented in separate blocks of 10 trials each, with the beginning of a new block signaled by a short reminder instruction (4 s). Matching the food task, subjects performed 9 blocks of each condition (i.e., 90 trials per condition and a total of 270 trials), with the block order counter-balanced across subjects and functional runs, with the exception that the first two blocks were always natural choice trials. Choices in these NC blocks were used to estimate a logistic regression [Choice = w  * $Self + w  * $Other] and used for a subject-specific selection of 30% of proposals most likely to elicit generous behavior and 30% of proposals likely to elicit selfish behavior. The remaining 40% of trials were randomly chosen from the full proposal space. Practice trials and a quiz prior to scanning verified that subjects were capable and comfortable to make the choice within 4 s. 


#### Probabilistic choices 
  
To decrease experimental demand and to ensure anonymity in the altruism task, subjects were informed that implementation of their choices was probabilistic and that in 40% of trials their choices would be reversed ( ). Subjects were informed that their partner would only know the proposal and the outcome of the randomly chosen trial, but not their decision (i.e., if the outcome was due to the subjects’ choice or a choice reversal). The implementation was as follows: After each choice (jittered delay of 2–4 s), an outcome screen (4 s) informed subjects of the implementation of choices (implemented/choice reversal), followed by a jittered inter-trial interval of 1–4 s (average of 2 s) before the next choice screen appeared. Computerized control questions during training confirmed that subjects understood the probabilistic nature of the task and that it was still in their best interest to choose according to their individual preferences. In the food task, we matched the probabilistic implantation in the altruism task, and informed participants prior to scanning that their choices would be implemented with 60% probability. 

Data from an independent behavioral pilot study (N = 17, 11 female, M ± SD: 24.12 years ± 5.83) confirmed that choices under almost perfect implementation (90%) closely matched those observed under 60% implementation conditions (within-subject design, all p’s > 0.37, uncorrected, for paired t-tests of RTs, percentage of generous and healthy choices). These findings strongly suggest that the probabilistic nature of the task did not systematically alter preference-based choices in both tasks. 



### Behavioral computational model (DDM) 
  
We used a multi-attribute extension of the standard drift diffusion model (DDM) ( ;  ) to capture behavior in both the food and altruism task, using a maximum-likelihood procedure similar to that described in ( ) to find the best-fitting parameters (see Appendix 1 – Drift diffusion model for details). For capturing behavior in the food task, we fit a model using five parameters: two parameters for the weights on tastiness and healthiness, a parameter for non-decision time (NDT) representing perceptual and motor processes, and two parameters specifying the initial height of the choice-determining threshold (b) as well as the exponential decay rate of this threshold toward zero (d) as the time limit for responding approached. For capturing behavior in the altruism task, we fit a model using six parameters: three parameters related to the weights on $Self, $Other, and fairness (−1*|$Self - $Other|), as well as parameters related to NDT, b, and d (see   for details). 


### Functional image acquisition 
  
Functional imaging was performed on a 3T MRI scanner (Magnetom Trio, Tim System, Siemens Medical Systems, Erlangen) equipped with a 32-channel head coil. T2*-weighted functional images were obtained using an echoplanar imaging (EPI) sequence (TR = 2.5 s, TE = 30 ms, flip angle = 85°, 3 × 3 × 3 mm, matrix size 64 × 64, 47 axial slices, descending sequential acquisition order). For the altruism task, a maximum of 1521 volumes were acquired. For the food task we acquired 990 volumes. High-resolution T1-weighted structural images were acquired at the end of each scanning session using an MPRAGE sequence (TR = 1.5 s, TE = 2.91 ms, flip angle = 10°, TI = 800 ms, 1 × 1 × 1 mm, matrix size 256 × 256, 176 slices). 


### fMRI data analysis 
  
Functional images were analyzed using the statistical parametric mapping software SPM12 (  http://www.fil.ion.ucl.ac.uk/spm  ) implemented in Matlab. Preprocessing consisted of slice-time correction (reference slice 47), spatial realignment (by first registering each subjects’ data to the first image of each run, then all functional runs were co-registered with each other), and normalization to the Montreal Neurological Institute (MNI) brain template (EPI template). For every subject, we estimated several general linear models (GLMs), using a canonical hemodynamic response function (hrf), and a 128 s high-pass cutoff filter to eliminate low-frequency drifts in the data. 

#### Trial-wise estimates of choice phases: GLM1 (food task) and GLM2 (altruism task) 
  
These GLMs aimed to identify brain responses that encode trial-by-trial variations in attributes (i.e., foods’ healthiness or tastiness in the food task; payoffs for subjects and confederate and the fairness of the offer in the altruism task) and decision-values (four-point response from ‘strong no’ to ‘strong yes’) during choice periods. To this end, these models obtained a trial-wise measure of BOLD responses during food (GLM1) and altruistic choices (GLM2) at the time of the choice. For each subject, GLM1 included a regressor for each choice period (R1-R270) in the food task, lasting from the onset of a food presentation to the button press that represented the choice for the trial. In addition, the model estimated a separate regressor for the outcome phases for each functional run, movement parameters, and run-wise session constants as regressors of no interest. GLM2 mirrored GLM1 and estimated regressors of interest for every altruistic choice (R1-R270), lasting from the onset of the monetary proposal to the button press that signified the choice in this trial. GLM2 also estimated regressors of no interest including outcome phases, movement parameters, and session constants. Estimated responses for the regressors of interest – the choice periods of each task (R1-R270 from GLM1 and 2, respectively) – were then used as inputs for the multivariate decoding analyses (support vector regressions, SVRs) described below. 


#### Neural computational model: within-subject decoding of choice attributes 
  
This multivariate pattern analysis (MVPA) aimed to identify brain regions that encode trial-by-trial fluctuations of choice-relevant attributes (e.g. foods healthiness, payoff to self) or decision values (four-point response from ‘strong no’ to ‘strong yes’), and to assess how current goals affect neural information on the attribute level. Thus, these decoding analyses allowed us to explicitly test if regulation-based changes in   neural   information on choice-relevant variables (e.g., healthiness of foods) matched predictions from the   behavioral   computational model. 

For each choice attribute and each condition, we applied a separate support vector regression (SVR) analysis in combination with a whole-brain ‘searchlight’ approach ( ). The key advantage of the searchlight decoding approach is that it does not depend on a priori assumptions about informative brain regions and ensures unbiased information mapping throughout the whole brain ( ;  ). For every subject, we defined a sphere with a radius of 4 voxels around a given voxel v  of the measured brain volume ( ;  ;  ;  ) For each of the N voxels within this sphere, we extracted trial-wise parameter estimates of a particular condition (i.e., 90 of the 270 trial-wise regressors of choice periods from GLM1 (food task) or GLM2 (altruism task)). N-dimensional pattern vectors were created separately for each of the 90 trials of the respective fMRI task. Neural pattern vectors for 8 of the 9 task blocks (‘training data’) served as input features, with trial-wise values of the attribute (e.g., healthiness rating) as labels of the prediction. The prediction was realized using a linear kernel support vector machine regression (  http://www.csie.ntu.edu.tw/~cjlin/libsvm  ) (ν-SVR) with a fixed cost parameter c = 0.01 that was preselected based on previous implementations of this decoding approach ( ;  ;  ;  ). The resulting model provided the basis for the prediction of the trial-wise values of an attribute (e.g. healthiness ratings) of the 10 trials of the remaining task block (‘test data’) based on their neural response patterns. This procedure was repeated nine times, always using pattern vectors of a different task block as test data, yielding a 9-fold cross-validation. Predictive information about the choice attribute was defined as the average Fisher’s z-transformed correlation coefficient between the value predicted by the SVR model and the actual values of an attribute in these trials ( ;  ;  ;  ). This decoding accuracy value was assigned to the central voxel of the searchlight. The procedure was repeated for every voxel of the measured brain volume, yielding a three-dimensional decoding accuracy map for every subject, separately for each choice attribute and each condition. Decoding maps were smoothed (6 mm full width at half maximum, FWHM) and submitted to two different random-effects group analyses. 

First, to establish that neural response patterns encode the current value of a choice-relevant attribute during choices, we averaged subjects’ decoding accuracy maps for a particular attribute obtained in the three conditions (e.g., separate SVRs for healthiness in NC, HC, and TC). Subject-specific average information maps were than used in a random effect second level analysis (single t-test as implemented in SPM) and tested against chance level at a statistical threshold of p < 0.05 (FWE cluster-corrected, height threshold of p < 0.001). Note that if resulting cluster sizes at this statistical threshold prevented effective functional localization (i.e., clusters that exceeded 6000 voxels), we report results at p < 0.05, FWE corrected at voxel-level. Second, to examine if predictive neural information on a choice attribute varied systematically across the three conditions of the respective task, we used a repeated measures ANOVA as implemented in SPM. Only regions that passed the statistical threshold of p < 0.05 (FWE corrected at cluster-level, height threshold of p < 0.001) are reported. 

We also compared the results of the multivariate SVRs with those of a conventional univariate analysis (see  , and Appendix 1 – Univariate Analysis of fMRI Data). However, note that multivariate decoding approaches have been prosed to be more sensitive than traditional mass-univariate approaches: because multivariate pattern classifiers take advantage of information encoded across multiple voxels and exploit systematic differences in voxel selectivity within a specific brain region, they have been suggested to detect information that would be missed by conventional analyses ( ). 

There is a potential concern that the some intervals of the response scales for choice attributes (e.g. tastiness) or decision values (‘strong no’, ‘no’, ‘yes’, ‘strong yes’) might be subjectively larger than other intervals. While the present data don’t allow ruling out this potential concern, previous implementations of the response scales in both established tasks suggest that the operationalization of attribute-specific judgments and decision values allows to reliably identify value signals in the brain ( ;  ;  ;  ). 


#### Neural computational model: cross-subject decoding of individual differences in regulatory success 
  
This multivariate decoding analysis investigated whether neural activation patterns predict individual differences in regulatory success. A cross-subject decoding approach was used to test for information on the   degree   to which cognitive regulation affected attribute weights and choices. Clusters identified in the repeated measures ANOVA (see above) were defined as regions of interest (ROIs). Importantly, a main goal of our study was to test for potential common neural substrates underlying context-sensitive weighting of choice-attributes across choice-domains. Hence, these decoding analyses focused on voxels identified in a formal conjunction of the significant clusters for flexible representations of Healthiness, Tastiness, and $Self (at p < 0.05, FWE corrected at cluster-level, height threshold of p < 0.001; see  ). First, we tested if neural activation in this ROI obtained during food choices encodes subject-specific regulation success in the food task, but also in an independent social altruism task. To this end, we extracted parameter estimates for all voxels in the ROI ( ) from subjects first-level GLM1 (food choices) using the contrast image [HC > (NC, TC)] (based on DDM results suggesting differential attribute representations for this comparison,  ). Resulting pattern vectors (one per subject) were used as input features for the prediction and individual difference scores in regulation success served as labels. Regulation success was defined using difference scores in DDM parameters (e.g., Δw Tastiness [HC – (NC, TC)]) and in observed choice behavior (e.g., ΔHealthy choices [HC – (NC, TC)]). Predictions used a linear ν-SVR (libSVM) with a fixed cost parameter c = 0.01 (similar to within-subject decoding) and a leave-one-subject out approach (yielding a 36-fold cross-validation). Decoding accuracies reflect correlations of the observed and predicted regulation score. Statistical significance was assessed by comparisons to empirical null-distribution (realized by randomly permuting the pairing of subjects’ neural pattern vectors and behavioral regulation scores 1000 times). Only decoding accuracies above the 95th percentile of null-distributions were considered statistically significant ( ). As a sanity check, analyses were repeated training on data obtained during altruistic choices (see  ). 

Note that   ROI-based cross-subject   decoding analyses used permutation tests to assess the statistical significance of the predictions instead of simple t-tests (as implemented in SPM) applied to the   whole-brain within-subject   searchlight decoding maps. Regarding the latter, computational costs for estimating empirical null-distributions for several tens of thousands of searchlight analyses - implemented separately for every attribute, decision-value, condition, and subject - prevented us from using permutation tests for whole-brain decoding analyses. However, supplemental analyses that used t-tests to statistically assess ROI-based results yielded similar results as permutation tests, demonstrating that both statistical approaches generate comparable interpretations for the present data. Notably, empirical permutation-based null-distributions for ROIs also confirmed the theoretical chance level of the prediction that underlies statistical inferences for the whole-brain searchlight results (t-tests as implemented in SPM). Nevertheless, statistical tests based on empirical null-distributions can be viewed as superior insofar as they address the potential concern that means and distribution of predictions based on chance alone might vary across brain regions. 

Note also that the ROI ( ) used for this analysis was defined based on a fully independent and orthogonal set of tests for altered decoding accuracies across task conditions at the group level. Thus, ROI-selection was not subject to double dipping ( ). 



 ## Data availability

Functional imaging and behavioral data is deposited at the project's Open Science Framework (OSF) page (osf.io/wa4cs). The project page also makes available the derived statistical maps (univariate and multivariate decoding analyses), regions of interest (ROIs) used in analyses of functional imaging data, processed behavioural data, and details on the experimental procedure. </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-20'>
<h2>20. PMID: 30430680</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Sex differences in own and other body perception</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Hum Brain Mapp</p>
<p><strong>Publication Year:</strong> 2018</p>
<p><strong>DOI:</strong> 10.1002/hbm.24388</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Study is an original fMRI experiment with healthy adult participants (N=30, mean age 26) who completed a social-related body perception/self-other distinction task during whole-brain fMRI acquisition. Analyses used whole-brain mixed-effects (FLAME) reporting cluster-corrected whole-brain results; not ROI-only. Participants were screened as healthy and within the 18–60 age range. The work is not a review/meta-analysis and does not include psychiatric or neurological patient groups. Therefore it meets all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.94</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Own body perception, and differentiating and comparing one's body to another person's body, are common cognitive functions that have relevance for self‐identity and social interactions. In several psychiatric conditions, including anorexia nervosa, body dysmorphic disorder, gender dysphoria, and autism spectrum disorder, self and own body perception, as well as aspects of social communication are disturbed. Despite most of these conditions having skewed prevalence sex ratios, little is known about whether the neural basis of own body perception differs between the sexes. We addressed this question by investigating brain activation using functional magnetic resonance imaging during a Body Perception task in 15 male and 15 female healthy participants. Participants viewed their own body, bodies of same‐sex, or opposite‐sex other people, and rated the degree that they appeared like themselves. We found that men and women did not differ in the pattern of brain activation during own body perception compared to a scrambled control image. However, when viewing images of other bodies of same‐sex or opposite‐sex, men showed significantly stronger activations in attention‐related and reward‐related brain regions, whereas women engaged stronger activations in striatal, medial‐prefrontal, and insular cortices, when viewing the own body compared to other images of the opposite sex. It is possible that other body images, particularly of the opposite sex, may be of greater salience for men, whereas images of own bodies may be more salient for women. These observations provide tentative neurobiological correlates to why women may be more vulnerable than men to conditions involving own body perception. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (46863 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## INTRODUCTION 
  
The neurobiology of identity and self‐concept is currently a hot topic among neuroscientists, and emerging data suggest that it is mediated by specific cerebral networks. One fundamental facet of identity is gender. While certainly influenced by cultural and other environmental factors, gender identity is, nevertheless, foremost shaped by the perception of one's own body and its sex characteristics. Yet, we know very little about how our brain processes identification of self in the context of the sex of one's body. How does our brain distinguish own body from other bodies? Are there specific neural networks for processing recognition of the sex of the body? Are there sex differences in how cerebral networks process recognition of the physical sex in relation to self? 

Self‐other distinction, crucial for human social interaction, relies mainly on the visual perception of the own and another person's body (Longo, Azañón, & Haggard,  ). This process can be viewed as a composition of three components: (1) those involving sensory perception of own body, (2) the specific perception of body ownership, and (3) the integration of own body into the concept of self. Neural regions, within more extended networks, specialized in visual body perception include the fusiform body area (FBA) and extrastriate body area (EBA), which are specialized in human body and body parts perception (Downing & Peelen,  ; Downing, Jiang, Shuman, & Kanwisher,  ; Peelen & Downing,  ; Schwarzlose, Baker, & Kanwisher,  ). The EBA and FBA, especially on the right side, were found to be involved in   own   body representation (Peelen & Downing,  ) and to show stronger responses after viewing pictures of one's own body compared to that of a same‐sex other (Vocks et al.,  ). These brain regions thus provide important self‐other information at a perceptual level of representation. Perception of body ownership primarily requires intact function of the temporo‐parietal junction (Limanowski & Blankenburg,  ). Higher order social cognition (e.g., mentalizing), self‐other distinction, and (own) body representation requires recruitment of cortical midline structures: the medial prefrontal cortex (mPFC), anterior and posterior cingulate cortex, and precuneus (Northoff & Bermpohl,  ). 

More specifically, the ventral and rostral medial prefrontal cortices (mPFC) have been shown to be involved in self‐relative to other‐evaluations and in affective processing of self‐relevant information. (Amodio & Frith,  ; Denny, Kober, Wager, & Ochsner,  ; Murray, Schaer, & Debbané,  ; van der Meer, Costafreda, Aleman, & David,  ). In contrast, the dorsal mPFC was suggested to be involved in the evaluation and decision‐making process of whether a certain stimulus is applicable to the self or to another person, and was associated with judgments about dissimilar others (D'Argembeau,  ; D'Argembeau et al.,  ; Denny et al.,  ; Mitchell, Macrae, & Banaji,  ; Murray et al.,  ; van der Meer et al.,  ). The posterior cingulate and precuneus areas have been associated with autobiographical and semantic memory retrieval about physical aspects of own body, may be responsible for integration of self‐relevant emotional information, and have been found to be important for self‐other differentiation (Northoff & Bermpohl,  ; Ruby & Decety,  ; van der Cruijsen, Peters, & Crone,  ; van der Meer et al.,  ). Of particular interest are findings in the precuneus cortex because this region is tightly connected with networks processing visual and pheromonal stimuli, and sexual arousal (Berglund, Lindström, & Savic,  ; Cavanna & Trimble,  ; Zhang & Li,  ). In concert with the cortical midline structures, activation in the (anterior) insula has consistently been associated with own body awareness and ownership, integration of internal affective bodily states, and with self and familiar face processing (Craig,  ; Kircher et al.,  ; Mega, Cummings, Salloway, & Malloy,  ; Tsakiris,  ; Tsakiris, Hesse, Boy, Haggard, & Fink,  ). 

Distortions of one's body image, including those that might arise during body perception, and impairments in social cognition are core symptoms of several psychiatric conditions, such as anorexia nervosa, body dysmorphic disorder, autism spectrum disorders, and in a subset of individuals with schizophrenia (American Psychiatric Association,  ; Beilharz, Castle, Grace, & Rossell,  ; Farrell, Lee, & Shafran,  ; Gardner & Brown,  ; Krumm, Ferraro, & Ingvalson,  ; Madsen, Bohon, & Feusner,  ; Priebe & Röhricht,  ; Röhricht & Priebe,  ; Ropar, Greenfield, Smith, Carey, & Newport,  ; Smeets, Smit, Panhuysen, & Ingleby,  ). Notably, several of these conditions show skewed sex ratios. Whereas, for example, autism spectrum disorders are more common in males than females, with a sex ratio of about 3:1 (Loomes, Hull, & Mandy,  ), eating disorders are much more prevalent in females (Hudson, Hiripi, Pope, & Kessler,  ; Keski‐Rahkonen & Mustelin,  ). Body dysmorphic disorder, on the other hand, has almost equal prevalence in males and females (Buhlmann et al.,  ; Koran, Abujaoude, Large, & Serpe,  ; Rief, Buhlmann, Wilhelm, Borkenhagen, & Brähler,  ). A direct link between gender and own body perception also represents the hallmark of gender dysphoria, a condition gaining increasing public attention. Gender dysphoria, termed “Gender Incongruence” in the latest ICD11 criteria of the World Health Organization (  https://icd.who.int/dev11/f/en#/http%3a%2f%2fid.who.int%2ficd%2fentity%2f411470068  ), is characterized by a perceived incongruence between a person's gender identity and his/her sex assigned at birth (DSM‐5, American Psychiatric Association,  ). This is possibly due to a disturbed own body perception with respect to gender identity (Burke, Manzouri, Dhejne, et al.,  ; Burke, Manzouri, & Savic,  ; Feusner, Dervisic, et al.,  ; Feusner, Lidström, et al.,  ; Manzouri, Kosidou, & Savic,  ). Gender dysphoria has traditionally been regarded to have a male (sex assigned at birth) predominance, although this has been questioned more recently (Steensma, Cohen‐Kettenis, & Zucker,  ; Zucker,  ). 

Whether and how own body perception differs between men and women is not known, although it has been hypothesized that women may be more sensitive to information about the own body image than men (Mitchison et al.,  ; Powell & Hendricks,  ). One of the few studies describing sex differences in brain activations upon viewing distorted images of one's own body (appearing with different degrees of thinness or fatness) found that women showed activations in the amygdala and prefrontal areas, suggesting more complex cognitive emotional processing, whereas men had activations in the primary and secondary visual streams, similar to object and spatial visual processing (Kurosaki, Shirao, Yamashita, Okamoto, & Yamawaki,  ). Shirao et al. ( ), investigating sex differences in brain activations during perception of negative body image related words, found amygdala activations in women, but hippocampal and prefrontal brain activations in men, suggesting a more cognitive rather than emotional processing of body image stimuli in men. 

Despite vivid discussions about the representation of one's own body image in the brain (Guterstam & Ehrsson,  ; Schauder, Mash, Bryant, & Cascio,  ; S Vocks et al.,  ; Wiebking et al.,  ), surprisingly little is known about the neural representation of sex or gender, thus how our brain processes perception of the sex of others' bodies in relation to self, and whether this process differs between men and women (Pavlova,  ). This issue is of special interest considering that the visual system is central for social communication, for example, for sexual attraction and partner selection. In line with this, sex differences in brain activations during body motion processing have been reported, with females showing increased activations in regions known to be involved in social cognition (Anderson et al.,  ; Pavlova, Sokolov, & Bidet‐Ildei,  ). In addition, perception of one's own in relation to another body's sex may contribute to self‐referential processes, for example, when comparing oneself to others of the same sex (“appearance competition”) (Jackson,  ). However, to the best of our knowledge, no study to date has investigated the neural correlates of gender identity, and sex differences in the perception of another person's body in the context of self. 

We therefore developed a body perception task paradigm (Feusner, Dervisic, et al.,  ; Feusner, Lidström, et al.,  ) in which male and female participants viewed photographs of their own body, same‐sex other bodies, opposite‐sex other bodies, and sets of bodies that were morphed in increments between own body and same‐sex and opposite‐sex other bodies. For each image, the participant rated the degree that the body appeared like them: “To what degree is this picture you?” Based on previous reports, we expected to find sex differences in brain activation during   own   body perception, such that women would show stronger activations in limbic brain regions (Kurosaki et al.,  ; Shirao et al.,  ). Furthermore, we expected that both men and women during own body perception and during the perception of bodies similar to their own (i.e., same‐sex other bodies) would recruit brain areas suggested to be involved in self‐referential processing and bodily self‐consciousness (Craig,  ; Ionta, Martuzzi, Salomon, & Blanke,  ; Northoff,  ; Northoff et al.,  ), such as the ventral mPFC and insula, in addition to regions involved in body perception in general (EBA and FBA). During perception of opposite‐sex bodies we predicted to find “other”‐related activations such as in the dorsal mPFC, precuneus, and TPJ (D'Argembeau et al.,  ; Eddy,  ; Van Overwalle,  ). Our paradigm allowed us to additionally test the novel question of whether brain activation patterns differ depending on the sex of the viewed body, independently of how that body was identified in relation to self, for instance, when the viewed body was of the opposite or same sex as the perceiver's but was in both events labeled as “not me.” 


## MATERIALS AND METHODS 
  
### Participants 
  
We enrolled 30 healthy participants (15 males, 15 females, mean age 26 ± 3.5 years) who performed the body perception task while we acquired functional magnetic resonance imaging (fMRI) data to measure brain activity. Participants were recruited via flyers and advertisements around the campus of The Karolinska Institute. Participants had no self‐reported neurological or psychiatric disorders and were not taking any psychotropic medications. The study was approved by the ethical committee of The Karolinska Institute (application number Dnr 2011/281–31/4) and each participant provided signed informed consent before entering the study. 


### Body perception task 
  
Participants were photographed from the front with a Nikon D90, 18–105 mm f/3.5–5.6 G ED VR camera, fixed on a tripod. Lightning, contrast, and luminance were identical during each photo session. Each participant wore a skin‐colored, skin‐tight, full body unitard, and was positioned against a wall in an identical manner. The purpose of using a full‐body unitard was to best approximate the view of one's own and other bodies in the nude while avoiding the discomfort of being photographed undressed. In addition, it eliminated any differences in skin tone that would have otherwise occurred from morphing images of participants' bodies to others' bodies. Hands, feet, and head in the photos were cropped, and the photos were then morphed with photos of five other male and five other female bodies acquired in an identical manner using FantaMorph Software, version 5.0 (Abrosoft  http://www.fantamorph.com/  ). Each participant's picture was morphed separately with pictures from five different female and five different male participant morph targets to degrees of 20%, 40%, 60%, 80%, and 100%, respectively (producing a total of 50 different morphed images). The “100%” images were simply unaltered photos of another person. We also included the unmorphed (0% morphed) picture of each participant (Figure  ). 
  
Examples of a scrambled image and a male's body images morphed, from left to right, to 20%, 40%, 60%, 80%, and 100% to the same (denoted by positive morph degrees) and the opposite (denoted by negative morph degrees) sex. Note that “100%” photographs were unaltered images of another person [Color figure can be viewed at   http://wileyonlinelibrary.com  ] 
  
The total number of morph conditions was thus 11: the unmorphed 0% and images morphed 20%, 40%, 60%, 80%, and 100% to the same sex and 20%, 40%, 60%, 80%, and 100% to the opposite sex. Images were also presented over two different presentation durations: short (0.5 s) and long (2 s) durations). We present results from trials of the long 2 s duration in the main text and results from trials of the short 0.5 s duration, as well as comparisons of the two presentation durations in the supplement. 

In each experiment, 15 repetitions were presented per morph percentage and for each of the two presentation durations, totaling 330 (15 × 11 × 2) experimental trials. Experimental trials were intermixed with 30 (15 for each of the short and long presentation durations) “scrambled” control images, created by phase scrambling an unmorphed body image using a Fourier phase randomization procedure (Näsänen,  ). Here, an image's phase spectrum is replaced with random values, keeping the amplitude spectrum of the image unaltered. Global low‐level properties (i.e., luminance, contrast, color distribution, and spatial frequency spectrum) of the original image are preserved while the shape information of the image is entirely degraded. Scrambled images were also shown at two different presentation durations, 2 s and 0.5 s, and there were a total of 30 scrambled image trials. 

Participants were instructed to respond as quickly as possible, rating the presented picture based on the degree to which it appeared like them, with the specific question “To what degree is this picture you?” Participants were instructed to press response button box keys 1 to 4, 1 corresponding to 0%–25% “me,” 2 to 25%–50% “me,” 3 to 50%–75% “me,” and 4 to 75%–100% “me.” Before starting the experiment, participants performed a practice session inside the scanner to ensure task comprehension. 

Using Presentation version 18.1 for stimulus delivery, trials appeared in randomized order across 3 runs of 9.5 min each, acquiring 280 volumes per run. There was a 1 min break between runs. Each run began with an instruction screen, followed by a fixation cross for 30 s. Each trial consisted of (a) an image presentation for either 0.5 s or 2 s, followed by (b) the appearance of a response screen for 1 s with button press options, followed finally by (c) a fixation cross for a jittered inter‐trial interval of 1–11 s. We used optseq2 (  http://surfer   .  http://nmr.mgh.harvard.edu  /optseq/), a genetic algorithm, to create jittered presentation timing with the highest efficiency. The presentation of images was balanced and randomized with respect to degree of morph and presentation time. 


### Body localizer task 
  
As an additional control condition and to localize those areas in the brain responsible for the specific processing of human bodies, participants performed the   body localizer task  . Participants viewed 16 alternating blocks (24 s duration) of images of either others' male or female clothed bodies (8 blocks) or chairs (8 blocks). A 10 s fixation screen was interspersed between every set of 4 blocks. To keep participants actively engaged in the task they were asked to press a button any time the exact same image (of either a chair or a body) would be presented twice in a row. 


### MR data acquisition 
  
Magnetic resonance imaging data was acquired on a 3 Tesla MRI scanner (Discovery 3 T GE‐MR750, General Electric, Milwaukee, WI). Functional MRI of both the body perception and body localizer tasks was performed with a gradient echo pulse sequence using a voxel size of 3.03 × 3.03 × 3.5 mm (TE = 30 ms, TR = 2000 ms, FoV = 23 cm, 41 bottom up interleaved axial slices, 3 mm thickness, 75° flip angle) and a 32‐channel head coil. 3D T1‐weighted Spoiled Gradient Echo pulse sequence (SPGR) images were acquired with 1 mm  isotropic voxel size (TE = 3.1 ms, TR = 7.9 ms, TI = 450 ms, FoV = 23 cm, 176 axial slices, 12° flip angle) using an 8‐channel coil. 


### Behavioral data analysis 
  
Sample characteristics and behavioral data of the fMRI task were analyzed using SPSS Statistics 21 (SPSS Inc., Chicago, IL). 

We calculated a   Self‐Perception Index   (Feusner, Lidström, et al.,  ) by multiplying the value of a participant's “self” rating (from 1 to 4) with the degree of morph. This degree of morph was 0 for the unmorphed image and was positive when images were morphed to the same‐sex other body (20%, 40%, 60%, 80%, 100%) and negative when images were morphed to the opposite‐sex other body (−20%, −40%, −60%, −80%, −100%). These weighted values were averaged for each participant and then divided by the number of rated images. Thus, greater positive values would indicate higher average “me” ratings for images morphed to a high degree to the same sex and greater negative values would indicate higher average “me” ratings for images morphed to a high degree to the opposite sex. Values closer to zero, on the other hand, would indicate higher average “me” ratings for images that were only slightly morphed from their own image. 

Furthermore, male and female participants were compared with respect to their ratings of “self” when viewing their own bodies compared to bodies morphed to either the same‐ and opposite‐sex (80% and 100%, and −80% and −100% morph degrees, respectively) to evaluate possible sex differences in self‐perception. 


### MR data analysis 
  
Data analysis was performed using FEAT (fMRI Expert Analysis Tool) version 5.0.8, part of FSL (FMRIB Software Library  http://www.fmrib.ox.ac.uk/fsl  ) (Jenkinson, Beckmann, Behrens, Woolrich, & Smith,  ). BOLD sequences were motion‐corrected (using the FMRIB linear image registration tool, MCFLIRT) and spatially smoothed (using FEAT) with a smoothing kernel of 5 mm. Portions of subject runs with notable movement greater than a maximum displacement of 1.5 mm were truncated if they occurred at the beginning or end of the run to minimize the effect of movement. An average of 59 TRs per run was truncated from 7 different runs of 6 subjects (3 female and 3 male controls) on account of movement. Functional images were registered to the participant's T1‐weighted image (using the FMRIB nonlinear image registration tool, FNIRT) after brain extraction using BET (implemented in FSL) with a fractional intensity threshold of 0.3. Images were then registered to the MNI‐152 brain for group analysis (using FNIRT). Higher‐level analysis was carried out first using Fixed Effects modeling to combine the three acquired runs per participant followed by a second higher‐level analysis using FLAME 1 (FMRIB's Local Analysis of Mixed Effects) for cross‐subject comparisons (Beckmann, Jenkinson, & Smith,  ; Woolrich,  ; Woolrich, Behrens, Beckmann, Jenkinson, & Smith,  ). We thresholded   z  ‐statistic group map images using a cluster‐forming threshold of   Z   > 2.3 and a corrected cluster significance threshold of   p   = .05. Cluster   p  ‐values were determined using a spatial smoothness estimated in FSL. In addition, to further explore the extent of sex differences in (own) body perception observed, contrasts directly comparing activations of men and women were explored at a lower threshold of   Z   > 2.0,   p   < .05, corrected. 

Our first set of questions was whether there are any sex differences in the perception of (1) one's own body, and (2) other bodies of the same or opposite sex, derived from images morphed 80% and 100% to same and opposite sex, respectively. Male and female participants were thus compared for the following contrasts: for (1) [own body (morphed 0%) – scrambled image]; for (2) [same‐sex other body (morphed 80–100%) – scrambled image], and [opposite‐sex other body (morphed 80%–100%) – scrambled image]. 

Our second set of questions was whether there are any sex‐differences in the processing of other bodies in contrast to one's own body, and if this would be affected by whether the other body is of same or opposite sex. We compared male and female participants, therefore, using the following contrasts: [same‐sex other body (morphed 80%–100%) – own body (morphed 0%)] and [opposite‐sex other body (morphed 80%–100%) – own body (morphed 0%)]. 

Finally, we sought to understand the neural correlates of cognitive self‐perception, utilizing participants' own behavioral measures of similarity to self as a parametric measure when viewing images morphed to either the same or opposite‐sex. Participants' responses to the question “To what degree is this picture you?” when viewing   any morphed   image (images morphed from 20% to 100%, excluding the unmorphed image of self) were parametrically modeled on a scale from 1 to 4 (see description of   Body Perception Task   above) and demeaned. Images morphed to the same‐sex and those morphed to the opposite‐sex were treated separately. This resulted in two continuous variables (for the same vs. opposite sex morphs, respectively) centered at 0, with higher values representing greater identification with “me.” In this way, neural processes involved in self‐perception could be separated from differences in perceiving same‐sex and opposite‐sex bodies of others. 



## RESULTS 
  
Sample characteristics and self‐perception indices are presented in Table  . Male and female participants did not differ in mean age or mean scores for handedness, and all participants identified as heterosexual. Self‐perception indices were positive for both groups, indicating, as reported earlier (Feusner, Dervisic, et al.,  ), self‐identification for images morphed to the same sex. Results from trials of the long 2 s duration are presented below, and the short 0.5 s duration results can be found in the supplement. Males' and females' ratings of self‐perception did not differ significantly at any morph degree (Figure  ). 
  
Sample characteristics and self‐perception indices 
      
Average morph ratings for men and women for each degree of morph. Ratings ranged from 1 (0%–25% “me”) to 4 (75%–100% “me”). Positive values indicate percentage morphed to the same‐sex, whereas negative values indicate percentage morphed to the opposite‐sex. Error bars indicate standard errors of the mean. There were no significant differences between groups at any morph degree [Color figure can be viewed at   http://wileyonlinelibrary.com  ] 
  
Despite the groups being of equivalent age, we reprocessed the analyses for all contrasts of the Body Perception Task, as presented below, using age as a covariate of no interest. The results were very similar as when age was not accounted for, and therefore are presented in the supplement (see Supporting Information Tables   and  , please compare to Tables   and  ). 
  
Brain (de)activation for the contrast own body perception (0% morph condition) > scrambled image (control condition) in men and women 
      
Sex‐differences in brain activation 
    
### Body localizer task 
  
As has been shown in previous studies, the   body localizer task   resulted in significant (  Z   > 2.3,   p   < .05, corrected) bilateral activation in areas specialized for body perception, in both males and females. These areas included bilateral lateral occipital cortices (EBA), temporal occipital fusiform gyri (FBA), precuneus, left angular gyrus, bilateral precentral gyri, and the right amygdala in males (see Supporting Information Table  ). When comparing males and females, males showed significantly (  Z   > 2.3,   p   < .05, corrected) greater activation in the bilateral motor cortex and superior frontal gyri (Table  ). 


### Own body perception 
  
On account of an error, one male participant did not see images of his own body but rather another participant's body during the scan. This participant was therefore excluded in all analyses involving   own body  . 

Contrasting perception of one's   own body   (0% morph) with the   scrambled   image baseline revealed significant (  Z   > 2.3,   p   < .05, corrected) activation in both men (N = 14) and women (N = 15) in the bilateral lateral occipital cortex, including the EBA, dorsal medial PFC, bilateral frontal operculum/anterior insula, caudate nucleus, and thalamus. There were no significant differences between groups (Supporting Information Figure   and Table  ). Both males and females showed right dominant deactivation in the precuneus, posterior cingulate, TPJ (bilateral, but right‐dominant middle temporal gyri, angular gyri, supramarginal gyri), right temporal pole, and fusiform gyri (Table   and Supporting Information Table  ). 


### Same‐sex other body perception 
  
Contrasting perception of   other bodies of the same sex   (80–100% morph) with the   scrambled   image baseline revealed significant (  Z   > 2.3,   p   < .05, corrected) activation in both (N = 15) men and (N = 15) women in the bilateral inferior lateral occipital cortices (EBA), fusiform cortices (FBA), bilateral caudate nucleus, thalamus, bilateral anterior insula, ventrolateral PFC, and dorsal mPFC, anterior cingulate cortices, and bilateral cerebellar hemispheres (Supporting Information Figure  ). In both groups, there was deactivation of the bilateral TPJ (middle temporal gyri, angular gyri, supramarginal, gyri) (Supporting Information Table  ). When comparing males and females, males showed significantly (  Z   > 2.3,   p   < .05, corrected) greater activation in the left superior lateral occipital cortex. Using a slightly more lenient threshold of   Z   > 2.0,   p   < .05, corrected, revealed additional, stronger activation in the precuneus cortex of males. The latter effect, however, was due to greater   de  activation in this area in females during perception of same‐sex other bodies (Table   and Supporting Information Table  ). 

Contrasting perception of other bodies of the   same sex   (80%–100% morph) with one's   own body   (0% morph) revealed significant (  Z   > 2.3,   p   < .05, corrected) activation only in males in the bilateral temporal occipital and fusiform cortex (EBA, FBA), left precentral gyrus, and left ventrolateral PFC (Figure  ). Women showed no significant differences in activation between perception of the own body and perception of other females' body. Although there were no significant differences between females and males at the   Z   > 2.3 threshold, lowering the threshold to   Z   > 2.0 revealed that men had significantly greater activation in the bilateral FBA and bilateral lateral occipital cortex (EBA) (Table  , Figure  ). 
  
Brain activation in men (blue‐light blue color) and women (red‐yellow color) when viewing images of (a) a same sex other body and (b) an opposite sex other body, contrasted to images of the own body, respectively, and (c) when viewing images of the own body contrasted to images of an opposite sex other body; MNI coordinates of the slices shown: (a)   x   = 30,   y   = −48,   z   = −14; (b)   x   = 4,   y   = −54,   z   = −12; (c)   x   = 4,   y   = 24,   z   = −4; R = right, L = left; color bars indicate   z   value of the presented contrast 
    
Sex differences in activation, with men (M) showing greater activation than women (F) when viewing images of (a) a same sex other body and (b) an opposite sex other body, contrasted to images of the own body, respectively; MNI coordinates of the slices shown: (a)   x   = −42,   y   = −66,   z   = −2; (b)   x   = 6,   y   = −74,   z   = 10; R = right, L = left; color bars indicate   z   value of the presented contrast 
  

### Opposite‐sex other body perception 
  
Contrasting perception of other bodies of the   opposite sex   (80%–100% morph) with the   scrambled   control images revealed significant (  Z   > 2.3,   p   < .05, corrected) activation in both men and women in the bilateral lateral occipital cortex including the EBA and FBA, and the right dorsolateral PFC. Both groups showed significant deactivation in the angular and supramarginal gyri. Women, in addition, showed deactivations in the precuneus and left frontal pole. Direct comparison of men and women revealed significantly greater activation in men in the bilateral EBA and FBA, precuneus, left middle temporal gyrus, right‐TPJ (angular, superior temporal, and supramarginal gyri), and left frontal pole (Supporting Information Figure   and Table  ). Using a slightly more lenient threshold (  Z   > 2.0,   p   < .05, corrected), men showed additional stronger activations compared to women in the bilateral caudate nucleus and left inferior frontal gyrus (Table  ). 

Contrasting perception of other bodies of the   opposite sex   (80%–100% morph) with one's   own body   (0% morph) revealed no significant (  Z   > 2.3,   p   < 0.05, corrected) activations in women, whereas in men there was significant activation in the (pre)cuneus cortex, bilateral TPJ (supramarginal, superior temporal, angular gyri), and right middle temporal gyrus (both anterior and posterior parts) (Figure  ). The direct group comparison revealed significantly stronger activations in men than in women in the bilateral precuneus, supra‐ and intracalcarine cortices, and lingual gyri (Figure  ). With a threshold of   Z   = 2.0,   p   < 0.05, corrected, men showed additional greater activations than women in the bilateral caudate nucleus and left accumbens, frontal pole, right‐TPJ (supramarginal, middle temporal, superior temporal, angular gyri), and the bilateral anterior insular cortices (Table  ). 

By contrast, women showed pronounced deactivation (i.e., greater activation to their   own   bodies compared to opposite sex bodies) in the bilateral anterior insula, right anterior cingulate cortex, left cerebellum, left postcentral gyrus, left precuneus, and bilateral (though right‐dominant) TPJ (Figure  c). Deactivations (activation to their   own   bodies more than to opposite sex bodies) in males were detected in the bilateral anterior cingulate gyri, right ventrolateral PFC, right‐anterior insula, and right‐superior parietal lobule (Figure  c). Thus, greater activations in response to own body compared with opposite sex bodies were observed in both men and women, but more pronounced in women. This indicates that the sex difference pattern in regions such as the anterior insula and right TPJ was driven by greater activation to own bodies than opposite sex other bodies in the women, rather than greater activation for opposite sex other bodies in men. 


### Response‐dependent perception of images morphed to same‐sex and opposite‐sex other bodies 
  
When viewing images morphed to the   same sex   (20%–100%), participants' ratings of greater self‐similarity (greater “me” rating) was significantly (  Z   > 2.3,   p   < 0.05, corrected) associated with activation in the left postcentral gyrus in both males and females. Participants' ratings of greater self‐similarity (greater “me” rating), when viewing images morphed to the   opposite sex   (20%–100%), was significantly (  Z   > 2.3,   p   < .05, corrected) associated with activation in the bilateral insula, anterior cingulate, and paracingulate in both males and females. 

By contrast, participants' rating of less self‐similarity (greater “not me” rating) of images morphed to the   same sex   (20%–100%) was significantly (  Z   > 2.3,   p   < .05, corrected) associated with activation in the precuneus and bilateral middle frontal gyri only in females. There were no significant associations for “not me” ratings in males. Participants' ratings of less self‐similarity (greater “not me” rating) when viewing opposite‐sex other bodies were significantly (  Z   > 2.3,   p   < .05, corrected) associated with activation in the bilateral TPJ and precuneus in both men and women. Men in addition showed significantly (  Z   > 2.3,   p   < .05, corrected) associated greater activations in the vmPFC and bilateral anterior temporal gyri. When males and females were directly compared regarding associations to greater “not me” ratings, males had significantly (  Z   > 2.3,   p   < .05, corrected) stronger associations in the bilateral amygdalae, precuneus, and posterior cingulate (Table  ). 

As noted above, brain regions that were associated with participants' ratings of self‐similarity (whether greater “me” or “not me” rating) differed when participants were viewing either the opposite or same‐sex—suggesting that the activation could be perceptually driven. To further investigate this possibility, we directly contrasted viewing of opposite versus same sex images in a combined group of males and females when parameterized to greater “not me” rating. Here, greater   “not me”   ratings when viewing bodies of the   same sex   versus the opposite sex were significantly (  Z   > 2.3,   p   < .05, corrected) associated with activation in the bilateral insula, bilateral vlPFC, right dlPFC, anterior cingulate cortices, left thalamus, and left cerebellum. By contrast, greater   “not me”   ratings when viewing bodies of the   opposite sex   versus the same sex were significantly (  Z   > 2.3,   p   < .05, corrected) associated with activation in the bilateral lateral occipital cortex (EBA), precuneus/posterior cingulate cortex, vmPFC, and left‐FBA, providing further evidence that the pattern of activation could be perceptually driven (Table   and Figure  ). 
  
Brain activation for parametrically modeled greater “not me” rating while viewing images morphed to the same versus opposite sex 
      
Across male and female participants, parametrically‐modeled “not me” ratings when viewing images of same sex and opposite sex other bodies of different morph degrees; red color = activation for the contrast “opposite sex – same sex bodies rated as ‘not me’”; green color = activation for the contrast “same sex – opposite sex bodies rated as ‘not me’”; MNI coordinates of the slices shown:   x   = 6,   y   = −66,   z   = 6; R = right, L = left; color bars indicate   z   value of the presented contrast 
  


## DISCUSSION 
  
The current study investigated whether cerebral processing of the perception of one's own body and of other bodies in the context of self differs between men and women. Perception of own, unmorphed bodies showed no sex differences, and involved activation of a set of brain regions previously described to be associated with perceptual recognition of self as well as during perceptual decisions about object identity (Ploran et al.,  ). This included body perception regions (EBA, FBA), and areas involved in self‐referential processing, such as the medial PFC, anterior insula, and thalamus (Amodio & Frith,  ; D'Argembeau,  ; D'Argembeau et al.,  ; Denny et al.,  ; Mitchell et al.,  ; Murray et al.,  ; van der Meer et al.,  ). Furthermore, activation of bilateral caudate nuclei was observed, congruent with previous reports about its involvement in processing of body and limb posture (Villablanca,  ). Finally, there was deactivation of the precuneus, right temporal pole, and both TPJ‐regions known to be involved in self‐other distinction, mentalizing, and perspective taking (Eddy,  ; Payne & Tsakiris,  ; van der Cruijsen et al.,  ). We also found activation in the cerebellum during own body perception, which is in line with a study describing its inclusion in a neuronal network underlying illusory own‐body perceptions (Schutter, Kammers, Enter, & Van Honk,  ). 

In sum, own body perception in the context of self involves cerebral processes related to one's own body schema, identification of self, as well as the specific distinction and comparison of self from and with others. Importantly, these processes do not seem to differ between men and women. 

Interestingly, and to the best of our knowledge not described earlier, during perception of   other bodies of the same   sex (contrasted to the   scrambled image  ), men and women engaged very similar brain areas as when viewing their own body, including the EBA, FBA, bilateral caudate, thalamus, bilateral anterior cingulate cortices, bilateral anterior insula, ventrolateral PFC, and dorsal mPFC. This was true also for the deactivation pattern (TPJ, temporal pole), with the only exception that it was more right‐lateralized in women than in men (Eddy,  ). 

One possible explanation for this similarity is that self‐referential information may be experienced and generalized to others who look similar to us (Platek, Krill, & Kemp,  ; Tsakiris,  ). It was also suggested that coactivation of the reward system and the dorsal anterior cingulate cortices during evaluation of self compared to others might contribute to the integration of social comparisons into evaluation of self (Lindner et al.,  ). Interestingly, an fMRI study (Lübke et al.,  ) that used body   odors   rather than visual body stimuli found very similar brain regions involved during perception of others' (males and females) body odors—the fusiform cortex, the anterior and posterior cingulate cortices, and the anterior insular cortex. 

As opposed to the “own, unmorphed body” condition, viewing another body of the same sex revealed a sex difference, with men having a more pronounced activation than women in the left lateral occipital cortex, which could be an indication of heightened attention towards same‐sex others. There was also a sex difference in the precuneus cortex, due to greater   de  activation of this region in female participants, implying that women might have less of self and same sex other differentiation compared to men (see further discussion). 

Notably, these sex differences in   same‐sex other   body perception became even more apparent when   contrasted to the own body   (0% morphed, rather than scrambled image). Whereas in female participants there was no significant difference in brain activation during own body and same‐sex other body perception, (there was a stronger   de  activation of the EBA), in male participants there was an increased activation of the FBA, left precentral gyrus and left ventrolateral PFC–when viewing another same sex body compared to the own body. A recent study showed that these latter brain areas were involved in decoding familiarity (of faces, bodies, and gait) (Hahn & O'Toole,  ). It may thus be possible that men show increased engagement, together with higher attentional load, in cognitive decision processes on differentiating between self and same‐sex others. This potentially could be evoking intrasexual competition (Buunk & Massar,  ) and/or could help to discern what is related and similar as opposed to different from self. Moreover, the sex differences in neural activations during perception of bodies similar to one's own may indicate that women more easily adopt other female bodies as “self” than men. This is also supported by the observed cerebellar activations during own and same‐sex other perception specifically in females, which have been reported to be involved in illusory own body perception (Schutter et al.,  ). Thus, our findings may be interpreted as that women may more easily be able to put themselves in other females' shoes, which require Theory of Mind (ToM), the ability to explain and predict other people's mental states, and cognitive empathy. Indeed, several previous studies have suggested sex differences in mind reading abilities as well as empathy (Adenzato et al.,  ; Frank, Baron‐Cohen, & Ganzel,  ; Krach et al.,  ; Schulte‐Rüther, Markowitsch, Shah, Fink, & Piefke,  ; Singer & Lamm,  ). 

A third major observation in this study related to perception of bodies of the opposite sex. When compared to the   scrambled image  , both men and women activated general as well as body perception‐specific attention circuits (EBA, FBA, right‐dorsolateral PFC). However, and notably, sex differences were most pronounced when contrasting viewing bodies of an opposite sex other to the   own body   (unmorphed image). The two groups differed distinctly in that men activated, whereas women   de  activated the precuneus and right TPJ. In addition, during viewing an opposite sex other body and when rating an image of their body that appeared female (morphed to the opposite sex) as “not me,” men showed activation in the visual cortex, caudate nucleus, precuneus, and bilateral amygdala, regions reported to be involved in other rather than self‐orientation (Bischoff et al.,  ; Eddy,  ), sexual arousal (Ponseti et al.,  ), and emotional salience (Gerber et al.,  ; Phan et al.,  ). 

Together, these data hint that the other body in relation to self might have a greater salience in men (van Hooff, Crawford, & van Vugt,  ), whereas for women images of the own body are more salient. The observed sex differences may have implications when trying to understand conditions involving own body perceptions such as anorexia nervosa, gender dysphoria, or autism spectrum disorders, which all show a sex skewed prevalence. Females previously were found to be more sensitive to information about their own body than males (Mitchison et al.,  ; Powell & Hendricks,  ), and therefore perhaps have a less distinct or a more vulnerable own body schema, rendering them more prone to internalized distorted perceptions of their own bodies. Females may also easier adopt other females' bodies as “self” and, conversely, do not accept the image of one's body as “self.” Worth mentioning is that all the participants were heterosexual, thus the discussion only pertains to heterosexual cis‐gender persons. 

In addition to investigating whether men and women engage different cerebral networks during perception of own and other bodies in the context of self, we also approached this at a different level: when distinguishing self from others, does the brain show differences depending on whether it is viewing the same or the opposite sex? To investigate this, we directly contrasted rating “not me” of same sex versus rating “not me” of opposite sex bodies. Here, greater   “not me”   ratings when viewing   same sex   bodies compared with opposite sex bodies was significantly associated with activation in regions involved in (illusory) own body perception and comparative processes (Kedia, Mussweiler, & Linden,  ). Yet, the same   “not me”   ratings but when viewing   opposite sex   bodies compared with same sex others did engage (body) perceptual and evaluative regions (Kedia et al.,  ). This suggests that the activations were dominated by perceptual—the type of visual body stimuli—rather than cognitive processes, since the latter was same in both cases: rating “not me.” 

Interestingly, and in support of this notion, a neuroimaging study using body odor stimuli from either the sisters or same‐sex best friends of a group of 12 women, showed that, independently of conscious recognition, olfactory‐based kin recognition activated self‐referential brain regions when smelling body odors of their sisters as compared to their female friends (Lundström, Boyle, Zatorre, & Jones‐Gotman,  ). In that study, kin recognition, via the mechanism of so‐called “automatic self‐referent phenotype matching” (Mateo & Johnston,  ), recruited self‐referential networks without any cognitive or conscious identification process involved. Together with the current study, these observations suggest that sensory body perception (visual or olfactory) seems to overrule cognitive perception (i.e., labeling a given body as “me” or “not me”), which was previously shown for other stimuli of high social and ecological importance, such as body odors, emotional faces, and infant crying and laughing sounds (Lundström, Boyle, Zatorre, & Jones‐Gotman,  ; Morris, Öhman, & Dolan,  ; Seifritz et al.,  ). Whether this overruling of sensory over cognitive perception also applies to other stimuli remains to be further investigated. 

Our findings should be viewed in light of its limitations. First, we did not assess participants' impression of the body stimuli afterward outside the scanner in terms of how attractive the opposite‐sex, or same‐sex body stimuli were perceived. It is possible that the male participants considered the opposite sex stimuli as more attractive than did the female participants, which might partially explain our findings of stronger attention and reward‐related brain activation in men for this condition. In addition, this information would have helped to establish more direct links between the activation patterns and cognitive/evaluative processes other than the subjective degree that the body was similar to theirs, about which we could only make post hoc inferences. We also did not obtain any ratings from independent raters of how similar the morph‐to stimuli bodies were to the participants' bodies and did not measure participants' body weight or body mass index. It may have theoretically been possible, by chance, that the female morph‐to bodies used were better comparable, in terms of, for example, height, weight, shape, or muscularity, to those of the female participants than how the male morph‐to bodies compared to the male participants' bodies. This might have affected the sex differences we observed in the same‐sex other versus own body condition. However, this is mitigated partially by the fact that based on the investigators' subjective impression, none of our participants had extremely different body composition than the morph‐to stimuli bodies; for example, none appeared obese or extremely underweight. Finally, though only (self‐reported) healthy participants were included, we did not perform a structured assessment of any prior or current eating disorder (or other psychiatric disorders). Therefore, we cannot rule out that there may have been (if the participants were unaware or did not report accurately) any disturbances in body image or possible concerns about the own body, that might have resulted in own‐body stimuli being much more emotionally salient and that might have been more common in one of the groups. 

In conclusion, we provide first evidence that the neural representation of own body does not differ appreciably between the sexes. In contrast, perception of other bodies, in particular of the opposite sex, could be a particularly salient social signal to men, whereas for women the own body likely has higher relevance. 


## CONFLICT OF INTERESTS 
  
The authors have no conflict of interest. 


## Supporting information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-21'>
<h2>21. PMID: 26644594</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> The shaping of social perception by stimulus and knowledge cues to human animacy</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Philos Trans R Soc Lond B Biol Sci</p>
<p><strong>Publication Year:</strong> 2016</p>
<p><strong>DOI:</strong> 10.1098/rstb.2015.0075</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an empirical fMRI study in healthy adults (final N=23, mean age 26.4, right-handed, native speakers) that investigated social perception/animacy processing while participants viewed agents interacting with objects — a social-related task. Data were acquired with whole-brain fMRI and analyses were conducted at the whole-brain level (voxel-wise thresholds reported, cluster-level FWE/FDR corrections noted); results are not limited to ROI-only analyses. The study is not a review/meta-analysis and does not include clinical/psychiatric populations. All inclusion criteria are met (task-based fMRI during social processing, healthy participants age 18–60, whole-brain results). No exclusion criteria are violated. Therefore the study should be included.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Although robots are becoming an ever-growing presence in society, we do not hold the same expectations for robots as we do for humans, nor do we treat them the same. As such, the ability to recognize cues to human animacy is fundamental for guiding social interactions. We review literature that demonstrates cortical networks associated with person perception, action observation and mentalizing are sensitive to human animacy information. In addition, we show that most prior research has explored stimulus properties of artificial agents (humanness of appearance or motion), with less investigation into knowledge cues (whether an agent is believed to have human or artificial origins). Therefore, currently little is known about the relationship between stimulus and knowledge cues to human animacy in terms of cognitive and brain mechanisms. Using fMRI, an elaborate belief manipulation, and human and robot avatars, we found that knowledge cues to human animacy modulate engagement of person perception and mentalizing networks, while stimulus cues to human animacy had less impact on social brain networks. These findings demonstrate that self–other similarities are not only grounded in physical features but are also shaped by prior knowledge. More broadly, as artificial agents fulfil increasingly social roles, a challenge for roboticists will be to manage the impact of pre-conceived beliefs while optimizing human-like design. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (49446 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Detection and recognition of other agents is a necessary ability across species. It is an integral pre-requisite for social interaction: one must accurately identify others in order to appropriately interact with them. For instance, one would not expect a robot to offer the same opportunities for social interaction as a human. Considering the predicted rise of artificial agents in society performing tasks alongside humans in hospitals, care homes and schools [ ], it will become increasingly important to distinguish between animate agents (e.g. humans) and inanimate agents (e.g. robots). Robots can act in the world by moving and achieving goals, but they are not sentient or intentional. Indeed, a key factor for classifying other agents is the perception of animacy—the presence of life in others. The distinct way that robots and humans look and move as well as what we know about their origins offer important cues to animacy [ ]. As such, a key question for social cognition and social neuroscience research pertains to understanding the cognitive and neurobiological mechanisms that enable us to recognize animacy in other agents [ ]. 

### The neuroscience of social perception and cognition 
  
The neuroscience of social cognition is concerned with how the brain manages social interactions with others [ ]. Several distinct brain circuits have been identified that process elements of our social worlds, three of which are of particular relevance to the current study ( ). Person perception research has shown how sensory systems are sensitive to the presence of conspecifics in the environment [ ]. For instance, patches of cortex in the ventral visual stream including fusiform and occipitotemporal gyri respond preferentially to images of social stimuli (faces and bodies) compared to non-social stimuli (houses and cars) [ , ]. Accumulating evidence suggests the ventral visual stream contributes to understanding identity through processing physical appearance, such as facial features, body shape and posture [ , ].
   
Social brain circuits. mPFC, medial prefrontal cortex; TP, temporal poles; Prec., precuneus; IFG, inferior frontal gyrus; IPL, inferior parietal lobule; TPJ, temporoparietal junction; pSTS, posterior superior temporal sulcus; FG, fusiform gyrus; OT, occipitotemporal cortex. The mirror neuron system and pSTS form the key nodes of the action observation network. 
  

Another form of social perception involves observing others moving through the environment and interacting with objects. Brain regions responding to the observation of others in action include posterior temporal gyri, inferior parietal lobule and inferior frontal gyrus [ – ]. The frontal and parietal responses are consistent with research into the mirror neuron system discovered in monkeys, which shows similar responses to performed and observed actions [ ]. One dominant theory argues that this frontoparietal network enables action understanding through simulation by mapping observed actions onto the observer's own motor system [ ]. 

Simply coding the physical characteristics of other agents and their movements would not, however, be sufficient to understand the meaning of their actions. It is also necessary to make inferences about information one cannot see, such as others' beliefs, desires, attitudes and traits [ ]. A third strand of social cognition research—mentalizing—aims to delineate the cognitive and brain systems integral to representing such mental states of others [ ]. Brain circuits spanning the medial prefrontal cortex (mPFC), temporoparietal junction (TPJ), temporal poles and precuneus are consistently engaged when inferring and evaluating mental states and are collectively known as the theory of mind network [ , ]. The ability to draw inferences about underlying intentions helps us to predict what another individual may do next and helps to regulate social interactions [ , ]. Together, the studies highlighted in this section have identified discrete brain circuits that subserve aspects of social perception and interaction. It is less clear, however, how social information is organized beyond a social–non-social distinction. 


### The ‘like-me’ hypothesis 
  
One dominant model in social cognition states that understanding the similarity between self and other is a basic principle of social cognition and that humans have developed to seek out self–other equivalence [ , ]. This account, known as the ‘like-me’ hypothesis, further proposes that actions performed by oneself and another are represented in common cognitive codes [ ]. At the core of the ‘like-me’ hypothesis is the proposal that cognitive and brain mechanisms have been shaped to show sensitivity to information that is physically or cognitively similar to one's own makeup. This view is consistent with the biological imperative to detect similar others as a foundation for successful navigation of the world [ ]. 

One approach to test predictions that follow from the ‘like-me’ hypothesis has been to vary cues to human animacy. In such studies, the idea is that the more human-like an agent is perceived, in terms of physical appearance and intentionality, the more it is considered to be ‘like me’. These studies have fallen into two main camps based on the type of cues to human animacy under investigation. One camp has manipulated stimulus features, such as what an agent looks like or how it moves. The second camp has manipulated knowledge cues to animacy, such as whether an observer believes an agent to be human or not. Both cue types are of clear relevance to the study of social perception. Humans move in a particular way, for instance using a minimum jerk trajectory, and have a particular form (i.e. head above a torso with limbs). Such distinctive physical features can be diagnostic of a human presence. Likewise, knowledge cues also matter for interpreting human animacy. If you know the gorilla across the street is actually a man in a costume, your perception of the social environment would be markedly different from if you were not aware of this fact. In the following, we review behavioural and brain-imaging studies that have manipulated stimulus cues and knowledge cues to human animacy. Instead of an exhaustive review of all studies exploring animacy detection, our focus is on brain systems that index the distinction between human and non-human agents. 


### Stimulus cues to human animacy 
  
The majority of research into cues influencing animacy perception has focused on stimulus cues to human animacy, such as what an agent looks like and how it moves. These can be considered ‘bottom-up’ cues that are determined by the visual appearance of the form and motion of an agent. Many studies have investigated responses along the ventral visual stream to depictions of human compared to non-human stimuli, such as other animals or inanimate objects [ , ]. Less research in the domain of person perception has varied cues to human animacy by comparing human to less human or robotic agents [ , ]. Gobbini   et al  . [ ] showed similar engagement of core face perception areas—fusiform face area (FFA), occipital face area (OFA) and posterior superior temporal sulcus—when observing human and artificial, robotic faces. In addition, core face and body processing regions also respond to cartoon and schematic depictions of faces and bodies [ , ]. Thus, the ventral visual stream appears to be indifferent to animacy cues that are based on physical form and responds to real faces and bodies as well as face- and body-like forms. 

In the domain of action perception, where agents are moving in the world and sometimes interacting with objects, results are mixed. The superior temporal sulcus has been shown to respond to biological motion, even in the absence of a clear human form [ , ]. Many studies have also compared the observation of actions performed by humans and robots. A common result is more engagement of sensorimotor brain regions collectively termed the action observation network (AON) and facilitated behavioural responses when the agent is more human than not [ , ]. For example, observing human form and motion increased motor priming in an imitation task [ , ]. In addition, right premotor cortex is engaged more during the observation of reaching actions performed by a human hand compared to a robotic claw [ ]. These results are consistent with a self-similarity bias and more AON engagement when an observed agent is more human. 

On further inspection of the action perception literature, however, several studies show indifference in the AON to degrees of stimulus-driven humanness or even a preference for non-human stimuli. For instance, Gazzola   et al  . [ ] failed to find any difference in brain responses when participants viewed actions performed by a human or robotic hand. Likewise, Ramsey & Hamilton [ ] found that the left anterior intraparietal sulcus, a core AON node, responded in a similar manner when participants observed a geometric shape or a human hand perform goal-directed actions. Moreover, some studies show an even greater response in the AON when perceiving non-human compared to human visual cues [ , ]. In two experiments, Cross and co-workers show greater engagement when watching rigid robotic movement compared to natural free-flowing dance moves that are more consistent with a human's motor repertoire [ ]. This robust AON engagement was seen when participants observed a human actor dancing and when observing a robot toy animated to move in a similar manner. Therefore, the AON was shown to be more sensitive to rigid, non-human-like movement irrespective of animacy cues based on physical form. Finally, Saygin & Stadler [ ] found that middle temporal gyrus and intraparietal sulcus are more sensitive to an android (a robot dressed as a human) than a clearly presented human or robot actor. Thus, the role of the AON in response to varying stimulus cues to human animacy remains somewhat unclear. 

Stimulus cues can also drive mental state reasoning and engagement of the person knowledge or theory of mind network. Heider & Simmel [ ] showed that when people observe simple shapes moving around as if they are interacting, they ascribe human-like mental states to these shapes. Using the same stimuli, Castelli   et al  . [ ] demonstrated that these stimuli also engage brain regions associated with mental state reasoning and social cognition (see also [ ]). Social context can also lead to mental state reasoning if stimuli are arranged in a manner that makes a moving object look like a social agent (such as an ice skater) rather than an inanimate object (like a spinning top [ ]). Finally, the same movie footage of social interactions engages person knowledge networks more if real video footage is viewed rather than modified versions that have been made to appear ‘cartoonish’ [ ]. Together, this work suggests that stimulus cues alone can provide an input to human-like mental state and animacy judgements. 


### Knowledge cues to human animacy 
  
Knowledge cues to animacy are based on beliefs about an agent's animate origins and can be task instructed or task independent [ ]. These can be considered ‘top-down’ cues that are driven by prior information about the stimulus, rather than by the visible form and motion cues. The impact of knowledge cues can be seen most clearly when visually identical stimuli are encountered across different conditions, which vary knowledge about the agent's humanness. Thus, any differences in cognitive or brain function are cued by information that is independent to the stimulus. 

A growing body of behavioural evidence supports the notion that beliefs about humanness influence social perception and interaction [ – ]. For example, Liepelt & Brass [ ] used an automatic imitation task and found that participants showed stronger evidence of motor priming when movements were thought to be made by a human rather than a wooden hand. Using simplified moving dot stimuli, Stanley   et al  . [ , ] showed increased behavioural interference together with reports of stimuli appearing more human-like when participants believed the stimuli originated from real human movement compared to computer-generated movement. Finally, using a manipulation where participants were required to coordinate their actions with a physically present humanoid robot, Stenzel   et al  . [ ] found that participants were more likely to represent the robot's action if they believed that the robot's behaviour was based on a biologically inspired neural network than when it was based on a computer program. 

Neuroimaging research has also varied knowledge cues to human animacy. Seminal fMRI studies of theory of mind used the same stimuli for both ‘human’ and ‘computer’ conditions, and varied participant instructions. The instruction ‘you are playing with a human’ gave rise to robust activation in the person knowledge network [ , ]. That is, the identical stimulus increasingly activated social brain regions when participants believed it originated in another person, not a computer. 


### Combined stimulus and knowledge cues to human animacy 
  
Few studies have directly compared stimulus and knowledge cues to human animacy. Press   et al  . [ ] showed that stimulus cues to animacy override knowledge cues when imitating hand actions. By contrast, Stanley   et al  . [ ] showed that knowledge of how a moving dot was made (human versus computer-generated) dominated perception of animacy compared to its motion properties. Klapper   et al  . [ ] showed that both types of cue influence imitation of hand actions. Moreover, fMRI results from the study by Klapper and co-workers showed that right TPJ was engaged more during an automatic imitation task when both stimulus   and   knowledge cues to human animacy were present than when only one or neither cue to human animacy was present [ ]. This result supports the view that right TPJ may be particularly sensitive to controlling interactions with human agents [ , ]. 

A neuroimaging study by Stanley   et al  . [ ] manipulated both types of cue by investigating passive observation of point-light animations. Point-light stimuli typically consist of a sequence of moving dots, representing several joints on an actor's body, which give the appearance of human biological motion [ ]. This study found that knowledge of human animacy engaged mPFC more than knowledge that the stimuli were computer-generated. By contrast, human-like movement did not engage social brain circuits more than less-human movement. While emerging evidence suggests instances when both stimulus and knowledge cues influence social perception and cognition, the conditions and parameters that lead to these biases remain largely unknown. 


### Summary and the current study 
  
Evidence suggests widespread cortical engagement of distinct social brain circuits for detecting and recognizing aspects of human animacy during social interactions. Stimulus and knowledge cues to human animacy engage person perception, action observation and mental state reasoning networks. The picture to date remains far from clear, but there appears to be some kernel of truth to the suggestion that a mechanism of self-similarity or ‘like me’ may operate across these studies. Many questions remain unanswered, however. A growing number of studies show indifferent or opposite brain or behavioural responses to those consistent with a theory based on self-bias. Moreover, few neuroimaging studies have directly compared stimulus and knowledge cues to human animacy in the same experiment to tease apart their relative contributions to detection and recognition of other humans. Indeed, only one other study to date has investigated action perception in this manner and this study did not present visible human features, such as faces or body parts, but instead used point-light displays of simple actions [ ]. Hence, it remains unclear how perception of action is influenced by cues to human animacy, particularly when physical form cues are visible. 

The current study, therefore, directly compares stimulus and knowledge cues to human animacy during the observation of agents interacting with objects. Face and body cues are manipulated as well as beliefs about the origins of such actions. By doing so, we are able to investigate which cues to animacy dominate perception of action as well as how these cues engage social brain circuits. To support the ‘like-me’ hypothesis, we would expect greater engagement of brain regions implicated in action observation [ , ], mentalizing [ , , ] and person perception [ , ] when stimulus or knowledge cues to human animacy (or both) are present. However, as a number of recent studies suggest [ , – ], we might also find that parts of the social brain are not solely tuned to preferentially respond to cues that are ‘like me’. Thus, the current study will provide novel insights into aspects of the social brain that are more or less responsive to features of an agent that are ‘like me’ through careful manipulation of stimulus and knowledge cues to human animacy. 



## Material and methods 
  
### Participants 
  
Twenty-nine physically and neurologically healthy young adults were recruited from the fMRI Database of the Max Planck Institute for Human Cognitive and Brain Sciences (Leipzig, Germany). All were monetarily compensated for their involvement and provided written informed consent in line with procedures set forth by the local ethics board. Six participants were excluded from the final analyses due to not believing the cover story (see   Behavioural Procedure and Task  ). The final sample included 23 participants (14 women, nine men;   M   = 26.41 years, s.d. = 3.02 years) who believed the cover story. All participants were native German speakers and right handed as measured by the Edinburgh Handedness Inventory [ ]. 


### Stimuli 
  
Stimuli were created using P  three-dimensional animation software (SmithMicro Software Inc, Santa Cruz, CA, USA) and featured 10 object-directed actions ( ). Each video lasted 5 s. To create the stimuli, a human actor was first filmed performing each action, and these videos served as a model for creating the Poser videos. Each action was mapped onto two different avatars: a human male and a custom-designed robot ( ). Each action was ‘filmed’ from the waist upwards and from three different angles: centre, off centre and from the side (see right panel of   a  ). These procedures yielded 60 videos in total (10 different actions × 2 different agents × 3 different viewing angles).
   
Details of experimental materials and design. (  a  )(i) Eight of the 10 actions featured in the stimuli set (the remaining two, ‘toss ball’ and ‘hammer nail’ are seen in (  a  )(ii) and in (  b  )). (  a  )(ii) The three viewing angles each action was ‘filmed’ from, to create a larger, richer stimulus set. (  b  ) The 2 × 2 factorial design that enabled investigation of bottom-up features (whether the agent looked like a human or robot; rows of design) as well as top-down features (whether participants were told the videos were created using human motion capture or computer animation; columns of design). 
  


### Belief manipulation 
  
In order to manipulate knowledge cues to human animacy, participants were told the current study was commissioned by a major German film studio for the purpose of examining how the human brain processes two cutting-edge animation techniques: human motion capture and computer-generated keyframe animation. Before taking part in the experiment, participants watched a 10-min custom-made and professionally produced ‘documentary’ that explained human motion capture and computer keyframe animation techniques in detail (see also [ ]). Specifically, participants learned that human motion capture involves recording real human movement via sensors that are attached to the body, whereas computer-generated keyframe animation involves a computer algorithm that fills in intermediate frames of a movement between predefined start and end positions. To further induce believability, the Poser stimuli used in the actual experiment were briefly seen in several parts of the cover story documentary to reinforce the idea that both kinds of animation could lead to the types of stimuli observed in the present study. In reality, however, all stimuli used in the real experiment were made with computer keyframe animation (the technique used by P  software), which closely approximates real biological motion. After watching the documentary, participants were asked whether they had understood how both techniques were used to animate avatars, and whether they had any questions about the techniques before the experiment started. 


### Behavioural procedure and task 
  
Participants' task in the scanner was to carefully observe 240 video stimuli during one functional run (each of 60 videos was repeated four times in total during the experiment). The videos were blocked into groups of five (with each group of five videos featuring either the human or the robot avatar), and participants observed a total of 48 blocks of five videos containing equal numbers of each agent form/belief pairing. Before each block of five videos was played, a cueing screen appeared for 2 s that specified that the following videos were made either with motion capture or computer keyframe animation (  b  ). The order of instruction screens and the individual actions that made up each series of five videos was pseudo-randomly assigned. 

After each video, one of two questions appeared which participants were required to answer: either (i) how much did you   like   the video you just saw? or (ii) how   smooth   did you find the movement in the previous video? These questions were chosen for several reasons. First, we wanted to determine how stimulus and knowledge cues to human animacy influence perception of the stimuli at a behavioural level. Second, two questions were chosen so that participants could not anticipate the exact question they would be asked, which required them to maintain attention to the stimuli. Participants made their ratings on a 1–8 scale via a fibre-optic scanner compatible button box. Following scanning, participants completed a debriefing survey where they were explicitly asked whether they noticed anything of note about the stimuli, as well as what they believed the true goal of the study was. The six participants (of the original sample of 29 participants) who raised suspicions the stimuli seemed to be the same and only the instructions changed were excluded from the final sample. Upon completing this survey, all participants were told the true nature of the study and compensated for their time. 


### MRI acquisition 
  
Functional neuroimaging was acquired using a Bruker 3 Tesla Medspec 20/100 whole-body MR scanning system, equipped with a standard birdcage head coil. Functional images were acquired continuously with a single-shot gradient echo-planar imaging sequence with the following parameters: echo time (TE) = 30 ms, flip angle = 90°, repetition time (TR) = 2000 ms, acquisition bandwidth 100 kHz. Twenty-four axial slices allowing for full-brain coverage were acquired in ascending order (pixel matrix = 64 × 64; FOV = 24 cm, resulting in an in-plane resolution of 3.75 × 3.75 mm , slice thickness = 4 mm, interslice gap = 1 mm). Slices were oriented parallel to the bicommissural plane (AC-PC line). The first two volumes of each functional run were discarded to allow for longitudinal magnetization to approach equilibrium. An additional 813–830 volumes of axial images were collected. Geometric distortions were characterized by a B0 field map scan (consisting of a gradient echo readout (32 echoes, inter-echo time 0.64 ms) with a standard two-dimensional phase encoding). The B0 field was obtained by a linear fit to the unwarped phases of all odd echoes. Following the functional run and field map scan, 24 two-dimensional anatomical images (256 × 256 pixel matrix, T1-weighted MDEFT sequence) were obtained for normalization purposes. In addition, for each participant, a sagittal T1-weighted high-resolution anatomical scan was recorded in a separate session. The anatomical images were used to align the functional data slices with a three-dimensional stereotaxic coordinate reference system. 


### Behavioural data analysis 
  
Behavioural responses to the smoothness and liking questions asked during the imaging task were combined to form a single dependent variable and were analysed with a 2 (Agent Form: human, robot) × 2 (Belief Manipulation: human motion capture, computer-generated animation) repeated measures ANOVA. 


### Imaging data analysis 
  
Data were realigned and unwarped in SPM8 (Wellcome Department of Imaging Neuroscience, London, UK) and normalized to the Montreal Neurological Institute (MNI) template with a resolution of 3 × 3 × 3 mm. Slice timing correction was performed after realignment. Functional data were normalized to individual participants' T1 anatomical scans with a resolution of 3 mm . All images were then spatially smoothed (8 mm). A design matrix was fitted for each participant, with each type of video (Human with Motion Capture instruction, Human with Computer Animation instruction, Robot with Motion Capture instruction and Robot with Computer Animation instruction), the belief manipulation instruction screen and the question/response period modelled as a boxcar function convolved with the standard haemodynamic response function. The imaging analyses were designed to achieve the following three primary objectives: 

#### Main effect of stimulus cues 
  
First, we evaluated the main effect of visual cues to the socialness of an observed agent. To achieve this, we compared observation of actions performed by the human avatar to the robot avatar (human > robot), as well as the inverse (robot > human). 


#### Main effect of knowledge cues 
  
We next assessed the main effect of our belief manipulation. We evaluated brain regions more engaged when videos were believed to have a human origin (motion capture > computer animation), or when videos were believed to be computer-generated (computer animation > motion capture). 


#### Interaction between stimulus and knowledge cues 
  
The third set of contrasts examined the interactions between agent form and belief cues. The aim of these interaction analyses was to determine the extent to which brain regions associated with the action observation, mentalizing or person perception networks are sensitive to specific pairings of stimulus-driven and knowledge-based cues to human animacy. The first interaction contrast interrogated brain regions more engaged when viewing congruent agent/belief pairings more than incongruent pairings. An example of a congruent pairing would be a human agent paired with motion capture belief or a robotic agent paired with computer-generated belief, whereas incongruent pairings would feature a human agent paired with computer animation belief or the robotic agent paired with motion capture belief. The inverse interaction examined brain regions more engaged when viewing the incongruent agent/belief pairings compared to the congruent pairings. 

All neuroimaging analyses were evaluated at the whole-brain level with a voxel-wise threshold of   p   < 0.005 uncorrected and   k   = 10 voxels [ ].   lists all regions that meet this threshold. To most clearly illustrate all fMRI findings,   t  -images are visualized on a participant-averaged high-resolution anatomical scan. Parameter estimates (beta values) were extracted and plotted for visualization purposes only for the two interaction analyses. Anatomical localization of all activations was assigned based on consultation of the Anatomy Toolbox in SPM [ , ].
   
Main effects and interaction from whole-brain analyses. MNI coordinates of peaks of relative activation within regions responding to the main effects of agent, collapsed across instruction (a: observing a human compared to a robot perform an action; and b: observing a robot compared to a human perform an action), the main effects of belief manipulation, collapsed across agent (c: observing actions said to be made by human motion capture compared to computer-generated animation; and d: observing actions said to be made by computer-generated animation compared to human motion capture) and the interactions between agent form and belief manipulation (e: observation of congruent agent/belief pairings; and f: observation of incongruent agent/belief pairings). Results were calculated at a voxel-level threshold of   p   < 0.005,   k   = 10 voxels. Up to three local maxima are listed when a cluster has multiple peaks more than 8 mm apart. Entries in bold denote activations significant at the false discovery rate cluster-corrected level of   p   < 0.05. HF, human form; RF, robot form; MCB, motion capture belief; CGB, computer-generated belief. 
  




## Results 
  
### Behavioural data 
  
During scanning, participants rated each video on how smooth they found the movement or how much they enjoyed watching it. Due to an error in the MATLAB code, it was not possible to separate ratings of liking and smoothness for the main experiment. However, a follow-up behavioural study was performed with 30 naive participants who performed the identical task with the same stimuli. These data showed that across all 120 stimuli/instruction pairings, ratings of liking and smoothness correlated at   r   = 0.53,   p   < 0.001. As prior work suggests that both questions tap into the same psychological construct (i.e. we tend to like movements more that are smooth [ ], and participants' ratings of movement smoothness and liking strongly correlate in other experimental settings [ ]), we considered it valuable to examine behavioural responses as a single combined variable. A repeated measures ANOVA revealed that participants rated movements they thought to be generated by human motion capture as significantly smoother and more pleasing to watch than videos they believed to be generated by computer animation,   F   = 21.28,   p   < 0.001 ( ). No main effect of agent (  p   = 0.39) emerged, nor was any interaction between belief and agent manifest in the data (  p   = 0.79). These data suggest that beliefs influence our dependent measure more than an agent's form.
   
Behavioural data from fMRI task. Plots illustrate mean ratings reported by participants to questions interrogating how smooth participants found the movements or how much they enjoyed watching them. A main effect of belief was manifest, such that participants found those action videos they believed to originate from human motion capture techniques to be smoother and more enjoyable to watch than videos they believed to originate from computer-generated animation. No other main effects or interactions were observed. 
  


### Functional imaging data 
  
#### Main effects of stimulus cues 
  
The first imaging analyses investigated the extent to which visual cues to human animacy influence action perception. No suprathreshold clusters emerged from the human > robot form contrast. The inverse contrast (robot > human form) revealed engagement of bilateral ventral temporal and occipital cortices, which survived correction for multiple comparisons (  p   < 0.005,   FWE  -corrected), as well as   engagement of portions   of the left superior temporal gyrus and hippocampus (  b   and   a  ). Similar to findings reported by Cross   et al  . [ ], this result suggests greater high- and low-level visual engagement when observing a robotic agent execute actions.
   
Main effects of agent form (stimulus) and belief manipulation (knowledge). Panel (  a  ) illustrates brain regions more engaged when participants watched actions performed by a robotic avatar compared to a human avatar. Panel (  b  ) shows brain regions more engaged when participants watched videos they believed to originate from human motion capture compared to computer animation. Full details of these findings are presented in  . STG, superior temporal gyrus; FG, fusiform gyrus; IOG, inferior occipital gyrus; SPL, superior parietal lobule. 
  


#### Main effect of knowledge cues 
  
The next set of contrasts evaluated the impact of belief or knowledge cues to human animacy on action perception. The first contrast (human motion capture > computer keyframe animation belief) revealed activity within the right inferior occipital and fusiform gyri. While these brain regions did not survive correction for multiple comparisons, it is nonetheless of interest to note that the cluster located within the right inferior occipital gyrus closely corresponds to functional localizations of the OFA (less than 6 mm away [ ]). Moreover, the peak of the cluster in fusiform gyrus is 14 mm away from an average peak location of this region when functionally localized, as reported by Spiridon   et al  . [ ]. It should be noted, however, that the fusiform cluster identified in the present study is more anterior to most reports of the FFA. Clusters also emerged in the left precuneus, as well as the left superior parietal lobule also emerged from this contrast (  c   and   b  ). The response in the precuneus corresponds closely to responses typically found with a theory of mind localizer task based on comparing beliefs to physical stories [ ]. The inverse contrast (computer keyframe animation > human motion capture) did not reveal any suprathreshold activations. 


#### Interaction between stimulus and knowledge cues 
  
The next set of analyses investigated the extent to which brain regions associated with social perception are influenced by the interaction of stimulus and knowledge cues to human animacy. The first interaction examined congruent pairings of agent and belief compared to incongruent pairings ((human form + motion capture belief) and (robot form + computer animation belief) > (human form + computer animation belief) and (robot form + motion capture belief)). Three uncorrected clusters emerged along the midline cingulate cortex, including middle and posterior cingulate cortices (  e   and electronic supplementary material, figure A). The parameter estimate plots reveal evidence for crossover interactions for the two middle cingulate activations, while the interaction within posterior cingulate cortex appears to be driven most by a stronger response to the human agent being paired with motion capture instructions compared to computer animation instructions. 

The inverse interaction evaluated brain regions more engaged when observing incongruent compared to congruent form and belief pairings ((human form + computer animation belief) and (robot form + motion capture belief) > (human form + motion capture belief) and (robot form + computer animation belief)). This contrast revealed two uncorrected clusters: one in the right inferior frontal gyrus, and a second in the cerebellum (  f   and electronic supplementary material, figure B). For this interaction, it is of note that the interaction present within these two brain regions is driven by different stimuli (see parameter estimates in electronic supplementary material, figure B). Specifically, robotic agents paired with motion capture instructions seem to drive the cerebellar region most strongly, while the human agents paired with computer animation instructions drive the inferior frontal gyrus region most. 




## Discussion 
  
Prior research has revealed that many different cues to human animacy engage brain networks associated with social cognition, while less is known about the relationship between these cues. In the present study, we used video stimuli featuring kinematically identical actions performed by a human or robotic agent and an elaborate belief manipulation to test the extent to which stimulus and knowledge cues to human animacy influence perception. Behaviourally, participants reported actions believed to originate from human motion capture to be smoother and more enjoyable to watch than those believed to have computer animation origins, while differences in agent form did not affect ratings. The neuroimaging findings echoed this pattern, with knowledge cues to human animacy showing subtle influence (at a liberal threshold) on brain circuits implicated in social cognition. 

We failed to find evidence that visual cues to human animacy more strongly engage the action observation, person perception or theory of mind networks than visual cues to a robotic agent, as might have been predicted. In contrast, we found a robust, cluster-corrected area of activation spanning ventral temporal and occipital cortices when participants observed actions performed by a robotic compared to human-like agent. These findings raise questions about the role played by stimulus cues to human animacy, while also highlighting the influence of knowledge cues on social perception when perceiving identical agents and actions. Together, they provide new insights into the supporting neural architecture and behavioural consequences of social perception. 

### Belief about humanness influences perception, as shown by brain and behavioural responses 
  
While some prior studies have failed to find evidence that belief about the human origins of a stimulus can impact perception [ ], a growing body of evidence supports the notion that beliefs about humanness influence the way we perceive and imitate other agents [ – , ]. Our results are consistent with these findings as participants were more likely to report actions supposedly originating from real human movements as smoother and more pleasing to watch (questions that tap into how natural or human-like an agent or action appears [ ]). Our findings also fail to demonstrate that differences in agent form influence these ratings, which further suggests that knowledge cues can dominate stimulus cues in explicit evaluation of social features of an observed action [ ]. A challenge for future behavioural research will be to systematically investigate how knowledge cues to animacy impact different facets of social cognition. To date, for example, perceptual and imitative processes have been studied separately, and the relationship between these key aspects of social cognition and knowledge cues to human animacy remains unexplored. 

At the neural level, our findings provide some evidence that actions paired with a human- compared to computer-generated belief lead to greater engagement of brain regions associated with person perception and theory of mind. Specifically, portions of the right inferior occipital gyrus and fusiform gyrus responded more to the same stimuli when they were paired with human motion capture instructions. Both regions are located in close proximity to patches of cortex that are face selective including the OFA [ ] and fusiform face [ ] and body areas [ ]. It is of note that these two brain regions associated with processing the human face were modulated in this instance by social knowledge, and not differences in stimulus-driven features. 

Also important is the emergence of a cluster within the right precuneus from this same contrast. The precuneus is consistently implicated in theory-of-mind tasks and is believed to play a role in explicit belief processing [ , ]. If these results were to be replicated by future studies, they would suggest that parts of the social brain network involved in perceiving others' physical features and reasoning about others' minds are engaged when viewing agents whose actions are believed to have human origins. Revisiting the study by Stanley   et al  . [ ], these researchers varied the motion parameters of point-light actions (ranging from veridical displays of the original action to completely scrambled versions of each action), and, as in the current study, they also varied instructions (human- or computer-generated). For the main effect of instructions (human > computer), and similar to the present study, Stanley and co-workers reported greater engagement of brain regions associated with mentalizing. Consistent with Stanley and co-workers' interpretation of this finding [ ], we propose that based on believing that an agent is more human in nature, greater demands are placed on extracting relevant cues to support and evaluate this belief, changing the observer's perception of the social scene. In other words, it seems plausible that visual inputs are matched against a human template more in the human- than computer-belief condition. This process engages theory of mind and person perception in combination. This interpretation, however, remains speculative at this stage and will require further research to test it thoroughly. 


### Revisiting stimulus cues to human animacy and the action observation network's role in social perception 
  
In contrast to a number of previous studies [ , , , ], we failed to find behavioural or brain-based evidence that stimulus cues to human animacy enhance action perception relative to non-human stimulus cues. Instead, we contribute further support, which survives correction for multiple comparisons, to a growing body of evidence that suggests that non-human stimulus cues can lead to the same or even an enhanced engagement of high- and low-level visual areas and the AON [ , – ]. Specifically, we add to the evidence that social brain circuits including the AON are frequently indifferent to stimulus cues to human animacy. 

Although visually salient differences between the human and robot avatar are apparent, the AON did not respond to this difference in the present study. An exploratory analysis of each stimulus form compared independently to an implicit baseline revealed that observing the human or robot agent in isolation resulted in widespread, robust engagement of bilateral AON, fusiform and occipitotemporal brain regions. The results of these simple contrasts help to rule out the possibility that the lack of findings in the human > robot contrast are due to a peculiarity of the human stimuli not engaging such brain networks on their own. The present findings could possibly be due to the fact that both agents executed the identical goal-directed actions (cf. [ , ]) or because the robot and human forms shared some features (i.e. a head atop a torso with two arms). Even though the human and robot forms were generated with the same CGI package, one potential reason the AON might have failed to discriminate between the agents might be because the human form was slightly less human than a video of a real person would be. Another possibility for why we found greater engagement of brain regions associated with person perception when observing a robot compared to a human could be that these brain regions are engaged to assimilate the robotic agent with a more familiar and predictable human template. A similar idea was discussed by Cross   et al  . [ ] in light of finding more robust AON engagement when observing robotic compared to human-like actions. Recent work [ ] lends tentative support to the idea that greater engagement of occipitotemporal brain regions when observing unfamiliar visual stimuli (such as the robotic actions in [ ] and the robotic agents in the current study) might indeed be due to differences in predictability, as outlined by a predictive coding model of action perception [ ]. 

Regardless of the reason for the absence of a difference in AON engagement observed between human and non-human stimulus cues in our study, the current findings suggest that the importance of a human-like form to social perception may have been overstated. Other factors such as top-down beliefs [ , ] and bottom-up kinematic information [ ] also shape social cognition when perceiving and interacting with others [ , ]. Our data help to redress the balance of how much weight the AON assigns to self–other similarities on a form-based, visual level. Future research investigating perception of human animacy may explore which social brain mechanisms are specifically tuned to respond to the extent to which a stimulus is perceived as being ‘like me’, and what other complementary mechanisms might be at play [ , ]. Returning to the ‘like-me’ account of social cognition, the current findings contribute to this view by demonstrating that social brain circuits may be tuned to detect human animacy based on knowledge cues that signal an agent to be ‘like me’. 

While we fail to find behavioural or imaging evidence demonstrating that visual cues to humanness influence social perception, it should be noted that exploratory further analysis of the human > robot form contrast (evaluated at   p   < 0.01,   k   = 10 voxels) revealed activity within the right temporoparietal junction, centred on coordinates   x   = 51,   y   = −37,   z   = 27. While this finding provides weak evidence that brain structures implicated in social cognition [ ] might indeed be more engaged when observing human compared to robotic agents, we are reluctant to interpret this finding further due to the lack of statistical strength. The clearer message to emerge from the main effects of the present study is that top-down belief cues to human animacy shape social perception to a stronger degree than bottom-up visual form cues to human animacy, with stimuli paired with human beliefs associated with engagement of brain regions implicated in person perception and theory of mind. 


### Interactions between stimulus and knowledge cues to human animacy 
  
The design of the present study enabled us to address how stimulus and knowledge cues to human animacy interact during action perception. Findings from the contrast comparing congruent with incongruent pairings of stimulus and knowledge cues failed to show modulation of the action observation, person perception or mentalizing networks. Instead, we report engagement of three uncorrected clusters spanning the middle and posterior cingulate cortex. However, as this finding was not predicted, we are reluctant to interpret it further. The result from the incongruent pairings interaction revealed an uncorrected cluster within the right inferior frontal gyrus located in a similar coordinate space to recent meta-analyses of the AON [ , ]. One simple interpretation of this finding, consistent with a rich literature on executive control, is that viewing incongruent pairings of agent form and humanness belief requires greater attentional control than when pairings are congruent [ ]. Alternatively, it is possible that increased engagement of this sensorimotor brain region when viewing incongruent stimulus and knowledge pairings relates to increased demands on motor simulation mechanisms to reconcile human and artificial features of an observed agent. In order to evaluate this necessarily speculative interpretation, further research is required to replicate and more fully delineate how stimulus and knowledge cues to human animacy interact. If we take a step back and attempt to construct a broader view of how the current study's findings fit in to the wider literature on the biological substrates of social perception and social cognition, given that some findings do support the ‘like-me’ hypothesis [ – ], while others do not [ – ], and the fact that not all reported results survive correction for multiple comparisons, replication of these findings will be important for future progress towards understanding how we perceive animacy in other agents. 


### Multiple routes to socialness and considerations for social artificial agent design 
  
The theoretical implications of the current study and research reviewed in this paper extend beyond the laboratory and serve to inform disciplines in addition to social cognition and neuroscience, including robotics. Over the past decade, individuals working to develop socially interactive artificial agents, including robots and avatars, are taking an increased interest in social cognition and social neuroscience research that examines the impact of ‘like-me’-ness on how we perceive and interact with such agents [ – ]. An ongoing goal for robotics designers has been to maximize the similarity of artificial agents to humans, in terms of appearance and movement (while perhaps attempting to circumnavigate the uncanny valley), in an attempt to make particular artificial agents as ‘like me’ as possible [ ]. However, findings from the current study and considerations raised by related work suggest that how an agent is perceived as being ‘like me’ can take many forms and is not only dictated by how convincingly a robot looks or moves like a human. Pre-conceived beliefs about robots will impact their reception in the workplace, schools, care homes and other social settings, and will undeniably shape how effective human–robot interactions will be. Thus, human knowledge about and attitudes towards robots will need to be optimized as much as a robot's physical form and motion parameters. As such, roboticists and computer animators stand to benefit from further dialogue and collaboration with researchers investigating mechanisms of social perception and their consequences for social interaction. 



## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-22'>
<h2>22. PMID: 25671708</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Simulating Fiction: Individual Differences in Literature Comprehension Revealed with fMRI</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2015</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0116492</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Study used fMRI in healthy adult participants (n=18, ages 18–27) and included an explicit social cognition (mentalizing/Theory-of-Mind) localizer task (false belief > false photograph) performed in the scanner. Whole-brain group analyses were conducted and reported (cluster-corrected p<0.05), in addition to ROI analyses, so results are not limited to ROIs. Participants were healthy with no psychiatric/neurological disorders. Therefore the study meets inclusion criteria: fMRI during a social-related task in healthy adults with whole-brain results.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
When we read literary fiction, we are transported to fictional places, and we feel and think along with the characters. Despite the importance of narrative in adult life and during development, the neurocognitive mechanisms underlying fiction comprehension are unclear. We used functional magnetic resonance imaging (fMRI) to investigate how individuals differently employ neural networks important for understanding others’ beliefs and intentions (mentalizing), and for sensori-motor simulation while listening to excerpts from literary novels. Localizer tasks were used to localize both the cortical motor network and the mentalizing network in participants after they listened to excerpts from literary novels. Results show that participants who had high activation in anterior medial prefrontal cortex (aMPFC; part of the mentalizing network) when listening to mentalizing content of literary fiction, had lower motor cortex activity when they listened to action-related content of the story, and vice versa. This qualifies how people differ in their engagement with fiction: some people are mostly drawn into a story by mentalizing about the thoughts and beliefs of others, whereas others engage in literature by simulating more concrete events such as actions. This study provides on-line neural evidence for the existence of qualitatively different styles of moving into literary worlds, and adds to a growing body of literature showing the potential to study narrative comprehension with neuroimaging methods. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (36222 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Narratives play an important role in human life, and it is more and more acknowledged that fiction is a powerful player in human development as well as in adulthood (e.g. [ , , ]). Despite its importance, it is largely unknown what the brain networks are that support our unique ability to move into a fiction world. While it is uncontroversial that people   are   moved into fiction worlds [ , ], it is unclear   how   readers do this. People differ greatly in how they engage in fiction (e.g. [ , – ]), but the neurocognitive mechanisms behind narrative engagement remain unclear (see [ ] for related work on theatre). Here we use neuroimaging to investigate individual differences during the comprehension of literary fiction stories. 

One way in which participants engage with stories, is via simulation of the story’s content. Recent philosophical and neuroscientific evidence shows that it is important to distinguish at least two neurocognitively distinct components of simulation when considering the understanding of narratives (e.g. [ ]). First,   sensori-motor simulation   is evidenced by activation of motor and visual cortices when people comprehend language related to actions and scenery [ – ]. The second component relates to our ability to understand thoughts, intentions and beliefs of others, sometimes called   mentalizing   [ ]. The distinction between these two components important for fiction understanding is theoretically motivated (e.g. [ ]), and supported by neural findings (e.g. [ , ]). 

In this study participants listened to excerpts (4 to 8 minutes long) from literary novels, while neural activity was measured across the whole brain by means of fMRI. We chose to use listening rather than word-by-word reading, because relatively long fragments are used and therefore listening is expected to be the most convenient option for participants in the scanner. Supposedly, this would not result in crucial differences in terms of the mental simulation they employ. Previous studies did find differences in brain activity between listening and reading (with more individual differences in activity for reading), but also several core regions shared between modalities [ ]. More importantly for the purposes of the present study, it has been shown that regions involved in mentalizing [ ] and action understanding [ ] are activated independent of presentation modality. It is an open question whether mentalizing differs during reading or listening to narratives, but based on the previous literature we expect the two modalities to engage overlapping neural correlates. 

Stories were tagged for motor (‘action’) and mentalizing content, and memory for the stories was debriefed afterwards. Brain regions known to be involved in the two kinds of simulation were localized with standardized localizer tasks. Target regions were left and right motor regions for sensori-motor simulation [ ], and anterior medial prefrontal cortex (amPFC), right temporoparietal junction (rTPJ) and precuneus for mentalizing [ , ] (see   section). Importantly, measurement of brain activity during story comprehension was done on-line, and without additional tasks for the listener. 

Some recent neuroimaging studies relate to the issue of mentalizing and sensori-motor simulation during the comprehension of narratives. For instance, Wallentin and colleagues showed that part of the visual cortex which is sensitive to perceiving visual motion, is also activated when participants heard pieces describing movement in a retelling of ‘The Ugly Duckling’ [ ]. Similarly, Speer and colleagues showed that parts of short children’s stories containing action descriptions activated the motor cortex [ ]. In an interesting recent approach, Altmann and colleagues presented short stories (around 40 words per story) to participants. Stories were either labeled as fact (describing an event that actually took place) or as fiction. Most interesting for the current approach was that stories that were labeled as fiction led to stronger activation in medial prefrontal cortex (among other regions), whereas labeling stories as describing actual facts led to higher activation levels in the premotor cortex (again, amongst other regions) ([ ]; see also [ , ]). 

In this study we follow up on this previous work by using more extended (i.e. longer) excerpts from literary fiction, written for adults, in order to give participants an experience of engaging with fiction that is relatively close to their real-world experience. We have a special focus on individual differences in simulation and mentalizing during narrative comprehension. Previous work has found that participants differ in how much they engage parts of the mentalizing system during the reading of texts labeled as fiction [ ], as well as that participants differ in how much they engage in sensori-motor simulation during language comprehension [ , ]. Here we combine these two to see how participants differ in their engagement of these two important subprocesses of narrative comprehension while listening to natural, unmodified literary fiction. 


## Materials and Methods 
  
### Participants 
  
Eighteen healthy, naïve native speakers of Dutch without psychiatric or neurological problems, and with normal or corrected-to-normal vision and no hearing problems took part in the experiment. Four participants were male, fourteen female. The average age was 22.2 years (range 18–27). Data for the ‘Theory-of-Mind localizer’ of one participant showed artifacts (Nyquist ghosting) and were therefore removed. Written informed consent was obtained prior to the study, and ethical approval was obtained from the local ethics committee (CMO Committee on Research Involving Human Subjects, Arnhem-Nijmegen, The Netherlands, protocol number 2001/095), in line with the Declaration of Helsinki. Participants were paid either in money or in course credit at the end of the study. 


### Story stimuli 
  
Sound recordings of three literary stories were selected from the Corpus of Spoken Dutch (‘Corpus Gesproken Nederlands’, [ ]). Recordings were spoken at a normal rate, in a quiet room by female speakers (one speaker per story). The fragments were taken from literary novels, and all contained descriptions of actions, characters, scenery, and plot and character development. Duration of the fragments was 3:49, 7:50, or 7:48 minutes, and the number of words was 622, 1291, and 1131 words per story. In order to create an experimental baseline condition, reversed speech versions of the story fragments were created (using Audacity 2.03,   http://audacity.sourceforge.net  ). 

The story fragments were annotated for Action and for Mentalizing content over the course of the story. Quantification of the content at specific time points in the story was done with PRAAT [ ], and consisted of assigning sentence parts which contained Action descriptions or Mentalizing descriptions to either category. A sentence part was coded as Action if it contained action of a person or an object. A sentence part was coded as Mentalizing if a character’s mental states (emotions, desires, intentions and/or beliefs) were described, as well as when a character was described in terms of his or her personality ( ). Sentence parts were predefined in the corpus, and never contained more than one main verb. Taken together, the Mentalizing sentence parts made up 22.9% of the total story durations, and the Action sentence parts 25.6%. A sentence part could contain more than one kind of description: the two descriptors had 11.1% overlap. Mean duration of the Mentalizing events (sentence parts) was 1.58 seconds (s.d. 0.76 sec.), and 1.75 seconds for Action events (s.d. 0.70 sec.). In total there were 252 Mentalizing events, and 225 Action events. 
   Example of stimulus scoring.        

### Procedure 
  
 Main task  . The main task was always carried out first. Participants were auditorily presented with the three story fragments while they were lying in the MRI scanner. Intermixed with the stories, the three reversed speech versions of the stories were played. There was no additional task but to listen to the materials carefully and attentively. There was a short break after each fragment. The stories were presented in counterbalanced order across participants, with the reversed speech version always being played either before or after the specific story it was created from. 

 Localizers for regions of interest  . After presentation of the stories, localizer scans were taken to define regions of interest (ROIs) that were hypothesized to be active during either motor simulation or during mentalizing. ROIs for motor simulation were defined by having participants carry out a localizer task for action execution. Simple hand action was required (opening and closing of the fingers of both hands)—a fast method that has proven to reliably elicit the motor cortex in studies of action language comprehension [ , ]. Each trial started with a fixation cross presented for 1 s, followed by one of the words HANDS or REST for 10 s in white text on a black screen. Participants were required to continuously open and close their hands (Hand blocks), or to not move (Rest blocks). There were six of these trials per condition. The trials were presented in a pseudorandom order so that a specific condition was not presented more than twice subsequently. 

The task that was used to define mentalizing ROIs was based on an existing Theory-of-Mind localizer [ ]. Here, the version designed by Dodell-Feder, Koster-Hale, Bedny and Saxe was used, in a Dutch translation [ , ]. The task consists of a ‘false belief story’ task that activates regions that are known to be specifically activated when thinking about other persons’ beliefs and intentions. Followed by an initial instruction screen that stayed up until button press, participants read 20 short stories, divided in two blocks of ten. Each trial started with a fixation cross that was presented for a time interval randomly jittered between 4 and 8 s, in steps of 250 ms (intertrial interval). Then a story of two or three sentences was presented in white text on a black screen for 10 s. Each story was followed by a single-sentence statement that could be true or false. This statement stayed on the screen for 5 s, and within this time participants had to make a left button press for true, right for false statements. Half of the stories belonged to a   false photograph   (non-Mentalizing), half to a   false belief   (Mentalizing) condition: regions were defined on the basis of this contrast. That is, they reflected where activity was greater for the false belief condition than for the false photograph condition. The stories were presented in pseudorandom order, so that the same condition was never presented more than two times in a row. 

On the basis of the two localizer tasks, regions of interest were created. This was done for the action localizer, by taking significant clusters from the ‘hands > rest’ contrast, using a statistical threshold of p<0.05 Family Wise Error-corrected at the voxel level. For the Mentalizing localizer, the contrast ‘false belief > false photograph’ (story plus subsequent test statement together) was used. Results were corrected for multiple comparisons by combining a voxel-wise threshold of p<0.001 with a cluster extent threshold computed using the theory of Gaussian random fields, to arrive at a statistical threshold with a p<0.05 significance level [ ]. The different procedure for statistical thresholding was motivated by the fact that action execution leads to very strong and easily detectable activations, warranting a more conservative thresholding procedure. The mean brain activity in each ROI (technically the mean beta weights per condition) during story comprehension was extracted per regressor (Mentalizing content, Action content) per participant, using the SPM toolbox MarsBaR [ ]. 

 Post-hoc memory test  . Participants, once out of the scanner, got a surprise test to check their memory for each of the stories. Participants were not told about this memory test before the start of the experiment. There were five multiple-choice questions per story fragment, with three possible answers (A, B, C) each. The questions were asking for general content, varying in level of detail (Example: What could be seen at the horizon? A. wind mill, B. watchtower, C. radio mast). Memory scores were summed, providing an overall score of participants’ memory and on-line attention to the story. 


### fMRI data acquisition and preprocessing 
  
Images of blood-oxygen level dependent (BOLD) changes were acquired on a 3T Siemens Magnetom Trio scanner (Erlangen, Germany) with a 32-channel head coil. Pillows and tape were used to minimize participants’ movement, and earphones used for presenting the stories also minimized scanner noise. Functional images were acquired using a fast T2*-weighted 3D EPI sequence [ ], with high temporal resolution (TR: 880 ms, TE: 28 ms, flip angle: 14 degrees, voxel size: 3.5 x 3.5 x 3.5 mm, 36 slices). High resolution (1 x 1 x 1.25 mm) structural (anatomical) images were acquired using an MP-RAGE T1 GRAPPA sequence. 

Preprocessing was performed using the Matlab toolbox SPM8 (  http://www.fil.ion.ucl.ac.uk/spm  ). After removing the first four volumes to control for T1 equilibration, images were motion corrected and registered to the first image. The mean of the motion-corrected images was then coregistered with the individual participants’ anatomical scan. The anatomical and functional scans were spatially normalized to the standard MNI template. Finally, all data were spatially smoothed using an isotropic 8 mm full width at half maximum (FWHM) Gaussian kernel. 


### Stimulus presentation 
  
Stimuli were presented with Presentation software (version 16.2,   http://www.neurobs.com  ). Auditory stimuli were presented through MR-compatible earphones. Presentation of the story fragments was preceded by a volume test: a fragment from another story but with comparable voice and sound quality was presented while the scanner was collecting images. Volume was adjusted to the optimal level based on feedback from the participant. All visual stimuli were projected onto a screen using a projector outside the MR scanner room, which could be seen by participants through a mirror mounted over the head coil. Responses to the Mentalizing localizer task were recorded with two button boxes (left and right hand). The story parts of the experiment required no response (listening only). 


### Data analysis 
  
At the single-subject level, statistical analysis was performed using a general linear model, in which beta weights for each regressor of interest are estimated using multiple regression analysis [ ]. In this model, the two regressors of interest (‘Mentalizing’ descriptions and ‘Action’ descriptions) were modeled as their true durations, convolved with a canonical hemodynamic response function [ ]. The variance inflation factor (VIF) of the two regressors of interest was calculated, to ensure that unique variance could be attributed to each regressor. The VIF of ‘Mentalizing’ and ‘Action’ was 1.22, which is low, and well within the range for assessing multicollinearity, in which values bigger than 10 are problematic [ – ]. The motion estimates of the motion correction algorithm (linear, quadratic and first-derivative regressors for three translations and three rotations) were modeled as regressors of no interest to account for head motion. 

To address the question about individual differences in kinds of simulation, activity for the Action regressor in action ROIs was correlated with activity for the Mentalizing regressor in mentalizing ROIs. The rationale behind this analysis is that if people differ in whether they engage more in one type of simulation compared to the other, we should find that there is a relationship between activity in the mentalizing network during Mentalizing descriptions, and activity in the neural action network during Action descriptions. All correlations were two-sided Pearson’s correlations, and to guard against false positives, all correlation results were corrected for the number of comparisons by changing the critical alpha value using Bonferroni correction. 

As a control analysis, the same correlation analysis was repeated on the data acquired while participants listened to the reversed speech fragments, for which the Mentalizing and Action regressors are meaningless. Naturally, no significant correlations were expected between regions and different regressors in this analysis. A direct comparison between correlation values of the real and reversed speech sessions was done using Steiger’s test [ ]. 

To see if the action ROIs and the mentalizing ROIs were each co-activated during story comprehension, Action regressor activity in each of the action ROIs was correlated with the other action ROIs, and Mentalizing regressor activity in each of the mentalizing ROIs was correlated with the other mentalizing ROIs. We expect the ROIs for each condition to co-activate, in line with previous studies (see e.g. [ ] for action ROIs, and [ , ] for mentalizing ROIs). 

Finally, as another control analysis, activity for the Action regressor in mentalizing ROIs was correlated with activity for the Mentalizing regressor in action ROIs. No relationship between those regressors and ROI activity was expected, and therefore also no significant correlations between the mentalizing and action ROIs. 

Although our main hypothesis concerned the mentalizing and action neural networks, we additionally performed a whole-brain analysis to assess whether there were activations of interest outside of our target networks. Statistical group analysis was performed by directly contrasting one of the sentence part regressors with the other. Participants were treated as a random factor in this analysis (“random effects model”, [ ]). Results were corrected for multiple comparisons by combining a voxel-wise threshold of p<0.001 with a cluster extent threshold computed using the theory of Gaussian random fields to arrive at a statistical threshold of p<0.05 [ ]. 



## Results 
  
### Behavioral 
  
Participants answered on average 9.9 (s.d. 1.11) questions correct of the 15 questions asked in the post-hoc memory questionnaire (multiple choice, three alternatives, 5 questions per story). Participants performed well above chance (p<0.001 for all stories) on the memory test, and there were no differences between the three stories (F(2, 16) = 1.41, p = 0.27; mean story 1: 3.17 (s.d. 1.25), story 2: 3.67 (s.d. 1.09), story 3: 3.11 (s.d. 0.96)). This indicates that participants paid attention to the story content, and that this was equally the case for all three stories. 


### Localizers 
  
The results of the localizer tasks show that the localizers worked well: both revealed activations in sets of areas that were expected based on previous literature (see below). 

 Action localizer  . The action localizer activated the cortical motor system robustly. The ‘hands > rest’ contrast resulted in activations in the precentral and central motor regions bilaterally, as well as in the supplementary motor area (SMA), and in the cerebellum ( ). Since we had no a priori hypothesis about distinctions within the motor system during sensori-motor simulation, and to reduce the number of tests in the correlation analysis, we combined the cortical ROIs into two motor cortex ROIs, one for the left hemisphere, and one for the right hemisphere (MNI coordinates of centre voxel: left -34 -23 56, right 32 -20 58). This means the cerebellum was excluded from further analysis. 
   Results of the localizer scans.  
Whole-brain analysis results for the action localizer scan in yellow (hand action execution versus rest), and for the mentalizing localizer in blue (false belief stories versus false photograph stories [ ]). The action localizer activated the cortical motor system robustly, and the mentalizing localizer led to activations in the previously defined mentalizing (or Theory-of-Mind) network. Areas from the localizers were used in the main analysis as regions of interest. Results are displayed at a statistical threshold level of p<0.05, corrected for multiple comparisons. 
  
 Mentalizing localizer  . The regions of interest defined from the Mentalizing localizer’s ‘false belief > false photograph’ contrast were the medial prefrontal cortex, left and right temporo-parietal junction, left and right middle temporal gyrus, and the precuneus ( ). Given previous research, and in order to restrict the number of statistical tests, we selected, as mentioned above, the mentalizing ROIs from the results that are most commonly reported in previous literature, namely aMPFC (MNI coordinates -3 50 -10, rTPJ 51 -60 25, and precuneus -1 60 37 [ , ]). 


### ROI analysis 
  
Mentalizing regressor activity in the mentalizing ROIs was correlated with Action regressor activity in the action ROIs. A significant negative correlation was found between the action ROIs activation for Action descriptions, and the aMPFC mentalizing ROI activity for Mentalizing descriptions ( ;  ). This shows that participants who engaged the aMPFC when listening to mentalizing content, did engage the cortical motor system less when listening to Action descriptions, and vice versa. Importantly, the same correlations were not observed for the reversed speech data (all p>0.5;  ). A direct comparison using Steiger’s Z-test [ ] of the correlation values showed that correlations between aMPFC and motor regions during the real speech fragments were more negative than during the reversed speech fragments (z = -1.74, p = 0.04). A similarly negative correlation was found between right TPJ activity during mentalizing content and right motor cortex during action content ( ), and although this effect did not reach statistical significance, it is still sizeable (r = -0.40), and importantly in the same direction as the aMPFC-motor cortex correlation. No significant correlation was observed between Mentalizing activation in the precuneus, and Action-related activation of either of the Motor regions ( ). 
   Results of the correlation analysis.  
Scatter plots of activation levels (beta weights) of Mentalizing regions (x-axes) while participants listened to mentalizing content, and activation in Motor regions while participants listened to Action content (y-axes).   A  ) There is a negative correlation between Mentalizing regressor activity in the aMPFC mentalizing ROI (x-axis) and Action regressor activity in the left precentral action ROI (y-axis). This illustrates the individual differences in engaging with fiction, with a gradient going from those who engage exclusively in mentalizing, to participants that engage much more in motor simulation ( ).   B  ) Relationship between Mentalizing activation in right TPJ and Action content activation in right motor cortex. There is a negative relationship, which is sizeable (r = -0.40), but does not reach statistical significance.   C  ) No relationship was observed between Mentalizing activation in the precuneus and Action content in left Motor regions. Activity is expressed as the mean (over voxels in a ROI) of beta weights of a specific regressor in the regression model. The beta weights reflect the fit of BOLD activity with the modeled response to either Action or Mentalizing events. Every dot represents activation from one participant. 
     Correlations between mentalizing and action regions.           Correlations between mentalizing and action regions for the reversed speech control data.           Brain maps illustrating activation clusters for the Mentalizing regressor contrasted against the Action regressor (red) and the Action regressor contrasted against the Mentalizing regressor (blue).  
All activations are corrected for the multiple comparisons at p<0.05. 
  
The mentalizing ROIs were co-activated as is evidenced by the correlations between mentalizing ROIs while participants listened to Mentalizing content ( ). The rTPJ and precuneus showed a significant correlation with each other during mentalizing content. The correlation of aMPFC with the other two regions of the mentalizing network was not statistically significant ( ). It is possible that the aMPFC stands out from the rest of the mentalizing regions (see  ), but we are cautious to draw this conclusion from the present findings since the non-significant correlations of aMPFC with rTPJ and precuneus are still sizeable (r = 0.39 and r = 0.42 respectively), which is in between medium and large effect size in Cohen’s convention [ ]. These numbers cannot be taken as suggesting an absence of correlation. 
   Correlations within sets of co-activated regions.        
The action ROIs (left and right motor regions) correlated significantly with each other while participants listened to Action descriptions ( ). 

As a final control analysis, Mentalizing regressor activity in action ROIs was correlated with Action regressor activity in mentalizing ROIs (‘swapped correlations’), and no significant negative correlations were found, as was expected (all p>0.2). This is extra evidence that the negative correlations displayed in   and  , are specific to the content of the stories driving mentalizing and action regions. 

Activation levels in none of the ROIs were correlated with later memory for the stories, neither for the Mentalizing regressor, nor for the Action regressor (all p>0.12). 


### Whole-brain analysis 
  
Comparing activation for the Mentalizing regressor versus the Action regressor, a cluster in anterior medial prefrontal cortex was found, close to (and partially overlapping) the aMPFC region from the mentalizing localizer ( ;  ). For the Action regressor (versus the Mentalizing regressor), both left and right superior temporal gyrus were significantly activated, as well as the posterior cingulate cortex, extending into BA 7 ( ;  ). Activation levels of these four regions for both regressors compared to baseline are displayed in  . 
   Bar plots showing mean activation levels (‘beta weights’) of each of the regressors (Mentalizing in black, Action in white) against baseline, in each of the regions found in the whole-brain analysis ( ).  
 A  ) left superior temporal gyrus.   B  ) right superior temporal gyrus.   C  ) posterior cingulate cortex.   D  ) anterior medial prefrontal cortex. Error bars represent standard error of the mean (s.e.m.). 
     Results of whole-brain analysis.        


## Discussion 
  
Understanding fiction is more than an enjoyable pastime. Sharing narratives is a key component of human development (e.g. [ , , ]), and there is evidence for the long-held conjecture that engagement with fiction renders people more empathic, presumably because of its enhancement of Theory-of-Mind abilities in the short and long term [ , , ]. Another pointer towards the importance of fiction is that storytelling occurs in all cultures, and has existed throughout large part of human history [ ]. Here we used fMRI to measure individual differences in narrative engagement on-line, measuring neural activation while people listened to excerpts from literary stories. 

We show that participants employ mentalizing and motor simulation differently during fiction comprehension. There was a negative correlation between the activation in part of the cortical mentalizing network (anterior medial prefrontal cortex, aMPFC) for Mentalizing content in the story, and activation in the cortical motor network when participants listened to content related to Action. This suggests that there is a gradient among people in the way they engage with a narrative. Some rely mostly on mentalizing, others rely more on (sensori)-motor simulation, and yet others rely on both. This research gives more insight into individual differences in ways of engaging with fiction, by showing that there is no bimodal distribution with ‘simulators’ versus ‘non-simulators’, but that most readers rely on a specific type of simulation more than others. Some people are moved into a fiction story by mainly focusing on the thoughts and beliefs of others, whereas others pay more (implicit) attention to more concrete events such as action descriptions. 

These findings add to recent insights about the two complementary systems for understanding actions and goals. A meta-analysis showed that the mirroring system (anterior intraparietal sulcus and premotor cortex) and the mentalizing system (TPJ, mPFC, and precuneus) play complementary roles, depending on how abstract the presented actions and/or goals are [ ]. Another recent study, found that when participants were told to focus on the motive behind an action, the mentalizing system became active, whereas the mirroring system was activated when they focused on the implementation of an action [ ]. 

Here, we observed this distinction between the two networks on the individual difference level, and within the broader scope of not just understanding actions and goals, but entire fictional stories. Apparently, when participants are explicitly told to use either kind of simulation, they will, but without instructions individual differences will play a larger role. Clearly, the fact that participants differed in their reliance on mentalizing or motor simulation during fiction comprehension does not mean that some are   incapable   of mentalizing or engaging in motor simulation. For instance, we did observe robust group-level activations to the Theory-of-Mind localizer task. The individual differences during narrative comprehension rather reflect an implicit preference, showing what participants do when processing fiction without additional task constraints. 

It should be noted that the correlation we observed between Mentalizing and Action networks, only holds for one of the Mentalizing regions, namely the anterior medial prefrontal cortex. It is tempting to conclude that this region plays a privileged role during fiction comprehension, in comparison to the other parts of the mentalizing network (right TPJ and precuneus in the present study). Van Overwalle and Vandekerckhove [ ] suggest that aMPFC and TPJ each fulfill specific roles during mentalizing. Anterior MPFC is thought to be activated by descriptions of stable characteristics and enduring traits, TPJ by more temporary intentions and beliefs [ ]. Indeed, a large part of the mentalizing descriptions in our story materials consisted of personality trait descriptions. While it is possible that aMPFC shows up in our analysis for this reason, we are cautious with drawing strong conclusions on the respective roles of aMPFC and rTPJ / precuneus in the mentalizing network. The correlation values between right TPJ and precuneus and the motor cortex were still sizeable, and the correlations between the mentalizing regions (aMPFC, right TPJ, and precuneus) were all sizeable. Moreover, there is evidence from connectivity analyses that anterior MPFC and right TPJ are strongly connected [ , ]. Finally it is important to note that by characterizing the stimuli a priori (i.e., tagging the stories for action and mentalizing content) and by selecting relevant action and mentalizing ROIs based on functional localizers, the interpretation of the results does not rely strongly on reverse inference of the type that has been criticized before [ , ]. 

Our results nicely complement previous observations of individual differences in employment of mentalizing or sensori-motor simulation during story comprehension. Altmann and colleagues showed that individual differences in self-reported mentalizing correlate with the coupling of the aMPFC to other mentalizing regions during the reading of short stories labeled as fictional [ ]. Other studies using behavioral measures show that individuals differ in how much they engage in sensori-motor simulation during language comprehension [ , ]. Our finding of individual differences is somewhat at odds with recent neuroimaging studies that found evidence for simulation across the study sample. For instance, Speer and colleagues found that premotor cortex was activated when participants heard action related descriptions, and Wallentin and colleagues showed involvement of visual motion areas when participants listened to descriptions of motion, and activations of the amygdala when participants listened to emotionally laden parts of a narrative [ , , ]. In contrast, we do not observe consistent activations in motor regions with group-level statistics (the regions we find are, in fact, in line with [ ]), but show that there are sizeable individual differences in participants’ sensitivity to action-related parts of the narrative. Note that we did observe activation of the aMPFC at the group level for listening to mentalizing-related parts of the story. One speculative reason for the difference across studies is in the difference in stimulus materials. Speer and colleagues [ ] presented descriptions of activities of a 7 year old child (from ‘One boy’s day’, by Barker and Wright, [ ]), and Wallentin and colleagues [ , ] used a classic fairy tale (‘The ugly duckling’, by H. C. Andersen) as materials. This is in contrast to the pieces of literary fiction, written for an adult audience, that we used here. The descriptions from ‘One boy’s day’ and ‘The ugly duckling’ could either be more concrete in their descriptions to start with, or participants may flexibly adapt to the genre they listen to (e.g. [ ]), leading to a more heterogeneous response in the case of the different genres employed in the present study. The present data do not allow for testing these suggestions, and they should serve as inspiration for future research. 

A final point is that our focus on sensori-motor simulation and mentalizing, two important factors in literary comprehension, is not meant to claim that there are no other ways to engage with fiction (e.g. [ ]). 

A remaining question is how the qualitative experience of fiction differs between people that rely more on the one kind of simulation compared to the other. It is likely that a qualitatively different type of engaging with a narrative leads to a qualitatively different experience of that narrative. We found no relation between memory performance and activation levels in any of the regions of interest, indicating that the difference in reading style that we observed does not lead to a difference in memory for the stories. The memory questions that we asked were however rather general, and perhaps not sensitive enough to pick up on fine-grained differences between participants. Moreover, it was not possible to qualify memory questions as being more indicative of mentalizing or motor simulation. This is in line with the findings by Happé and colleagues who observed different activations in medial prefrontal cortex in autistic as compared to healthy control participants, but did not observe differences in memory for stories [ ]. Future research should investigate how individual differences in engaging with literature influence the phenomenological experience of a given narrative. 

From a more methodological point of view, the present study adds to a recent line of work showing that using neuroimaging to gain more insight into discourse / narrative comprehension is feasible and can give important insights about language comprehension at the level of narrative (e.g. [ , , – ]). 

In sum we provide on-line neural evidence for the existence of qualitatively different styles of engaging with fiction. Participants could be placed on a continuum of how much they relied on mentalizing or motor simulation while listening to literary fiction stories. People differ in how they are moved into a fiction world, and the current study qualifies part of how this is the case. Future work should be geared towards understanding what the consequences of these individual differences are for the understanding and appreciation of literature. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-23'>
<h2>23. PMID: 22003388</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Predicting Decisions in Human Social Interactions Using Real-Time fMRI and Pattern Classification</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2011</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0025304</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Meets all inclusion criteria: Participants were healthy adult humans (male, ages 23–28). The task is socially related (ultimatum game) performed during fMRI acquisition with real-time and offline analyses. The paper reports whole-brain analyses and results (offline whole-brain SVM classification, discriminating volumes and listed informative brain areas across the whole brain), not only ROI findings. No psychiatric or neurological patient groups are included. Therefore the study addresses social processing in healthy adults using whole-brain fMRI and should be included in the review.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Negotiation and trade typically require a mutual interaction while simultaneously resting in uncertainty which decision the partner ultimately will make at the end of the process. Assessing already during the negotiation in which direction one's counterpart tends would provide a tremendous advantage. Recently, neuroimaging techniques combined with multivariate pattern classification of the acquired data have made it possible to discriminate subjective states of mind on the basis of their neuronal activation signature. However, to enable an online-assessment of the participant's mind state both approaches need to be extended to a real-time technique. By combining real-time functional magnetic resonance imaging (fMRI) and online pattern classification techniques, we show that it is possible to predict human behavior during social interaction   before   the interacting partner communicates a specific decision. Average accuracy reached approximately 70% when we predicted online the decisions of volunteers playing the ultimatum game, a well-known paradigm in economic game theory. Our results demonstrate the successful online analysis of complex emotional and cognitive states using real-time fMRI, which will enable a major breakthrough for social fMRI by providing information about mental states of partners already during the mutual interaction. Interestingly, an additional whole brain classification across subjects confirmed the online results: anterior insula, ventral striatum, and lateral orbitofrontal cortex, known to act in emotional self-regulation and reward processing for adjustment of behavior, appeared to be strong determinants of later overt behavior in the ultimatum game. Using whole brain classification we were also able to discriminate between brain processes related to subjective emotional and motivational states and brain processes related to the evaluation of objective financial incentives. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (44181 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Neuroscientific studies of the brain mechanisms of social decision-making offer new insight which helps to incorporate human behavior into economic models. In the framework of neuroeconomics, cognitive and neural constraints of the complex processes of social decision-making are explored  – . Experimental paradigms from game theory are well suited to the investigation of neural correlates of decision-making, because profound empirical insight into human behavior is provided  ,  . 

Using a real-time noninvasive technique based on fMRI, we investigated the neural correlates of social decision-making and tried to already infer the decisions made by participants involved in social interaction from brain activation during scanning. We employed a well-established economic game called the ultimatum game (UG), in which two players split a given amount of money. One player acts as the proposer, retaining one share of the money and offering the remaining share to the other player (the responder). The responder can either accept or reject the proposer's offer. If the offer is accepted, the money is split as proposed. If the offer is rejected, neither player receives anything. According to the notion of profit maximization, the proposer is expected to offer the smallest possible sum of money and the responder to accept this offer, because even the smallest profit is preferable to no monetary reward  . Contrary to this assumption, it has been repeatedly shown that the results of negotiation in this game do not conform to the expected game-theoretic equilibrium outcomes. Instead, low (unfair) offers of 10–20% of the total sum of money are rejected in more than 50% of cases  ,  , suggesting that emotions, attitudes, and expectations influence players' decisions. 

Social interaction as in the ultimatum game may lead to conflicts between players' goals and internal attitudes and social norms, which elicit emotions. These conflicts require considerable cognitive effort to be resolved  ,  ,  . Consequently, previous fMRI studies on decision-making report the involvement of cortical and subcortical brain regions related to cognitive control, such as prefrontal cortex, anterior cingulate cortex, and regions connected to emotional response such as amygdala and insular cortex (for a review see  ). Decision-making processes in social interaction scenarios have already been examined using functional magnetic resonance imaging (fMRI)  ,  ,  ,  . For example, Sanfey et al. reported activation of anterior cingulate cortex, anterior insula, and dorsolateral prefrontal cortex when presenting unfair offers vs. fair offers in a single-shot version of the UG  . In the single-shot UG, the responder plays just one trial against a single proposer, whereas in the repeated UG, a responder interacts repeatedly with the same proposer. Generally, the behavior in the repeated version of the game is influenced by strategic reasoning and the interaction of the players is more competitive than in the single shot version  . 

However, the statistical analysis used in these studies relies on the comparison of mean blood oxygen level dependent (BOLD) signals calculated from many trials, leaving the question open whether these effects are strong enough to be reliably detected in   single   decisions   before   the decision is revealed by the subject, and without prior knowledge of the actual offer in the trial  . Multivariate classification is well suited to such a “brain-reading” task. Brain states have been decoded from the temporal and spatial patterns in fMRI data  – . The application of pattern classification to fMRI data was done in the fields of fear perception  , visual perception  , goal-related intentions  , or lie detection  . However, in conventional fMRI decoding, these methods are applied offline in the post-experimental analyses. We aimed to predict the decisions before volunteers communicated them and therefore combined the multivariate classification of brain states with real-time fMRI (rtfMRI). This technique allows for online analysis of BOLD activity, for example in the framework of brain computer interfaces  – . To date, real-time multivariate analysis of fMRI data has been conducted in very few studies  – . La Conte et al. and Sitaram et al. combined whole-brain classification and rtfMRI to implement neurofeedback experiments. Posse et al. combined a classifier with neuroanatomically constrained boosting to analyze rtfMRI data recorded during visual stimulation, finger tapping, auditory attention, and mental calculation. In none of these studies were the online data used to continuously retrain the classifiers during the experiment to improve classification performance. 

Here our goal was to discriminate complex brain states occurring in social interactions on the basis of the BOLD signal in a small number of distinct brain regions in real time. Including only few relevant brain areas allowed us to adapt the model parameters of a Relevance Vector Machine (RVM) classifier   during the ongoing experiment to improve online classification performance. In a second offline analysis step, we trained a multivariate pattern classifier on the whole brain across subjects and tested the transfer of the brain activation over subjects. This latter step allowed us to   a posteriori   evaluate if the pre-selected brain areas used in the online approach were adequate. We were also able to investigate hypotheses about the role of brain processes related to subjective emotional and motivational states during decision-making and to distinguish them from brain processes related to the evaluation of an objective financial incentive. 


## Materials and Methods 
  
### Subjects and paradigm 
  
Ten healthy male subjects (23–28 years, mean: 24.7±1.6 years) with normal or corrected to normal vision were examined after providing written informed consent. The experiments were approved by the local ethics committee of the Medical Faculty of the University of Magdeburg. One subject was excluded from the study after reporting doubts about whether he was playing with human partners. Data from two subjects served for the initial training of the classifier that was subsequently used to examine seven subjects. To avoid cross-gender effects, only male volunteers participated in the study  . 

At the beginning of a session, participants met two male individuals, who were introduced to them as the proposers in the UG. Participants were told that the actual proposer would be chosen randomly from these two individuals for each single trial and that proposers do not interact with each other during the experiment. This procedure was chosen because personal contact between responder and proposer is considered to be an essential prerequisite to establishing a social bond between players  ,  ,  . During scanning, the actual offers were made by a computer in a predefined order. This ensured a controllable set of offers. 

Brain activity was measured and analyzed using rtfMRI and real-time pattern classification while each volunteer completed 60 trials of 22 s length each. In each trial the amount to be split was shown for 2 s. Subsequently, the offer was shown to the volunteer for 12s. The BOLD signal of the first 10 s after showing the offer was used to predict the upcoming decision. During the following response phase of 4 s length, participants pressed one of the two buttons to convey their decision. Finally, the payoff in the current trial was presented for 4 s and the next trial started immediately (see   for the trial design). The amount of money to share was 3 euros in every trial and five types of offers were presented at the following rates (percentage of 3 euros share for proposer: responder): 6×50∶50, 8×65∶35, 12×70∶30, 21×80∶20, 13×90∶10. These offers were presented in a random order. As usual in economic bargaining games, reimbursement for the volunteers was determined solely by their earnings in the ultimatum game. During the experiment no cumulative earnings were presented. After the experiment, every participant completed a questionnaire to assess whether he had any doubts about having played with a human partner at any time during the experiment. Also the questionnaire assessed the emotional states during the experiment and the perceived decision behavior concerning timing and fairness. 
   Single trial design in the ultimatum game with cumulative event times.  
 (a)   Each trial started by displaying the amount to be split (3 euros) for 2 s.   (b)   Subsequently, the offer was shown to the volunteer, who then had 12 s to make up his mind. This time was required for BOLD activity to build up and to subsequently use it to predict the upcoming decision. The classification result was indicated to the experimenter 1–2 s   before   the response screen   (c)   was shown to the participant. During the response phase (4 s), participants pressed one of the buttons to convey their decision. After the response, the payoff (split sum as proposed when the offer was accepted or no money for both players when offer was rejected) in the current trial was presented for 4 s   (d)  . The outcome of a rejected offer is shown. 
  
Stimuli were backprojected with an LCD beamer onto a transparent screen. Subjects had to press buttons with their left or right index finger to convey their decisions on the given offers. The mapping between buttons and responses (for either accepting or rejecting) was switched randomly for each trial and displayed at the beginning of each response phase. This prevented the classifiers from using brain activity related to preparation of motor responses  ,  . 


### Imaging protocol and real-time prediction 
  
The blood oxygen level dependent (BOLD) response was measured in a 3 Tesla whole-body MRI scanner equipped with Avanto gradient system (Siemens Medical Systems, Erlangen, Germany). The imaging protocol consisted of a gradient echo EPI sequence for BOLD imaging with repetition time (TR) of 2 s, time to echo (TE) of 29 ms, and a flip angle of 90°. Thirty-one slices with axial slice orientation covering the whole brain were acquired. The matrix size was 64×64 and spatial resolution was 3.4×3.4×4 mm . 

The vendor's EPI BOLD sequence (system version VA25A) and the corresponding image reconstruction programs were modified to export each EPI volume immediately after acquisition and internal motion correction to the host computer of the MR scanner (see   for a scheme of the hardware and the dataflow). All further preprocessing steps, statistical data analysis and classification were performed on an external computer (“External PC” in  , Pentium IV, 3.0 GHz, 2 GB Random Access Memory, Windows XP) which received the preprocessed EPI volumes via a 100 MBit/s network connection. 
   Schema of information flow in the experimental setup.  
The components highlighted in gray depict the vendor-specific measurement system (Siemens Trio with SYNGO Version VA25A). Initially, the original MR data are fourier-transformed and motion-corrected by the vendor image processing unit (Image PC). The reconstructed data are then transferred to the host computer (External PC). There the data are processed using custom software (rtExplorer). This software performs pre-processing, statistics, online classification, and documentation of the classification results. The participants' responses are processed in the stimulus PC and transferred to the external PC for evaluation of the classification and for retraining the classifier during the ongoing session. 
  
The locations of the regions of interest (ROIs) used in the online procedures were pre-specified on the basis of functional MRI data from preliminary experiments including two participants (120 trials) using the same experimental paradigm. The results of a whole-brain offline trained Support Vector Machine (SVM) classifier indicated signal changes predictive of the volunteers' decisions in anterior insula, lateral prefrontal cortex, and occipital cortex (see also  ). The informative brain areas revealed in the pilot study were in concordance with those reported in the literature on social interaction where in particular anterior insula and lateral prefrontal cortex were found to be involved in decision making in the ultimatum game  ,  . Therefore, we selected prefrontal cortex, anterior insula and visual cortex as ROIs for the online classification.   lists the MNI coordinates of the centre points and volumes of these ROIs (also shown in  ). 
   The regions of interest (ROIs) used for online classification projected onto anatomical data of one participant.  
Three distinct brain regions were used for classifying the volunteers' decisions: anterior insula (AI), lateral prefrontal cortex (LPFC) and occipital cortex (OC). See   for MNI coordinates and volumes of the ROIs. 
     Regions of interest used in the real-time classification.        
These preliminary data sets were also used to obtain an initial solution for the model parameters of the real-time classifier used in the online experiment. This allowed us to start prediction without first acquiring an exhaustive set of individual data. Importantly, using only a small set of ROIs reduced the feature space sufficiently allowing us to continuously adapt the classifier in real time by retraining with newly arriving individual data. 

In the online experiments, custom rtfMRI analysis software was used to process the incoming image data as soon as they were acquired  . During online processing, data sets were normalized to 3×3×3 mm  MNI space (Montreal Neurological Institute  ) and detrended to remove linear signal drifts. The BOLD signal of homologous left and right brain areas were pooled. Then the mean BOLD signal in the ROIs during the baseline period (1  and 2  scan immediately following the offer) were compared to the mean BOLD signal during the active period (3  to 5  scan) by calculating one t-value per ROI. Note that we only used data acquired during ten seconds immediately following the presentation of the offer to predict the subject's intended decision in single trials. Thus all data for prediction was acquired before the mapping for the manual decision was revealed. Specifically, we calculated t-values comparing the BOLD response in the first four seconds (scans 1&2) and seconds 6–10 (scans 3&4&5) which were fed into the real-time classification. Because the BOLD response requires approximately five seconds to develop  ,   we can use the data acquired in the first four seconds after the offer was presented as a baseline. The BOLD response to the offer can be expected to be fully developed 6–10 seconds after the offer and the difference between BOLD following the offer and baseline is the trial specific effect of the offer. 

The three t-values per trial served as input for the online classifier, a nonlinear Relevance Vector Machine Classifier   (Software available at   www.miketipping.com/index.php?page=rvm  ), was used to decide on each trial   i   whether an offer would be accepted or rejected. The training set   X   of the classification problem is defined as: 

We refer to   y   as decision vector. Its elements   y   take a value of 1 for an accepted offer and 0 for a rejected offer. 

During the experiment, the initial training set (  X  ) was continuously expanded by including the t-values and decision from the   n  -1th trial into the training data (  X  ) of the   n  th trial: 

The classifier was continuously retrained in each trial using the expanded training set. As such, the system adapted the model parameters based on subject-specific activation states in real time and included these in the forecast of volunteers' future decisions to improve classification accuracy. 

The RVM applied in online prediction makes use of Bayesian inference to obtain sparse solutions for classification. By computing a posterior distribution, it provides probabilistic classification and has the same functional form as the well-known Support Vector Machines:  

Here   w   depicts a weight vector and   is a kernel function that can be used to express a non-linear relationship between   x   and   y  . The goal is to compute the posterior probability of class membership   given the input   x   and target class   y  . This is solved by computing the weight posterior  , where α denotes a hyperparameter. More details are described in  . 


### Offline estimation of the guessing level of the real-time classifier 
  
To test the reliability of the online prediction, we determined individual empirical guessing levels to ensure that the online discrimination rates were not obtained by pure guessing but exploit information inherent to the data. The theoretical guessing level of a two-class experiment (e.g. accept or reject an offer) is 50% (perfect coin toss). However, other factors, such as the relative frequencies of the two classes in the training set, may influence the classifiers' strategy and bias the guessing level to much higher values than expected  . 

We estimated individual empirical guessing levels by permuting the decision vectors in each subject's data set. Permutation destroys the coherence between the observed BOLD data and volunteers' decisions but retains other information such as class size ratio. The classifier was then retrained, and all trials were classified according to the new training set. These steps were repeated 500 times to estimate the mean guessing level and the 95% confidence interval. Empirical guessing levels were calculated as the geometric mean of the guessing levels for the classes accept and reject  . Only if the correct prediction rate of the classifiers in the actual experiment exceeded the 95% confidence interval of the empirical guessing level estimates did we assume that the classifier learned from the inherent structure of the data  . 


### Offline whole brain classification 
  
Additional offline classification was performed to assess classification performance achievable using BOLD data from the whole brain and to further investigate the neural correlates of the decision process. Preprocessing included motion-correction, spatial smoothing with a 9 mm Gaussian kernel, and linear detrending. Furthermore, low-frequency signal fluctuations were removed using a high-pass filter with a cut-off frequency of 0.01 Hz, and BOLD volumes were normalized to 3×3×3 mm  MNI space. Non-brain voxels were excluded by applying a MNI brain template. Before combining the BOLD-data over subjects we first z-scored every subject's data individually. This normalization was done voxel-wise and as a result the BOLD-time series of each voxel had a mean of 0 and a standard deviation of 1. The volumes of the 2 , 3 , and 4  scan after the presentation of the offer were averaged for every subject. This resulted in 420 average functional brain volumes serving as single samples for whole brain classification. Our learning algorithm thus provides a cross-subject model based on single trial data. We then used this to classify the single trial data of the single subject excluded from the classifier training. 

The 2 , 3 , and 4  volumes after offer presentation were chosen because the participants reported in the post-scanning questionnaire that they made their internal decisions quickly (i.e. always in less than 5 seconds) after an offer was revealed and always before the accept/reject screen was shown. We thereby also avoided including information about the actual motor response, because in the interval included the participants did not know the mapping of the two buttons for accepting or rejecting the offer. 

We used feature selection, a very common approach in pattern classification, to reduce the number of features (voxels) in the input space. This was done on a training set by correlating signal changes with the volunteers' two different decisions. Voxels with correlation values between −0.15 to 0.15 were excluded. Since we wanted to analyze which voxels the trained classifier judged as informative we chose this relatively liberal value to somewhat reduce the number of voxels used for classification without being overly restrictive. Approximately 10  voxels were retained for subsequent classification using this criterion. 

For offline classification, we used a publicly available implementation of a SVM  . We used a linear classifier because it allows direct analysis of informative features learned during training  . Generalization performance was tested in a leave-one-average-volume-out cross-validation (LOOCV) which also included feature selection. In LOOCV, one trial is excluded from feature selection and training. The trained classifier is then used to predict the class label of the excluded trial. These steps are repeated for all trials, and the result (the percentage of correct classified decisions) represents a measure of the generalization power of the classifier. The correct prediction rate is finally calculated as: 


### Guessing level of the whole brain classification and discriminating volume 
  
Theoretical and empirical guessing levels were determined analogous to the approach in real-time prediction, in a permutation test with 500 repetitions. 

We extracted the spatial patterns used by the classifier to discriminate between different brain states from the weight vector   w   (Eq. 3). Therefore,   w   was transformed from feature space into the original voxel space and scaled to the length of one. The absolute weight value of each voxel reflects its importance for the discrimination of brain states. To obtain a probability distribution of the weight for each voxel, we permuted the class labels 1000 times. This provides a probability distribution under the null hypothesis of no relationship between class labels and the intrinsic structure of the data  . Based on these distributions, we computed the p-values for each voxel to determine which voxels were significantly predictive for the class label. The threshold for the reported discriminating volumes was set to p<0.05 (uncorrected). 



## Results 
  
### Behavioral analysis and real-time prediction 
  
The percentages of acceptance for the five types of offers are depicted in  . The acceptance/rejection ratios are in accordance with previous studies employing the repeated UG  – . A dramatic drop in the acceptance rate for offers around 20% or less of the amount to be split indicates that these offers were judged as unfair by our participants. 
   Overall percentage of acceptance rates of the offers in the ultimatum game.  
Values are calculated as rate of accepted offers over seven volunteers. Labels on the x-axis show the split rate: (proposer: responder). 
  
As depicted in  , the average online prediction accuracy reached 69.7%±2.4%. The average empirical guessing level derived from permutation tests was 52.3%±2.8% (average 2.5% and 97.5% quantiles were 47.2% and 55.3%, respectively). The real-time prediction accuracy was significantly above guessing level (p<0.0038, binomial distribution). The significant prediction results show that the classifier captured information about rejection or acceptance of an offer which was available in brain activity before the participant revealed his decision. With our approach, we were able to predict the participants' decisions 1–2 s before their response ( ). The online processing algorithm (pre-processing, real-time classification) was executed in less than 0.5 s (time required for retraining of the classifier was 0.4 s on average). 
   Real-time prediction accuracy of the RVM classifier in the ultimatum game.  
The arrows mark the empirical guessing levels. 
  
To assess the gain in correct predictions achieved by continuously retraining the classifier, we simulated the online procedure both with and without retraining. The overall prediction accuracy increased by 10.7% when novel data were used to retrain the classifier showing a clear benefit of retraining with individual data ( ). 
   Improvement of online prediction due to continuous retraining.  
The number of additional correct predictions using individual data acquired during the experiment in a sliding window of six trials are shown. Each window includes 42 single predictions (6 trials times 7 subjects). 
  
In addition to binary classification accuracy, RVM classification provides a continuous posterior probability estimate for each classified decision. The mean probability estimates for the five types of offers are depicted in  . Acceptance of an offer is indicated by a probability exceeding 0.5. 
   Mean posterior probabilities for accepting an offer assigned by the RVM to single offers in the UG.  
Means and standard deviations plotted were calculated over the seven volunteers tested in online analysis. The labels on the x-axis depict the split rate: (proposer: responder). 
  
The analysis of the activation of the signal variation immediately following an offer showed a clear difference between frontal and posterior ROIs. Higher BOLD signal in AI and LPFC predicted rejection, whereas a higher BOLD signal in OC predicted acceptance of an offer ( ). This finding suggests different functional roles during the evaluation of the offer for frontal and posterior sensory areas. 
   Mean fMRI signal differences in the ROIs used in the online UG to predict acceptance vs. rejection for the five types of offers.  
Differences were calculated between 1  to 2  and 3  to 5  scan after the offer and averaged over the seven participants. Bold signal in AI (slope linear fit 0.062, p<0.05) and LPFC (slope linear fit 0.11, p<0.05). In contrast, signal decreases in OC when the likelihood of acceptance decreases (slope linear fit −0.16, p<0.05). 
  

### Offline whole brain classification 
  
In an additional offline analysis, we pooled the single trial fMRI data from all but one subject (leave on subject out) to train classifiers and test generalization among subjects. This improved the correct classification rate greatly to an average of 81.2%. The average guessing level of the offline classification determined in permutation tests was 51.1%±2.3% SD (average 2.5% and 97.5% quantiles were 47.3% and 55.1%, respectively). Again, the correct classification rate clearly exceeds the 95% confidence interval for guessing. This results clearly shows that there is information about rejection or acceptance of a decision in the BOLD data that is similar among participants. Moreover, this analysis allowed us to derive brain areas informative about a participant's decision from a larger set of subjects and to validate the choice of the ROIs in the online experiment.   lists the discriminating volumes extracted from the trained linear SVM (see also  ). Importantly, the brain areas revealed by this analysis include the predefined ROIs used for real-time classification. Both, bilateral LPFC and OC were revealed as informative by the classifier. The only discrepancy was that bilateral AI was used in the online experiment but the offline classifier revealed only right AI as an informative ROI. In addition, offline classification found informative differences consistent over subjects in medial frontal gyrus (MFG), ventromedial prefrontal cortex (vmPFC), ventral striatum (VS), CRUS I in cerebellum, right orbitofrontal cortex (OFC), and posterior superior temporal sulcus (pSTS). 
   Volumes discriminative for decisions in the offline classification.        
The decision process we investigated so far includes at least two sub-processes: one related to the evaluation of the offer (e.g. low or high earning) and another related to the choice of the response (reject or accept an offer). We analyzed our data according to choices in the previous offline analysis. However, since choice and offer value are correlated over the full scale of offers it is possible that BOLD activity related to evaluation of offer value is more predictive about the subjects' UG responses than choice related BOLD activity, at least on the full scale of offers. To investigate this hypothesis each trial received two labels: one for the offer (low or high) and one for the choice (accepted or rejected) and we trained two classifiers with trials of the same dataset sorted in the two different ways (choice or value). The datasets used for classifier training have to be balanced with respect to each of the four possible label combinations (low/accept, high/accept, low/reject, and high/reject) to avoid unwanted classifier bias. In order to maximize the number of trials available in the four label combinations we distinguish high from low offers around the categorical decision border between 80∶20 and 70∶30 split rates where acceptance rate sharply drops. We labeled 50∶50, 65∶35, and 70∶30 trials as high offers and 80∶20 and 90∶10 trials as low offers. The combination reject/high offer contained the lowest number of samples (n = 19), restricting the number of trials used in the other three combinations in the training of the classifier. In order to avoid selection bias, we evaluated classifier performance on 200 balanced subsets of 76 samples each of which included the 19 rejected/high offers and 19 samples randomly drawn from each of the other three label combinations. The average LOOCV classification accuracy revealed that it was possible to discriminate high from low offers on the basis of the single trial BOLD activity (65.9% correct ±6.2% SD) with some success. On the contrary, discrimination according to choice (accept/reject) was around chance level (56.4% correct ±5.9% SD). This result indicates that brain processes related to the evaluation of offer value rather than the choice related activation allows the prediction of the subject's response on the wide range of offer values used in the offline prediction. 

Although no systematic brain activation difference related to choice (reject/accept) may exist over a wide range of offer values, this does not rule out, that a strong link between choice and brain activity exists that may manifest in a predictable and restricted regions along the offer scale where a large change in choices (accept/reject) is found. In the following analysis we aim to demonstrate such an isomorphism between brain activity and behavior for choice related activity. The reasoning behind this analysis follows previous work from us and other groups  ,   and is outlined below. We assume that brain activation related to choice should easily discriminate between two adjacent offers if these differ greatly in their acceptance rate and little if they differ little in their acceptance rate. Behaviorally, trials with split rates 50∶50, 65∶35, and 70∶30 trials were mostly accepted and trials with 80∶20 and 90∶10 trials were mostly rejected. Discrimination between trials with different offers within the same category (accepted or rejected) should be low because choice related brain activity should be very similar in trials from the same category. Importantly, choice related brain activity should reproduce the categorical border between acceptance and rejection of offers observed between 70∶30 and 80∶20 split ratios. Consequently, a classifier trained to discriminate between trials either of these two split ratios should produce particularly high discrimination rates because these offers cross the category border between acceptance and rejection. In addition, classifiers trained on adjacent pairs of offers from within a category should be less discriminable. 

We tested this prediction by training an SVM in an LOOCV to discriminate between adjacent offers. Therefore, we repeatedly (200 times) selected 42 examples from each split rate. The number of trials used per repetition was limited by the class with the lowest number of examples, in this case the number of trials in the 50∶50 split rate. In concordance with our hypothesis we found the highest discrimination rate between trials from 70∶30 and 80∶20 splits (71.4%±5.53% SD). The single trial discrimination rate was at guessing level for the comparisons among trials between split rates 80∶20 vs. 90∶10 (53.4%±5.3% SD), and 65∶35 vs. 70∶30 (54.6%±4.7% SD), and moderate for the discrimination between split rates 50∶50 vs. 65∶35 (65.9%±5.2% SD). It is important to note that this pattern of results cannot be explained by value differences between offers. The 70∶20 offer differs by 10% (or 0.3 Eurocent) from the 80∶20 offer, the same amount the 80∶20 differs from the 90∶10 and even less than the 65∶35 differs from the 70∶30, and the 50∶50 from the 60∶35 offer ( ). This result indicates that there exists informative brain activity that reflects choice rather than evaluation of the offer value. The discriminative brain areas found at the choice category border 70∶30 vs. 80∶20 are listed in   together with those areas discriminative for offers 50∶50 vs. 65∶35 (see also  ). 
   Discriminating volumes found in the offline classification of offers.        


## Discussion 
  
### Real-time analysis of decision processes 
  
In this study, we show that it is possible to predict the behavior of social agents acting as responders in the UG in real time using BOLD measurements of brain activity to detect complex emotional and cognitive states. Offline analyses confirmed the ROIs selected for online prediction on two pilot subjects and the rejection rates. More detailed analyses of the information about split rate and decision outcome available in the BOLD-data strongly supports the notion that brain activity related to expected subjective value of an offer rather than choice predict the subjects behavior over a large range of offer values. the mere decision process. Importantly, we find that information about choice in the BOLD activity predicts the behaviorally observed categorical change from offer acceptance to rejection. 


### BOLD modulation related to emotional and regulatory processes predicts imminent behavior in the UG 
  
We found that AI and LPFC are both predictive of the rejection of an offer on a trial-by-trial basis, in the online as well as in the offline analysis. Both brain areas are involved in emotion regulation and adjustment during social interaction  ,  –  as well as in the evaluation of negative emotions such as disgust  ,  . Increasing activation in AI and LPFC may reflect the experienced level of unfairness which in turn leads to the rejection of the offer in a given trial. In accordance with this interpretation, AI was found to be informative about split level when comparing 70∶30 splits to 80∶20 splits ( ) but not when comparing 50∶50 splits to 65∶35 splits. Moreover, this finding is in concordance with Sanfey et al.  , who also found that higher BOLD activation in AI indicated the rejection of an offer. A competing hypothesis is that activation in AI is not directly connected to the evaluation of negative emotional content but rather refers to attentional processes as reaction to salient environmental stimuli. As part of the ventral attention system the AI is thought to support the reorientation of the attention focus to external stimuli  . In this context it was suggested that activation of the ventral attention system may be connected to switching “internally directed” activities to behaviorally salient external stimuli, also in social cognition  . 

As opposed to AI and LPFC, activation in early visual cortex decreased with unfavorable split rates. It has been shown that attention strongly influences the responses of cortical neurons  ,  . Different levels of attention elicited by offers with different split rates, i.e. a fair offer may induce stronger attention because it reflects fair behavior and higher monetary outcome, may result in different activation in early visual cortex. However, one could also argue that the behavioral relevance is comparable for high and low offers in the UG and thus should lead to comparable attentional effects. The role of attention-related activation in encoding of decision behavior in the presented social context is not fully explored and may be subject to further investigation. 

In sum, the results from the online experiment suggest that activation in brain areas reflecting the subject's emotional and motivational state and self-regulatory processes can be used to discriminate accepted from rejected offers. 


### Reward-related brain areas predictive of altruistic punishment and financial incentive 
  
When playing against a computer that is creating offers in a random order, it makes no sense to reject an offer from an economic perspective. Thus, the participants' best strategy to optimize monetary gain would have been to accept any offer. However, responders in our study rejected unfair offers (20% of 3 euros and less) significantly more often than fair offers. This is the behavior expected in the repeated version of the UG ( ) with two humans playing, and corroborates the participants' reports that they thought they were playing with a human. In such a social setting of reciprocal cooperation, altruistic punishment, sacrificing potential monetary gain, can serve to optimize gains in the long run. 

Thus, in the ultimatum game the acceptance of an offer is correlated with the expectation of a financial incentive but, in addition, hedonic states following costly punishment of an unfair offer may also contribute to adjustment of behavior  ,  . We hypothesized that processing of the financial incentive and altruistic punishment is likely to involve different brain circuits although the same behavioral result, the acceptance or rejection of an offer, is observed  ,  . We probed this hypothesis by comparing the discrimination power of brain activity according to financial incentive vs. discrimination power tracking a categorical change from acceptance to rejection signifying altruistic punishment. We found that BOLD activation in VS signified the categorical border and discriminated between offers with a 70∶30 split rate vs. 80∶20 split rate but not between 50∶50 and 65∶35 offers (  and  ). The first pair differs with respect to the number of accepted offers, whereas the number of accepted offers is approximately equal and the difference in financial incentive is even higher in the second pair. This implies that, in our social setting, activation in VS, an important component of the reward network, is linked to hedonic states following punishment of unfair offers rather than financial incentive. OFC, another informative brain area of the reward circuit, provides similar information. Interestingly, OFC has previously been linked to the evaluation of threatening and/or punishing stimuli that may lead to the adjustment of behavior  ,  . In contrast, ventral medial prefrontal cortices discriminate accepted from rejected offers when all split rates are included ( ) but they do not discriminate 70∶30 from 80∶20 split rate trials ( ) where the categorical transition between accepted and rejected offers occurred. This suggests that, in contrast to VS and OFC, activation in ventral medial prefrontal cortices is related to the evaluation of monetary gain rather than hedonic states following punishment of unfair offers. This is in agreement with results from previous studies linking ventral medial prefrontal cortices to evaluation of primary as well as secondary rewards like monetary gain  . Thus, the result of the offline analysis adds further support to the conclusions that activation in brain areas reflecting the subject's emotional and motivational state and the self-regulatory processes thereof can be used to discriminate accepted from rejected offers in the social UG. 


### Cross subject ROI based probabilistic classification 
  
Unlike other offline “mind reading” approaches (compare e.g.  ,  ), we used a cross-subject approach in the online analysis. Nevertheless, the high prediction rate of 69.7% in the cross-subject procedure confirms the good generalization of the classifier between subjects. This indicates the identification of neural mechanisms that are common between our volunteers. The advantage of this approach is that it allows training of the RVM classifier prior to measurement, simplifying the setup by providing an initial solution of the classification problem without acquisition of additional training trials. Our approach made it possible to predict the subject's choice from the first experimental trial on, although this was with reduced accuracy. Importantly, continuous retraining during the course of the experiment increased classification performance by approximately 11% on average. 

Moreover, RVM provides posterior probabilities for single trial class membership, which can be useful in classification-based neurofeedback (compare  ,  ). Subject-specific offline classification resulted in 81.2% average accuracy and was, as expected, superior to cross-subject online prediction performance. This increase might be partly due to including subject-specific anatomical information but also to the high dimensional feature space we used in offline training. Thus, we would expect improvements in online classification using a more elaborate training scheme that combines non-subject-specific ROI-based classifiers with subject-specific whole-brain classifiers. During an experiment, the classification result would be calculated as a weighted average of the two classification approaches with weights adjusted by the quantity of information available for online classifier retraining. Fast implementations of procedures for preprocessing and training of whole-brain fMRI data are necessary for this approach. 


### Implications of single trial online prediction of social decision-making 
  
Whether a responder in the UG finally decides to reject or accept a specific offer depends on a multitude of internal factors. Among these factors are emotions such as the feeling of being treated fairly as well as rational considerations of reward maximization. The extraction of this information about the way a social agent is tending with a decision in real time   before   the decision was actually revealed can have extensive consequences for negotiations and other social interactions. However, the framework presented here for online decision prediction can also be used to study the link between neuronal and behavioral aspects of human decision-making In future studies, this framework could be used to investigate how decision-making processes are influenced by additional information about the emotional or cognitive state of a communication partner in an “augmented communication” scenario which feeds back information about current hidden brain states of the partner. Our approach could significantly extend previous work on effects of overt social cues in social interaction  ,  , or emotional facial expressions of social agents in bargaining games  . 


### Conclusion 
  
In sum, our results show that, in single trials, it is possible to reliably predict acceptance or rejection of an offer from BOLD measurements of brain activity before the subject reveals the decision with an overt response. However, more detailed analyses indicated that prediction of the decision was based on brain processes related to the perception and evaluation of the offer rather than processes related to the decision itself. Importantly, AI, VS, and LOFC, brain areas related to emotional self-regulation and reward processing for adjustment of behavior, appeared to be strong determinants of overt behavior in the ultimatum game. The decisions derived from the activation in these brain areas paralleled the behaviorally observed categorical transition from high likelihood of acceptance to high likelihood of rejection of an offer when the split rate fell below 70∶30. The framework presented here can be used in future studies to augment information available in social interaction with information about current brain states that remain hidden in traditional approaches. 



## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-24'>
<h2>24. PMID: 31269199</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Social evaluations under conflict: negative judgments of conflicting information are easier than positive judgments</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Soc Cogn Affect Neurosci</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1093/scan/nsz045</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study reports BOLD fMRI data collected while healthy adult participants (N=20; ages 18–29) performed a social judgment task (forced-choice evaluations of target persons in situational contexts). Analyses include whole-brain multilevel modeling and whole-brain results (clusters reported, voxel coordinates, thresholding), with ROI analyses presented additionally but not exclusively. Participants are healthy and within the 18–60 age range. The paper is an original empirical fMRI study (not a review/meta-analysis) and does not report clinical/neurological populations. Therefore it meets all inclusion criteria (fMRI during social task, healthy adults 18–60, whole-brain results) and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
In the current study, we used functional magnetic resonance imaging to investigate how the brain facilitates social judgments despite evaluatively conflicting information. Participants learned consistent (positive or negative) and ambivalent (positive and negative) person information and were then asked to provide binary judgments of these targets in situations that either resolved conflict by prioritizing a subset of information or not. Self-report, decision time and brain data confirm that integrating contextual information into our evaluations of objects or people allows for nuanced (social) evaluations. The same mixed trait information elicited or failed to elicit evaluative conflict dependent on the situation. Crucially, we provide data suggesting that negative judgments are easier and may be considered the ‘default’ action when experiencing evaluative conflict: weaker activation in dorsolateral prefrontal cortex during trials of evaluative conflict was related to a greater likelihood of unfavorable judgments, and greater activation was related to more favorable judgments. Since negative outcome consequences are arguably more detrimental and salient, this finding supports the idea that additional regulation and a more active selection process are necessary to override an initial negative response to evaluatively conflicting information. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (40891 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
Every day we evaluate and interact with others across a range of situations. Because human behavior is complex, it is not uncommon that information we gather about others is marked by ambivalence, for example, when we perceive a person as cold but competent. Often, we are forced to resolve such evaluative conflict toward a favorable (e.g. collaborate with this person) or unfavorable judgment (e.g. do not collaborate). In the current article, we extend existing literature by investigating how the brain facilitates these social decisions by weighing evaluative information in line with affordances of the situation. Importantly, we provide data suggesting that negative judgments can be considered the easier, ‘default’ response when experiencing evaluative conflict. 

Social evaluations are influenced by aspects of the task or situation that provide goals in relation to which a person or object is evaluated. Thereby, situational affordances facilitate flexible, nuanced evaluations ( ;  ). In a recent study, we suggested that situational affordances can resolve evaluative conflict by prioritizing specific information; that is, we may judge someone positively in a specific situation despite knowing that the person also has negative features ( ). For example, we may judge a colleague who is charming and lazy positively when deciding whether to invite him or her to a social event because we prioritize the positive trait (charming) over the more negative one (lazy). Accordingly, affordances of the situation can also fail to resolve conflict if features of opposite valence remain relevant for the current judgment. For example, choosing whether to organize a social event with a friend who is charming and lazy makes both positively (i.e. charming) and negatively evaluated traits (i.e. lazy) important and evaluative conflict remains ( ). These situations of evaluative conflict and specifically how judgments are facilitated despite evaluative conflict are the focus of the current study. 
  
Proposed processing of evaluative information in line with situational affordances. 
  
Cognitive conflict is traditionally studied in paradigms where a more salient, default response interferes with an objectively correct response (e.g. Stroop task and Eriksen Flanker task). Interestingly, there is no objectively correct response when conflict occurs between subjective evaluations, and the default response in these evaluative conflicts is unclear. We suggest that in such cases, negative judgments are the easier, default response based on two theoretical approaches. First, psychologists and neuroscientists have theorized that conflicts generate negative value (Botvinick, 2007; Braem et al., 2017; Dreisbach & Fischer, 2012; Inzlicht et al., 2015; Schouppe et al., 2015). For example, in a facial electromyographic study using a variant of the current impression formation paradigm, participants expressed less positive affect when ambivalent person information remained conflicted in the evaluation situation compared to when ambivalence was resolved (Nohlen et al., 2016). The negative value of conflict has also been suggested to extend to evaluations. Direct evidence comes from a study by Fritz &\Dreisbach (2013), who showed that presenting conflict (incongruent Stroop) primes increases the number of negative judgments of neutral targets (words or Chinese pictographs) that followed these primes. 

Second, some have argued for a greater impact of negative information on evaluations because it arguably outweighs positive information in terms of salience and outcome consequences ( ;  ;  ). For example, animals that are conflicted between approaching and avoiding a predator-infested water source tend to show avoidance behavior ( ). This bias may be due to the fact that ignoring negative information can instill higher costs (e.g. being eaten) than ignoring positive information (e.g. drinking water;  ). Similarly, negative judgments that insinuate avoidance in social situation (e.g. do not collaborate) could represent the ‘safer choice’ by maintaining the status quo when feeling torn between positive and negative evaluations (cf.  ). 

A tendency toward negative social judgments on the basis of conflicting person information can thus be expected because they may be easier due to the negative value of conflict which influences evaluations (e.g. Botvinick, 2007; Fritz & Dreisbach, 2013), and because negative information arguably outweighs positive information in terms of salience and outcome consequences (Gray & McNaughton, 2000; Rozin & Royzman, 2001). 

If negative judgments are the easier response in evaluative conflicts, positive judgments should be more effortful and take more time. Supporting this argument, research has shown that even though ambiguous (i.e. surprised) facial expressions are primarily judged as negative, positive judgments become more likely when participants take more time to evaluate the stimulus ( ;  ;  ). This suggests that overriding an initial negative response to interpret an ambiguous stimulus positively requires additional regulatory processes; we need to invest effort and actively attend to positive information ( ,  ;  ). 

Many models of control and executive functioning focus on the interaction of the anterior cingulate cortex (ACC) and dorsolateral prefrontal cortex (DLPFC) to resolve such complex decision situations ( ;  ;  ). These domain-general regions are also more active in impression formation task when evaluations are updated with information that is inconsistent with prior information ( ;  ). Because of their engagement during many tasks, it has proven difficult to pinpoint the specific role of these regions. Interpretations of dorsal ACC’s (dACC’s) function thus vary from conflict monitoring ( ) and detection (e.g.  ) to violation of expectancies ( ), negative affect and pain ( ) or comparisons of value outcomes, to name a few ( ;  ;  ;  ). Even though there is thus some debate on the specifics of dACC functioning (e.g.  ;  ), it is widely agreed that dACC is engaged when tasks are more difficult and effortful as is, for example, the case when we have to form an integrative judgment from conflicting information ( ). Recently, the Expected Value of Control theory ( ) suggested that dACC has the role of a ‘controller’ that detects and signals an increased need for control through a cost–benefit analysis for optimal control allocation ( ;  ). Important in the current paradigm, these control-eliciting situations are often those in which one behavior, generally referred to as the default response, is suppressed in favor of another behavior that serves current goals better ( ;  ). 

According to this idea, difficult choice situations signaled by the ACC are relayed to the DLPFC, which is critically involved in the implementation of control ( ). Specifically, DLPFC has been associated with biasing processing in line with salient goals, meaning that it is involved in attending to task-relevant information and selecting context-appropriate responses ( ;  ). Supporting this, Hughes   et al.   ( ) found both dACC and DLPFC to play a role in an intergroup social judgments task. A failure to engage these regions was associated with increased ingroup bias in that participants did not adjust their impression of ingroup members to incorporate negative information and stuck to their default (biased) response. Based on the idea that negative judgments are the default response in situations of evaluative conflict, positive judgments should represent a move away from the default response and thus be mediated by greater DLPFC and dACC activation. 

## Present research and hypotheses 
  
The goal of our study was to investigate how the human brain facilitates social judgments when information is conflicting. Two aspects were central. First, we were interested in replicating our previous work showing the flexibility of ambivalent person evaluations with the idea that the same positive and negative person information elicits evaluative conflict in some but not in other situations ( ). Second, we examined the role of dACC and DLPFC in biasing evaluations toward positive or negative judgments when evaluative conflict remains. As far as we know, this is the first study investigating whether blood oxygen level-dependent (BOLD) signal can be related to the valence of social evaluations. 

We used a novel forced-choice task in which participants judged target persons described by consistent (positive or negative) or ambivalent (positive and negative) traits in different situations that either allowed for prioritizing some traits over others (conflict is resolved) or not (conflict remains unresolved; cf.  ). If negative judgments of conflicting information are the default, we should find an interaction effect of the valence of social judgment (positive, negative) and the presence of evaluative conflict on BOLD signal. More specifically, dACC and DLPFC response should be stronger if participants experience evaluative conflict and override the default negative judgment and judge the person positively. Accordingly, weaker dACC and DLPFC activation should be related to negative judgments under evaluative conflict. If conflict does not have a negative value that influences evaluations, brain response to the valence of social judgments should be independent from conflict. 


## Methods 
  
### Participants 
  
Participants were 20 adults (11 male, 9 female) in the age range of 18 to 29 years (  M   = 22.7; s.d., 2.60). Participants provided informed consent, had normal or corrected-to-normal vision, and had no history of neurological problems. Nineteen of 20 participants were right handed. All procedures were approved by the local ethical committee. 


### Design and procedure 
  
#### Target persons 
  
Two to 5 days before scanning, participants received descriptions of four male target persons that consisted of a list of traits and a short text to make the traits more memorable. One target was described by positive traits (friendly, charming, enthusiastic, intelligent), one by negative (dominant, jealous, lazy, dumb), and two by the combination of the two positive and two negative traits each (dominant, jealous, enthusiastic, intelligent; friendly, charming, lazy, dumb). The combinations of names and traits were counterbalanced across participants, and we used a pretest (  N   = 34; Supplementary Material S1) to ensure that the trait combinations were evaluated as positive, negative or ambivalent. Participants memorized the combinations of names and traits before coming to the laboratory and were verbally tested on recall during take-in. If participants were not able to recall the traits and names of the targets, they were given additional time to learn them. Because we did not want differences in knowledge of the name–trait combinations to introduce noise in the data, exposure to the pairs may have varied between participants. Post-relearning, all participants were able to quickly recall the combinations when prompted. 


#### Evaluation situations 
  
The four target persons were evaluated in 21 different situations (cf.  ). All situations were combined with each of the four target persons (84 trials). Based on a pretest (S1), situations were selected that varied in the degree to which they resolved conflict between ambivalent trait information by prioritizing a subset of either positive or negative traits. In the pretest, we used a one-item adaptation of  ) subjective ambivalence scale, which assesses experienced conflict by asking participants to evaluate the degree to which they experienced ‘mixed feelings and/or thoughts’ toward each target person (described by their specific traits) in each of the different evaluation situations on a scale ranging from 0 (not at all) to 100 (very much). Results were used to categorize the combinations of ambivalent target persons and evaluation situations as representing either situationally resolved ambivalent (2 target persons × 10 situations = 20 trials), or unresolved ambivalent judgments (2 target persons × 11 situations = 22 trials), resulting in three critical trial types based on the combination of person traits and evaluation situation ( ). Note that the situation did not have to resolve conflict when targets were described by positive or negative (i.e. consistent) traits; they elicited unconflicted judgments across all situations (2 target persons × 21 situations = 42 trials). Whether situations resolved conflict between ambivalent target information was dependent on the specific target; the same situation could thus be categorized as situationally resolved ambivalent for one target and unresolved for another (Supplementary Material S2 for all stimuli).  Additionally, a manipulation check was added to this study to test whether this categorization was successful (see  ). 
  
(A) Timing sequence of an experimental trial. (B) Example trial of each trial type. 
  


### Social Judgment task 
  
#### Functional magnetic resonance imaging social judgment task 
  
In the scanner, participants indicated their judgment (‘yes,’ ‘no’) to each combination of target person and evaluation situation by pressing one of two buttons with their right index and middle finger. Choice labels were counterbalanced between participants. Participants completed one functional run of 84 randomly presented trials with a 5 s break after every 21 trials. Trials started with a fixation cross (500 ms), and stimuli were presented until participants responded. After the response, participants saw a white dot on a black screen with varying presentation times (min, 4000 ms; max, 6600 ms) before the next trial ( ). Responses were recoded so that yes responses represent positive judgments and no responses represent negative judgments of the person in that situation. 


#### Manipulation checks 
  
##### Before scanning: assessing ambivalence toward target persons 
  
To confirm that information about the target persons was indeed perceived as consistent or conflicted, we assessed experienced ambivalence toward the four target persons with the subjective ambivalence scale ( ). This scale assesses psychological conflict with three items anchored with ‘Toward this person I… have completely one-sided feelings/feel no conflict/feel no indecision’ (0) and ‘have mixed feelings/feel maximum conflict/maximum indecision’ (100). Participants responded on a slider without numeric labels (α = 0.71). Ambivalence was calculated by taking the mean of these questions. 


##### After scanning: assessing ambivalence toward each target person in each situation 
  
To verify that we correctly categorized the combinations of person information and evaluation situation as conflicting or conflict resolved on the basis of pretest data, participants indicated their ambivalence toward each target person in each situation using the same scale ( ; e.g. ‘I have mixed feelings/feel conflict/feel indecision about collaborating with X’). Responses were given on a slider (0–100) without numeric labels (α = 0.93). 




### Magnetic resonance imaging data acquisition 
  
Imaging was conducted with a 3.0-T Philips Achieva scanner at the Spinoza Centre for Neuroimaging in Amsterdam. Head motion was limited by placing foam inserts around the head inside the head coil. Stimuli were presented using E-Prime and projected onto a screen in the magnet bore, which participants could see through a mirror attached to the head coil. Functional data were obtained using T2*-weighted echo-planar imaging in one event-related run (84 trials). The first two dummy scans were removed to allow for equilibration of T1 saturation effects [time repetition (TR), 2 s; time echo (TE), 28 ms; voxel size, 3 × 3 × 3 mm; field of view (FOV), 240^2]. A high-resolution T1-weighted sagittal scan was collected as anatomical reference (TR, 9.56 s; TE, 4.6 s; voxel size, 1.2 × 1.2 × 1.2; FOV, 224^2). 


### Functional magnetic resonance imaging preprocessing 
  
Data were preprocessed using FEAT (FMRI Expert Analysis Tool) Version 6.00, part of FMRIB’s Software Library (FSL,   www.fmrib.ox.ac.uk/fsl  ). Data were corrected for motion using FMRIB’s Linear Image Registration Tool (MCFLIRT; (FSL’s Motion Correction using FMRIB’s Linear Image Registration Tool;  ); the brain was extracted using FSL’s Brain Extraction Tool (BET;  ) and spatially smoothed using a Gaussian kernel (full width at half maximum [FWHM] = 5 mm). The four-dimensional data set was grand-mean intensity normalized by a single multiplicative factor. We applied a high-pass temporal filter (Gaussian-weighted least-squares straight line fitting, with σ = 50 s). Registration to standard space images was carried out using FLIRT ( ;  ). 



## Results 
  
### Behavior analysis 
  
#### Manipulation checks 
  
##### Before scanning: assessing ambivalence toward target persons. 
  
Results on the subjective ambivalence scale confirmed that the combination of traits successfully created unconflicted (consistent) or conflicted evaluations of the target persons independent of evaluation situation. Participants experienced less conflict regarding persons described by positive or negative traits (  M   = 11.03, SE  = 2.24) than toward those described by positive and negative traits [  M   = 40.67, SE  = 3.13;   t  (19) = −8.610,   P   < 0.001,   r   = 0.89]. 


##### During scanning: response behavior 
  
In line with the categorization, target persons described by positive traits were evaluated positively in 416 of 420 trials (99%) independent of evaluation situation, and negatively described targets were evaluated negatively in 399 of 420 trials (95%). Correspondingly, judgments were mixed when target persons were described by positive and negative traits; positive judgments were given in 433 of 840 trials (51.5%) and negative judgments in the remaining 407 trials (48.5%). Splitting ambivalent trials according to situational resolution of conflict showed that negative judgments were given in 181 of the 400 conflict-resolved ambivalent trials (45.3%) and in 226 of the 440 unresolved ambivalent trials (51.4%). This difference was significant in that participants judged ambivalent target persons negatively more often when conflict remained unresolved (51.4%) compared to when it was situationally resolved [45.3%;   F  (1,19) = 8.09  , P   = 0.01,   η   = 0.30]. 


##### After scanning: assessing ambivalence toward each target person in each situation 
  
We assessed experienced conflict toward target persons in each evaluation situation to verify the pretest-based categorization between situations that resolved conflict and those that did not. Results confirmed the expected main effect of trial type [consistent, situationally resolved ambivalent, situationally unresolved ambivalent;   F  (1.27,24.14) = 33.13,   P   < 0.001,   η   = 0.64 (Greenhouse–Geisser corrected)]. Experienced ambivalence toward unconflicted trials (  M   = 7.96, SE  = 2.5) was lower than toward conflict-resolved ambivalent trials (  M   = 23.16, SE  = 3.00;   P   < 0.001), which was lower than ambivalence toward conflict-unresolved ambivalent trials (  M   = 31.15, SE  = 3.74,   P   < 0.001). The pattern of results provides confidence in the categorization into three trial types by combining trait information with evaluation situations. 



#### Decision times 
  
The time it takes to make a judgment provides an indication of judgment difficulty. To confirm that judgments were more difficult when conflict was not situationally resolved and to verify that negative judgments are easier when experiencing conflict, we conducted a repeated-measures analysis of variance (ANOVA) comparing decision times between trial type (consistent, resolved ambivalent, unresolved ambivalent) and the judgment participants provided (positive, negative). Expectedly, trial type influenced decision times [  F  (2,38) = 37.89,   P   < 0.001,   η   = 0.66]; participants were quickest to evaluate persons with consistent traits (  M   = 2.73 s, SE  = 0.13 s) and somewhat slower when traits were conflicted but resolved by situational affordances (  M   = 3.84 s, SE  = 0.28 s;   P   < 0.001). Judgments took longest when traits were conflicted and remained conflicted in the evaluation situation (  M   = 4.20 s, SE  = 0.31 s;   P   = 0.02), suggesting that these were experienced as most difficult. As expected, there was no main effect of response behavior, and participants were equally quick in providing negative and positive judgments [  F  (1,19) = 1.53,   P   = 0.23]. 

Critically, we found the expected interaction of response behavior and trial type [  F  (2,38) = 6.54,   P   = 0.004,   η   = 0.26]. Confirming that negative judgments of conflicting stimuli are the easier response, decision times were quicker when participants judged situationally conflicting targets negatively (  M   = 3.95 s, SE  = 0.30 s) than positively (  M   = 4.45 s, SE  = 0.34 s;   P   = 0.03). In line with hypotheses, no difference in decision times between positive and negative judgments was found for ambivalent stimuli when situational affordances resolved conflict (  P   = 0.24). Regarding consistent stimuli, positive judgments were made faster (  M   = 2.59 s, SE  = 0.12 s) than negative judgments (  M   = 2.88 s, SE  = 0.16 s),   P   = 0.03. 
  
Interaction effect of trial type and response behavior in the whole-brain MLM analysis (Montreal Neurological Institute [MNI] coordinates:   x   = 12,   y   = −6,   z   = 18). Activation thresholded at   P   = 0.005 (red) and   P   = 0.001 (yellow). The left side of the brain is shown on the right side and vice versa. 
  


### Image analysis 
  
#### Whole brain: multilevel model 
  
Because we differentiated trials on the basis of subjects' judgments, we dealt with an unequal number of observations in each cell of the study design. To estimate the effect of trial type and subjects' judgment simultaneously, we thus constructed a multilevel model (MLM) that can deal with such unbalanced designs. Using AFNI’s 3dDeconvolve function, we obtained β estimates for BOLD response magnitude for each voxel and trial by modeling functional magnetic resonance imaging (fMRI) time series with individual trial regressors based on onset times for stimulus presentation (  https://afni.nimh.nih.gov/;-stim_times_IM  ; see  ;  ;   for similar approaches). Decision times were included as duration modulation. Trial type and response behavior were coded as categorical variables. Using R ( ), we then modeled fMRI BOLD from the three trial types (consistent, resolved ambivalent, unresolved ambivalent), the judgments participants made (response behavior: positive   vs   negative judgment) and their interaction, with random intercepts on the subject level at each voxel to account for the repeated measures design (lme4-package;  ). Categorical variables were automatically dummy coded in the analysis, and in order to examine the effects of the two degrees of freedom simultaneously, we used the ANOVA function in the car library (car-package;  ). 

We observed a significant interaction between the effect of trial type and response behavior on brain activation in several regions, including bilateral DLPFC and dACC as hypothesized ( ). For our analyses, we used an a priori threshold of   P   < 0.005 with a cluster size of 25 ( ) to balance Type I and Type II errors. However, all effects of interest were significant at a more stringent threshold and are more accessibly presented using a threshold of   P   < 0.001 with a cluster size of 25 ( ). For the ease of presentation, we use this more stringent threshold in the main paper for presentational purposes and place the full list of activations at the original threshold in the Supplementary Material S3. 
  
Regions that showed a significant interaction effect of trial type and response behavior in the whole-brain MLM (  P   < 0.001, uncorrected) 
  
 Notes  . Only clusters that exceed a minimum size of 25 voxels are shown. Voxel coordinates of the maximally activated voxels are given. 

IFG, inferior frontal gyrus PFC, prefrontal cortex; SFG, superior frontal gyrus. 
    
Activation in right DLPFC (A) and dACC (B) by trial type and response behavior. 
  


### ROI analysis 
  
#### Simple effects 
  
 Post hoc   tests were conducted in SPSS on the DLPFC and dACC regions from the MLM analysis to decompose the interaction effect of trial type and response behavior. For each cluster, we extracted the β estimates for each trial and participant that were used to run the whole-brain MLM analysis. We averaged estimates across voxels for each trial and participant within each cluster. Note that the following analysis is applied to interpret the significant interaction effect by testing simple effects, not to run the same analysis on a subset of the data ( ). 

##### DLPFC 
  
In line with expectations, we observed greater DLPFC activation for positive than negative judgments only when target persons were described by ambivalent traits and evaluative conflict remained unresolved by the situation in which the evaluation took place (right DLPFC, left DLPFC:   P   < 0.001;  ). When target traits were ambivalent but affordances resolved conflict, results showed no difference in DLPFC activation for positive and negative judgments (right DLPFC:   P   = 0.67; left DLPFC:   P   = 0.82). Activation in DLPFC was weaker when participants made positive compared to negative judgments when target traits were consistent (right DLPFC:   P   = 0.009; left DLPFC:   P   = 0.02). 


##### dACC 
  
The pattern of activation in the dACC mirrored DLPFC activation. When trials elicited (unresolvable) evaluative conflict, dACC activation was stronger when participants judged the person positively than negatively (  P   < 0.001;  ). We found no difference for judgment valence in dACC response to ambivalent target persons when affordances resolved conflict (  P   = 0.79). Finally, judging consistently described target persons negatively was associated with greater dACC activation than judging them positively (  P   = 0.05). 

In a follow-up analysis, we verified that these effects cannot be ascribed to differences in decision times. Including decision times did not eliminate the critical interaction between trial type and response behavior on DLPFC activation [right: χ (2) = 22.63,   P   = 1.22e−05; left: χ (2) = 21.95,   P   = 1.71e−05; Type III Wald] and on dACC activation [χ (2) = 14.65,   P   = 0.0007; see Supplementary Material S5 for details]. 



#### Explaining response behavior from variation in BOLD within trial type 
  
A more stringent test of the hypothesis that dACC and DLPFC signal under evaluative conflict is related to going with or against the default evaluation is to test the relationship between judgment behavior and BOLD variability within different trial types while controlling for differences between participants and trial type. If we find that greater (weaker) DLPFC (dACC) activation is related to a greater likelihood of positive (negative) judgments—only within situationally unresolved ambivalent trials—we solidify the claim that positive judgments of conflicting information are more effortful. Compared to the previous analysis in which we found that positive judgments are in general related to greater DLPFC (dACC) response in situationally unresolved ambivalent trials across participants, this analysis looks for the relationship within participants and trial types. To test this, DLPFC (dACC) activation and decision times were centered within participant and trial type. Using R, trial type (consistent, resolved ambivalent, unresolved ambivalent), centered BOLD response and centered decision time effects, as well as their interaction with trial type, were modeled in a multilevel-model nested within subject. Trial type was coded as a categorical variable. Testing the interaction between centered BOLD response and trial type while controlling for decision times thus allows us to test whether response behavior can be explained by variation in BOLD signal in each type of trial. For readability, the discussion of the results focuses on the predicted interaction between BOLD response and trial type. Other effects are reported in the notes. 

##### DLPFC 
  
Most critically, we found that variation in DLPFC activation predicted response behavior dependent on trial type [χ (2) = 22.16,   P   = 1.54e−05; left DLPFC: χ (2) = 21.73,   P   = 1.91e−05]. As can be seen in  , DLPFC activation had little effect on the valence of judgments when target persons' traits were consistent or the situation resolved ambivalence. When target traits were ambivalent and situational affordances did not resolve conflict, however, comparatively lower DLPFC activation was related to a greater likelihood of negative judgments and positive judgments were more likely under greater DLPFC activation. This supports our suggestion that negative judgments are easier when judging ambivalent targets, whereas greater DLPFC activation is necessary to bias toward more favorable judgments. 
  
Likelihood of positive and negative social judgments within each trial type on the basis of centered brain activation in right DLPFC (A), left DLPFC (B) and dACC (C). Shaded areas represent 95% confidence intervals. 
  

##### dACC 
  
The analysis was repeated for the dACC, again examining the interaction between centered dACC signal and trial type while controlling for decision times. The results mirrored the effect of DLPFC activation. Most importantly, variation in dACC activation within trial type condition predicted response behavior differently for different trial types [χ (2) = 14.92,   P   = 0.0006;  ). However, the pattern was less clear than in DLPFC. 





## Discussion 
  
In the current study, we investigated how the brain facilitates social judgments when person information is conflicting. We made two claims. First, we put forward that social evaluations are dynamic and have situational dependency ( ;  ). Second, we hypothesized that people have a tendency toward negative evaluations under evaluative conflict. To investigate this, our paradigm compared social judgments of people described by consistent or ambivalent trait information across different situations. Our findings confirm that social judgments of the same person vary across situations. Dependent on the situation in which the person was evaluated, ambivalent trait information elicited or failed to elicit evaluative conflict as represented in self-report, decision times and brain activation. Importantly, decision time and brain data converged in support of the hypothesis that negative evaluations are easier when experiencing evaluative conflict; participants were faster to make negative than positive judgments. Crucially, positive judgments were associated with greater DLPFC and dACC activation than negative judgments even when controlling for decision time, suggesting that differences in response magnitude are not simply an effect of processing time. Moreover, the variability of participants' DLPFC and dACC activation predicted the likelihood of positive and negative judgments only within evaluative conflict trials. The study thus provides converging evidence suggesting that saying no is easier than saying yes when experiencing evaluative conflict. 

Our findings complement and extend prior work in a number of ways. Related work has focused on the negative value of response conflict, for example, showing that the negative value of conflict primes translates to negative judgments of following neutral targets ( ). The current study extends this line of research showing that negative value of conflict translates to faster negative evaluations of the conflict stimulus itself. Additionally, whereas previous studies focused primarily on the negative value of response conflicts, we focused on evaluative conflict in the traditional sense, which requires the presence of conflict between positive and negative valence (i.e. ambivalence). Thereby, it provides a stringent test of the idea that negative evaluations of conflict-eliciting stimuli can be considered the default response, whereas positive evaluations require more control. 

Important to note is that, even though we observed more negative judgments when participants experienced evaluative conflict compared to when they did not (on the basis of the same ambivalent person information), there was an equal number of positive and negative judgments within high conflict trials. In line with others ( ), we suggest that overriding negative interpretations of ambiguous or conflicting information in favor of a positive interpretation requires regulatory processes. That is, even though negative judgments were easier, participants regularly seem to exert effort in favor of positive judgments. However, it is as yet unclear what motivates people to exert this effort and bias their judgment. 

To our knowledge, this is also the first study that related the likelihood of positive or negative judgments of conflicting information to dACC and DLPFC activity. Negative judgments were made quicker, and weaker dACC and DLPFC response in trials eliciting evaluative conflict was linked to a greater likelihood of negative judgments, whereas stronger dACC and DLPFC response predicted a greater likelihood of positive judgments. Greater activation in dACC on trials eliciting evaluative conflict could be a prerequisite for implementing control and processing changes in DLPFC toward a more favorable judgment. However, the similar activation pattern observed here makes claims regarding their individual contribution challenging. Our interpretation is based on prior work suggesting that both regions play important roles in behavioral flexibility with dACC signaling the need for behavior adjustment, which is critically implemented by the DLPFC (e.g.  ). In social evaluation tasks, regions in the lateral prefrontal cortex have been linked to updating initial impressions with incongruent information ( ). For example, Bhanji and Beer (2013) demonstrated that modifying impressions toward a more favorable (i.e. positive) judgment is linked to parametrically increasing engagement of a region within lateral prefrontal cortex. Similar to our suggestion, they interpret this increased engagement as a reflection of cognitive effort. We argue that the engagement of DLPFC when changing one’s social judgment is not linked to the valence (i.e. positivity) of the evaluation   per se   but dependent on whether the evaluation moves away from the default response. For example,  ) showed that engagement of DLPFC was related to incorporating negative information about positively evaluated ingroup members. Since it is not the valence of the evaluation but the movement away from the default response that engages DLPFC, and since positive evaluations of ingroup members are the default response, integrating negative information into the evaluation of an ingroup member requires more effort similar to moving toward a positive evaluation when experiencing evaluative conflict in our task. This may also suggest some interesting boundary conditions worthy of future investigation. Whereas we suggest that it is easier to evaluate individuals negatively based on conflicting information, there are likely situations under which this effect may be diminished or even reversed due to motives of the evaluator. Situational factors such as group membership, one’s need to belong or stressful social situations (e.g. ostracism) may influence our interpretation and value judgment of certain traits as well as our global evaluation of another person. For example, when we feel socially rejected or lonely, we may be more inclined to evaluate another person positively despite conflicting trait information, thus shifting the default response to evaluatively conflicting information from negative to positive. Additionally, when evaluating ingroup and outgroup members on the basis of the same conflicting trait information, it may be relatively easier to judge an ingroup member positively because group membership carries positive value and we may process negative information about ingroup members in a biased manner (cf.  ). 

Usually, research into cognitive conflicts and the role of dACC and DLPFC in executive functioning is tested with non-social tasks in which perceptual or response conflict is correctly resolved by actively attending to and regulating behavior. Our study shows that the role of dACC and DLPFC in guiding behavior flexibly in more low-level cognitive control tasks also maps onto more complex tasks in which people have to search memory and weigh information in line with situational affordances. However, an important aspect of our study design was that participants were forced to provide a positive or negative judgment. By forcing a single-factor solution from evaluatively contradicting information, we created an evaluation situation in which neither response option fits participants' evaluation of the stimulus. Even though this approach mirrors many real-life situations, it prevents us from pulling apart possibly separate fMRI responses to evaluative conflicts and response conflicts. The distinction is less relevant for the current study since we were interested in the interaction between the presence of conflict and the judgment provided. However, independent of judgment valence, it may be that dACC response was partly driven either by the difficulty to choose between two unfitting response options or by the evaluative conflict that the stimulus elicits independently of choice. Future studies may investigate this further by comparing forced-choice situations with situations in which participants can indicate mixed evaluation toward an evaluatively conflicted stimulus. 


## Conclusions 
  
The current study shows that social evaluations are dynamic and form in a particular situation, with a particular goal in mind. Complex and conflicted stimulus representations can be resolved by situational prioritization of information. Extending the work on conflicts as negative signals, the findings indicate that when prioritization fails to resolve conflict, negative judgments of conflicting stimuli are easier than positive judgments as indicated by decision times and engagement of dACC and DLPFC. 


## Notes. 
  
  
Given the traits and situations included in the study, a majority of the judgments related to the competence of the target person in a given situation (Supplementary Material S2). 
  
Participants additionally rated how positively (negatively) they evaluated each target persons' most positive (negative) traits on a scale ranging from not at all (0) to very (100). Ratings were combined in line with Thompson Zanna, and Griffin (1995): Ambivalence = (Pos + Neg)/2 −|Pos − Neg|. This measure has been moved to the notes due to word constraints and because we expected the same pattern of results as on the subjective ambivalence scale. Results on this measure indeed confirmed the other self-report results that targets described by mixed traits elicited more ambivalence (  M   = 48.05, SE = 5.14) than did targets described by consistent traits [  M   = −30.21, SE = 4.61;   t  (19) = −9.405,   P   < 0.001,   r   = 0.91]. 
  
For exploratory reasons, participants also responded to the same questions presented in the scanner on a continuous scale ranging from definitely not (0) to definitely yes (100). This measure was not analyzed for this study. 
  
We verified the results of the MLM by running an ANOVA. Note that because of the unbalanced design, ANOVA is inferior to MLM in this case. This analysis resulted in similar findings; the details can be found in the Supplementary Material S4. 
  
Activation in right DLPFC explained response behavior [χ (1) = 4.47,   P   = 0.03; left DLPFC: χ (1) = 6.50,   P   = 0.01] next to decision times [χ (1) = 10.75,   P   = 0.001; left DLPFC: χ (1) = 9.48,   P   = 0.002]. Whereas there was no main effect of trial type on the valence of the judgments participants made, we observed that the effect of decision time on the direction of judgments depended on trial type [χ (2) = 16.69,   P   = 0.0002; left DLPFC: χ (2) = 14.89,   P   = 0.0006]. 
  
We observed that the direction of response behavior could be explained by (participant- and valence-centered) activation in dACC [χ (1) = 3.70,   P   = 0.05] next to (participant- and valence-centered) decision times [χ (1) = 9.35,   P   = 0.002]. Variation in decision times also predicted the valence of judgments dependent on trial type [χ (2) = 15.21,   P   = 0.0005]. 
  


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-25'>
<h2>25. PMID: 18431500</h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Cooperation and Deception Recruit Different Subsets of the Theory-of-Mind Network</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2008</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0002023</p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social cognition (theory-of-mind: cooperation, deception) performed in healthy adult participants (n=13; ages 22–38, within 18–60). The task is social-related (attribution of intentions/beliefs), and BOLD whole-brain data were acquired (complete cortical coverage) and an exploratory whole-brain analysis (ToM vs non-ToM) is reported. Although subsequent hypothesis-driven analyses used ROIs derived from the whole-brain results, the study presents whole-brain activation patterns and reports contrasts across ToM conditions. Participants were healthy with no psychiatric/neurological disorders. This is an original empirical fMRI study (not a review) and not limited to patient samples. Therefore it meets all inclusion criteria (social task, healthy adults 18–60, whole-brain results) and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
The term “theory of mind” (ToM) describes an evolved psychological mechanism that is necessary to represent intentions and expectations in social interaction. It is thus involved in determining the proclivity of others to cooperate or defect. While in cooperative settings between two parties the intentions and expectations of the protagonists match, they diverge in deceptive scenarios, in which one protagonist is intentionally manipulated to hold a false belief about the intention of the other. In a functional magnetic resonance imaging paradigm using cartoons showing social interactions (including the outcome of the interaction) between two or three story characters, respectively, we sought to determine those brain areas of the ToM network involved in reasoning about cooperative versus deceptive interactions. Healthy volunteers were asked to reflect upon the protagonists' intentions and expectations in cartoons depicting cooperation, deception or a combination of both, where two characters cooperated to deceive a third. Reasoning about the mental states of the story characters yielded substantial differences in activation patterns: both deception and cooperation activated bilateral temporoparietal junction, parietal and cingulate regions, while deception alone additionally recruited orbitofrontal and medial prefrontal regions. These results indicate an important role for prefrontal cortex in processing a mismatch between a character's intention and another's expectations as required in complex social interactions. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (41032 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
The term “theory of mind” (ToM) describes both the ability to understand and predict the behavior of other people by making inferences about their mental states, their intentions, feelings, expectations, beliefs or knowledge, and to cognitively represent one's own mental states  . It is widely acknowledged that ToM evolved in hominids in response to the increasing complexity of social interactions, representing a powerful cognitive tool to determine whether or not a conspecific is willing to cooperate and reciprocate  , or tends to intentionally deceive and defect at the expense of others  . In humans, this cognitive mechanism is more or less permanently “online”, to the extent that we sometimes ascribe mental states to inanimate objects such as cars, computers etc  . Given that ToM requires quite large computational resources, it is not surprising that a dysfunction of the ToM mechanism is involved in a variety of neuropsychiatric disorders, including autism and schizophrenia and may cause severely compromised social competence in patients with such conditions  – . 

A number of functional brain imaging studies have revealed that ToM involves an extended neural network located in the frontal, temporal and parietal lobes bilaterally  ,  . Specifically, ToM recruits several cortical midline structures, including the medial prefrontal cortex (MPFC), the anterior cingulate (ACC), and the precuneus as well as lateral areas of the middle temporal lobes (MTL), the temporoparietal junction (TPJ), the superior temporal sulcus (STS) and the temporal poles (reviewed in  ,  – ). The area extending from the anterior cingulate cortex to the anterior frontal pole, particularly the paracingulate cortex, is supposed to be engaged in self-reflection, person perception and in making inferences about others' thoughts  . Furthermore, regions near the temporoparietal junction (TPJ) are thought to be involved in reasoning about the contents of another person's mind  ,  , attribution of a character's actual belief or state of knowledge  ,   and the discrimination between self and others  . Although hemispheric specialisation has been observed, the results are contradictory: while some studies found selective activity in right TPJ  ,  , others showed left TPJ to be necessary for representing other persons' beliefs  ,  . The mPFC and the ACC are thought to help distinguish self from other, to be engaged in error monitoring, and to differentiate salient from non-salient stimuli  ,  ,  . The role of the precuneus is less well known, but this brain area seems to be important for the experience of agency and self-consciousness  ,  . The temporal regions around the STS contain mirror neurons that play a decisive role in imitation and learning as well as in recognition of intentional movements  ,  . In addition, amygdalar, insular and orbitofrontal activity may contribute the affective “tone” to the evaluation of thoughts and intentions  . For example, the insula has been shown to be activated if unfairness is being recognised  . 

A prototypical task used in ToM research has been the ”false belief task”, which requires the subject to predict where a character will look for an object that has been displaced by another character unbeknownst to the first character. While successful performance in this task is considered a milestone in the development of ToM in young children  ,  , it does not entail “higher order” processes in the framework of interpersonal expectations and intentions such as beliefs of a character about the mental states of a third party–which is crucial to determine whether or not a person has an understanding of the intentions of others (i.e. “ I know that X does not know that Y wants to cheat upon him, and that Y knows that X cannot know what Y really intends to do”). 

It is as yet unknown whether an individual's understanding of another person's mental states about cooperative or deceptive intentions of a third party, resulting from false or true interpretations of the third party's actions and behavior, are processed in discrete brain regions of the ToM network. In this study, we therefore sought to examine whether a subject's evaluation of cooperative and deceptive interactions between two or three story characters elicits differential activation patterns within the ToM neural network. 

Accordingly, healthy participants were shown cartoon stories depicting scenarios of cooperation, deception or both; the participants' task was to attribute intentions and beliefs to the protagonists. The stories described either a) situations where one person wants another to cooperate to the advantage of both, b) situations where one person deceives another person, and c) situations where two persons cooperate to deceive a third person. Since the outcome of the scenarios was visible to the participants, the experimental design was suitable to examine the test subject's ability to represent a “true” or “false” belief held by one of the story characters. Moreover, the deception condition overtly signalled unfairness, whereas the cooperation condition clearly depicted reciprocity and fairness. By means of fMRI we investigated whether these concepts draw on different brain regions, i.e. whether the representation of a character's erroneous belief in the (unfair) deception condition recruits different brain regions compared to the mental representation of a character's correct inference of intentions in the (reciprocal) cooperation condition.. In addition, the combined cooperation/deception stories were introduced to determine brain regions commonly activated by the formation of a cognitive representation of both a cooperative and deceitful intention. In an additional baseline condition, we showed the same cartoons in jumbled order, the task of the participants was to answer questions regarding physical properties of the stimuli. 

Since involvement of temporoparietal junction and precuneus in intention and belief attribution has repeatedly been demonstrated, we expected these regions to be activated across all scenarios. In contrast, we hypothesised that the representation of a scenario depicting a character's concealed deceitful intention would recruit additional brain activation  . As a potential candidate for these more complex scenarios we predicted that the medial prefrontal cortex would be more strongly activated due to its involvement in disambiguating information, including discrepancies between one's own expectation and others' (covert) intentions  . Moreover, we expected that limbic and orbitofrontal structures such as the insula would differentially be activated by the deceitful scenario, which was associated with a high level of unfairness. We also assumed that increasing complexity of the social interaction in scenarios describing both cooperation and deception and an interaction of three characters would lead to more widespread brain activation due to the higher processing load involved. 


## Results 
  
### Imaging 
  
We analyzed results by directly contrasting all three types of stories, cooperation (COOP), deception (DEC) and cooperation/deception (COOPDEC) with each other, using a height threshold of p<0.02 and an extent threshold of k = 15. The contrasts were calculated for the ROIs derived from the preceding exploratory whole-brain analysis that compared activation during the ToM tasks with activation during the non-ToM tasks. These ROIs encompassed superior, medial and inferior frontal regions, and ACC, insula, as well as parietal and temporal regions including the TPJ and precuneus. In several of these ROIs, mentalizing about stories with a deception element yielded differential activation from mentalizing about stories with a cooperation element. Other regions were commonly activated by both types of stories, with spatially distinct peaks of activation (see   and  ,  ). 
   Brain activation in frontal, temporoparietal and temporal regions.  
Activation patterns are rendered on the brain surface in the contrasts of stories describing deception (DEC), cooperation (COOP) and both (COOPDEC). n = 13, extent threshold k = 15; height threshold p<0.02. 
     Brain activation in medial frontal, cingulate and parietal regions.  
Brain activation patterns are shown for the contrasts of stories describing deception (DEC), cooperation (COOP) and both (COOPDEC). n = 13, extent threshold k = 15; height threshold p<0.02. 
     Contrasts of the ToM task conditions cooperation (COOP), deception (DEC), and cooperation/deception (COOPDEC) (n = 13; height threshold p<0.02, extent threshold k = 15).        
As expected, stories containing both cooperation and deception elements recruited the largest regions, in comparison to the other conditions. Specifically, brain activation patterns of the stories containing both elements (COOPDEC) tended to show higher BOLD responses in the majority of ToM-activated regions, i.e. in bilateral TPJ, right anterior temporal cortex, left inferior and superior frontal cortex compared to COOP and DEC, respectively. These results suggest that the processing load for the more complex situation depicted in the COOPDEC scenarios might be higher than for the more straightforward one-to one interactions. 

Compared to DEC>COOP, the contrast COOPDEC>COOP showed larger activation in bilateral temporoparietal regions, while both contrasts yielded similar activation in inferior and superior frontal gyrus. Compared to COOP>DEC, the contrast COOPDEC>DEC shows larger activation in inferior frontal gyrus and righthemispheric parietal and temporal regions. 

#### Frontal activation 
  
The results from direct contrasts between stories containing elements of deception or cooperation or both showed differential activation patterns. Participants showed higher medial (lefthemispheric BA 9 and 10) and left inferior frontal (BA 47) activation when mentalizing about stories containing an element of deception compared to cooperation. On the other hand, mentalizing about cooperation alone, but not about the combined cooperation/deception stories, led to higher activation in superior frontal gyrus (lefthemispheric BA 9 and 10) when compared to deception alone. 

Moreover, within stories containing an element of deception, superior and medial prefrontal activation (left hemisperic BA 9) was higher in DEC compared to COOPDEC, while inferior frontal gyrus activation (lefthemispheric BA 47) was higher in COOPDEC than in DEC. 

On the other hand, within stories containing the element of cooperation there was higher activation in left superior frontal gyrus (BA 9) in COOP than in COOPDEC, while the opposite applied in bilateral inferior frontal gyrus (BA 47) and left medial frontal gyrus (BA 32), where COOPDEC stories led to higher activation than COOP stories. A higher activation of COOP in left superior frontal gyrus (BA 10) was also found compared to DEC. 

In general, these results suggest that stories containing a deception element activated predominantly left inferior and medial frontal gyrus. In spatially distinct regions of left superior frontal gyrus, higher activation was found in tasks containing only the cooperation element or the deception element, respectively (see   and  ,  ). 


#### Limbic activation 
  
In left posterior cingulate gyrus (BA 31), both types of stories containing a deception element led to higher activation than stories dealing with cooperation alone, while both types of stories containing a cooperation element led to higher activation in right posterior cingulate gyrus (BA 31) compared to the deception stories. 

Further differentiation between stories was found in right ACC (BA 33) and bilateral posterior cingulate gyrus (BA 23), where the activation was higher for DEC than for COOPDEC, and in left posterior cingulate (BA 30), where activation was higher for COOP than for COOPDEC (see  ,  ). 


#### Temporoparietal junction activation 
  
Both types of stories containing a deception element led to higher activation in left middle temporal gyrus (BA 39) than cooperation alone, while they activate right middle temporal gyrus (BA 39) less than cooperation alone. 

Furthermore, stories containing a cooperation element led to higher activation than DEC in several regions of the TPJ: in left superior and middle temporal gyrus (BA 12, 22, 39) and in right middle temporal gyrus, however, there are no TPJ regions where stories containing a cooperation element commonly show less activation than deception stories (see  ,  ). 


#### Other temporal regions 
  
Right middle temporal gyrus (BA 39) exhibits higher activation regarding stories containing a deception element than mere cooperation stories. Within stories containing deception, some regions in right middle temporal gyrus (BA 21, 37) are activated stronger by COOPDEC than by DEC, while a more superior situated region in left middle temporal gyrus appear to be activated stronger by DEC than COOPDEC (BA 22). 

There are no temporal regions that commonly exhibit higher activation in stories containing a cooperation element compared to deception. However, some temporal regions show differential activation when comparing COOP and COOPDEC, such as left superior temporal gyrus (BA 41), which is activated stronger by COOP than by COOPDEC, while regions in right superior (BA 21, 22) and middle temporal gyrus (BA 37) are activated stronger by COOPDEC than COOP. In general, stories containing a deception element apparently lead to higher temporal activation than those without. In particular righthemispheric middle temporal regions are predominantly involved in deception processing and/or even more in the combination of deception and cooperation (see  ,  ). 


#### Parietal regions 
  
Both types of stories containing a deception element yield higher activation in left precuneus (BA 7) than stories with only a cooperation element, however, when comparing deception type stories with each other, this same region is activated higher in DEC than in COOPDEC stories, and also activation in an adjacent precuneus region (BA 31 left) is higher in COOP compared to COOPDEC. No parietal region shows higher activation in COOPDEC compared to DEC and COOP, respectively. 

It appears that lefthemispheric precuneus BA 7 is activated predominantly when deception has to be processed, while BA 31 seems rather to be involved in processing cooperation. 



### Mean signal intensity 
  
An ANOVA comparing mean signal intensity in left medial (BA 9/10) and inferior frontal (BA 47) gyrus and in left temporoparietal junction (BA 22) in all three ToM task conditions revealed main effects of condition (F(2) = 7.917 p<0.001, region (F(2) = 4.830 p<0.01 and a significant condition*region interaction (F(4) = 9.910 p<0.001). Paired t-tests comparing activation in the same region for different conditions showed significantly higher activation in medial prefrontal cortex during DEC compared to COOP and COOPDEC (t(12) = 2.537 p<0.01 and t(12) = 2.290 p<0.01, respectively); in inferior frontal cortex during DEC and COOPDEC compared to COOP (t(12) = 3.041 p<0.01 and t(12) = 4.005 p<0.001), and in temporoparietal junction in COOPDEC compared to DEC (t(12) = 2.079 p<0.01) and COOP (t(12) = 4.173 p<0.001). T-tests comparing activation in the same condition for different regions showed significantly higher activation in medial PFC than in TPJ for DEC (t(12) = 3.179 p<0.01), and higher activation in TPJ than in inferior frontal gyrus for COOP and COOPDEC (t(12) =  3.726 p<0.01 and t(12) = 2.757 p<0.01) (see  ). 
   Activation in frontal and temporal regions during the different ToM conditions.  
The graph shows the mean signal intensity (+/− s.e.m.) (in arbitrary units) in these regions in the conditions DEC (black), COOP (white) and COOPDEC (grey), respectively. The ANOVA with the factors condition and region showed main effects of condition (F(2) = 7.917 p<0.001, region (F(2) = 4.830 p<0.01 and a significant condition*region interaction (F(4) = 9.910 p<0.001 with significantly higher activation in medial prefrontal cortex during DEC compared to COOP and COOPDEC (t(12) = 2.537 p<0.01 and t(12) = 2.290 p<0.01, respectively); in inferior frontal cortex during DEC and COOPDEC compared to COOP (t(12) = 3.041 p<0.01 and t(12) = 4.005 p<0.001), and in temporoparietal junction in COOPDEC compared to DEC (t(12) = 2.079 p<0.01) and COOP (t(12) = 4.173 p<0.001). Activation during DEC was significantly higher in medial PFC than in TPJ (t(12) = 3.179 p<0.01), and during COOP and COOPDEC significantly higher in TPJ than in inferior frontal gyrus (t(12) =  3.726 p<0.01 and t(12) = 2.757 p<0.01). 
  

### Behavioral measures 
  
Participants performed at ceiling level in the paper-and-pencil ToM story comprehension task that followed the fMRI session. The mean score was 23.0 for answering the ToM questionnaire alone (standard error 0.00) and 59.0 for the ToM questionnaire combined with the sequencing task (standard error 0.00). 



## Discussion 
  
In a functional magnetic resonance imaging paradigm using cartoons showing social interactions (including the outcome of the interaction) between two or three story characters, respectively, we sought to determine whether brain areas of the ToM network would be differentially involved depending on the nature and complexity of the observed interaction. The overall activation pattern observed in our ToM task showing activated regions in temporoparietal junction, precuneus, temporal cortex, cingulate areas, and prefrontal cortex corresponds largely to the findings of previous studies and the general notion of the theory-of-mind network  – . Since story comprehension of cooperative and deceitful scenarios was flawless in all participants, as indicated by the behavioral data, the observed activations most likely reflect adequate belief reasoning in all three task types. When considering the results from contrasting the three task conditions, it can be assumed that an area that is primarily involved in processing deception will most likely show up in the contrast DEC>COOP, but not its opposite, and potentially also in the contrasts DEC>COOPDEC or COOPDEC>DEC. An area primarily involved in processing cooperation should show up in the contrast COOP>DEC, but not its opposite, and potentially also in COOP>COOPDEC or COOPDEC>COOP. 

### Temporoparietal junction, precuneus and posterior cingulate regions are involved in the comprehension of cooperation and deception 
  
Mentalizing about scenarios describing both cooperation and deception (COOPDEC) always showed higher activated areas in the temporoparietal junction when compared to the DEC or COOP conditions alone. Moreover, the opposite contrasts of COOP>DEC and DEC>COOP exhibited activation in TPJ. COOP and COOPDEC tend to activate bilateral TPJ stronger than DEC, with COOPDEC moreover showing higher activation than COOP in these regions. In general, these results correspond to studies reporting temporoparietal activation in ToM tasks requiring belief reasoning  ,  . However, in contrast to lateralized effects found in recent imaging studies on belief reasoning, with right TPJ selectively activated in false belief   and belief attribution during moral judgments  , and the findings from lesion studies implicating left TPJ in belief reasoning  ,  , our results showed bilateral TPJ activation in both cooperation and deception conditions. A possible reason for the disparity of the observed activation pattern compared with previous studies could lie in differences in task requirements. Our stories were designed to force subjects to reason about (cooperative and deceitful)   intentions   of the story characters, whereas the study by Sommer et al. (2007) used stories where the   knowledge   of a story character had to be inferred. Hence, the higher processing demands placed on the ToM network by our task may well have recruited more bilaterally distributed TPJ activation than a standard task requiring comprehension of a false belief about the location of an object.. 

Accordingly, our findings expand upon previous findings on the role of the temporoparietal junction in ToM, suggesting that processing deception, cooperation or both activates bilateral TPJ. 

Precuneus activation was also observed in all contrasts of cooperation, deception, and cooperation/deception compared with the other conditions. These findings correspond to the study by Sommer et al.  , who also found precuneus activation in both false and true belief reasoning about object location. An fMRI study by Ochsner et al.   found left precuneus to be one of the regions activated by attributing emotions to other people and the self, together with posterior cingulate and prefrontal cortex. According to Vogeley & Fink  , the medial parietal cortex-together with medial prefrontal cortex-has a role in taking the first-person perspective and differentiating between actions controlled by the self versus other persons. However, in a PET study by Ruby and Decety  , there was more bilateral precuneus activation when taking a third person perspective than first person perspective. In an fMRI study that compared thinking about physical causality (physical event and its consequences) versus intentional causality (a subject's intentions and its consequences), the precuneus/posterior cingulate cortex was found to subserve reasoning about intentional causality  , a function that usually develops before false belief understanding. In accordance with the literature, our results therefore suggest that in ToM tasks, the precuneus performs a rather broad function, relating to perspective taking as well as attribution and processing of emotions and intentions, that is required for belief reasoning including comprehension of cooperation and intentional deception. 

Another region commonly activated to varying degrees in all contrasts across conditions is the posterior cingulate gyrus /posterior cingulate (BA 23, 30, 31). Posterior cingulate activation has previously been found in theory of mind research when reading stories about social interaction  ,  , in particular reading about a protagonist's thoughts  , and also specifically in tasks focussing on empathy  –here together with anterior cingulate, paracingulate gyrus and amygdala. These results hint at a role for posterior cingulate apparently related to social/emotional processing aspects of ToM, which in our study were present in both forms of belief reasoning. 


### Processing deception additionally recruits prefrontal cortex, insula and anterior cingulate 
  
Mentalizing about a situation involving intentional deception on the part of the acting character and not recognizing the deceitful intent on the part of the passive character additionally activates left orbitofrontal lateral, inferior, and medial frontal cortex, as seen in the contrasts of DEC vs COOP and COOPDEC, respectively, and in the contrast COOPDEC vs DEC. These results indicate that these prefrontal regions might have a central role in processing a mismatch between intentions and expectations of the protagonists, and also in processing emotional aspects of unfairness  . 

Regions in left lateral superior frontal gyrus, however, showed up in all contrasts, suggesting that adjacent, but spatially distinct areas in this region are involved in processing of cooperation and deception, respectively. 

Involvement of different frontal regions in ToM tasks has been observed in previous PET and fMRI imaging studies  ,  ,  ,  ,  . These studies, however, did not specify variations of cooperative or deceitful intentions shown in their tasks, nor did they explicitly request to evaluate expectations and intentions of the protagonists in a social setting. These studies revealed either left  ,   or right   activation of medial frontal and inferior frontal cortex during ToM tasks performance, or right orbitofrontal activation during recognition of mental states  , as well as specific medial frontal activation  . 

One recent neuroimaging study considering belief processing in ToM associated right lateral rostral prefrontal cortex, but not medial prefrontal cortex, with reasoning about a character's false belief  . The authors used a standard false belief task that described hiding and dislocation of objects, which required subjects to predict a behavior without intention attribution–as already pointed out, this constitutes an important difference to our task that may account for differential results. 

Two further studies found activation of medial prefrontal cortex in subjects playing games that involved trust and reciprocity, particularly when cooperative intentions had to be evaluated  ,  . At first sight these findings might seem contradictory to our results of deception-specific medial frontal activation. However, evaluating cooperative intentions also requires checking for a match or mismatch between one's own expectations and the other's intentions-which might include deception. Therefore such a task may be more similar to our deception task than to our cooperation task, where cooperation was evident and needed no additional evaluation in terms of the truthfulness of the cooperative intent. 

Moreover, our results are consistent with lesion studies showing that damage to the medial frontal lobe impaired detection of deception in a ToM task   and caused deficits in “affective” theory of mind, including evaluation of another person's emotional situation  . It is conceivable that these divergent findings on medial and orbitofrontal involvement in ToM reasoning result from different task paradigms that concentrate either on cognitive or affective aspects of the ToM task. In contrast to classic second-order false belief tasks, which require only a cognitive understanding of the difference between one person's knowledge and that of another, our ToM task required both cognitive and affective ToM in true and false belief conditions. Therefore, the higher activation of medial and orbitofrontal prefrontal regions in tasks requiring both the processing of a malicious intent of one character and the ignorance of that intent by another character might well be related to the stronger emotional valence and perception of unfairness in the deception scenario compared to cooperation. 

Interestingly, as shown by Abe et al., orbitofrontal medial PFC has also been found activated when subjects themselves were deceiving another person,  . In combination with our findings, these results indicate a general involvement of this region in deception processing, regardless of whether one's own actions or actions of others are concerned. These findings blend in well with the general role suggested for the anterior rostral medial prefrontal cortex (arMFC)–a region which corresponds largely to the area activated in our deception task-by Amodio & Frith  . Their review suggests that the arMFC is involved particularly in thinking about mental states and intentions–of self and others. 

Orbitofrontal/ventromedial PFC (BA 10/11) and dorsolateral PFC (BA 9/10/46) have also been found to participate in moral judgements  – . Before a moral judgment can be made, the inappropriate and harmful intention of an actor has to be detected and linked to empathetic engagement with the deceived person. In our study, participants did not have to judge the moral implications of the scheming person's behavior, because the outcome of each scenario was evident. Thus, subjects were merely requested to describe the deceiver's intention and the victim's ignorance. It is therefore conceivable that the activation during moral judgment in previous studies results from a more complex process in which a malicious intention has to be detected. Inferior frontal gyrus (BA 47) in ventrolateral orbitofrontal cortex has also been found activated in response to moral and social transgressions  , suggesting that the activation in left BA 47 during deception processing observed in our study may well relate to the moral implications of the depicted events. 

However, orbitofrontal cortex activation has to date rarely been found to be involved in theory of mind  . It has been suggested that orbitofrontal cortex belongs to a system responding to aversive reactions of others and is therefore also activated in intentional or unintentional violations of social norms  . These notions of orbitofrontal cortex involvement in evaluation of moral behavior and violation of social norms loosely correspond to our finding of involvement of orbitofrontal cortex in mentalizing about people who take advantage of the false beliefs of others to transgress social norms. 

Bilateral anterior cingulate regions also showed higher activation in conditions containing a deception element, in particular in the contrast DEC>COOP. These results correspond to those by Sommer et al.  , who found ACC activation in the contrast false vs. true belief. In their comparison of neuronal correlates of ToM and empathy, Völlm et al.   found empathy associated with enhanced activations of paracingulate, anterior and posterior cingulate; thus it might be conceivable that higher activation of anterior cingulate regions during processing of false belief situations relates to empathizing with the deceived character. The left insula region (BA 13) also exhibited higher activation in deception compared to the other conditions. In accordance with the results by Sanfey et al.  , this activation could relate to the perception of unfairness in the deception scenarios. 


### Conclusion 
  
Our results suggest that bilateral TPJ, precuneus, and posterior cingulate are regions involved in belief reasoning and evaluation of both cooperative and deceptive intentions of others embedded in a social interaction, at least if the outcome of the social interaction is directly observable. In contrast, orbitofrontal and medial prefrontal cortex, and anterior cingulate regions seem to be predominantly active during processing of a character's ignorance of a malicious intent against him, and attribution of deceptive intentions to a third party. To the best of our knowledge, this study is the first to further dissect the cognitive architecture of processing cooperation versus intentional deception. Our findings provide evidence for the hypothesis that different processes of ToM, namely the comprehension of cooperation and deception, are associated with different activation patterns of the neural network involved in social cognition. 



## Methods 
  
### Participants 
  
13 healthy participants (mean age 26.46 years, SD 5.3 years, range 22–38 years; 4 male participants, mean age 26.25 years, SD 4.78; 9 female participants, mean age 26.55 years, SD 5.79) without a history of neurological or psychiatric disorder or first-degree relatives with such illnesses took part in this study after giving written informed consent. The protocol was approved by the local ethics committee of the Ruhr-University Bochum. Prior to the experiment, participants received a handout informing them about the MRI procedure and the instructions for the ToM task. 


### Theory of Mind Task 
  
The theory of mind (ToM) task consisted of six different cartoon stories with four pictures each  , showing scenarios of: a) cooperation of two persons depicting reciprocality, b) deception, where one person deceives another person associated with overt unfairness, and c) cooperation of two persons to the disadvantage of a third person,-i.e. two cartoon stories of each type (Examples see  ). In order to compare activation elicited by ToM demands with non-ToM activation, we introduced a control (non-ToM) condition, where the pictures of the stories were presented in jumbled order. 
   Examples of the ToM cartoon stories presented to the subjects.  
Panels show (A) cooperation, (B) deception, and (C) cooperation/deception. (D) shows an example of a jumbled cartoon story presented in the non-ToM condition. 
  
For the purpose of acquiring fMRI data during performance of the task, the cartoon stories were projected onto a screen during the MR scanning session and presented to the participant via a 45° angled mirror fixed on the head coil. The mirror was adjusted to enable each participant to view the screen without having to move the head. Prior to scanning, a test image was displayed on the screen to ensure that the images were in focus and that the participant could comfortably see the pictures and read the questions. All four pictures of a given story were shown simultaneously on the screen, arranged in two rows in left to right order. In each condition (cooperation, deception, cooperation/deception and non-ToM control), at first the cartoon story was presented alone for 15 sec, then two questions were successively superimposed upon the screen (between the first and the second row of pictures) for 12 seconds each. The task of the participant was to regard the story attentively during the first phase and to think about the answer to each question as long as the question was displayed on the screen. 

In the ToM conditions, the questions referred to intentions and beliefs of the protagonists. While one question always referred to the intention of the acting character(s) (e.g. “What does the boy with the red pullover have in mind?”), which could be positive (cooperation) or negative (deception) for the other; the second question pertained to the belief of the reacting character (e.g. “What does the boy in the blue pullover expect from the boy in the red pullover?”), which could be false or true. False beliefs included the incorrect assumption that the other person wanted a positive social interaction (to cooperate, to play, to give a present) or had a problem and needed help. True beliefs correctly assumed a desire for a cooperative social interaction. In the non-ToM control condition, the questions referred to properties of objects displayed on the scene (e.g., “Is the background blue or yellow?”). 

The cartoon stories for the ToM and non-ToM condition were presented alternatingly in a blocked design with a total of 12 phases (6 ToM phases and 6 non-ToM control phases) of 39 sec duration each, always beginning with a non-ToM phase, with conditions of cooperation, deception and cooperation/deception presented in randomized order. Each experimental scanning session had a duration of approx. 7 min 48 secs. 


### Behavioural measures 
  
After the scanning procedure, the participants completed a paper and pencil version of the ToM task. In the first part of this task, the four pictures of each story were presented in a jumbled order and participants had to put them into the correct sequence. For each cartoon story sequenced correctly, subjects received 6 points (max. score 36 points). In addition, 23 open questions pertaining to the mental states of the cartoon characters were given, i.e. the 12 questions from the scanning session plus additional questions. Here each correct answer scored 1 point (max. total 23 points). The maximum total score for sequencing and questionnaire was 59 points (for details, see  ). 


### fMRI Data Acquisition 
  
Data were acquired using a whole body 1.5 T scanner (Magnetom Symphony, Siemens, Germany) equipped with a high power gradient system (30 mT/m/s; SR 125 T/m/s), using a standard imaging head coil. Blood-oxygen level dependent (BOLD) images were obtained with a single-shot SpinEcho-EPI sequence (TR 3000 ms, TE 60 ms, matrix 64×64, field of view 224 mm, slice thickness 3.0 mm, 0.3 mm gap between slices, voxel size 3.5×3.5×3.0 mm). To reduce noise and obtain an adequate signal-to-noise ratio we restrained the subjects' heads in order to prevent head motion, chose a voxel size of 3.5×3.5×3 mm and used a block length of 13 scans ( =  39 seconds) as well as a spatial smoothing algorithm of 6 mm FWHM in the single subject preprocessing. We acquired 30 transaxial slices parallel to the anterior commissure–posterior commissure (AC-PC) line. The area covered by the fMRI scans encompassed the complete cortex area extending from the superior pole of the cortex to the inferior pole of the temporal cortex. Additionally, anatomical images of each subject were acquired using an isotropic T1-3dGE (MPRAGE) sequence (TR 1800 ms, TE 3.87 ms, matrix 256×256, field of view 256 mm, slice thickness 1 mm, no gap, voxel size 1×1×1 mm) with 160 sagittally oriented slices covering the whole brain. 


### fMRI Data Analysis 
  
For preprocessing and statistical analysis of the fMRI data, we used the Statistical Parametric Mapping (SPM) Software, Version 5 (Wellcome Department of Cognitive Neurology, London, UK) implemented in Matlab (Mathworks, Sherbon, MA). The first 5 images of each fMRI session (total 157 images), during which the BOLD signal reaches steady state, were discarded from further analysis. Single subject preprocessing consisted of the following steps: realignment for motion correction, normalization to standard stereotaxic coordinates (MNI coordinates), smoothing at 6 mm  voxels, and first-level single subject data analysis. The acceptable limit of head motion was 2 mm for translational movements and 0.5° for rotational movements. 

To assess the differences between the individual ToM conditions (i.e. cooperation versus deception, deception versus cooperation/deception and cooperation versus cooperation/deception), we performed second-level paired   t  -test analyses by using first-level contrasts obtained for cooperation, deception and cooperation/deception minus the global non-ToM condition. To do this, in a first-level single subject analysis, contrast images were calculated for activation in the ToM conditions relative to the non ToM condition for each participant. The analysis encompassed the complete presentation phases of the cartoons, i.e. both processing of the story and answering the questions. The individual contrast images were then entered into an exploratory second-level random-effects analysis (one-sample   t  -test) of the activation patterns for all subjects, with a liberal threshold of p<0.02 (uncorrected) and with a minimum cluster size of k = 15 voxels-in order to find the areas involved in mentally answering questions requiring theory of mind in general. 

We restricted our further analysis to ToM-relevant areas found significantly activated in this first exploratory analysis comparing all ToM conditions to all non-ToM conditions. These hypothesis-driven regions of interest (ROIs) were identified by extracting activated clusters using the MARSBAR tool  . These clusters encompassed significantly activated regions in left TPJ, BA 21,22 (peak voxel at −58 −40 16), left precuneus, BA 7/31 (peak voxel at −6 −54 36), right Insula, BA 13 (peak voxel at 38 −22 24), left anterior cingulate, BA 33 (peak voxel at −2 6 20), right middle temporal gyrus, BA 21/37/39 (peak voxel at 60 −64 6 and 62 −6 16), bilateral inferior frontal gyrus BA 47 (peak voxels at −46 30 −10 and 40 20 −20), left medial frontal gyrus BA 9/10 (peak voxel −2 62 22) and BA 32 (peak voxel −12 16 50) and left superior frontal gyrus, BA 9/10 (peak voxel at −16 53 34). Using the MARSBAR procedure, box-shaped ROIs were refined based on these clusters by applying the end coordinates in the x,y,z dimensions of the activated areas as corner points of the boxes. To compare the different ToM conditions (cooperation, deception, cooperation-deception) with each other, contrasts within the described ROIs were calculated in a first-level single-subject analysis for each of the conditions separately, in each case compared to the overall non-ToM condition, resulting in three basic comparisons per subject. The resulting contrast images were then entered into second-level random-effects group analyses, i.e. into paired   t  -tests, by means of which we calculated direct contrasts between the activation patterns in all three conditions, resulting in six contrasts (DEC vs. COOP; DEC vs. COOPDEC; COOP vx DEC, COOP vs. COOPDEC, COOPDEC vs. DEC, and COOPDEC vs. COOP). Functional imaging results are reported as   t  -scores with a threshold of p<0.02 (uncorrected) and a minimum cluster size of 15 contiguous voxels. In view of the height threshold chosen, a minimum cluster size of 15 voxels was selected in order to further protect against including areas of spurious activation in our analysis. Maxima of significant activation were transformed into Talairach space  , anatomical labelling was performed using the Talairach Demon database  . 

Mean signal intensities (in arbitrary units) were calculated for all conditions using the MARSBAR toolbox for SPM for several regions of interest that showed activation differences between the task conditions. The resulting mean values for the activated regions were entered in an ANOVA (SPSS 11.5) comparison of the different conditions and regions. 


 </div>
</div>
</div>
</div>
</div>
</div>

<footer>
    <p>Generated by Qualitative Review Tool for Meta-Analysis Pipeline</p>
</footer>
</body>
</html>
