<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>False Positives at Fulltext Stage</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        .study {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 20px;
            margin-bottom: 20px;
            background-color: #f9f9f9;
        }
        .metadata, .screening, .content {
            margin-bottom: 15px;
            padding: 10px;
            border-left: 3px solid #3498db;
        }
        .metadata {
            border-left-color: #3498db;
        }
        .screening {
            border-left-color: #e74c3c;
        }
        .content {
            border-left-color: #2ecc71;
        }
        strong {
            color: #2c3e50;
        }
        .study-list {
            margin-top: 20px;
        }
        footer {
            margin-top: 40px;
            text-align: center;
            font-size: 0.9em;
            color: #7f8c8d;
        }
        
        /* Accordion styles */
        .accordion {
            background-color: #f1f1f1;
            color: #444;
            cursor: pointer;
            padding: 10px;
            width: 100%;
            border: none;
            text-align: left;
            outline: none;
            font-size: 14px;
            font-weight: bold;
            margin-top: 10px;
            margin-bottom: 10px;
            border-radius: 4px;
        }
        .accordion:hover {
            background-color: #ddd;
        }
        .accordion:after {
            content: ' \25BC'; /* Down arrow */
            font-size: 10px;
            color: #777;
            float: right;
        }
        .accordion.active:after {
            content: ' \25B2'; /* Up arrow */
        }
        .panel {
            padding: 0 18px;
            background-color: white;
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.2s ease-out;
            border: 1px solid #ddd;
            border-top: none;
            border-radius: 0 0 4px 4px;
        }
        .panel-content {
            padding: 15px;
        }
        .fulltext-content {
            white-space: pre-wrap;
            font-family: monospace;
            font-size: 12px;
            line-height: 1.4;
        }
    </style>
</head>
<body>
<script>
    function toggleAccordion(btn) {
        btn.classList.toggle("active");
        var panel = btn.nextElementSibling;
        if (panel.style.maxHeight) {
            panel.style.maxHeight = null;
        } else {
            panel.style.maxHeight = panel.scrollHeight + "px";
        }
    }
</script>
<h1>False Positives Papers at Fulltext Stage</h1>
<p>Total papers: 76</p>
<div class='study-list'>
<div class='study' id='study-1'>
<h2>1. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/30639176/' target='_blank'>30639176</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Trustworthiness appraisal deficits in borderline personality disorder are associated with prefrontal cortex, not amygdala, impairment</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Neuroimage Clin</p>
<p><strong>Publication Year:</strong> 2018</p>
<p><strong>DOI:</strong> 10.1016/j.nicl.2018.101616</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6411618/' target='_blank'>6411618</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This fMRI study examines social perception (trustworthiness and fear appraisal of faces), which fits the review constructs (Perception and Understanding of Others). It includes a healthy control group of adults (n=17; ages 18–45) with results reported separately alongside a BPD group. The paper reports whole-brain analyses (group-level FEAT mixed-effects analyses in MNI space, whole-brain contrasts and voxel-wise results and cluster thresholds) in addition to ROI analyses; thus it is not limited to ROI-only reporting. The task is a social-related behavioral paradigm completed during fMRI. Therefore all inclusion criteria are met and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
## Background 
  
Borderline Personality Disorder (BPD) is associated with sensitivity to signals of interpersonal threats and misplaced trust in others. The amygdala, an integral part of the threat evaluation and response network, responds to both fear- and trust-related stimuli in non-clinical samples, and is more sensitive to emotional stimuli in BPD compared to controls. However, it is unknown whether the amygdalar response can account for deficits of trust and elevated sensitivity to interpersonal threat in BPD. 


## Methods 
  
Facial stimuli were presented to 16 medication-free women with BPD and 17 demographically-matched healthy controls (total n = 33). Participants appraised fearfulness or trustworthiness of the stimuli while BOLD fMRI was obtained. 


## Results 
  
Though BPD participants judged stimuli as less trustworthy compared to controls, trustworthiness did not correlate with amygdalar activity in either group. Trustworthiness correlated with prefrontal regional activity in the insula and lateral prefrontal cortex. Prefrontal BOLD activity while appraising trustworthiness was smaller in BPD compared to controls, and the size of the reduction was proportional to each participant's response bias. 


## Conclusions 
  
Neural substrates of trustworthiness appraisal are associated with the lateral prefrontal cortex and insula, not amygdala, suggesting that untrustworthy stimuli do not elicit a subcortical threat response. Current models of BPD and its treatment may need to include a focus on improving impairments in frontally mediated trustworthiness appraisal in addition to amygdala- driven emotional hyper-reactivity. 

   Highlights  
  
BPD is associated with sensitivity to signals of interpersonal betrayal and misplaced trust in others. 
  
BPD subjects judged faces to be less trustworthy than controls. 
  
Amygdala activity did not correlate with trustworthiness, but was modulated robustly by fearfulness of the stimulus. 
  
Prefrontal cortex, not amygdala, was modulated by trustworthiness. 
  
BPD was associated with reduced prefrontal activity, and the reduction was proportional to each individual’s response bias. 
  
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (30045 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Heightened sensitivity to threat signals in interpersonal relationships and a misplaced trust in others are common vulnerabilities in Borderline Personality Disorder (BPD) ( ;  ;  ). Individuals with BPD are prone to judge others as more hostile ( ), are more likely to detect anger in ambiguous faces ( ), to recognize angry faces faster than healthy controls ( ), and to exhibit an elevated affective startle reflex ( ). BPD is also associated with greater mistrust of others, characterized by a response bias during trustworthiness appraisal ( ;  ). Furthermore, the emotional valence of a neutral face, i.e., the degree to which the face appears to be happy or angry, influences the visual assessment of trustworthiness in non-clinical individuals and has led to the hypothesis that appraisal of trustworthiness is actually an assessment of interpersonal threat ( ). Thus, greater sensitivity to cues of interpersonal threat in BPD ( ;  ;  ) may explain its association with elevated mistrust of others ( ). 

The neural mechanisms of threat appraisal have been studied extensively, and, it is widely accepted that the amygdala is an integral part of the threat appraisal and response system ( ;  ;  ). The amygdala has also been proposed to be an important structure in the appraisal of trustworthiness ( ;  ;  ;  ). Bilateral lesions of the amygdala result in appraisals of elevated trustworthiness and approachability in both monkeys ( ) and humans ( ). Faces judged to be untrustworthy are associated with greater amygdala activity than trustworthy faces ( ;  ;  ). Furthermore, after interpersonal betrayal, nasally administered oxytocin reduces amygdala activity, and preserves trust and cooperation ( ). These findings suggest that, in non-clinical adults, appraisal of trustworthiness involves the amygdala, and cues of interpersonal threat, such as expressions of anger or aggression, lead to an amygdala-based threat signal. By extension, greater mistrust of others in BPD may plausibly be a consequence of amygdala hyperactivity ( ). In fact, several studies have reported that individuals with BPD exhibit greater amygdala activation to a wide range of interpersonal and emotional stimuli compared to controls ( ;  ;  ;  ), though hypoactivation has also been reported ( ). However, though BPD has been associated with elevated amygdala activity to emotional stimuli and reduced interpersonal trust, a direct link between the elevated amygdala activity and impairment in trustworthiness appraisal has not been established. In the present study, facial expressions were systematically varied along the fearfulness or trustworthiness dimensions, and appraised by a BPD and a healthy control group. We tested the hypothesis that the response bias toward judging faces as untrustworthy, characteristic of BPD, will be correlated with amygdala hyperactivity. We also performed whole-brain analyses to determine whether other regions were related to trustworthiness appraisal deficits in BPD. 


## Methods and materials 
  
### Participant characteristics 
  
All participants were female between the ages of 18 and 45 years; 17 were healthy controls and 16 had a DSM-IV diagnosis of BPD ( ). Participants were recruited via advertisements and referral through a large, metropolitan hospital as part of ongoing clinical studies in mood disorders, suicidal behavior, and BPD. None of those with BPD were taking psychotropic medications while participating in the study, though 60% had a history of use of psychiatric medication. Exclusion criteria for the BPD group included a current major depressive episode, psychotic disorder, current substance use disorder, or a recent suicide attempt (in the last 6 months). The healthy control group was matched on demographics (age, ethnic/racial frequency, marital status), education level, and verbal IQ (the vocabulary subtest of the Wechsler Adult Intelligence Scale)( ), and was assessed with semi-structured interview to rule out a history of psychiatric or substance use disorder. Institutional Review Boards at two institutions approved the study. Fifty-eight participants signed consent, and 43 completed all assessments and the fMRI scan.   summarizes the demographic and clinical descriptions, and Supplementary Table 1 summarizes the clinical diagnoses of the BPD sample. Notably, 37.5% of the BPD group reported past of substance abuse or dependence, 68.8% had a past major depressive disorder, and none had a current or past bipolar or PTSD diagnosis.   
Demographic and Clinical Characteristics. 
  Table 1     


### Clinical assessment 
  
For individuals with BPD and controls, diagnoses were determined by Structured Clinical Interview for DSM-IV, Patient Edition (SCID-I) ( ) and the Structured Clinical Interview for DSM-IV Axis II Personality Disorders (SCID-II) ( ). Reliability studies within our research division yielded the following intra-class correlation coefficients (ICCs) (criterion levels are shown in parentheses): Axis I diagnosis/SCID-I, ICC = 0.80 (0.70); Axis II diagnosis/SCID-II, ICC = 0.70 (0.70); BPD diagnosis, ICC = 0.89 (0.70). Depression severity was assessed using the Hamilton Depression Rating Scale (Ham-D; ( )). Concurrent negative emotional state was assessed with the Profile of Mood States ( ) a 65-item self-report questionnaire that provides a total score of state negative emotion scores based on 6 transient emotional states: tension-anxiety, depression-dejection, anger-hostility, confusion-bewilderment, vigor-activity, and fatigue. Hostility and aggression were assessed using the Buss Durkee Hostility Inventory (BDHI; ( )). Abuse history was assessed as part of the demographic interview, which asks participants whether they have experienced physical and sexual abuse before age 18. We assessed the number of prior suicide attempts from the Columbia Suicide History interview ( ). The Rejection Sensitivity Questionnaire was used to assess anxious anticipation and expectation of interpersonal rejection ( ) (See   for clinical characteristics). 


### Trustworthiness-fear face appraisal task 
  
We utilized a task developed and validated by our group ( ;  ) to measure an individual's capacity to make subtle discriminations between facial features that indicate potential interpersonal threats, expressions of fear and of trustworthiness. Trustworthy faces were male, computer generated avatars selected from the stimuli developed and psychometrically validated by Todorov and colleagues ( ). Facial fear stimuli were selected from the NimStim Face database ( ) and identical to those used in Fertuck et al. ( ). 

Faces at opposite extremes (neutral vs. fearful) or (trustworthy vs. untrustworthy) were morphed together in steps of 10% to create intermediate fear and trust values (Morpher software for Windows, version 3.1, M. Fujimiya). Individuals were presented with faces that varied along the fear or trustworthiness dimensions and asked to judge each face on a five-point Likert scale (where 1 is neutral or trustworthy and 5 is fearful or untrustworthy). (See ( ) for more details on the development of the task and Supplementary Fig. 1 and Supplementary Methods for sample stimuli and further elaboration of the procedure). 

Subjective appraisal parameters were determined by fitting the behavioral data (i.e. rating versus % morph) to a logistic function of the form, (y = α + β/(1+ e ) where x is the morph percentage of the stimulus, y is the mean subjective rating, and the free parameters are α (the offset or bias), β (the scaling or sensitivity), and λ (the slope or discriminability) of the psychometric function. Each participant's responses were checked to confirm that they completed the tasks as instructed (i.e. that subjective responses were not random but showed a monotonically increasing relationship with morph value). From those participants who completed the fMRI task, 2 BPD participants were excluded due to corruption of the data, and 4 BPD and 4 control participants were excluded because their ratings of either the trust or fear stimuli indicated a lack of discrimination between the most and least untrustworthy or fearful stimuli. All results, then, were based on data from 16 BPD patients and 17 healthy controls. 


### Functional imaging 
  
#### fMRI parameters 
  
Functional MRI was performed on a 1.5 Tesla GE Signa scanner using the EPI-BOLD sequence (TR = 2.0, TE = 86, flip angle = 34, number of slices = 27, array size = 64 × 64, voxel size = 3.1 mm × 3.1 mm × 4.0 mm, number of volumes = 150, duration of run = 6 min. Structural scans were performed using the 3D SPGR sequence (124 slices, 256 × 256, FOV = 200 mm). 


#### fMRI data analysis 
  
All analysis was done using the FMRIB Software Library (FSL 5.0.10; ( ) and Matlab 2017a. Preprocessing consisted of motion correction (McFlirt), slice timing correction, high-pass filtering (> 50 s), and spatial filtering (FWHM = 5 mm). Relative head motion of 0.5 mm was set as a threshold and runs exceeding this value were excluded (none reached the threshold). Motion parameters (3 translations, 3 rotations, derivative and quadratic terms; 18 regressors total), CSF and white matter activity were included as confound regressors. Standard statistical parametric mapping techniques (FEAT) were performed in original T2* space. Group analyses were performed using FEAT in MNI152 space at 2 mm isotropic resolution. Voxel-wise activation thresholds were set at p = 0.05, correction for multiple comparisons was done using Gaussian Random Field Theory with a cluster threshold of p = 0.001. A whole brain mask was used to exclude voxels outside the brain. 

For each functional run, a regression model was created assuming three neural processes: (1) an unmodulated process, (2) the subjective appraisal of the stimulus, and (3) the quadratic term of the appraisal. The unmodulated regressor consisted of a set of boxcars in which each boxcar began at stimulus onset and ended when the subject made a response. The height of each boxcar was equal to 1 and represented any task-general activity (e.g. working memory, spatial attention, sensory processing, and other processes) that do not differ between conditions). The appraisal regressor had an identical temporal structure to the unmodulated regressor but the height of each boxcar was proportional to the participant's subjective mean rating of the stimulus for the trust or fear decision. The quadratic regressor used an identical temporal structure to the appraisal regressor but with amplitude generated by demeaning the subject's ratings and taking the absolute value. Trials with response times >2.5 standard deviations outside the mean were excluded from the behavioral and imaging analyses. Each regressor was convolved with a custom HRF, which was individually estimated for each participant from their primary visual activity ( ); custom HRFs have been shown to reduce both model error ( ) and bias ( ) relative to the canonical HRF. A fixed effects (2nd level, within subject) and a mixed-effects (3rd level, between subjects) analysis was done to compare patients with controls for the trust and fear appraisal regressors. We performed two ROI analyses of the amygdala. First, we created a mask by searching the Neurosynth database ( ) using the keyword “threat”. The reverse inference map was thresholded at 7 and binarized resulting in a bilateral amygdala mask positioned primarily over the lateral nuclei of the amygdala (MNI: −22, −2, −20; 24, −4, −20). A second analysis was performed subject-specific masks of threat-sensitive voxels. These voxels were identified as voxels modulated by subjective appraisal of fearfulness, thresholded at >1.6) and intersected with a whole amygdala mask. Both the Neurosynth mask and the subject-specific mask were used to average the parameter estimates of the masked voxels during trustworthiness appraisal. The Kolmogorov-Smirinov Test was used test for deviations from Normality for all   t  -tests (Supplementary Results). Cohen's D (  d  ) was computed as the group mean divided by sample standard deviation. 


#### Assumptions 
  
Our goal was to determine whether subjective appraisal of trustworthiness depends on threat signals generated by the amygdala. We assumed that fearfulness appraisal elicits threat signals in the amygdala and that any activity in the amygdala that increased with untrustworthiness would also represent a threat signal. Given these assumptions, if our paradigm could generate threat signals in the amygdala using fearful stimuli, it should also be able to generate amygdala threat signals using untrustworthy stimuli. Furthermore, since BPD is associated with elevated sensitivity to social threat and a bias toward judging others as untrustworthy, BPD subjects should show elevated threat activity in the amygdala compared to controls using untrustworthy stimuli. 




## Results 
  
Consistent with our previous study ( ), the BPD group showed a response bias to judge faces as untrustworthy (  t  -test of bias: control, M = 1.6, SD = 0.15; BPD, M = 2.1, SD = 0.16, t(28) = 2.44, z = 3.23, p = 0.02) and had a smaller dynamic range, or, sensitivity (t-test for scale: control, M = 3.08, SD = 0.41; BPD, M = 1.71, SD = 0.23, t(28) = 2.8, z = 3.98, p < 0.01). Trustworthiness appraisal did not result in significant group differences in discriminability ( ). Appraisal of fearfulness did not show any significant group differences for bias (p = 0.47), sensitivity (p = 0.14), or discriminability (p = 0.49). An analysis of variance showed that the BPD group exhibited longer RTs than controls ( ) for trustworthiness (rating, p = 0.002; group, p < 0.0001) and fearfulness (rating, p < 1 × 10 ; group, p = 0.007), and no significant interactions.   
Appraisal of trustworthiness and fearfulness. (A) For both tasks, participants demonstrated categorical judgments (i.e. a sigmoidal, monotonically increasing relationship). Behavioral responses were fit with logistic functions using three parameters: offset, scale, and slope. A comparison of the three parameters showed that, consistent with our previous work, the offset parameter in the trustworthiness task was significantly higher in the BPD group, indicating a bias toward judging others as “untrustworthy.” In addition, the scale parameter was smaller for BPD than controls, indicating a reduced dynamic range of responses. Remaining parameters for the two tasks were not significantly different. (B) Response times were greater for patients than controls on both tasks (ANOVA). 
  Fig. 1   

To identify the neural structures associated with the two types of appraisals, we performed a whole brain analysis, regressing the appraisal ratings made by each subject on the BOLD data. Consistent with most fMRI studies of fear processing ( ;  ), both amygdalae were robustly modulated by subjective appraisals of the fearful stimuli – BOLD magnitude increased as a function of the subjective rating of intensity of the stimulus ( A; peak response, MNI: 24, −8, −14, Z = 3.83; −24, −4, −14, Z = 3.56; Supplementary Table 2). If the threat-related cues detected by the amygdala are also important for trustworthiness appraisal, then amygdala activity should be modulated by trustworthiness. However, the whole brain analysis showed no activity in the amygdala that was significantly modulated by stimulus trustworthiness ( B; Supplementary Table 2).   
Monotonically increasing activity. (A) Robust, bilateral activation of the amygdala increased with fearfulness of the stimulus across all participants. A similar, monotonically increasing relationship with untrustworthiness was not present. (B) For each subject, a mask was created representing voxels sensitive to fearfulness within the amygdala and the mean of the parameter estimates was computed. No significant relationship for trustworthiness was present for control or BPD participants, suggesting that untrustworthy stimuli do not produce an amygdala-based fear response. Finally, during trustworthiness appraisal, amygdala activity in BPD participants showed a small, but significant, reduction of response, contrary to the amygdala hyperactivity found in previous BPD studies. 
  Fig. 2   

Averaging across voxels can improve the signal to noise ratio; thus, we performed an ROI analysis of the amygdala using a mask generated on Neurosynth using the keyword “threat”. In healthy controls, the mean activity of voxels within the mask showed robust amygdala modulation by subjective fear ratings (p = 0.01, d = 0.70) but contrary to previous work ( ;  ), no significant modulation by subjective trust ratings (p = 0.33, d = 0.25). In the BPD group, no significant activity was detected either by fear (p = 0.33, d = 0.25) or trust (p = 0.56, d = −0.15) ratings. Since BPD is associated with elevated sensitivity to interpersonal threats ( ;  ), if the amygdala were sensitive to untrustworthiness, then BPD subjects should show greater amygdala activation than controls as the stimuli become less trustworthy. However, a comparison of the two groups showed no significant difference between groups for trust (p = 0.26, d = 0.40) or fear (p = 0.33, d = 0.35).  .   
Quadratically modulated activity. (A) A weak, but significant, quadratic relationship with fearfulness was present in the amygdala. Some voxels with a quadratic relationship to trustworthiness were detected on the striatum-amygdala and csf-amygdala boundaries, though the peak responses of these clusters were outside the amygdala. (B) Using an amygdala mask, the mean response was quadratically related to fearfulness, but not trustworthiness. 
  Fig. 3   

Previous studies have suggested that the effect of trustworthiness appraisal on amygdala activity in healthy controls is best described by a quadratic relationship ( ), ( ;  ). Though our controls showed a significant quadratic relationship for fear (p = 0.04, d = 0.53), no significant quadratic relationship for trust (p = 0.80, d = 0.06) was found. In the BPD group, the quadratic model was not significant for fear (p = 0.68, d = 0.18), but was significant for trust (p = 0.02, d = 0.65). 

To determine whether the two tasks activate similar brain networks, we compared whole-brain activations ( A). Fearfulness appraisal activated primarily sub-cortical regions, whereas trustworthiness appraisal was associated primarily with cortical activity. To dissociate activity specific to fearfulness and trustworthiness appraisal from general decision-making activity related to stimulus intensity, we performed a contrast between task conditions (contrasting fearfulness > trustworthiness and trustworthiness > fearfulness on the appraisal regressor;  B). Using a cluster threshold of p = 0.001, fearfulness > trustworthiness did not result in significant activations. However, because the amygdala nuclei are small structures, p = 0.001 may result in elevated Type II error in subcortical structures. At a cluster threshold of p = 0.05, fearfulness-specific activity was localized to subcortical regions, i.e., amygdala and ventral striatum (peak response, MNI: 22, −6, −8), consistent with the previous ROI analysis (i.e.  ). Moreover, even at a more liberal threshold, no fearfulness-specific activity in the cortex was detected. In contrast, trustworthiness-specific activity was present only in cortical regions, broadly distributed across posterior parietal cortex, and dorsolateral and mediolateral prefrontal cortex, and no spatial overlap of amygdala (Supplementary Table 3).   
Whole brain comparison. (A) A whole-brain analysis demonstrates that the monotonic fearfulness response activates primarily subcortical structures i.e. amygdala and ventral striatum, whereas, the trustworthiness response was primarily cortical. (B) To identify activity unique to fearfulness and trustworthiness, and not to general decision processes common to both tasks, fearfulness > trustworthiness and trustworthiness > fearfulness contrasts were performed. Fearfulness-specific activity was localized to amygdala, ventral striatum, and left frontal pole. There was no trustworthiness-specific activity in subcortical structures. 
  Fig. 4   

Because BPD is associated with behavioral abnormalities in trustworthiness appraisal, we hypothesized that the trustworthiness-specific network (i.e. trustworthiness > fearfulness) would show activity differences between BPD and control subjects. We, thus, performed the following contrast: (trustworthiness > fearfulness)  > (trustworthiness > fearfulness) . BPD participants had lower trustworthiness-specific activity in prefrontal cortex ( A), especially anterior insula and lateral PFC (Supplementary Table 3). Finally, to determine whether these group differences were related to individual subjects' decision variables, we intersected voxels that showed activity specific for trustworthiness appraisal ( B, trustworthiness > fearfulness) with voxels that differed between groups (5A, (trustworthiness > fearfulness)  > (trustworthiness > fearfulness) ) and compared them to individual differences in response bias and sensitivity. The anterior insula and lateral PFC ( B) activity was related to the degree of bias (  r   = 0.457, p = 0.007) and sensitivity (  r   = 0.597, p = 0.0005) impairment in trustworthiness appraisal ( C), such that, the weaker the network activity, the greater the bias toward untrustworthy ratings and the smaller the range of responses.   
BPD-related deficits. (A) BPD participants showed reduced trust-specific activity in the anterior insula and lateral prefrontal cortex. (B) The intersection of voxels that were sensitive to trustworthiness and significantly reduced in BPD localized to anterior insula and lateral prefrontal cortex. (C) These intersecting voxels were negatively related to bias (i.e. the greater the bias toward mistrusting others, the larger the reduction in activation) and positively correlated to scale (i.e. the smaller the dynamic range of responses, the larger the reduction in activation). Dashed lines represent 95% confidence interval. 
  Fig. 5   


## Discussion 
  
The amygdala is an integral part of the threat detection system in humans ( ;  ;  ), and to the extent that untrustworthy faces represent interpersonal threats, investigators have argued that the amygdala is integral to the appraisal of trustworthiness in non-clinical adults ( ;  ;  ). Furthermore, individuals with BPD have been shown to have response biases toward mistrusting others ( ;  ;  ) and hyperactive responses of the amygdala to emotional stimuli ( ;  ;  ;  ). Our goal was to test whether amygdala hyperactivity could explain the response biases in BPD during the appraisal of trustworthiness ( ;  ;  ). Surprisingly, we found no relationship between trustworthiness appraisal and amygdala activity, and no difference in amygdala activity between BPD and control participants. Instead, trustworthiness appraisal deficits in BPD were associated with blunted prefrontal activity in anterior insula and lateral PFC compared to controls. 

Evidence that trustworthiness activates the amygdala has been inconsistent. Studies that categorically compared trustworthy versus untrustworthy stimuli typically find greater amygdala responses to untrustworthy faces ( ;  ;  ;  ). Similarly, some parametric studies have demonstrated that amygdala activity increases monotonically with untrustworthiness ( ;  ). However, others found a quadratic, not monotonic, relationship, between trustworthiness and amygdala responses ( ;  ). Contrary to these previous studies, we found no evidence that amygdala activity increases monotonically or quadratically with untrustworthiness in healthy controls. This lack of response was not due to sensitivity of our behavioral paradigm. In fact, consistent with our previous studies ( ;  ;  ), our behavioral data showed a sigmoidal relationship between stimulus and response, and a response bias in BPD for judging stimuli as less trustworthy, but not more fearful. Moreover, the trustworthiness-stimuli were psychometrically discriminable by both groups with a dynamic range similar to the fearful stimuli and the fearful stimuli elicited robust, bilateral amygdala responses that scaled parametrically with subjective intensity. This suggests that if trustworthiness decisions depended on threat-related amygdala activity, modulation of amygdala by trustworthiness would have been detectable with our paradigm. 

Previous parametric studies focused mostly on “implicit,” or sub-conscious, processing of trustworthiness, distracting subjects from the trustworthiness dimension with an irrelevant task ( ;  ;  ) or using very short (200 ms) stimulus durations ( ). While implicit trustworthiness processing is commonly referred to as “trustworthiness decisions,” it is not clear that any amygdala activity that is correlated with trustworthiness, but also lacks an associated behavioral response, actually represents a decision process. Instead, this activity is more likely to be related to low-level, perceptual processing ( ;  ;  ;  ;  ;  ;  ). In fact, trustworthiness has been shown to be decomposable into two perceptual factors – dominance and emotional valence, where emotional valence is expressed as facial features ranging from happy to angry ( ;  ). However, while anger has been shown to represent a cue for untrustworthiness, a meta-analysis of 105 imaging studies has not found it to reliably activate the amygdala ( ). Moreover, because the amygdala generally responds to emotional faces ( ), even at sub-threshold levels ( ;  ;  ;  ;  ;  ;  ), the implicit or rapid processing of trustworthiness by the amygdala may actually reflect the emotional valence detectable in the stimulus rather than the appraisal of trustworthiness per se. 

Facial cues associated with low trustworthiness are not necessarily reliable or immediate expressions of threat, compared to reliable cues such as an image of a snake or a pointed gun. Rather, trustworthiness appraisal may be better conceptualized as a probabilistic prediction about the likelihood of interpersonal betrayal or exploitation by others. Probabilistic reasoning, especially in social contexts, has been associated with prefrontal cortical processing ( ;  ;  ). Our results show that trustworthiness is mediated by prefrontal cortical (posterior parietal cortex, anterior insula, and lateral PFC) activity and that trustworthiness appraisal deficits in BPD are also mediated by the same regions. 

The trustworthiness appraisal impairments identified here may help elucidate mechanisms of turbulent relationships in BPD. Individuals with BPD maintain unstable interpersonal ties, as they oscillate between establishing new relationships and ending them ( ). Some of the most high risk diagnostic criteria of BPD such as self-injury, suicidality, intense and inappropriate anger, impulsivity, and heightened emotional sensitivity are mediated by the quality of interpersonal bonds between the person with BPD and significant others ( ). Facial expressions within in interpersonal contexts are salient stimuli, and can anticipate mistrust and the expectation of rejection ( ;  ;  ;  ). Consequently, the trustworthiness appraisal impairments in BPD can increase their propensity interpersonal conflicts, lead to uncooperative exchanges in social interactions, threaten the formation of new relationships, and undermine long-term relationships. The trustworthiness discriminability impairment mediated by prefrontal cortex processes may help clinicians to understand commonly observed interpersonal dynamics in BPD. For instance, individuals with BPD often reflexively enter into new relations with questionable partners, while simultaneously expressing extreme caution and suspiciousness toward presumably helpful and supportive others. 

Improving accurate appraisal of trustworthiness in interpersonal and therapeutic relationships in BPD may be crucial to therapeutic improvement, and dissociating the roles of prefrontal cortex and amygdala in trustworthiness appraisal may aid in sharpening intervention targets. Prominent, evidence-based therapies for BPD such as Transference Focused Psychotherapy (TFP, ( )) and Mentalization-Based Therapy (MBT, ( )), focus implicitly and explicitly ( ) on enhancing trustworthiness appraisal by fostering frontally-mediated social reappraisal processes. However, there may yet be untapped strategies and interventions that those with BPD, such as improving accurate probabilistic reasoning around trustworthiness appraisals. 

### Limitations 
  
Without a psychiatric control group, the specificity of the trustworthiness impairment findings has yet to be established. However, we have published work using the same trustworthiness and fear tasks in a PTSD sample compared to a trauma-exposed/no PTSD control group and a healthy control group. The PTSD group showed a response bias toward judging stimuli as more trustworthy compared to the trauma-exposed controls ( ). This is opposite to our BPD findings, which show a bias toward less trustworthy appraisals, and suggests some clinical specificity of our results. Finally, although our BPD sample has relatively few co-morbidities, the mean Global Assessment of Functioning (GAF) score of the group was 55.12, consistent with multi-site, longitudinal studies of BPD ( ) and suggesting that our BPD group had comparable severity of illness. 


### Conclusions 
  
In summary, we found no evidence of amygdala hyperactivity in BPD subjects during appraisal of trustworthiness. Our results show, however, that trustworthiness biases in BPD involve higher order prefrontal cortical regions. 

Additionally, further study is needed to clarify impact of emotional expressions (e.g., appraisal of anger in facial stimuli may overlap with untrustworthiness perception) on trustworthiness appraisal and amygdala activity in BPD and comparison groups. 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-2'>
<h2>2. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31593216/' target='_blank'>31593216</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> A look at actions: direct gaze modulates functional connectivity of the right TPJ with an action control network</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Soc Cogn Affect Neurosci</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1093/scan/nsz071</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6917026/' target='_blank'>6917026</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social gaze processing (social perception/understanding of others) while participants performed a social-related task (responding to virtual characters’ gaze shifts). Sample: healthy adults (n=30 after exclusions), age range 19–41, meeting the required age group. The authors report whole-brain analyses (GLM second-level flexible factorial with cluster-forming p<0.001 and FWE cluster correction p<0.05) for main effects and interactions. They also conducted a psychophysiological interaction analysis (gPPI) with FWE voxel-level correction; although a seed was used, whole-brain/main effects are reported and ROI-only reporting is not the sole analytic approach. No results are reported exclusively for clinical groups. Therefore all inclusion criteria are met and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>   ABSTRACT  
Social signals such as eye contact and motor actions are essential elements of social interactions. However, our knowledge about the interplay of gaze signals and the control of actions remains limited. In a group of 30 healthy participants, we investigated the effect of gaze (direct gaze   vs   averted) on behavioral and neural measures of action control as assessed by a spatial congruency task (spatially congruent   vs   incongruent button presses in response to gaze shifts). Behavioral results demonstrate that inter-individual differences in condition-specific incongruency costs were associated with autistic traits. While there was no interaction effect of gaze and action control on brain activation, in a context of incongruent responses to direct gaze shifts, a psychophysiological interaction analysis showed increased functional coupling between the right temporoparietal junction, a key region in gaze processing, and the inferior frontal gyri, which have been related to both social cognition and motor inhibition. Conversely, incongruency costs to averted gaze were reflected in increased connectivity with action control areas implicated in top-down attentional processes. Our findings indicate that direct gaze perception inter-individually modulates motor actions and enforces the functional integration of gaze-related social cognition and action control processes, thereby connecting functional elements of social interactions. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (33873 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
The interdependency of gaze processing and motor actions plays a key role in our everyday social interactions. Underlining their joint functioning, empirical studies have revealed a strong overlap between brain areas that process hand and gaze movements (e.g.  ). Furthermore, it has been shown that social gaze impacts goal-directed movement precision ( ) as well as reaction speed ( ;  ). The latter, however, could not be observed in individuals with autism spectrum disorder ( ), who are also characterized by abnormalities in motor behaviors as well as the processing of eyes and observed movements ( ;  ). 

In social interactions, a specific role needs to be attributed to the perception of direct gaze, which reflexively attracts attention ( ;  ). Crucially, direct as compared to averted gaze has been described as a signal that conveys the intention to interact ( ). In line with this, empirical evidence suggests a facilitation effect of direct gaze on imitative behavior ( ;  ) as well as an attentional effect of gaze cues on manual responses to target stimuli ( ;  ). Yet, besides imitation and beyond attentional guidance of gaze, social interactions might require re-actions to gaze movements that are compatible but not identical with observed actions ( ). Still, how gaze interacts with action control processes on the behavioral and brain level and how the specific gaze context modulates functional connectivity between gaze and action control areas, particularly when tendencies towards spatial congruency need to be suppressed, remains unclear. Therefore, we systematically investigated how the perception of direct or averted gaze affects action control in the context of an fMRI-compatible and previously established spatial stimulus-response compatibility (SSRC) paradigm ( ;  ). Instead of using social and non-social stimuli as in previous studies, we realized a 2 × 2 factorial design by asking participants to generate button presses in a spatially congruent or incongruent manner (factor congruency: CON   vs   INCON) in response to gaze shifts produced by an anthropomorphic virtual character (VC), whose initial gaze position was either direct or averted (factor gaze: direct   vs   averted). As dependent variables, we measured task performance (accuracy) and reaction time (RT) as well as brain activity obtained via BOLD fMRI. 

In line with empirical evidence, incongruent compared to congruent reactions incur increased computational load and thus, lead to prolonged RTs and a decreased percentage of correct responses ( ;  ). Additionally, the incongruency effect should be reflected in an increased activation in a bilateral dorsal fronto-parietal network of frontal motor areas and superior parietal lobules, a network responsive to increased top-down attentional demands and need for increased action control ( ;  ). For the main effect of direct compared to averted gaze, we hypothesized brain regions sensitive to eye contact and gaze-related movements ( ;  ), namely the temporoparietal junction/posterior sulcus temporalis superior (TPJ/pSTS) and the fusiform gyrus, to show increased BOLD signal in response to direct gaze stimuli ( ;  ;  ). 

The main focus of this study was to investigate the interaction between the perception of gaze and mechanisms of action control. While some evidence suggests a general facilitation effect of direct gaze ( ,  ), in other studies, an association of direct gaze and accelerated reactions has only been found for compatible stimulus-response mappings ( ;  ;  ). On the brain level, both motor control areas such as the inferior frontal cortex as well as the gaze sensitive TPJ have been implicated in the interaction of gaze and motor control processes ( ;  ). Building on this, the present study tested whether the same brain regions are differentially recruited as representations of gaze-dependent incongruency costs. Furthermore, in light of evidence that indicates gaze-dependent functional connectivity changes of the TPJ/pSTS with an extended gaze perception network ( ) as well as multi-modal functional coupling of the right TPJ ( ), we expected gaze and action control networks to interact at the level of right TPJ connectivity, reflecting a differential integration of gaze-related and action control processes. Thus, in order to systematically investigate the relationship of gaze-specific incongruency costs in terms of functional connectivity, we conducted a psychophysiological interaction analysis and analyzed whether the interplay of the gaze context and action control demands modulates the functional connectivity between the right TPJ and an ‘action control network’, being composed of all action-associated brain regions as defined by a Neurosynth ( ) search including the search term ‘action’. In a context of direct gaze and an increased demand for action inhibition due to spatial incongruence, we expected to see increased functional coupling between our seed region, which was located in a functional cluster that has been related to social cognition ( ), and particularly the IFG, indicating an integration of gaze-related social cognition and action control ( ;  ;  ). 

In light of autism-related differences observed in the original version of our SSRC task ( ), we further obtained measures of autistic traits and hypothesized to replicate a positive relationship between autistic traits and gaze-specific incongruency costs. 


## Methods 
  
Thirty-two volunteers (15 females) participated in our study. Due to neurological and psychiatric conditions (sleeping disorder, ventricumegaly), two participants were excluded from all further analyses. The remaining 30 participants (14 females) had a mean age of 24 (s.d. = 5.08, range = 19–41), normal or corrected-to-normal vision, no history of neurological or psychiatric history and were right-handed as assessed by the Edinburgh Handedness Inventory ( ). The mean group autism quotient (AQ) ( ) was 14.99 (s.d. = 6.38, range = [6, 32]). All participants gave informed written consent and received a fixed monetary compensation of 30€. At the end of the experiment, participants were debriefed and thanked for their participation. The study protocol followed the guidelines of the Declaration of Helsinki and was approved by the ethics committee of the Ludwig-Maximilians-Universität München. 

### Experimental design and procedure 
  
The paradigm used in this fMRI study resembled an adapted version of previously used SSRC paradigm ( ;  ). Instead of asking participants to respond to the gaze movement of an anthropomorphic VC or the movement of a geometric symbol as in previous studies, VCs were always present. This allowed us to keep the social stimulus constant while now systematically manipulating exposures to direct compared to averted gaze. 
  
Experimental task. (  A  ) One of two female VCs demonstrating direct gaze in the congruent condition [indicated by the initial cue ‘GLEICH’ (German for ‘same’)]. The first gaze shift to the left requires a congruent left button press, the second gaze shift to the right a right button press. (  B  ) One of two male VCs demonstrating averted gaze in the incongruent condition [indicated by the initial cue ‘GEGEN’ (German for ‘opposite’)]. The first gaze shift to the left requires an incongruent right button press, the second gaze shift to the right a left button press. 
  
Before the experiment and before entering the fMRI scanner, participants received detailed instructions on the overall procedure and MRI safety. During the experiment, they were asked to respond as fast as possible to gaze shifts shown by the VC by pressing a right or left button using the right or left index finger, respectively. The experiment consisted of 24 blocks of 12 events each with 50% left- and 50% right-directional gaze shifts, realizing a 2 × 2 factorial design: congruent blocks were instructed by the initial cue ‘GLEICH’ (German for ‘same’) and required participants to respond to gaze shifts in a spatially compatible manner, i.e. pressing the ipsilateral button. The initial cue ‘GEGEN’ (German for ‘opposite’) introduced blocks of spatially incompatible responses, where participants had to press the contralateral button in response to a gaze shift, for instance the right button had to be pressed following a gaze shift to the left ( ). Each cue was presented once for 1500 ms at the beginning of each block of 12 gaze shifts and each block was followed by a jittered inter-stimulus interval of 15 to 17 s. During the experiment, participants did not receive any feedback on their performance. Besides the factor ‘congruency’, our second experimental factor ‘gaze’ was expressed by the VC either looking up (averted gaze) or facing the participant (direct gaze). Pixel coordinates and the timing of gaze shifts were identical over all conditions. In each block, male participants experienced one of two male VCs while female participants were confronted with one of two female VCs. The appearance of either of the two same sex VCs was equally likely. Stimuli were presented through the software package Presentation (Neurobehavioral Systems, Inc.; Version 18.1) on an fMRI compatible computer monitor (refresh rate = 59 Hz, resolution of 1024 × 768, viewable region of 500 mm × 380 mm) and were created manually in Poser 10 (Smith Micro Software, Inc., CA, USA). As stimuli of the present study differed from stimuli of previous studies, a pre-study was conducted to control for unbalanced stimuli preferences. Twelve volunteers (employees, 8 females) from the Max Planck Institute of Psychiatry rated all four VCs on a five-level Likert scale on attractiveness, valence, arousal and other characteristics (Supplementary Table S1). A repeated measures ANOVA using stimulus type (VC 1–4) and characteristics (Supplementary Table S1) revealed no significant effect of stimulus type (  F  [1,11] = 0.94,   P   = 0.43) or interaction effect on VC ratings,   F  (1,11) = 1.15,   P   = 0.10. All volunteers correctly indicated whether the VC demonstrated direct or averted gaze and whether the gaze was directed to the left or right. 


### Behavioral and questionnaire data preprocessing 
  
RTs, the dependent variable that expressed the behavioral outcome of action control, reflected the time frame between the onset of the gaze shift and the button press of the participant. We applied the following RT data preprocessing steps (e.g.  ;  ): trials with no answer, multiple answers or incorrect answers were categorized as error trials. Further, trials with responses two standard deviations from the participant-specific mean RT over all conditions were interpreted as anticipation error or missed response and also labeled as error trials. In total, 9.4% of all trials were error trials. In order to exclude uninformative task blocks, e.g. blocks in which participants missed the initial instructive cue, blocks with more than 25% error trials (> = 3 error trials/block) were not considered in subsequent analyses, resulting in an average exclusion of one block per participant (Supplementary Table S2 for details). Task performance reflected the mean percentage of correctly answered trials of all correct and error trials, which was calculated for each combination of experimental conditions. The AQ of participants was assessed in order to evaluate the relationship of autistic traits and gaze-specific incongruency costs. To conserve comparability of AQ scores, missing values (four participants did not fill in one item each) were interpolated over the individual sub-scale values of the respective item filling in the missing data point. 


### Behavioral data analyses 
  
Main effects and interaction effects of experimental conditions on task performance and RTs were tested by means of repeated measures 2 (gaze: direct   vs   averted) × 2 (congruency: congruent   vs   incongruent) ANOVAs. To test whether direct gaze modulates responses in the congruent or incongruent condition, we implemented post-hoc contrasts of conditions (direct_CON   vs   averted_CON; direct_INCON   vs   averted_INCON) as Bonferroni corrected paired two-sided   t  -tests. After calculating the RT incongruency costs, i.e. RT slowing in incongruent compared to congruent trials, we obtained the difference in RT incongruency costs between the direct and averted gaze condition (incongruency costs direct—incongruency costs averted) as a measure of direction and size of effect of gaze on RT incongruency costs. To further analyze the relationship of the difference in RT incongruency costs between the direct and the averted gaze condition, we correlated the measure with AQ scores. Here, due to non-normally distributed AQ scores (Shapiro–Wilk statistic = 0.93,   P   < 0.05), the non-parametric two-sided Spearman’s rank correlation statistic was used. 



## fMRI data analysis 
  
Participants completed the experiment inside a 3T MR scanner (MR750, GE, Milwaukee, USA). The procedure comprised a single functional run of 290 volumes of 40 slices (32-channel head coil, AC-PC-orientation, 96 × 96 matrix, 3 × 3 mm voxel size, 3 mm slice thickness, 0.5 mm slice gap). First, structural T1-weighted images were acquired [BRAVO FSPGR pulse sequence, 1 mm isotropic voxels, repetition time (TR) of 6.2 ms, echo time (TE) of 2.3 ms]. Second, during the experiment, T2 -weighted functional images were obtained by means of gradient echo planar imaging (TR of 2000 ms, TE of 20 ms, 90° flip angle) and the first four functional volumes we removed to control for non-equilibrium effects. FMRI data preprocessing and analysis were performed in SPM12 (Statistical Parametric Mapping Software, Wellcome Department of Imaging Neuroscience, London;   http://www.fil.ion.ucl.ac.uk  ) and included the following steps: functional images were spatially realigned to the mean functional image (rigid body transformation). Next, functional and structural images were co-registered. Both structural and functional images were spatially normalized to the Montreal Neurological Institute (MNI) template using tissue segmented T1-weighted anatomical images (BRAVO FSPGR pulse sequence, 1 mm isotropic voxels, TR of 6.2 ms, TE of 2.3 ms). Functional images were resliced to 2 × 2 × 2 mm voxel size. Finally, a 3D Gaussian Kernel with full width of half maximum of 8 mm was used for smoothing. 

All valid experimental blocks (RT data preprocessing) were modeled as epochs in a general linear model (GLM) with an average duration of 54 s (range 46–64 s). Experimental factors, i.e. ‘gaze’ (direct   vs   averted gaze) and ‘congruency’ (congruent   vs   incongruent) were captured in four different regressors of interest. Error blocks were modeled by a regressor of no interest. Our GLM design matrix further contained 26 confound regressors of no interest: the first 24 contained six z-standardized rigid body motion realignment parameters, their temporal derivatives and the squared values of both realignment parameters and derivatives ( ). Another two regressors captured confounding signal from white matter and cerebrospinal fluid. Here, we obtained a binarized mask from the respective segmented individual structural images using a 0.95 threshold in SPM’s image calculator (imcalc tool) and calculated the first principal component of the respective tissue type, explaining 85.42% (s.d. = 4.28%) and 79.11% (s.d. = 5.85%) of variance in the signal ( ). No global scaling was applied and low-frequency signal drifts were filtered out (128 s cutoff period). In order to correct for temporal autocorrelation of the data, voxel-wise maximum likelihood estimators were calculated ( ). 

Studying the effect of congruency and gaze as well as their interaction, BOLD signal during main effects and interactions of conditions were analyzed in a second-level flexible factorial design. A binarized group-specific explicit grey matter (GM) mask (sum of participant specific probability of GM > 0.05; imcalc tool) contained all voxels of interest. Besides our two experimental factors, we added a ‘subject’ factor, accounting for subject-specific heteroscedasticity, and implemented SPM’s default settings of unequal variances within each factor. In order to analyze the main effects of congruency and gaze, we contrasted congruent and incongruent as well as direct and averted gaze conditions [congruency: (direct_CON + averted_CON) > (direct_INCON + averted_INCON), (direct_INCON + averted_INCON) > (direct_CON + averted_CON); gaze: (direct_CON + direct_INCON) > (averted_CON + averted_INCON), (averted_CON + averted_INCON) > (direct_CON + direct_INCON)]. Statistical interactions of conditions were modeled as contrast of incongruency costs in the direct and averted gaze conditions [IA1: (direct_INCON > direct_CON) > (averted_INCON > averted_CON), IA2: (averted_INCON > averted_CON) >(direct_INCON > direct_CON)]. 
  
Behavioral measures  .   (  A  ) Mean percentage of correct responses and (  B  ) left panel: mean RTs; right panel: mean RTs for direct and averted gaze in the congruent condition. Light blue lines mark a decrease in RT from direct to averted; dark blue lines mark an increase. The light blue solid line represents the mean decrease in RTs from the direct to the averted gaze condition. Black horizontal lines represent the mean values, boxes represent the standard error of the mean (SEM), blue vertical lines the standard deviation (s.d.). 
  
Moreover, we conducted a generalized condition-specific psychophysiological interaction analysis ( ) to investigate the context-dependent functional coupling between gaze and action processing areas. Based on the available literature and a term-based meta-analysis in Neurosynth ( ), we identified a region typically labelled as right TPJ ( ) as the seed region for our gPPI analysis. The coordinates of our seed region [44, −52, 12] represented the peak coordinates in the brain map of the term ‘gaze’ (retrieved 2 October 2018 from   www.neurosynth.org  , z-score = 7.33) and were further situated in a functional sub-section of the right TPJ involved in social cognition ( ; Neurosynth, retrieved 3 June 2019, meta-analytic association of peak coordinates with terms ‘default network’, ‘mentalizing’). After creating a sphere of 6 mm radius in marsbar ( ; Supplementary Figure S1A), we extracted the first eigenvariate of our seed sphere and allowed actual ROIs to vary in size between participants, but restricted them to first level masks generated by SPM12. In order to investigate the context-dependent functional coupling of our right TPJ seed with brain areas involved in action control, we retrieved an associative ‘action’ mask from Neurosynth ( : retrieved 2 October 2018 from   www.neurosynth.org  ). After smoothing (3D Gaussian Kernel with full width of half maximum of 4 mm) and binarization (imcalc, i1 > 0.1, Supplementary Figure S1B), it was implemented as explicit mask in our second level analysis. Specifically, we were interested in the functional coupling of the right TPJ and the action network for the statistical interactions of our experimental conditions [IA1: (direct_INCON > direct_CON) > (averted_INCON > averted_CON)] and [IA2: (averted_INCON > averted_CON) > (direct_INCON > direct_CON)]. 

Statistical maps of the activation analysis are shown at a cluster-forming threshold of   P   < 0.001 (uncorrected) and a cluster threshold of   P   < 0.05 (FWE). In the psychophysiological interaction analysis,   P  -values were thresholded at   P   < 0.05 (FWE) at voxel level. The Anatomy Toolbox ( ; Version 2.2c) and the AAL atlas in MRIcron ( ) were used for functional localization and the Surf Ice software for brain visualizations (  https://www.nitrc.org/projects/surfice/  ). 


## Results 
  
### Behavioral results 
  
As expected, a repeated measures ANOVA focusing on the condition-specific performance revealed a significant main effect of congruency on the percentage of correct responses,   F  (29,1) = 32.09,   P   < 0.001, η  = 0.53. There was no main effect of gaze [  F  (29,1) = 1.80,   P   = 0.19, η  = 0.06] or an interaction effect of congruency and gaze on performance,   F  (29,1) = 1.27,   P   = 0.27, η  = 0.04 ( ). 

A second repeated measures ANOVA demonstrated a significant main effect of congruency also on RTs,   F  (29,1) = 134.71,   P   < 0.001, η  = 0.82. Neither did gaze impact participants’ RTs [  F  (29,1) = 1.30,   P   = 0.26, η  = 0.04] nor did the interaction effect of experimental conditions reach significance,   F  (29,1) = 3.88,   P   = 0.06, η  = 0.12 ( ). Post-hoc contrasts showed that congruent RTs were significantly higher in the direct gaze compared to the averted gaze condition,   t  (29) = 2.86,   P   < 0.01, R  = 0.22. Incongruent RTs, however, did not differ between gaze conditions,   t  (29) = 0.17,   P   = 0.87.   presents the condition-specific performance and RTs. 
  
Condition-specific RTs and accuracy. Brackets contain the standard deviation (s.d.). 
  
Condition-specific RT incongruency costs, i.e. the increase in RTs in incongruent compared to congruent trials, are displayed in  . On average, RTs of incongruent reactions increased by 48 ms (s.d. = 27 ms) in the direct gaze condition and by 56 ms (s.d. = 27 ms) in the averted gaze condition. Building on this, a two-sided Spearman’s rank correlation analysis indicated a significant negative correlation between AQ scores and the difference in RT incongruency costs for direct as compared to averted gaze,   rs  (28) = −0.40,   P   < 0.05 ( ). 
  
Condition-specific RT incongruency costs. Boxes represent the SEM. 
    
Linear association of AQ scores and the difference in RT incongruency costs (ranks) between experimental conditions (direct—averted). 
  

### fMRI results 
  
Applying a cluster-forming threshold of   P   < 0.001 (uncorrected) and a cluster threshold of   P   < 0.05 (FWE), incongruent contrasted to congruent trials [(direct_INCON + averted_INCON) > (direct_CON + averted_CON)] were associated with a differential increase in BOLD signal in the right inferior parietal lobule, left superior parietal lobule and right middle frontal gyrus ( ). For the reversed contrast [(direct_CON + averted_CON) > (direct_INCON + averted_INCON)], a large cluster of 2319 voxels emerged in the bilateral medial prefrontal cortex (MPFC), including voxels in the superior medial gyri, superior frontal gyri and the anterior cingulate cortices, spreading to the right medial cingulate cortex. Congruent compared to incongruent trials further elicited activation in the right IFG as well as the left cerebellum and posterior part of the left fusiform gyrus ( ). 
  
Main effects of conditions in the left (L) and right (R) hemisphere  .   (  A  ) Incongruent   vs   congruent, (  B  ) congruent   vs   incongruent, (  C  ) direct   vs   averted gaze. The cluster forming threshold was set to   P   < 0.001 (uncorrected), the cluster threshold to   P   < 0.05 (FWE) and cluster size (A) k > 414 voxels, (B) k > 287 voxels, (C) k > 638 voxels. [(A) SPL: superior parietal lobule, mFG: medial frontal gyrus; MFG: middle frontal gyrus (B) SFC: superior frontal cortex, FFG: fusiform gyrus, ACC: anterior cingulate cortex, MPFC: medial prefrontal cortex, CRBL: cerebellum; IFG: inferior frontal gyrus (C) lPS: intra-parietal sulcus]. 
  
During direct gaze   vs   averted gaze [(direct_CON + direct_INCON) > (averted_CON + averted_INCON)], increased signal was found in the right intraparietal sulcus ( ). The contrast of averted gaze   vs   direct gaze [(averted_CON + averted_INCON) > (direct_CON + direct_INCON)] did not show any suprathreshold activation. Similarly, significant clusters emerged in neither of the interactions of congruency and gaze [IA1: (direct_INCON > direct_CON) > (averted_INCON > averted_CON)] and [IA2: (averted_INCON > averted_CON) > (direct_INCON > direct_CON)] (Supplementary Table S3 for coordinates, T-values and cluster sizes). 

In our psychophysiological interaction analysis, we analyzed how the right TPJ was coupled with the action network for the interactions of the experimental factors, i.e. IA1 and IA2 (Supplementary Figure S2 and Table S4 for coordinates, T-values and cluster sizes of all PPI contrasts). Statistical maps were thresholded at   P   < 0.05 (FWE) at voxel level. Results demonstrated that for IA1, which represented increased BOLD incongruency costs for direct compared to averted gaze, the right TPJ showed context-dependent connectivity with the IFG and the right middle temporal gyrus ( , brown color map). For IA2, reflecting increased BOLD incongruency costs for averted compared to direct gaze, activation in the seed region was coupled to activation in a dorsal network of superior and inferior parietal lobules, pre- and postcentral gyri, temporal gyri, occipital gyri, left superior, posterior medial, middle and IFG, right paracentral gyrus, left putamen and right cerebellum ( , blue/green color map). 
  
Interaction effects in a psychophysiological interaction analysis in the left (L) and right (R) hemisphere  .   IA1 (brown): (direct_INCON > direct_CON) > (averted_INCON > averted_CON), IA2 (blue/green): (averted_INCON > averted_CON) > (direct_INCON > direct_CON). The results were FWE corrected at   P   < 0.05 voxel level. [IFG: inferior frontal gyrus, MTG: middle temporal gyrus MFG: middle frontal gyrus, PreCG: precentral gyrus, PostCG: postcentral gyrus, SPL: superior parietal lobule, OccG: occipital gyrus, CRBL: cerebellum, ITG: inferior temporal gyrus; pmFG: posterior medial frontal gyrus; ParaCG: paracentral gyrus]. 
  


## Discussion 
  
The present study investigated the effect of gaze perception on behavioral and neural correlates of action control of non-imitative re-actions. Our results demonstrate context-dependent functional integration of gaze and action control processes and our behavioral findings are in line with theories suggesting a relationship between gaze effects and autistic traits. 

As hypothesized, we found a significantly lower percentage of correct responses and longer RTs when participants had to respond in a spatially incompatible manner to the VCs’ gaze shifts ( ;  ;  ). Moreover, in line with a priori expectations, key regions of the so-called dorsal fronto-parietal attention network showed increased activation in incongruent as compared to congruent experimental blocks, possibly reflecting the increased need for top-down control ( ;  ). 

The opposite contrast, namely congruent   vs   incongruent, depicted increased brain activation in the left posterior fusiform gyrus and the MPFC. Given the lack of significant results in previous studies, we did not have specific hypotheses about the present contrast. A possible explanation for the brain activation found might be that similar to the sensitivity of the left fusiform gyrus towards faces and shapes ( ), MPFC activation has previously been found in response to spatially congruent gaze shifts, potentially representing occurrences of joint attention ( ). Hence, in a situation of low task difficulty, participants might have used free cognitive capacities to thoroughly process the social encounter with a VC ( ). Alternatively, representing a central hub of the default mode network, which is known as the task-negative network (e.g.  ), MPFC activation might indicate the occurrence of stimulus-independent thoughts that have been referred to as ‘day dreaming’ or mind wandering ( , Neurosynth, retrieved 3 June 2019: association of peak coordinates with terms ‘default mode’, ‘mentalizing’). Despite of the richness of literature on the decisive role of the IFG in response inhibition processes (e.g.  ), in the present contrast, the right IFG was activated during congruent blocks not requiring to withdraw from or cancel motor actions. Instead, the IFG might have come into play through holding representations of the CV’s gaze movements and hence, might have supported action understanding ( ;  ; Neurosynth, retrieved 3 June 2019: association of peak coordinates with terms ‘decision task, ‘comprehension’, ‘reappraisal’). Further, in light of its implication in gaze-grasping mappings ( ;  ), the IFG might have promoted a congruent button pressing by translating the gaze movement into a finger movement that corresponded to the direction of the gaze. Here, future research needs to clarify the specific role of the IFG during congruent task conditions. 

Direct compared to averted gaze was followed by increased brain activation in the right intraparietal sulcus, a region known to be involved in visuo-spatial aspects of action planning, the understanding of complex or irrational actions and the integration of visual and motor computations ( ;  ;  ). However, contrary to our hypotheses, direct gaze was not accompanied by increased activation in the right TPJ and fusiform gyrus—a result that might be caused by block design-induced habituation effects ( ). 

Incongruency costs describe the behavioral or neural cost of performing a spatially incompatible motor response. In the present study, we were interested in the differences in incongruency costs between the direct and averted gaze conditions. Contrary to our hypothesis, incongruent RTs did not differ between the direct and the averted gaze condition. As has been shown previously ( ), in a more difficult task situation, gaze did not have an impact on behavior. However, contrary to the reported facilitation of motor imitation with direct gaze, in our study, the translation of a gaze shift into a left- or right-handed button press was less time-consuming for averted gaze movements. Thus, our results indicate that the facilitation effect of direct gaze might not apply to non-imitative behaviors. Consistent with behavioral results, there was no interaction effect of experimental conditions at the brain level. 

The difference in RT incongruency costs between the direct and averted gaze condition represented a measure of the gaze-depended incongruency effect on reaction speed. A correlation analysis showed that high AQ values were associated with higher incongruency costs in the averted gaze condition, whereas the difference in incongruency costs between conditions diminished and even changed towards higher incongruency costs in the direct gaze condition with decreasing AQ scores. This result points towards inter-individual differences in the sensitivity towards social gaze, as a function of autistic traits. In this sense, individuals with low AQ scores might be more susceptible to the influence of direct gaze than individuals with higher AQ values. 

How the communication between the right TPJ and the action network changes depending upon the interplay of the experimental factors was addressed by means of a psychophysiological interaction analysis. Importantly, studies have indicated a functional partitioning of the right TPJ into an anterior and a posterior cluster: while the global functional integration of the anterior cluster suggests a mediating role in shifting from one functional brain state to another ( ), our ‘gaze’-associated seed region overlaps with the posterior TPJ cluster, implicated in social cognition, imagination and episodic memory retrieval ( ). As hypothesized, the context-dependent connectivity between our seed and the IFG, known to be involved in the integration of action inhibitory tendencies and motivational, emotional or social input (e.g.  ;  ; Neurosynth, retrieved 3 June 2019: association of peak coordinates with term ‘theory of mind’), was increased for incongruency costs in the context of direct gaze. As a consequence, the connection between the right TPJ and the IFG might reflect an upregulated exchange of gaze information and inhibitory control processes in the context of direct gaze. Moreover, in parallel to the association of our TPJ region to object or scenic imagination ( ), the IFG has been discussed not only to contribute to reactive but also proactive motor control ( ;  ). Accordingly, it would be possible that the IFG has been involved in preparing or anticipating a reorientation response that might have been supported by gaze-related input from the TPJ. In line with this post-hoc hypothesis, the right middle temporal gyrus has been indicated in mapping hypothetical motor actions to perceptual input ( ). 

Conversely, costs for reacting incongruently in the context of averted as compared to direct gaze movements were represented in increased functional connectivity between our seed region and major parts of the action network, predominantly in the left hemisphere and including the parietal lobules, the primary motor and sensory cortex, the frontal and temporal gyri. Besides belonging to the action network, the superior parietal and frontal regions are also relevant in top down attentional control processes ( ;  ) and have been shown activated in working memory tasks, during spatial attention towards or the planning of actions ( ). In summary, incongruency costs for averted gaze appear to manifest in more wide-spread connectivity that encompasses somatosensory motor areas. Incongruency costs for direct gaze, however, are reflected in increased connectivity with brain regions that are involved in both action control and social cognition. 

In conclusion, the results of the present study shed new light onto the neurobiology that underlies the specific role of direct gaze in social encounters: by increasing the connectivity of multimodal brain regions, the processing of direct gaze results in an integration of brains regions implicated in action control and social cognition. In this way, direct gaze could be seen as contributing to a comprehensive processing of the social situation that goes beyond a strongly stimulus-driven orientation. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-3'>
<h2>3. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/20520767/' target='_blank'>20520767</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> The Brain Functional Networks Associated to Human and Animal Suffering Differ among Omnivores, Vegetarians and Vegans</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2010</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0010847</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/2877098/' target='_blank'>2877098</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study in healthy adults (n=60; ages 18–60) that examines neural responses during viewing of human and animal suffering — a social-cognition/empathy task (perception and understanding of others). The paper reports whole-brain random-effects analyses using SPM2 with FWE-corrected results and MNI coordinates (not limited to ROI-only analyses). Healthy participant results are reported separately and meet the age inclusion (17–65). No exclusion criteria apply (not an ROI-only study, and not restricted to clinical samples). Therefore it meets all inclusion criteria for fMRI studies of social-related processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Empathy and affective appraisals for conspecifics are among the hallmarks of social interaction. Using functional MRI, we hypothesized that vegetarians and vegans, who made their feeding choice for ethical reasons, might show brain responses to conditions of suffering involving humans or animals different from omnivores. We recruited 20 omnivore subjects, 19 vegetarians, and 21 vegans. The groups were matched for sex and age. Brain activation was investigated using fMRI and an event-related design during observation of negative affective pictures of human beings and animals (showing mutilations, murdered people, human/animal threat, tortures, wounds, etc.). Participants saw negative-valence scenes related to humans and animals, alternating with natural landscapes. During human negative valence scenes, compared with omnivores, vegetarians and vegans had an increased recruitment of the anterior cingulate cortex (ACC) and inferior frontal gyrus (IFG). More critically, during animal negative valence scenes, they had decreased amygdala activation and increased activation of the lingual gyri, the left cuneus, the posterior cingulate cortex and several areas mainly located in the frontal lobes, including the ACC, the IFG and the middle frontal gyrus. Nonetheless, also substantial differences between vegetarians and vegans have been found responding to negative scenes. Vegetarians showed a selective recruitment of the right inferior parietal lobule during human negative scenes, and a prevailing activation of the ACC during animal negative scenes. Conversely, during animal negative scenes an increased activation of the inferior prefrontal cortex was observed in vegans. These results suggest that empathy toward non conspecifics has different neural representation among individuals with different feeding habits, perhaps reflecting different motivational factors and beliefs. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (31724 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Social cognition includes mental processes necessary to understand and store information about the self and other persons, as well as interpersonal norms and procedures to navigate efficiently in the social world  . Basic abilities underlying social cognition include the perception and evaluation of social stimuli, the integration of perceptions with contextual knowledge, and finally the representation of possible responses to the situation. One of the hallmarks of social cognition in humans is the ability to understand conspecifics as beings like oneself, with intentional and mental lives like one's own  . Accordingly, human beings tend to identify with conspecifics and attribute mental states to them. Such abilities rely on the activity of several brain regions, including the frontal lobes (orbitofrontal cortex, medial prefrontal cortex, and cingulate cortex), the temporal lobes (including the amygdala), the fusiform gyrus, and the somatosensory cortices  ,  ,  . The majority of these regions is also critically involved in the processing of emotions  . This suggests that the merging between emotions and feelings experienced by oneself and those perceived in other individuals may be a key ingredient of social understanding, and it may play a major role in promoting empathy, prosocial behaviours, and moral norms  ,  . Moreover, empathic responses can be modulated by the subjective attitude held toward suffering individuals  , as well as by personal experience  . Several functional magnetic resonance imaging (fMRI) studies showed that observing the emotional state of another individual activates a neuronal network involved in processing the same state in oneself, whether it is pain, disgust, or touch ,  ,  . Empathy toward another person, which can be defined as the ability to share the other person's feeling in an embodied manner, has been related to recruitment of a network mostly including the somatosensory and insular cortices, limbic regions and the anterior cingulate cortex (ACC). Whereas cognitively inferring about the state of other person (known as theory of mind) has been associated with recruitment of medial prefrontal regions, the superior temporal sulcus and the temporo-parietal junction . 

A few investigations have also assessed whether affective links between people modulate their brain empathic responses to others, such as when these are loved ones or strangers , or when they are believed to be fair or unfair persons  ,  . The majority of previous studies attempting to characterize empathy-related responses did not separate empathy towards humans from that towards animals. Furthermore, in some studies, scenes showing animals were treated as a neutral condition. However, a recent study   that compared stimuli depicting human and non human animal targets demonstrated higher subjective empathy as the stimuli became closer in phylogenetic relatedness to humans (mammalian   vs  . bird stimuli), thus indicating that empathic response towards humans may generalize to other species. 

In this study, we postulated that the neural representation of conditions of abuse and suffering might be different among subjects who made different feeding choice due to ethical reasons, and thus result in the engagement of different components of the brain networks associated with empathy and social cognition. In details, we tested the hypothesis that the neural processes underlying empathy in vegetarians and vegans may not only operate for representations about humans but also animals, and thus vary between them and omnivore subjects. Vegetarians and vegans, who decided to avoid the use of animal products for ethical reasons, have a moral philosophy of life based on a set of basic values and attitudes toward life, nature, and society, that extends well beyond food choice. The earliest records of vegetarianism as a concept and practice among a significant number of people was closely connected with the idea of nonviolence towards animals and was promoted by religious groups and philosophers. The term veganism, which was coined from vegetarianism, acknowledges the intrinsic legitimacy of all sentient life and rejects any hierarchy of acceptable suffering among creatures. Veganism is a lifestyle that seeks to exclude the use of animals for food, clothing, or any other purpose  . The central ethical question related to veganism is whether it is right for humans to use and kill animals. Due to these differences of believes and behaviours, we also hypothesized that, in addition to a common shared pattern of cortical processing of human and animal suffering, vegetarians and vegans might also have functional architecture differences reflecting their different motivational factors and believes. 


## Results 
  
### Empathy assessment 
  
The Empathy quotient (EQ) score was significantly different between groups (p = 0.002). At post-hoc analysis, the EQ score was significantly higher in vegetarians in comparison with omnivore subjects (mean EQ score = 49.5, SD = 8.9 in vegetarians   vs  . 38.8, SD = 8.1 in omnivore; p = 0.001), and in vegans (mean EQ score = 44.6, SD = 9.8) in comparison with omnivore subjects (p = 0.04) ( ). The difference between vegans and vegetarians was not statistically significant. 
   Graph showing error bars of means and standard deviations of empathy quotient (EQ) score in the three groups of subjects.  
See text for further details. 
  

### Within-group fMRI results 
  
The observation of both human and animal negative valence scenes resulted in the recruitment of several brain areas involved in emotion and empathy in the three groups of subjects, including the anterior insula, basal ganglia, thalami, and several other cortical areas located in the occipital lobes, prefrontal and parietal cortices.   shows the brain patterns of activations in the three groups of subjects during the different experimental conditions.   summarizes the main results of within-group comparisons of the two experimental conditions. 
   Within-group analysis of activations.  
Cortical activations on a rendered brain from omnivore (A–H), vegetarian (I–R) and vegan (S–W) subjects during observation of pictures showing negative valence scenes of humans (A–D, I–N, S–V) or animals (E–H, O–R, Z–W) (within-group analysis, one-sample t tests, t = 3 for display purpose). Images are in neurological convention. 
     Within-group comparisons of human   vs  . animal negative valence picture view and vice versa in omnivore subjects, vegetarians and vegans (paired t test in each group, p<0.05 FWE-corrected).        

### Between-group fMRI results 
  
The patterns of activations during the neutral condition did not differ between groups. 


### Common regions of activations between vegetarians and vegans 
  
During human negative valence picture view, omnivore subjects had a more significant activation (p<0.05, FWE) of the bilateral middle temporal gyrus (MTG) (MNI space coordinates: 38, −58, 8, t value = 5.65; and −36, −76, 8, t value = 5.56) when compared to vegetarians and vegans. Compared to omnivore subjects, the entire sample of vegetarians and vegans had more significant activations (p<0.05, FWE) of the ACC (MNI space coordinates: 10, 22, 40; 10, 36, 28, and −4, 30, 36; t values = 5.65, 5.43, and 5.30), and the left inferior frontal gyrus (IFG) (MNI space coordinates: −48, 20, 0, t value = 5.56) ( ). 
   Results of the between-group comparisons of emotional (human and animal) negative valence picture views.  
Results are superimposed on a high resolution T1-weighted image in the standard MNI space, at a threshold of p<0.05 corrected for multiple comparisons. Areas activated during human picture view in vegetarians and vegans   vs.   omnivores are shown in yellow. Activations specific for vegetarians are shown in blue. Activations specific for vegans are shown in red. A: human picture view; B: animal picture view. Images are in neurological convention. 
  
During animal negative valence picture view, omnivore subjects had more significant activations (p<0.05, FWE) of the bilateral MTG (MNI space coordinates: −46, −62, 0, t value = 6.03; and 34, −74, 4, t value = 5.94), when compared to vegetarians and vegans. Compared to omnivore subjects, the entire sample of vegetarians and vegans had more significant activations (p<0.05, FWE) of the bilateral IFG (MNI space coordinates: −50, 14, −2, t value = 6.84; and 52, 14, −4, t value = 6.34), bilateral lingual gyrus (MNI space coordinates: 8, −80, −14, t value = 6.83; and −10, −78, −14, t value = 6.58), ACC (MNI space coordinates: 0, 24, 28; −2, 52, 8; t values = 5.76 and 5.51), posterior cingulate cortex (PCC) (MNI space coordinates: 0, −42, 26, t value = 5.87), left cuneus (MNI space coordinates: −2, −78, 24, t value = 5.83), and left middle frontal gyrus (MFG) (MNI space: −44, 46, 8, t value = 5.50) ( ). This analysis also showed that, compared to omnivores, vegetarians and vegans had a lower activation of the right amygdala (MNI space coordinates: 30, 2, −20, t value = 5.38). To better define amygdala behavior in the three groups of subjects, we analyzed its activations and deactivations during the two experimental conditions in each group (  and  ). This analysis revealed no significant activation neither deactivation (even when lowering the threshold for the statistical significance at a p<0.001, uncorrected) during animal picture view in this region in vegetarians and vegans. 
   Cluster maxima coordinates of activations/deactivations, at the within-group one sample t test analysis of the areas which showed a significant interaction between groups and conditions (p<0.001, uncorrected).        

### Different regions of activations between vegetarians and vegans 
  
We also directly compared the neural responses in empathy and emotion-related networks between omnivores, vegetarians, and vegans, using a masking procedure (See  ), to identify regions of specific activations of each group contrasted to the others. 

#### a) Vegetarians vs. omnivores and vegans 
  
Observation of human negative valence scenes resulted in a selective recruitment of the right IPL (BA40) (MNI space coordinates: 52, −50, 40, t value = 4.44) in vegetarians ( ). For animal pictures, activations specific to vegetarians were found in the ACC (MNI space coordinates: −2, 52, 10, t value = 5.02) and the right lingual gyrus (MNI space coordinates: 8, −84, −10, t value = 5.00) (p<0.05, FWE). 


#### b) Vegans vs. omnivores and vegetarians 
  
During human negative valence picture view, no cortical activation “specific” to vegans was found. During animal negative valence picture view, vegans activated the IFG bilaterally (MNI space coordinates: 54, 16, −6, and −46, 18, −2, t values = 4.88 and 4.67), and the left MFG (BA10) (MNI space coordinates: −46, 48, 4, t value = 4.29) ( ) (p<0.05, FWE). 



### Analysis of interaction 
  
To further explore the specificity of stimulus processing within the three groups of subjects, we performed an analysis of interaction between picture types (animal/human) and groups (omnivore/vegetarian/vegan). Results showed an interaction in the right amygdala (MNI space coordinates: 24, −10, −22) (greater increases to animal negative valence view in omnivores and to human negative valence view in vegans) ( ), the left amygdala (−22, −8, −28) (greater increases to human negative valence view in vegans) ( ), the ACC (MNI space coordinates: −2, 52, 10) (preferential increases to human negative valence view in omnivores, and to animal negative valence view in vegetarians) ( ); and the right IFG (MNI space coordinates: 52, 20, −8) (selective responses to animal negative valence view in vegans) ( ). 
   Interactions between stimuli (animal/human) and groups (omnivore/vegetarian/vegan).  
An interaction was found in the right amygdala (A), indicating greater increase to animal negative valence picture view in omnivores and to human negative valence picture view in vegans. An interaction between “human pictures” and “vegan group” was also found in the left amygdala (A). An interaction was found in ACC (B) between the “omnivore group” and “human pictures”, as well as between “vegetarian group” and “animal pictures”; and in the right IFG between “animal pictures” and “vegan group” (C). Foci of activations are shown on a high-resolution T1-weighted image in the standard MNI space. Plots indicate activation changes detected in the three groups during the two experimental conditions in each of these regions. Images are in neurological convention. 
  
 summarizes the behavior, in terms of activations/deactivations, at the within-group one sample t test analysis of the three main areas which showed a significant interaction between groups and conditions (i.e., amygdala, IFG, and ACC). 


### Analysis of correlations 
  
During human negative valence picture view, no correlation was found between EQ score and fMRI activity in the three groups of subjects of the study. 

During animal negative picture view, significant correlations (p<0.001) were found between EQ score and: 
  
activation of the left MTG (r = 0.87), ACC (r = −0.76) and the bilateral IFG (right IFG: r = −0.71, left IFG: r = −0.89) in omnivores; 
  
activation of the left IFG (r = 0.92), the left MFG (r = 0.68), and the right MTG (r = −0.75) in vegetarians; 
  
activation of the bilateral lingual gyrus (right lingual gyrus: r = 0.69, left lingual gyrus: r = 0.75) and the left IFG (r = 0.78) in vegans. 
  


## Discussion 
  
The first main finding of this study was the demonstration of a common functional architecture of emotional processing in vegetarians and vegans. In particular, while omnivores are characterized by a greater activation of the bilateral posterior MTG during both human and animal negative valence scenes, vegetarians and vegans have constantly an higher engagement of empathy related areas while observing negative scenes, independently of the species of the individuals involved, which is characterized by an increased recruitment of the ACC and the IFG. Increased activation in the ACC and left IFG in vegetarians and vegans during human and animal suffering view is likely to reflect a stronger empathic response in the first two groups. 

Remarkably, vegetarians and vegans have an higher engagement of empathy related areas while observing negative scenes regarding animals rather than humans, with the additional recruitment of the mPFC, PCC, and some visual areas. ACC has been associated with alert states, self awareness and pain processing  , whereas mPFC and PCC activations are frequently observed in conditions involving representation of the self and self values  . The PCC is also thought to be involved in memory and visuospatial processing  , particularly in relation to emotions and social behavior  . PCC is consistently activated when subjects have to judge the valence of emotionally salient words or episodic memories, with the strongest responses seen when unpleasant stimuli are presented  . 

The notion that empathic response might differ among vegetarians, vegans and omnivores, and that such a response might vary during viewing of human and animal sufferance is at least partially supported by the results of EQ assessment in the three groups of subjects and by the analysis of correlation between EQ scores and fMRI findings, which showed a direct relationship between the EQ score and left IFG recruitment during animal suffering view in vegetarians and vegans, whereas in omnivores such a relationship was inverse. 

The pattern of increased recruitment of empathy-related areas in vegetarians and vegans during animal suffering view was also associated with a reduced activation of the right amygdala in comparison to omnivores. The amygdala responds to various kinds of aversive stimuli, most strongly fearful and threatening scenes   and, to a lesser extent, to those associated with disgust  . Remarkably, the within-group analysis during animal picture view, showed the absence of signal changes (in terms of activations and deactivations) within the amygdala in vegetarians and vegans, suggesting a down-regulation of amygdala response from areas located in the frontal lobes, in an attempt to regulate emotion through cortical processes in these subjects. 

The second main finding of this study is the demonstration of strong functional architecture differences between the vegetarians and vegans during observation of negative scenes. During human suffering viewing, activations specific to vegetarians were located along the IPL. The IPL is involved in bodily representations that distinguish the self from the other  , and was found to be more activated when pictures of mutilations were presented than when contamination or neutral pictures were shown , which suggests a stronger effect on the somatosensory system in observers exposed to the former than the latter conditions. 

More critically, for animal pictures, activations specific to vegetarians were found in the ACC and the lingual gyrus, whereas activations specific to vegans were found in the bilateral IFG and the left MFG. Our data, therefore, point to differential ACC responses to animal suffering for vegetarians, a region highly interconnected with limbic and prefrontal structures that is thought to play a key role in normal and dysfunctional emotional self-control as well as social behaviour  . ACC activation has been related to awareness of emotional material, attention to emotional stimuli  , and rating of affect intensity. In a meta-analysis study, Phan et al.   found that emotional tasks with explicit cognitive components (e.g., recognition or evaluation of emotional stimuli and biographic material) engaged specifically the ACC as compared to passive emotional conditions. The ACC has also been associated with alertness and attention, notably in terms of response control and during painful stimulation  . The recruitment of this region in vegetarians might therefore correspond to their distinctive behavioral response to pictures of animal suffering, e.g., enhanced attention and empathic pain  , or increased self control and monitoring  . On the other hand, the activation of the inferior prefrontal cortex (IFG) seen in vegans during animal suffering, which is consistent with a role of such a region in different emotional tasks  , may be related to aspects of cognitive control during emotion processing. Notably, right IFG is critically involved in inhibitory processes during both cognitive   and emotional   conditions. In addition, even if the existence of the mirror-neuron system (MNS) in humans is still controversial, the IFG is also considered to be part of such a system, since these regions are often activated during action observation, motor learning and imitation of action  . Activation of MNS areas has been shown to increase during social interaction, as well as during observation and imitation of emotional faces  . The role of the MNS in social cognition is also supported by studies in patients with autism, who show a reduced recruitment of the MNS, and in particular of the IFG, during observation and imitation of facial expressions  . Our findings therefore suggest a distinctive pattern of empathic response and emotional control in vegans, mediated through the IFG and MFG. 

Between-group differences in stimuli processing were also confirmed by an analysis of interaction, which showed greater increases to animal negative valence view in omnivores and to human negative valence view in vegans in the amygdala, a preferential increase to human negative valence view in omnivores, and to animal negative valence view in vegetarians in the ACC, and selective responses to animal negative valence view in vegans in the right IFG. Intriguingly, an inverse correlation between amygdala response and activation in the right PFC and ACC has previously been shown during emotional tasks  . In humans, this system is thought to control and direct emotional responses through appraisal and evaluation of their experiences. Such an inverse correlation (i.e., decreased activation of the amygdala together with increased activations of the ACC and PFC) has also been demonstrated during “reappraisal”, which implies altering the meaning of a potentially emotion-eliciting situations in order to reduce their emotional impact  , suggesting that cortical networks of prefrontal regions can exert a cognitive modulation on emotion processing in the amygdala, particularly during intense emotional responses. An alternative hypothesis that has been considered is that limbic structures, such as the amygdala, might respond preferentially to emotive stimuli at a sensory level, and less likely to be engaged in the cognitive processing of emotional material  . 

Collectively, our results reveal that distinct brain responses are evoked by emotionally significant pictures of humans and animals in people with vegetarian and vegan feeding habits, as well as between vegetarians and vegans, suggesting that different motivational factors might underlie their preferences and moral attitudes. Vegetarians showed distinctive responses to negative valence scenes of animals in the ACC, but also to negative valence scenes of humans in the IPL, which might be consistent with greater empathic pain responses and/or enhanced attention in this group for these two conditions. On the other hand, the selective response of vegans to animals in the ACC (with reduced amygdala responses) might reflect a greater attribution of self-relevance   and a greater recruitment of emotional regulation mechanisms  ,   when viewing negative states of non-human beings, together with an enhanced activation of the motor MNS and inhibitory control processes mediated through the MFG and the IFG, respectively. By contrast, omnivores, showed greater responses to human negative valence scenes in the ACC (together with reduced amygdala activation), suggesting that self-relevance and emotion control mechanisms were more specifically engaged by viewing suffering conspecifics than suffering animal beings. 

Our study is the first to assess the neural correlates of empathy towards non conspecifics in people with different social norms, as reflected by their feeding habits. Our results converge with theories that consider empathy as accommodating a shared representation of emotions and sensations between individuals, allowing us to understand others  . They also led us to speculate that the neuronal bases of empathy involve several distinct components including mirroring mechanisms  , as well as emotion contagion and representations of connectedness with the self  . In addition, brain areas similar to those showing different emotional responses between groups in our study (such as the IFG and the mPFC) have also been found to be modulated by religiosity  , further supporting a key role of affect and empathy in moral reasoning and social values. 

This study is not without limitations. First, the use of neutral scenes as a “baseline” condition does not allow defining the neural response to suffering per se, since the response might be influenced by seeing humans or animals. Second, even if a questionnaire related to feeding habits and the EQ were obtained from all the study subjects, affective and cognitive responses during fMRI acquisition were not recorded. Clearly, further studies are warranted to confirm our results. 


## Materials and Methods 
  
The study was approved by the Ethics Committee of Scientific Institute and University Ospedale San Raffaele, Milan, Italy and a written informed consent was obtained from all subjects prior to study entry, according to the Declaration of Helsinki. 

### a) Subjects 
  
We studied 60 right-handed   healthy subjects (34 women, and 26 men, mean age = 37.7 years, range = 18–60 years), with different dietary habits. All subjects had normal or corrected-to-normal vision. We recruited 20 omnivore subjects (11 women and 9 men; mean age = 36.9 years, range = 22–60 years), 19 vegetarians (11 women and 8 men; mean age = 40.3 years, range = 23–60 years), and 21 vegans (12 women and 9 men; mean age = 36.3 years, range = 18–53 years). The groups did not statistically differ for sex and age. A questionnaire was filled in by all the subjects before fMRI acquisition to investigate feeding habits, reasons/motivations of the feeding choices, and the time elapsed from such a choice. All vegetarians and vegans reported to have made their feeding choice for ethical reasons. They had stable feeding habit since 3.8 years (SD = 8.7 years), and were recruited among vegetarian associations. Omnivore subjects were recruited by advertisement and none of them had been vegetarian or vegan before the study. Eight vegans had been vegetarians before becoming vegans. All the subjects were naïve about the goal of the study. None of the subjects had any history of neurological, major medical, or psychiatric disorders (including depression), and either alcohol or drug abuse. In addition, none of the subjects was taking any medical treatment at the time of fMRI assessment and all of them had a normal neurological examination. 


### b) Empathy assessment 
  
On the day of fMRI acquisition, subjects were evaluated with the EQ questionnaire  , a self-report questionnaire which has been developed to measure the cognitive and affective aspects of empathy. This questionnaire is widely used in clinical research  ,  , as well as in neuroscience studies  . The EQ comprises 60 questions: 40 questions tapping empathy, and 20 filler/control items. The 20 filler/control items have been included to distract the participant from a relentless focus on empathy. On each empathy item, a person can score 2, 1, or 0, so that the EQ has a maximum score of 80 and a minimum score of 0. To avoid response bias, approximately half of the employed items are worded to produce a “disagree” response and half to produce an “agree” response  . The EQ has a forced choice format, can be self-administered, and is straightforward to score because it does not depend on any interpretation. 


### c) Experimental design 
  
During fMRI, an event-related design was used. A program implemented with the Presentation software (  www.neuro-bs.com  , Version 9.70) presented in a random order a series of 150 pictures: 40 showed negative valence scenes related to humans, 40 negative valence scenes related to animals, and the remaining 70 showed “neutral” natural landscapes. Pictures were pseudo-randomized so that no more than two pictures of the same category were presented consecutively. Negative-valence scenes were taken from the International Affective Picture System  , newspapers, books, or magazines (all images were of high-quality resolution and taken in an electronic format). Scenes had to show the entire figure and not only the face of the subject/animal. Human and animal pictures were comparable in terms of valence and arousal rating. Non-IAPS pictures were validated in a group of 50 healthy subjects that did not participate in the fMRI experiment. To assess the three dimensions of pleasure, arousal, and dominance, the rating procedure by Lang was used  . 

Each trial began with a fixation cross presented in the centre of the screen for 3 sec, followed by the pictures, in a random order, presented for 2 sec followed by black screen. A variable interstimuls interval was used. Subjects were instructed to look at the scenes, without providing any specific response during fMRI acquisition. 


### d) fMRI acquisition 
  
Brain MRI scans were obtained using a 3.0 Tesla scanner (Intera Philips Medical Systems, Best, The Netherlands) with a gradient strength of 40 mT/m. Functional MR images were acquired using a T2*-weighted single-shot echo-planar imaging (EPI) sequence (echo time [TE] = 30 ms, flip angle = 85°, matrix size = 128×128, field of view [FOV] = 240 mm , repetition time [TR] = 3.0 seconds). During each functional scanning run, 151 sets of 40 axial slices, parallel to the AC-PC plane, with a thickness of 3 mm, covering the whole brain were acquired. Shimming was performed for the entire brain using an auto-shim routine, which yielded satisfactory magnetic field homogeneity. Head movements were minimized using foam paddings. 

On the same occasion, a brain dual-echo turbo spin echo sequence (TR = 3500 ms, TE = 24/120 ms; echo train length = 5; flip angle = 150°, 44 contiguous, 3-mm-thick, axial slices with a matrix size = 256×256 and a FOV = 240×240 mm ) was also acquired. 


### f) FMRI analysis 
  
FMRI data were analyzed using the statistical parametric mapping (SPM2) software. Prior to statistical analysis, all images were realigned to the first one to correct for subject motion, spatially normalized into the Montreal Neurological Institute (MNI) space, and smoothed with a 10-mm, 3D-Gaussian FWHM filter. 


### g) Statistical analysis 
  
Event-related paradigms for each condition were modelled on a voxel-by-voxel basis, using the general linear model and the theory of random Gaussian fields  . In each subject, a first-level design matrix was built, where motion parameters were used as regressors of no interest. Then, specific effects were tested by applying appropriate linear contrasts. For each subject, the following contrasts were defined: human negative valence images > neutral, and animal negative valence images > neutral. To test whether between-group differences in processing the neutral conditions might have influenced our results, the contrast assessing activations of neutral images was also defined. Significant hemodynamic changes for each contrast were assessed using t statistical parametric maps (SPMt). Then, a second level random effect analysis was performed to assess the main effects of the stimuli, differences between groups, and interactions between groups and conditions  , using an ANOVA model where groups and conditions were entered as separate factors (2×3 factorial design). To assess between-group similarities and differences in the brain patterns of activations, the following sets of linear comparisons were performed: 1) vegetarians and vegans, separately,   vs.   omnivores; 2) vegetarians and vegans, combined,   vs.   omnivores; 3) vegetarians   vs.   vegans, and vice versa. Common patterns of activations between vegetarians and vegans during a given contrast were identified by a conjunction analysis  . Regions of specific activations of each group contrasted to the other were identified by inclusively masking (uncorrected mask p value = 0.05) the relevant contrast from comparison 1 (e.g., vegetarians   vs.   omnivores) with the appropriate contrast from comparison 3 (e.g., vegetarians   vs.   vegans). 

Intra-group activations were evaluated using a one-sample t test and a paired t test, as appropriate. At this stage, task-related activations and deactivations were estimated. We report activations below a threshold of p<0.05 corrected for multiple comparisons (FWE). Within each region of statistical significance, local maxima of signal increase were determined and their locations expressed in terms of   x  ,   y  , and   z   coordinates into the MNI space. A 3D anatomical atlas was also used to increase confidence in the identification of the anatomical locations of the activated areas  . Using a linear regression analysis, the correlation of fMRI changes during task performance with EQ score was assessed (p<0.001, uncorrected). 

Demographic and behavioral data were compared using the SPSS software and an ANOVA model (version 13.0). 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-4'>
<h2>4. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/26000902/' target='_blank'>26000902</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> fMRI Study of Social Anxiety during Social Ostracism with and without Emotional Support</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2015</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0127426</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4441506/' target='_blank'>4441506</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Study uses fMRI and the Cyberball social ostracism/support paradigm (a social-related task). Participants are healthy adults (undergraduates; mean age 19.85) with a majority (37/46) having no Axis I disorders; data include whole-brain voxel-wise analyses (EX–IN and SUP–EX contrasts) and regression analyses across social anxiety scores. Whole-brain results are reported (one-sample t-tests and whole-brain regressions) and supported by ROI analyses, satisfying the requirement that whole-brain analyses are available. Although a minority of participants met criteria for SAD, the sample includes healthy participants and the reported whole-brain findings pertain to the sample and to social anxiety as a continuous measure rather than being limited to a clinical group. Therefore the study meets inclusion criteria for fMRI of social processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.88</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Social anxiety is characterized by an excessive fear of being embarrassed in social interactions or social performance situations. Emotional support can help to decrease or diminish social distress. Such support may play an important role at different points of social interaction. However, it is unclear how the beneficial effects of social support are represented in the brains of socially anxious individuals. To explore this, we used the same paradigm previously used to examine the effects of emotional support on social pain caused by exclusion. Undergraduates (n = 46) showing a wide range of social anxiety scores underwent functional magnetic resonance imaging (fMRI) while participating in a Cyberball game. Participants were initially included and later excluded from the game. In the latter half of the session in which participants were excluded, they were provided with supportive messages. In line with our previous work, we found that social exclusion led to increased anterior cingulate cortex (ACC) activity, whereas emotional support led to increased left dorsolateral prefrontal cortex (DLPFC) activity. Despite validation of the paradigm, social anxiety was not associated with increased ACC activity during social exclusion, or during perceived emotional support. Instead, fear of negative evaluation as assessed by the Brief Fear of Negative Evaluation (BFNE) scale showed positive associations with left DLPFC activation while receiving emotional support, compared to while being socially excluded. The more socially anxious an individual was, the greater was the left DLPFC activity increased during receipt of messages. This suggests that highly socially anxious people still have the ability to perceive social support, but that they are nevertheless susceptible to negative evaluation by others. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (32554 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Social anxiety is characterized by an excessive fear of being embarrassed during social interactions. This embarrassment stems from being scrutinized, negatively criticized, or excluded [ ,  ]. The severity of social anxiety is continuously distributed [ – ] and an excessive form of the condition has been labeled social anxiety disorder (SAD) [ ]. Certain clinical features of individuals with high social anxiety have been described, including poor social relationships [ ,  ], difficulties with emotional regulation [ ], and sensitivity to the perceived threat of social isolation [ ,  ,  ]. People with high social anxiety also have poor quality and fewer intimate social interactions with others, including basic acquaintances and intimate partners [ ,  ]. Certain studies investigating social ostracism have employed a ball catching game paradigm named Cyberball, in which participants are virtually ostracized [ – ]. In Cyberball, participants play catch with two other players whose actions are in fact computer generated. The two computer-generated players toss the ball to the participant at the beginning of the game and after a while they may continue to do so, or may not throw the ball to the participant at all, or do so only infrequently. Social ostracism evokes physiological [ ] as well as psychological reactions [ – ], and reactivity to exclusion simulated by the Cyberball computer task prospectively predicted social anxiety 2 months later [ ]. 

The Cyberball task has been administered to socially anxious individuals, and when they are excluded, they show reactions distinct from those of socially non-anxious persons [ ,  ]. Excluded socially anxious people show lower need scores, including belonging (e.g., “I felt like an outsider”), self-esteem (e.g., “I felt good about myself”), control (e.g., “I felt like I had control over the course of the interaction”), and meaningful existence (e.g., “I felt nonexistent”), than socially non-anxious persons [ ], indicating that socially excluded individuals, especially those with high social anxiety, experience greater need-threat. Oaten et al. (2008) [ ] also used the Cyberball paradigm and showed disordered self-regulation in people with high social anxiety. 

In order to examine the neural responses underlying the effect of ostracism, neuroimaging studies have been conducted during Cyberball. It has been reported that healthy people show increased anterior cingulate cortex (ACC) and insula activity when they are excluded from getting the ball [ ,  ]. Emotional support can frequently help to diminish social distress. Such support may play an important role at different points in the chain of events that begins with a potential stressor and culminates in physiological stress [ ]. Regarding emotional support, our previous study demonstrated that when healthy participants got emotionally-supportive messages while they were being excluded from getting the ball, they showed both decreased social distress and decreased ACC activation compared to when they were socially excluded without supportive messages [ ]. In addition, left dorsolateral prefrontal cortex (DLPFC) activation was negatively correlated with participants’ subjective feelings of social distress: Increased DLPFC activation corresponded to increased beneficial effects of social support on subjective social pain [ ]. However, to the best of our knowledge, previous studies have not investigated brain areas associated with social anxiety, either while people are excluded, or while they are being emotionally supported. 

The present experiment was conducted using the Cyberball paradigm to examine particular neural responses associated with social anxiety while people with a broad range of social anxiety scores were ostracized and were provided with emotional support while being ostracized. We investigated (1) if social anxiety is positively correlated with ACC activation while people are excluded from a virtual ball-tossing game, and (2) if emotional support was less effective in ameliorating the subjective distress of more socially anxious people while they were being ostracized, by examining if DLPFC region activation is negatively correlated with increased subjective social distress and social anxiety. 


## Method 
  
### Ethics Statement 
  
The Ethics Committee of Hiroshima University approved the present study and all participants signed a written informed consent form. 


### Participants and questionnaires 
  
Forty nine right-handed undergraduates took part in the study. Three of them were excluded from analyses because of protocol malfunction, and 46 people (29 women; mean age = 19.85 years) were ultimately included in the final analysis. Of these, 37 participants had no current Axis I disorders, whereas 9 participants met criteria for SAD based on the Structured Clinical interview for DSM-IV, Axis I (SCID). Participants also completed the Brief Fear of Negative Evaluation Scale (BFNE) [ ]. The BFNE is a brief version of the original Fear of Negative Evaluation Scale (FNE) [ ] that assesses the interaction-related anxiety subtype, which is part of the social anxiety spectrum [ ]. People with high FNE show a more negative perception of their own actions as the anxiety level in a situation increases [ ]. BFNE scores are highly correlated with original FNE scores [ ] and were found to provide more information than the original FNE [ ]. The BFNE also has the practical advantage of brevity, and has become a frequently used instrument in social anxiety research with non-clinical populations [ – ]. The mean BFNE score for patients with social phobia is reported to be 51.5 points (standard deviation (SD) = 7.3), with a range between 30.0 to 60.0 points, whereas the mean score of a community sample is 29.2 points (SD 8.2), with a range between 16.0 to 52.0 points [ ]. As the BFNE scores in the present study ranged from 18 to 57 points (median = 40), with the mean score being 39.65 points (SD = 11.03), participants in the present study showed a wide range of social anxiety. Participants also completed a 12-item measure of social distress [ ] which assesses participants’ subjective experience of social distress during the Cyberball task, including self-esteem (“I felt liked”), belongingness (“I felt rejected”), meaningfulness (“I felt invisible”), and control (“I felt powerful”) [ – ,  ]. As in previous studies [ – ,  ], we used these 4 items for present analyses. Each item is rated from 1 to 9, with total scores therefore ranging from 4 to 36. It has been reported that this measure of subjective experience has acceptable reliability and validity [ ]. 


### fMRI session 
  
An experimental manipulation of social exclusion (ostracism) was conducted using the Cyberball task, as modified by Onoda et al., (2009, 2010); see   [ ,  ]. Participants were initially told that the experimenters were interested in the neural mechanisms that underlie mental visualization ability, and that they would be playing a game of catch with two other players (actually computer generated), while being connected via the Internet. The two other players, whose photographs were shown to the participants before the fMRI session, were of the same gender and similar age as the participants. The photographs of the two supposed players were obtained from the SOFTPIA JAPAN database (the service has since been terminated), by selecting 20 neutral faces of people in their twenties (10 of each gender). Twenty-three graduate students then rated the faces on three aspects: Preferences, congeniality, and attractiveness. For each gender, four photographs with median ratings on these aspects were selected and used for the experimental sessions, to be used in pairs. Two combinations of two photographs were selected for each gender and were counter balanced. 
   Cyberball Paradigm.  
Each block was composed of a ball catching phase for 26~28 seconds, with messages provided on the top center of the screen. Two messages and intervals of 12~18 seconds were provided for each block. There were five blocks in each condition. 
  
Participants saw a ball, cartoon images representing the two virtual computer players on the left and right sides of the screen, an arm representing the participant on the lower central portion of the screen, and a message at the top of the screen ( ). The virtual players automatically threw the ball to each other or to the participant. The participant was free to decide who would next receive the ball, and to throw the ball by pressing a button on a button box. The ball was thrown 9~12 times per block. Participants were also told that when one of the other players caught the ball, they were to push the button on the same side of the button box as the player who caught the ball. Throughout the ball-tossing game, messages were displayed. Participants were told to pay attention to messages that were supposedly displayed on the screen by experimenters who were watching the ball-tossing game in a separate room. In fact, the messages had been preprogrammed. A message was presented for the first half of a block, and then another message was shown for the second half of the block. Therefore, two messages per block (10 messages per condition) were shown to the participants. 

The fMRI task in the Cyberball paradigm consisted of four conditions, and each condition contained five blocks with a duration of 26~28 seconds per block and a 12~18-second rest periods between blocks. Because the paradigm was self-advancing for each participant, block length varied slightly across individuals. The first condition was the control condition (CON). In CON, participants were told that experimenters had to confirm the connection to the Internet through the participants’ button push. Therefore, participants knew that they would not be thrown a ball during the control condition. The next condition was the social inclusion condition (IN), during which participants received three or four throws per block. The ratio of ball tosses received by participants varied between 30%-35% across the five inclusion blocks. The third condition was the social exclusion condition (EX), during which participants received no ball throws. Participants were told that after they received a message to start playing catch with three people at the end of the CON condition, the catch game would start and continue until the end of the Cyberball task, such that they could expect that balls would be thrown to them throughout the Cyberball task. On the other hand, participants were also told that when one of the other players caught the ball, they had to push the button on the same side of the button box as the player who caught the ball. Although participants were anticipating ball throws throughout the Cyberball task, they were never thrown the ball during the EX condition. Therefore, participants had to push the button on the same side of the button box as the player who caught the ball, while in fact anticipating that they would be thrown balls during the EX condition. As a result, the difference between CON and EX was that participants were aware in advance that they were not supposed to be thrown the ball (CON), or they were not aware of this (EX). In CON, IN, and EX, messages displayed on the screen consisted of experimental instructions: For example, “The button box is under validation,” “Intervals are included in a certain period of time,” “Do not sleep, please.” The last condition was the social support condition (SUP); this condition and EX were identical, except for the messages, which were caring statements instead of experimental instructions [ ]. Emotionally-supportive messages were chosen from 17 messages on the basis of 23 graduate students’ ratings. The ratings were based on understanding the participants’ feelings, taking a hopeful view of the situation, and encouragement to remain in the socially excluded situation. The ten highest-rated messages were selected and displayed on the screen during SUP. Examples of emotionally-supportive messages included “We are sorry for making you feel terrible,” and “I know it was unpleasant for you to be excluded.” 

Upon completion of the virtual game, participants retrospectively completed questionnaires outside of the MRI that assessed their subjective experiences [ ] during each condition of the Cyberball task, with the exception of CON. As we had to make participants believe that they were playing catch with actual people instead of computer generated players, we did not assess social distress during CON [ ]. Instead, we assessed participants’ subjective experiences before the fMRI session as a baseline. Since we examined the imaging data for contrasts between the conditions, as will be described subsequently in the fMRI data acquisition section, we subtracted the numerical value of participants’ subjective experiences at baseline from those during the three analyzed conditions (IN, EX, and SUP). At the end of the procedure, participants were fully debriefed. 


### fMRI data acquisition 
  
A Symphony 1.5 tesla scanner (Siemens AG, Symphony, Tokyo, Japan) was used to acquire imaging data. A time-course series of 297 volumes per participant was acquired with echo planar imaging (EPI) sequences (repetition time (TR) = 3000 ms, echo time (TE) = 40 ms, field of view (FOV) = 256 mm, matrix size = 64 x 64, 30 slices, 4 x 4 x 4 mm voxel dimensions, flip angle =. 90)). Functional scans lasted 14 min and 57 s, including a pre-baseline interval (15 s). After functional scanning, structural scans were acquired using T1-weighted gradient echo pulse sequences (TR = 12 ms, TE = 4.5 ms, FOV = 256 mm, flip angle =. 20), which facilitated localization. 


### Data analysis 
  
Image processing and statistical analyses were carried out using Statistical Parametric Mapping (SPM8) software (Wellcome Department of Cognitive Neurology, London, UK) under Ubuntu Linux 10.04. The first five volumes of the fMRI run were discarded because the MRI signals were unsteady. All EPI images were realigned to the first volume, slice timing correction was performed for each set of functional volumes, spatially normalized to a standard template based upon the Montreal Neurological Institute (MNI) reference brain, and smoothed using an 8-mm full width at half maximum Gaussian kernel. To perform image data analysis, a whole-brain voxel-by-voxel multiple linear regression model was employed at the individual participant level. Four regressors for each condition (CON, EX, IN, and SUP) were modeled with a canonical hemodynamic response function. The realignment parameters were also included in the model as a covariate of no interest. We created the following two corresponding contrasts for the first-level analysis for each participant to isolate brain circuits related to (1) social exclusion and (2) social support: (1) EX–IN and (2) SUP–EX. These individual contrast images were used at the whole-brain group-level, random-effects analyses. First, one sample   t  -tests were performed to assess the overall effect of each contrast and to see if the present sample with the current experimental paradigm showed acceptable neural activity consistent with previous healthy samples. Second, regression analysis using continuous social anxiety as measured by the BFNE was performed to assess the effect of social anxiety on each contrast. We decided on a cut-off threshold that would minimize the risk of Type II errors [ ]. However, we also had to reduce Type I error risk. Therefore, we decided to employ a cut-off threshold of   p   < 0.005 (without a correction for multiple comparisons) with a cluster size of k > 30, after Choi et al. (2009) [ ], instead of a cluster size of k > 10 as recommended by Lieberman et al. (2009) [ ]. Additionally, we reported results using Region-of-Interest (ROI) analyses as supporting information, in order to confirm the overlap between reported regions and those of previous studies. A ROI for the ACC was defined as a 10mm-sphere centered on 10, 32, and -10, based on peak voxels identified in our previous study during an EX to IN comparison. Another ROI was defined for the DLPFC as a 20mm-sphere centered on -34, 24, and 22, based on peak voxels identified in our previous study during a SUP to EX comparison. In these ROI analyses a stricter significance level of p<.05 for family wise error (FWE) corrected for the small volume based on our previous study [ ] was used. We created EX-IN contrast to isolate brain circuits related to social exclusion, and we created a SUP-EX contrast to isolate brain circuits related to social support using this threshold. If brain regions that are not associated with social exclusion or social support correlated with social anxiety as measured via the BFNE, it would be difficult to interpret such an association with consideration to social anxiety. Therefore, we focused on brain regions that are associated with social support or social exclusion and are also known to be modulated by social anxiety. 

Activated clusters were localized using Anatomical Automatic Labeling for SPM8 ver. 1 (  http://www.cyceron.fr/web/aalanatomicalautomaticlabeling.html  ). The ROIs for the ACC and DLPFC were defined using the WFU Pickatlas (  http://www.fmri.wfubmc.edu/download.htm  ). Behavioral data was analyzed using one-way repeated measures ANOVA with the Statistical Package for the Social Science (SPSS) version 20.0.0. Averaged contrast values estimated during SUP compared to EX in the active cluster from the regression analysis was extracted using MarsBar (  http://marsbar.soureeforge.net/  ). 



## Results 
  
### Behavioral results 
  
We performed a one-way repeated measures analysis of variance (ANOVA) to analyze participants’ subjective experience of social distress during participation in a ball-tossing game (IN), during exclusion from a ball-tossing game (EX), and when being offered emotional support (SUP) while being excluded from the game. Participants’ self-reported social distress levels are shown in  . There was a significant main effect of condition,   F   (2, 90) = 52.15,   p   < 0.001, η  = 0.537. Bonferroni post-test analysis indicated that the subjective social distress during IN was lower than during EX (  p   < 0.001, Hedges’s g (g) = 0.47), as well as lower than that during SUP (  p   < 0.005, g = 0.34). Moreover, social distress during EX was higher than during SUP (  p   < 0.005. g = 0.12). There were no significant positive or negative correlations between subjective social distress and self-reported social anxiety for the EX-IN or SUP-EX comparisons (EX-IN:   r   = 0.232,   p   = 0.121, SUP-EX:   r   = -0.082,   p   = 0.587). 
   Subjective experiences of social distress during each condition.  
The values for subjective experience of social distress were: (1) during participation in the virtual ball-tossing game (IN, mean value = 15.70, standard deviation (SD) = 3.18, 95% confidence interval (CI) 14.75–16.64), (2) during exclusion from getting the ball (EX, mean value = 24.48, SD = 5.14, 95% CI 22.95–26.01), and (3) during supportive messages (SUP, mean value = 22.15, SD = 4.41, 95% CI 20.84–23.46). There were significant main effects of condition: Social pain was higher during EX and during SUP than during IN, and lower during SUP than during EX. IN = the social inclusion condition, EX = the social exclusion condition, SUP = the social support condition. ***   p   < 0.001, **   p   < 0.005. 
  

### Neural activity during social exclusion and social support 
  
The entire present sample evidenced several regions of activation during EX compared to IN and during SUP compared to EX. A one-sample   t  -test indicated that, similar to previous studies [ ,  ], participants showed significantly increased activity in the right medial prefrontal cortex, including the ventral anterior cingulate cortex (vACC) (x = 4, y = 36, z = -18,   t   = 4.88, cluster size = 1011,   p   < 0.005,  ,  ) and bilateral insula (x = 40, y = -14, z = 18,   t   = 7.30, cluster size = 929, x = -42, y = -18, z = 20,   t   = 6.78, cluster size = 584,   p   < 0.005,  ), during EX compared to during IN. Participants also showed significantly increased activity in the bilateral lateral prefrontal cortex (LPFC), bilateral temporal pole (TP), left superior temporal sulcus (STS), bilateral medial prefrontal cortex (MPFC), and bilateral precuneus ( ,  ) during SUP compared to EX. Small volume (ROI) analyses revealed significant activations (FWE-corrected < 0.05,  ) in the ACC during EX comparing to IN (x = 4, y = 34, z = -16,   t   = 4.64, cluster size = 165,   p   = 0.002, FWE corrected) (Figure A in  ) and in the DLPFC during SUP comparing to EX (x = -34, y = 24, z = 40,   t   = 5.85, cluster size = 83;   p   < 0.001, FWE corrected) (Figure B in  ). 
   Brain regions indicating ostracism and social support.  
The brain regions indicating ostracism-induced activation were identified during the social exclusion condition compared to during the social inclusion condition (A) and brain areas indicating social-support-induced activation were identified during the social support condition compared to the social exclusion condition (B). 
     Local maxima of brain activity showing significant social exclusion and social support effects.        

### Regression analysis 
  
We conducted simple regression analyses using BFNE scores to assess possible relationships between social anxiety and social exclusion (EX-IN), as well as social support (SUP-EX) masked by the positive effect of each contrast (inclusive mask threshold was set at   p   < 0.05 uncorrected). Results indicated neither a significant positive relationship nor a significant negative relationship between social anxiety and social exclusion (EX-IN). Moreover, a significant positive relationship between social anxiety and brain activation during social support (SUP-EX) was found for the left DLPFC (x = -28, y = 32, z = 40, t = 4.70, cluster size = 54,   p   < 0.005,  ), whereas no brain region showed a negative relationship between social anxiety and brain activation (SUP-EX). The relationship between social anxiety and DLPFC activation during social support (SUP-EX) survived small volume correction at   p   < 0.05 with FWE correction, within a 20mm-sphere ROI for the DLPFC (x = -28, y = 30, z = 36,   t   = 5.03, cluster size = 17,   p   = 0.004, FWE corrected,  ) (A and B Figs in  ). 
   Correlation of the activation in the DLPFC between social anxiety and social distress.  
The left dorsolateral prefrontal cortex (L.DLPFC), for which significant positive correlation between changes of brain activation and BFNE scores were found (A). To illustrate the correlation between L.DLPFC activation and social anxiety, a scatter plot of the relationship between changes in blood-oxygen-level dependent (BOLD) signals in the L.DLPFC and BFNE scores during the social support condition compared to during the social exclusion condition is presented (B). To illustrate the correlation of L.DLPFC activation and subjective feelings of social distress, a scatter plot of the relationship between changes in blood-oxygen-level dependent (BOLD) signal in the L.DLPFC and subjective feelings of social distress during the social support condition compared to during the social exclusion condition is presented (C). BFNE = the Brief Fear of Negative Evaluation Scale. 
  
In order to investigate functions underlying increased left DLPFC activation, we examined the potential relationships between self-reported social distress and brain activation in the left DLPFC during SUP compared to EX. We conducted a correlational analysis to examine changes in social distress during the social support condition compared to the social exclusion condition. We found that there was a statistically-significant negative correlation between changes in subjective social distress and left DLPFC activation (  r   =   -  .364,   p   = 0.018,  ) during SUP compared to EX. 



## Discussion 
  
In this study we examined how social anxiety is correlated with underlying neuronal activities while ostracized people were being provided with emotional support. Results showed that left DLPFC activation was positively correlated with social anxiety. Moreover, changes in left DLPFC activation were negatively correlated with participants’ subjective social distress. This is the first study to report that increased activation in the DLPFC is associated with a decline in subjective social distress in highly socially anxious participants, while they were being provided with emotional support. 

The DLPFC is a central regulation area in the brain involved in cognitive control [ – ]. It is known that fear of negative evaluation is one of the core features of SAD. However, positive evaluation is also important for individuals with SAD [ ]. We speculated that socially anxious individuals might show increased left DLPFC activity when perceiving supportive messages from others. This is suggestive of an excessive apprehension around stimuli potentially related to evaluation by others, even when the evaluation is positive. The underlying mechanisms of this process, however, remain to be identified. On the other hand, changes in left DLPFC activation were negatively correlated with participants’ subjective social distress, which suggest that their ability to recognize social support remained intact. Since all our participants, including the socially anxious individuals, were university students, they might have been relative well adjusted through effective cognitive control of fears that they experience during their daily lives. It is not clear if this phenomenon could be generalized to different stages of SAD, or whether it could distinguish people with a non-clinical level of social anxiety from a clinical population with SAD. Patients with social phobia have shown decreased DLPFC activation compared to healthy individuals in research using a stressful task [ ], social stimuli [ ], and reappraisal of negative self beliefs [ ]. Hence, in the present study, participants who were socially anxious might have been able to deal with their anxious feelings through increased activation in the DLPFC, without developing symptoms of severe social anxiety. Increased activation in the DLPFC might be involved in facilitating functioning in social situations, in spite of the relatively high social anxiety of these participants. Consequently, DLPFC activation during emotional support might indicate differences between non-clinical and clinical populations of individuals with SAD. 

No areas of the brain showed positive or negative relationships with social anxiety, while participants were excluded (EX-IN). Moreover, subjective social distress while participants were excluded from the game, compared to when they were included, did not show a significant relationship with social anxiety. Findings of previous studies examining the effects of social anxiety on ostracism have not been consistent [ ,  ,  ]. The present results indicated that neural responses underlying social exclusion were not associated with social anxiety, which could suggest that social isolation itself is not an exceptionally painful experience for people with social anxiety. 

The present experimental paradigm demonstrated that when participants were excluded from the ball-tossing game, their subjective social distress increased, which is similar to previous research findings [ – ,  ,  ]. Participants reported that their subjective social distress was the highest when they were excluded from the virtual ball-tossing game (EX), and that their social distress decreased when they received supportive messages (SUP) while they were excluded, compared to when they received no such messages during exclusion (EX). The activation in the vACC was stronger during EX than during IN, which is consistent with previous studies [ ,  ], including our own that compared SUP and EX [ ] and showed stronger activation in the MPFC, LPFC, TP, and STS. These findings suggest that the present experimental design can successfully replicate the Cyberball paradigm, and therefore that the analysis used in this study was valid. Also, left DLPFC activation was negatively correlated with participants’ subjective social distress, which replicated our previous study [ ]. 

Brain regions that are activated during SUP compared to EX, including the MPFC, temporal pole region, STS, and precuneus, are regions that comprise the theory-of-mind network [ ,  ]. Theory of mind refers to the distinction between one’s own thoughts and intentions and those of others [ ], as well as to the ability to be aware of mental states of oneself and others [ ]. Participants in the present study might have made effective use of theory of mind in order to benefit from socially supportive messages. 

There are limitations of this study. It was conducted as a preliminary investigation with non-clinical participants. We considered it appropriate to use a non-clinical population in this study, because social anxiety is considered to lie on a continuum in the general population [ ,  – ]. In addition, it was advantageous to conduct a preliminary study in which the results were not confounded by variations in levels of medication and/or severity of mental disorder. This study demonstrated an association between brain activity and subjective ratings. However, the participants in this study were university students who were likely capable of adequately handling their academic responsibilities and their daily lives, even though some of the participants had several symptoms of SAD. Future studies should sample clinical populations suffering from severe symptoms of SAD that require treatment. Another limitation of this study was that all of the participants were undergraduates and therefore, the results of this study cannot be generalized to younger populations, such as adolescents, or to people older than college undergraduates. Despite the shortcomings of a fixed sequential design, we conducted the Cyberball paradigm in a sequential order, because it was necessary to make participants believe that they were playing catch with real people. Moreover, it was important to prevent participants from anticipating being excluded. If emotionally supportive comments were shown in advance of participants being excluded, this might have aroused participants’ suspicions about the game played via the Internet. From these reasons, we used a fixed sequence, similar to previous studies [ ,  ,  ]. As a result, it is possible that the differences in activation between the experimental conditions are confounded by tiredness, or by resignation regarding the experience of being excluded from the social interaction. In the present study, activation of the dACC or insula did not decrease during SUP compared to EX. We interpret this phenomenon, in which social distress is decreased during SUP compared to EX, as the product of increased activation in the DLPFC, rather than decreased activation in the dACC or insula. However, further investigations are required to clarify this account. We used the BFNE as a measure of social anxiety. The BFNE is a brief version of the FNE that assesses an interaction anxiety subtype, which is part of the social anxiety spectrum [ ]. Although this is an important aspect of social anxiety [ ], future studies should use other commonly used social anxiety scales such as the Liebowitz Social Anxiety Scale [ ]. 

The present study investigated neural response to emotional support provided through positive messages. Given that people with SAD exhibit altered neural reactions to facial expressions suggestive of social rejection [ ], future studies should take differences in neural reactions between positive messages and negative messages into consideration, in order to verify anxious reactions to various social interactions. 

In summary, the left DLPFC activity during SUP compared to EX was positively correlated with social anxiety as measured by the BFNE. More socially anxious participants showed stronger DLPFC activation when they got emotional support compared to exclusion without emotional support. Social anxiety was associated with an increased BOLD signal in the left DLPFC when individuals were offered positive social support while being excluded. 


## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-5'>
<h2>5. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/23155450/' target='_blank'>23155450</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Effect of Intentional Bias on Agency Attribution of Animated Motion: An Event-Related fMRI Study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2012</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0049053</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3498331/' target='_blank'>3498331</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an event-related whole-brain fMRI study in healthy adults (n=12, mean age 25.2) using Heider–Simmel-style animations to probe agency attribution and theory-of-mind/intentionality (social cognition). Analysis used whole-brain random-effects SPM2 contrasts (reported at p<0.001 uncorrected) with activation maps across cortex (STS, IFG, temporal pole, occipital areas), not limited to ROIs. Participants were healthy and within the 17–65 age range. No clinical-group–only results or ROI-only reporting were found. Therefore all inclusion criteria (social-related task, healthy adult sample, whole-brain analyses) are met and no exclusion criteria apply.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Animated movements of simple geometric shapes can readily be interpreted as depicting social events in which animate agents are engaged in intentional activity. However, the brain regions associated with such intention have not been clearly elucidated. In this study, intentional bias was manipulated using shape and pattern animations while measuring associated brain activity using event-related functional magnetic resonance imaging (fMRI). Twenty-five higher-intention involved and twenty-five lower-intention involved animations were presented to participants. Behavioral results showed that the degree of agency attribution of the mental state increased as intentional involvement increased. fMRI results revealed that the posterior superior temporal sulcus (STS), inferior temporal gyrus (ITG), inferior frontal gyrus (IFG), premotor, temporal pole, supramarginal gyrus, and superior parietal lobule (SPL) were activated while participants viewed the high-intention animations. In contrast, occipital, lingual, and middle frontal gyri were activated while the participants viewed the low-intention animations. These findings suggest that as agent attribution increases, the visual brain changes its functional role to the intentional brain and becomes a flexible network for processing information about social interaction. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (29268 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Recent evidence from cognitive social neuroscience has accelerated our understanding of intricate social brain functions, including processes involving the perception of others and their apparent behavior. However, relatively little research has been conducted to evaluate agency and its role in intentional bias. Moreover, there is limited evidence regarding how the intentional brain can be differentiated from the visual brain. For example, some configural cues such as contingent movement of geometrical patterns trigger an agency or animacy detectors in the brain that can partially explain intentional agents such as other people's minds. 

We hypothesize that the specific intentional brain function of estimating others' mental states based on agency attribution is an extended version of the visual brain. This extension involves recruiting higher brain regions found in the temporo-parietal cortices like the superior temporal sulcus (STS)  . The social braininvolves consciousness of one's own and others' mental states, intentions, attitudes, beliefs and motives and, therefore, is closely related to the theory of mind (ToM) and intentional agents. The ToM requires the ability to estimate the intentional states of others. Estimating another's state of mind involves modeling the other person's intention, possibly by agency attribution and one's own past experience. 

Current social neuroscience studies suggest that the superior temporal sulcus (STS) and medial prefrontal cortex (MPFC) are likely essential components of the social brain region involved in intentional tasks. In order to examine this issue, we developed simple animations that manipulated intentional bias (higher- and lower-intention involved animations) by representing geometrical shapes as opposed to complex verbal or visual tasks. 

In their seminal research, Heider and Simmel (1944)   and Michotte (1963)   used simple moving geometrical patterns as intention-involving agents in a local environment (i.e., a house having walls and a door). In Heider and Simmel's classic experiment, observers were asked to interpret a moving-picture film in which three geometrical figures (i.e., a large triangle (“T”), a small triangle (“t”) and a circle (“c”)) moved in various directions. A rectangle (“house”) with a wall section that opened and closed as a door was also shown. In their original film sequence, the animation was as follows. When the door opened, “t” and “c” moved into the “house.” Then, “T” moved into the “house” and shut the door. Next, “T” and “t” fought and “T” won. Finally, “t” and “c” broke through the door and ran away from the house. This work suggests that moving shapes can simulate the actions of living beings and, therefore, can represent agents performing actions. Accordingly the moving shapes are perceived to have goals and to possess qualities of an intentional mind. Therefore, the moving shapes are likely observed as if they represent the intentional states of others. 

In his theory of interpersonal relations, Heider proposed that individuals perceive and create explanations for the behavior of other's, a process he called “attribution”  . Researchers have documented that higher-order cognition involving concepts such as causality and agency can be elicited by observing interactions, but not by observing the independent random movements of simple geometrical objects. If animations could possibly evoke mental state attributions based on intention, we propose that attributions of a mental state can be applied to animated objects. If this supposition is true, it would suggest that the neural substrate associated with understanding intentional events would include the same substrate (i.e., the STS) that becomes active when watching an interactive animated object in cooperation with other regions  . To date, however, there have been few empirical studies to investigate why and how these attributions are affected by animations containing objects with lower- or higher-intentional involvement. 

In mentalization studies in which the ability to estimate another's mind is required, the observer must infer and model the intentions of another person. In this type of paradigm, the observer models the behavior of the other person prospectively by using attributions that are represented as animated dots or cartoons. For example, Baron-Cohen et al. (1994)   found a rCB (regional cerebral blood flow) increase in the orbitofrontal cortex of the right hemisphere during the TOM task. Abel, Happe, and Frith, using two triangles moving around the screen in one of three ways (ToM-like, in a goal-directed way, or randomly), compared the attribution of the mental state in autistic children having less TOM than that of normal children, finding that the former used mentalizing (ToM-like) descriptions less often than the latter did  . 

In another study, Schultz et al. presented short animations to participants in which two moving disks appeared to be either interacting or moving independently from each other  . Using fMRI, they found that activation in the STS increased in proportion to the degree of correlation between the motion of two disks, and that an increase in correlation increased the amount of interactivity and animacy the observers attributed to the two disks. 

Perception of animacy also influences interactive behavior  . Recent fMRI studies using non-Heider & Simmel patterns showed that the STS is also activated by simple moving objects whose interactions appear causal or intentional   and that the STS is involved in the representation of observed intentional actions  . Saxe et al. presented a real movie of a human walking into a room with or without occlusion (e.g., bookcase), finding that the walking figure activated the right posterior STS, which appears to be sensitive to the relationship between the observed motion and local environment  . They further hypothesized that the right posterior STS is involved in the representation of observed intentional actions. 

In a study using PET, Castelli, Happe and Frith presented participants with a silent, computer-generated animation involving two simple geometric shapes (e.g., triangles) that resembled Heider and Simmel patterns  . They found that the STS, MPFC, and temporal regions, including the fusiform gyrus, temporal pole, and occipital gyrus, were activated. The investigators argued that these animations strongly evoked mental state attributions based on intentions and hypothesized that the ability to make inferences about another's mental state evolved from the ability to make inferences about another's apparent behavior. Their findings suggest that controlling the degree of intention from high to low evoked by animations that vary in attribution appears to be critical in this type of research. They had six adult participants observe an animation that involved two moving triangles that manipulated the degree of intention from high to low in three ways: 1) ToM-like, corresponding to high intention; 2) goal-directed, corresponding to intermediate intention; and 3) randomly, corresponding to low-intention intention. These stimuli could therefore be graded from random movements to goal-directed actions, and finally to complex intentional states. 

The primary goal of the current work was to evaluate the degree to which intentional bias could result in greater STS activation and less MPFC activation. Similar animations were used such that objects always stayed within the same local region. However, animations differed in terms of their movements. Specifically, some animations were designed to give a graded impression of either intentional-oriented interactions or mechanical-oriented movements  . In other words, a primary aim of our study was to describe how the social brain is influenced by animations that evoke high intention relative to less or no intention. We sought to replicate and extend the findings of Castelli et al.   using a larger sample and event-related technology, and by grading stimuli based upon random movements, goal-directed actions, and complex intentional states. 


## Methods 
  
### Participants 
  
Twelve healthy, right-handed participants (4 males and 8 females; mean age = 25.2) and fifteen separate participants (11 males and 4 females, mean age = 25.8) were recruited for the fMRI experiment and preliminary rating study, respectively. All had normal or corrected-to-normal vision, and were screened for the presence of current or past neurological and psychiatric disorder. 


### Ethics Statement 
  
The experiment was conducted in accordance with the guidelines of the ethical committees of the Brain Activity Imaging Center (ATR, Kyoto, Japan) and of Kyoto University. All individuals voluntarily participated in the study and provided their written, informed consent prior to study participation. 


### Procedure 
  
The animations used in the study was modeled on that of Heider and Simmel  .   depicts examples of the five-second animations (moving from left to right) used. Two or three triangles of different colors (blue, pink, and green) moved around on a black background. These triangles corresponded to the “t,” “c,” and “T” stimuli used in the Heider and Simmel animation. Additionally, the animation had a “house” with a gap on its side wall. 
   Typical animation strips from high- and low-intention groups, each 5 seconds in length from left to right.  
Three geometrical objects of different colors (blue, red, and green triangle) move around a black background containing a “house,” which has a gap on its side wall. Preceding the experiment, 2 sets of 25 animation movies each were developed that involve high- and low-intentionality groups. The movies varied in terms of the ratio of degree of attribution of mental states to animated pattern. For example, when the door opened, blue and red move into the “house”. Then, green moves into the “house” and shuts the door. Green and blue fights and green wins. Blue and red broke the door and they ran away from the “house” under the highest intentionality condition (rated 5.77), while figures move in parallel under the lowest intentionality condition (rated 1.79). 
  
The upper panel of   shows a high-intention-involved animation (rated 5.77 and corresponding to condition i = 1 in  ; see movies for details). In our preliminary study (see below), one participant reported a ToM-like story corresponding to the high-intention-involved animation as follows: “When the door of the ‘house’ opened, the blue and pink triangles moved in. Then, a green triangle moved in. Green and pink fought and green won. Blue and pink broke out of the ‘house’ and ran away. Based on this script, the two triangles were chased and persecuted by the green triangle and each triangl moved in an interactive way. 
   Samples of matched animation sequence from left to right with a 1 s interval between sequences.  
The upper panel depicts matched pairs (i = 9, r = 9; three triangles) and the lower panel depicts other matched pairs (i = 19, r = 19; two triangles). I = intention; R = random. 
  
The lower panel of   depicts a low-intention-involved animation (rated 1.79 and corresponding to condition r = 1 in  ; see movie file in detail). In our preliminary study (see below), a typical response to a story corresponding to one of the low-intention-involved animations as follows: “Triangles moved merely randomly or drifting without interaction”. By varying the motion path of the triangles, 25 different pairs consisting of one high- and one low-intentionality animation were designed for a total of 50 animations. Interactive motion (two triangles chased and persecuted by the third triangle) was varied by the experimente. In order to test the effect of the number of objects, we used three triangles in all but six pair in which the green triangle did not appear. The animations were created and encoded using Adobe Flash CS3 (30 flames per second, 320×320 pixel). 


### Preliminary study 
  
In the preliminary behavioral study, 15 participants rated each animation based on an intentionality score. The intentional score was rated using a Likert-type scale of 1 to 7 (1: not at all intentional; 7: highly intentional). Next we selected 25 “high” and 25 “low” intentionality animations. Observers were asked to rate intentionality between the blue object and the other objects based on their mutual actions. 

Pairs of high- and low-intention animations were created. Their paths of motion are shown in  . The highest-intention animation was created in a manner similar to the Heider and Simmel   pattern (  upper panel, which corresponds to i = 1 motion path in  ). The lowest intention (i.e., random) animation was made by simple drifting (  lower panel, which corresponds to r = 1 motion path in  ). We also made a series of different intermediate animation pairs for a total of 25 pairs ranging from (i = 1, r = 1) to (i = 25, r = 25), where i and r indicates intention and random, respectively. Thus, we matched animation to have a similar motion path length and time for all triangles within a pair. Based upon this design, it was expected that participants would judge the triangles in a pair (for example, i = 19, r = 19 shown in  ) to be somehow different from each other in terms of intentionality, while triangles in another pair (for example, i = 1(highest), r = 1(lowest) shown in   and  ) would be much different from each other Thus, we created a total of 25 graded steps of stimulus pairs. Of the 25 animations, the mean intentionality score was 5.77 in the “high” group and 1.79 in the “low” group. 

A two-way repeated-measures ANOVA (intention×animation number) revealed a significant main effect for intentionality [F(1,14) = 768.9,   p  <.001] and stimulus number [F(24,336) = 4.82,   p  <.001]. We also found significant interaction between intentionality and stimulus number [F(24,336) = 6.35,   p  <.001]. Multiple comparisons using Turkey's HSD revealed significant differences between high- and low-rated scores. Thus, we confirmed that the higher-rated group was significantly more sensitive to intention than the lower-rated group. T-tests comparisons between the number of objects (2 to 3 objects) found no differences in terms of intentionality. Based on these preliminary findings, we adopted all the stimulus objects tested for later experiments. 


### fMRI session 
  
No participants who participated in the preliminary study participated in the fMRI study. In an fMRI session, an animation was presented one second after a beep tone and an evaluation screen appeared which asked the participant to rate the level of intentionality from one (high) to four (low). Participants made ratings by choosing from two sets of four buttons (one set for each hand). One trial took 17 s, resulting in a total of length of 14 min 30 s for each session. For the first session, fifty moving patterns were presented in random order to participants in a counter-balanced manner. Twenty-five patterns were presented to the high group and to the low group, respectively. In the second session, up-down reversed patterns from the first session were presented. The presentation of normal and up-down reversed patterns was counter-balanced for each participant. In the preliminary study, we confirmed that participants could easily decide a response after reading the agent's intention 3 s after presentation. Therefore, the fMRI scan began 3 s after the animation presentation. 

Animations were back-projected onto a screen viewed through an angled mirror. The size of each animation was 11.5°×11.5°. In one session, participants observed 50 animations presented in random order. The length of each trial was 17 seconds. 


### fMRI data acquisition 
  
Whole brain images were acquired on a 1.5-T whole-body magnetic resonance imaging scanner (Shimadzu-Marconi Magnex Eclipse, Kyoto, Japan). Head motion was minimized with a forehead strap. Functional MRI was performed with a gradient echo-planer imaging (TR = 3000 ms, TE = 49 ms, flip angle = 90°, 5 mm slice thickness, FOV = 192 mm×192 mm, and pixel matrix 64×64). After the collection of functional images, T1-weighted images (154 slices with no gap) using a conventional spin echo pulse sequence (TR = 12 ms, TE = 5 ms, flip angle = 8°, FOV = 220 mm×220 mm, and pixel matrix 256×256) were collected for anatomical co-registration with the functional images. 

After image reconstruction, functional images were analyzed using SPM2 (Wellcome Department of Imaging Neuroscience, London, UK). Six initial images were discarded from the analysis to eliminate the non-equilibrium effects of magnetization. All functional images were corrected for between-slice timing differences in image acquisition and realigned to correct for head movement, which was less than 1 mm within runs. The functional images were normalized and spatially smoothed with an isotropic Gaussian filter (6 mm full-width at half-maximum). Low-frequency noise was removed by high-pass filtering (time constant = 128 s). We conducted the analysis using an event-related design. An onset of an event according to the data analysis occurred three seconds after an animation started based on the results of the preliminary study. 

Data were modeled by convolving the vector of expected neural activity with the canonical hemodynamic response function (HRF) included in SPM2 and modulated by ratings of intentionality (4-point scales: high for 4 and low for 1). Single-participant   t  -contrast images were then entered into second-level analysis using a random effects model for all participants. The levels of statistical significance for these analyses were set to   p  <0.001 (uncorrected). 



## Results 
  
Two contrasts were specified per single-participant analysis: 1) Low versus High and 2) High versus Low. Low-intention involves activations under participant's button press 1 (highest) and 2 (higher) and high-intention involves that of button press 3 (lowest) and 4 (lower). As shown in   and  , fMRI revealed activation of three main areas when participants observed 25 low-intention-involved animations (low>high): the left middle occipital areas including the calcarine sulcus/cuneus (BA17,18), the right lingual gyrus (BA18), and the right prefrontal gyrus in the middle prefrontal cortex (BA9). However, when participants observed 25 high-intention-involved animations and intentional bias was increased (high>low), the activated areas extended to include the bilateral posterior STS sulcus (BA22/37/39), the right temporal pole (BA38), the bilateral inferior frontal gyrus (BA47:IFG), the premotor (BA6), the inferior temporal gyrus (ITG), the left supramarginal gyrus, and the left superior parietal lobule (SPL). We did not find any activation in the MPFC ( ). 
   Brain activation regions for high→low-intention corresponding to the social brain (i.e., yellow area) and areas for low→high-intention corresponding to the perceptual brain (i.e., blue area).  
Event-related fMRI results showed that main activation areas occurred in three regions while participants observed low-intention animations: extrastriate cortices including calcarine sulcus and lingual gyrus (BA 17,18), and right middle frontal gyrus (BA9). During high-intention animations, activation of more widespread regions was observed, including: bilateral inferior frontal gyrus (BA47:IFG), premotor (BA6:PM), superior temporal sulcus (BA22/37/39: STS), inferior temporal gyrus(ITG), left supramarginal gyrus (SMG), left superior parietal lobule (BA 7: SPL), and right temporal pole (BA38:TP). 
     Brain region of activation for each contrast.        

## Discussion 
  
In this study, we sought to investigate the differential contributions of the areas involved in visual and intentional cognitive processes. Participants conducted tasks that required them to make social interpretations by looking at moving objects that were presented as low- or high-intentionally biased animations. By varying the stimuli, we varied the extent to which intentional cognitive processing was required, which facilitated the analysis of intentional and perceptual influences on various brain regions. 

Based upon event-related fMRI data, our results revealed activation of several visual areas including the calcarine sulcus/cuneus and the lingual gyrus (BA17, 18), which is near the fusiform gyru when the visual brain operated in a mechanical low-intention-involved context. The middle frontal gyrus is thought to maintain visual attention to groups of moving objects  . In contrast, the fusiform gyrus is believed to play a general role in the representation of visual stimuli that signify intent, independent of the visual form  . Our finding of activation in the lingual gyrus, which is near the fusiform gyrus corroborates with a previous study  . 

As shown in  , when the brain processes high-intention-involved interactive animations, activation in the posterior STS involving part of the supramarginal area increased. It has been demonstrated that the STS becomes activated while viewing animated geometrical figures portraying social interactions  ,  ,   and when evaluating the intentions of others. Using fMRI, Gobbini et al.   reported that social animations activated an extensive portion of the STS including areas in the posterior STS as well as the inferior parietal lobule. 

In an earlier PET study, Castelli et al.   presented animations that featured two characters (a large red triangle and a small blue triangle) moving on a framed white background similar to Heider and Simmel's pattern  . The investigators presented each participant with three types of animation: 1) ToM (two triangles bluffing one another); 2) goal-directed (two triangles dancing together); and 3) random (two triangles merely drifting). These animations were displayed for approximately 40 s over the course of 12 scans and divided into two consecutive counterbalanced blocks consisting of cued and uncued animations. These animations were designed to evoke mentalizing and elicited activity in the STS relative to a random motion condition. The design of the current study improved that done by Castelli et al. in two ways. First, intentional biases were manipulated continuously from highest to lowest by 25 matched pairs selected from 50 animations using ratings from the participants in a preliminary study. Second, an event-related design was introduced to avoid prior knowledge by using a shorter presentation duration (5 s). Based on our results, it is likely that intentional bias may be controlled more by the STS than by the MPFC, particularly when brain responses to high-intention-involved animations are compared with responses to low-intention-involved animations. 

The STS has been hypothesized to be closely connected to the perception of biological motion. Studies using transcranial magnetic stimulation   and magnetoencephalography   have shown that the simulation of human walking induced by moving dots selectively activates a brain area on the ventral bank in the occipital extent of the STS and the right temporo-parietal junction. Furthermore, such animations may be similar to the Heider and Simmel   paradigm. We show here that tasks tapping mentalization and agency attribution activated the same brain regions in the STS and temporo-parietal cortices including the supramarginal gyrus, inferior temporal gyrus, the temporal pole, and the SPL. One explanation for why we did not find activation in the MPFC is that we used an event-related design to avoid expectancy with a much shorter presentation time than the 30 s previously reported  . Expectancy cueing and longer presentation time could also yield possible contingent activations in the MPFC in addition to controlling intentional bias in the STS. It is highly possible, therefore, that higher-intention-involved animations, such as the fight between the blue and green triangle used in the current study, was perceived by the observer as though he/she was participating in the action against an antagonis. Indeed, humans may possibly detect intentions in shapes, even when those shapes change their motion to face another object  . 

Overall, we assumed that activation in the premotor cortex invoked a mirror system when a human acts and when the person observes the same action performed by anothe  . This system may be important for understanding the actions of other people, and that of the geometrical shapes in our animations. Some researchers also speculate that mirror systems may simulate observed actions, thus contributing to ToM skills  ,  . In the premotor area, a functional mirror system estimating others' intentions may contribute to activation of the IFG  . In the current study, significant increases of activation in the IFG were observed only when the animations were actively viewed with intention. Therefore, it is possible that the IFG monitors intentional thoughts in the STS. In contrast, activity in visual areas, including the lingual gyrus, which is near the fusiform gyrus, was only found in conditions requiring less intentional involvement and passive viewing. 

With close interconnections to the STS, the IFG and the temporal pole provide internally-represented self and other's mental states. Rather than the MPFC per se, it is the ventral side of the IFG, close to the orbitofrontal PFC and temporal pole, along with temporo-parietal-junction areas including the posterior STS and supramarginal gyrus  ) that are possible critical components for the representation of another's mental state. Saxe et al.   examined whether activation of the posterior STS, similar to the perception of intentionality, depends particularly on the contingency between an agent's motion and the environment by introducing short and long occlusions of a walking person's animation strip. They showed that right posterior STS activation occurred following the long occlusion (i.e., when a person remained hidden for a few seconds before re-emerging). In the current study, we found activation in the same region; namely, the bilateral posterior STS, using simple geometric animations depicting high-intention-involved action. The present study suggests that the posterior STS is involved in constructing an abstract visual description of another agent's intentional actions, without engagement of the MPFC. Based on the present results, it is possible that incoming animated information is decoded perceptually and integrated with contextual interpretation; the constituent product of these two processes can be understood either in terms of perceptual- or intention-involved behaviors. 

In their examination of the neural correlates of mentalization, Vogeley et al. (2001)   used fMRI to investigate common and differential neural mechanisms underlying ToM and the self during the presentation of a verbal story, finding that a ToM task led to increased neural activity in the temporal pole, whereas the self-task led to increased neural activity in the right temporo-parietal junction involving the STS. Interestingly, our data corroborate theirs regarding the neural correlates of ToM despite the large differences in the methods employed. The ability to model another intentional mind using an animated patter could be an evolutionary innovation in the human social brain that developed from the perceptual brain. Further investigations are necessary in order to clarify this issue. 


## Conclusion 
  
To summarize, we investigated how the visual brain transitions to the social brain using event-related fMRI in the present study. Animations consisted of moving patterns evoking various mental states of attribution based on intentions. Among 25 pairs of animations, each participant rated the higher- and lower-intention animation according to their attribution of agency (i.e., internal or external). Results showed that activations of the posterior STS, ITG, IFG, premotor, temporal pole, supramarginal gyrus, and SPL occurred under high-intention–involved animations, whereas occipital, lingual, and middle frontal gyri were activated under lower-intention-involved animations. 

Findings of the present study suggest that as intentional stance increased, the portion of the social brain involving the representation of an agent's intentional actions became more activated. Thus, developing the capacity to model another's mind could be an evolutionary innovation in the human social brain that developed from the perceptual brain. Previous studies have implicated regions activated by higher intention in self-monitoring in the perception of biological motion and in the attribution of mental states, and regions activated by lower-intention in simple perceptual processing. In the present study, we report how the visual brain shifts to the social brain in an agency attribution experiment. We suggest that as agent attribution increases, the visual brain changes to the intention-assuming social brain and therefore possesses a flexible network for processing information about social interactions based on agency attribution. 


## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-6'>
<h2>6. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/20644633/' target='_blank'>20644633</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> The Integration of Prosodic Speech in High Functioning Autism: A Preliminary fMRI Study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2010</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0011571</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/2903486/' target='_blank'>2903486</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study reports an fMRI experiment in which participants listened to 90-s connected prosodic speech (affective/communicative prosody), which pertains to social communication and perception of others. It includes a healthy control group of adults (8 males, mean age ~23) within the 17–65 range and reports whole-brain analyses (one-sample and two-sample t-tests, conjunction analyses, FDR-corrected results). Although a clinical HFA group is also included, results for healthy participants are reported separately. Both whole-brain and ROI analyses are present, and whole-brain results are provided, so the study does not meet any exclusion criteria. Therefore it satisfies all inclusion criteria for fMRI studies of social-related processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
## Background 
  
Autism is a neurodevelopmental disorder characterized by a specific triad of symptoms such as abnormalities in social interaction, abnormalities in communication and restricted activities and interests. While verbal autistic subjects may present a correct mastery of the formal aspects of speech, they have difficulties in prosody (music of speech), leading to communication disorders. Few behavioural studies have revealed a prosodic impairment in children with autism, and among the few fMRI studies aiming at assessing the neural network involved in language, none has specifically studied prosodic speech. The aim of the present study was to characterize specific prosodic components such as linguistic prosody (intonation, rhythm and emphasis) and emotional prosody and to correlate them with the neural network underlying them. 


## Methodology/Principal Findings 
  
We used a behavioural test (Profiling Elements of the Prosodic System, PEPS) and fMRI to characterize prosodic deficits and investigate the neural network underlying prosodic processing. Results revealed the existence of a link between perceptive and productive prosodic deficits for some prosodic components (rhythm, emphasis and affect) in HFA and also revealed that the neural network involved in prosodic speech perception exhibits abnormal activation in the left SMG as compared to controls (activation positively correlated with intonation and emphasis) and an absence of deactivation patterns in regions involved in the default mode. 


## Conclusions/Significance 
  
These prosodic impairments could not only result from activation patterns abnormalities but also from an inability to adequately use the strategy of the default network inhibition, both mechanisms that have to be considered for decreasing task performance in High Functioning Autism. 

 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (37064 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Autism is a neurodevelopmental disorder characterized by a specific triad of symptoms such as: abnormalities in social interaction, abnormalities in communication and restricted activities and interests. Communication disorders are considered to be core features of Autism Spectrum Disorders  . While verbal autistic subjects may present a correct mastery of the formal aspects of speech, they have difficulties in pragmatics  ,  . Pragmatics can be seen as the linguistic conditions of appropriate use of sentences in context: the knowledge of basic speech acts types, such as assertions, questions and commands; the knowledge of all the systems of rules governing “things done with words”, such as congratulations and proclamations; and the knowledge of what is to be included in talk-in interaction pragmatics, such as organization of turn-taking  . Pragmatics is essentially conveyed by speech prosody, i.e., the speech musical dimension which is carried by variations of the fundamental frequency (F ) and whose perceptual correlate is pitch. Pragmatics includes modifications in pitch, duration and amplitude at the word and the sentence levels. Clinical observations have reported that young children with autism present either a lack of interest in motherese  ,   or a marked preference for a synthetic voice resembling motherese  , which is in favour of a dysfunction in natural speech processing at an early stage of the development. Numbers of studies have reported that autistic subjects, whether children or adults, present prosodic impairment  – . Thus, prosodic deficits of every kind pepper autistic speech productions: flat or exaggerated intonation, resulting in inappropriate intonation, abnormalities in rhythm and/or in pitch variations. These productive prosodic dysfunctions appear to persist with age although the formal aspects of speech tend to improve  – . Nonetheless, this impairment in prosodic production may stem from a more complex dysfunction concerning prosodic perception, which would be in line with the hypothesis that an abnormality of sensory integration processing would be the core of autism  . 

One test, the Prosody-Voice Screening Profile (PVSP), aims at assessing the speaker's prosody and voice in conversational speech  . The only available test assessing both the perceptive and productive prosodic difficulties in English is the Profiling Elements of the Prosodic System (PEPS-C) developed by Peppé and McCann  . Different studies using PEPS-C have revealed that subjects with Language-Delayed High-Functioning Autism (LD-HFA) present prosodic deficits, distributed about equally on receptive and expressive prosodic tasks   and that the prosodic ability of children with LD-HFA is lower than in children with typical development of the same age from both a productive and perceptive point of view, and somewhat independent of other language skills  . These results suggest a perceptive deficit, even if the fact that this perceptive deficit is the cause or the consequence of the productive deficit still remains to be investigated. 

Atypical processing of low level perceptual processing has been revealed in the auditory domain  . Several studies have reported an enhanced simple low- level processing for pitch discrimination and chord disembedding (spectral processing)  ,   whereas other studies have reported that tasks combining spectrally and temporally dynamic, complex material, with complex operations (speech) display a deficit  ,  . These findings have been related to the weak central theory which predicts that processing information globally may hamper perceptual functions in autism  . However, speech complexity processing by subjects with autism presents a dichotomous picture, since some studies have revealed an enhanced perceptual pitch processing of speech in autism  –  though other studies have put forward a temporal processing impairment in speech   and a lost in the enhanced ability of pitch discrimination in speech  . 

However, while prosodic impairment in autism is beginning to be well documented from a behavioural point of view, little is known about   the neural substrate underlying the integration of prosody  . In typically developing subjects, auditory prosodic processing has revealed the involvement of the frontal, parietal and temporal cortices bilaterally, that is to say the bilateral ventral pathway, the left dorsal pathway and its right counterpart, thus replicating imaging studies in adults  . 

Concerning autism and the basis of prosody, i.e., vocal sounds, an fMRI study of adults with autism and aged-matched controls during passive listening to vocal sounds and non vocal sounds has revealed that the autism group failed to activate bilateral superior temporal sulcus areas, which are considered to be voice-selective areas  , in response to vocal sounds  . Concerning prosody in particular, three studies using cortical-evoked potentials in Asperger have demonstrated deficient encoding of speech and have related this deficit to poor receptive prosody. Kujala and collaborators   have reported that adults with Asperger syndrome present a deficit in the processing of pitch variations which would be linked to hypoactivity of the right cerebral hemisphere. Another study has revealed atypical neural responses to affective prosody in children with Asperger and their fathers, especially over the right cerebral hemisphere, and that this impairment can already be seen at low-level information processes  . The most recent study using MisMatch Negativity has observed an enhanced response in individuals with Asperger in a constant-feature discrimination for both pitch and vowel stimuli whereas no effect has been revealed when the condition involves deciphering phonemes with pitch variations  . The authors have concluded that children with autism lose their advantage in phoneme discrimination when the context of the stimuli is speech-like and requires abstracting invariant speech features from varying input, whereas the discrimination of pitch   per se   is enhanced in autism as compared to controls. A recent study has revealed that children with autism present aberrant, non-direction-specific pitch tracking which could be related to a deficient brainstem encoding of pitch, leading to the hypothesis that abnormalities in pitch processing may stem from an early subcortical processing impairment, which may account for cortical abnormalities  . Nevertheless, though no fMRI study has examined the neural correlates of prosodic speech in autism; three fMRI studies have investigated pragmatics in children and adults with autism. They reported increased activation in the right inferior frontal gyrus for subjects with autism as compared to controls when making inferences from discourse   or when comprehending pragmatic language  , which may reflect the higher task demands that subjects with autism faced when interpreting discourse in context. More interestingly, Wang and collaborators   have investigated the neural basis of irony comprehension in children and adolescents with High Functioning Autism by differentiating the role of prosody and the role of context. Across all conditions, children with autism presented more activation in prefrontal and temporal regions than control children. More specifically, when only contextual cues were present the right IFG was more activated whereas greater activity was observed in the left Superior Temporal Sulcus and the right temporal pole in children with autism versus children with typical development. The authors have suggested that the greater involvement of the temporal regions may reflect a greater burden for children with autism than for control children when task demands require reliance on prosodic information alone. All together, these studies have revealed that subjects with autism present variations in the involvement of right cerebral cortex as compared to controls, when processing pragmatic, affective prosody or pitch variations in speech. 

Along with studies interested in activation patterns, several studies have identified a deficit in the default mode network  . When comparing the differences between psychiatric patients such as in autism  ,   and controls, fMRI studies have revealed differences in decreased activity in the default mode network between patients and controls. Put another way, when subjects perform a cognitive task, activity in task-related areas increases and default mode activity decreases  . Recently, it has been shown that the degree of anticorrelation between activation and deactivation networks is correlated to performance on cognitive tasks  . Impairment in the balance between task-dependent activated and task-independent activated networks could be suggested. 

Taken together, these data suggest the existence of neural abnormalities underlying language impairment and more particularly   prosodic impairment  . It can thus be hypothesized that an abnormal integration of prosody in speech (requiring both a spectral and a temporal processing) could be at the centre of these deficits. However, the question arises whether this deficit in prosody results from an abnormal neural network functioning, with a hypo or hyper activation of right cortical areas and/or from an altered balance between activated and deactivated networks. 

The goal of the present study was therefore to characterize the neural network elicited by the integration of 90-s long connected speech stimuli of high degrees of prosodic information in High Functioning Autism (HFA) using functional Magnetic Resonance Imaging (fMRI). Since speech exists over time, long connected speech stimuli appear to favor a better integration of pitch modulations, since they present much more F  modulations than isolated words or sentences do. The perceptive and productive prosodic abilities were investigated using the PEPS-C so as to assess the prosodic deficits in the HFA group. Results revealed the existence of a link between perceptive and productive prosodic deficits in autism and demonstrates for the first time that the neural network involved in prosodic speech perception exhibits abnormal activation and deactivation. 


## Materials and Methods 
  
### Participants 
  
Eight male adults with HFA (mean age 23.38, ±2.10, mean Verbal Intelligence Quotient 89, ±7.89) matched with 8 male controls (mean age 23.05, ±2.02, mean VIQ 128.33, ±4.58) participated in the study after having given their informed written consent in accordance with the guidelines approved by the Ethics Committee of the Bordeaux Medical University. HFA participants were recruited by the Autism Resource Center of Charles Perrens Hospital of Bordeaux and were diagnosed with HFA according to the DSM-IV-R criteria   and the ADI-R. They all presented delay in speech onset. Controls were recruited from the community at the University of Bordeaux 2. 

No participants had hearing disorders. They had no prior experience of either behavioural or fMRI tasks and were not familiar with the stimulus materials. 


### Behavioural study: French adaptation of the English PEPS-C 
  
The PEPS-C   was adapted to the French language and culture (Hesling   et al  , in preparation). The French PEPS was implemented with E-prime software (Psychology Software Tools, Pittsburgh, PA), is computerized and lasts 30 minutes. 

The procedure aims at evaluating prosodic skills according to a psycholinguistic model  . Tasks are at 2 levels: (i) communicative function tasks in which prosody plays an important role (requiring top-down processing, involving meaning) and (ii) form tasks (requiring bottom-up processing, where no meaning is involved). The communicative function tasks are assessed in both receptive and expressive modes whereas the form tasks are assessed in receptive mode in the French version because of the age of the participants since they found the expressive form tasks, i.e., imitation of humming sounds, embarrassing. 
  
Four communicative functions were transposed so as to assess   both perception and production skills   in French. For each perceptive task, subjects are presented with two images on a computer screen and are required to click on the right image. For the output task, one image is presented and they have to produce what they see. The turn-end task, which involves intonation, aims at assessing the ability to distinguish between a question with rising pitch and a statement with falling pitch. For example, for the input task subjects are required to listen to single words (food items) and decide whether they sound like questions, i.e. if the person on the computer was “asking them if they want some”; or if they sound like statement. For the output task subjects are required to produce this distinction. The chunking task assesses the ability to disambiguate syntactically ambiguous sentences by the use of rhythm and silence. For example, for the input task subjects are required to listen to word groups such as “vingt-quatre, douze” (twenty-four, twelve) versus “vingt, quatre, douze” (twenty, four, twelve) and decide whether it sounds like 2 or 3 figures by clicking on the right image. For the output task one image (for example “thirty-one, twelve”) is presented and they have to produce the distinction.The focus task aims at assessing the ability to evaluate the emphasized word by the use of stress. For example, for the input task, subjects are required to listen to sentences and to identify which item is missing from sentences such as “je voulais du PAIN et des pommes” (I wanted BREAD and apple). For the output task subjects are required to produce this distinction. The affect task assesses the ability to decode the affective state of the speaker as produced using variation in intonation and voice and to produce such an affective state. For example, for the input task subjects are required to listen to one word and decide if the voice likes or does not like the food item by clicking on the right smiley. For the output task, one item is presented with one food item and they have to produce the affect symbolized by the smiley. 
  
Auditory discrimination abilities are also assessed by 2 form tasks, making it possible to assess whether the subject has the underlying skills required to complete the communicative function tasks. The two form tasks are divided into short item tasks (1 or 2 syllables) and long item tasks (6 or 7 syllables). Short items represent intonation whether long items represent rhythm. The stimuli are laryngograph signals, which sound rather like humming, taken from the recordings of a selection of the four input communicative function tasks. 
  
Each task, whether the 8 receptive and expressive communicative function tasks and the 2 receptive form tasks, includes 18 items with binary responses making it possible to calculate a score. This raw score calculated over 18 is then transformed in percentage. The choice of 18 items is justified by the necessity of having a reasonable number of non-chance scores since the response is binary, as it was done in the PEPS-C  . 

Data were analysed using a Mann-Whitney-U test to assess any differences between the groups for each task. Spearman's correlation test was also done to assess the strength of association between perception and production abilities for each communicative function task in each group. Owing to the heterogeneity of the VIQ in the autistic group, a Spearman's correlation test was done to check if the VIQ interfered with the score of each communicative task. 


### fMRI protocol 
  
A 90-s-long prosodic connected speech stimulus dealing with a French story for children, which includes intonation, rhythm, focus and affect prosodic aspects (i.e., the 4 function tasks) was recorded by a trained native speaker in a soundproof room at a 16 bits/44.1 kHz sampling rate. The 90-s-long recording was digitally cut at sentence boundaries to obtain 3 fragments of 30-s-long activation periods. So as to avoid any disturbing noise, the 5 ms of the beginning of each fragment were gradually increased (fade-in process) and the 5 ms of the end of each fragment were gradually decreased (fade-out process). 

The fMRI protocol consisted in 3 thirty-second-long stimuli interleaved with 4 fifteen-second-long rest periods, the total length of the procedure being 2 minutes and 50 seconds. Participants were asked to listen to the stimuli while remaining motionless and to keep their eyes closed. The speech stimuli were presented binaurally through headphones specifically designed for use in the scanner (MR Confon, Magdeburg, Germany). 


### fMRI acquisition 
  
The MRI data were collected at 1.5 Tesla using an Intera Philips system (Philips Medical System, Best, Netherlands) equipped with an eight-element phased-array head coil. For each subject, a series of 50 functional scans were acquired using a T2*-weighted single shot echo-planar sequence (FOV = 256×256, Matrix = 128×128, TR/TE = 3000/60 ms, Flip angle = 90°, SENSE factor = 2). Each scan included 25 slices (no gap, thickness 4mm) parallel to AC-PC (Anterior Commissure-Posterior Commissure). Three dummy scans were used to reach steady-state magnetization. A high-resolution T1-weighted anatomic scan was also acquired to obtain a morphological reference (25 slices parallel to AC-PC with a resolution of 1×1×4 mm , no gap). 


### fMRI debriefing 
  
After the scanning session, the two groups of participants were submitted to a 10 items questionnaire so as to verify they understood the text. Though the autistic group is heterogeneous in VIQ, each subject with autism properly answered the 10 questions, and no significant difference between the two groups was revealed (Student   t  -test, p<0.887). 


### Whole brain analyses 
  
All data were analyzed using SPM5 (Statistical Parameter Mapping, Wellcome Department of Imaging Neuroscience, London UK) and MATLAB 7.1 (The Mathworks Inc., Natick, MA, USA) and SPSS 16.0 (SPSS, Chicago). 

For each individual subject, the dynamic scans were adjusted for slice timing differences, realigned to the first scan to correct for head movement, normalized to the standard Montreal Neurological Institute space (MNI) and spatially filtered by applying an 8 mm  Gaussian kernel. High-pass filtering (cut off 128s) was performed to remove low frequency artefacts. Then, a general linear model was used to model the data  . The functional time series were modeled by a boxcar model convoluted with a canonical hemodynamic response. After estimation of the model parameters, a linear contrast (prosodic speech vs. rest) was built and entered in a 2  level random effect model. Since the heterogeneity of the VIQ in the autistic group can be confounded, the model was adjusted with VIQ in each group. 

#### Activation 
  
A one sample   t  - test was conducted to reveal activated brain areas in each group. A conjunction analysis was performed to determine areas commonly activated in the HFA and control groups  . A two sample   t  -test was then run to determine the differences in activation between groups (HFA vs. Controls) for the prosodic listening condition. All data were intensity-thresholded at p<0.01 and cluster size-thresholded, at p<0.05, FDR corrected for multiple comparisons. Anatomical localization was performed using the AAL atlas  . 


#### Deactivation 
  
A one sample   t  - test was conducted to reveal deactivated brain areas in each group. A conjunction analysis was performed to determine areas commonly deactivated in the HFA and control groups  . A two sample   t  -test was then run to determine the differences in deactivation between groups (HFA vs. Controls) for the prosodic listening condition. All data were intensity-thresholded at p<0.01 and cluster size-thresholded, at p<0.05, FDR corrected for multiple comparisons. Anatomical localization was performed using the AAL atlas  . 



### ROIs analyses 
  
#### Activation 
  
An ROI analysis was conducted to examine the relation between task performances and activated brain areas extracted from the HFA>controls results. Each ROI was defined as an 8 mm-diameter sphere centered in the coordinates of the peak activated voxels of each activated brain cluster. 

A percent BOLD signal change for each ROI was estimated for both groups using MarsBar  . Then, a Spearman correlation test was done to assess the strength between BOLD signal and scores of the input tasks. 


#### Deactivation 
  
An ROI analysis was conducted to examine the relation between task performances and deactivated areas extracted from the one sample t-test results. Each ROI was defined as an 8 mm-diameter sphere centered in the coordinates of the peak deactivated voxels of each deactivated brain cluster. A percent BOLD signal change for each ROI was estimated for both groups using Marsbar  . Then, a Spearman correlation test was done to assess the strength between deactivated areas and scores of the input tasks. 




## Results 
  
### Behavioural results 
  
#### French PEPS 
  
Controls performed all the perceptive and productive tasks at nearly ceiling, though the test cannot be considered as saturated since the score of 100% was only obtained for 2 subtests (expressive Turn-end and expressive chunking). The HFA group's results were significantly lower than those of controls for all the input and output tasks (p<0.001), ( ). 
   French PEPS input results.    
No significant correlation was found between VIQ and any of the communicative tasks using Spearman correlation ( ). 
   Bivariate correlations between VIQ and receptive and expressive scores for the French PEPS tasks in the HFA and control groups.        
Statistical analyses using Spearman correlation revealed that 3 communicative tasks (chunking task, p<0.001, Focus task, p<0.01, affect task p<0.01) out of 4 (Turn-end task) presented a significant positive correlation coefficient between perception and production tasks for the HFA group ( ). No significant correlation was found for the control group. 
   Bivariate correlations between receptive and expressive scores for the French PEPS tasks in the HFA group.        


### Whole-brain analyses 
  
For all the fMRI analyses, the model was adjusted with VIQ. 

#### Activation: One sample t test 
  
The bilateral STS and the left cerebellum were activated in both groups whereas the right thalamus was only activated in the autistic group ( ). 
   Brain activation in HFA and in controls.        

#### Activation: Conjunction analysis 
  
Common activated areas between HFA and controls were observed bilaterally in the middle temporal gyrus (MTG, BA 21), and in the right temporal lobe (MTG, BA 21, ITG, BA38) ( ,  ). 
   Conjunction map of activation between HFA and controls.       Brain areas commonly activated in HFA and controls.        

#### Activation: Two sample t-tests HFA vs. Controls 
  
The HFA group revealed significantly greater activation in the left Supra Marginal Gyrus (SMG) as compared to the control group, whereas no brain area was more activated in the reverse contrast, i.e., Controls>HFA ( ,  ). 
   Two sample t tests of activation, HFA>controls.       HFA >Controls: brain activation.        

#### Deactivation: One sample t test 
  
The left precuneus, the right anterior cingulate cortex and the left medial prefrontal cortex deactivated during the prosodic stimulus in the control group, whereas no brain areas were deactivated in the HFA group ( ,  ). 
   Map of deactivation in controls.       Deactivation in controls.        

#### Deactivation: Conjunction analysis 
  
There were no common deactivated areas between the HFA and the control groups. 


#### Deactivation: Two sample t-tests: Controls vs. HFA 
  
The control group revealed significantly greater activation in the left precuneus, the left medial prefrontal cortex and the left middle temporal gyrus as compared to the HFA group, whereas no brain area was more activated in the reverse contrast, i.e., HFA>Controls ( ). 
   Controls >HFA: brain deactivation.        


### Correlations between ROIs analyses and French PEPS 
  
#### Activation 
  
Statistical analyses using Spearman correlation revealed that the left SMG presented a significant positive correlation coefficient with the score of 2 communicative tasks, i.e. the turn-end task (p<0,01) and the focus task (p<0,05) for the natural speech condition in the HFA group ( ). No other correlation between cerebral activity and PEPS subtests was found in either group. 
   Bivariate correlations between receptive scores of the French PEPS tasks and the left SMG in the HFA group.        

#### Deactivation 
  
Statistical analyses using Spearman correlation revealed that for the control group the left medial prefrontal cortex presented a significant negative correlation coefficient with the score of 3 communicative tasks, i.e., the chunking task (p<0.05), the focus task (p<0.05) and the affect task (p<0.01). The left precuneus presented a significant negative correlation coefficient with the score of 2 communicative tasks, i.e., the turn-end task (p<0.05) and the affect task (p<0.05). The right anterior cingulate cortex presented a significant negative correlation coefficient with the score of 3 communicative tasks, i.e., the chunking task (p<0.05), the focus task (p<0.05) and the affect task (p<0.05). 

None of these 3 regions presented a significant correlation with the score of the communicative tasks for the HFA group ( ). 
   Bivariate correlations between receptive scores of the French PEPS tasks and deactivated areas in both groups.        



## Discussion 
  
This experiment revealed the existence of a link between perceptive and productive prosodic deficits in autism and demonstrates, for the first time, that the neural network involved in prosodic speech perception exhibits abnormal activation and deactivation. The French adaptation of the English PEPS-C confirmed that subjects with autism not only present difficulties in the production but also in the perception of speech prosody. Moreover, the magnitude of the deficit between perception and production was found to be linked for the HFA group. The fMRI results revealed that brain mechanisms underlying the processing of the prosodic connected prosodic speech comprehension are supported by a different cerebral network in HFA than in controls, involving the left SMG for the HFA as compared to controls. Moreover, whereas controls deactivated brain regions pertaining to the default mode such as the left precuneus and the left middle frontal gyrus as well as the right anterior cingulate while processing the prosodic connected speech comprehension, the HFA group failed to deactivate these brain areas. These results support the existence of a prosodic perceptive impairment in autism. 

The French PEPS made it possible to assess significant prosodic differences between the control group and the HFA group, the latter revealing poorer prosodic abilities in both production and perception tasks. This is in accordance with the different results obtained in the English language by the PEPS-C  – . More particularly, the Turn-end task, which consists in differentiating between a question and a statement, involves intonation, i.e., pitch variations. It could be suggested, regarding the significantly lower score obtained by the HFA group, that HFA subjects present difficulties in decoding and producing those pitch variations in speech. However, these results are in contradiction with results from Jarvinen-Pasley and collaborators   since they have reported an enhanced ability in auditory pitch processing in speech in autism as compared with controls. One issue can be raised to account for these discrepancies in results: in their study, Jarvinen-Pasley and collaborators asked subjects to listen to sentences with 4 different pitch contours and then to match them with a drawing representing the contour. In fact, in this paradigm, subjects can leave aside semantics and concentrate on pitch variations. In our study, as subjects had to match the listened word with the image, they had to integrate both the signifier (the acoustic representation of the word, i.e., the word they listened to) and the signified (the concept, i.e., the image representing the word),  . In fact, though both paradigms require high level processing, it may be hypothesized that Jarvinen-Pasley's paradigm involves more low-level processing though the paradigm in the present study involves more high-level processing, which could explain those surface discrepancies.The Chunking task, which allows for disambiguating lexically ambiguous sentences, mainly based on pauses and silences, was also poorly performed. The Focus task, which consists in emphasizing one word in a sentence, was also more difficult for the HFA group, suggesting a problem with stress. As the affect task requires the 3 acoustic correlates of prosody, namely pitch variations, duration (pauses and silences) and intensity, this task was unsurprisingly less well performed by the HFA group than by the control group. Results obtained in the 4 communicative function tasks may be accounted for by results from the 2 form tasks. In fact, these form tasks make it possible to assess whether the subject has the underlying skills required to complete the communicative function tasks. In the present study, these 2 form tasks were significantly poorly performed by the HFA group. More particularly, the short items discrimination task, which represents the ability to process intonation, i.e., pitch variations, is poorly performed by the HFA group, which can be linked to their poor performance in the Turn end task. The long items discrimination task, which represents the ability to process rhythm, is also poorly performed by the HFA group, which can be linked to their poor performance in the chunking task. However, it can be put forward that as these 2 form tasks do not involve a semantics processing, an enhanced processing in the HFA group as compared to controls could have been expected. One possible explanation would be that as these tasks require both spectral and temporal information processing, subjects with autism encounter difficulties with temporal information processing as supported by some studies revealing an abnormal temporal processing of auditory stimuli in speech  – . In summary, both perceptive and productive prosodic skills appear to be impaired in the HFA group. Moreover, the magnitude of the perceptive and productive deficits was revealed to be linked for the chunking, focus and affect tasks in the HFA group. This suggests that perception and production deficits are strongly connected and it can be hypothesized that production depends on perception abilities as regard studies on deaf subjects or on second language learning  . 

Data from the fMRI study contribute to understanding this impairment since the cerebral network underlying the processing of prosodic connected speech present differences between the 2 groups. In controls, the bilateral temporal lobes are found to be activated, which is in accordance with previous data showing that auditory sentence comprehension is associated with involvement of both left and right STG  – . However, some studies on auditory prosodic speech perception have revealed whether a right  –  and/or left  –  Inferior Frontal Gyrus (IFG) activation, which was not achieved in the present study at the chosen threshold as in other studies  ,  . One possible explanation is that the content of the stimulus, though prosodic, was not emotional enough to make subjects rehearse the stimulus. 

While no brain area was more recruited for the control group as compared with the HFA group; the reverse contrast, i.e., HFA>controls, revealed greater activation in the left SMG. The left SMG has been revealed to be connected with a part of the inferior frontal gyrus (pars triangularis, F3td) through the arcuate fasciculus  . The left SMG is viewed as the starting point of the working memory loop for phonology which then projects frontally  . As such, the left SMG can be considered as the phonological store area and would then be a part of the phonological loop postulated by Baddeley  . It can thus be suggested that autistic subjects rely more on working memory processes and processes translating from auditory to articulatory representations than controls do in the natural condition  . Correlations between the left SMG and the Turn-end and Focus tasks in the HFA group revealed that the more this brain structure is activated, the more accurately the HFA subjects performed the tasks. Controls, in the case of natural speech integration, did not present more activation in the left SMG as compared to HFA, though their scores on the task were nearly at ceiling. It can thus be hypothesized that the HFA group recruit the left SMG as a compensatory phenomenon, which is supported by the idea that prosody could be so troublesome for them that they would be more concentrated on phoneme discrimination, which is part of the literal speech decoding, either to avoid paying attention to prosodic features or to be able to understand the story. A further explanation which may be raised for accounting for this left SMG activation could stem from a right hypoactivation in the HFA group, which is in light with previous cortical evoked potential studies reporting a right hypoactivation in autism  ,  . In fact, even if the present results did not reveal any differences in the right STS between controls and the HFA group at the chosen threshold, a less permissive threshold revealed that the right STS is more activated in controls than in the HFA group, which would support the hypoactivation hypothesis. Another complementary explanation comes from results from deactivation. When comparing the differences between autistic patients  ,  , and controls, fMRI studies have revealed differences in decreased activity in the default network between patients and controls, although these differences were not correlated with task performance. In line with this, in the present study, the control group exhibited deactivation in this default mode network while processing prosodic connected speech comprehension, suggesting that listening to the story leads to inhibition of this network engaged in self-reflective thought  . The underlying mechanism of this inhibition seems to be a facilitation of task-specific activations through the suppression of task-irrelevant cortical regions, enabling the subject to focus his attention on the relevant process. This hypothesis is supported by results from correlations between the PEPS scores and the 3 seed deactivated regions (the left precuneus, the right anterior cingulate cortex and the left medial prefrontal cortex). In fact, it can be hypothesized that the more these brain regions deactivate, the better the score, which may reflect the degree to which subjects express the balance between tasks-dependent and tasks-independent networks. With this respect, the inabilities of deactivating the default mode network encountered by the HFA group evidenced here could support, at least in part, a less efficient processing of the relevant information, i.e. the prosodic dimension of speech, in autistic patients. The question arises if this deactivation failure results from abnormal functional interaction between task-dependant and task-independent networks or from a dysfunction of default mode network itself. Even if the first hypothesis cannot be excluded, several functional imaging studies in autism have revealed abnormalities in middle anterior and posterior regions involved in the default mode network during a variety of tasks, either in socioemotional  –  or non-socioemotional tasks  ,  . 

This preliminary study also has several limitations that need to be taken into account when interpreting the findings. Indeed, the results are based on a relatively small sample of subjects and there is heterogeneity in VIQ in the HFA group, which limits the generalization of the results and makes replication efforts an important step. Even if these limits must be considered, three main points can be raised to run counter to them (i) VIQ scores did not correlate with any of the communicative tasks, (ii) each subject properly answered the 10 items questionnaire, making it possible to state that they understood the text and (iii) VIQ was used as a covariate in all the imaging measures. 

In conclusion, this study confirms the existence of perceptive prosodic deficits in autism and demonstrates for the first time that the neural network involved in prosodic speech perception exhibits abnormal activation and deactivation. Future studies should further precise the respective role of task dependant and independent networks and assess the direction of the link between perception and production in autism. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-7'>
<h2>7. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31269199/' target='_blank'>31269199</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Social evaluations under conflict: negative judgments of conflicting information are easier than positive judgments</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Soc Cogn Affect Neurosci</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1093/scan/nsz045</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6778826/' target='_blank'>6778826</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is a functional MRI study in healthy adults (N=20, ages 18–29) using an explicit social judgment task (evaluations of target persons across situations). The task probes social processing (perception/understanding of others; social evaluation). The paper reports whole-brain analyses (multilevel whole-brain MLM; voxelwise results reported at P<0.001 and supplementary material) in addition to ROI follow-ups. Participants are healthy and results for this group are reported separately. Thus the study meets all inclusion criteria (fMRI during a social task, healthy adult sample, whole-brain analyses reported) and none of the exclusion criteria are met.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
In the current study, we used functional magnetic resonance imaging to investigate how the brain facilitates social judgments despite evaluatively conflicting information. Participants learned consistent (positive or negative) and ambivalent (positive and negative) person information and were then asked to provide binary judgments of these targets in situations that either resolved conflict by prioritizing a subset of information or not. Self-report, decision time and brain data confirm that integrating contextual information into our evaluations of objects or people allows for nuanced (social) evaluations. The same mixed trait information elicited or failed to elicit evaluative conflict dependent on the situation. Crucially, we provide data suggesting that negative judgments are easier and may be considered the ‘default’ action when experiencing evaluative conflict: weaker activation in dorsolateral prefrontal cortex during trials of evaluative conflict was related to a greater likelihood of unfavorable judgments, and greater activation was related to more favorable judgments. Since negative outcome consequences are arguably more detrimental and salient, this finding supports the idea that additional regulation and a more active selection process are necessary to override an initial negative response to evaluatively conflicting information. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (40891 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
Every day we evaluate and interact with others across a range of situations. Because human behavior is complex, it is not uncommon that information we gather about others is marked by ambivalence, for example, when we perceive a person as cold but competent. Often, we are forced to resolve such evaluative conflict toward a favorable (e.g. collaborate with this person) or unfavorable judgment (e.g. do not collaborate). In the current article, we extend existing literature by investigating how the brain facilitates these social decisions by weighing evaluative information in line with affordances of the situation. Importantly, we provide data suggesting that negative judgments can be considered the easier, ‘default’ response when experiencing evaluative conflict. 

Social evaluations are influenced by aspects of the task or situation that provide goals in relation to which a person or object is evaluated. Thereby, situational affordances facilitate flexible, nuanced evaluations ( ;  ). In a recent study, we suggested that situational affordances can resolve evaluative conflict by prioritizing specific information; that is, we may judge someone positively in a specific situation despite knowing that the person also has negative features ( ). For example, we may judge a colleague who is charming and lazy positively when deciding whether to invite him or her to a social event because we prioritize the positive trait (charming) over the more negative one (lazy). Accordingly, affordances of the situation can also fail to resolve conflict if features of opposite valence remain relevant for the current judgment. For example, choosing whether to organize a social event with a friend who is charming and lazy makes both positively (i.e. charming) and negatively evaluated traits (i.e. lazy) important and evaluative conflict remains ( ). These situations of evaluative conflict and specifically how judgments are facilitated despite evaluative conflict are the focus of the current study. 
  
Proposed processing of evaluative information in line with situational affordances. 
  
Cognitive conflict is traditionally studied in paradigms where a more salient, default response interferes with an objectively correct response (e.g. Stroop task and Eriksen Flanker task). Interestingly, there is no objectively correct response when conflict occurs between subjective evaluations, and the default response in these evaluative conflicts is unclear. We suggest that in such cases, negative judgments are the easier, default response based on two theoretical approaches. First, psychologists and neuroscientists have theorized that conflicts generate negative value (Botvinick, 2007; Braem et al., 2017; Dreisbach & Fischer, 2012; Inzlicht et al., 2015; Schouppe et al., 2015). For example, in a facial electromyographic study using a variant of the current impression formation paradigm, participants expressed less positive affect when ambivalent person information remained conflicted in the evaluation situation compared to when ambivalence was resolved (Nohlen et al., 2016). The negative value of conflict has also been suggested to extend to evaluations. Direct evidence comes from a study by Fritz &\Dreisbach (2013), who showed that presenting conflict (incongruent Stroop) primes increases the number of negative judgments of neutral targets (words or Chinese pictographs) that followed these primes. 

Second, some have argued for a greater impact of negative information on evaluations because it arguably outweighs positive information in terms of salience and outcome consequences ( ;  ;  ). For example, animals that are conflicted between approaching and avoiding a predator-infested water source tend to show avoidance behavior ( ). This bias may be due to the fact that ignoring negative information can instill higher costs (e.g. being eaten) than ignoring positive information (e.g. drinking water;  ). Similarly, negative judgments that insinuate avoidance in social situation (e.g. do not collaborate) could represent the ‘safer choice’ by maintaining the status quo when feeling torn between positive and negative evaluations (cf.  ). 

A tendency toward negative social judgments on the basis of conflicting person information can thus be expected because they may be easier due to the negative value of conflict which influences evaluations (e.g. Botvinick, 2007; Fritz & Dreisbach, 2013), and because negative information arguably outweighs positive information in terms of salience and outcome consequences (Gray & McNaughton, 2000; Rozin & Royzman, 2001). 

If negative judgments are the easier response in evaluative conflicts, positive judgments should be more effortful and take more time. Supporting this argument, research has shown that even though ambiguous (i.e. surprised) facial expressions are primarily judged as negative, positive judgments become more likely when participants take more time to evaluate the stimulus ( ;  ;  ). This suggests that overriding an initial negative response to interpret an ambiguous stimulus positively requires additional regulatory processes; we need to invest effort and actively attend to positive information ( ,  ;  ). 

Many models of control and executive functioning focus on the interaction of the anterior cingulate cortex (ACC) and dorsolateral prefrontal cortex (DLPFC) to resolve such complex decision situations ( ;  ;  ). These domain-general regions are also more active in impression formation task when evaluations are updated with information that is inconsistent with prior information ( ;  ). Because of their engagement during many tasks, it has proven difficult to pinpoint the specific role of these regions. Interpretations of dorsal ACC’s (dACC’s) function thus vary from conflict monitoring ( ) and detection (e.g.  ) to violation of expectancies ( ), negative affect and pain ( ) or comparisons of value outcomes, to name a few ( ;  ;  ;  ). Even though there is thus some debate on the specifics of dACC functioning (e.g.  ;  ), it is widely agreed that dACC is engaged when tasks are more difficult and effortful as is, for example, the case when we have to form an integrative judgment from conflicting information ( ). Recently, the Expected Value of Control theory ( ) suggested that dACC has the role of a ‘controller’ that detects and signals an increased need for control through a cost–benefit analysis for optimal control allocation ( ;  ). Important in the current paradigm, these control-eliciting situations are often those in which one behavior, generally referred to as the default response, is suppressed in favor of another behavior that serves current goals better ( ;  ). 

According to this idea, difficult choice situations signaled by the ACC are relayed to the DLPFC, which is critically involved in the implementation of control ( ). Specifically, DLPFC has been associated with biasing processing in line with salient goals, meaning that it is involved in attending to task-relevant information and selecting context-appropriate responses ( ;  ). Supporting this, Hughes   et al.   ( ) found both dACC and DLPFC to play a role in an intergroup social judgments task. A failure to engage these regions was associated with increased ingroup bias in that participants did not adjust their impression of ingroup members to incorporate negative information and stuck to their default (biased) response. Based on the idea that negative judgments are the default response in situations of evaluative conflict, positive judgments should represent a move away from the default response and thus be mediated by greater DLPFC and dACC activation. 

## Present research and hypotheses 
  
The goal of our study was to investigate how the human brain facilitates social judgments when information is conflicting. Two aspects were central. First, we were interested in replicating our previous work showing the flexibility of ambivalent person evaluations with the idea that the same positive and negative person information elicits evaluative conflict in some but not in other situations ( ). Second, we examined the role of dACC and DLPFC in biasing evaluations toward positive or negative judgments when evaluative conflict remains. As far as we know, this is the first study investigating whether blood oxygen level-dependent (BOLD) signal can be related to the valence of social evaluations. 

We used a novel forced-choice task in which participants judged target persons described by consistent (positive or negative) or ambivalent (positive and negative) traits in different situations that either allowed for prioritizing some traits over others (conflict is resolved) or not (conflict remains unresolved; cf.  ). If negative judgments of conflicting information are the default, we should find an interaction effect of the valence of social judgment (positive, negative) and the presence of evaluative conflict on BOLD signal. More specifically, dACC and DLPFC response should be stronger if participants experience evaluative conflict and override the default negative judgment and judge the person positively. Accordingly, weaker dACC and DLPFC activation should be related to negative judgments under evaluative conflict. If conflict does not have a negative value that influences evaluations, brain response to the valence of social judgments should be independent from conflict. 


## Methods 
  
### Participants 
  
Participants were 20 adults (11 male, 9 female) in the age range of 18 to 29 years (  M   = 22.7; s.d., 2.60). Participants provided informed consent, had normal or corrected-to-normal vision, and had no history of neurological problems. Nineteen of 20 participants were right handed. All procedures were approved by the local ethical committee. 


### Design and procedure 
  
#### Target persons 
  
Two to 5 days before scanning, participants received descriptions of four male target persons that consisted of a list of traits and a short text to make the traits more memorable. One target was described by positive traits (friendly, charming, enthusiastic, intelligent), one by negative (dominant, jealous, lazy, dumb), and two by the combination of the two positive and two negative traits each (dominant, jealous, enthusiastic, intelligent; friendly, charming, lazy, dumb). The combinations of names and traits were counterbalanced across participants, and we used a pretest (  N   = 34; Supplementary Material S1) to ensure that the trait combinations were evaluated as positive, negative or ambivalent. Participants memorized the combinations of names and traits before coming to the laboratory and were verbally tested on recall during take-in. If participants were not able to recall the traits and names of the targets, they were given additional time to learn them. Because we did not want differences in knowledge of the name–trait combinations to introduce noise in the data, exposure to the pairs may have varied between participants. Post-relearning, all participants were able to quickly recall the combinations when prompted. 


#### Evaluation situations 
  
The four target persons were evaluated in 21 different situations (cf.  ). All situations were combined with each of the four target persons (84 trials). Based on a pretest (S1), situations were selected that varied in the degree to which they resolved conflict between ambivalent trait information by prioritizing a subset of either positive or negative traits. In the pretest, we used a one-item adaptation of  ) subjective ambivalence scale, which assesses experienced conflict by asking participants to evaluate the degree to which they experienced ‘mixed feelings and/or thoughts’ toward each target person (described by their specific traits) in each of the different evaluation situations on a scale ranging from 0 (not at all) to 100 (very much). Results were used to categorize the combinations of ambivalent target persons and evaluation situations as representing either situationally resolved ambivalent (2 target persons × 10 situations = 20 trials), or unresolved ambivalent judgments (2 target persons × 11 situations = 22 trials), resulting in three critical trial types based on the combination of person traits and evaluation situation ( ). Note that the situation did not have to resolve conflict when targets were described by positive or negative (i.e. consistent) traits; they elicited unconflicted judgments across all situations (2 target persons × 21 situations = 42 trials). Whether situations resolved conflict between ambivalent target information was dependent on the specific target; the same situation could thus be categorized as situationally resolved ambivalent for one target and unresolved for another (Supplementary Material S2 for all stimuli).  Additionally, a manipulation check was added to this study to test whether this categorization was successful (see  ). 
  
(A) Timing sequence of an experimental trial. (B) Example trial of each trial type. 
  


### Social Judgment task 
  
#### Functional magnetic resonance imaging social judgment task 
  
In the scanner, participants indicated their judgment (‘yes,’ ‘no’) to each combination of target person and evaluation situation by pressing one of two buttons with their right index and middle finger. Choice labels were counterbalanced between participants. Participants completed one functional run of 84 randomly presented trials with a 5 s break after every 21 trials. Trials started with a fixation cross (500 ms), and stimuli were presented until participants responded. After the response, participants saw a white dot on a black screen with varying presentation times (min, 4000 ms; max, 6600 ms) before the next trial ( ). Responses were recoded so that yes responses represent positive judgments and no responses represent negative judgments of the person in that situation. 


#### Manipulation checks 
  
##### Before scanning: assessing ambivalence toward target persons 
  
To confirm that information about the target persons was indeed perceived as consistent or conflicted, we assessed experienced ambivalence toward the four target persons with the subjective ambivalence scale ( ). This scale assesses psychological conflict with three items anchored with ‘Toward this person I… have completely one-sided feelings/feel no conflict/feel no indecision’ (0) and ‘have mixed feelings/feel maximum conflict/maximum indecision’ (100). Participants responded on a slider without numeric labels (α = 0.71). Ambivalence was calculated by taking the mean of these questions. 


##### After scanning: assessing ambivalence toward each target person in each situation 
  
To verify that we correctly categorized the combinations of person information and evaluation situation as conflicting or conflict resolved on the basis of pretest data, participants indicated their ambivalence toward each target person in each situation using the same scale ( ; e.g. ‘I have mixed feelings/feel conflict/feel indecision about collaborating with X’). Responses were given on a slider (0–100) without numeric labels (α = 0.93). 




### Magnetic resonance imaging data acquisition 
  
Imaging was conducted with a 3.0-T Philips Achieva scanner at the Spinoza Centre for Neuroimaging in Amsterdam. Head motion was limited by placing foam inserts around the head inside the head coil. Stimuli were presented using E-Prime and projected onto a screen in the magnet bore, which participants could see through a mirror attached to the head coil. Functional data were obtained using T2*-weighted echo-planar imaging in one event-related run (84 trials). The first two dummy scans were removed to allow for equilibration of T1 saturation effects [time repetition (TR), 2 s; time echo (TE), 28 ms; voxel size, 3 × 3 × 3 mm; field of view (FOV), 240^2]. A high-resolution T1-weighted sagittal scan was collected as anatomical reference (TR, 9.56 s; TE, 4.6 s; voxel size, 1.2 × 1.2 × 1.2; FOV, 224^2). 


### Functional magnetic resonance imaging preprocessing 
  
Data were preprocessed using FEAT (FMRI Expert Analysis Tool) Version 6.00, part of FMRIB’s Software Library (FSL,   www.fmrib.ox.ac.uk/fsl  ). Data were corrected for motion using FMRIB’s Linear Image Registration Tool (MCFLIRT; (FSL’s Motion Correction using FMRIB’s Linear Image Registration Tool;  ); the brain was extracted using FSL’s Brain Extraction Tool (BET;  ) and spatially smoothed using a Gaussian kernel (full width at half maximum [FWHM] = 5 mm). The four-dimensional data set was grand-mean intensity normalized by a single multiplicative factor. We applied a high-pass temporal filter (Gaussian-weighted least-squares straight line fitting, with σ = 50 s). Registration to standard space images was carried out using FLIRT ( ;  ). 



## Results 
  
### Behavior analysis 
  
#### Manipulation checks 
  
##### Before scanning: assessing ambivalence toward target persons. 
  
Results on the subjective ambivalence scale confirmed that the combination of traits successfully created unconflicted (consistent) or conflicted evaluations of the target persons independent of evaluation situation. Participants experienced less conflict regarding persons described by positive or negative traits (  M   = 11.03, SE  = 2.24) than toward those described by positive and negative traits [  M   = 40.67, SE  = 3.13;   t  (19) = −8.610,   P   < 0.001,   r   = 0.89]. 


##### During scanning: response behavior 
  
In line with the categorization, target persons described by positive traits were evaluated positively in 416 of 420 trials (99%) independent of evaluation situation, and negatively described targets were evaluated negatively in 399 of 420 trials (95%). Correspondingly, judgments were mixed when target persons were described by positive and negative traits; positive judgments were given in 433 of 840 trials (51.5%) and negative judgments in the remaining 407 trials (48.5%). Splitting ambivalent trials according to situational resolution of conflict showed that negative judgments were given in 181 of the 400 conflict-resolved ambivalent trials (45.3%) and in 226 of the 440 unresolved ambivalent trials (51.4%). This difference was significant in that participants judged ambivalent target persons negatively more often when conflict remained unresolved (51.4%) compared to when it was situationally resolved [45.3%;   F  (1,19) = 8.09  , P   = 0.01,   η   = 0.30]. 


##### After scanning: assessing ambivalence toward each target person in each situation 
  
We assessed experienced conflict toward target persons in each evaluation situation to verify the pretest-based categorization between situations that resolved conflict and those that did not. Results confirmed the expected main effect of trial type [consistent, situationally resolved ambivalent, situationally unresolved ambivalent;   F  (1.27,24.14) = 33.13,   P   < 0.001,   η   = 0.64 (Greenhouse–Geisser corrected)]. Experienced ambivalence toward unconflicted trials (  M   = 7.96, SE  = 2.5) was lower than toward conflict-resolved ambivalent trials (  M   = 23.16, SE  = 3.00;   P   < 0.001), which was lower than ambivalence toward conflict-unresolved ambivalent trials (  M   = 31.15, SE  = 3.74,   P   < 0.001). The pattern of results provides confidence in the categorization into three trial types by combining trait information with evaluation situations. 



#### Decision times 
  
The time it takes to make a judgment provides an indication of judgment difficulty. To confirm that judgments were more difficult when conflict was not situationally resolved and to verify that negative judgments are easier when experiencing conflict, we conducted a repeated-measures analysis of variance (ANOVA) comparing decision times between trial type (consistent, resolved ambivalent, unresolved ambivalent) and the judgment participants provided (positive, negative). Expectedly, trial type influenced decision times [  F  (2,38) = 37.89,   P   < 0.001,   η   = 0.66]; participants were quickest to evaluate persons with consistent traits (  M   = 2.73 s, SE  = 0.13 s) and somewhat slower when traits were conflicted but resolved by situational affordances (  M   = 3.84 s, SE  = 0.28 s;   P   < 0.001). Judgments took longest when traits were conflicted and remained conflicted in the evaluation situation (  M   = 4.20 s, SE  = 0.31 s;   P   = 0.02), suggesting that these were experienced as most difficult. As expected, there was no main effect of response behavior, and participants were equally quick in providing negative and positive judgments [  F  (1,19) = 1.53,   P   = 0.23]. 

Critically, we found the expected interaction of response behavior and trial type [  F  (2,38) = 6.54,   P   = 0.004,   η   = 0.26]. Confirming that negative judgments of conflicting stimuli are the easier response, decision times were quicker when participants judged situationally conflicting targets negatively (  M   = 3.95 s, SE  = 0.30 s) than positively (  M   = 4.45 s, SE  = 0.34 s;   P   = 0.03). In line with hypotheses, no difference in decision times between positive and negative judgments was found for ambivalent stimuli when situational affordances resolved conflict (  P   = 0.24). Regarding consistent stimuli, positive judgments were made faster (  M   = 2.59 s, SE  = 0.12 s) than negative judgments (  M   = 2.88 s, SE  = 0.16 s),   P   = 0.03. 
  
Interaction effect of trial type and response behavior in the whole-brain MLM analysis (Montreal Neurological Institute [MNI] coordinates:   x   = 12,   y   = −6,   z   = 18). Activation thresholded at   P   = 0.005 (red) and   P   = 0.001 (yellow). The left side of the brain is shown on the right side and vice versa. 
  


### Image analysis 
  
#### Whole brain: multilevel model 
  
Because we differentiated trials on the basis of subjects' judgments, we dealt with an unequal number of observations in each cell of the study design. To estimate the effect of trial type and subjects' judgment simultaneously, we thus constructed a multilevel model (MLM) that can deal with such unbalanced designs. Using AFNI’s 3dDeconvolve function, we obtained β estimates for BOLD response magnitude for each voxel and trial by modeling functional magnetic resonance imaging (fMRI) time series with individual trial regressors based on onset times for stimulus presentation (  https://afni.nimh.nih.gov/;-stim_times_IM  ; see  ;  ;   for similar approaches). Decision times were included as duration modulation. Trial type and response behavior were coded as categorical variables. Using R ( ), we then modeled fMRI BOLD from the three trial types (consistent, resolved ambivalent, unresolved ambivalent), the judgments participants made (response behavior: positive   vs   negative judgment) and their interaction, with random intercepts on the subject level at each voxel to account for the repeated measures design (lme4-package;  ). Categorical variables were automatically dummy coded in the analysis, and in order to examine the effects of the two degrees of freedom simultaneously, we used the ANOVA function in the car library (car-package;  ). 

We observed a significant interaction between the effect of trial type and response behavior on brain activation in several regions, including bilateral DLPFC and dACC as hypothesized ( ). For our analyses, we used an a priori threshold of   P   < 0.005 with a cluster size of 25 ( ) to balance Type I and Type II errors. However, all effects of interest were significant at a more stringent threshold and are more accessibly presented using a threshold of   P   < 0.001 with a cluster size of 25 ( ). For the ease of presentation, we use this more stringent threshold in the main paper for presentational purposes and place the full list of activations at the original threshold in the Supplementary Material S3. 
  
Regions that showed a significant interaction effect of trial type and response behavior in the whole-brain MLM (  P   < 0.001, uncorrected) 
  
 Notes  . Only clusters that exceed a minimum size of 25 voxels are shown. Voxel coordinates of the maximally activated voxels are given. 

IFG, inferior frontal gyrus PFC, prefrontal cortex; SFG, superior frontal gyrus. 
    
Activation in right DLPFC (A) and dACC (B) by trial type and response behavior. 
  


### ROI analysis 
  
#### Simple effects 
  
 Post hoc   tests were conducted in SPSS on the DLPFC and dACC regions from the MLM analysis to decompose the interaction effect of trial type and response behavior. For each cluster, we extracted the β estimates for each trial and participant that were used to run the whole-brain MLM analysis. We averaged estimates across voxels for each trial and participant within each cluster. Note that the following analysis is applied to interpret the significant interaction effect by testing simple effects, not to run the same analysis on a subset of the data ( ). 

##### DLPFC 
  
In line with expectations, we observed greater DLPFC activation for positive than negative judgments only when target persons were described by ambivalent traits and evaluative conflict remained unresolved by the situation in which the evaluation took place (right DLPFC, left DLPFC:   P   < 0.001;  ). When target traits were ambivalent but affordances resolved conflict, results showed no difference in DLPFC activation for positive and negative judgments (right DLPFC:   P   = 0.67; left DLPFC:   P   = 0.82). Activation in DLPFC was weaker when participants made positive compared to negative judgments when target traits were consistent (right DLPFC:   P   = 0.009; left DLPFC:   P   = 0.02). 


##### dACC 
  
The pattern of activation in the dACC mirrored DLPFC activation. When trials elicited (unresolvable) evaluative conflict, dACC activation was stronger when participants judged the person positively than negatively (  P   < 0.001;  ). We found no difference for judgment valence in dACC response to ambivalent target persons when affordances resolved conflict (  P   = 0.79). Finally, judging consistently described target persons negatively was associated with greater dACC activation than judging them positively (  P   = 0.05). 

In a follow-up analysis, we verified that these effects cannot be ascribed to differences in decision times. Including decision times did not eliminate the critical interaction between trial type and response behavior on DLPFC activation [right: χ (2) = 22.63,   P   = 1.22e−05; left: χ (2) = 21.95,   P   = 1.71e−05; Type III Wald] and on dACC activation [χ (2) = 14.65,   P   = 0.0007; see Supplementary Material S5 for details]. 



#### Explaining response behavior from variation in BOLD within trial type 
  
A more stringent test of the hypothesis that dACC and DLPFC signal under evaluative conflict is related to going with or against the default evaluation is to test the relationship between judgment behavior and BOLD variability within different trial types while controlling for differences between participants and trial type. If we find that greater (weaker) DLPFC (dACC) activation is related to a greater likelihood of positive (negative) judgments—only within situationally unresolved ambivalent trials—we solidify the claim that positive judgments of conflicting information are more effortful. Compared to the previous analysis in which we found that positive judgments are in general related to greater DLPFC (dACC) response in situationally unresolved ambivalent trials across participants, this analysis looks for the relationship within participants and trial types. To test this, DLPFC (dACC) activation and decision times were centered within participant and trial type. Using R, trial type (consistent, resolved ambivalent, unresolved ambivalent), centered BOLD response and centered decision time effects, as well as their interaction with trial type, were modeled in a multilevel-model nested within subject. Trial type was coded as a categorical variable. Testing the interaction between centered BOLD response and trial type while controlling for decision times thus allows us to test whether response behavior can be explained by variation in BOLD signal in each type of trial. For readability, the discussion of the results focuses on the predicted interaction between BOLD response and trial type. Other effects are reported in the notes. 

##### DLPFC 
  
Most critically, we found that variation in DLPFC activation predicted response behavior dependent on trial type [χ (2) = 22.16,   P   = 1.54e−05; left DLPFC: χ (2) = 21.73,   P   = 1.91e−05]. As can be seen in  , DLPFC activation had little effect on the valence of judgments when target persons' traits were consistent or the situation resolved ambivalence. When target traits were ambivalent and situational affordances did not resolve conflict, however, comparatively lower DLPFC activation was related to a greater likelihood of negative judgments and positive judgments were more likely under greater DLPFC activation. This supports our suggestion that negative judgments are easier when judging ambivalent targets, whereas greater DLPFC activation is necessary to bias toward more favorable judgments. 
  
Likelihood of positive and negative social judgments within each trial type on the basis of centered brain activation in right DLPFC (A), left DLPFC (B) and dACC (C). Shaded areas represent 95% confidence intervals. 
  

##### dACC 
  
The analysis was repeated for the dACC, again examining the interaction between centered dACC signal and trial type while controlling for decision times. The results mirrored the effect of DLPFC activation. Most importantly, variation in dACC activation within trial type condition predicted response behavior differently for different trial types [χ (2) = 14.92,   P   = 0.0006;  ). However, the pattern was less clear than in DLPFC. 





## Discussion 
  
In the current study, we investigated how the brain facilitates social judgments when person information is conflicting. We made two claims. First, we put forward that social evaluations are dynamic and have situational dependency ( ;  ). Second, we hypothesized that people have a tendency toward negative evaluations under evaluative conflict. To investigate this, our paradigm compared social judgments of people described by consistent or ambivalent trait information across different situations. Our findings confirm that social judgments of the same person vary across situations. Dependent on the situation in which the person was evaluated, ambivalent trait information elicited or failed to elicit evaluative conflict as represented in self-report, decision times and brain activation. Importantly, decision time and brain data converged in support of the hypothesis that negative evaluations are easier when experiencing evaluative conflict; participants were faster to make negative than positive judgments. Crucially, positive judgments were associated with greater DLPFC and dACC activation than negative judgments even when controlling for decision time, suggesting that differences in response magnitude are not simply an effect of processing time. Moreover, the variability of participants' DLPFC and dACC activation predicted the likelihood of positive and negative judgments only within evaluative conflict trials. The study thus provides converging evidence suggesting that saying no is easier than saying yes when experiencing evaluative conflict. 

Our findings complement and extend prior work in a number of ways. Related work has focused on the negative value of response conflict, for example, showing that the negative value of conflict primes translates to negative judgments of following neutral targets ( ). The current study extends this line of research showing that negative value of conflict translates to faster negative evaluations of the conflict stimulus itself. Additionally, whereas previous studies focused primarily on the negative value of response conflicts, we focused on evaluative conflict in the traditional sense, which requires the presence of conflict between positive and negative valence (i.e. ambivalence). Thereby, it provides a stringent test of the idea that negative evaluations of conflict-eliciting stimuli can be considered the default response, whereas positive evaluations require more control. 

Important to note is that, even though we observed more negative judgments when participants experienced evaluative conflict compared to when they did not (on the basis of the same ambivalent person information), there was an equal number of positive and negative judgments within high conflict trials. In line with others ( ), we suggest that overriding negative interpretations of ambiguous or conflicting information in favor of a positive interpretation requires regulatory processes. That is, even though negative judgments were easier, participants regularly seem to exert effort in favor of positive judgments. However, it is as yet unclear what motivates people to exert this effort and bias their judgment. 

To our knowledge, this is also the first study that related the likelihood of positive or negative judgments of conflicting information to dACC and DLPFC activity. Negative judgments were made quicker, and weaker dACC and DLPFC response in trials eliciting evaluative conflict was linked to a greater likelihood of negative judgments, whereas stronger dACC and DLPFC response predicted a greater likelihood of positive judgments. Greater activation in dACC on trials eliciting evaluative conflict could be a prerequisite for implementing control and processing changes in DLPFC toward a more favorable judgment. However, the similar activation pattern observed here makes claims regarding their individual contribution challenging. Our interpretation is based on prior work suggesting that both regions play important roles in behavioral flexibility with dACC signaling the need for behavior adjustment, which is critically implemented by the DLPFC (e.g.  ). In social evaluation tasks, regions in the lateral prefrontal cortex have been linked to updating initial impressions with incongruent information ( ). For example, Bhanji and Beer (2013) demonstrated that modifying impressions toward a more favorable (i.e. positive) judgment is linked to parametrically increasing engagement of a region within lateral prefrontal cortex. Similar to our suggestion, they interpret this increased engagement as a reflection of cognitive effort. We argue that the engagement of DLPFC when changing one’s social judgment is not linked to the valence (i.e. positivity) of the evaluation   per se   but dependent on whether the evaluation moves away from the default response. For example,  ) showed that engagement of DLPFC was related to incorporating negative information about positively evaluated ingroup members. Since it is not the valence of the evaluation but the movement away from the default response that engages DLPFC, and since positive evaluations of ingroup members are the default response, integrating negative information into the evaluation of an ingroup member requires more effort similar to moving toward a positive evaluation when experiencing evaluative conflict in our task. This may also suggest some interesting boundary conditions worthy of future investigation. Whereas we suggest that it is easier to evaluate individuals negatively based on conflicting information, there are likely situations under which this effect may be diminished or even reversed due to motives of the evaluator. Situational factors such as group membership, one’s need to belong or stressful social situations (e.g. ostracism) may influence our interpretation and value judgment of certain traits as well as our global evaluation of another person. For example, when we feel socially rejected or lonely, we may be more inclined to evaluate another person positively despite conflicting trait information, thus shifting the default response to evaluatively conflicting information from negative to positive. Additionally, when evaluating ingroup and outgroup members on the basis of the same conflicting trait information, it may be relatively easier to judge an ingroup member positively because group membership carries positive value and we may process negative information about ingroup members in a biased manner (cf.  ). 

Usually, research into cognitive conflicts and the role of dACC and DLPFC in executive functioning is tested with non-social tasks in which perceptual or response conflict is correctly resolved by actively attending to and regulating behavior. Our study shows that the role of dACC and DLPFC in guiding behavior flexibly in more low-level cognitive control tasks also maps onto more complex tasks in which people have to search memory and weigh information in line with situational affordances. However, an important aspect of our study design was that participants were forced to provide a positive or negative judgment. By forcing a single-factor solution from evaluatively contradicting information, we created an evaluation situation in which neither response option fits participants' evaluation of the stimulus. Even though this approach mirrors many real-life situations, it prevents us from pulling apart possibly separate fMRI responses to evaluative conflicts and response conflicts. The distinction is less relevant for the current study since we were interested in the interaction between the presence of conflict and the judgment provided. However, independent of judgment valence, it may be that dACC response was partly driven either by the difficulty to choose between two unfitting response options or by the evaluative conflict that the stimulus elicits independently of choice. Future studies may investigate this further by comparing forced-choice situations with situations in which participants can indicate mixed evaluation toward an evaluatively conflicted stimulus. 


## Conclusions 
  
The current study shows that social evaluations are dynamic and form in a particular situation, with a particular goal in mind. Complex and conflicted stimulus representations can be resolved by situational prioritization of information. Extending the work on conflicts as negative signals, the findings indicate that when prioritization fails to resolve conflict, negative judgments of conflicting stimuli are easier than positive judgments as indicated by decision times and engagement of dACC and DLPFC. 


## Notes. 
  
  
Given the traits and situations included in the study, a majority of the judgments related to the competence of the target person in a given situation (Supplementary Material S2). 
  
Participants additionally rated how positively (negatively) they evaluated each target persons' most positive (negative) traits on a scale ranging from not at all (0) to very (100). Ratings were combined in line with Thompson Zanna, and Griffin (1995): Ambivalence = (Pos + Neg)/2 −|Pos − Neg|. This measure has been moved to the notes due to word constraints and because we expected the same pattern of results as on the subjective ambivalence scale. Results on this measure indeed confirmed the other self-report results that targets described by mixed traits elicited more ambivalence (  M   = 48.05, SE = 5.14) than did targets described by consistent traits [  M   = −30.21, SE = 4.61;   t  (19) = −9.405,   P   < 0.001,   r   = 0.91]. 
  
For exploratory reasons, participants also responded to the same questions presented in the scanner on a continuous scale ranging from definitely not (0) to definitely yes (100). This measure was not analyzed for this study. 
  
We verified the results of the MLM by running an ANOVA. Note that because of the unbalanced design, ANOVA is inferior to MLM in this case. This analysis resulted in similar findings; the details can be found in the Supplementary Material S4. 
  
Activation in right DLPFC explained response behavior [χ (1) = 4.47,   P   = 0.03; left DLPFC: χ (1) = 6.50,   P   = 0.01] next to decision times [χ (1) = 10.75,   P   = 0.001; left DLPFC: χ (1) = 9.48,   P   = 0.002]. Whereas there was no main effect of trial type on the valence of the judgments participants made, we observed that the effect of decision time on the direction of judgments depended on trial type [χ (2) = 16.69,   P   = 0.0002; left DLPFC: χ (2) = 14.89,   P   = 0.0006]. 
  
We observed that the direction of response behavior could be explained by (participant- and valence-centered) activation in dACC [χ (1) = 3.70,   P   = 0.05] next to (participant- and valence-centered) decision times [χ (1) = 9.35,   P   = 0.002]. Variation in decision times also predicted the valence of judgments dependent on trial type [χ (2) = 15.21,   P   = 0.0005]. 
  


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-8'>
<h2>8. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/25885533/' target='_blank'>25885533</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Action Processing and Mirror Neuron Function in Patients with Amyotrophic Lateral Sclerosis: An fMRI Study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2015</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0119862</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4401664/' target='_blank'>4401664</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study used fMRI during social-cognitive tasks: action observation and action understanding (theory-of-mind related), which fall under ‘Perception and Understanding of Others’. The sample included a healthy control group (reported separately; Experiment 1: n=16 HCs in analyses; Experiment 2: n=16 HCs) even though patients with ALS were also studied. Whole-brain second-level random-effects analyses were conducted and reported (e.g., understand>observe, HC>ALS contrasts) alongside some ROI SVCs; thus whole-brain results are available. Behavioral ToM measures (RME) accompany the imaging. Minor caveat: explicit participant age range (17–65) is not listed in the full text, but participants were adult controls matched for age and gender; given typical adult recruitment and matching, inclusion is judged appropriate.</p>
<p><strong>Fulltext Confidence:</strong> 0.85</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Amyotrophic lateral sclerosis (ALS) is a highly debilitating and rapidly fatal neurodegenerative disease. It has been suggested that social cognition may be affected, such as impairment in theory of mind (ToM) ability. Despite these findings, research in this area is scarce and the investigation of neural mechanisms behind such impairment is absent. Nineteen patients with ALS and eighteen healthy controls participated in this study. Because the mirror neuron system (MNS) is thought to be involved in theory of mind, we first implemented a straightforward action-execution and observation task to assess basic MNS function. Second, we examined the social-cognitive ability to understand actions of others, which is a component of ToM. We used fMRI to assess BOLD activity differences between groups during both experiments. Theory of mind was also measured behaviorally using the Reading the Mind in the Eyes test (RME). ALS patients displayed greater BOLD activity during the action-execution and observation task, especially throughout right anterior cortical regions. These areas included the right inferior operculum, premotor and primary motor regions, and left inferior parietal lobe. A conjunction analysis showed significantly more co-activated voxels during both the observation and action-execution conditions in the patient group throughout MNS regions. These results support a compensatory response in the MNS during action processing. In the action understanding experiment, healthy controls performed better behaviorally and subsequently recruited greater regions of activity throughout the prefrontal cortex and middle temporal gyrus. Lastly, action understanding performance was able to cluster patients with ALS into high and lower performing groups, which then differentiated RME performance. Collectively, these data suggest that social cognition, particularly theory of mind, may be affected in a subset of patients with ALS. This impairment may be related to functioning of the MNS and other regions related to action processing and understanding. Implications for future research are discussed. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (41190 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Amyotrophic lateral sclerosis (ALS) is a progressive neurodegenerative disorder affecting both upper and lower motor neurons of the brain and spinal cord. The disease affects motor functioning, resulting in paralysis and eventual death typically from respiratory failure. There is increasing evidence that patients with ALS exhibit signs of multi-modal dysfunction, even in the early stages. Such impairments include cognitive [ – ] and behavioral (e.g. apathy and social disinhibition) dysfunction [ , – ]. Previous population-based studies have estimated approximately 35% of patients with ALS have these impairments, and an estimated 15% also have frontotemporal dementia (ALS-FTD) [ , ]. Although psychological symptoms in ALS were reported more than 80 years ago [ ], the characterization of cognitive dysfunction in this disease remains poorly understood. 

Recent evidence suggests that theory of mind (ToM), which is a higher level social-cognitive ability, may be one of the cognitive domains affected in ALS [ – ]. ToM describes ‘the ability to be in another person’s shoes’, for example by inferring the state or thoughts of another person. Understanding the actions of others is one domain of ToM function. By simply observing another person’s motor movement (e.g. reaching for the cup), one is able to interpret the meaning of that movement (e.g. to pick up the cup) and even propose the intent and goal of the action (e.g. to drink and quench thirst) [ , ]. The action observation network (AON) is recruited during this behavior, which has been associated with the location of mirror neurons (and is sometimes described interchangeably as the mirror neuron system (MNS) [ ]). It is suggested that this process of understanding motor actions of others is established by covertly mapping these actions onto one’s own motor repertoire, as if mentally simulating the action [ ]. Action understanding is therefore a relevant research area in the field of ALS because motor regions in the brain progressively degenerate, therefore the question remains whether the ability to process or understand the movements of others also becomes affected. 

Mirror neurons were first identified in the ventral premotor cortex and inferior parietal lobule [ – ] in the macaque monkey using single-cell recording. The landmark finding from these studies was that the same neurons became excited when the primate executed an overt motor action (e.g., reaching for an object), as well as when they observed the same action performed by another individual. Mirror neurons have since been recognized in humans and are believed to serve a role in social-cognition [ , – ]. Importantly, these neurons may be involved in the progression of ALS [ , ]. 

To investigate the ability of patients with ALS to process or understand the actions of others, we examined motor mirror neuron function using functional magnetic resonance imaging (fMRI). At the first level, we aimed to determine if the basic underlying neural substrate of the MNS system is affected. This was investigated during a straightforward motor action-execution and observation experiment. Our second aim was to examine neural and behavioral responses during social-cognitive ToM processing, specifically understanding the actions of others. Theory of mind was further evaluated behaviorally using a standardized assessment. 

We hypothesized that patients with ALS would show greater activation compared to healthy controls throughout regions in the MNS during both experiments, particularly the inferior frontal gyrus and inferior parietal lobe. We additionally hypothesized that in the second experiment we would see increased recruitment in prefrontal and posterior parietal regions that are involved during motor simulation states (such as theory of mind [ ]) and recognition of pantomimed movement [ , ]. Clinically, the MNS is believed to be important during social behavior (  see   [ , ]; thus any alteration of this capacity (behaviorally, cognitively, or physiologically) in ALS may be important in clinical management and care. 


## Methods 
  
### Participants 
  
Nineteen patients with ALS participated in this study. Patients were recruited through the University of Michigan ALS Clinic and were all diagnosed by a neuromuscular physician specializing in ALS with either probable or definite ALS, according to the El Escorial Criteria. Twenty healthy controls (HCs) were matched for age and gender and were recruited through the general Ann Arbor community through the   www.umclinicaltrials.org   website and from flyer postings. 

Participants were without contraindication to MRI and able to lie on their back for over one hour without respiratory distress. Exclusion criteria included a current diagnosis of a psychological or neurological disorder (other than ALS), or self-reported history of drug or alcohol abuse. Additionally, healthy control participants were excluded if they showed signs of depression or mild cognitive impairment, resulting in exclusion of two controls. Two HCs were unable to complete the fMRI portion of the study due to claustrophobia while in the magnet. These two participants completed all other parts of the study. 

Patients with ALS completed the ALS Functional Rating Scale, revised version (ALSFRS-R), which is a validated instrument of disease severity [ ]. The maximum possible score on this scale is 48, with lower scores indicating greater disease severity. Mean age, gender, mean years-of-education (based on degree obtained), mean months-since-symptom-onset, and ALSFRS-R means scores are presented in  . 
   Demographic Information for ALS and Healthy Control Groups.        
Education was calculated based on highest degree obtained. Specifically, a high school diploma or GED equaled 12 years; an associate’s or trade degree equaled 14 years; a bachelor’s degree equaled 16 years; a master’s degree equaled 18 years; a doctoral degree (medical, philosophy, or equivalent) equaled 20 years. Additional years of education beyond each degree but without obtaining the next level of degree added one year to the education level. This was calculated so education of a person many years of college, but without obtaining a degree, was not equivalent to someone who had the same years of college but with an appropriate degree. 

#### Ethics Statement 
  
This study was approved by the Institutional Review Board at the University of Michigan (Study: HUM00053092). All participants provided written informed consent prior to participation. No participants were mentally disabled; therefore, all had the capacity to provide consent. If a patient was unable to produce a written signature, a verbal consent was given and a legal representative consented in writing on the behalf of participant. 



### Neuropsychological Assessment 
  
Cognition between groups was assessed using the both the ALS Cognitive Behavior Screen (ALS-CBS) [ ] and Montreal Cognitive Assessment (MoCA) [ ]. The ALS-CBS tests for frontal lobe-mediated abilities, and is sensitive in screening patients with comorbid frontotemporal dementia (FTD). The MoCA is aimed to screen for mild cognitive impairment in general elderly populations, therefore was well suited to screen for cognitive impairment in the healthy control group. 

Theory of mind is often related to executive functioning, which involves higher-level cognitive processes such as problem solving, planning, and working memory. To test for executive function differences between groups, standardized behavioral assessments of executive function were conducted. Verbal fluency is among the most sensitive measures of executive dysfunction in ALS [ ], therefore the Controlled Oral Word Association Test (COWAT, for letters C, F and L) and the Category verbal fluency (Animal Naming) tasks were used. To adjust for speech impairment, a Verbal Fluency Index score was calculated using the number of words generated and the length of time it took to repeat these words [ ]. 

A standardized behavioral measure of theory of mind processing was also implemented, specifically the Reading the Mind in the Eyes Test (RME) [ ]. The RME assesses a person’s ability to infer the emotions of others by examining pictures of facial eye expressions. In this test, participants are shown a picture in which only the region of the face surrounding the eyes is displayed. Participants are then asked to select a phrase (out of four choices) that best describes the way the person in each picture is feeling. 

Behavioral changes in the ALS patients were examined with two different screens: the ALS-CBS caregiver form and the Emotional Lability Questionnaire. The ALS-CBS caregiver form [ ] is a questionnaire for the patient’s caregiver to report the amount of behavioral change observed since the onset of the patient’s ALS symptoms, such as apathy and depression. Lower scores indicate greater behavioral change. Pseudobulbar affect, which includes uncontrollable bouts of crying or laughing, was measured using the Emotional Lability Questionnaire (higher scores reflect more symptoms) [ ]. Both the patient and the caregiver completed this questionnaire. Lastly, depressive symptoms were measured using the Geriatric Depression Scale, shortened version [ ], which screening tool for depression. This measure was chosen because it does not incorporate questions that could confound depressive symptoms with physical or vegetative symptoms specific to ALS, such as changes in sleeping or eating patterns. Higher scores on this screen suggest greater risk of depression. All neuropsychological measurements are described in  . 
   Descriptive results of neuropsychological assessments administered to patients with ALS and healthy controls.        

### fMRI Protocol 
  
Blood oxygenated level dependency (BOLD) signal activity was collected over a period of 8.9 minutes for Experiment 1 and 12.0 minutes for Experiment 2. Both experiments were implemented using E-Prime v. 2.0. These experiments were projected onto a screen at the head of the scanner bore and viewed with a back-projected mirror placed on the head coil. 

#### Experiment 1: Action Observation and Execution 
  
A key property of mirror neurons is involvement during observation of an action [ ]. Therefore, to test whether mirror neurons may be affected in ALS, the first experiment implemented a basic task involving the simple observation of actions. This experiment involved a block design that included two alternating conditions: i) an action-observation condition (watching a video on a computer screen of someone squeezing a ball), and ii) an action-execution condition (the participant squeezing a ball). The action-execution component served as a benchmark for replicating previous research. Previous research has shown that BOLD signal differences in patients with ALS during motor execution resulted in greater activity in the motor regions, even after correcting for effort [ ]. Therefore, we expected to see similar activity differences in the observation condition, supporting our hypothesis that mirror neuron function is affected in ALS. Fourteen blocks total were presented, alternating between observe and execute conditions. These blocks were separated by a jittered fixation (between 4-8sec) and were preceded by a 1sec prompt of either the word “watch” or “squeeze”. 

During the observe condition, participants watched an actor’s hand rhythmically squeeze a ball every 1.5 seconds over a 12sec-block duration (see  ). Participants were told to passively observe this action and to not move their own hand while observing. Participants were monitored from outside the scanner to ensure these instructions were followed. 
   Example of a trial from each condition (action-observation and action-execution) in Experiment 1.    
During the action-execution condition, participants squeezed a small soft ball every 1.5sec for a duration of 12sec using their dominant/non-affected hand. During this time participants viewed a picture of a ball on the computer screen that shrank every 1.5sec to signal when to squeeze their hand. Participants were not shown an actor’s hand in this condition to reduce the confound of activity that would be induced by action observation [ ]. Participants were told to squeeze the ball at a comfortable level in order to reduce expected increased exertion and neural recruitment by patients with ALS [ , – ]. 

The number of squeezes observed and executed were the same within scans and between participants. To control for tactile stimulation, participants held the ball throughout the duration of the scan. To assist with hand weakness for ALS participants, Velcro straps were wrapped around the ball and the hand of the participant to hold the ball in place. For experimental consistency, this was done for every participant. Participants were trained outside the scanner on this experiment. 


#### Experiment 2: Action Understanding 
  
Experiment 2 was carried out to examine involvement of the mirror neuron network during motor cognition, specifically action understanding. This experiment was a modified version of that designed by Molenberghs et al. [ ]. In Molenberghs et al. [ ], three conditions were examined in order to tease apart context effects. The goal of the current study, however, was to measure activity during action understanding, which was compared to passive observation of actions. Therefore our experiment only included two of the three conditions from Molenberghs et al. [ ]. Another difference was that only one run was implemented (opposed to two) to reduce possible fatigue or discomfort for the patients. 

During this experiment, participants watched a computer screen and were told to either passively observe (observe condition) or actively understand (understand condition) a short (1sec) video of an actor pantomiming an action with their hands. In each video, only the torso section of the actor was displayed and no objects were used (  see   [ ]). Each video was preceded by the condition cue (“observe” or “understand”) and followed by a 6sec delay. After the delay, participants were either shown a 2sec no-go (catch trial) screen or a response screen. During the observe condition, the response screen showed two side-by-side pictures. Participants had to select which picture matched a still-frame scene from the video. During the understand condition, participants had to select the correct action from two phrases (see  ). There were 20 trials of each condition, randomly presented per participant. 
   Example of a trial from each condition (understand and observe) in Experiment 2.    
During this scan, all participants held in each hand a small response bulb that was Velcro-strapped around their palms (to assist with hand weakness). Participants made a forced-choice response by either hand, corresponding to the location of their response selection on the screen (left or right). Because some patients were not able to make a physical response, all participants were also instructed to think of their selection. 



### Imaging Acquisition 
  
All scanning was performed at the University of Michigan's Functional MRI Laboratory on a GE 3T Excite 2 (General Electric, Milwaukee, WI, USA). During each participant's session, medium-resolution spin-echo (T -Overlay) and high-resolution spoiled-gradient recall (T -SPGR) anatomic images were collected in the axial plane (256 x 256 matrix, 220 mm FOV, and with 1.2 mm slice thickness). T -Overlay images were acquired in the same-slice locations as the T2* volumes, however at a higher in-plane resolution (256 x 256 matrix, 220 mm FOV). T2* time-series data were acquired in the axial plane (aligned to the anterior–posterior commissure) using a reverse-spiral k-space readout. A total of 266 and 360 T2*-weighted volumes were collected for each participant during Experiment 1 and Experiment 2, respectively (repetition time TR = 2sec, 40-slice volumes at 3 mm slice thickness and no skip, echo-time TE = 30ms, 64 x 64 matrix, 220 mm FOV). Four T2* volumes at the beginning of each time-series acquisition were excited but not recorded in order to achieve thermal equilibrium of magnetization. 


### Preprocessing 
  
Slice timing and motion correction were applied using Statistical Parametric Mapping, version 8 (SPM8; Wellcome Trust Center for Neuroimaging, (  http://www.fil.ion.ucl.ac.uk/spm  , release 4667) and FSL's MCFLIRT (  http://www.fmrib.ox.ac.uk/fsl   version 5.0.2.2), respectively. Each participant's T -Overlay volume was co-registered to the time-series data; the T -SPGR was then co-registered to the co-registered T -overlay image. Spatial normalization to the Montreal Neurological Institute (MNI 152) template of the resulting co-registered T -SPGR image was then performed using SPM8/VBM8. The resulting normalization was applied to the slice-time-corrected time-series data. The resulting T2* images had 3 mm isotropic voxels. These normalized T2* time-series data were subsequently spatially smoothed with a 5 mm Gaussian kernel. 


### fMRI Data Analyses 
  
All fMRI statistical models were conducted using SPM8. In Experiment 1 (action observation and execution), fMRI blood oxygenated level dependency (BOLD) signal differences were analyzed using a standard hemodynamic response function, implemented with the General Linear Model (GLM). In this task, first level regressor estimates for each of the conditions (observe and execute) were obtained by contrasting each condition (observe, execute, observe + execute) against the implicit resting baseline (contrasts [1, 0, 0]; [0, 1, 0]; [.5,. 5, 0]). Second-level random-effects analyses were compared between ALS patients and HCs using uncorrected   p   < 0.001 threshold. 

The primary goal of this experiment was to examine the basic functioning of the MNS in patients with ALS. Again, the MNS is composed of neurons that respond to both an executed action and observation of that same action. Therefore a conjunction analysis was performed to extract the intersected (overlapping) voxels within the MNS that were activated specifically during both action observation and execution conditions. An inclusion mask of MNS regions identified in the human brain (  see   [ ]) was created using the WFU PickAtlas software tool [ ] and was applied at the second-level for Experiment 1. Overlapping voxels of activity resulting from these two conditions within the MNS mask were counted per participant using a custom code written in MATLAB, and then compared between groups using an independent sample   t  -test. 

In Experiment 2 (action understanding), first level analyses were run using the finite response function (FIR), following in line with methods implemented by Molenberghs and colleagues [ ]. In this model, only neural activity resulting from observing or understanding the action in each trial was included in the analysis, therefore not confounding results with activity derived from the overt motor response made after each trial. To examine activity specific to the social cognitive task of understanding actions, first-level analyses were run with the   understand > observe   contrast (1–1 0) using the GLM. This was entered into a second-level random-effects group whole brain analysis between ALS patients and HCs using an uncorrected   p   < 0.001 threshold. 


### Experiment 2 Behavioral Data: Action Understanding 
  
Accuracy data was collected in Experiment 2 for understand and observe trials and was compared between patients with ALS and HCs. Omissions were not included in accuracy measurements. Comparisons between groups were made using independent sample   t  -tests in SPSS, version 22. 



## Results 
  
### Neuropsychological Assessments 
  
Means and standard deviations for each of the cognitive and social measurements that were gathered (ALS Cognitive Behavioral Screen, Montreal Cognitive Assessment, Controlled Oral Word Association Test, Categorical Fluency for Animals, Reading the Mind in the Eyes, Emotional Lability Screen, and the Geriatric Depression Scale, shortened version) are reported in   for both patients with ALS and healthy controls. One patient scored low on the MoCA, but no participant scored below the cut-off for frontotemporal dementia on the ALS-CBS (therefore indicating a low risk of participants with FTD). Two patients showed signs of pseudobulbar affect according to the ELQ (from both self and caregiver reports), and both patients’ caregivers reported high levels of behavioral changes according to the ALS-CBS caregiver form. Neither of these patients appeared at high risk for cognitive dysfunction (e.g. one patient scored in the 96  percentile on the COWAT). One patient was at risk for having depression, according to the GDI. One healthy control scored below the 5  percentile during the verbal fluency tests and scored in the cognitively impaired range on the MoCA, and another scored in the range for suspected depression on the GDI. Accordingly, data from these control participants were removed from the study and not included in any of the analyses or tables. 

Between-group differences for verbal fluency (COWAT), general cognition (ALS-CBS and MoCA), and theory of mind (RME) were tested. Because scores between the COWAT and Animals were collinear (Pearson’s   r   = 0.36,   p   = 0.03), only the COWAT was included in the model since this test is more represented in the literature. To account for multiple comparisons between tests and to control for level of education (  t  (35) = 3.70,   p   < 0.01, see  ), a multivariate analysis of covariance (MANCOVA) was conducted. One patient and one HC did not complete the RME, resulting in 18 patients and 17 HCs in this analysis. Overall, there was not a main effect of group,   F(  1, 31) = 0.60,   p   = 0.71, however the effect of education reached near significance,   F  (1, 31) = 2.60,   p   = 0.05. This model showed no univariate differences in any of the neuropsychological assessments between patients with ALS and HCs, however, education had a significant effect on the verbal fluency test (COWAT,   p   = 0.02). These results imply the groups were overall similar in their performance but that level of education (regardless of group) was related to verbal fluency ability. 


### Experiment 1: Action Observation and Execution 
  
#### fMRI Data 
  
Nineteen patients with ALS and sixteen HCs were included in these results. Between-group analyses in Experiment 1 showed greater activity in the ALS group compared to HCs for all three contrast conditions. Greater activity was observed throughout the MNS, particularly in the right hemisphere. Notably, the right inferior operculum was more active in the ALS group for all three contrasts (  observe  ,   execute  ,   observe + execute  ),   p   < 0.001 (uncorrected, see Figs   and  ). There was also greater activity in left inferior parietal lobe and left middle temporal gyrus during both the   observe   and   observe + execute   contrasts. The main condition of interest, the observe condition, resulted in increased activity throughout the right frontal lobe including the supplementary motor area and rolandic operculum, the right parietal and temporal lobes, and the basal ganglia and cerebellum. The   observe + execute   contrast also recruited greater right frontal, parietal, and superior temporal gyrus activity as well as increased activity in the left primary motor cortex, left subcortical regions, and cerebellum. In accordance with previous literature, the motor execution condition resulted in greater activity in the ALS group compared to HCs. Specifically, activity was greater in the right premotor region (see  ), right somatosensory cortex, right middle temporal gyrus, and left basal ganglia. The HC group exhibited no regions of greater activity compared to the ALS group in any contrast. See   for complete results. 
   Experiment 1 Action Observation and Execution Task, ALS > HC.  
Greater activity in the ALS group compared to HCs throughout the frontal lobe during the action observation and execution conditions.) 
     Experiment 1 Action Observation and Execution Task, ALS > HC.  
Greater activity in the ALS group compared to HCs in the right inferior operculum from the combination of both action observation and execution conditions.) 
     Anatomical regions and coordinates located in activation maps during Experiment 1 (Action Observation and Execution).        
Small volume correction analyses were evaluated for specific   a priori   regions of interest in the observe condition using a 5mm sphere, including the inferior operculum and inferior parietal lobe. The right inferior operculum,   p   < 0.001 (MNI: 52, 5, 25), and left inferior parietal lobe,   p   < 0.009 (MNI: -57, -52, 49) were both significantly more active in the ALS group during this task. 

In the conjunction analysis, the ALS group (  M   = 505.12,   SE   = 127.70) had significantly greater number of coactivating voxels within the MNS compared to the HC group (  M   = 192.06,   SE   = 66.57),   t  (33) = 2.10,   p   = 0.048. This greater extent of activity (see  ) seen in patients with ALS suggests a compensatory mechanism in the ALS brain when both observing and executing an action. 
   Experiment 1 Conjunction Analysis of Co-activated Voxels During Execution and Observation of Actions.  
Cut-out sections of the inferior frontal gyri and inferior parietal lobes. Activity maps indicate only the voxels that were active during both the action execution and observation conditions during Experiment 1. The ALS group’s intersecting voxels are shown in red, the HC group is shown is green. Colors are blended in overlapping regions.) 
  


### Experiment 2: Action Understanding 
  
#### fMRI Data 
  
Data presented for this experiment includes 18 patients with ALS (one patient was excluded from the analyses because they fell asleep during this experiment) and 16 HCs. Activity from the   understand > observe   contrast displayed greater activity in the HC group throughout right prefrontal cortex including the triangularis, bilateral orbital regions, bilateral temporal lobe, and the occipital lobe (  p   < 0.001, uncorrected, see  ). Regions of greater activity in the ALS group only included the right occipital lobe (See  ). 
   Experiment 2 Action Understand > Observe, HC > ALS.  
Greater activity in the HC group compared to patients with ALS throughout the right prefrontal cortex and temporal regions shown for the   understand>observe   contrast from Experiment 2.) 
     Anatomical regions and coordinates located in activation maps during Experiment 2 (Action Understanding) for the   understand > observe   contrast.        
To make sure differences in education were not driving these results, we analyzed this data again including years-of-education in the GLM model as a covariate for the   HC > ALS   contrast. Results confirmed that the pattern of BOLD activity differences described above were not a result of education differences between groups. Specifically, the pattern of greater activity in the HC group was similar to that described above, including increased activity in the right frontal inferior operculum and triangularis, right inferior, middle and superior orbital regions, superior and middle frontal gyri, bilateral middle temporal gyri, right superior temporal gyrus, left inferior temporal gyrus, left middle cingulate, left thalamus, and right putamen (  p   = 0.001, uncorrected). 


#### Behavioral Data 
  
Behavioral data was obtained for thirteen patients from the ALS group (missing due to motor impairment), and data from three HCs were not collected because of temporary equipment malfunction (response signals were not received by EPrime). A non-parametric Mann-U Whitney test was conducted to compare group accuracy percentage differences. Both groups were similarly accurate in identifying the correct matching picture during the observe condition,   U(24) =   79,   Z = -  0.28,   p =   0.80, (  M   = 82.65,   SD   = 11.14;   M   = 80.32,   SD   = 13.79). There was a ceiling effect found for the understand condition in the HC group, and also for a portion of ALS patients, thereby creating a bi-modal distribution of the ALS data. 

We therefore separated the ALS patients into two groups according to their action understanding performance (9 patients at ceiling and 6 patients   M   = 78.98(%),   SD   = 10.39). Sub-groups were contrasted at the second level in SPM for the   understand > observe   contrast. It was found that patients who were 100% accurate in their responses also showed greater activity in bilateral frontal superior gyri, whereas patients who performed worse did not have any areas of greater activity (  p   = 0.001, uncorrected). 

Because the action understanding task is deemed to assess ToM behavior, we further compared group differences to the standardized Reading the Mind in the Eyes ToM test (RME). Accuracy measurements from the RME test were compared between subgroups using an independent sample Mann-U Whitney Test. It was found that the subgroup of patients who performed better on the action understanding task also performed better on the RME test (  M   = 79% accurate) compared to the patients who performed worse (  M   = 69% accurate),   U(  12) = 7.5,   Z   = -2.02   p   < 0.05. 




## Discussion 
  
Patients with ALS experience rapid progression of muscle weakness and paralysis. It is known that brain regions responsible for motor execution become compromised. Our study shows more complex motor systems, including the MNS and other extra-motor regions, may also be affected by the disease process. 

The first experiment in our study aimed to evaluate basic mirror neuron function by examining neural recruitment within the MNS system when participants either observed or executed a simple motor action. Results from the action execution component supported previous findings of greater recruitment of BOLD activity in patients with ALS [ , – ]. Importantly, greater activity was recruited in the patient group in MNS regions within the right frontal and left parietal lobes while simply observing a motor action. Both tasks in particular recruited greater activity in the inferior operculum. The operculum is known to be important during action processing [ , ] and is one of the primary regions comprising the MNS [ ]. It is suggested the operculum reflects the human homologue to the region F5 in the macaque monkey, where mirror neurons were first identified [ , , ]. 

Increased recruitment of the MNS was further supported by the conjunction analysis. When the number of co-activated voxels during both observation and execution of a hand squeeze were examined, patients with ALS had a significantly higher number of intersecting voxels. The conjunction analysis only included voxels that were active during both observation and execution of the same motor action. Therefore, increased voxels seen in the ALS group were partially derived from passive observation of simple actions and not solely a result of motor execution differences. If exertion differences were causing greater recruitment of co-activated voxels, as is typical with motor execution paradigms, then this would infer patients were also exerting greater energy when simply viewing the actions of others. Overall, results from Experiment 1 support the possibility that the MNS is affected by ALS at the basic level, and that the MNS may initiate a compensatory strategy when involved in action processing. 

The second experiment in this study examined the higher-level social cognitive ability of action understanding, which is considered a function of the MNS and also a component of theory of mind. This experiment showed that healthy controls were overall better at this task. In line with this behavior they recruited greater activity within the MNS and in regions associated with action understanding, particularly the right frontal regions. Healthy controls also recruited more activity in the left middle temporal gyrus, which has recently been identified as the primary region that bridges together the two neural pathways involved specifically in action understanding [ ]. Patients with ALS recruited more activity only in the occipital lobe. 

Results from the second experiment do not support a role for compensatory MNS recruitment in ALS. However, results from both studies do suggest there are differentiated roles of the MNS during basic action processing compared to action understanding. Likewise, these results appear to reflect behavioral performance. Specifically, behavioral performance and neural function during simple observation of actions may be more similar to the mechanisms involved during the execution of an action in ALS. This corresponds to mirror neuron literature showing neural responses to both executed and observed actions [ ], and also corresponds to literature showing a compensatory strategy initiated by the execution of an action in patients with ALS [ , , ]. Research shows involvement of neural regions both within and outside the MNS during action understanding [ ]. Therefore, better performance by the HC group could be reflected in the greater neural recruitment seen in the action understanding task, which would not counter the possibility of a compensatory MNS theory. Rather, it would support the notion that action understanding may be compromised in ALS, without the resources for neural compensation. This pattern of greater neural recruitment corresponding to better action understanding performance was also seen in the patients who scored at ceiling on this task compared to the lower performing patients. 

Results from these experiments, especially the first experiment, share similarities with work examining motor imagery in ALS. For example, increased activity in patients with ALS have been seen during imagined movement throughout the parietal, premotor, and primary motor cortices [ , ], and behavioral differences during imagined hand positions have been reported [ ]. Both the action observation network (AON) and motor imagery (MI) network are presumed to fall under a hierarchical simulation network, which share a core network [ ]. Specifically, the AON includes bilateral involvement of the premotor cortex, supplementary motor cortex, inferior frontal gyrus, prefrontal cortex, posterior middle temporal gyrus, superior and inferior parietal lobe, and the posterior cingulate gyrus [ ]. The MI network however is thought to entail the premotor cortex, supplementary cortex, cingulate, superior, inferior and middle frontal gyri, inferior parietal lobe, basal ganglia, and cerebellum [ ]. 

Motor simulation processes support various motor functions, including recognition and understanding [ ], and are important precursors for executing actions. For example, when learning a motor movement, increased activity is seen throughout the extra motor regions within the AON and MI network, and is negatively correlated to skill level (see [ ]). This trend of neural efficiency has been demonstrated when learning to sequence strokes on a guitar [ ] and also in expert gymnasts [ ]. These studies indicate that as one masters a skill, the demand on extra-motor neural resources for action execution decreases. Corroborating research involving imagined and executed movements in ALS [ , , , , ] indicates the opposite effect is happening, specifically as the ability to produce overt motor actions decreases, the need for neural resources increases. However, other research has shown a decrease in activity in motor regions during executed movement [ ], which may be specific to a later disease stage process [ ]. This emphasizes the need for continued longitudinal evaluation of motor network changes. 

As previously stated, motor imagery and action observation networks are considered to be two distinct networks [ , ], yet with considerable overlap [ , ]. However, it is unknown the level of interaction, and whether observation of actions can automatically activate motor imagery [ ]. This is a potential confound in the current study, as these systems are possibly intertwined [ ]. Interestingly, research comparing these systems is minimal. Specifically, a recent meta-analysis showed that of all the motor imagery and action observation studies, only approximately 3% examined both functions [ ]. 

Although data from this study may suggest a role of mirror neuron involvement and decreased ability to process the actions of others in patients with ALS, other explanations must be considered. It has already been suggested that motor imagery may confound results with motor observation. Results from this study may also support the possibility that a preparatory role in action initiation is compromised [ ]. This possibility could explain the increased cortical activation seen in the ALS group during Experiment 1 as opposed to direct mirror neuron involvement. Last, action understanding processing in ALS may be distinct from the mirror neuron system and therefore not directly related to mirror neuron processing [ ]. This would suggest a more general role of action processing that encompasses various motor functions being compromised in ALS. 

### Reading the Mind in the Eyes Test 
  
Behavioral performance during the theory of mind task (Reading the Mind in the Eyes, RME [ ]) was not different between patients with ALS and healthy controls. This supports a previous study that also used the RME [ ]. A second research study that used this assessment however found group differences that were trending toward significantly poorer performance by the ALS group [ ]. When all three studies are examined collectively, it appears ToM as examined by the RME is not particularly sensitive in ALS. However, other work has found ToM changes in patients with ALS when using other forms of ToM assessment [ , , , ]. Particularly, ToM differences may be more pronounced during social situations [ ]. 

In all four previous ToM experiments [ , , , ], patterns of behavioral differences became more apparent when patients were examined more closely at the individual level. When examined more closely, our data too showed that patients could be separated according to performance in the action-understanding task. Specifically, patients who performed at ceiling on the action-understanding task also recruited greater activity in the bilateral superior frontal gyrus, supporting a trend of increased recruitment during better action understanding performance that was also seen in the HC group. Additionally, these specific patients performed better in the Reading the Mind in the Eyes (RME) task [ ]. Theory of mind performance may therefore be able to further identify patients who display social-cognitive symptoms, yet without global cognitive impairment. 

This idea corroborates recent research suggesting ToM could be sensitive to identifying cognitive impairment [ ]. It may be possible to even dissociate ToM impairment from other executive function abilities [ ], which our data partly supports as patients were not impaired during the executive function task (verbal fluency) in this study. Although executive functions are the most commonly reported cognitive symptoms in ALS [ , , , – ], it is becoming clear that cognitive impairment is not limited to executive functioning. For example, additional domains such as emotional [ , – ] and sensory processing [ ] impairments have been reported in patients with ALS. Even more related to our current study is research showing an impairment in processing action words (verbs) [ – ]. 


### Limitations 
  
It is noted that several clinical measures that may confound cognitive function were not collected in this study, such as forced vital capacity and behavioral impairment. Both patients who were at risk for behavioral impairment, according to the ALS-CBS, also had scores from the ELQ indicating possible pseudobulbar affect. Neither of these patients however showed any signs of cognitive impairment, and both performed at ceiling on the action understanding task. Another limitation is that neuroimaging results presented are at the uncorrected (  p   < 0.001) threshold, thus warranting further replication. Despite a liberal analysis, results were consistently in accord with brain regions associated with action observation and understanding. 


### Conclusions 
  
Overall, this study supports ALS as a multi-system disorder, and furthermore corroborates research showing that social cognitive functioning, and specifically theory of mind, can be negatively impacted in some patients. It would be of interest to examine whether action observation would help prolong extra motor network function [ ] and slow the progression toward previously observed decreased neural recruitment [ ]. Further research is needed to explore the specific involvement mirror neurons may play in ALS, and how this may aid in furthering our understanding of the pathogenesis of this disease. 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-9'>
<h2>9. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/24040207/' target='_blank'>24040207</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Isn’t it ironic? Neural Correlates of Irony Comprehension in Schizophrenia</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2013</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0074224</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3769349/' target='_blank'>3769349</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study reports BOLD fMRI during an explicit social-communication task (irony comprehension), which falls under Social Communication / Perception and Understanding of Others. It includes a healthy control group (n=15) of adults matched to patients; results for controls are reported separately. Imaging analysis used whole-brain random-effects analyses in SPM5 with MNI coordinates and voxelwise thresholds (p<0.001 uncorrected, cluster extents), and whole-brain between-group contrasts are reported (not ROI-only). Thus it meets all inclusion criteria (social task, healthy adult participants, whole-brain analyses) and violates no exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Ironic remarks are frequent in everyday language and represent an important form of social cognition. Increasing evidence indicates a deficit in comprehension in schizophrenia. Several models for defective comprehension have been proposed, including possible roles of the medial prefrontal lobe, default mode network, inferior frontal gyri, mirror neurons, right cerebral hemisphere and a possible mediating role of schizotypal personality traits. We investigated the neural correlates of irony comprehension in schizophrenia by using event-related functional magnetic resonance imaging (fMRI). In a prosody-free reading paradigm, 15 female patients with schizophrenia and 15 healthy female controls silently read ironic and literal text vignettes during fMRI. Each text vignette ended in either an ironic (n = 22) or literal (n = 22) statement. Ironic and literal text vignettes were matched for word frequency, length, grammatical complexity, and syntax. After fMRI, the subjects performed an off-line test to detect error rate. In this test, the subjects indicated by button press whether the target sentence has ironic, literal, or meaningless content. Schizotypal personality traits were assessed using the German version of the schizotypal personality questionnaire (SPQ). Patients with schizophrenia made significantly more errors than did the controls (correct answers, 85.3% vs. 96.3%) on a behavioural level. Patients showed attenuated blood oxygen level-dependent (BOLD) response during irony comprehension mainly in right hemisphere temporal regions (ironic>literal contrast) and in posterior medial prefrontal and left anterior insula regions (for ironic>visual baseline, but not for literal>visual baseline). In patients with schizophrenia, the parahippocampal gyrus showed increased activation. Across all subjects, BOLD response in the medial prefrontal area was negatively correlated with the SPQ score. These results highlight the role of the posterior medial prefrontal and right temporal regions in defective irony comprehension in schizophrenia and the mediating role of schizotypal personality traits. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (33426 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Ironic remarks, although common, represent a comprehension challenge for the listener. In the case of linguistic irony, what is said is, in most cases, the exact opposite of what is intended (e.g., ‘oh brilliant’ when something bad happens). Several factors make research on comprehending ironic and sarcastic remarks in schizophrenia very interesting. Irony, alone, is interesting because it is so frequently used in everyday language, as indicated by linguistic analyses  ,  ,  . Understanding irony relates to ambiguity resolution  . Irony is ambiguous   per se   and is often used in difficult stages of communication  ,  ,  ,  . Interaction deficits, defective appraisal of the intentions of others, and language abnormalities, particularly in an ambiguous context, are hallmark features of the psychopathology of schizophrenia. 

Comprehension of ironic remarks in schizophrenia was recently the topic of a series of studies  ,  . It is now confirmed that patients with schizophrenia have deficits in comprehending ironic remarks  ,  ,  ,  , although not all patients exhibit the deficit  ,  . It is generally assumed that the difficulties in irony comprehension in patients with schizophrenia have a common neural basis. However, little is known about the neural correlates of irony comprehension in schizophrenia. Unravelling these neural correlates is important because irony comprehension tasks could possibly serve as a window into the dysfunction of several neuronal subsystems in schizophrenia. For instance, irony comprehension relates to hemispheric interaction. In essence, irony comprehension involves both the cerebral hemispheres and their interplay  ,  ,  ,  ,  ,  , so that irony comprehension may provide insight into hemispheric interaction in schizophrenia  ,  . Another functional system that might relate to defective irony comprehension in schizophrenia is the mirror neuron system. It has been proposed that mirror neuron dysfunction may underlie the social cognition deficits in patients with schizophrenia  ,  ,  . Moreover, this system has been reported to be involved in the comprehension of irony (see  ). A third possibly affected system is the brain default mode network, which is altered in schizophrenia  . The default mode network is involved in theory of the mind (TOM;  ), which is also an important cognitive operation in irony comprehension  ,  . The medial prefrontal cortex, a key region for the comprehension of ironic stimuli in healthy subjects  ,  ,  ,  , is part of this network. It has been previously demonstrated that medial prefrontal cortex dysfunction may underlie impaired affective mentalizing in schizophrenia  ,  ,  . 

Several theoretical models have been proposed for brain dysfunction during irony comprehension in schizophrenia. Perhaps, the most commonly proposed model is that the defective irony and sarcasm (that is, irony with hurtful intentions) comprehension in individuals with schizophrenia is due to deficits in TOM and perspective taking  ,  . Indeed, TOM is one of a number of essential cognitive steps required for irony comprehension  ,  . This model assumes that the TOM is the key problem and implies that the functional neuroanatomical deficits are present in brain regions crucial for TOM, such as the medial prefrontal cortex. 

Misinterpretation of ironic remarks may also contribute to developing or worsening positive symptoms such as persecutory delusions. The cognitive model proposed by Salvatore et al.   assumes misinterpretation of “ambigous and hard-to-interpret communicative signals” such as “ironic comments” in co-occurence with the factors above may induce delusions. Thus, investigating the (mis)understanding of ironic remarks in schizophrenia will provide insights into an important aspect of schizophrenic psychopathology. 

Leitman and colleagues   proposed a model that deficits in prosody and speech melody perception are important for sarcasm detection deficits in schizophrenia. This model suggests a deficit in the brain regions associated with comprehension of prosody, such as the right superior temporal cortex  ,  . Further, this would mirror fMRI findings in autism, where prosody interacts with fMRI correlates during irony comprehension  . Nevertheless, the importance of prosody for irony comprehension is controversial because it is only one of a number of markers for irony  . Irony without speech melody is not only possible  , but is actually very frequent in written language  ,  ,  . In fact, patients with schizophrenia show abnormalities in tasks with written irony  ,  . 

Another model states that dysfunction of the right cerebral hemisphere and/or defective interaction between the cerebral hemispheres may underlie difficulties in deciphering irony and sarcasm in schizophrenia  ,  . Traditionally, comprehension of non-literal stimuli is ascribed to the right cerebral hemisphere ( ; see  ,   for a critical discussion). Indeed, there is sufficient evidence that the right hemisphere is involved in the comprehension of irony. Both the left and right hemispheres are more involved in comprehension of ironic remarks than in lower linguistic functions  ,  ,  . The hypothesis that the comprehension difficulties in schizophrenia represent a right hemisphere deficit is, therefore, plausible, but currently lacks experimental support. The functional lateralisation of irony comprehension in schizophrenia is also interesting from another point of view; increasing evidence indicates that language lateralisation is reduced in schizophrenia  , i.e., in schizophrenia, language is shifted to the right cerebral hemisphere to a higher extent. It has been proposed that language functions previously outperformed by the right hemisphere might, in a similar manner, shift to the left hemisphere  , particularly in patients with severe thought disorder  ,  ,  . The latter assumption is supported by findings of studies in patients with severe thought disorders and language production tasks  ,  , and in patients with difficulties in literal language comprehension  ,  ,  . 

Dysfunction of the brain language system is crucial for another model of disturbed irony comprehension that was recently proposed by our group  ,  , in which we assumed a role of the frontotemporal language semantic comprehension network for disturbed irony comprehension in schizophrenia and adopted a model put forward by Siever and Davis. Siever and Davis   suggested a model that strengthens the role for schizotypal personality traits in schizophrenia. Briefly, they suggested that individuals with elevated schizotypal traits and patients with schizophrenia share a temporal lobe deficit, which is compensated for by lateral prefrontal overactivation in schizotypy, but not in schizophrenia. Nonliteral language comprehension highly relies on frontotemporal interaction  ; moreover, underactivation in left prefrontal regions has been reported for another type of nonliteral language, metaphors, in schizophrenia  ,  . Therefore, language paradigms represent good paradigms to test the hypothesis. Indeed, in our previous publication, we showed that higher degrees of schizotypal personality traits in a non-clinical population resulted in reduced lateral temporal activation, but increased left lateral prefrontal activation, as detected using fMRI  . Following Siever and Davis  , we hypothesize reduced activation in both these regions in schizophrenia. 

To our knowledge, no fMRI studies on irony comprehension in schizophrenia have been reported. The aim of this work is to provide the first insights into the functional neuroanatomy of irony comprehension in schizophrenia using fMRI. Our hypotheses for activation abnormalities in schizophrenia are based on the functional models outlined above. We hypothesize a functional deficit in the brain fronto-temporal semantic language system in both cerebral hemispheres. Based on our previous study in non-clinical schizotypal individuals, we think that the strength of the deficit will correlate with the degree of schizotypal traits. Further, we expect that as an alternative, or in addition to, the abnormalities in the frontotemporal system, functional deficit will be observed in TOM regions, including the medial prefrontal cortex and the temporoparietal junction, both of which play a role in irony comprehension in healthy subjects  . Prosody may likewise interact with the functional deficits in schizophrenia. Thus, in this investigation, we chose a prosody-free task to limit influencing factors. Deficits in both the medial prefrontal and temporal lobe systems are expected to mirror the findings for irony comprehension in autism  ,  . Further, we hypothesize that compensatory activation (fMRI signals greater in schizophrenia patients versus controls), equivalent to literal language perception in schizophrenia  , may occur in brain regions adjacent to the classical semantic system, such as the premotor cortex. 


## Materials and Methods 
  
### Subjects 
  
This study included 15 right-handed probands with DSM-IV schizophrenia and 15 healthy control subjects matched for age, years of education, and verbal intelligence  . All study participants were female. The recruitment process and results for the control group were published previously in detail  . Patients were recruited from the Department of Psychiatry, University of Tübingen, Germany. All patients were acute or subacute inpatients, were native German speakers, had no other past or present medical illness, and had sufficient reading skills. All patients were on stable medication, mainly with atypical antipsychotics (mean dosis   516 (SD: 237) chlorpromazine equivalents). Among the 15 patients, four patients showed concretism. Among the 15 patients, four patients showed concretism. Schizotypal personality traits (SPQ total score) showed a range between 14 and 70 in patients (range 1–44 in controls  ). Further group characteristics are shown in  . 
   Clinical and sociodemographic characteristics of patient and control group.        

### Procedure 
  
The study was approved by the local ethical committee (University of Tuebingen, Germany). First, all subjects received complete information about the study and ability to consent was ensured in an interview with an experienced psychiatrist (A.R.). Afterwards, subjects underwent a practice session with stimuli not used in the experiment and provided written informed consent. Then, the subjects completed the schizotypal personality questionnaire (German version,  ) and underwent functional magnetic resonance imaging. During the fMRI scanning procedure, subjects lay supine in the MR-scanner, their head secured by foam rubber to minimize movement artefacts. Stimuli were presented as whole sentences visually on a translucent screen viewed by the subjects via a mirror. To reduce the difficulty of the task, the context scenarios were additionally presented acoustically using a tape-recorded version with a female voice. To avoid influences of an ironic tone of voice on brain activation  ,  , only visual presentation was used in the case of target sentences. During the scanning session, task instruction was to attend to the stimuli and assess if intention of the target sentences was ironic or not. However, to avoid effects of motor response on brain activation, no motor response was requested. Instead, subjects read all sentences silently and performed an attention task during which they pressed a button with their right index finger any time a particular picture appeared on the screen. Stimulus sequence was unforeseeable for the subject and optimised using optseq software (  http://surfer.nmr.mgh.harvard.edu/optseq/  ). 


### Experimental Stimuli 
  
A set of 56 German stimuli, each consisting of context scenarios and target sentences, was used in the experiment. Exact description of the stimuli and evaluation process was given previously  ,  . In brief, the context scenarios consisted of 2 sentences (8–12 words), each with 2 protagonists. The target sentences always consisted of 1 statement made by one of the protagonists and had, in the context, either an ironic or a literal meaning. The number of words and sentences, grammatical complexity, and word frequency were counterbalanced between literal, ironic, and meaningless context scenarios. Corresponding literal and ironic target sentences were identical. 


### Functional MRI Acquisition 
  
Imaging was performed on a 3-T Scanner (Siemens,TIM TRIO). Functional images were acquired with an echoplanar image sequence which is sensitive to BOLD-contrast (TE 40 ms, TR 2 s, 32 slices, slice thickness 3 mm, gap 1 mm, FoV 192×192 mm , pixel size 3×3 mm ). One run consisting of 390 volumes was acquired during the experiment. After the functional task, structural images of the whole brain were acquired using a T1-weighted MPRAGE sequence (TR 2200 ms, TI 900 ms, TE 2.92 ms, voxel size 1×1×1 mm ). 


### Data Analysis 
  
First level processing parameters for the imaging data were identical with  . For image processing and all statistical analysis, SPM5 (Wellcome Department of Imaging Neuroscience, London) was used. The functional images of each subject were slice time corrected to the middle slice and were corrected for motion and realigned by using the first scan of the block as reference. T1 anatomical images were coregistered to the mean of the functional scans and spatial normalized to the MNI space by the combined segmentation, bias correction and spatial normalization tool in SPM5. The calculated nonlinear transformation was applied to all functional images. Finally, the functional images were smoothed with an 8-mm full-width, half-maximum (FWHM) Gaussian filter. A general linear model (GLM) was constructed for each participant to analyze the hemodynamic response function. In each GLM, regressors were generated by convolving a box car function with the hemodynamic function. Separate regressors were used to model the hemodynamic responses during presentation of target textoids, ironic sentences, literal sentences and the visual baseline condition. Moreover, a high-pass filter (1/128 Hz) was applied to remove low-frequency drifts. 

For each subject, several T-Test contrasts were calculated separately for (1) the ironic target sentences (“irony”) and (2) literal target sentences (“literal”) conditions versus visual baseline and (3) ironic versus literal target sentences. Random effects analyses on group level were calculated for each of these contrasts. Then, between group comparisons were calculated for each of these contrasts using two sample T-Tests. 


### Effect of Psychopathology and Schizotypal Personality Traits on Brain Activation 
  
To investigate the influence of psychometric schizotypy and psychopathology on brain activation, simple regression analyses of SPM data were applied. In this type of analysis, each single voxel in the brain is individually examined with respect to whether the size of the BOLD response is correlated with a variable over subjects. 

Effects of schizotypal personality traits were calculated using the total score of the schizotypal personality questionnaire ( , German version  ) as regressor. These analyses were calculated for all participants together, following the rationale that schizotypal traits represent a continuum  ,  ,  . The result of this analysis is a brain map, which depicts the voxels with which there is a significant correlation between the variables. Because of the exploratory character of our pilot-study, we chose a liberal threshold of p<0.001 uncorrected and an extent threshold of 5 voxels for these analyses. In each analysis, separate tests were performed to detect positive correlation (that means the higher the score of the individual score of the study subject, the stronger the BOLD response) and negative correlation (the higher the score of the individual subject, the weaker the BOLD response) were calculated. 

Effects of psychopathological parameters were calculated within the schizophrenia group. Due to computer hardware failure, psychopathological data for 2 patients was lost. Therefore, regression analyses were performed using data from only 13 patients. In separate subanalyses, SAPS (positive symptoms,  ) total score, SANS (negative symptoms,  ) total score and SAPS formal thought disorder subscale were used as regressors. 


### Off-line Testing 
  
After fMRI, the subjects performed an off-line test to detect error rate. In this test, the subjects indicated by button press whether the target sentence has ironic, literal, or meaningless content  ,  . Subjects were seated in front of a computer screen. A total of 54 stimuli was used for this experiment (22 ironic and 22 literal textoids identical to the fMRI experiment, 10 textoids with similar structure and content followed by a nonsense statement by one of the two protagonists). The task was to indicate by pressing one out of three buttons whether the target sentence was in this context most likely ironic, literally meaningful, or meaningless. Afterwards, subjects completed a short test battery (verbal intelligence  , digit span  , subtest picture sequencing from the HAWIE-R intelligence test  ). Then, subjects were clinically assessed (by A.R.) using the SAPS  , SANS   and PANSS  . 



## Results 
  
Results of the attention task inside the MR scanner indicate good performance with no significant difference between patients and controls (mean error rate 0.1 errors in healthy controls, 0.8 errors in schizophrenia, p = 0.33). 

### Off-line Data 
  
Immediately after the fMRI session, subjects completed the off-line irony test. Off-line performance in the irony comprehension task showed substantial performance in both control subjects (mean 96.3% correct answers, SD 3.4) and schizophrenia (85.3% correct, SD 15.3), however with a significant difference (p = 0.02, ANOVA). A significant correlation was found between psychometric schizotypy (total score of the schizotypal personality questionaire) and and percentage of correct responses (r = −0.55, p = 0.004). 


### Brain Activation 
  
Main effects for reading priming sentences, ironic targets, and literal targets showed robust activations in a predominantly left lateralized network including visual cortices, temporal lobe, and prefrontal cortex in the study participants. 


### Differences between Control and Patient Group 
  
Results for differential contrasts between control subjects and schizophrenia patients are shown in  ,  ,   and  . 
   Group comparison healthy controls>schizophrenia for ironic>literal target sentences.  
p<0.001, ext. 5 voxels. Differences are present in the right hemisphere middle temporal gyrus, rolandic operculum and postcentral gyrus. The opposite contrast (patients>controls) showed no activated clusters. 
     Group comparison healthy controls>schizophrenia for ironic sentences>visual baseline.  
p<0.001, ext. 5 voxels. Strongest maxima in the posterior part of the anterior cingulate (ACC) and the LH anterior insula. See as well supplemental  . 
     Group comparison between healthy controls and schizophrenia. p<0.001, ext. 5 voxels.      
In brief, differential contrasts between ironic and literal target sentences showed diminished activation in right hemisphere temporal and parietal regions in schizophrenia. Further, during processing of ironic, but not literal, target sentences, BOLD response in schizophrenia was decreased in a network including the posterior medial prefrontal cortex (MNI maximum at −3 18 27, Brodmann area 32/24) and left hemisphere (LH) insula. In the reverse contrast (schizophrenia>controls) patients showed enhanced BOLD response in the posterior temporal lobe bilaterally ( ). Again, this difference was only detectable for ironic, but not literal target sentences. 


### Influence of Schizotypal Personality Traits on Brain Activation 
  
Influences of schizotypal personality traits, as measured with the total score of the SPQ   were calculated across all study participants. As positive and negative correlations indicate different processes, they were calculated separately. A negative correlation was found, that is the higher the degree of psychometric schizotypy, the lesser the BOLD response, in the posterior medial prefrontal cortex (anterior cingulate, MNI x, y, z: 3, 18, 33; z = 3.34) for reading ironic sentences>visual baseline in the same regions previously found underactivated in schizophrenia patients in the differential contrast ( ). Reading ironic sentences>visual baseline contrasts showed no positive correlation with the SPQ total score. Further, the contrasts for ironic>literal target sentences or literal sentences>visual baseline did not show significant correlations (neither positive nor negative). 
   negative correlation between BOLD response at MNI [−3 18 27] and SPQ total score.  
ACC activation in the cluster with strongest underactivation relative to controls (see  ) shows negative correlation with the schizotypal personality questionaire total score. Ironic sentences>visual baseline. For illustrative purposes, threshold of p<0.005, ext. 10 voxels are used. 
  
Results from further correlations between cognitive-perceptual and interpersonal subscales of the German schizotypal personality questionaire are shown in table S4. We could not investigate an association with the disorganised factor since, in contrast to the original version, the German version of the SPQ has no disorganised factor  ,  . Within the schizophrenia group, there was no significant correlation between the SPQ and PANSS   total score (r = 0,08; p = 0,79) or the global assessment of functioning score (r = −0,17; p = 0,58). 


### Influence of Psychopathology within the Patient Group 
  
Correlations with symptom dimensions within the patient group were detectable in both cerebral hemispheres are shown in  . 
   Correlation analysis between fMRI signal during irony comprehension and psychopathology dimensions.        


## Discussion 
  
We investigated the comprehension of ironic and literal text vignettes in female patients with schizophrenia by using event-related fMRI. In a prosody-free reading task, subjects processed text vignettes that ended in either a literal or an ironic statement made by one of the protagonists. As expected, we were able to detect robust differences between patients and subjects in a control group, which was matched for age and educational level (control group results previously published  ). Differences were detectable both for ironic versus literal, as well as for ironic sentences versus visual baseline, between the groups. However, no differences were detected for reading literal target sentences vs. visual baseline. This lack of difference is in line with a number of fMRI studies on literal language in schizophrenia  . 

In this pilot study, we had several hypotheses concerning the results, which were partially confirmed. Most investigations in healthy subjects (see  ), as well as those with brain lesions (see  ), indicate that both cerebral hemispheres are involved in the comprehension of ironic remarks. In healthy individuals, the contribution of the right hemisphere seems to be more prominent for irony than for literal language  ,  ,  ,  . Based on these and other studies, we hypothesised that impairment in irony comprehension in both schizophrenia and autism may be caused by right hemisphere dysfunction  ,  . However, our results have been mixed in terms of cerebral lateralization. Indeed, contrasts for ironic vs. literal ( ) indicate a deficit in the right cerebral hemisphere; however, contrasts between ironic target sentences vs. visual baseline and correlations with symptomatology ( ) indicate that the left hemisphere also contributes to the deficit. 

Our main hypothesis was that dysfunction of the brain’s frontotemporal language system may be crucial in the pathophysiology of the difficulties experienced by patients with schizophrenia in interpreting ironic remarks, and that schizotypal personality traits might mediate the magnitude of these difficulties. As expected, patients showed attenuated activation in the RH middle temporal gyrus ( ,  ). 

Moreover, BOLD response in the RH temporal lobe showed correlations with both positive and negative symptoms ( ). The right hemisphere temporal lobe is part of the brains semantic system  ,  . Our finding of decreased activation during a language task in schizophrenia therefore supports other evidence of impairment of this system in schizophrenia  ,  ,  . However, in contrast to our expectation  , and in contrast to other fMRI findings for figurative language in schizophrenia  ,  , there was no activation difference in the left inferior frontal gyrus. 

The cognitive model for delusions by Salvatore et al.  ,   assumes that ambiguous intersubjective interactions, such as ironic remarks, are relevant for the development of positive symptoms in schizophrenia and may be caused by mirror neuron dysfunction. The brain regions typically associated with mirror neurons are the ventral premotor cortex and the inferior parietal lobule  , and these regions did   not   show the most prominent differences between patients and controls in our study, although they are known to be involved in irony comprehension in healthy subjects  ,  . However, the human mirror neuron system may extend into other brains regions as well  . 

The most prominent differences between healthy controls and patients with schizophrenia have been found in the posterior medial prefrontal cortex, as well as the LH insula, RH middle temporal gyrus, and bilateral postcentral gyrus ( ). As hypothesised, medial prefrontal brain activation was attenuated in patients with schizophrenia ( ,  ). However, activation was localised more posterior than that suggested by the “classical” theory of mind regions  ,   in the dorsal part of the anterior cingulate and more posterior than activations found in previous studies on irony comprehension (see  ). This more posterior part of the anterior cingulate is thought to play a role in conflict monitoring and action monitoring   and in making judgements about the external world  . Therefore, activation in this part might represent a correlate of the difficulties of patients with schizophrenia to simulate the social situation during the decision process and to determine if a sentence is ironic or not. The medial prefrontal cortex is also ascribed the function to suppress the incorrect alternative literal meaning during comprehension of nonliteral stimuli  ,  , so attenuated activation in this area could possibly reflect the tendency of patients with schizophrenia to literally interpret nonliteral stimuli (“concretism”). 

In the present study, the degree of attenuation of the BOLD response in this region correlated with psychometric measures of schizotypy across all subjects, i.e., the higher the SPQ score, the lesser the BOLD response exhibited by the subject during the processing of ironic sentences, irrespective of diagnostic group. Thus, our results further strengthen previous assumptions of a continuum between schizotypal traits in nonclinical subjects and symptoms manifested in patients with schizophrenia  ,  . Our data are also compatible with previously made assumptions according to which the interaction between medial prefrontal and lateral temporal brain areas might be determined by the magnitude of schizotypy expression and other subclinical psychotic symptoms. For example, based on their research on schizotypy in nonclinical adolescent subjects, Lagioa et al.   suggested that schizotypy is associated with “inefficient connectivity” between medial prefrontal and language areas  . Similarly, Brent et al.   suggested, on the basis of fMRI research on subclinical psychotic symptoms in their nonclinical population, that “aberrant connectivity” between frontal and lateral temporal areas may play a role in the pathophysiology of psychosis. 

Another region found to be underactivated in schizophrenia was the LH insula. The insula is involved in perceptual decision making  ,  ,   and in the comprehension of irony   and other nonliteral stimuli in healthy subjects  ,  ,  . The insula shows structural and functional abnormalities in schizophrenia  . Underactivation of the insula in fMRI studies has been previously reported during social cognition tasks   and language comprehension on sentence level in schizophrenia  ,  ,  . 

Patients showed stronger BOLD response than controls in the left hemisphere parahippocampal gyrus. This region frequently shows activation during the comprehension of nonliteral stimuli, which could possibly represent ambiguity processing and analyzing/ascribing emotional connotation to nonliteral stimuli  . It could also represent “integrating context”  ,   or “recognizing the importance of social cues” during irony comprehension  . A growing body of evidence suggests that the parahippocampal gyrus may play a significant role in schizophrenia. For example, in fMRI studies, aberrant activation of the parahippocampal gyrus has been shown to be associated with positive symptoms in patients with schizophrenia  ,  ,  ,  . Rankin et al.   speculated that defective “top-down influence on the parahippocampal gyrus” from the dorsomedial prefrontal and insular cortex may play a role in the pathophysiology of defective sarcasm detection in neurodegenerative diseases, arguing that these brain regions are functionally interconnected. The same mechanism may also play a role in the pathophysiology of defective irony comprehension in schizophrenia, as we found impaired activation in the dorsomedial prefrontal cortex and insula, and increased activation in parahippocampal regions. 

### Limitations 
  
We are aware of several limitations in our study. First, the number of subjects is rather low, especially when considering that correlation analyses were performed. This gives our investigation more of the character of a pilot study. Future research is therefore needed to confirm the reliability of the findings in a larger sample. On the other hand, stable and replicable correlations with personality traits and psychopathology have been shown in studies with roughly the same number of subjects  ,  ,  . Furthermore, conference proceedings with data from an additional fMRI study on irony comprehension in schizophrenia confirm the underactivation of the insula in schizophrenia  . 

Affective connotation is a further limitation. In our task, ironic statements were predominantly negative. However, irony with positive connotations may have different neural correlates  . Furthermore, we studied only female individuals. This point is of possible importance because gender differences have been reported for irony comprehension  ,  . Furthermore, gender differences have been reported for schizotypy   and schizophrenia  . Future research is therefore encouraged to evaluate how irony comprehension in schizophrenia interacts with gender  . 

Previous fMRI studies have showed that irony comprehension may be related to motor cortex function. To avoid confounding with button press or motor response, our subjects had to indicate whether the sentence was ironic or not only in the offline task. Thus, we cannot be certain that subjects performed the task in the scanner correctly. Nevertheless, good performance in the attention task, the quality of movement parameters during the imaging session, and stable activation in the brain’s language system in each individual subject do indicate that subjects complied with the instructions. 

Several limitations relate to the nature of our irony comprehension task. Irony is a complex phenomenon and can have various linguistic forms. In our irony comprehension test, most stimuli characteristics were paralleled between ironic and literal text vignettes. In the target sentences, a protagonist made an ironic or literal statement. Our task was explicit (i.e., subjects were aware that ironic utterances may occur during the task), and ironic statements were made concerning others (not relating to the study participants). It is possible that patients with schizophrenia might show aberrant responses when dealing with issues pertaining to them personally, but this was not the case here. In a more general sense, it is very likely that social cognition in a real world setting might be different  ,  ,  . In interpersonal communication that is not in written form (which was used here), it is postulated that subjects include information from facial affect, prosody, larger context, information about the speaker, momentary affect, general world knowledge, and other factors when trying to decide whether a statement is ironic or not. All of these factors have been shown to undergo altered processing in schizophrenia, and aberrant activation of various brain regions has been confirmed in functional imaging studies in connection with most of these factors in patients with schizophrenia. Thus, it is obvious that our study represents only the beginning in this investigation, and future research must clarify how these other factors interrelate with schizophrenic psychopathology during irony appreciation. 



## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-10'>
<h2>10. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/30225341/' target='_blank'>30225341</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Motivation Modulates Brain Networks in Response to Faces Varying in Race and Status: A Multivariate Approach</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> eNeuro</p>
<p><strong>Publication Year:</strong> 2018</p>
<p><strong>DOI:</strong> 10.1523/ENEURO.0039-18.2018</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6140103/' target='_blank'>6140103</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study reports task-based fMRI in healthy adult participants (final N=60 male participants, mean age 23.8, within the 17–65 range) performing an explicitly social impression-formation task (forming impressions of faces varying by race and socioeconomic status). Analyses include whole-brain preprocessing and GLMs and a whole-brain multivariate behavioral PLS analysis (permutation/bootstrapping; voxelwise results reported and thresholded; clusters reported), not limited to ROI-only results. No clinical/psychiatric-only sample is used and healthy participant results are reported separately. Therefore it meets all inclusion criteria (social task, healthy adults, whole-brain analyses) and violates no exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Previous behavioral and neuroimaging work indicates that individuals who are externally motivated to respond without racial prejudice tend not to spontaneously regulate their prejudice and prefer to focus on nonracial attributes when evaluating others. This fMRI multivariate analysis used partial least squares analysis to examine the distributed neural processing of race and a relevant but ostensibly nonracial attribute (i.e., socioeconomic status) as a function of the perceiver’s external motivation. Sixty-one white male participants (  Homo sapiens  ) privately formed impressions of black and white male faces ascribed with high or low status. Across all conditions, greater external motivation was associated with reduced coactivation of brain regions believed to support emotion regulation (rostral anterior cingulate cortex), introspection (middle cingulate), and social cognition (temporal pole, medial prefrontal cortex). The reduced involvement of this network irrespective of target race and status suggests that external motivation is related to the participant’s overall approach to impression formation in an interracial context. The findings highlight the importance of examining network coactivation in understanding the role of external motivation in impression formation, among other interracial social processes. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (50096 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Significance Statement 
  
This multivariate fMRI analysis examined distributed neural processing as participants formed impressions of faces varying in race and status. Across all conditions, participants reporting greater external motivation to respond without racial prejudice showed reduced coactivation in brain regions believed to support emotion regulation, introspection, and social cognition. These results suggest that external motivation may calibrate how perceivers form impressions in an interracial context, irrespective of target race. The results from this analysis raise new questions that may not have readily emerged in studies relying on traditional behavioral and univariate fMRI analyses. 


## Introduction 
  
Race remains a contentious topic in the United States and around the world. Evaluations of others based on race and other features may depend on motivations to respond without prejudice ( ;  ). In contrast to individuals who intentionally cultivate a racially egalitarian self-concept (i.e., internally motivated), individuals who are motivated to avoid the social sanctions of expressing racial prejudice (i.e., externally motivated) can be especially uncomfortable when race is salient ( ;  ). These motivations are frequently assessed using the internal motivation scale (IMS) and the external motivation scale (EMS;  ). Potentially due to race-related discomfort ( ;  ), whites with high EMS scores typically engage in more effortful (albeit less efficient) self-regulation during intergroup interactions ( ;  ;  ;  ;  ;  ). High-EMS individuals also tend to avoid explicit mentions of race, focusing instead on nonracial categories or topics ( ;  ). In a recent fMRI study ( ), we examined neural responses to perceived race and socioeconomic status (SES) during impression formation as a function of white perceivers’ EMS scores. Findings from this original univariate analysis indicated that EMS modulated the processing of SES (but not race) in brain regions involved in person evaluation. To gain greater insight into this intriguing set of findings, we used a multivariate approach known as behavioral partial least squares (PLS) analysis ( ) to identify how brain networks may be modulated as a function of individual differences in perceiver motivation. 

In our original univariate analyses ( ), we found that EMS modulated responses to SES in the bilateral nucleus accumbens (NAcc) and ventromedial prefrontal cortex (VMPFC), consistent with the literature on status-based evaluations ( ,  ). Notably, high-EMS participants showed neural response patterns to SES that were difficult to reconcile with the largely positive evaluations of high SES (when considered independently of other dimensions) observed in the behavioral ( ;  ) and neuroimaging ( ,  ) literature. 

In the present analysis, we used behavioral PLS analysis to examine distributed neural responses to perceived race and SES as a function of white perceivers’ EMS scores. Behavioral PLS analysis is a data-driven method that allows for the identification of one or more latent variables (LVs) that reliably account for covariance between individual differences (e.g., EMS) and distributed patterns of neural responses to conditions of interest (e.g., targets varying in race and status;  ;  ;  ). Because this is a data-driven approach to brain–behavior correlations, behavioral PLS analysis allows for the identification of several potentially compatible LVs. One possibility is that brain–behavior correlations may differ qualitatively across conditions ( ). Based on our original analysis showing EMS-related modulation of neural responses to SES ( ), for example, EMS could correlate with increasing coactivation across a distributed network of brain regions when forming impressions of high-SES targets and with decreasing (or null) coactivation in a different network when forming impressions of low-SES targets. The converse is also possible. Although our original univariate analysis did not show a reliable relationship between EMS and localized neural responses to race (or the race-by-status interaction), it is nonetheless possible that EMS may predict distinct patterns of neural coactivation as a function of race in a multivariate analysis. For example, one study using multivoxel pattern analysis examined the neural representation of race in key regions of interest (ROIs) as white participants were assigned to one of two mixed-race groups and subsequently categorized members from both groups while in the scanner ( ). Although no effects of race were reported in the behavioral or univariate analyses, the authors did find that race was reliably decoded above chance in the visual cortex and the fusiform gyri but not in control regions (for a similar study using gender instead of race, see  ). This is particularly interesting because recent work has suggested that distributed neural responses to race are decoded more reliably in the fusiform gyri when race processing is incidental to the task (i.e., as in the present study) compared with when race processing is integral to the task ( ). A final possibility is that brain–behavior correlations are similar across all conditions ( ). In other words, EMS could increase or decrease the overall coactivation between brain regions irrespective of face race or SES, implying that EMS influences how participants approach the task overall. Although the data-driven nature of PLS analysis obviates the need to formalize a priori ROIs, we anticipated that any latent variables would likely implicate regions involved in person evaluation (VMPFC;  ;  ;  ;  ,  ) and the regulation of prejudice (e.g., cingulate cortex, lateral prefrontal cortex;  ;  ;  ). 


## Materials and Methods 
  
### Participants 
  
Eighty-two Chicago-area men passed the initial screening. Of the 82 eligible participants, 61 completed the study. The 21 eligible participants who did not complete the study either failed to complete the on-line battery of questionnaires or were unable to schedule a suitable time for the scanning session before achieving our intended quota for this study (  N   = 60). One participant was excluded from analyses as an outlier for IMS (a control variable), exceeding 3.5 SDs from the sample mean (see Results). The final sample comprised 60 male participants (mean age, 23.8 years; SD = 4.59 years). 


### Protocol 
  
#### On-line surveys 
  
Eligible participants completed a battery of questionnaires on-line before the day of their scan. Most of these measures were assessed for a large-scale resting-state fMRI investigation or an unrelated experiment completed immediately before the impression-formation task used for the present analysis. Although we provide an overview of pertinent measures for this report (see Experimental design and statistical analysis), full details are available in the open-access report from our previous analysis of the presented data ( ). 


#### Scanning session 
  
On the day of scanning, participants were instructed to arrive without having consumed drugs, including caffeine and alcohol. After signing consent and imaging center paperwork, the participant was photographed and completed brief surveys. Participants were then trained on the two tasks they would complete while in the scanner. The primary experimental task involved forming impressions of faces varying in race and ascribed status. An additional task, which served as a control task for the purpose of an analysis performed for the current study, involved explicitly rating (1) the attractiveness of a series of faces depicting white actors and models and (2) the likeability of a separate set of white actor faces based on their body of work. The faces of black actors and models were not used for this control task. 

Participants were first trained on the control task. They completed a practice block outside of the scanner in which they learned how they would be rating the actors and models while in the scanner. The practice block was a shortened version of the main experiment (one run with three blocks of 10 trials each), using actors and models that would not be presented in the scanner. After completing the full practice block for the control task, participants then learned about the main impression-formation task. The experimenter informed participants that the study investigated how people think of others varying in SES. SES was defined as follows: “Those who have the highest social status tend to have the most money, the most education, and the most respected jobs. Those who have the lowest social status tend to have the least money, the least education, and the least respected jobs or no job.” Following this definition, participants learned to associate colors with low- and high-status Americans (e.g., blue = low; orange = high). Status–color associations were counterbalanced across participants. 

To thoroughly learn status–color associations, participants completed simple association training blocks ( ;  ;  ). In an initial block of 10 trials, participants viewed a darkened silhouette over a colored background (i.e., orange or blue: five per status level), indicating by key press whether the silhouette was low status or high status based on the background color. Participants were informed of their cumulative accuracy on each trial (mean, 98.5%). Next, participants completed a block of 10 trials (5 per status level) in which they were asked what color represents low (or high) status. Participants were again informed of their cumulative accuracy on each trial (mean, 93.4%). 

Having learned the two status–color associations, participants briefly practiced the impression-formation task that they would complete while in the scanner (see Experimental design and statistical analysis). The experimenter first verbally confirmed that the participant learned the status–color associations and then explained that participants would no longer be categorizing targets as low or high in status for the impression-formation task. Instead, they would be forming quick overall impressions of male faces, taking into account all visually available information ( ). This was repeated for participants in the written instructions for the practice block of the impression-formation task. The procedure for the practice trial block was the same as the procedure reported for the experimental block. 

Once situated in the scanner, participants first completed two fMRI runs of the control task ( ). After this task, participants completed a brief task reminding them of the learned status–color associations and how to use the button box. All participants correctly recalled the status–color associations. After this reminder, participants completed two runs of the impression-formation task (each ∼4 min), followed by resting-state and anatomic scans, time permitting (total scan time, ∼1 h). On exiting the scanner, participants completed explicit stimuli ratings and judgments ( ). After this block of surveys, participants were compensated and debriefed. 


#### fMRI acquisition 
  
We used a Phillips dStream Achieva 3 T system and 32-channel head coil to acquire BOLD, T2* contrast-weighted echoplanar images (EPIs). With a 2000 ms repetition time and a 25 ms echo time, we acquired 34 oblique slices using an interleaved   z  -shim acquisition protocol ( ). Slices were 4 mm thick with a 0.5 mm gap, a 3 mm  in-plane resolution, 77° flip angle, and a 192 × 134 × 192 mm field of view. Slices were aligned to the anterior commissure–posterior commissure axis of each participant ( ). 



### Experimental design and statistical analysis 
  
#### Design and key measures 
  
The present analysis focuses on BOLD responses as participants formed impressions of targets varying in race and SES. We describe the impression-formation fMRI task design first, followed by the primary individual difference measures of EMS and IMS. 

##### Impression-formation task 
  
After a brief training session completed outside the scanner (see Protocol), participants learned to associate two colors with different status levels ( ). For example, blue conveyed high status, and orange conveyed low status. Status–color associations were counterbalanced across participants. 

The impression-formation task that participants completed during functional scanning adhered to a rapid event-related design ( ). Trials began with a black or white male face surrounded by a blue- or orange-colored frame over a black background. After 1500 ms, the face was replaced by a white fixation of a jittered duration (i.e., intertrial interval of 500, 2500, 4500, or 6500 ms). Participants formed a quick impression of each individual by the time the face disappeared or shortly thereafter. To signal they formed an impression, participants simultaneously pressed two keys, one per index finger. Participants were informed that their responses were not meant to indicate the content of their impressions, but merely to indicate that they had formed an impression. In each run of the impression-formation task, participants viewed 60 male faces divided evenly across conditions (for details on stimulus equating, see  ). Two reminder trials after the first and second thirds of the sequence required participants to identify the status level of a silhouette framed by either blue or orange. 

Faces from all four combinations of race (black, white) and status (low, high) were interspersed in a fixed pseudorandom sequence. To optimize fMRI design efficiency ( ), three fixed trial sequences were generated using optseq2 ( ). For further details on trial sequence design and optimization, see the study by  ). 


##### Control task 
  
The control task consisted of an event-related design with two functional runs. Full details on stimulus equating and counterbalancing have been reported (T.P.D., B.D.M., J.T.K., and J.C., unpublished observations). Images of actor faces and model faces were presented over two functional scans, with 30 unique white actors and 15 unique white models per functional scan. In each scan, participants rated half of the actors on attractiveness and the other half on the body of work. The models were rated only on their attractiveness. 

Before each block of the control task, participants viewed a prompt indicating the evaluative judgment and target group (e.g., How attractive are these models?). All trials began with a 1500 ms presentation of a face over a black background, followed by a 500 ms fixation. After 500 ms of fixation, the fixation cross changed from white to green, prompting participants to indicate their evaluation of the actor or model. Participants responded on a scale of 1 (very attractive/likable) to 4 (very unattractive/unlikable), with key mapping counterbalanced across participants. After 1000 ms, the green fixation changed back to white and remained for an additional 1000 ms. Jittering was implemented after each trial using 0, 2000, 4000, or 6000 ms fixations. 


##### Motivation to respond without racial prejudice 
  
This 10-item measure ( ) was administered on-line before the participant’s scheduled scan date. The EMS (Cronbach’s α = 0.874) included five items (e.g., “I try to act nonprejudiced toward black people because of pressure from others”). The IMS (Cronbach’s α = 0.764) also contained five items (e.g., “Being nonprejudiced toward black people is important to my self-concept”). Both motivations were measured on a 9 point scale from 1 = strongly disagree to 9 = strongly agree. EMS and IMS were uncorrelated in the final sample (  r   = 0.052,   p   = 0.694). Full details on the distributions of EMS and IMS are reported by  ). 


##### Postscan stimulus ratings 
  
Participants completed a measure of explicit likeability for each of the 60 male face stimuli viewed in the scanner during the impression-formation task. Faces were presented with the same status-associated colored backgrounds used in the scanner. Participants rated each face on a scale from 1 = extremely unlikeable to 9 = extremely likeable. 



#### Analyses of behavioral data 
  
For the sake of completeness, we report briefly on participants’ reaction times (RTs) during the impression-formation task, simultaneously testing whether reaction times show any relationship with EMS. Using a similar approach, we also explore whether EMS predicts postscan stimulus ratings of likeability. 

##### Reaction time analysis 
  
Because of device malfunctions, RTs were not recorded from four participants. Therefore, the RT analysis included only 56 participants. Any RTs <250 ms (<0.1% of all trials) and any trials where no response was provided (1.5% of all trials) were immediately excluded from analysis. We then subsequently trimmed any remaining RTs exceeding 3 SDs from the participant’s mean RT (0.4% of all trials). RTs were then log-transformed before analysis to reduce the natural skew of RT data. To test for effects in the speed of responses during the impression-formation task, we used a linear mixed-effects model in which log-transformed reaction times were predicted by target race, target status, and the participant’s EMS score. The model included a random intercept, all possible random slopes by participant, and all possible correlation parameters. 


##### Postscan likeability ratings and EMS 
  
Using a similar linear mixed-effects model, we analyzed postscan ratings of stimulus likeability as a function of target race, target status, and the participant’s EMS score. As in the analysis of RTs, the model included a random intercept, all possible random slopes by participant, and all possible correlation parameters. 



#### Analyses of fMRI data 
  
For the fMRI data, we first summarize the preprocessing parameters and GLM parameters as reported in the original univariate analysis of these data ( ). We then provide a detailed overview of the multivariate behavioral PLS analyses used in the present report. Additional supplemental analyses are also described. 

##### Preprocessing 
  
EPIs from each participant’s four runs (two per task) were preprocessed and analyzed at the first level using SPM8 (  www.fil.ion.ucl.ac.uk/spm  ), facilitated by a custom suite of scripts for fMRI analysis (  https://github.com/ddwagner/SPM8w  ). We first implemented slice-time correction ( ), using the 17th slice acquisition as the reference. Subsequently, we integrated the four repeated   z  -shim slices ( ). The resulting images from each participant were then unwarped and realigned to the participant’s mean EPI to correct for motion and motion-by-distortion interactions ( ). Images were subsequently normalized to the MNI template and smoothed with an 8 mm FWHM kernel ( ). 


##### GLM 
  
To estimate the BOLD responses for each condition, each trial was considered as an event, and the stimulus time series was convolved with the canonical hemodynamic response function. A GLM modeled scan sequences concatenated by task as a single session with regressors for each condition. For the race-status impression-formation task, we modeled four conditions (ordered as follows: high-status black, high-status white, low-status black, and low-status white). For the control task, we modeled three conditions (ordered as follows: attractiveness ratings for actors, body-of-work ratings for actors, and attractiveness ratings for models). For both task GLMs, regressors for the key conditions of interest were followed by regressors controlling for variance associated with: (1) reminder trials; (2) low-frequency drift (i.e., a linear trend); (3) session means (1 for scan 1, 0 for scan 2); (4) six movement parameters; (5) a constant across all scans; and (6) slow fluctuation of the signal (i.e., a standard set of harmonic regressors effectively serving as a 1/128 Hz high-pass filter). Contrast images reflecting the first-level effect of each condition versus baseline were used for PLS analyses ( ). 


##### Behavioral PLS analysis 
  
Behavioral PLS analysis is a data-driven method that allows for the identification of LVs that reliably account for covariance between individual differences on a behavioral measure (e.g., EMS) and one or more distributed patterns of neural responses to conditions of interest ( ). In other words, the goal of behavioral PLS analysis is to find weighted patterns (i.e., the LVs) characterized by maximal covariance between the behavioral and neural datasets. A description of this method given in considerable detail can be found in previous work ( ;  ;  ;  ). In this section, we first provide some detail on how the analysis is implemented followed by an overview of the benefits and limitations of behavioral PLS analysis. 


##### Analysis parameters 
  
In the present report, we use the same analysis procedure reported by   to examine the degree to which EMS predicts distributed neural responses to all conditions of interest in both the impression-formation and control tasks. To test the overall significance of each LV, a set of 2000 permuted samples was created by randomly reordering participants and condition labels (without replacement) in the voxelwise fMRI dataset, but conserving the original behavioral dataset (i.e., EMS scores). The same model used to generate the LV was subsequently applied to each permuted dataset, resulting in 2000 new covariance matrices. These covariance matrices embody the null hypothesis that there is no relationship between brain activity and behavioral data. Each covariance matrix was then subjected to singular value decomposition (SVD), resulting in a null distribution of singular values. The significance of the SVD of the original LV was ultimately assessed with respect to this null distribution. The   p   value was calculated as the proportion of the permuted singular values that exceeded the original singular value. For each significant LV, the reliability of brain–behavior correlations specific to each condition was tested using 95% confidence intervals ( ). These confidence intervals were generated using a 2000-sample bootstrapping test. Because the top and bottom bounds of the confidence intervals are derived from a bootstrap distribution, it is common for these bounds to be asymmetric relative to their corresponding estimates ( ). Indeed, when the underlying distribution is sufficiently skewed, it is possible for the correlation estimate to fall outside of its bootstrapped confidence interval. We report confidence intervals derived from the standard estimation procedure built into the PLS analysis toolbox (see   http://web.mit.edu/seven/src/PLS/Plscmd/pls_analysis.m  ). 
  
  A   , External motivation to respond without prejudice (EMS) emerged as a significant LV in behavioral PLS analysis. Brain–behavior correlations were similar across conditions.    B   , Patterns of whole-brain activity covarying with EMS are presented on lateral–anterior (left) and medial (right) views of the right hemisphere. All voxels with BSR ≥2.5 are displayed, irrespective of their respective cluster sizes. Note that the directionality of brain activity needs to be interpreted in conjunction with the plotted brain–behavior correlations in    A   . Increasingly positive BSRs in    B    indicate greater reliability of the negative brain–behavior correlations depicted in    A   . 
  
The reliability with which each voxel contributes to the LV (i.e., the “salience” of the voxel) was also determined with bootstrapping. A set of 2000 bootstrap samples was created by resampling participants (with replacement) within each condition. Each new covariance matrix was subjected to SVD as before, and the singular vector weights from the resampled data were used to build a sampling distribution of the voxel saliences from the original dataset. The purpose of a constructed bootstrapped sampling distribution is to determine the reliability of each salience; saliences that are highly dependent on which participants are included in the analysis will have wide distributions. A single index of reliability termed “bootstrap ratio” (BSR) is calculated by taking the ratio of the salience to its bootstrap estimated SE ( ). A BSR for a given voxel is large when the voxel makes a strong contribution to the LV and the bootstrap-estimated SE is stable across many resamplings. 

In the present study, voxel-specific BSR values were thresholded at the 95% confidence interval, corresponding to absolute BSR values exceeding 2.5. We used xjview (  http://www.alivelearn.net/xjview  ) to identify and report the clusters of ≥20 contiguous voxels showing BSRs at or above this threshold ( ,  ).
 
  
Results of behavioral PLS analysis using external motivation to respond without prejudice (EMS) 
      
Behavioral PLS analysis results from the supplemental analysis of the control task 
    

##### Benefits and limitations of PLS analysis 
  
Although other methods exist for examining changes in functional connectivity as a function of individual differences (e.g., psychophysical interaction, dynamic causal modeling), one of the primary advantages of behavioral PLS analysis relative to these methods is that behavioral PLS analysis maximizes coactivation at the whole-brain level without constraining analysis to correlations with a particular seed voxel or region ( ). Behavioral PLS analysis can result in differences in brain–behavior correlations across conditions ( ), albeit in a less subject-specific fashion than for more traditional analyses. This is because estimates for brain–behavior correlations are determined through a bootstrapping approach that collapses across participants. Therefore, behavioral PLS analysis can illustrate intercondition differences in at least two ways. First, confidence intervals for brain–behavior correlations in one or more conditions may contain zero. In this case, one can have little confidence that the condition containing zero in the confidence interval reliably contributes to the latent variable, unlike for the other conditions that do not contain zero in their confidence intervals. Second, confidence intervals across conditions may lie on opposite sides of zero. In this case, one can more strongly articulate a difference between conditions. Namely, conditions with positive (vs negative) brain–behavior correlations would be associated with opposite changes in coactivation in brain regions with large BSR values of the same sign (e.g., positive) as a function of the behavioral variable (e.g., EMS). 

Because behavioral PLS analysis is a data-driven approach, distributed neural responses that maximally covary with the behavioral data need not be condition specific as in the preceding examples. In fact, a significant LV could reflect neural responses that correlate with the behavioral data to a similar degree for all conditions ( ). In this case, supplemental analysis of a control task can provide additional information regarding the relative context specificity of brain–behavior correlations. For the present report, the control task served to determine whether the relationship between EMS and distributed neural coactivation in the impression-formation task, which systematically varies target race, would generalize to a different face evaluation task for which race is not a factor. Such generalization would suggest that findings from our analysis of interest (i.e., how EMS shapes neural coactivation when forming impressions of faces varying in race and status) are not task specific but rather are revealing of broader differences in the neural responses of individuals varying in EMS. 


##### Supplemental PLS analyses 
  
Because the EMS is thought to have different consequences depending on the perceiver’s IMS score ( ), we conducted a follow-up analysis that controlled for IMS by partialing out variance in the EMS accounted for by the IMS and using the residuals in behavioral PLS analysis. Because the mean IMS score was 7.64 (on a scale from 1 to 9), the original analyses of EMS assume a high-IMS participant sample. For all analyses, the pattern of findings was similar even after controlling for IMS. As noted here and in our previous work ( ), the limited range in IMS precludes the possibility of generalizing effects to individuals who are low in IMS (all participants scored above the midpoint of the scale). 

Finally, we also conducted a task PLS analysis of the fMRI data from the impression-formation task. Task PLS analysis differs in important ways from behavioral PLS analysis for which each LV represents (1) a correlation between an individual difference (e.g., EMS) and distributed neural activity across participants and (2) the spatial pattern of voxel activations that supports that profile. In task PLS analysis, each LV represents (1) differences between experimental conditions for each participant (interpreted as a contrast) and (2) the spatial pattern of voxel activity that supports that contrast. In other words, because task PLS analysis results in brain scores at the participant level, it allows for more formal tests of differences between conditions, albeit in the absence of any individual difference variables such as EMS. In the present analyses, we used task PLS analysis to test for latent variables accounting for the relationship between the 2 (race: black, white) × 2 (status: low, high) factorial design and distributed patterns of neural responses. The same permutation and bootstrapping parameters for behavioral PLS analyses were applied to the task PLS analysis. Because results failed to return any significant LV (all   p   > 0.11), we do not further report on the task PLS analysis. 




### Code accessibility 
  
Analyses of RT and postscan ratings were conducted in R ( ) using the lme4 ( ) and lmerTest ( ) packages. The code used to run preprocessing and GLM steps of the analysis was facilitated by SPM8 (  www.fil.ion.ucl.ac.uk/spm  ) and a custom suite of scripts for fMRI analysis (spm8w version r5236;   https://github.com/ddwagner/SPM8w  ). PLS analyses were conducted using a set of scripts based on an existing MATLAB-based PLS analysis toolbox (PLS Applications version 6.1311050:   http://pls.rotman-baycrest.on.ca/UserGuide.htm  ). All code used for analysis is available from the authors on request. Analyses were performed on a linux-based server (OS, Redhat Release 7) using Matlab 2012a. 



## Results 
  
### Reaction time data 
  
RTs were on average just under 1 s (mean RT = 977 ms; SD = 306 ms). Analyses revealed similar RTs irrespective of target race, target status, and EMS score. A marginal main effect of target status (  b   = 0.00673, SE = 0.00350, 95 CI% = [−0.000138, 0.0136],   t   = 1.920,   p   = 0.060) suggested a nonsignificant trend for faster responses when forming impressions of low-status (vs high-status) targets. All other effects were also nonsignificant (  p   > 0.24). 


### Postscan likeability ratings 
  
Postscan ratings of likeability revealed significant main effects of target race (  b   = 0.793, SE = 0.124, 95% CI = [0.550, 1.04],   t   = 6.385,   p   < 0.001) and target status (  b   = 0.413, SE = 0.106, 95% CI = [0.205, 0.621],   t   = 3.896,   p   < 0.001). These effects indicated greater likeability ratings for black (vs white) targets and high-status (vs low-status) targets, respectively. Consistent with the behavioral PLS analysis reported below, we observed a significant main effect of EMS (  b   = −0.175, SE = 0.0790, 95% CI = [−0.330, −0.020],   t   = −2.215,   p   = 0.031), with greater EMS scores associated with lower likeability ratings, irrespective of the race or status of the target. All other effects were nonsignificant (  p   > 0.19). 


### PLS analysis of the impression formation task 
  
Results revealed a significant effect of EMS as the first LV (  p   = 0.028), which explained 61.4% of the crossblock covariance. Across all conditions ( ), larger EMS scores were associated with reduced coactivation in regions that form part of the emotion regulation [rostral anterior cingulate cortex (rACC)], introspection [middle cingulate cortex (MCC)], and social cognition [dorsomedial frontal pole, dorsomedial prefrontal cortex (DMPFC), and temporal pole] networks ( ,  ). This relationship was not substantially impacted when controlling for IMS (first LV:   p   = 0.028, explaining 57.9% of crossblock covariance). Due to the similarity between these two analyses and the limited IMS variance in our high-IMS sample, all reported results are without controlling for IMS. Nonetheless, any differences that emerged between these two analyses are indicated in  . 


### PLS analysis of the control task 
  
Results revealed a significant effect of EMS as the first LV (  p   = 0.025), which explained 56.7% of the crossblock covariance. Notably, only the attractiveness conditions reliably contributed to the LV: model brain–behavior correlation = 0.4235, 95% CI = [0.4568, 0.7570]; actor brain–behavior correlation = 0.1466, 95% CI = [0.0740, 0.6331]. The confidence interval for ratings of actor likeability based on body of work contained zero: brain–behavior correlation = 0.0878, 95% CI = [−0.0025, 0.4718]. In the attractiveness conditions, larger EMS scores were associated with increased coactivation in a distributed network of regions largely localized to the visual cortex, cerebellum, and sensorimotor and lateral prefrontal areas ( ). Note that the directionality of this effect (i.e., EMS was associated with increased coactivation between brain regions) runs in the opposite direction to that observed in the impression-formation task (i.e., EMS was associated with decreased coactivation). 



## Discussion 
  
The present findings provided the first demonstration using PLS analysis that motivation can shape the recruitment of brain networks when forming impressions of others. Specifically, increasing EMS predicted reduced coactivation of regions involved in affect regulation (e.g., rACC), introspection (MCC), and social cognition (frontal pole, DMPFC, and temporal pole) when forming impressions of faces varying in race and social status. The components of the network emerging from the impression-formation task analysis are noteworthy in several respects. We discuss each set of regions separately in the following section. 

Notably, the supplemental analysis of the control task (i.e., explicit evaluations of white actors and models) provides some evidence that the negative relationship between EMS and coactivation in the aforementioned network of regions may be specific to social evaluations when race is a factor (i.e., as in the main impression-formation task). Although the supplemental analysis of the control task showed a positive relationship between EMS and coactivation of a network of regions that was distinct from the main task analysis, we nonetheless caution the reader that this difference may also reflect task differences other than the salience of race. For example, the main task involved privately forming impressions, whereas the control task required relatively more explicit and public ratings. 

Beyond providing insight into the potential neural underpinnings of EMS, the present findings are also noteworthy in that the network observed in the present analysis emerged in a relatively private context. Although previous work often indicates that high-EMS individuals are typically sensitive to experimental contexts in which they believe their responses are being monitored or will be made public ( ;  ;  ), the effects of the EMS are still observed even in a private context. For example, previous studies using both EEG ( ) and behavioral methods ( ) have also identified the effects of EMS on the endorsement/inhibition of stereotypes in private contexts. One possibility is that participants’ awareness that their brains were being scanned while forming impressions of black and white targets may have triggered externally motivated regulation (e.g., pipeline effects, see  ). Unfortunately, these present data do not allow us to directly test the extent to which external motivation was triggered by (erroneous) beliefs about scanners reading minds. It would be interesting in a future study to examine this possibility by scanning participants who have been deceived with information that individual preferences and tendencies can be inferred from brain data versus those who have been informed about the limitations of fMRI research. Informing participants during scanning that their responses will be private (vs made public) should have a similar effect. In summary, although the mechanism requires further study, our findings add to the existing behavioral and EEG literatures, suggesting that EMS may be associated with distinct neural underpinnings even when the central threat pertaining to EMS (i.e., the potential to be exposed as harboring racist tendencies) is minimized by the private nature of the impression-formation task. 

### rACC 
  
Although the present data do not directly speak to the relationship between rACC and affect regulation, the emergence of this region in the present analysis is interesting in light of earlier work that has more directly implicated the rACC (among other regions) in the regulation of negative affect ( ,  ) and prejudice ( ;  ;  ). The rACC and adjacent areas of the orbitofrontal cortex/VMPFC are thought to serve as a conduit for inhibitory signals from dorsomedial and lateral prefrontal regions en route to the amygdala ( ;  ;  ). Even in simple cognitive tasks, rACC is associated with enhanced processing of emotion-related stimuli ( ) and attempts to increase emotional responses to errors under low cognitive load ( ). In the context of race, the rACC has been implicated in the experience of guilt after learning about one’s own implicit prejudice. More specifically, in a high-IMS score sample, rACC activity to prejudice-indicative feedback increased as self-reported guilt decreased ( ), suggesting that the rACC may have been recruited spontaneously to downregulate the negative experience of guilt in the absence of an opportunity to effectively reduce their prejudice ( ). Such an interpretation is consistent with the recent suggestion that the rACC may play a special role in implicit emotion regulation—that is, regulation arising without conscious monitoring, immediate insight, or awareness ( ). 

As in previous work reporting multivariate analyses of race ( ;  ) and gender ( ) perception, response patterns differed from those we observed in our behavioral and univariate analyses ( ). Nonetheless, we note that the rACC region detected in the present PLS analysis overlaps partially with the medial prefrontal region detected in the whole-brain analysis of the same dataset ( ). This univariate analysis indicated that the overall larger response to high-status (vs low-status) targets reversed in high-EMS score individuals, specifically in a region involved in social evaluation (VMPFC, extending to rACC; compare with ROI analyses of VMPFC, NAcc, and amygdala). The brain–behavior correlations in   are consistent with this picture (i.e., indicating numerically larger decreases in coactivation in the rACC for high-status than for low-status targets. Together, these findings suggest that EMS score may be associated with changes in both the participant’s overall approach to the task (i.e., poorer coordination between key networks previously implicated in affect regulation, introspection, and social cognition) and the participant’s sensitivity to target attributes within the task (i.e., status level). Based on the partial anatomic overlap between the findings from these two complementary studies, it will be important to more closely examine the degree to which rACC may play a unique role in supporting both task-general and target-specific effects of motivation. We believe that a multianalysis approach such as the one used for the present dataset should guide such future investigations. 


### MCC 
  
In addition to the rACC, the MCC was also part of the overall network that decreased in coactivation as a function of EMS. Although the MCC is perhaps less frequently implicated in studies on motivation or affect regulation, several studies have tied activity in this region to introspection about one’s own internal states ( ;  ;  ) or unpleasant emotions ( ). In the present study, we observed decreased coordination between this region and areas previously implicated in affect regulation and social cognition as a function of increased EMS. On the basis of this finding, we speculate that increasing awareness of one’s own negative internal states (vis-à-vis neural substrates in the MCC) may play an important role in circumventing the regulatory difficulties experienced by high-EMS score individuals in an interracial context (see  ). In any case, the present finding highlights the MCC as an important ROI in future work on external motivation to respond without racial prejudice. 


### DMPFC and frontal/temporal poles 
  
Beyond the cingulate cortex, EMS was associated with diminished coactivation in regions previously implicated in social cognition, such as the medial prefrontal cortex (frontal pole and DMPFC) and temporal pole. In general, these regions often emerge in studies of impression formation and mentalizing ( ). The frontal pole in particular is thought to support recently evolved aspects of social cognition including the planning and monitoring of goal-directed actions ( ;  ). Recent work illustrates that the frontal pole can be divided into cytoarchitectonically and functionally distinct subregions. Meta-analyses have linked the dorsomedial subregion of the frontal pole (corresponding to the frontopolar region observed in the present study) to affective and social cognitive tasks ( ;  ). For example, this region appears to be sensitive to reputational outcomes for the self and close others ( ). In addition, analyses of functional connectivity have revealed that the dorsomedial frontal pole is functionally connected with a number of other key regions observed in this PLS analysis, including lateral temporal cortex, rACC, and middle/posterior cingulate cortex ( ;  ). 

In addition to the cingulate cortex and frontal pole, we also observed EMS-related decreases in coactivation between the DMPFC and temporal pole. Previous work has implicated these regions in general impression formation ( ;  ;  , ;  ) and the representation of evaluative and/or stereotypic person knowledge ( ;  ;  ), respectively. The EMS-related coactivation between DMPFC and the temporal pole (in addition to the rACC) overlaps considerably with the results observed in a recent study on race-based impression formation in the presence of evaluation-relevant person knowledge ( ). In that study, diminished activity was observed in the DMPFC, temporal pole, and rACC as high-IMS (vs low-IMS) participants formed impressions of black and white targets paired with evaluatively incongruent traits (i.e., positive and negative traits, respectively). This finding suggests that high-IMS (vs. low-IMS) individuals may be less sensitive to evaluative incongruence, resulting in diminished recruitment of regions involved in (affect-related) conflict regulation and impression formation. Notably, the present analysis indicates that these same regions (DMPFC, temporal pole, and rACC, among others) nonetheless exhibit sustained coactivation as high-IMS individuals form impressions of targets varying in race and other attributes (i.e., status). However, this coactivation between regions involved in emotion regulation and social cognition is diminished in individuals with higher levels of EMS. Together, the relationship between EMS and diminished coactivation in this social-cognitive network (in addition to regions involved in affect regulation and introspection) raises the possibility that high-EMS individuals may have been less engaged with the impression-formation task overall, despite also reporting high IMS. Future work is needed to more directly examine the relationships among coactivation in this network, task engagement, and potential mediators, such as negative affect arising from external concerns about implicit evaluative bias. 


### Relevance to the neuroscience of prejudice 
  
Previous neuroimaging work has implicated the frontal control network (including the ACC) in the regulation of prejudice in paradigms ranging from race-irrelevant spatial location tasks ( ;  ) to race-related fear learning ( ) and measures of implicit bias ( ;  ). In recent reviews, the ACC [i.e., dorsal ACC (dACC)] is typically considered to reflect monitoring for conflicts between internal desires to be egalitarian and an undesirable propensity for stereotypic or prejudiced responses ( ;  ;  ;  ). It bears mentioning that cingulate activity in the present analysis was localized to the rACC and the MCC. Although previous work on the neural substrates of prejudice regulation has focused primarily on the dACC, some have suggested on the basis of evidence from event-related potentials (ERPs) that rACC may be recruited to monitor for conflicts with external cues such as egalitarian norms ( ;  ). This possibility is consistent with the present finding that EMS (i.e., an external motivation) affected coactivation in a relatively rostral aspect of the ACC. 

Although this is one of the first fMRI studies to examine the effects of EMS on impression formation (but see  ;  ), previous work relying primarily on ERPs has long suggested that the ACC may be sensitive to perceiver motivations to respond without prejudice. Specifically, high-IMS individuals are thought to exhibit amplified conflict monitoring when race is salient ( ,  ), even when not explicitly instructed to control their racial bias ( ). Even at high levels of IMS, increasing EMS has been observed to diminish control-related ERPs, ultimately resulting in poorer regulation of racial prejudice ( ). This is consistent with the present observation (also in a high-IMS sample) that EMS reduced overall coactivation between a collection of regions previously implicated in both affect regulation (rACC) and social cognition (frontal pole, DMPFC, and temporal pole). 

Finally, it is imperative to note that the present study did not involve any revelations of prejudice; nor did it directly assess the regulation of negative affect. For this reason, it is difficult to determine what mechanism is mediating the effects of EMS on neural coactivation. Exploratory analyses of postscan stimulus ratings indicated a significant negative relationship between EMS and ratings of target likeability irrespective of target race or status, providing indirect support for the notion that high-EMS participants may be less predisposed to like others in the context of this interracial impression-formation task. The reason for this decline in likeability ratings as a function of EMS is unclear. It is possible that forming impressions of any individual in an interracial context is particularly uncomfortable for individuals with high EMS scores ( ;  ;  ;  ), resulting in lower overall likeability ratings. In summary, it will be important for future work to examine additional behavioral correlates of EMS to triangulate more precisely what psychological mechanism underlies the relationship between individual differences in EMS and the pattern of neural coactivation observed in the present study. Consistent with existing evidence that high EMS affects neural control mechanisms in participants concerned about appearing prejudiced ( ;  ), one possibility is that externally motivated concerns (e.g., about the scanner detecting one’s prejudice) may have diminished effective regulation of negative affect arising from conflicts between racial/class bias and intentions to form unbiased impressions ( ;  ). Alternatively, EMS may be associated with a diminished awareness of and/or propensity to regulate negative affect in the first instance. Further research is needed to differentiate between these and other possibilities. 


### Conclusion 
  
Using PLS analysis, we found that EMS diminished coactivation between brain networks previously implicated in affect regulation, introspection, and social cognition as high-IMS white perceivers formed impressions of targets varying in race and status. Notably, this EMS score-related decrease in coactivation was observed in all conditions, suggesting that EMS was associated with the way participants approached the impression-formation task as a whole rather than their responses to attributes of the targets, such as status (but compare with  ). The emergence of the rACC in the present analysis is noteworthy in light of previous work that has more directly examined the role of this region in prejudice regulation ( ;  ;  ). Moreover, together with the previous univariate analysis of the same dataset ( ), the present analysis suggests that the rACC may uniquely contribute to both task-specific and target-specific effects of motivation to respond without racial prejudice. Finally, the current findings also raise new questions regarding the relationship between self-reported levels of EMS and the psychological and neural mechanisms of prejudice regulation. 

In conclusion, the present PLS analysis provides insight above and beyond what was previously obtained using univariate analysis ( ), suggesting that EMS leads to decreases in coactivation in regions previously implicated in emotion regulation, introspection, and social cognition. Although the precise mechanism underlying this EMS-related decrease in coactivation across this network requires further study, we believe that this network and multivariate approach will be a fruitful starting point for research into the neural substrates of previously established relationships among EMS, race-related discomfort ( ;  ;  ;  ), and prejudice regulation ( ;  ;  ;  ;  ;  ;  ). 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-11'>
<h2>11. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/30834300/' target='_blank'>30834300</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> What Makes Eye Contact Special? Neural Substrates of On-Line Mutual Eye-Gaze: A Hyperscanning fMRI Study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> eNeuro</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1523/ENEURO.0284-18.2019</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6397949/' target='_blank'>6397949</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social processing (real-time mutual eye contact/mutual gaze) in healthy adults (final analyzed sample: 30–32 healthy participants, mean age ~21.7). The task is explicitly social/communication-related (eye contact, shared attention). Analyses include whole-brain voxelwise GLM contrasts (LIVE > REPLAY) with cluster-level FWE correction, nonparametric permutation validation (SnPM), whole-brain seed-to-voxel gPPI, and voxel-to-voxel interbrain synchronization across the entire brain — i.e., whole-brain results are reported rather than only ROIs. No clinical or patient-only groups are reported; healthy participant results are reported separately. Therefore all inclusion criteria are met and no exclusion criteria are triggered.</p>
<p><strong>Fulltext Confidence:</strong> 0.96</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>   Visual Abstract  
  
  
Automatic mimicry is a critical element of social interaction. A salient type of automatic mimicry is eye contact characterized by sharing of affective and mental states among individuals. We conducted a hyperscanning functional magnetic resonance imaging study involving on-line (LIVE) and delayed off-line (REPLAY) conditions to test our hypothesis that recurrent interaction through eye contact activates the limbic mirror system, including the anterior cingulate cortex (ACC) and anterior insular cortex (AIC), both of which are critical for self-awareness. Sixteen pairs of human adults participated in the experiment. Given that an eye-blink represents an individual’s attentional window toward the partner, we analyzed pairwise time-series data for eye-blinks. We used multivariate autoregression analysis to calculate the noise contribution ratio (NCR) as an index of how a participant’s directional attention was influenced by that of their partner. NCR was greater in the LIVE than in the REPLAY condition, indicating mutual perceptual–motor interaction during real-time eye contact. Relative to the REPLAY condition, the LIVE condition was associated with greater activation in the left cerebellar hemisphere, vermis, and ACC, accompanied by enhanced functional connectivity between ACC and right AIC. Given the roles of the cerebellum in sensorimotor prediction and ACC in movement initiation, ACC–cerebellar activation may represent their involvement in modulating visual input related to the partner’s movement, which may, in turn, involve the limbic mirror system. Our findings indicate that mutual interaction during eye contact is mediated by the cerebellum and limbic mirror system. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (52963 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Significance Statement 
  
Eye contact is a key element that connects humans during social communication. We focused on a previously unaddressed characteristic of eye contact: real-time mutual interaction as a form of automatic mimicry. Our results indicate that real-time interaction during eye contact is mediated by the cerebellum and limbic mirror system. These findings underscore the importance of the mirror system and cerebellum in real-time unconscious social interaction. 


## Introduction 
  
Automatic mimicry refers to unconscious or automatic imitation of movement ( ). It is a critical part of human social interaction because it is closely tied to the formation of relationships and feeling of empathy ( ). Automatic mimicry occurs when two or more individuals engage in the same behavior within a short window of time (e.g., facial expressions, body postures, laughter, yawning;  ). Automatic mimicry induces synchronous behavior through recurrent interaction ( ), thereby enabling spontaneous synchronization (e.g., clapping) and goal-directed cooperation ( ). 

Eye contact is one of the most salient types of automatic mimicry, as two people must be able to synchronize their eye movements to make eye contact ( ). Eye gaze provides a communicative signal that transfers information regarding emotional and mental states ( ). Eye contact, or mutual gaze, conveys the message, “I am attending to you,” thereby promoting effective communication and enhancing social interaction ( ;  ). 

Recent functional magnetic resonance imaging (fMRI) studies have revealed that eye contact activates the social brain, including the fusiform gyrus ( ;  ;  ), anterior superior temporal gyri ( ;  ), posterior superior temporal gyri ( ;  ;  ), medial prefrontal cortex ( ;  ;  ;  ), orbitofrontal cortex ( ;  ), and amygdala ( ;  ;  ; for review, see  ). The above-mentioned studies were conducted using single-participant fMRI data, contrasting the neural activation elicited by an eye-contact event with that elicited by an eye-aversion event. However, neural substrates underlying recurrent interaction during eye contact that result in the development of shared, pair-specific psychological states (e.g., attention and emotion) remain unknown. 

The mirror neuron system plays a role during mutual interaction through joint attention ( ;  ). The existence of two main networks with mirror properties has been demonstrated, with one residing in the parietal lobe and premotor cortex plus caudal part of the inferior frontal gyrus (parietofrontal mirror system), and the other formed by the insula and anterior medial frontal cortex (limbic mirror system;  ). The parietofrontal mirror system is involved in recognizing voluntary behavior, while the limbic mirror system is devoted to recognizing affective behavior ( ). We hypothesized that mutual interaction involving eye contact activates the limbic mirror system. 

This study aimed to elucidate the behavioral and neural representations of mutual interaction during eye contact using hyperscanning fMRI ( ). The neural activity associated with real-time eye contact was compared with that of non-real-time eye contact using a double-video system ( ). Eye contact is characterized by a two-way, behavioral stimulus-to-brain coupling, such that the behavior of a partner is coupled to the activation in the brain of the other ( ). Thus, face-to-face interaction through eye contact can be regarded as a mirrored reactive–predictive controller system consisting of two controllers ( ). We used eye-blink as a behavioral index of mutual exchange of communicative cues between two participants during eye contact. As the blinks of others can be easily recognized due to their relatively long duration (200–400 ms;  ), eye-blinks can provide social communication cues ( ). Further, blink rates change with internal states such as arousal, emotion, and cognitive load ( ;  ;  ). Finally, the timing of eye-blinks is associated with implicit ( ) and explicit ( ) attentional pauses in task content.   observed that eye-blinks of a listener and speaker were synchronized during face-to-face conversations, and concluded that eye-blinks define the attentional temporal window and that its synchronization reflects smooth communication between interactants through sharing of attention in the temporal domain. In this study, we used hyperscanning fMRI to analyze brain activation related to eye-blinks using the following different measures: activation, modulation of functional connectivity, and interbrain synchronization. 


## Materials and Methods 
  
### Participants 
  
Thirty-four volunteers participated in the experiment (20 men, 14 women; mean age ± SD, 21.8 ± 2.12 years). Participant pairs were determined before the experiment and consisted of participants of the same sex. None of the participants had met each other before the experiment. All participants except one were right handed, as evidenced by the Edinburgh Handedness Inventory ( ). None of the participants had a history of neurologic or psychiatric illness. The protocol was approved by the ethics committee of the National Institute for Physiological Sciences. The study was conducted in compliance with the national legislation and the Code of Ethical Principles for Medical Research Involving Human Subjects of the World Medical Association (Declaration of Helsinki). All participants provided written informed consent before the experiment. 


### Design and Procedure 
  
#### Experimental setup 
  
To measure neural activation during the on-line exchange of eye signals between pairs of participants, we used a hyperscanning paradigm with two MRI scanners (Magnetom Verio 3T, Siemens) installed side-by-side in parallel, sharing one control room and a triggering system ( ;  ). The top component of the standard 32-channel coil was replaced by a small four-channel flex coil (Siemens) attached with a special holding fixture (Takashima Seisakusho;  ;  ) to fully visualize the eye region. On-line grayscale video cameras were used during scanning to identify reciprocal face-to-face interaction (NAC Image Technology). The cameras captured images of each participant’s face, including the eyes and eyebrows. The captured images were in turn projected using a liquid crystal display projector (CP-SX12000J, Hitachi) onto a half-transparent screen that stood behind the scanner bed. The captured images were also entered into the picture delay system (VM-800, Sugioka System), which could output video delayed by an arbitrary amount of time. For analysis, video pictures used in the experiment were transferred to a video recording system (Panasonic). We recorded facial movement in AVI (audio video interleave) format (640 × 480 pixels, 30 frames/s). While the exact values varied depending on the participant’s head size, the screen stood ∼190 cm from the participants’ eyes, and the stimuli were presented at a visual angle of 13.06° × 10.45°. The delay between the capture and projection of the participants’ face was controlled using a hardware device (VM-800, Ito Co., Ltd.) connected between the video camera and projector. The delay was set at 20 s for the REPLAY condition and 0 s for the LIVE condition. The intrinsic delay of the on-line video system in this experimental setup was ∼100 ms. 


#### Experimental conditions 
  
We adopted a conventional blocked design for this study. Each run included three conditions: LIVE, REPLAY, and REST. During the LIVE condition, participants were presented with a live video of their partner’s face in real time ( ), allowing for the on-line exchange of information between the two participants. We instructed participants to gaze into the right or left eye of their partners and think about their partner as follows: what he/she is thinking about, what is his/her personality, how he/she is feeling. The participants were instructed not to exhibit explicit facial expressions such as laughing or grimacing. We also informed them that we will stop MRI scanning if they were not gazing into the partner’s eyes for an extended period of time. The REPLAY condition was identical to the LIVE condition, except that the participant watched a video picture of their partner’s face presented at a delay of 20 s. Therefore, there was no real-time interaction between the participants ( ). During the REPLAY condition, the participant was informed that all the videos they were watching represented their partner’s face in real time. During the REST condition (baseline), participants were required to gaze at the blank screen ( ). Although we monitored the participants to ensure that they do not fall asleep, two participants fell asleep during the experiment, and we had to restart the experiment after a short break. 
  
Experimental setup.    A   , LIVE condition: the face of Participant 1 is projected on the screen of Participant 2 in real time and vice versa, allowing a mutual exchange of information.    B   , REPLAY condition: the picture is projected on the screen with a 20 s delay; therefore, there is no mutual interaction between participants in real time.    C   , REST condition (baseline): no image is presented on the black screen.    D   , Sequence of presentation of the experimental conditions. 
  
Before starting the run, a live video of the partner was presented on the screen to confirm that an interactive partner was in the other scanner. Following confirmation, the video was turned off. The first run began with the REST condition for 30 s, followed by the LIVE, REPLAY, and REST conditions for 20 s each. After each 20 s presentation of the partner’s face, the screen was turned off for 1 s, and the condition was switched (e.g., from LIVE to REPLAY, REPLAY to REST;  ). The 1 s interval was designed to prevent participants from becoming aware of the difference between the LIVE and REPLAY conditions. The order of presenting the conditions was pseudorandomized. The conditions were switched manually during the fMRI run according to a predefined experimental design. Each run consisted of eight LIVE and eight REPLAY conditions. The total length of each run was 8 min and 30 s, and the entire scan consisted of four runs. Throughout the experiment, none of the participants exhibited any sudden display of emotions such as laughter. 

An interview following the experiment revealed that only one female pair realized that a delayed facial picture was presented in one of the conditions during the experiment; thus, the requirements of the experiment were not fulfilled in the pair. Data were analyzed from the remaining 32 participants (20 men, 12 women; mean ± SD age, 21.8 ± 2.03 years). 


#### MRI data acquisition 
  
Brain activation data were acquired using interleaved T2*-weighted, gradient echo, echoplanar imaging (EPI) sequences. Volumes consisted of 60 axial slices, each 2.0 mm thick with a 0.5 mm gap, covering the entire cerebral cortex and cerebellum. The time interval between two successive acquisitions of the same image [repetition time (TR)] was 1000 ms, with a flip angle of 80° and echo time (TE) of 30 ms. The field of view (FOV) was 192 mm, and the in-plane matrix size was 64 × 64 pixels. We used the multiband accelerated sequence developed at the University of Minnesota ( ), with the multiband factor set to 6. Thus, 510 volumes (8 min and 30 s) were collected for each run. For anatomic reference, T1-weighted high-resolution images were obtained using a three-dimensional magnetization-prepared rapid acquisition gradient echo (MPRAGE) sequence (TR = 1800 ms; TE = 2.97 ms; FA = 9°; FOV = 256 mm; voxel dimensions = 1 × 1 × 1 mm ) and a full 32-channel phased array coil. 



### Data analysis 
  
#### Behavioral data analysis 
  
##### Extraction of eye-blink time series 
  
Eye-blink was chosen as a behavioral index of interaction during mutual gaze ( ). We calculated the “motion energy” using the AVI video of the participant’s face during the task ( ) to evaluate the time series of eye-blinks. Due to technical difficulties with the video recording system, data from two pairs were unavailable. In total, video data of faces from 14 pairs (18 men, 10 women; mean ± SD age, 21.8 ± 2.17 years) were subjected to the analysis described below. 

 illustrates the procedure used to calculate the motion energy time series representing eye-blinks. First, the spatial window (400 × 100 pixels) of the AVI video was manually set to cover the eye area of each participant. Second, using the pixel intensity of the defined eye area, we obtained the motion energy index, which can detect the occurrence of motion only from a series of pictures ( ). The first-order difference in picture intensity was calculated frame by frame in each pixel, and the average of the absolute value of differences in each frame was calculated. This process was used to obtain motion energy values at specific time points. The calculation was repeated to obtain the motion energy time series reflecting eye-blinks during each run. Third, we divided the time series in each run into shorter subsections corresponding to the LIVE, REPLAY, and REST conditions. Although each condition lasted 20 s ( ), we analyzed only the final 15 s of each condition to minimize the effect of brightness instability (largely due to the procedure for switching conditions). We obtained eight time series for each condition of a single run. As each participant underwent four runs, 32 time series were obtained for each condition per participant. Finally, the effect of the linear trend in the data was removed using the “detrend” function implemented in MATLAB. The whole procedure was performed using a MATLAB script (MATLAB 14, MathWorks) developed in-house. 
  
Evaluation of the motion energy time series representing eye-blinks. The red dots indicate the timing of the detected eye-blink. 
  

##### Number of eye-blinks 
  
To determine whether the number of eye-blinks itself was influenced by differences in the type of task, we calculated the number of eye-blinks in the LIVE, REPLAY, and REST conditions using the extracted time series of motion energy. We first adapted the peak-detection function implemented in MATLAB, which automatically detected and marked the time point at which the eye-blink appeared to occur ( ). Next, we visually examined whether the detected time point was acceptable. Finally, we calculated the average number of eye-blinks in 1 block (  15   s) for each participant. All calculations were performed using a MATLAB script (MATLAB 2014) developed in-house. 


##### Causality analysis between eye-blink time series 
  
Several hyperscanning studies have used synchronization or correlation as an index of interaction ( ), neither of which can evaluate the directional effect. In this study, we used an Akaike causality model ( ;  ), which can delineate the causal direction and quantify its effect. The Akaike causality model uses a multivariate autoregressive (MVAR) model under the steady-state assumption and can quantify the proportion of the power-spectral density of an observed variable from the independent noise of another variable. The quantified causality, that is, the noise contribution ratio (NCR) index, is regarded as a measure of how one variable is influenced by another. In this study, we assumed that the eye-blink time series satisfies a steady-state assumption at least in one block. The NCR values were calculated as follows. 

First, an MVAR model was applied to a pair of time-series data,   x  (  t  ) and   y  (  t  ), using the linear sum of the history of the two time series, as follows: where the time series   and   correspond to the time series of the participant’s eye-blinks and that of the partner, respectively. In these equations,  ,  ,  , and   indicate AR coefficients, while   and   indicate the residual noise in the eye-blinks of the participant and partner, respectively. The AR order   N   defines the duration of the history. For each pair of time-series data, the AR order   N   was estimated to minimize the Akaike information criterion in the range from 1 to 10. Next, we estimated the power spectrum of the two time series based on the sum of the contributions of the   x  -specific noise (i.e.,  ) and   y  -specific noise (i.e.,  ). Here,   and   are frequency response functions, derived from Fourier transformation via an impulse response function, using a set of AR coefficients, while   and   indicate the variance of residual noise   and  , respectively. The  , an index reflecting how the participant’s eye-blinks   are influenced by the partner’s eye-blinks  , was calculated from the ratio of part of the spectral density of   contributed by   to the total spectral density of   at frequency   f  . Therefore,   can be expressed as follows: 

To assess how   is influenced by   across the whole frequency range, we mathematically integrated   NCR   values via trapezoidal numerical integration as follows: where   f   is the sampling frequency of the time series   and  . In this study,   f   was 30 Hz, based on the frame rate of the video data. We collected 32 time series for each condition. Therefore, our calculations yielded 32 ΣNCR values for each condition per participant. These 32 ΣNCR values were averaged to calculate one summarized ΣNCR value for each participant in each condition. Using the summarized ΣNCR, we applied statistical analyses to determine whether the influence of the partner differed between conditions. The entire procedure was performed using a MATLAB script (MATLAB 2014) written in-house. 

In this study, we calculated four ΣNCR values to assess how a participant’s eye-blink was influenced by that of the partner. Firstly, in the REST condition, participants could see nothing on the screen. Therefore, the ΣNCR value in the REST condition (i.e.  ) was regarded as a baseline of causal relationship. In the LIVE condition, the face of one participant was immediately projected on the screen, and the partner was able to see the face in real time. In this condition, we calculated ΣNCR between two participants’ time series (i.e.,  ).　The ΣNCR value represents how participants influence their partners when they mutually interact with each other in real time. Next, in the REPLAY condition, two types of causality were calculated as follows: first, the ΣNCR value between actual eye-blinks, like in the LIVE condition (i.e.,  ); and second, the ΣNCR value in the REPLAY condition representing how the eye-blinks projected on the screen has an influence on the actual eye-blink time series,  . While it is possible that a participant’s face receives influence from the delayed picture on the screen ( ), influence from an actual eye-blink to the screen (reverse influence) is theoretically absent. We also calculated the ΣNCR value (i.e.,  ). It represents how participants are influenced by a video picture, while there could be only unidirectional influence from the screen to actual eye-blinks. 


##### Estimation of statistical inferences and data visualization 
  
All statistical inference estimation for the behavioral data analysis was performed using R (RRID:  SCR_001905  ). We analyzed three types of behavioral measures. (1) The number of eye-blinks is highly influenced by the degree of attention ( ;  ;  ;  ;  ) and could reflect the differences across conditions. We tested the number of eye-blinks in three conditions using repeated-measures analysis of variance (ANOVA). (2) ΣNCR values: we have four ΣNCR values for each participant,   in the REST condition,   and   in the REPLAY condition, and   in the LIVE condition. The differences between them were assessed using repeated-measures ANOVA. (3) Enhanced ΣNCR values: in the REST condition, participants know there is no interaction with a partner as nothing is projected on the screen. Therefore, theoretically speaking, the REST condition could be regarded as a baseline condition. We calculated the increase in ΣNCR values (enhancement) by subtracting the   value from each of the ΣNCR values. Thus, we have three enhanced ΣNCR values for each participant:   and  . Repeated-measures ANOVA was used to test the differences between these values. In all ANOVA procedures, the effect size was measured using the generalized η  value ( ). In the   post hoc   pairwise analysis, estimated   p   values were adjusted using a Bonferroni correction. The confidence levels for   post hoc   pairwise analyses were calculated via the pairwise confidence intervals of  . The details of the statistical methods used in this behavioral data analysis are listed in  . All the graphs were prepared using the RainCloudPlots R-script ( ;   https://github.com/RainCloudPlots/RainCloudPlots  ), which could provide a combination of box, violin, and dataset plots. In the dataset plot, each dot represents a data point, respectively. Outliers were defined by 2 SDs and are represented in   by red diamonds. In the boxplot, the line dividing the box represents the median of the data, while the ends of the box represent the upper and lower quartiles. The extreme lines show the highest and lowest values excluding outliers defined by 2.0 SDs. 
  
Statistical analysis 
  


#### Neuroimaging analysis 
  
##### Image preprocessing 
  
The first 10 volumes (10 s) of each fMRI run were discarded to allow for stabilization of the magnetization, and the remaining 500 volumes/run (total of 2000 volumes/participant) were used for the analysis. The data were analyzed using statistical parametric mapping (SPM12, Wellcome Trust Center for Neuroimaging, London, UK; RRID:  SCR_007037  ) implemented in MATLAB 2014 (RRID:  SCR_001622  ). All volumes were realigned for motion correction. The whole-head T1-weighted high-resolution MPRAGE volume was coregistered with the mean EPI volume. The T1-weighted image was normalized to the Montreal Neurologic Institute (MNI) template brain using a nonlinear basis function in SPM12. The same normalization parameters were applied to all EPI volumes. All normalized EPI images were spatially smoothed in three dimensions using a Gaussian kernel (full-width at half-maximum = 8 mm). 


##### Estimation of task-related activation using univariate generalized linear modeling 
  
Because of technical difficulties, we could not acquire fMRI data from one pair. Therefore, we analyzed whole fMRI data acquired from 30 participants (18 men, 12 women; mean ± SD age, 21.7 ± 2.10 years). Statistical analysis was conducted at two levels. First, individual task-related activation was evaluated. Second, summary data for each participant were incorporated into a second-level analysis using a random-effects model ( ) to make inferences at a population level. 

In the individual-level analysis, the blood oxygenation level-dependent (BOLD) time series representing the brain activation of each participant was first modeled using a boxcar function convolved with a hemodynamic response function and filtered using a high-pass filter (128 s), while controlling for the effect of runs. Serial autocorrelation assuming a first-order autoregressive model was estimated from the pooled active voxels using the restricted maximum likelihood procedure and used to whiten the data ( ). No global scaling was applied. The model parameters were estimated using the least-squares algorithm on the high pass-filtered and whitened data and design matrix. Estimates for each of the model parameters were compared with the linear contrasts to test hypotheses regarding region-specific condition effects. Next, the weighted contrasts of the parameter estimate (i.e., LIVE > REST and REPLAY > REST) in the individual analyses were incorporated into the group analysis. Contrast images obtained via individual analyses represented the normalized task-related increment of the MR signal relative to the control condition (i.e., the REST condition) for each participant. 

In the group-level analysis, we investigated differences in brain activation between the LIVE and REPLAY conditions using these contrast images and the random-effects model implemented in SPM12. We analyzed these data using the paired   t   test. The resulting set of voxel values for each contrast constituted a statistical parametric map of the   t   statistic (SPM {t}).   T  he threshold for significance of the SPM {t} was set at   p   < 0.05 with familywise error (FWE) correction at the cluster level for the entire brain ( ). To control FWE rates using random field theory ( ), the height threshold was set at an uncorrected   p   value <0.001, which is conservative enough to depict cluster-level inference with the parametric procedure ( ). To validate the statistical inference with a parametric method, we also tested the statistical significance of activation using a nonparametric permutation test implemented in the SnPM13 toolbox (RRID:  SCR_002092  ;  ). We used the nonparametric paired   t   test with no variance smoothing; the number of permutations was set at 10,000. The SnPM toolbox did not yield statistical significance at all the voxels reported in SPM; thus, the   p   values for some voxels have not been listed in the tables. 


##### Generalized psychophysiologic interaction analysis 
  
Next, we performed generalized psycho-physiologic interaction (gPPI) analysis ( ;  ) using the CONN toolbox ( ; RRID:  SCR_009550  ) to reveal how effective connectivity from the LIVE- or REPLAY-specific regions (toward other brain regions) was altered between the LIVE and REPLAY conditions. For this purpose, we selected three clusters based on the LIVE > REPLAY contrast defined by the results of univariate generalized linear modeling (GLM) analysis ( ,  ) as seed regions for the gPPI analysis. We used conventional seed-to-voxel gPPI analysis in which the whole brain is the search area. The components associated with a linear trend, CSF, white matter (WM), and experimental tasks (i.e., LIVE and REPLAY effects) were removed from the BOLD time series as confounding signals. Using the residual time series, gPPI analysis was performed to evaluate whether the effective connectivity from the seed region was modulated by the task condition (i.e., the LIVE or REPLAY condition) at the individual level. This individual-level analysis produced contrast images representing the modulation of effective connectivity from the seed region. Up to this point, all procedures were conducted using the CONN toolbox. Finally, we used these contrast images and the random-effect model implemented in SPM12 to test whether any regions exhibited significant differences in effective connectivity between the LIVE and REPLAY conditions. Analyses were assessed at   p   < 0.05 with FWE correction at the cluster level. The height threshold to form each cluster was set at an uncorrected   p   value of 0.001. This relatively high cluster-forming threshold is enough to prevent the failure of a multiple-comparison problem in cluster-level statistical inference ( ;  ). We also listed statistical values estimated by the SnPM toolbox with a nonparametric permutation test. 
  
Behavioral analysis.    A   , The number of eye-blinks per block. We omitted the first 5 s of each block because of instability of the recorded video induced by task switching; the number of eye-blinks was therefore calculated based on the succeeding 15 s. Each dot represents a data point. In the boxplot, the line dividing the box represents the median of the data, the ends represent the upper/lower quartiles, and the extreme lines represent the highest and lowest values excluding outliers.    B   , ΣNCR values. The integral of the NCR of each condition across the whole frequency range was calculated.   is the ΣNCR from the time series of the participant’s facial movement to that of the partner during the LIVE condition.   is the ΣNCR from the time series of the participant’s facial movement to that of the partner during the REPLAY condition.   is the ΣNCR from the time series of the participant’s facial movement to that of the partner during the REST condition.   is the ΣNCR from the time series from the participant’s delayed facial movement on the screen to the partner’s time series during the REPLAY condition.    C   , Enhanced ΣNCR values from the REST condition. 
    
Regions exhibiting greater activation in the LIVE condition than in the REPLAY condition 
    

##### Interbrain synchronization analysis 
  
We tested for differences in the interbrain synchronization of the LIVE and REPLAY conditions using conventional voxel-to-voxel method used by previous hyperscanning fMRI studies that can identify interbrain synchronization of activation without any prior assumptions ( ;  ). We focused on the spontaneous fluctuation of BOLD signal that is unrelated to the task-related activation or deactivation ( ). First, the task-related activation/deactivation was removed from the BOLD time series using the GLM model implemented in the SPM12. This yielded 3D-Nifti files representing residual time series that are independent of task-related activation/deactivation compared with baseline (i.e., the REST condition). Second, we divided the original time series into three sub-time series based on the experimental design: LIVE, REPLAY, and REST conditions. Third, we concatenated sub-time series into one long time series. The length of the LIVE- and REPLAY-related residual time series was 640 volumes. Next, we calculated the interbrain synchronization between the voxels representing the same MNI coordinates (  x  ,   y  ,   z  ) in the two participants using the Pearson’s correlation coefficient. This computation was performed using a MATLAB script developed in-house. The correlation coefficient   r   was transformed to the standardized   z   score using Fisher’s   r  -to-  z   transformation. Finally, we obtained two 3D-Nifti images representing interbrain synchronization in the LIVE and REPLAY conditions per pair. 

We conducted the random-effects model analysis in SPM12 at the group level. The normalized interbrain synchronization images were used in the group-level analysis. Here, the paired   t   test was used to test the differences in interbrain synchronization between the LIVE and REPLAY conditions. The resulting set of voxel values for each contrast constituted a statistical parametric map of the   t   statistic (SPM {t}). The threshold for significance of the SPM {t} was set at   p   < 0.05 with FWE correction at the cluster level for the entire brain ( ); the height threshold was set at an uncorrected   p   value of 0.001. This cluster threshold is conservative enough to prevent failure in cluster-level inference ( ;  ). The statistical inference was also estimated by a nonparametric permutation test using the SnPM toolbox, like the GLM and gPPI analyses. Anatomic labeling was based on Automated Anatomic Labeling ( ) and the Anatomy toolbox version 1.8 ( ). Final images have been displayed on a standard template brain image (  http://www.bic.mni.mcgill.ca/ServicesAtlases/Colin27  ) using MRIcron (  https://www.nitrc.org/projects/mricron  ;  ). 





## Results 
  
### Behavioral index 
  
 shows the average number of eye-blinks per block. Repeated-measures ANOVA revealed a significant effect of condition ( , a;   F   = 13.1814,   p   < 0.0001, η  = 0.0354). A   post hoc   comparison with Bonferroni correction revealed that there were no significant differences in the number of eye-blinks between the LIVE and REPLAY conditions ( , d;   t   =2.3522,   p   = 0.0786, Bonferroni correction), while the number of eye-blinks was greater in the REST condition than in the LIVE ( , b;   t   =3.9464,   p   = 0.0015, Bonferroni correction) and REPLAY ( , c;   t   = 3.8499,   p   = 0.0021, Bonferroni correction) conditions. 

 N  ext, we compared the ΣNCR values using repeated-measures ANOVA ( ) and found a significant effect of condition was significant (  F   = 3.9830,   p   = 0.0295, η  = 0.03236;  , e). A   post hoc   comparison with Bonferroni correction revealed that there were significant differences between the   (  t   = 3.406,   p   = 0.0126;  , f),   (  t   =3.2934,   p   = 0.0168;  , h). Differences in the other pairs did not meet the threshold for statistical significance ( , g, i, j, k). To confirm that the outliers did not skew the parametric statistics, we recomputed the statistical values after removing outliers defined by two SDs rather than 1.5. Four subjects to whom the outlier data could be attributed in at least one of the four conditions were excluded from the analysis; the repeated-measures ANOVA therefore included a sample of 24. Even after removing the outliers, the repeated-measures ANOVA could replicate the significant effect of condition (  F   = 4.3334,   p   = 0.0074, η  = = 0.0785;  , l), as well as the significant differences between the   (  t   =3.0965,   p   = 0.0306;  , m), and between   (  t   = 3.0779,   p   = 0.0318;  , o). Differences in the other pairs did not meet the threshold for statistical significance ( , n, p, q, r). 

We also tested differences across enhanced ΣNCR values using repeated-measures ANOVA ( ) and found that the effect of condition was significant (  F   = 10.3784,   p   = 0.0002, η  = 0.03236;  , s). A   post hoc   comparison with Bonferroni correction revealed that there were significant differences between   and   (  t   = 3.4061,   p   = 0.0063;  , t), as well as between   and   (  t   = 3.2934,   p   = 0.0084;  , u). Differences in the other pair did not meet the threshold for statistical significance ( , v). We recalculated statistical inferences as raw NCR values without outliers to ensure that the outliers had no effect on the inferences. The stricter criteria for outliers remained 2 SDs, resulting in the removal of seven subjects from the analysis. Even after outliers were excluded from the analysis, we obtained qualitatively identical results: significant effect of condition (  F   = 7.9233,   p   = 0.0013, η  = 0.1330;  , w), and significant differences between   and   (  t   = 2.8343,   p   = 0.0306;  , x) and between   and   (  t   = 2.9034,   p   = 0.0265;  , y). Differences in other pairs did not meet the threshold for statistical significance ( , z). 

To test whether or not these enhancements of entrainment of eye-blinking is influenced by the number of blocks, we calculated the Akaike causality index for separate blocks of the experiment and applied the repeated-measures ANOVA (4 blocks × 4 conditions) to the ΣNCR data. We found a significant effect of conditions (  F  =3.9830,   p   = 0.0106, η  = 0.0132;  , aa). However, the effects of sessions (  F  =1.0351,   p   = 0.3816, η  = 0.0139;  , bb) and interaction (session × conditions;   F   = 1.8235,   p   = 0.0647, η  = 0.0128;  , cc) were nonsignificant. Therefore, in the following analysis of neuroimaging data, we combined data from the four blocks. 


### Brain activation in the LIVE and REPLAY conditions 
  
We used GLM analysis ( , dd, ee) to elucidate brain activation in the LIVE and REPLAY conditions. For the LIVE versus REPLAY contrast, we observed greater activation in the left cerebellar hemisphere (lobules VI, VII, and VIIIa), bilateral paravermis area (lobule XI;  ), and the pre-supplementary motor area (SMA) extending to the dorsal tier of the anterior cingulate cortex (ACC;  ). No significant differences in activation were observed in the REPLAY versus LIVE contrast. Detailed information regarding each cluster is outlined in  . 
  
Brain regions exhibiting significantly greater activation in the LIVE condition than in the REPLAY condition.    A   , Cerebellar activation is overlaid on the coronal planes of the SUIT template ( ;  ).    B   , The activation in the ACC is superimposed on the T1-weighted high-resolution anatomic MRI normalized to the MNI template space in the sagittal (left), coronal (middle), and transaxial (right) planes that crossed at (6, 12, 40) in the MNI coordinate system (in mm). SUIT, Spatially unbiased infratentorial template. 
  

### Results of the gPPI analysis 
  
The gPPI analysis ( , ff, gg) revealed that the effective connectivity from the ACC region toward the dorsal anterior insular cortex (dAIC;  ) was greater during the LIVE condition than during the REPLAY condition ( ,  ). No regions exhibited greater effective connectivity involving the pre-SMA-ACC regions in the REPLAY condition than in the LIVE condition. There was no modulation of effective connectivity involving cerebellar seed regions.
 
  
Regions exhibiting greater effective connectivity from the ACC in the LIVE condition than in the REPLAY condition. The area outlined in white is the dAIC ( ). X indicates the MNI coordinates (in mm). 
    
Regions exhibiting enhanced effective connectivity from the ACC in the LIVE condition 
    

### Interbrain synchronization 
  
 illustrates interbrain synchronization that is specific to the LIVE condition ( , hh, ii). It was found on the bilateral middle occipital gyrus (MOG). Detailed information about these clusters is described in  . No regions showed significant interbrain synchronization in the REPLAY condition compared with the LIVE condition. 
  
Regions exhibiting greater interbrain synchronization during the LIVE condition than the REPLAY condition. These areas are superimposed on a surface-rendered high-resolution anatomic MRI normalized to the MNI template viewed from the left and right. 
    
The regions exhibiting enhanced interbrain synchronization in the LIVE condition compared with REPLAY condition 
    


## Discussion 
  
This study aimed to elucidate the behavioral and neural representations of mutual interaction during eye contact by comparing the neural activity associated with real-time eye contact with that associated with non-real-time eye contact. Our findings suggest that mutual interaction/shared attention during eye contact is mediated by the cerebellum and the limbic mirror system. 

### Behavioral index 
  
In this study, causal analysis using an MVAR model ( ;  ) was performed to assess how an individual’s temporal attentional window is influenced by that of the partner ( ;  ;  ). Our results show that participants were more sensitive to the eye-blinks of a partner in the LIVE condition than in the REPLAY condition because none of the participants perceived the difference between the LIVE and REPLAY conditions. Thus, the experimental setup for our LIVE condition enabled a reciprocal feedback system through the visual modality. Our findings suggest that perceptual–motor interaction occurs during eye contact without conscious awareness. Previous researchers have argued that an essential component of real-time social interactions involves reciprocal coupling via perceptual–motor linkages between interacting individuals ( ;  ;  ;  ;  ). Our results extend this notion to the attention mediated by the minimal motion of blinking, which represents the temporal window of attention toward one’s partner. Interestingly, the influence from a partner was significantly greater when the information flow between two individuals was reciprocal ( ) than when it was unidirectional ( ). As the mutual interaction in real time evinced a significant effect on the partner’s eye-blink, this finding indicated that the mutual on-line interaction is critical to the influence of the other’s eye-blink. Feedback through the on-line mutual interaction may induce a nonlinear response, causing the subtle effect to be amplified ( ). 

This experiment can be regarded as a simplified version of the social contingency detection task originally reported by  . Social contingency is defined as the cause–effect relationship between one’s behavior and consequent social events ( ;  ) and is highly associated with a sense of self or one’s own body in infancy, developing a sense of reciprocity, and participation with others ( ), all of which are critical for typical development ( ;  ;  ;  ;  ). Several previous studies have investigated differences in mother–infant interactions between real-time bidirectional interaction and off-line unidirectional interaction ( ;  ;  ;  ). Even in adults, turn-taking behavior accompanying social contingency is likely to serve as experience sharing, which represents the basis of all social behaviors ( ;  ). Our results indicate that even a minimal task condition, such as mutual gaze, constitutes a reciprocal feedback system that can provide a basis for the detection of social contingency, promoting sharing of attention between partners ( ;  ). 


### Neural substrates of eye contact in real time 
  
Using a conventional GLM approach, we observed LIVE-specific activation in the cerebellum and ACC. The cerebellum plays a key role in error detection and processing of temporal contingency ( ;  ;  ), the latter of which is critical for real-time social communication ( ). The cerebellum is also critically involved in sensorimotor prediction ( ), especially in building predictions about the actual sensory consequences of an executed motor command. One previous fMRI study reported that the prediction error caused by sensory feedback is essential for acquiring internal forward models of movement control ( ). This prediction (forward model) is mainly used in the early stages of movement execution to maintain accurate performance in the presence of sensory feedback delays ( ), as well as in social interaction ( ). Considering that real-time social interaction can be regarded as a cross-individual sensorimotor loop ( ;  ), the cerebellum may receive visual afferents of the partner’s blink as sensory feedback for the prediction of one’s blink movement, to evaluate temporal contingency between the partners’ blinks. 

In humans, the ACC is located in the medial wall of the cerebral hemisphere, adjacent to the pre-SMA ( ). The ventral (limbic) tier occupies the surface of the cingulate gyrus, corresponding to Brodmann’s areas 24a and 24b, and subcallosal area 25. The dorsal (paralimbic) tier is buried in the cingulate sulcus, corresponding to Brodmann’s areas 24c and 32 (for review, see  ). The dorsal tier is involved in volitional motor control ( ;  ;  ). 

The ACC and cerebellum constitute a tightly connected corticocerebellar network. Recent functional connectivity analysis studies have demonstrated that distinct cerebellar seed regions in the anterior portion of the crus I exhibit functional connectivity with the dorsolateral prefrontal cortex, the rostral portion of the inferior parietal lobule, and a frontal midline region bordering the pre-SMA and ACC in healthy adults ( ;  ). Conversely, the ACC exhibits a negative correlation with the cerebellum ( ), possibly reflecting its hypothesized role in the inhibition of prepotent stereotyped responses ( ;  ). In terms of anatomic connectivity,   used diffusion MRI to demonstrate disruption of WM connectivity between the cerebellum and the cingulate cortex in individuals with Friedreich ataxia, an autosomal recessive disease involving degeneration of the spinal cord and cerebellum, thereby supporting the notion of reverse cerebellar diaschisis ( ). 

The corticocerebellar–thalamocortical circuit involving the cerebellum and ACC plays a role in attention. The cerebellum is involved in attention, including anticipation/prediction of the internal conditions for a particular operation, as well as the setting of specific conditions in preparation for that operation ( ;  ).   reported that patients with schizophrenia exhibited an attenuated response of the ACC and cerebellum to degradation of the target during a continuous performance task, paralleling their limited visual attentional resources. They also observed disruption in the pattern of task-related connectivity of the ACC to the prefrontal regions.   concluded that attentional impairments associated with schizophrenia could be attributed to the corticocerebellar–thalamocortical circuit, which includes the ACC and cerebellum. Considering the role of the ACC and cerebellum in sensorimotor and attentional control, the ACC–cerebellar network may constitute a reactive–predictive controller system ( ) by which one’s own attention-contingent motor output (that is, eye-blink) is modulated by the visual input of the partner’s movement. Under the mirror configuration during the LIVE condition, the reactive–predictive controllers in two individuals work to coordinate their own behavior with the partner’s. Thus, it closes the sensorimotor circuits across the individuals. 


### Enhanced connectivity between the ACC and AIC 
  
We observed enhanced effective connectivity from the ACC to the right dAIC in the LIVE condition than in the REPLAY condition. In the present study, no emotional processes were included in the task, suggesting that the enhancements in connectivity were related to recurrent interaction via eye contact. The ACC has a strong connection to the AIC ( ;  ), most prominently in the dAIC ( ), a central hub in which several different cognitive networks converge ( ;  ). The ACC–AIC network represents the portion of the limbic mirror system related to the recognition of affective behavior ( ;  ;  ). 

 proposed that the AIC and ACC represent the basis of self-awareness by constituting the input (AIC) and output (ACC) components of a system. In such a system, the integrated awareness of cognitive, affective, and physical states first generated by the integrative functions of the AIC are then re-represented in the ACC as a basis for the selection of and preparation for responses to inner or outer events.   regarded the AIC as the probable site for awareness, based on its afferent representation of “feelings” from the body, and the ACC as the probable site for the initiation of behaviors.   proposed a “like-me” framework for the understanding of others. He suggested that imitation enables the understanding of another mind based on an understanding of actions and their underlying mental states.   observed that pain empathy relies on neural structures that are also involved in the direct experience of that emotion [i.e., the limbic mirror system (ACC, AIC)]. This finding is consistent with the Simulation Theory, which proposes that “we understand other people’s minds by using our mental states to simulate how we might feel or what we might think in a given situation” ( ).   concluded that perceiving the states of another activates neural representations encoding each state when it is experienced personally. In the eye-contact state, participants are aware that they are attending to their partner during eye contact. Therefore, given that the ACC–AIC network represents self-awareness, its activation during real-time eye contact may represent a shared mental state (i.e., awareness involving the participant and partner) such as shared attention. This interpretation is consistent with a study by  , which demonstrated that autonomic arousal is enhanced by eye contact with a live human, but not with static images of faces. The authors argued that this might be due to the enhancement of self-awareness by the presence of another person. The results of our study suggest that the self-awareness is enhanced by the social contingency generated with live humans through the interaction of each other’s attentional windows via eye-blinks and that the regulation of self-awareness by interaction might be caused by the cerebellar–cerebral networks that tap into the limbic mirror system. 


### Interbrain synchronization 
  
By comparing the degree of interbrain synchronization between the LIVE and REPLAY conditions, we found an enhancement in the MOG region related to the LIVE condition. This region is in the lateral occipitotemproral cortex (LOTC) and is almost identical to the region that shows interbrain synchronization specific to the eye-contact state ( ). Previous studies suggest that the LOTC receives both sensory inputs of a partner’s behavior ( ) and efference copies of one’s own behavior ( ;  ). Therefore, the roles of the LOTC in supporting action perception and overt action performance are closely related. The LOTC may play a role in the human action observation network ( ) that is typically attributed to the frontoparietal mirror system ( ). Thus, the MOG region may conceivably receive information about self and other’s eye-blinks. 

Based on the electroencephalography (EEG) hyperscanning experiment of the mutual gaze between mothers and infants,   found interpersonal neural synchronization. They argued that the phase of cortical oscillations reflects the excitability of underlying neuronal populations to incoming sensory stimulation ( ), a possible mechanism for temporal sampling of the environment ( ). Interpersonal neural synchronization could increase within a dyad during the course of social interaction because each partner is continuously producing salient social signals (e.g., gaze) that act as synchronization triggers to reset the phase of his or her partner’s ongoing oscillations ( ). The present study showed neural synchronization in the LOTC, which receives both visual input of others’ actions and efference copies of one’s own actions. The salient social signals were sent to the partner through gaze or blink (defining the temporal attentional window), and the motor command corresponding to which is likely delivered to the LOTC as an efference copy. The eye-blink may, thus, act as a synchronization trigger. Therefore, the cross-individual neural synchronization of the MOG represents the alignment of the temporal pattern of attention, which may optimize communicative efficiency ( ). 


### Limitations and future directions 
  
The present study is subject to several limitations. First, concerning the hyperscanning fMRI experimental design, the very long mutual gaze condition was not ecological and may be quite different from conceptions of “mutual gaze” or “eye contact” informed by daily life. This is due to our use of a blocked design, the most effective way to detect brain activation. Also, the product of our experimental design, estimations of the temporal dynamics of eye-blink entrainment, brain activation, and interbrain synchronization, could not be performed. While we could not find a significant effect of session on the eye-blink entrainment in real-time eye contact, it is possible that the eye-blinking entrainments only occur in the very first phase of mutual gaze condition in one block. By refining the experimental and analytical design, we may further gain insight into the dynamics of interindividual interaction through eye-contact and interbrain synchronization. To explore the temporal dynamics of interbrain synchronization, we are currently conducting a hyperscanning simultaneous EEG-fMRI recording that could integrate the merits of the two neuroimaging methods ( ). As the present study demonstrated the efficacy of using Akaike causality analysis to evaluate dynamic mutual interaction, future studies applying this method to EEG data in ecological settings of normal and diseased populations are warranted. 

The present study is also limited by its capacity to find interbrain synchronization only between homologous regions, but not between nonhomologous regions (i.e., frontoparietal synchronization;  ). In our setting, two participants play identical roles in eye-to-eye communication; therefore, the resonance through interbrain closed loop might occur in the homologous regions. However, the interbrain effect may also occur between nonhomologous regions. To explore this possibility, an ROI analysis based on the precise parcellation of human cerebral cortex in a human connectome project may be the most suitable ( ). Future studies adapting this method could reveal the mechanism underlying the means by which two brains are wired through eye-to-eye communication without any conscious awareness. 


### Summary 
  
In the present hyperscanning fMRI study, we focused on real-time mutual interaction during eye contact. The open-and-close timing of the attentional window, defined by eye-blinks, was entrained to that of the counterpart during real-time mutual interaction. Our findings indicate that the social interaction is nonlinear, and the influence from the partner might be amplified by the nonlinearity during the real-time interaction. Corresponding with the nonlinearly amplified behavioral coordination, real-time interaction during eye contact was found to be mediated by the amplified activation of the cerebellum and the cingulate motor cortex. This was accompanied by enhanced connectivity within the limbic mirror system. These findings underscore the notion that real-time eye contact generates an emergent property of shared attention, which is mediated by a cerebellocerebral network inclusive of the limbic mirror system. 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-12'>
<h2>12. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/26106544/' target='_blank'>26106544</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Brain activation during self- and other-reflection in bipolar disorder with a history of psychosis: Comparison to schizophrenia</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Neuroimage Clin</p>
<p><strong>Publication Year:</strong> 2015</p>
<p><strong>DOI:</strong> 10.1016/j.nicl.2015.04.010</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4473805/' target='_blank'>4473805</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of self- and other-reflection (social-related processing: Perception and Understanding of Self and Others). It includes a healthy control group (n=21) with results reported separately and behavioral/neuroimaging results for HCs are presented. Whole-brain analyses were performed and reported for main task effects in HCs (p<.05 FWE voxel-level); group comparisons also reported (some ROI-restricted tests were used, but whole-brain task effects for healthy participants are available). Participants are adults and no indication they fall outside the 17–65 range. Therefore all inclusion criteria are met and no exclusion criteria are triggered.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
## Objectives 
  
Reflecting on the self and on others activates specific brain areas and contributes to metacognition and social cognition. The aim of the current study is to investigate brain activation during self- and other-reflection in patients with bipolar disorder (BD). In addition, we examined whether potential abnormal brain activation in BD patients could distinguish BD from patients with schizophrenia (SZ). 


## Methods 
  
During functional magnetic resonance imaging (fMRI), 17 BD patients, 17 SZ patients and 21 healthy controls (HCs) performed a self-reflection task. The task consisted of sentences divided into three conditions: self-reflection, other-reflection and semantic control. 


## Results 
  
BD patients showed less activation in the posterior cingulate cortex (PCC) extending to the precuneus during other-reflection compared to HCs (  p   = 0.028 FWE corrected on cluster-level within the regions of interest). In SZ patients, the level of activation in this area was in between BD patients and HCs, with no significant differences between patients with SZ and BD. There were no group differences in brain activation during self-reflection. Moreover, there was a positive correlation between the PCC/precuneus activation during other-reflection and cognitive insight in SZ patients, but not in BD patients. 


## Conclusions 
  
BD patients showed less activation in the PCC/precuneus during other-reflection. This may support an account of impaired integration of emotion and memory (evaluation of past and current other-related information) in BD patients. Correlation differences of the PCC/precuneus activation with the cognitive insight in patients with BD and SZ might reflect an important difference between these disorders, which may help to further explore potentially distinguishing markers. 

   Highlights  
  
We investigated self-reflection and other-reflection in bipolar disorder. 
  
Bipolar had less PCC/precuneus activation during other-reflection than controls. 
  
PCC/precuneus activation was unrelated to cognitive insight in bipolar patients. 
  
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (35764 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Several studies have demonstrated disturbed metacognitive processing in patients with bipolar disorder (BD) ( ;  ;  ). Self- and other-reflection can be considered metacognitive processes and refer to the evaluation process by which people determine to what extent certain cues (e.g. traits and attitudes) apply to themselves or others respectively ( ). Patients with BD may show comparable impairments in several metacognitive domains as patients with schizophrenia (SZ) ( ;  ;  ) in whom self- and other-reflection have been investigated more abundantly ( ;  ;  ;  ;  ). However, little is known about self- and other-reflection and the underlying neural correlates in BD patients. 

Self-reflection and other-reflection are related to the function of cortical midline structures (CMS). The CMS consist of the anterior cingulate cortex (ACC), posterior cingulate cortex (PCC), dorsal medial prefrontal cortex (DMPFC) and ventral medial prefrontal cortex (VMPFC) ( ). The   cognitive neuropsychiatric self-reflection/self-appraisal model   ( ) suggests that these different structures each have a specific contribution to reflective processing. According to this model, directing attention is associated with activation of the ACC. The PCC is involved in consultation of autobiographical memory to facilitate decisions whether the confronted stimuli apply to self or others. Ultimately, the final decision is proposed to be related to activation of the DMPFC. In addition, the insula seems to be involved in reflective processing and is associated with evaluation of internal self-state and somatic feedback ( ). These processes are similar in both self- and other-reflection ( ). Moreover, a specific role in tagging self-relevant information has been hypothesized for the VMPFC.   have reported evidence that the level of activation in the VMPFC is mediated by the degree of self-relatedness. They demonstrated that the VMPFC is activated by stimuli related to self and, to a lesser extent, a close other, but not by stimuli referring to a public other. 

There are currently, to our knowledge, no studies investigating the neural correlates of self- and other-reflection in BD patients. However, studies conducted in SZ patients have revealed abnormal brain activations during self- and other-reflection that occur during psychotic periods and seem to persist during stable periods after psychotic symptoms disappear. Compared to healthy individuals, SZ patients have shown less activation during self-reflection in the PCC ( ), inferior temporal gyrus extending to the middle temporal gyrus ( ) and precuneus ( ), but also hyper-activation in the PCC has been reported ( ). During other-reflection, less activation in the VMPFC, ACC, insula and cuneus ( ) and PCC/precuneus ( ) has been reported. In addition, comparing self to other has shown less activation in the DMPFC ( ), and higher activation in the PCC/precuneus ( ). These studies suggest that the self- and other-reflective network is abnormally activated in SZ patients during reflective processing, even in the absence of current symptoms ( ). 

 have reported that the same genes could lead to vulnerability for both of these disorders and some authors even suggest that BD and SZ are an expression of different levels of severity on the same disease continuum rather than two completely different diseases ( ). It has indeed been shown that patients with BD and SZ share several clinical features (e.g. anhedonia, psychotic symptoms;  ;  ). Moreover, patients with both BD and SZ have shown disturbed metacognitive processing in social and emotional domains such as theory of mind (e.g.  ;  ;  ) which is closely associated with self- and other-reflection ( ;  ;  ). In addition, while healthy individuals tend to attribute more positive than negative events to themselves during self-reflection (self-serving bias;  ), this tendency is disturbed in both SZ patients ( ;  ) and BD patients ( ). However, BD and SZ have been classified as two different disorders for a long time. SZ patients have shown worse cognitive functioning than BD patients ( ), which also implies differences between BD and SZ. Therefore, it would be interesting to explore whether potential abnormal activations during self- and other-reflection in BD patients are comparable to those in SZ patients or whether these represent unique neurobiological features distinguishing BD patients from SZ patients. 

In order to maximize comparability between BD and SZ groups, and also potentially get more pronounced differences compared to healthy individuals, we recruited a relatively homogeneous group of BD patients who had a history of psychosis, but were not currently experiencing a psychosis. Notably, it has been found that activation during reflective processing is associated with level of illness insight ( ). BD patients have generally a good level of illness insight when they are not in a manic episode ( ), while in SZ patients illness insight could be low during all phases of illness ( ;  ). Therefore, we aimed to investigate differences between BD and SZ in brain activation during self- and other-reflection in patients with good insight only. 

In the present study, we aimed to investigate the neural correlates during a self-reflection task in BD patients with a history of psychotic symptoms. Based on the importance of the self-reflective network during both self- and other-reflective processing and their established deficiencies in relation with psychotic symptomatology, we hypothesized that BD patients would show abnormal activation within the self-reflection network compared to healthy individuals. Additionally, differences between patients with BD and SZ in brain activation during reflective processes, as well as correlations with insight, were explored in order to examine whether the potential abnormalities in BD were specific for BD. 


## Methods 
  
### Participants 
  
This study included BD patients, SZ patients and healthy controls (HCs). The following inclusion criteria were applied to both BD and SZ patients: (1) Being stable on current medication and no medication change in the week before scanning; (2) no electroconvulsive therapy in the year prior to the scan; (3) having no psychiatric disorders other than BD or SZ (e.g. substance use disorder); and (4) for BD patients, having a history of an episode with psychotic symptoms, lifetime. A specific inclusion criterion for HCs was no current or past psychiatric disorders. Additional inclusion criteria for all participants were: (1) No somatic or neurological disorders that may have impacted the central nervous system; and (2) no MRI-incompatibilities (e.g. metal implants, claustrophobia or pregnancy). 

Following these criteria, 21 BD patients (8 males, 13 females) were recruited from several mental health care institutions in the North of the Netherlands. Diagnosis of BD was confirmed with the Mini International Neuropsychiatric Interview-Plus 5.0.0 (MINI-Plus;  ). 

Based on the final BD patient sample (see   Patient disposition), 17 SZ patients (11 males, 6 females) were selected from a sample of a previous study ( ). These participants were not significantly different from the BD sample on intelligence (measured with the Dutch reading test for adults (NLV);  ), age, gender and level of education. Diagnosis of SZ was confirmed with the MINI-Plus. Because self-reflection is also associated with insight into illness (both clinical insight and cognitive insight) ( ), it is important to match patients with BD and SZ on insight to exclude alternative explanations for any potential group differences. We matched SZ patients with BD patients on illness insight, based on the Schedule of Assessment of Insight-Expanded version (SAI-E, clinical insight;  ) and the Beck Cognitive Insight Scale (BCIS, cognitive insight;  ). The BCIS is composed of a self-reflectiveness subscale and a self-certainty subscale. Cognitive insight is measured by a composite score of these two sub-scales (i.e. score on the self-reflectiveness minus the self-certainty score). BD and SZ patients were matched on the BCIS subscales and the BCIS composite score. Higher scores on the SAI-E and BCIS indicate better insight. 

In addition, we included a group of 21 HCs (12 males, 9 females) matched on intelligence, gender and level of education with both patient groups. The HC group was the same as in a previous study ( ). 

The present study was performed in accordance with the Helsinki Declaration of 1975 and was approved by the Medical Ethics Committee of the University Medical Center Groningen (UMCG). All participants gave written informed consent and received monetary compensation (€45) for participation. 


### Clinical assessment and measures 
  
Current severity of depression and mania was measured by the Quick Inventory of Depressive Symptomatology (QIDS-SR;  ) and Young Mania Rating Scale (YMRS;  ), respectively. A depressive state was defined as a score of >10 on the QIDS-SR ( ) and a mania state was defined as a score of >8 on the YMRS ( ). Current psychotic symptoms were assessed with the Positive and Negative Syndrome Scale (PANSS;  ). The PANSS is composed of three dimensions: positive, negative and general psychopathology. Lower scores on QIDS, YMRS and PANSS indicate lower symptom severity. 


### Self-reflection task 
  
The self-reflection task consisted of three conditions: (1) self-reflection (self): sentences referring to “I/me” which were balanced for positive/negative valence and mental/physical quality (e.g. “It's always fun with me”, “I am a liar”, “I look youthful”, “I am fat”); (2) other-reflection (other): sentences referring to a relative or close friend who remained the same throughout the whole experiment, also balanced for positive/negative valence and mental/physical quality (e.g. “(other) has respect for others”, “(other) sometimes says stupid things”, “(other) is healthy”, “(other) has wrinkles”). Prior to scanning, the name of a close other was provided to match the familiarity and difficulty of accessing stored knowledge compared to the self and would replace the “other” in the given examples; (3) semantic control (semantic): sentences containing equal number of false and true general knowledge statements (e.g. “snow is black”, “dogs run faster than snails”). Before scanning, participants received instructions and explanations about the task. Participants were instructed to define on a four-point continuum how much they agreed with the presented sentence (1-fully disagree; 4-fully agree). Each trial consisted of a sentence presented for 4000 ms followed by a 500 ms fixation cross. 

For each condition, sixty sentences were presented. Sentences were presented in a block design, with each block consisting of five trials. The three conditions were counterbalanced in a semi-random order to avoid consecutive presentation of the same condition. Reaction times (RT) were recorded. The procedure lasted about 15 min. 


### Image acquisition 
  
fMRI data were collected using a 3.0 Tesla whole body scanner (Philips Intera, Best, NL). Stimuli were rear-projected on a screen, which was visible via a mirror attached to the sense-8 head coil. The head was kept in position by an elastic band and foam cushions on each side of the head. A T1-weighted 3D fast field echo anatomical image was acquired parallel to the bicommissural plane, covering the whole brain (170 slices; TR = 9.00 ms; TE = 3.50 ms; FOV = 232.00 × 170.00 × 256.00 mm; voxel size: 1 × 1 × 1 mm). The functional images were acquired using T2*-weighted echo planar imaging sequences. Each functional image consisted of 37 interleaved axial slices of 3.5 mm thickness (slice gap = 0 mm; TR = 2.00 s; TE = 30 ms; FOV = 224.00 × 129.50 × 224.00 mm; 64 × 64 matrix of 3.50 × 3.50 × 3.50 voxels). To prevent artefacts due to nasal cavities, images were tilted approximately 10° to the AC−PC transverse plane. 


### Data analysis 
  
#### Behavioural analysis 
  
In order to check the self-serving bias in BD patients, we recoded the 4-point scale to agreed and disagreed items. Items scoring 1 or 2 on the four-point continuum were considered as items disagreed, while those scoring 3 or 4 were considered as items agreed. We calculated a value corresponding to the self-serving bias by subtracting the number of negative sentences participants attributed to themselves from the number of positive sentences, yielding one score per participant. In addition, we calculated this value for the other-condition (other-serving bias). Behavioural group differences were assessed with a one-way analysis of variance (ANOVA) for self-serving bias and other-serving bias separately. 

In addition, differences in RT were tested using a repeated measures ANOVA, with condition (self and other) and valence (positive and negative) as within-subjects factors, and group (BD, SZ and HC) as between-subjects factor. Significance level was set at   p   < .05 (two-sided) for behavioural analyses. 


#### fMRI analysis 
  
fMRI data were pre-processed and analysed using statistical parametric mapping (SPM 8) (   http://www.fil.ion.ucl.ac.uk/spm/   ) implemented in Matlab 7.13 (The Math Works Inc., Natick, MA). Before pre-processing, Philips PAR-files were converted to analyse data by MRIcro. Functional images were slice-time corrected, realigned and co-registered to the anatomical image. Following this, the fMRI images were normalized into standard Montreal Neurological Institute (MNI) space and smoothed with a 3D 10 mm full-width/half-maximum Gaussian Kernel. 

In the first-level analysis, separate regressors were defined for self, other and semantic sentences. In order to avoid systematic low-frequency noise, a high-pass filter was defined based on the following formula: 1.1 times the longest period between two subsequent trials of the same condition. For each participant, two contrasts were defined: self > semantic and other > semantic. 

For second-level analyses, contrast images were entered in a full factorial model, with condition (self > semantic and other > semantic) as within-subjects variable and group (BD, SZ and HC) as between-subjects variable. Age was added as covariate of no interest. Because the behavioural results showed that only a few sentences were regarded as negative, we did not investigate differences related to valence on a neural level. 

The main task effects were investigated in the three groups separately for the contrasts self > semantic, other > semantic, [(self > semantic) > (other > semantic)] and [(other > semantic) > (self > semantic)]. The threshold was set at   p   < .05 family wise error (FWE) corrected for multiple comparisons on voxel-level and an extended threshold of k ≥ 10 voxels. 

In order to assess reflective processing in BD patients,   t  -tests were conducted between BD patients and HCs for each contrast. Following this, to investigate whether patients with BD and SZ would show different or comparable activations,   t  -tests were conducted comparing BD with SZ patients. Furthermore, in order to check whether we could get comparable results as observed in previous studies of reflective processing in SZ patients ( ;  ;  ;  ;  ;  ), we also performed   t  -tests between SZ patients and HCs. For all   t  -tests, significance level was set at   p   < .05 FWE corrected on cluster-level for the spatial extent of our regions of interest (ROIs). 

Limiting the regions of interest to the self- and other-reflection network, four ROI-masks were created by drawing a sphere of 20 mm (radius) around the cluster centre coordinates reported in quantitative meta-analyses of self- and other-reflection tasks by  , in accordance with  . Regarding the masks for the contrasts other > semantic and [(self > semantic) > (other > semantic)], we used the coordinates for the close-other reported by  . For the mask for the contrast [(other > semantic) > (self > semantic)], we took the coordinates of close-other and public-other combined reported by  , because no significant clusters were reported for close-other only. 

For the purpose of visualizing the trend of activation level in the three groups, mean activation values of the area(s) resulting from the   t  -tests were extracted for each participant using the MarsBaR toolbox (   http://marsbar.sourceforge.net   ) and were plotted for each group. 

We repeated these analyses with the self-serving bias and other-serving bias added as covariates of no interest during testing of self- and other-reflection respectively, to test whether the findings would be related to behavioural performance. Moreover, we performed correlation analyses between the mean activation values of the areas showing a difference (extracted with the MarsBaR toolbox) and the scores on SAI-E, BCIS (the two subscales and the composite score), as well as scores on PANSS, YMRS and QIDS to assess whether the potential different activations were related to insight and symptom severity. Correlation analyses were first performed in all groups together, and then in the subgroups separately in order to explore whether there were group differences in correlations. This exploratory analysis might shed some light on our understanding of the neural mechanisms underlying the same symptoms in affective psychotic disorder (BD) and non-affective psychotic disorder (SZ). The Benjamini–Hochberg procedure was applied to correct for multiple tests in order to control for the false discovery rate. In case there were group differences in correlation, Fisher's   r   to   z   transformation ( ) was applied to compare whether the correlations in each group differed significantly from each other. 




## Results 
  
### Patient disposition 
  
Demographic and clinical data of participants are shown in  . Three BD patients were excluded because of excessive head movements (more than 3 mm and/or 3° in any direction) and one BD patient was excluded because of missing behavioural data. A total of 17 BD patients, 17 SZ patients and 21 HCs were included in the analyses.   
Demographic and clinical characteristics for BD patients, SZ patients and HCs. 
                

Of the 17 included BD patients, 13 were in a euthymic state and 4 were in a depressed state. Moreover, 14 out of the 17 BD patients had a BD type I diagnosis and 2 had a BD type II diagnosis. For one of the 17 BD patients, we did not have information on the type of BD, because he did not participate in the clinical interviews. His treating psychiatrist confirmed the diagnosis BD of this patient, so we included this patient in the final analysis. 

There was a group difference on age (  F  (2, 52) = 5.106,   p   = .009). Post-hoc   t  -tests showed that HCs were younger than BD patients (  p   = .002, mean difference in age = −11.34, 95% CI of the mean difference in age: −18.47 ~ −4.21). There was no significant difference in age between BD and SZ patients (  p   = .129) or between HCs and SZ patients (  p   = .123). 

Regarding the clinical measures, both patients with BD and SZ had higher QIDS-scores than HC, with no significant differences between them. Patients with BD and SZ also did not differ on YMRS-scores. In addition, SZ patients had higher PANSS-scores compared to BD patients (positive symptom score, negative symptom score and general psychopathology score). 


### Behavioural results 
  
For the self-serving bias ( ), a main effect of group was present (  F  (2, 52) = 10.021,   p   < .001): compared to HCs, both BD patients (  p   < .001, mean difference in self-serving bias = −9.43, 95% CI: −14.47~−4.38) and SZ patients (  p   < .001, mean difference in self-serving bias = −9.72, 95% CI: −14.77~−4.67) showed a reduced self-serving bias, indicating that patients with BD and SZ attributed more negative and less positive events to themselves. Patients with BD and SZ did not differ in self-serving bias (  p   = .91). Regarding the other-serving bias, no significant differences were seen (  p   = .22). RTs did not significantly differ among groups (  p   = .12).   
Behavioural results of bias value and reaction times for BD patients, SZ patients and HCs. 
    


### Neuroimaging results 
  
#### Main effects of task 
  
Visual inspection showed similar patterns of activation in the three groups (see  ). In HCs, the contrast self > semantic revealed activations in the VMPFC, DMPFC, ACC, PCC, precuneus, angular gyrus, supramarginal gyrus (SMG), inferior parietal lobule (IPL), cerebellum, superior parietal lobule (SPL) and postcentral gyrus. A similar pattern of activation as for self > semantic was seen for other > semantic. The contrast [(other > semantic) > (self > semantic)] revealed activation differences in the PCC, precuneus, and the cuneus, while the contrast [(self > semantic) > (other > semantic)] did not show any effect.   and Table S1 (see Supplementary material) summarize these task effects.   
Main task effects of brain activation during self > semantic in HCs (A), BD patients (C) and SZ patients (E); during other > semantic in HCs (B), BD patients (D) and SZ patients (F). 
  


#### Group comparisons 
  
When comparing BD patients to HCs, BD patients showed less activation in the PCC/precuneus during other > semantic ( ; peak MNI-coordinates: x = 2, y = −60, z = 22,   t   = 3.77, k = 128,   p   = .028 FWE corrected on cluster-level). There were no significant differences in other areas. In addition, no significant group differences were observed for the contrasts self > semantic, [(self > semantic) > (other > semantic)] and [(other > semantic) > (self > semantic)].   
Group comparison between HCs and BD patients for contrast other > semantic. BD patients show reduced activation in the PCC/precuneus compared to HCs. On the right, bar graph shows mean PCC/precuneus activation. Error bar = 1 S.D. *  p   < .05. 
  

Additionally, even though SZ patients displayed an intermediate level of activation in the PCC/precuneus between BD and HC during other-reflection (see  ), the difference between BD patients and SZ patients was not significant (  p   = .20). Nor did we detect significant differences between patients with BD and SZ on the other three contrasts. In addition, no significant differences were seen between SZ patients and HCs. 


#### Additional neuroimaging analyses 
  
The hypo-activation in the PCC/precuneus during other-reflection in BD patients remained significant after adding other-serving bias as covariate of no interest (peak MNI-coordinates: x = 2, y = −60, z = 22,   t   = 3.79, k = 124, and   p   = .03 FWE corrected on cluster-level). The lack of group difference during self-reflection was not changed by adding self-serving bias as covariate of no interest. Furthermore, no significant correlations were seen between the degree of activation in the PCC/precuneus cluster and scores on the SAI-E, BCIS, PANSS, YMRS, or QIDS (  p  s > .05). However, at a more liberal threshold (i.e. without multiple comparison correction), we found a positive correlation between the PCC/precuneus activation and the BCIS composite score (cognitive insight) in SZ patients (  r   = .508,   p   = .038), but not in BD patients (  r   = −.250,   p   = .35) (see  ). This apparent interaction was significant (  Z   = 2.124,   p   = .034).   
Correlation between the cognitive insight (BCIS composite score) and PCC/precuneus activation during other-reflection in patients with BD and SZ. A positive correlation is seen in SZ patients, but not in BD patients. 
  




## Discussion 
  
In the present study, our main aim was to investigate brain activation during self- and other-reflection in patients with bipolar disorder (BD) with a history of psychotic symptoms compared to healthy controls (HCs). In addition, we compared BD patients to patients with schizophrenia (SZ) to investigate whether observed abnormal activations were unique features of BD. Most importantly, BD patients showed less activation in the posterior cingulate cortex (PCC) extending to the precuneus during other-reflection compared to HCs. No significant differences were observed between BD and SZ patients, with SZ patients showing a level of activation in between BD patients and HCs. 

### Comparison between BD patients and HCs during other-reflection 
  
During other-reflection, hypo-activation in the PCC/precuneus was observed in BD patients compared to HCs, which was not induced by differences in activation in response to the semantic control condition (see Supplement material) or by behavioural performance during other-reflection. Moreover, since most participants were stable during scanning, the observed hypo-activation is likely irrespective of current residual psychotic, depressive and manic symptoms. Altogether, this suggests that the hypo-activation in the PCC/precuneus was due to differences of other-reflection per se rather than any other confounding factor. 

Both the PCC and precuneus have been shown to be important areas underlying autobiographical memory ( ;  ;  ). It has been suggested that autobiographical memory may play a critical role in self-reflective processing ( ), and also in other-reflective processing ( ). Indeed, according to the   self-reflection/self-appraisal model   ( ), the role of the PCC and precuneus during self- and other-reflection is associated with autobiographical memory processing. For the current results, it could be suggested that less activation in the PCC/precuneus reflects reduced integration between past and current information, and more specifically regarding to information about other people. In line with this suggestion, previous literature has shown that autobiographical memory is indeed impaired in BD patients, e.g. they provide less details during autobiographical memory recall than healthy individuals ( ;  ). 

In addition, the PCC is an important structure for emotional processing. For example,   have shown that healthy individuals have more activation in the PCC in response to both positive and negative words compared to neutral words. Interestingly, BD patients have shown a lack of PCC/precuneus activation during emotionally modulated cognitive processing (i.e. emotional Stroop task) ( ). In addition, it has been found that BD patients show reduced PCC activation during emotion regulation compared to HCs ( ). Combined with the role of the PCC/precuneus in autobiographical memory, we propose that the PCC/precuneus may be an interaction unit of processing emotional information and autobiographical memory. A recent study has indeed confirmed that the PCC and precuneus are activated during emotional autobiographical memory processing ( ). Therefore, it might be suggested that the hypo-activation in the PCC/precuneus during other-reflection in BD patients implies disturbed integration of emotional information and autobiographical memory related to a close other. This might result in inappropriate or inaccurate knowledge about the close other. 

This disturbed processing of close-other information might be related to disturbed social cognition (e.g. theory of mind) in BD patients, and hence disturbed social functioning. BD patients indeed have shown impairments in social cognition ( ;  ;  ). Interestingly, the PCC and precuneus have been shown to be involved during social cognition, for instance during theory of mind ( ;  ;  ), and processing of social-self (e.g. judging self with social-value traits, such as “am I intelligent”) ( ). We therefore postulate that less activation in the PCC/precuneus during other-reflection in BD patients might be related to the commonly observed impairments in social cognition. 


### Comparison between BD patients and HCs during self-reflection 
  
Concerning self-reflection, our behavioural results showed that BD patients attributed less positive sentences and more negative sentences to themselves compared to HCs (smaller self-serving bias). Nonetheless, we did not find any significant differences in neural activation during self-reflection. Several potential explanations could be suggested. One possible explanation is that the circuitry for self-reflection is not impaired in BD. Instead, the reduced self-serving bias in BD patients might be related to depressive realism, which can be the results of proper insight regarding their situation, such as less social support and stigma (for a review, see  ). Another possible explanation could be that neural abnormalities are valence-specific or opposed between different valences. Due to a limited number of negative sentences attributed to the self or other, we are unable to make any statements on the valence effects related to the neuroimaging findings. More studies are necessary to clarify these. 


### Comparison of SZ patients with BD patients and HCs 
  
In order to identify whether abnormal activation of the PCC/precuneus during other-reflection was specific for BD patients, we compared BD patients to SZ patients. The intermediate level of activation in the PCC/precuneus in SZ patients reported in the present study may imply that activation during other-reflection in SZ patients tends to be less abnormal than in BD patients. This is remarkable, because SZ patients in general perform worse than BD patients on tasks measuring cognitive performance (e.g. verbal memory, verbal fluency and verbal working memory;  ). Moreover, we also compared SZ patients with HCs in order to replicate previous findings, and no differences were seen. In previous studies to SZ, disturbances in brain activation during self- and other-reflection have been seen in different areas, including the medial prefrontal cortex (dorsal and ventral), ACC, precuneus, cuneus, PCC, angular gyrus, lingual gyrus, temporal gyrus (superior and inferior/middle) and insula ( ;  ;  ;  ;  ;  ). The reported abnormalities also differ on hypo- or hyper-activation. Thus, there are quite some inconsistent findings among previous studies. We think a selection bias could explain these results. We selected SZ patients matched on illness insight to the BD patients. BD patients with a history of psychotic symptoms were selected to represent the more severe BD patients. These BD patients were in general scanned during a euthymic period and had good insight. As such, the SZ patients also had good insight and might therefore represent a less severe group of SZ patients, with relatively preserved ability of reflective processing. This could lead to not finding differences between SZ and both BD and HC. This is underscored by the finding of a positive correlation between cognitive insight and PCC/precuneus activation in SZ patients, which indicates that a lower level of activation in the PCC/precuneus was related to worse insight in SZ. Some other factors such as sample size, control condition and illness state may also have contributed to this inconsistency with previous studies. 


### Correlations with insight 
  
Notably, we found a positive relationship between PCC/precuneus activation and cognitive insight in SZ patients, but not in BD patients. This differential pattern is remarkable, as patients with BD and SZ did not differ on cognitive insight at a group level. Caution is needed in interpreting this correlation, however, as it did not survive the correction for multiple comparisons. Nonetheless, it may serve as a heuristic for future research. Cognitive insight is defined as the ability to reflect on abnormal experiences and to correct incorrect interpretations ( ). The observed correlation might imply that better cognitive insight in SZ is associated with more retrieval of autobiographical memory during reflection on a close other. More information from autobiographical memory could be helpful for differentiating a close other to a larger extent from the self, from which SZ patients may benefit to re-evaluate and correct sensations coming from psychotic symptoms (e.g. hallucination). Because patients included in this study generally had a good level of insight, differences are not likely driven by considerable levels of cognitive impairments. The SZ patients had more severe psychotic symptoms than BD patients though. Better insight may be more important for normalizing metacognitive brain activation in SZ patients, but not in BD patients. Taken together, this finding of a difference in correlation with insight is interesting in terms of that the neural correlates underlying metacognition could differentiate between BD and SZ patients, which might help pave the way to further explore potentially distinguishing markers for BD and SZ. 


### Limitations 
  
There were some limitations of the current study. Firstly, most patients in our study were taking medication, which may have confounded our results. Psychotropic medication has been shown to have an ameliorative effect on functional abnormalities in BD patients ( ;  ). Because most of the BD patients in our study were stable during scanning, existing differences between BD and HC groups might have been obscured by the psychotropic medication. Secondly, our sample size was modest. However, it has been shown that a sample size of 16 has a kappa index around .62 ( ), which indicates substantial power for reproducibility (kappa index = .61–.80) ( ). In addition, our sample size was comparable to most of previous self- and other-reflection studies in SZ patients (with samples between 11 and 19 patients in five out of six studies, and one with a group of 47 SZ patients) ( ;  ;  ;  ;  ;  ). Thirdly, the age difference between groups could have influenced our results, but this was controlled for by adding age as covariate in the second level analyses. Although extremely difficult to perform, future research with larger, age matched samples, and medication naïve patients is needed to confirm and extend our results. Fourthly, the results of correlation with insight were observed without multiple comparisons correction. Fifthly, BD is characterized by emotional problems; therefore, it would be interesting to investigate the valence-specific difference in self- and other-reflection. However, the number of negative attributions was quite small in the present study. Therefore, we were not able to investigate the effect of valence on a neural level. Finally, BD patients in our study were mostly euthymic. Although one previous study with bipolar manic and depressive patients, including those with psychosis, has shown no, even reverse self-serving bias ( ), it would be interesting to explore the behavioural changes in self- and other-reflection in BD among Euthymia, past psychosis and current psychosis in one study. Future studies are needed to shed light on this. 



## Conclusions 
  
In conclusion, we observed less activation in the PCC extending to the precuneus during other-reflection in BD patients compared to HCs. BD patients did not differ in brain activation from SZ patients, and SZ patients showed a level of activation in the PCC/precuneus in between BD patients and HCs. This hypo-activation of the PCC/precuneus could contribute to a disturbance in coupling information from autobiographical memory and current other-related stimuli. This may be of relevance for the impairments in social cognition observed in patients with BD and SZ. Future studies may include an additional BD group without a history of psychosis to investigate whether the observed disturbance in our BD sample is related to psychosis. 


## Conflicts of interest 
  
None of the authors have commercial or other relationships that might pose a conflict of interest in connection with the present study. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-13'>
<h2>13. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/33039973/' target='_blank'>33039973</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Aberrant effective connectivity is associated with positive symptoms in first-episode schizophrenia</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Neuroimage Clin</p>
<p><strong>Publication Year:</strong> 2020</p>
<p><strong>DOI:</strong> 10.1016/j.nicl.2020.102444</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/7551359/' target='_blank'>7551359</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study using the HCP social cognition (Animated Triangles) paradigm (social-related processing). It includes a healthy adult control group (N=25) with results reported separately from first-episode schizophrenia patients. Analyses are whole-brain (SPM12, reporting FWE whole-brain corrected results and conjunction analyses), not ROI-only. Therefore it meets all inclusion criteria and violates none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>   Highlights  
  
We use DCM in patients newly diagnosed with schizophrenia. 
  
Patients were naïve to therapeutic antipsychotics, but not completely drug naïve. 
  
Patients have stronger feedforward connectivity than matched healthy controls. 
  
Stronger positive symptoms are associated with disinhibition in the temporal lobe. 
  
In active inference, this may relate to aberrant precision and prediction errors. 
  
  
Schizophrenia is a neurodevelopmental psychiatric disorder thought to result from synaptic dysfunction that affects distributed brain connectivity, rather than any particular brain region. While symptomatology is traditionally divided into positive and negative symptoms, abnormal social cognition is now recognized a key component of schizophrenia. Nonetheless, we are still lacking a mechanistic understanding of effective brain connectivity in schizophrenia during social cognition and how it relates to clinical symptomatology. To address this question, we used fMRI and dynamic causal modelling (DCM) to test for abnormal brain connectivity in twenty-four patients with first-episode schizophrenia (FES) compared to twenty-five matched controls performing the Human Connectome Project (HCP) social cognition paradigm. Patients had not received regular therapeutic antipsychotics, but were not completely drug naïve. Whilst patients were less accurate than controls in judging social stimuli from non-social stimuli, our results revealed an increase in feedforward connectivity from motion-sensitive V5 to posterior superior temporal sulcus (pSTS) in patients compared to matched controls. At the same time, patients with a higher degree of positive symptoms had more disinhibition within pSTS, a region computationally involved in social cognition. We interpret these findings the framework of active inference, where increased feedforward connectivity may encode aberrant prediction errors from V5 to pSTS and local disinhibition within pSTS may reflect aberrant encoding of the precision of cortical representations about social stimuli. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (39328 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Schizophrenia is a neurodevelopmental psychiatric disorder that affects about 1% of the population worldwide ( ). The symptoms of first-episode schizophrenia manifest across an age range from adolescence to early adulthood ( ). The highest incidence of first-episode schizophrenia is around age 22 ( ;  ), whereas early-onset schizophrenia (EOS) (age 14–18) is very rare, has a more severe prognosis and many EOS patients are rediagnosed later in life ( ,  ). While symptomatology is traditionally divided into positive and negative symptoms on the one hand, and cognitive deficits on the other, abnormal social cognition is recognized a key component of schizophrenia ( ). Recent research has shown that patients with high levels of both positive and negative symptoms, or negative symptoms alone, have more profound deficits in theory of mind compared to patients with only positive symptoms ( ,  ). While negative symptoms have been associated with hypo-mentalizing similar to autism ( ), positive symptoms have been associated with hyper-mentalizing, in particular delusions and paranoia ( ). Importantly, it has been suggested that patients with schizophrenia could be switching between hyper- and hypo-mentalizing, depending on social context ( ,  ). 

Theory of mind refers to the belief that other people have minds different from our own ( ). From a computational perspective, it is an agent’s ability to generate an internal model of another agent’s beliefs about the world. This internal model is necessary to explain other agents’ behavior in terms of their intentions, goals and desires ( ). Without a generative model of mental states to explain observed behavior, one wouldn’t know that a smile (behavior) is caused by happiness (mental state) or that tears can be happy or sad, depending on which theory of mind (model) we adopt. One of the most validated and widely used theory-of-mind tasks is the “Animated Triangles” task ( ,  ,  ). Brain mapping studies using fMRI have consistently associated theory of mind with increased activation of the posterior superior temporal sulcus (pSTS) and the medial prefrontal cortex ( ,  ). This paradigm has also been used to identify abnormal BOLD activation in patients with schizophrenia compared to healthy controls ( ,  ,  ,  ; A.  ). However, in contrast to healthy subjects with normal neurodevelopment, brain activation in patients with schizophrenia has been inconsistent. While Das   et al.   found reduced activation of the right superior temporal gyrus (STG), the temporo-parietal junction (TPJ) and bilateral inferior frontal gyri (IFG) in male patients with established schizophrenia ( ,  ), Martin   et al.   showed increased activation of bilateral IFG, left STG and left caudate nucleus ( ) in chronic, medicated patients. In contrast, Bliksted   et al.   found that largely drug-naïve first-episode schizophrenia (FES) patients hyper-mentalized during non-social stimuli, accompanied by increased activation of the anterior medial prefrontal cortex ( ). 

Schizophrenia is a neurodevelopmental disorder thought to emerge with synaptic dysfunction ( ,  ,  ). A variety of studies using non-invasive electrophysiology (EEG and MEG) have identified abnormal post-synaptic responses to both auditory stimuli ( ,  ,  ), visual stimuli ( ,  ,  ,  ) and tactile stimuli ( ,  ) in patients with schizophrenia compared to healthy controls. In addition to the abnormal neurophysiology that inherits from synaptic dysfunction, there is some evidence of widespread white-matter abnormalities that could impair axonal conduction between brain areas ( ,  ,  ). However, we are still lacking a mechanistic understanding of effective brain connectivity in patients with first-episode schizophrenia. 

To this end, we used functional magnetic resonance imaging (fMRI) and dynamic causal modelling (DCM) to test for abnormal brain connectivity in twenty-four patients with first-episode schizophrenia (FES) compared to twenty-five matched controls during the HCP social cognition paradigm ( ). First, we use Bayesian model reduction and parametric empirical Bayes (PEB) ( ) to test for aberrant feedforward, feedback and intrinsic (inhibitory) connectivity in FES patients. Finally, we use PEB and Bayesian model comparison to test how these connectivity estimates are differentially related to positive and negative symptomatology. 


## Material and methods 
  
### Patients 
  
We initially recruited 31 patients from the OPUS Clinic, a first-episode schizophrenia clinic at Aarhus University Hospital, Aarhus, Denmark. While each patient met the ICD-10 criteria for schizophrenia, they had no history of neurological disorder or severe head trauma according to ICD-10, nor did they have an ICD-10 diagnosis of drug- or alcohol dependency. Patients were excluded if they had an estimated premorbid IQ < 70 based on their history or if they were not able to understand spoken Danish sufficiently well to comprehend the testing procedures. Seven patients were excluded from the fMRI experiment due to dental braces (N = 3), pregnancy (N = 1) and several no-shows (N = 3). Finally, 24 first-episode patients were included in the fMRI experiment. Given that our patients were newly diagnosed, most of them did not receive regular doses of antipsychotic medication at a therapeutic level that could be converted to standard chlorpromazine equivalents ( ). Some of the patients received their initial depot injection a few days before the MRI scan, so that a stable, therapeutic concentration was not yet expected. Other patients only agreed to take very low doses of antipsychotics used as an   ad hoc   sedative in order to fall asleep (e.g. 25 mg Quetiapine, where 750 mg is the expected clinical antipsychotic dose). See   for a summary of the patients' medication history.   
Medication history of first-episode schizophrenia patients. 
      
Demographics, psychopathology, IQ, and social cognition. 
      


### Healthy controls 
  
We initially recruited 29 healthy controls. Exclusion criteria were the same as for the patients, except that controls were excluded if they or a first-degree relative had an ICD-10 diagnosis, or if a diagnosis was confirmed during the Present State Examination (PSE) interview (ICD-10, WHO). Four controls were excluded from the fMRI experiment on the day of scanning: two had dental braces and two left the study prematurely. FES patients and healthy controls were intended matched on age, gender, educational level (last commenced education), and parental socioeconomic status (SES). However, we did not succeed completely with this strategy, so the two groups ended up being matched on a group level. Finally, 25 healthy controls were included in the fMRI study. 


### Psychopathology and social functioning 
  
First-episode schizophrenia patients were interviewed by a psychiatrist with the Present State Examination interview regarding schizophrenia and drug dependency ( ). All FES patients and healthy controls were rated with the Scale for the Assessment of Negative symptoms (SANS) and the Scale for the Assessment of Positive Symptoms (SAPS) ( ,  ). Level of psychosocial functioning was measured using the Global Assessment of Functioning (GAF-F) ( ) and the Personal and Social Performance Scale (PSP) ( ). 


### Intelligence and social cognition 
  
We estimated intelligence using two subtests from the Wechsler Adult Intelligence Scale (WAIS-III) ( ). The two subtests were chosen based on their high correlation with the total WAIS-III IQ-score: Block Design and Vocabulary. Theory of mind ability was evaluated diagnostically using the “Animated Triangles” task ( ). In the “random” condition, the triangles move randomly about. In the “theory of mind” condition, the animated triangles move in a coordinated fashion that resembles a social interaction, a scenario that normally developing individuals consistently explain using theory of mind ( ). There are four clips of each type of animation with 38–41 s duration. After each animation, the participants were asked to describe what they thought was happening and their answers were scored regarding degree of mental state attribution (range 0–5) and appropriateness of their description (range 0–3) as outlined in Appendix 2 of ( ). Each answer was scored by two clinical psychologists (LV and VB) and the ordinal scores were summed within category for statistical analysis. Using the Mann-Whitney   U   test, we then tested for differences in the distribution of scores between patients with schizophrenia and healthy controls. Intraclass correlation (ICC) in a two-way random-effects model showed absolute agreement of intentionality scores in the “random” condition (ICC = 0.97, 95% CI (0.93; 0.99),   P   < 0.0001) and the “theory of mind” condition (ICC = 0.96 95% CI (0.89; 0.98),   P   < 0.001) and absolute agreement of appropriateness scores in the “random” condition (ICC = 0.97, 95% CI (0.92; 0.99),   P   < 0.001) and the “theory of mind” condition (ICC = 0.96, 95% CI (0.91; 0.98),   P   < 0.001) among the two ratings. 


### fMRI paradigm 
  
To test for abnormal brain connectivity during social cognition, we used the social cognition paradigm from the Human Connectome Project (HCP) ( ) with permission from the WU-Minn HCP consortium (  http://www.humanconnectome.org/  ). Visual stimuli consist of animated sequences of 20 s duration showing geometric shapes (triangles, squares and circles) that move about in either a coordinated fashion that resembles a social interaction among individuals (social motion) or in a random fashion (non-social motion). Participants were presented with 10 sequences of social scenarios and 10 sequences of non-social scenarios in randomized order. After each stimulus sequence, participants were asked whether they had perceived a social interaction, answering ‘yes’ with their right index finger or ‘no’ with their right middle finger. The response period lasted 3 s. The paradigm was presented with E-prime 2.0 (Psychology Software Tools, Inc.) and projected onto a screen at the back of the MRI bore that participants viewed through a mirror mounted on top of the radio frequency coil. Each block of stimulus and response was followed by 15 s of visual fixation (see  ).   
Judgment of social versus non-social stimuli (A) Social cognition paradigm (B) Response times with 95% confidence intervals (C) Judgment accuracy with 95% confidence intervals: patients with schizophrenia were less accurate in detecting social scenarios than healthy controls, with no consistent difference between groups when judging non-social scenarios. 
  


### Ethics statement 
  
All participants received written and verbal information about the project and a written informed consent was obtained before inclusion. The study was approved by the Central Denmark Region Committee on Health Research Ethics (Ref: 1–16-02–87-15) and the Danish Data Protection Agency. The project complied with the Helsinki-II-declaration. 


### fMRI acquisition 
  
T2*-weighted echo planar images (EPI) were acquired on a 3 T Siemens Magnetom Trio using a 32-channel RF head coil at the Center of Functionally Integrative Neuroscience, Aarhus University, Denmark. Each volume consisted of 40 slices with 3 mm thickness acquired in descending order with repetition time (TR) = 2 sec, echo time (TE) = 27 ms, flip angle = 90°, field of view (FOV) = 192 × 192 mm and in-plane resolution = 64 × 64. The subjects’ head was fixated with soft cushions to minimize head movement during the experiment. 


### fMRI analysis 
  
fMRI data were analyzed using Statistical Parametric Mapping (SPM12, revision 6906). Echo-planar (EPI) images were resampled to 2 mm  voxels, realigned within subject and spatially normalized to MNI space using the ICBM template of European brains. The time-series were high-pass filtered at 1/128 s using a discrete cosine set and temporal correlations were modelled using a first-order autoregressive (AR(1)) model. Social and non-social motion conditions were modelled as boxcar regressors convolved with a canonical HRF and fitted to the BOLD time-series using a general linear model ( ). Visual fixation periods were not modelled and hence constituted an implicit baseline. Finally, the scan-to-scan realignment parameters (translations and rotations) were included in the GLM to adjust for the effects of head movement. Head movement did not differ between patients and healthy controls (RMS displacement:   F  (1, 47) = 0.54,   p   = 0.47). We created contrast images for each patient and control testing for visual motion in general (both social and non-social versus fixation) and the difference in activation between social and non-social stimuli. Finally, contrast images were smoothed with a 6-mm FWHM Gaussian kernel and used as summary statistics in a random-effects analysis using one-sample   t  -tests within patients and controls, separately. To identify regions active both during the perception of visual motion in general and during social motion in particular, we used a conjunction analysis to test for a conjunction of   t  -tests (global null). This corresponds to masking one significant contrast with another to identify an overlap of significant activations ( ). We thus tested for visual motion in general (conjunction) and for social compared to non-social stimuli to identify effects in each group separately, differences between groups and, finally, commonalities across groups. All statistical tests were thresholded at   p   < 0.05, family-wise error (FWE) whole-brain corrected for multiple comparisons using random field theory ( ). 


### Dynamic causal modelling of effective connectivity 
  
We used a two-state dynamic causal model (DCM) for fMRI (DCM12, revision 6755) to estimate the effective connectivity within and between brain areas, given observed haemodynamic measurements ( ). While one-state DCM for fMRI is used to model extrinsic connections only, two-state DCM models both extrinsic connections between regions as excitatory forward and backward connections and intrinsic connectivity within each region in terms of one inhibitory population and one excitatory population of neurons. This allows us to model the intrinsic connectivity within each cortical area as an increase or decrease in cortical inhibition ( ). We summarised the BOLD signal in each participant using the first eigenvariate (principal component) of voxels within a sphere of 8 mm radius centred on each participant’s local maximum. This subject-specific local maximum was identified within a sphere of 20 mm radius centred on the peak of the group effect. The network derived empirically from the group-level fMRI result comprised motion-sensitive area V5 and posterior superior temporal sulcus p(STS) in the right hemisphere (see  .). The hemodynamic responses to all visual motion (social and non-social stimuli) were mean-centred and modelled as a driving input to area V5 (C-matrix). Using parametric modulation of the regressor encoding all visual motion, the responses to social compared to non-social stimuli were modelled as a modulation (increase or decrease) of the intrinsic and extrinsic connection strengths (B-matrix) in relation to the average connectivity estimated from the mean-centred responses to all visual motion (A-matrix).   
Brain mapping commonalities among patients and controls: difference between social and non-social stimuli in regions that were also activated by visual motion in general (conjunction analysis). 
    

We analysed the intrinsic and extrinsic connectivity between V5 and pSTS under four alternative hypotheses (see   for a schematic). The first hypothesis was formulated as a full DCM where (1) both extrinsic connections between V5 and pSTS and intrinsic connections within V5 and pSTS encode the differences between experimental conditions. The second hypothesis was formulated as a reduced model where (2) only extrinsic connections between V5 and pSTS encode the differences between experimental conditions. The third hypothesis was formulated as a reduced model where (3) only the feedforward connection from V5 and pSTS encodes the differences between experimental conditions. Finally, a null model encoded the belief that (4) no connections change between conditions. 


### Bayesian model inversion 
  
We then inverted the full dynamic causal model encoding the first hypothesis for each patient and control using variational Laplace ( ). This provides both the posterior distribution of the connection strengths and the free-energy approximation to the marginal likelihood of the model itself, known as the model evidence. The free parameters and the Bayesian model evidence of each reduced model were then estimated using Bayesian model reduction under the Laplace assumption ( ). 

In variational Laplace, the conditional expectations and covariance of the (multivariate) approximate posterior distribution   are estimated iteratively by maximizing a lower bound on the logarithm of the model evidence  . This optimization uses Fisher scoring to maximize the (negative) variational free energy   of the model 

where   is the expectation under the approximate posterior density   and   is the Kullback-Leibner divergence between the approximate posterior and prior probability densities. To understand why the free energy is useful for model comparison, we can decompose it into accuracy and complexity terms. The accuracy is the expected log-likelihood of the data, given the model parameters, and scores the goodness-of-fit of a model. The complexity penalises models that overfit the data by favouring models with low posterior correlation among the parameters. In other words, the free energy penalizes models with high parameter redundancy. The formulation of the complexity as a KL divergence rests on the assumption that the posterior density should not have to move too far from the prior to accommodate the data. 


### Parametric empirical Bayesian (PEB) analysis of group effects 
  
Having estimated the connection strengths and model evidence at the first level, we then used parametric empirical Bayes (PEB) to identify increases or decreases in connection strengths at the group level. PEB is a hierarchical Bayesian model in which empirical priors on the connection strengths at the single-subject level are estimated empirically using a Bayesian general linear model at the group level ( ). Unlike classical inference such as ANOVA, this hierarchical Bayesian model allows us to identify commonalities and differences in connection strengths at the group level, taking into account not only the mean of parameter estimates at the single-subject level, but also their variance. This means that subjects with more precise parameter estimates have greater influence on group-level parameters, whereas subjects whose parameters are surrounded by more uncertainty are down-weighted ( ). The advantage of parametric empirical Bayes is that it provides both the posterior distribution of the connection strengths at the group level and the marginal likelihood or Bayesian model evidence of the PEB model itself for Bayesian model comparison of alternative hypotheses. We then compared our alternative hypotheses using both random-effects Bayesian model selection ( ,  ) of dynamic causal models at the single-subject level and fixed-effects Bayesian model comparison of PEB-DCMs at the group level. 

Finally, we used Bayesian model comparison of PEB models to adjudicate between two alternative hypotheses about the relation between effective connectivity and clinical symptomatology using Bayesian linear regression. In this way, we are able to disambiguate between positive and negative symptoms as the best explanation of patient variability in synaptic efficacy. Normally, one would include medication dose for antipsychotics as a nuisance regressor in the regression model. However, given that all patients were newly diagnosed and did not yet receive standard antipsychotic treatment at a therapeutic level, conversion of their heterogeneous medication to standard chlorpromazine equivalents was not feasible ( ). Hence, we were not able to reliably adjust the regression models of positive and negative symptoms for standard doses of antipsychotics. 


### Software note 
  
The scripts used to reproduce the original results are available from   https://github.com/martinjdietz/Publications/tree/master/NICL-2020  . 



## Results 
  
### Demographics, psychopathology, intelligence, and social cognition 
  
Given that patients and controls were matched with regard to age, gender, educational level (last commenced education), and parental socioeconomic status (SES), we did not observe differences between groups in estimated IQ and, to our surprise, no differences in social cognition ( ). 


### Behavioural results of fMRI paradigm 
  
We first analysed response times within healthy controls and FES patients separately. Healthy controls were slower when judging social compared to non-social stimuli (  t  (24) = 2.26,   p   = 0.01, Cohen’s   d   = 0.41, two-tailed   t  -test). In contrast, FES patients showed no difference in response times when judging between social and non-social stimuli (  t  (23) = -0.35,   p   = 0.7, two-tailed   t  -test). We then compared response times between patients and healthy controls. There was no evidence of a difference between groups for social stimuli (  t  (47) = -0.25,   p   = 0.8, two-tailed   t  -test), nor for non-social stimuli (  t  (47) = -1.6,   p   = 0.1, two-tailed   t  -test). 

We then tested for a difference in task accuracy using McNemar’s   Chi  -test. This tests for a difference in proportions of accurately judged scenarios within each group separately. Neither healthy controls (  Chi  (1) = 1.08,   p   = 0.3), nor patients with schizophrenia (  Chi  (1) = 0.03,   p   = 0.9) showed evidence of a difference in judgment accuracy between social and non-social stimuli. We then tested for a difference in judgment accuracy between patients and controls using Pearson’s   Chi  -test. This revealed that healthy controls were more accurate in judging social motion than patients with schizophrenia (  Chi  (1) = 4.2,   p   = 0.04, Cramer’s   phi   = 0.09). In contrast, there was no evidence of a difference in accuracy between patients and controls when judging non-social motion (  Chi  (1) = 2,   p   = 0.2). 


### fMRI brain mapping in healthy controls 
  
When healthy controls perceived motion in general (social and non-social) they had increased activation in motion-sensitive area V5 in the right hemisphere with peak at MNI coordinate [44–70 −2],   T  (24) = 17.41,   P   < 0.0001, as well as V5 in the left hemisphere with peak at MNI coordinate [-44–72 −10],   T  (24) = 13.42,   P   < 0.0001. We also observed increased activation in the left superior parietal lobule (SPL) with peak at MNI coordinate [-30–50 56],   T  (24) = 7.69,   P   < 0.0001. In contrast, when healthy controls perceived social motion compared to non-social motion, they had increased activation in posterior inferior temporal gyrus with peak at MNI coordinate [48–50 −18],   T  (24) = 11.40,   P   < 0.0001 and posterior superior temporal sulcus (pSTS) with peak at MNI coordinate [56–46 20],   T  (24) = 9.40,   P   < 0.0001 ( ).   
fMRI brain mapping in healthy controls and FES patients (A) Visual motion in healthy controls (B) Visual motion in patients with schizophrenia (C) Social > non-social stimuli in healthy controls (D) Social > non-social stimuli in patients with schizophrenia. Statistical   t  -maps are thresholded at   p   < 0.05, FWE-corrected for multiple comparisons and rendered on a single-subject structural MRI in MNI space. See main text for MNI coordinates. 
    
Alternative hypotheses about effective connectivity in patients with first-episode schizophrenia (A) Full model with free parameters on extrinsic and intrinsic connections (B) Reduced model with free parameters on extrinsic connections (C) Reduced model with a free parameter the on feedforwards connection only (D) Null model with no connections between V5 and pSTS. 
  


### fMRI brain mapping in patients with first-episode schizophrenia 
  
When patients with first-episode schizophrenia perceived motion in general (social and non-social) they had increased activation in motion-sensitive area V5 in the right hemisphere with peak at MNI coordinate [38–80 4],   T  (23) = 13.40,   P   < 0.0001, as well as V5 in the left hemisphere with peak at MNI coordinate [-48–72 0],   T  (23) = 15.45,   P   < 0.0001. We also observed increased activation in the right superior parietal lobule (SPL) with peak at MNI coordinate [10–58 60],   T  (23) = 7.24,   P   < 0.0001. In contrast, when patients perceived social compared to non-social stimuli, they had increased activation in posterior inferior temporal gyrus with peak at MNI coordinate [46–52 −14],   T  (23) = 9.30,   P   < 0.0001 and posterior superior temporal sulcus (pSTS) with peak at MNI coordinate [54–42 12],   T  (23) = 8.05,   P   < 0.002. We also observed increased activation in area V4 in right inferior occipital gyrus with peak at MNI coordinate [30–92 −2],   T  (23) = 10.96,   P   < 0.0001. There were no differences in BOLD amplitude between patients and controls at a standard family-wise error rate of   P   < 0.05 ( ). 


### Brain mapping commonalities among patients and controls 
  
We then used a conjunction analysis to identify regions active both during the perception of visual motion in general (social and non-social) as well as during social motion in particular (social minus non-social) in both patients and controls. This revealed two main clusters in the right hemisphere centred on motion-sensitive area V5 and the posterior superior temporal sulcus (pSTS) summarized in  . Importantly, the activation of the pSTS during social motion conforms to the anatomical findings in the literature ( ). The time-series in these two regions, common to both patients and controls, were then used for dynamic causal modelling. 


### Effective connectivity between V5 and pSTS in healthy controls 
  
Using dynamic causal modelling (DCM) and parametric empirical Bayes (PEB), we analysed the strength of extrinsic connectivity between V5 and pSTS in the right hemisphere, as well as inhibitory connectivity within each area. While the responses to motion in general were modelled as a driving input to V5, the responses to social versus non-social stimuli were modelled as a modulation (increase or decrease) of the intrinsic and extrinsic connection strengths and hence constituted the experimental effects-of-interest. Random-effects Bayesian model comparison of DCMs ( ) revealed that the cortical network with changes in both extrinsic and intrinsic connections had the highest posterior probability in healthy controls (Posterior model probability > 0.85 and protected exceedance probability > 0.99). This was confirmed by a Bayesian model comparison of the PEB models at the group level (Posterior model probability > 0.99). Within this network, healthy controls had an increase in feedforward connectivity from V5 to pSTS (Posterior probability > 0.99) and a decrease in feedback connectivity (Posterior probability > 0.99). At the same time, there was a decrease in intrinsic (inhibitory) coupling within V5 (Posterior probability > 0.99) and a concomitant increase in intrinsic (inhibitory) coupling within pSTS (Posterior probability > 0.99) ( ).   
Pathophysiology in first-episode schizophrenia compared to healthy controls (A) Bayesian model comparison of PEB models (2nd-level models) and random-effects Bayesian model comparison of DCMs (1st-level models) (B) Dynamic causal model showing stronger feedforward connectivity in patients compared to healthy controls (C) Connection strengths in patients with first-episode schizophrenia during social > non-social stimuli and (D) connection strengths in healthy controls. 
  


### Aberrant effective connectivity in patients with schizophrenia compared to healthy controls 
  
Using parametric empirical Bayes (PEB), we then tested for differences in the strength of extrinsic and intrinsic connectivity between patients with schizophrenia and healthy controls. Again, random-effects Bayesian model comparison of DCMs ( ) revealed that the full model had the highest posterior probability across patients and controls (Posterior probability > 0.89 and protected exceedance probability > 0.999). This was confirmed by a Bayesian model comparison of PEB models at the group level (Posterior probability > 0.99). Within this network, patients had increased feedforward connectivity when they perceived social stimuli compared to the healthy controls (Posterior probability > 0.97) ( ). 


### Patients with stronger positive symptoms have more disinhibition within pSTS 
  
We then tested for an association between psychopathology and effective connectivity in patients during social stimuli compared to non-social stimuli. Using parametric empirical Bayes (PEB), we compared the model evidence of a PEB-DCM with connection strengths explained by positive symptoms to the model evidence of a PEB-DCM explained by negative symptoms. Bayesian model comparison showed that between-patient differences in effective connectivity were better explained by their positive symptoms than by their negative symptoms. Inspection of the PEB model revealed that patients who reported a higher degree of positive symptoms had reduced intrinsic (inhibitory) coupling within a dynamic causal model of the posterior superior temporal sulcus (Posterior probability > 0.99). In other words, patients with more positive symptoms had more disinhibition within posterior superior temporal sulcus (pSTS) ( ).   
Intrinsic connectivity associated with positive symptoms in first-episode schizophrenia (A) Bayesian model comparison of PEB models of clinical symptomatology, showing that positive symptoms are a better explanation of individual differences in effective connectivity than negative symptoms in this patient sample (B) Patients with stronger positive symptoms (SAPS score) had more disinhibition within a DCM of pSTS. 
  



## Discussion 
  
### High-functioning FES patients have aberrant brain connectivity 
  
In this study, we used DCM for fMRI to test for differences in effective connectivity between patients with first-episode schizophrenia and healthy matched controls during the HCP social cognition paradigm ( ). This allowed us to identify pathophysiological differences in the feedforward and intrinsic connectivity in patients compared to controls. The behavioral results summarized in   suggest that these first-episode patients were high-functioning in relation to previous studies, where patients with schizophrenia typically performed 1–2 standard deviations below healthy controls on cognitive and social cognition tasks ( ,  ,  ,  ,  ,  ). This might be due to a short duration of illness, combined with a successful match of FES patients and controls. Despite their high level of functioning, our DCM results show aberrant brain connectivity in relation to healthy matched controls. Moreover, our results point to an association between cortical inhibition within the posterior superior temporal sulcus (pSTS) and the severity of positive symptoms in first-episode patients. Recent studies have shown differences in pSTS activation and functional connectivity with prefrontal cortex between patients with schizophrenia and healthy controls during different social perception paradigms ( ,  ,  ,  ,  ). In line with our finding, Backash et al. showed an association between pSTS activation and delusional (positive) symptoms ( ). However, in contrast to these previous studies, we show an association between psychopathology and brain function using a biophysical model of the underlying neuronal activity, as opposed to the level of observed BOLD responses. 


### Active inference and failures of social inference 
  
Computational theories of the brain that describe neuronal connectivity as a process of Bayesian inference are becoming increasingly useful for a mechanistic understanding of perception and action ( ). In the context of social cognition, active inference offers a natural way to understand theory of mind as inferring the hidden states of another agent’s intentions, given their observed behavior ( ). Crucially, this inference rests on a generative model of the mental states that cause a particular social behavior. For an agent to successfully engage in social communication, this generative model must be able to account for both the social behavior of other agents and one’s own behavior. In other word, one must model the behavior caused by other agents and the behavior caused by oneself and as being generated by the same model of intentions ( ). We here provide an account of abnormal social cognition in terms of aberrant encoding of precision within a generative model of intentions or mental states. 

In active inference, perception corresponds to inferring the hidden states in the world that cause sensory observations. These states are hidden in the sense that the world can only be observed through noisy sensory inputs. In order to infer the (hidden) mental states of other agents that cause a particular social behavior, the brain must have a generative model that combines prior beliefs about plausible mental states with the likelihood of observing a particular behavior to form posterior beliefs (theory of mind). These probabilistic beliefs are encoded in terms of their expectation and precision. Precision is simply the inverse variance or uncertainty with which the brain represents the external world. It follows from the form of this generative model that the brain must minimize the surprise   about sensory observations   at any one time, given a particular model   m   or explanation of those sensations. However, as computing surprise itself is mathematically intractable, a plausible solution is that the brain minimizes an upper bound on surprise known as variational free energy ( ). 

Feedback connections are thought to encode an agent’s internal predictions about hidden states in the external world, such as one’s beliefs about the mental states of other agents that constitute theory of mind ( ). By contrast, feedforward connections mediate the ensuing prediction errors that are inconsistent with these predictions, given current sensory observations. The key imperative of active inference is to reduce uncertainty within the brain’s generative model of the world by actively sampling parts of the sensorium that require sensory interrogation ( ). When exposed to social stimuli, the influence of prediction errors on posterior beliefs (social inference) is controlled by their relative precision or confidence. Our results show that patients were less accurate in detecting social scenarios than healthy controls. At the same time, patients had increased feedforward connectivity from V5 to pSTS during these social stimuli compared to controls. This increased level of feedforward connectivity may be compensatory in nature and reflect a state where prediction errors are weighted by an abnormally high level of precision during visual stimuli. This fits well with theories proposing that schizophrenia is associated with abnormally high levels of prediction error during perceptual inference ( ). Our interpretation is that there is a failure to integrate the social information carried by prediction errors into a patient’s generative model of mental states that constitutes their theory of mind. In other words, there is an impairment in the way sensory information used to resolve uncertainty about the world during active sampling. Psychologically, this failure to resolve uncertainty about the world would result in a misinterpretation of social cues that may be understood as hypo-mentalizing ( ). This interpretation is entirely supported by our finding that patients were less accurate in detecting social scenarios than healthy controls. 

Neurobiologically, a developmental dysfunction of synaptic efficacy has been proposed as a likely disease mechanism in schizophrenia ( ). Specifically, a dysfunction of the glutamatergic   N  -methyl-  D  -aspartate (NMDA) receptor expressed at both excitatory pyramidal cells and GABAergic inhibitory interneurons ( ) has been proposed to play a central role in the generation of perceptual, cognitive and psychotic symptoms ( ,  ,  ,  ). Evidence from non-invasive electrophysiology in humans has been reported by Schmidt et al. who observed an increase in feedforward connectivity within the auditory system ( ) and Rosch et al. who observed a selective disinhibition within the superior temporal gyrus, both under NMDA-receptor blockade with ketamine ( ). Similar findings under pharmacological manipulation of NMDA-receptor function have been linked to psychosis ( ,  ,  ). Finally, Backash et al. who showed an association between pSTS activation and delusional (positive) symptoms ( ). Our finding of more disinhibition within pSTS in patients with positive symptoms concurs with these studies and adds to the evidence that psychosis may associated with an abnormal balance of excitation and inhibition ( ,  ). 


### Replicability and future research 
  
Our reasons for using the HCP social cognition paradigm are twofold. First, it allowed us to replicate previous findings in the typical brain ( ) using the exact same paradigm. Replicability in the normal population is valuable because it adds to the construct validity of our findings. Second, it allowed us to test for aberrant pathophysiology in a patient cohort using a standardized paradigm. Sharing of standardized stimulus paradigms and data analysis pipelines is essential for the replicability of neuroimaging findings in new datasets from both healthy and clinical cohorts across independent research sites. We are currently planning more research integrating fMRI with MEG and EEG in order to identify both differences and commonalities in pathophysiology across different subgroups of patients with schizophrenia, ranging from children at genetic risk of developing schizophrenia to first-episode patients. 



## Funding statement 
  
This work was supported by “Seed Money” from the Interacting Minds Center, Aarhus University. MJD was funded by VELUX FONDEN [00013930]. 


## CRediT authorship contribution statement 
  
 Martin J. Dietz:   Conceptualization, Investigation, Methodology, Formal analysis, Visualization, Writing - original draft, Writing - review & editing.   Yuan Zhou:   Conceptualization.   Lotte Veddum:   Investigation, Formal analysis.   Christopher D. Frith:   Conceptualization, Supervision.   Vibeke F. Bliksted:   Conceptualization, Investigation, Resources, Formal analysis, Project administration, Writing - original draft, Writing - review & editing. 


## Declaration of Competing Interest 
  
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-14'>
<h2>14. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/28169323/' target='_blank'>28169323</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Social pain and social gain in the adolescent brain: A common neural circuitry underlying both positive and negative social evaluation</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Sci Rep</p>
<p><strong>Publication Year:</strong> 2017</p>
<p><strong>DOI:</strong> 10.1038/srep42010</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5294419/' target='_blank'>5294419</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI whole-brain study of social evaluation (Social Feedback Task) in a sample of healthy adolescents/young adults (N=56; age range 17–20). The task probes social-related processes (social inclusion/exclusion, social evaluation), and analyses report whole-brain results using conservative FWE correction (not ROI-only). Participants were screened to exclude current Axis I disorders and results for the healthy group are reported separately. All inclusion criteria are met and no exclusion criteria apply. Therefore the study should be included in the meta-analysis of fMRI studies of social processing in healthy adults (ages 17–65).</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Social interaction inherently involves the subjective evaluation of cues salient to social inclusion and exclusion. Testifying to the importance of such social cues, parts of the neural system dedicated to the detection of physical pain, the dorsal anterior cingulate cortex (dACC) and anterior insula (AI), have been shown to be equally sensitive to the detection of social pain experienced after social exclusion. However, recent work suggests that this dACC-AI matrix may index   any   socially pertinent information. We directly tested the hypothesis that the dACC-AI would respond to cues of   both   inclusion and exclusion, using a novel social feedback fMRI paradigm in a population-derived sample of adolescents. We show that the dACC and left AI are commonly activated by feedback cues of inclusion and exclusion. Our findings suggest that theoretical accounts of the dACC-AI network as a neural alarm system restricted within the social domain to the processing of signals of exclusion require significant revision. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (27902 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
Humans are fundamentally social. We create and reside within a diversity of emergent social systems ranging from couples, families, and groups to cities, countries and civilizations. These social structures have evolved in tandem with biological and psychological mechanisms that support social behavior, and the consequent rich capacity for social interaction has enabled humans to survive, reproduce, and flourish. Central among these mechanisms is the ability to detect and respond to diverse signals of social inclusion and social exclusion – behavioral dynamics that are critical to the establishment and maintenance of relationships, groups and social hierarchies. Indeed, acceptance by our desired social partners is so fundamental that social exclusion has profound negative consequences for affect, health and well-being  and is particularly toxic during adolescence . 

There is burgeoning evidence to indicate that the mental ‘pain’ described by those experiencing such exclusion is more than just a metaphor. Brain imaging data suggest that the neural response to social rejection co-opts components of the well-established physical pain signature in the brain . Cues of rejection have reliably been shown to activate a network of so-called ‘social pain’ regions that overlaps with the neural response to nociceptive stimulation and primarily includes the dorsal anterior-cingulate-cortex (dACC) and the anterior insula (AI) . This account has been extended to suggest that the dACC in particular is involved in domain-general processing of pain information as it pertains to survival-relevant goal conflicts such as hunger or thirst and that social exclusion represents just one form of such survival threat . 

However, recent neuroimaging investigations within the social domain, have raised interesting questions about this social pain account of dACC-AI functioning . For example, multi-level kernel density meta-analyses  of the two prototypical social rejection paradigms used in neuroimaging studies – Cyberball (in which participants are excluded in a virtual ball-tossing game), and the reliving of memories of romantic rejection – have provided equivocal support for the claim that rejection activates the same neural matrix identified in studies of physical pain. Consistent with this, multivariate functional magnetic resonance imaging (fMRI) pattern analyses suggest that separate neural representations code physical pain and mental pain within this identified shared network . Parallel to this, some have argued the broad dACC-AI overlap between social pain and physical pain can be simply explained as salience, and hence trigger multimodal cognitive processes involved in detecting, orienting attention towards, and/or reacting to salient events . 

An alternative possibility is that this pattern of dACC-AI co-activation emergent from the social exclusion literature is not simply a form of ‘pain’, but instead a more sophisticated index of the social dynamic . One compelling candidate is that this network operates as a gauge of social inclusivity, a form of sociometer . If true, then this system would subserve the processing of any signal that provides salient information about social inclusivity, whether it indexes social pain or ‘social gain’. 

We therefore investigated the hypothesis that the dACC-AI matrix prototypically identified in studies of social rejection is in fact critically involved in processing signals of   both   social pain and social gain. We used a novel Social Feedback fMRI task that provides participants with comparably intense signals pertaining to either social exclusion or social inclusion, within the same paradigm, thus allowing us to identify their common and discrete neural substrates. 

Participants believed that they were competing with other contestants in a multi-round game. Participants were told that: at the end of each round, one contestant is excluded from the game while the others are included in the next round; each round involves each contestant individually performing a social task and performance is evaluated by a panel of judges; that these ratings form the basis of the inclusion/exclusion decisions; and that the game is played in a hyperscanning context  where each contestant is in a separate MRI scanner. In fact the judges and other contestants were confederates, only the participants were in a scanner, and only one round of the game, comprising our Social Feedback Task ( ; see also  ), was ever played. 

## Results 
  
Our results showed that participants rated negative social feedback as more upsetting than neutral feedback (  t   = 12.6, df = 55, p < 0.001) and positive feedback as less upsetting than neutral (  t   = 13.5, df = 55, p < 0.001), as expected ( ). Consistent with the social pain literature , the fMRI data (all whole brain,   p   < 0.05, FWE corrected) revealed greater activation in the bilateral dACC and left AI when receiving negative compared to neutral social feedback ( ). Critically, however, these same regions were also activated when receiving positive (relative to neutral) social feedback, along with the ventromedial prefrontal cortex (vmPFC) and ventral striatum bilaterally ( ). In fact, there were no regions that were significantly more activated for negative social feedback relative to positive (negative > positive contrast), even when we explored the data using lower activation thresholds (  p   < 0.005, uncorrected). Furthermore, the reverse contrast (positive > negative) simply revealed activations in the aforementioned ventral striatum and vmPFC regions, areas traditionally associated with reward processing ( )  ( ). These findings indicate that a common dACC-AI network subsumes the processing of information pertaining to both social exclusion and social inclusion. 

This was supported by a logical ‘AND’ conjunction analysis  of ‘negative > neutral social feedback ( )’ AND ‘positive > neutral social feedback ( )’, which revealed clusters in the left AI (peak voxel x = −28, y = 18, z = −10) and the dACC (peak voxel x = 2, y = 32, z = 24) that were significantly active across both conditions (whole brain   p   < 0.05, FWE corrected;  ). The conjunction contrast was masked inclusively using the contrasts ‘positive feedback > baseline’ and ‘negative feedback > baseline’ (see  ) to ensure activation was not a product of the neutral condition, though it should be noted the results were the same without masking the conjunction. Furthermore, separate psychophysiological interaction (PPI) functional connectivity analyses, seeded from these AI and dACC regions, showed comparable results for the positive and negative social feedback conditions (relative to neutral feedback) with significant (p < 0.05, FWE corrected) associations with activity in the right fusiform gyrus and inferior occipital lobe for both contrasts ( ,  , and  ). 

Is the common dACC-AI network identified here the same as that emerging from prior studies of social rejection ? An overlay of the results of our conjunction analysis ( ) on the clusters identified in the whole brain meta-analysis of social rejection studies  suggested that the conjunctive regions identified in the current data map closely onto the meta-analytic findings ( ), indicating that our Social Feedback Task is activating the same network as the Cyberball and romantic rejection paradigms reviewed therein. A similar overlay ( ), this time using just the results of our positive > neutral social feedback contrast, confirms that the network specifically underlying responses to positive evaluative information in the present data conjoins the social rejection network identified in the meta-analysis. In fact, if we extract the parameter estimates from our data that correspond to the peak dACC and AI coordinates from this whole-brain meta-analysis, they show the greatest activation during   positive  , rather than negative feedback in our data, suggesting that this network (hitherto associated with social pain) is actually more strongly activated in a social inclusion context. This is replicated when plotting the peak coordinates from a meta-analysis of social rejection tasks with a restricted focus on ACC activity  ( ,  ) and in structural and functional region of interest (ROI) analyses of the same regions ( ). 

Are there other potential accounts of the present data that merit consideration? One possibility (see   for a full discussion) is that the dACC-AI network activation found here in the context of signals of social inclusion simply occurs as a result of expectancy or carry-over effects from negative social feedback elsewhere in the task. However, these putative influences would also be present for the neutral feedback trials, for which the relevant activations were subtracted out in our critical positive social feedback contrast term, making this explanation less compelling. A related possibility is that positive and negative feedback activate a common neural network because they both involve some form of expectancy violation . However, again this seems unlikely because, if for illustration we focus on the critical positive feedback findings, the pattern of dACC-AI activation remains even for the subset of participants (  n   = 10) who (by their own ratings) expected to be consistently judged as best across all social domains and for whom the positive feedback was therefore unlikely to violate expectancies ( ). 

The shared dACC-AI activation also seems unlikely to be a simple function of emotional arousal as the effects remain after regressing out skin conductance responses (a reliable marker of psychophysiological arousal  recorded during the feedback epochs ( ). Similarly, applying an exclusive mask of the neural correlates of rating the affective impact of feedback (Rating Slide;  ) still revealed significant dACC-AI feedback conjunction clusters, suggesting that this shared activation is not simply attributable to affect processing ( ). Analogously, the pattern of dACC-AI activation in our feedback conjunction remained after applying either an exclusive meta-analysis mask of ‘salience’ (from neurosynth.org)  ( ), or a mask created by re-binning the feedback trials as a function of trial-by-trial stasis/change in social rank  ( ), suggesting that simple explanations based on general salience or social rank processing are also unlikely to account for the results. 


## Discussion 
  
The dACC and AI regions of the brain are implicated in a diverse range of psychological processes . Within social contexts, the dACC-AI network has hitherto been associated with experiences of social exclusion and rejection . However, our results show comparable patterns of involvement of this network in the processing of signals of social inclusion and of social acceptance. By comparable patterns, we mean we report significant independent contrasts of positive versus control conditions (either neutral or low-level baseline), and negative versus control conditions, and a significant conjunction (FWE corrected) for those separate effects. We are not intending to imply that those effects are identical in magnitude, although we failed to find any support for greater activation in this network in the face of negative social feedback relative to positive, or vice versa. These findings suggest that theoretical accounts of the dACC-AI network as a neural alarm system targeted at processing signals of exclusion within social contexts, and the resultant mental pain, require significant revision and extension. The current data are more consistent with a framework in which the dACC-AI matrix indexes signals of social inclusivity more generally within social contexts - a neural sociometer . This accords with functional level models emphasizing the integration of signals of social inclusion and exclusion as a gauge of fluctuating social status , and mirrors a similar theoretical shift concerning the brain’s so-called physical pain networks which have also been shown to be heavily implicated in the processing of physical pleasure . 

Several notable strengths of the current study bolster confidence in these conclusions, including the relatively large (for fMRI) and population-derived sample (  n   = 56), the use of a novel task targeted at the key research question, the application of a comprehensive analytic approach to address common potential confounds in the social pain literature , and the stringent use of familywise error-corrected statistics. 

Other findings from the wider social neuroscience literature are also consistent with this view that the prototypical dACC-AI social pain network is involved in the processing of inclusive social signals. Somerville   et al  . , in a study ostensibly examining social feedback in the context of expectancy violations, report comparable levels of dACC activation when subjects viewed pictures of people who reportedly dislike them   or   like them . Similarly, rostral ACC activation increases in tandem with increasing expectation of positive social feedback . Furthermore, μ-opioid receptors (MOR) that moderate physical pain appear to respond to positive social feedback in key social pain structures . Using Positron Emission Tomography (PET) combined with a social feedback task examining whether one is liked (social acceptance) or disliked (social rejection), MOR activation during social rejection was positively correlated with MOR activation during social acceptance in the anterior insula (left, r  = 0.79; right, r  = 0.62) and dACC (left, r  = 0.86; right, r  = 0.92) with no significant differences in levels of MOR activation in these structures between positive or negative social feedback conditions . 

Interestingly, potentially inconsistent data come from studies using the prototypical social rejection paradigm – Cyberball . Cyberball invariably contains a social ‘inclusion’ comparison condition where the participant is included in the virtual ball tossing game. Unlike social rejection, though, inclusion within Cyberball does not appear to activate the dACC-AI network . However, ‘inclusion’ here simply means not being excluded from the virtual ball tossing game. Such inclusion in this game playing context would be considered the social norm  and consequently is unlikely to be overt or salient enough to markedly activate any putative inclusivity-related brain network. To address this, some studies have adapted Cyberball by using an ‘over-inclusion’ condition in which participants receive the ball 80% of the time . However, if inclusion is the social norm as opposed to an overt, socially positive event, then increasing the number of social inclusion trials is likely to simply accentuate this. Indeed, although the fMRI results in these over-inclusion studies mirrored the usual Cyberball findings in showing that the dACC was more active during exclusion compared to over-inclusion, there was no behavioural difference in the level of subjective social pain reported between inclusion and over-inclusion conditions. This suggests that participants did not find over-inclusion any more socially rewarding than standard inclusion. Hence, while the Cyberball paradigm creates valid socially painful experiences through exclusion, it may be ill-suited to assess the social pleasure associated with inclusion. 

Some potential limitations merit comment. With the absence of a non-social comparison condition we were unable to evaluate the social specificity of our data, and hence rule out interpretations within the broader context of salience processing , although our findings remain even when exclusively masking brain regions prototypically associated with salience processing. Secondly, our GSR data suggest that the neutral condition was not equidistant from the negative and positive conditions in terms of elicited arousal, with the neutral condition being more similar to the negative condition. However, our findings remain the same when comparing positive and negative feedback to our low-level baseline (i.e., without the neutral condition) and when regressing out GSRs in the analyses, suggesting that this does not account for the results. Importantly, the neutral condition was well titrated in terms of its emotional impact relative to the positive and negative conditions ( ). Finally, as more resources and importance appear to be bestowed upon social evaluation in adolescence , our data may not be generalizable to the adult population. Future research into such questions would be beneficial. 

In summary, we show that the classic social pain network in the human brain, centered on the dACC and AI, shows similar patterns of sensitivity to signals of social inclusion as it does to social rejection. These findings have strong theoretical implications for our understanding of the role of this neural network in social cognition and are consistent with a neural sociometer that gauges the implications of all pertinent social information with respect to the organism’s social inclusion status. 


## Methods 
  
### Participants 
  
Participants were adolescents/young adults [  N   = 60; Mean (SD) age = 18 (0.7), range 17–20 years; 31 females] recruited from the population-representative ROOTS cohort (Total   N   = 1143) . We selected adolescents/young adults as we felt the Social Feedback Task would resonate strongly with that demographic. Inclusion criteria were: normal or corrected-to-normal vision; and English speaking. Exclusion criteria were: any history of neurological trauma resulting in loss of consciousness; current psychotropic medication use; current neurological disorder; current Axis 1 psychiatric disorder according to the Diagnostic and Statistical Manual of Mental Disorders (DSM-IV; ref.  ); presence of metal in body; diagnosed specific learning disability; or IQ < 85 on the Wechsler Abbreviated Scale of Intelligence (WASI; ref.  ). 

Participants recruited to the study showed no significant selection bias compared to the total ROOTS sample in terms of gender ratio or socioeconomic status as assessed using the ACORN (A Classification Of Residential Neighbourhoods) geodemographic measure  (  http://www.caci.co.uk  ). 

One participant was removed from further analysis due to a failure of imaging acquisition. Additionally, in the post-scan questioning (see below) three subjects reported some disbelief concerning the veracity of the cover story and were removed from all subsequent analyses, leaving a total of 56 participants for analysis (See   for participant data). 

The study was carried out in accordance with the Declaration of Helsinki and Good Clinical Practice guidelines and approved by the Cambridgeshire Research Ethics Committee. All participants provided written informed consent. 


### The Social Feedback Task 
  
The paradigm was styled as a ‘Big Brother’ game, where participants competed against other contestants (in fact these were confederates) to impress a set of six judges (also confederates) on a series of tasks in order to win through successive rounds of the game (they were told that one contestant per round was rejected from the game) and to eventually win the game. During the study participants were told they would be competing against three other contestants who were each located in MRI scanners located across the U.K, electronically linked so they can play the game interactively (hyperscanning) (see also  ). 

Participants were told that there would be three rounds of the game in total, with one person being rejected on each round until there was one winner remaining. In fact, this was a cover story and only one round of the game was played with all participants being voted off at the end of round one before being fully debriefed following a series of post-scan questions. For this first (and only) round of the game, each participant made a one-minute video recording to be rated by the panel of six judges. Participants were told that these ratings decided which contestant would be rejected from the game and who would progress to the subsequent (fictitious) rounds. The participants were told the six judges were together in a room at a separate location where they could be e-mailed the video recordings and from where they could submit their ratings. The participants were shown pictures of the six judges who were all just a few years older than the participants and were told that the judges had been extensively trained in making social judgments from video recordings. 

For the video recording, participants were asked to describe themselves, talk about what they enjoy doing, say what is important to them in life, outline their aims and achievements and say what was the most important thing that has happened to them was. Participants were given time before the video was recorded to think about these issues, and were shown a video made by a previous participant as an example. A still photograph of each participant was taken at this point for subsequent use in the fMRI session. Participants were informed that, for round one of the game, the judges would be rating these videos on a series of social dimensions (social competence, motivation, self-confidence, personal strength, social attractiveness and emotional sensitivity) that had been reliably linked to social success, prosperity and satisfaction across the life course, and that had been reliably shown to be easily rated on the basis of short video clips. They were told that, for each attribute, each judge would rank the participant and the other three contestants in terms of who was the best on that attribute (positive social feedback), who was the worst on that attribute (negative social feedback), and who was intermediate (neutral feedback) on that attribute. The decisions of each judge for each attribute (36 sets of feedback) were then shown to each participant during the fMRI session, prior to the final decision about who was rejected from the game on Round 1. Participants were told the design of the game was intended to build tension, akin to the voting on ‘Big Brother’ style game shows. 

To encourage believability in the other contestants, having made their own video recording, participants were asked to rate their competitors’ videos along the same social dimensions as the judges were using. Participants were told that each of the other contestants would be doing the same with their (the participant’s) video in the other contestants’ separate locations. 

Participants were told that different recordings for Rounds 2 and 3 would be completed following potential success on Round 1 (which never in fact happened, but was described in order to maintain believability). 

In the MRI scanner (See  ), each judgment epoch began with an 8-second ‘Judge Slide’ showing which judge would be judging which attribute (e.g.   David will now be judging you on social attractiveness  ). This was followed by an 8-second anticipation period of fixation, and an 8-second ‘Feedback Slide’, showing whether each contestant was judged to be the best (positive feedback), intermediate (neutral feedback) or worst (negative feedback) on that particular attribute by that particular judge. Following this ‘Feedback Slide’, and a 2-second fixation, a 10-second ‘Rating Slide’ of how the participants felt about the feedback (ranging from 0 (disappointed) – 10 (pleased)) was completed. This sequence was repeated 36 times for each social attribute from each judge, resulting in 12 ‘best’ judgments, 12 ‘neutral/intermediate’ judgments and 12 ‘worst’ judgments. Attribute and judge orders were counterbalanced across participants. At the end of the 36 judgments, overall judgments were made by each judge detailing whether the participant had made it through to the next round, a total of 6 such final judgments was made (one by each judge); 5 of which were ‘worst’ and one ‘middle’ resulting in the participant being rejected on round one of the game. Following the scan, as a manipulation check, participants were asked a series of questions aimed at assessing believability of the task and of the hyperscanning environment. 

All personally identifiable information (videos and photographs) was deleted immediately following debriefing. 


### Data Acquisition and Analysis Approaches 
  
#### Image acquisition and preprocessing 
  
MRI scanning was conducted at the Medical Research Council Cognition and Brain Sciences Unit on a 3-Tesla Tim Trio Magnetic Resonance Imaging scanner (Siemens, Germany) by using a head coil gradient set. Whole-brain data were acquired with echoplanar T2*-weighted imaging (EPI), sensitive to BOLD signal contrast (48 sagittal slices, 3 mm thickness; TR = 2000 ms; TE = 30 ms; flip angle = 78°; FOV 192 mm; voxel size: 3 × 3 × 3 mm). To provide for equilibration effects the first 5 volumes were discarded. T1 weighted structural images were acquired at a resolution of 1 × 1 × 1 mm. 

SPM8 software (  www.fil.ion.ucl.ac.uk/spm/  ) was used for data analysis. The EPI images were sinc interpolated in time for correction of slice timing differences and realignment to the first scan by rigid body transformations to correct for head movements. Field maps were estimated from the phase difference between the images acquired at the short and long TE and unwrapped, employing the FieldMap toolbox. Field map and EPI imaging parameters were used to establish voxel displacements in the EPI image. Application of the inverse displacement to the EPI images served the correction of distortions. Utilising linear and non-linear transformations, and smoothing with a Gaussian kernel of full-width-half-maximum (FWHM) 8-mm, EPI and structural images were co-registered and normalised to the T1 standard template in Montreal Neurological Institute (MNI) space. Global changes were removed by proportional scaling and high-pass temporal filtering with a cut-off of 128 s was used to remove low-frequency drifts in signal. 


#### Statistical analysis approach to fMRI data 
  
After preprocessing, statistical analysis was performed using the general linear model. Analysis was carried out to establish each participant’s voxel-wise activation during the Feedback and Rating Slides (see  ). Activated voxels in each experimental context were identified using an epoch-related statistical model representing each of the three feedback trial types and subsequent affect ratings, convolved with a canonical haemodynamic response function and mean-corrected. Six head-motion parameters defined by the realignment were added to the model as regressors of no interest. Multiple linear regression modelling was then applied to generate parameter estimates for each regressor at every voxel. At the first level, the following feedback contrasts were generated; ‘positive feedback’; ‘neutral feedback’; ‘negative feedback’; ‘positive feedback’ minus ‘neutral feedback’; ‘negative feedback’ minus ‘neutral feedback’; ‘positive feedback’ minus ‘negative feedback’ and ‘negative feedback’ minus ‘positive feedback’. The same contrasts were also generated for the ratings of affect (Rating Slides) following each Feedback Slide. For group statistics, random effects analysis was utilized. A conservative voxel-wise statistical threshold of P < 0.05 familywise error (FWE) corrected for multiple comparisons across the whole-brain was used for all analyses. 




## Additional Information 
  
 How to cite this article:   Dalgleish, T.   et al  . Social pain and social gain in the adolescent brain: A common neural circuitry underlying both positive and negative social evaluation.   Sci. Rep.   7  , 42010; doi: 10.1038/srep42010 (2017). 

 Publisher's note:   Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-15'>
<h2>15. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/25278250/' target='_blank'>25278250</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Lost for emotion words: What motor and limbic brain activity reveals about autism and semantic theory</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Neuroimage</p>
<p><strong>Publication Year:</strong> 2015</p>
<p><strong>DOI:</strong> 10.1016/j.neuroimage.2014.09.046</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4265725/' target='_blank'>4265725</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study reports event-related fMRI during passive reading of emotion words—an experimental manipulation probing processing of emotions/mental-state semantics, which maps onto the construct ‘Perception and Understanding of Self/Other’ and thus qualifies as social-related processing. It includes a healthy control group of adults (n=18, mean age 28.6, within 17–65) with results reported separately. Whole-brain analyses are presented (FWE-corrected group contrasts reported), alongside ROI analyses; therefore it is not limited to ROI-only results. No exclusion criteria apply. Hence the paper meets all inclusion criteria for fMRI studies of social-related processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Autism spectrum conditions (ASC) are characterised by deficits in understanding and expressing emotions and are frequently accompanied by alexithymia, a difficulty in understanding and expressing emotion words. Words are differentially represented in the brain according to their semantic category and these difficulties in ASC predict reduced activation to emotion-related words in limbic structures crucial for affective processing. Semantic theories view ‘emotion actions’ as critical for learning the semantic relationship between a word and the emotion it describes, such that emotion words typically activate the cortical motor systems involved in expressing emotion actions such as facial expressions. As ASC are also characterised by motor deficits and atypical brain structure and function in these regions, motor structures would also be expected to show reduced activation during emotion-semantic processing. Here we used event-related fMRI to compare passive processing of emotion words in comparison to abstract verbs and animal names in typically-developing controls and individuals with ASC. Relatively reduced brain activation in ASC for emotion words, but not matched control words, was found in motor areas and cingulate cortex specifically. The degree of activation evoked by emotion words in the motor system was also associated with the extent of autistic traits as revealed by the Autism Spectrum Quotient. We suggest that hypoactivation of motor and limbic regions for emotion word processing may underlie difficulties in processing emotional language in ASC. The role that sensorimotor systems and their connections might play in the affective and social-communication difficulties in ASC is discussed. 
   Highlights  
  
Motor and limbic cortices are typically activated by emotion words. 
  
In ASC, activity in these key regions is reduced for this word type specifically. 
  
Hypoactivity does not appear in brain regions unrelated to emotion word processing. 
  
ASC motor systems' hypoactivity to emotion words correlates with symptomatology. 
  
Motor deficits may help explain emotion processing problems and other ASC symptoms. 
  
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (43421 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Inherent in Kanner's first description of autism as a ‘disturbance of affective contact’ ( ), the domain of emotion has been cardinal throughout the history of autism research. Disturbances in the affective domain may help to explain why individuals with autism spectrum conditions (ASC) have difficulty in connecting, socializing, communicating, and understanding the hidden mental world of others that drives much of social behaviour ( ). A recent, methodologically rigorous meta-analysis of the emotion recognition literature in autism suggests that a pervasive deficit exists ( ), extending to understanding emotions in vocal cues and nonverbal gestures ( ,  ,  ,  ,  ,  ,  ). In terms of emotional expression, studies in autism also indicate lower responsivity to emotional displays of others ( ,  ), a lack of spontaneous mimicry of others' facial expressions ( ,  ,  ), and attenuated physiological response to emotional expressions, pain and distress in others ( ,  ,  ,  ). Vocalisations and facial expressions of affect in autism are characteristically flat or neutral ( ,  ,  ), and may be inappropriately disconnected from the social context in which they appear ( ,  ,  ). Finally, difficulty in identifying and describing emotions verbally, known as alexithymia, is much more prevalent in people with ASC ( ,  ) and their parents ( ). In summary, it seems that individuals with ASC are atypical in how they express emotions in comparison to typically-developing peers and that, likewise, their perception and mirroring of emotions are reduced, if not impaired. 

This pattern of emotion expression and perception deficits is one component of the difficulty in mentalising, the ability to represent one's own emotional states and thought processes and those of others ( ,  ,  ,  ,  ,  ). In this sense, deficits in self-referential processing may alter an individual's ability to use the self as a proxy for simulating the mental lives of others. A deficit in representation and/or recognition of one's own emotions would impair attempts to accurately simulate others via oneself ( ). 

The more generalized role of simulation in mental operations is increasingly recognised in the field of cognitive neuroscience, where   names it “a core form of computation in the brain” (pp. 618–619). A proposal which has recently gained speed with much empirical support is that self-performed actions (including those involved in emotional expression) and the perceptual consequences of the same lead to linked action–perception representations that are later used in cognitive processing and social interaction ( ,  ). In action cognition, for example, researchers have suggested that action goals are simulated in the motor systems of observers in order to understand the intentions underlying actions, such as whether or not the actor intends to eat the object ( ). In the context of the mirror neuron theory, these joint action–perception circuits, consisting of these self-same sensorimotor neurons with visual and/or auditory properties, have been found underactive in autism ( ,  ,  ,  ). 

Given that alexithymia in autism is a   linguistic   deficit in processing the emotions of self and others, this implies that there is atypical processing of words semantically related to emotions. Prior work in autism suggests that these individuals do indeed show difficulty in understanding and using emotional and cognitive mental state terms (such as “dread”, “thought”: see  ,  ,  ,  ,  ,  ,  ,  ,  ) as well as an inability to link mental state terms to emotional information present in features of the eyes ( ,  ). The neural correlates of this deficit are, however, unknown. In the present study we used event-related fMRI to investigate brain systems activated when people with ASC process abstract emotion words. Our hypotheses about atypical cortical activity during emotion word processing focused on two key areas. 

In typically developing (TD) individuals, understanding the meaning of action and emotion words and concepts seems to involve the cortical motor system ( ,  ). Our prior work has shown that individuals with autism show hypoactivity of cortical motor systems when they process action words and concepts ( ,  ), and this is consistent with atypical structure of the motor cortex ( ) and movement impairments in ASC (see  , for review). The motor regions unexpectedly inactive during action word processing in ASC were the same as those found particularly active when TD individuals processed abstract emotion words ( ). Theoretically, this ‘motor embodiment’ of emotion words suggests that the link between an emotion word and the emotional state it expresses depends on emotion expression in action ( ,  ,  ). In early language acquisition, emotion expression by infants provides a natural context for teaching emotion words and, therefore, the motor and limbic regions for emotion expression may be woven into the semantic representations of abstract emotion-related words. As TMS and work in brain-damaged patients shows that somatosensory and motor regions along with limbic emotion processing areas in insular cortex are necessary for the perception of emotion-related information immanent to the face ( ,  ), and these same areas are also active in emotion word processing ( ,  ), we hypothesised that these cortical motor and limbic systems would be affected in autism during emotion word processing and might reflect the degree of autistic traits in ASC. 

An additional hypothesis focuses on limbic areas involved in emotion processing ( ). A range of these regions, including orbitofrontal and frontopolar cortex, anterior cingulate gyrus, insula, and basal ganglia (putamen, caudate, and globus pallidum), are involved in emotion   word   processing (for review see  ,  ). Because these regions are specifically activated by   emotion-related   language, this subset of limbic areas, along with motor systems, provides a putative cortical basis for ‘simulation’ of word meaning and affective semantics more generally. It has been suggested that, at the neurobiological level, strong emotional-affective associations of emotion words are mechanistically organised as ‘limbic tails’ of cortical cell assemblies reaching into subcortical structures of the limbic system ( ). In addition to the aforementioned abnormalities of cortical motor systems, people with ASC also show atypical activity and structure in many of these limbic regions ( ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ), so we predict additional hypo-activity in limbic systems when people with ASC process emotion-related words. 

In summary, activation of motor and limbic areas during abstract emotion word processing seen in TD individuals may be atypical in ASC, partly due to their deficits in emotion processing and thus limbic activation, and to deficits in emotion expression in action and thus motor system activity. Whereas limbic hypoactivation might be predicted by the common emotion processing deficits in ASC, the additional prediction of motor hypoactivity in emotion word processing rests on the semantic link between emotion words and motor systems ( ). If the semantic link between an emotion and the word denoting it is via emotion expression in motor behaviour, the motor difficulties reported in ASC imply that this link will be atypical even during single word reading and comprehension, a task unrelated to overt emotion processing. Therefore, if words denoting abstract emotional states draw on cortical motor and limbic regions during processing, atypical functioning may be apparent in both of these regions when individuals with ASC simply read these words. In comparison with words denoting animals or abstract verbs, neither of which are especially linked with motor or limbic regions, we predicted that individuals with ASC would show a category-specific abnormality during emotion word processing that should be specific to the motor and limbic areas that are atypical in ASC and associated with emotion word processing in typical controls. 


## Materials and methods 
  
### Participants 
  
Right-handed, native English-speaking participants comprising 18 high-functioning adults with an ASC (mean age: 30.4 years [standard deviation (SD): 10]; mean IQ: 113.5 [SD: 23]) and 18 age- and IQ-matched typically-developing (TD) controls (mean age: 28.6 years [SD: 11.7]; mean IQ: 110.2 [SD: 12.3]). Data from TD participants were previously published in  ; here, a new and independent analysis compares these participants and individuals with ASC who were recruited from the volunteer database at   www.autismresearchcentre.com  , hosted by the Autism Research Centre at Cambridge University, UK. All ASC participants had been previously clinically diagnosed using DSM-IV criteria: 17 met criteria for Asperger Syndrome, one for PDD-NOS (pervasive developmental disorder not otherwise specified). The ASC group scored significantly higher than the control group (t [32] = 6.857, p < .001) on the Autism Spectrum Quotient (AQ: Baron-Cohen et al. 2001b), with a mean score of 34 (SD: 10) in comparison to the control mean AQ of 13 (SD: 5). All but 4 of the ASC group scored above 26 on this test, a cut-off point that captures the majority of adults with autism ( ). In order to keep the procedure short, this experiment matched participants only in full-scale IQ ( ). Although they were not directly matched in verbal IQ, both had performed with no significant differences in accuracy in a general language processing task reported in a previous experiment ( ) and the participants with ASC were high-functioning individuals who had or were currently working or studying, and so seemed to be comparable in their ability to read and understand the task. 

All participants gave written informed consent prior to participating in this study and were remunerated for their time. Ethics approval was provided by NHS Research Ethics Service Cambridgeshire. 


### Stimuli 
  
A semantic rating study was carried out prior to the fMRI experiment in order to assess semantic properties for a large corpus of words: these included arousal, valence, imageability, concreteness, visual-relatedness, form-relatedness, colour-relatedness, and action-relatedness. Arousal and valence ratings have previously been employed in work on emotional-affective meaning ( ,  ) to classify words as emotional or non-emotional. Our previous work ( ) used an additional explicit rating of emotion-relatedness to identify words (primarily verbs) specifically used to speak about emotions, such as “dread”, “hate” and “fear”. As words with action-related meanings (e.g. “kick”) are also known to activate cortical motor systems, we excluded more concrete emotional items with sensorimotor associations used in the previous study (such as “wail” or “scream”), which were less optimal for exploring ‘pure’ abstract emotion concepts (see   for details of this and the rating procedure). As such, a more refined category of the most abstract emotion words (20) was contrasted with 40 animal names (nouns such as “hawk”, “mouse”, “sheep”) and 40 abstract verbs (e.g. “heal”, “dwell”, “waive”, which also lacked overt or concrete sensorimotor associations with the body). Words were matched in length, number of neighbours, word frequency, bigram and trigram frequency (see Table S1 in supplementary information for psycholinguistic and semantic properties of all experimental word categories). In order to disguise the focus of the study, the experimental words were dispersed among 240 filler words and 120 hash-mark strings (###) which, matched in length with the 360 word stimuli, were used as a low-level visual baseline unrelated to language. 

Animal names were included as a word category unrelated to actions, in order to rule out the possibility of indiscriminate motor activity during general language processing. Whilst a lexical confound existed with the animal name category (nouns), both the emotion and abstract word categories were verbs (or had strong primary use as verbs): any atypical activity which appeared for emotion words but not for abstract verbs could not therefore be ascribed to a general problem with this lexical category. Though matched in word frequency, animal words were rated as significantly more familiar than our other experimental word categories. Abstract verbs, which were not significantly different to emotion words in familiarity (t [58] = .246, p = .807) or the concreteness of their meaning (t [58] = .510, p = .612), were the stronger control category. All three experimental word categories can be seen in Table S2 (Supplementary materials): they were presented in lowercase just as they appear. 


### Procedure and experimental design 
  
Prior to scanning, all subjects completed Form A of the Cattell Culture Fair test ( ) and the Autism Spectrum Quotient (AQ:  ), in order to obtain measures of IQ and number of autistic traits. The Cattell Culture Fair test is a non-verbal IQ test frequently employed in cognitive neuroscience ( ). It is believed to provide the strongest measure of “fluid” intelligence ( ,  ,  ,  ), that which is distinct from learned verbal material (which influences some subtests of the Wechsler Adult Intelligence Scale [ ]) and which is considered to reflect “true” problem-solving or abstract reasoning ability ( ,  ) rather than ‘crystallised’ intelligence (learned knowledge). 

Event-related fMRI was used to compare brain activity during passive silent reading of experimental words, which were presented tachistoscopically for 150 ms. This short presentation time was employed to discourage saccades and encourage continuous attention in order to perform well on the task. Participants were asked to focus on a central fixation cross (presented for an average of 2350 ms) following the presentation of word stimuli, with SOA varied at an average of 2500 ms. Two pseudo-randomised stimulus lists were counterbalanced between subjects, who were instructed to read the words silently without moving their lips or tongue. Observation during scanning ruled out the effect of overt movements on results. 

Immediately following scanning, an unseen word recollection test containing a combination of experimental and novel distracter words asked participants to rate how confident they were that each word had appeared in the experimental task. Accurate results confirmed that participants had maintained attention on the experimental task. T-tests confirmed that both groups performed above chance (average hit rate: controls = 76.2% (SD = 18.1%), ASC = 76.2% (SD: 19.1%)), with no significant difference appearing between them in the number of correct answers (t [34] = − .018, p = .913). 


### Imaging analysis 
  
Participants were scanned in a 3 T Tim-Trio scanner with a 12-channel head-coil attached. Functional scans consisted of 32 slices covering the whole brain in descending order (slice thickness: 3 mm, in-plane resolution: 3 × 3 mm, inter-slice distance: 0.75 mm), and echo-planar sequence parameters were TR = 2000 ms TE = 30 ms and flip angle = 78°. SPM5 (Wellcome Department of Imaging Neuroscience, London, UK) was employed for all processing stages, including slice-timing and re-aligning using sinc interpolation, co-registration of images to structural T1 images and normalisation of the previous to the 152 subject T1 template of the Montreal Neurological Institute (MNI). Transformation parameters were applied to co-registered EPI images, which were also resampled with a spatial resolution of 2 × 2 × 2 mm and spatially smoothed with an 8-mm full-width half-maximum Gaussian kernel. 

Single-subject, second level and group statistical contrasts were computed using the canonical haemodynamic response function (HRF) of the general linear model. Low-frequency noise was removed by applying a high-pass filter of 128 s. Onset times for each stimulus were extracted from E-prime output files and integrated into a model for each block in which each stimulus category was modelled as a separate event. Group data were then analysed with a random-effects analysis. Direct statistical contrasts between groups for each word category were computed and voxel coordinates reported in MNI standard space. Statistical thresholding was initially set at a liberal threshold of p < .001, uncorrected, in order to observe the activation landscape evoked by words but was then followed up by more stringent thresholding at a Family-Wise Error (FWE) corrected level of p < .05. 

In addition to whole-brain analysis, a regions-of-interest (ROI) investigation was undertaken, using the MarsBar function of SPM5, in order to look for statistical interactions between brain regions, word category and group in an ANOVA approach. ROIs were created by pooling participants from both groups and assessing regions where brain activity was robust for the general language contrast of all words against the hash-mark baseline. The three clusters (each with 3 peak loci) with most highly significant t values at a FWE-corrected threshold of p < .05 were selected for detailed analysis in 5 mm-radius ROIs. Activation was collapsed across the 3 peaks within each cluster to form the factor of Area for statistical analysis. These three Areas for analysis therefore included a left-hemispheric temporal cluster (its collapsed peaks located in inferior temporal [− 60, − 34, − 2] and fusiform gyrus [− 40, − 44, − 18, and − 42, − 4, − 44]: henceforth referred to as the “Temporal cluster”); a left-hemispheric cingulate cluster (collapsed loci in dorsal medial BA 6 [− 6, − 2, 64] and cingulate cortex at BA 32 [− 6, 16, 40] and BA 23 [− 8, − 8, 46]; henceforth the “Cingulate cluster”); and a right hemispheric motor cluster (its collapsed loci in primary motor [BA 4: 52, − 8, 42] and premotor cortex [BA 6: 62, 4, 12, and 60, 2, 38]; henceforth the “Motor cluster”). As can be seen in   Part A, the activity evoked by general reading spread across disparate areas, and consequently, a peak arose within the same cluster as the temporal ROIs that was actually located in left premotor cortex (BA 6: − 42, − 4, 44). As this peak could not be included in the Temporal cluster within the ANOVA described below, it was analysed separately. After analysing at these 3 Areas (collapsed across 3 ROIs in each), their homologues in the contralateral hemisphere were computed, and these homologues (themselves collapsed from individual peaks into Areas mirroring those in the left hemisphere) were averaged with the originals in order to carry out a bilateral analysis. 

Finally, correlations between AQ scores and activity in these three bilateral Areas for each of the three word categories (3 × 3 tests) were examined in the ASC group. On observing the data, two clear outliers were observed who scored very low in ASC traits, more than 10 points below the typical cut-off point of 26 ( ). The AQ is not a diagnostic measure but in this previous work, it reliably identified people with ASC in 83% of tested cases. It was noted that one of our outliers was in fact the one participant with PDD-NOS, which has also been known as “atypical autism”, being a diagnostic label for cases which meet many but not all the prototypical symptoms of autism or which have additional, uncharacteristic symptoms. These two individuals were more comparable with the control group for AQ scores (see Supplementary materials, image S4). These two participants were identified as outliers in the ASC group on two fronts, being more than 2 standard deviations from the group's mean AQ and secondly through calculation of the median absolute deviation (see  , for details of this recommended method for outlier identification). They were removed from the correlation analysis but kept in brain-imaging analyses for the sake of matching group size; checks were made to guarantee that removal of these outliers did not affect significance in the other findings. 



## Results 
  
Activity during general word processing (all word categories against the hash-mark baseline), pooled across all participants, revealed widespread activity which was strongly left-lateralised across perisylvian language regions (fusiform to superior temporal cortex, inferior frontal gyrus), plus activity in the motor system bilaterally. 

Direct between-group statistical contrasts at a FWE-corrected whole-brain level revealed a range of cortical regions for each word category which were activated more strongly in the typically-developing (TD) control participants than in the ASC group. Regions where emotion words evoked greater activity in TD than ASC participants are displayed in   and   (p < 0.05, FWE corr.). These included a large cluster of voxels (n = 2438) encompassing left-hemispheric motor systems (BA 4 and 6) and the insula, and additional clusters in the left fusiform gyrus and the right-hemispheric motor system (BA 6). A left-hemispheric cluster including the anterior cingulate and caudate nucleus was also more strongly activated by emotion words in TD than ASC subjects, but this cluster did not survive FWE correction. Areas more strongly activated by the control word categories in the control participants are displayed in Supplementary Materials (Table S3), though none survived FWE correction. The contrast of ASC > control participants was non-significant at whole-brain level for each word category.   
Areas of greater activity for emotion words in Control vs. ASC participants. 
      
Statistical group contrast (controls > ASC) for emotion words (red). Activation is thresholded at p < .001, but the yellow parts of the activation clusters reflect activity which survived FWE (p < .05) correction. 
  

In a secondary ROI analysis, activation for each word category was examined in three large clusters of activity (left temporal, cingulate, and right motor cortex) that arose from the contrast of all words against the hash-mark baseline for all subjects pooled. The coordinates of the loci collapsed in each cluster can be seen in  , part A.   
Part A): Activation for all words as contrasted against the hash-mark baseline, presented at a threshold of p < .001 for all subjects pooled. Individual loci, depicted above, were collapsed in the analysis to form one Temporal cluster, one Cingulate cluster and one Motor cluster. Part B): Graphs depict activity for each word category in each cluster. Significant Word Category × Group interactions, driven by between-group differences marked by asterisks (*), were found in the Cingulate and Motor clusters. Mean activation for the control participants is in blue, for the ASC participants in red. Error bars reflect standard error. 
  

These clusters were entered into an ANOVA including the factors Area (3 levels: Temporal, Cingulate, Motor), Word Category (3 levels: animal names, abstract verbs, and emotion words) and Group (2 levels). This revealed a significant (following Huynh–Feldt correction) interaction of Area, Word Category and Group:   F  (4, 136) = 4.833, p = .001. The left motor ROI, which arose as part of the cluster of activity with the Temporal ROIs but which was analysed separately, did not produce a significant main effect of Word Category (p = .09) or a Word Category interaction with Group (p = .866), though greatest activity for emotion words over other word types was seen in both groups. 

The interaction of Area, Word Category and Group was unpacked in an analysis of each Area separately, employing an ANOVA with the factors Word Category (3 levels) and Group. Significant interactions between Word Category and Group were present only in Cingulate and Motor clusters (see  ,  ). Post-hoc t-tests of these interactions revealed significant between-group differences for emotion but not comparison word categories in both the Cingulate (  t  (34) = 2.116, p = .042) and Motor (  t  (34) = 2.867, p = .007) Areas. In fact, this hypoactivity for emotion words in the Cingulate Area correlated with the hypoactivity for emotion words seen in the Motor area (r = 863, p = .001), although no other correlations were seen between brain activity for word categories in other regions.   
Significant interactions in key regional clusters. 
    

A bilateral analysis using homologues of the ROIs collapsed in these three clusters confirmed this pattern of hypoactivity, producing an interaction of Area, Word Category and Group which was significant following Huynh–Feldt correction (  F  (4, 136) = 3.993, p = .004). Again, post-hoc analysis revealed that emotion words were the only word category to differ significantly between groups in the bilateral Cingulate (  t  (34) = 2.145, p = .039) and Motor (  t  (34) = 2.826, p = .008) Areas. 

Within group analysis of all three major clusters together showed no significant word category differences for ASC, but several in the control group (  F  [2, 34] = 3.444, ε = .906, p = .043). These were significant in the Motor Area (F [2, 34] = 8.049, ε = 1.000, p = .001), where greater activity was evoked by emotion words than by animal names (  t  (17) = 3.413, p = .003) or abstract verbs (  t  (17) = 3.002, p = .008) respectively. 

Correlations between bilateral activity for each word category in the three key clusters and the AQ were explored in order to assess a potential behavioural link with the hypoactivity for emotion words described above. Following the removal of two outliers (see Methods for detail), a highly significant correlation between activity elicited by emotion words in the Motor Area bilaterally and AQ score (r = − .679, p = .004) was seen in the ASC group. This correlation reflected that higher scores, indicating a greater number of autistic traits, were associated with lower activity to emotion words in the Motor Areas (see Supplementary materials, item S4). It remained significant following Bonferroni correction (to a corrected p-value of 0.0056, based on 9 tests) and confirmation with a non-parametric test (Spearman's Rho: r = − .677, p = .004). We did not find any significant correlations between AQ scores and activity for any of the other categories in the motor Area, and no significant correlations between AQ scores and activity for any word category in the cingulate or temporal Areas. 


## Discussion 
  
Brain activation elicited during passive reading of abstract emotion words and two comparison control categories was compared in ASC and typically-developing (TD) control participants. Whole-brain analyses of activity evoked by emotion words showed significantly reduced neurometabolic responses in ASC, specifically in bilateral motor areas and in the left insula and basal ganglia. ROI analysis confirmed and extended these findings. A statistically-significant interaction of the factors Area (3 levels: temporal, cingulate, motor), Word category (3) and group (2) revealed that in cingulate and motor areas (the former including BA 23, BA 32, the latter primary motor and premotor cortex [BA 4 and 6 respectively]), people with ASC showed significantly reduced activity than controls for emotion words, but not for abstract verbs and animal names. Reduced activity in the ASC group for emotion words did not appear in temporal cortex but only specifically in the motor and insular regions where the same TD controls showed the strongest emotion word-evoked activity ( ). Furthermore, motor systems activation in people with ASC significantly correlated with their number of autistic traits, as assessed by AQ scores. 

### Action binds words to emotional meaning 
  
Alongside elevated rates of alexithymia ( ,  ) and general deficits in emotion processing and recognition ( ), people with ASC show difficulty in the processing of mental or emotional states and words semantically related to emotions ( ,  ,  ,  ,  ,  ,  ,  ,  ). As these impairments must reflect a neurological correlate, we hypothesised that substantial differences might exist in how these individuals process and store words with emotional meaning. 

Against a background of extensive atypical limbic structure and function in ASC (see  ), reduced activity here for emotion-related words is not in itself a surprising finding. Due to the poor temporal resolution of fMRI, it is not possible to determine whether limbic hypo-activation to emotion words reflects general problems with late stage, conscious   post-understanding   processing of emotion words or a deactivation of these emotion concepts in the earliest time window when semantic differences are reflected by brain response ( ,  ). Reduced activity in the limbic system was however accompanied by and correlated with reduced activity in the motor system, which in turn reflected the degree of autistic traits in the ASC group. On the basis of this data, we would venture to suggest that the under-activation in limbic systems and its accompanying motor hypoactivity are a hallmark of autism rather than an epiphenomenon. 

Cortical language and motor systems are tightly entwined, such that passive language perception activates motor regions in a general fashion, as if simulating the spoken or written language ( ,  ,  ). Over and above this, however, semantic theory and experimental data suggest that the meanings of both action words ( ,  ,  ,  ,  ,  ,  ; see  , for review)   and   emotion words ( ) are ‘embodied’ in cortical motor systems — such that words do not activate these areas equally. Action words are represented somatotopically such that they activate the cortical motor regions for the effectors involved in that action. For emotion words, the link between emotions and the symbols (words) denoting them may be established by way of actions, and motor activation in emotion word processing may therefore index this link. Cortical motor systems are the vehicle of emotion expression. Because they refer to abstract concepts such as “fear” which cannot be easily pointed to or labelled, the meaning of emotion words is established by the use of the words in action contexts — facial expressions and emotional behaviours such as crying, screaming and gesticulating. As the only visible ‘signals’ of internal emotional states, semantic theory postulates that these actions are critical for bridging the gap between word and meaning and so, in the typical population, become incorporated in the neural network representing the meaning of these emotion terms ( ). During this process, the word comes to be associated with the internal feeling it describes, and so, in addition, these words possess ‘limbic tails’ ( ), activating neurons in limbic structures involved in processing the specific emotions denoted by these words. In the typically-developing participants, these areas included the orbitofrontal and frontopolar cortex, anterior cingulate gyrus, insula, and basal ganglia including putamen, caudate, and globus pallidum ( ; areas also highlighted in abstract word processing, see  ). In the motor system, these participants showed the greatest activity in motor systems for emotion words and the lowest for animal names with little or no semantic relationship to actions. Though abstract words, too, may be partially grounded in a multitude of sensorimotor action contexts ( ,  ,  ,  ,  ,  ,  ), they are detached from   specific   action schemas ( ,  ). As such, despite equal ratings in action-relatedness, they evoked less activity in cortical motor systems than did emotion words, and the hierarchy of motor activation in our typical population – highest for emotion words, lowest for animal names as according with their action-relatedness – sits comfortably within the previous literature ( ). 

In comparison to the typically-developing participants, individuals with ASC here exhibited reduced activity for emotion words in limbic and motor regions (primary motor and premotor cortex, the insula, cingulate and caudate nucleus: see  ). That reduced motor and limbic activity was restricted to emotion words, but not other word types, is evidence for the atypical alteration of the action-semantic link (via behaviours involving motor systems) between emotion words and their related emotions. Stringent matching of our word categories, particularly the abstract verbs, allowed us to refute the possibility that participants with ASC might have a particular difficulty with   all   verbs, or with all words of an abstract nature. The cause of the group difference in activity for emotion words can therefore be presumed to be related to the emotional and mental state content of emotion words (e.g. “dread”) that was absent in the case of equally abstract verbs such as “dwell”, revealing a genuine category-specific semantic abnormality. 


### The role of motor systems in emotion word processing, alexithymia and ASC 
  
The pattern of activity in the control group, who in a previous analysis showed substantial overlap in the motor activity evoked by abstract emotion words such as “fear” and that evoked by overt action words such as “frown”, is consistent with the theoretical grounding of emotional concepts via actions ( ). The precise role of such motor activity for emotional words, however, is as yet unclear. 

Semantic theory postulates that words are represented in distributed “action–perception circuits” which link the representation of phonology and articulatory word features in core perisylvian language cortices with the representation of meaning in sensorimotor systems ( ). Functional importance of these sensorimotor systems for the processing of action words is supported by a plethora of empirical work, which demonstrates a common neural substrate for movement and the understanding of action-related language ( ,  ). Among the strongest evidence is that relating deficits in action word processing to damage or disease of the motor system ( ,  ,  ,  ,  ,  ,  ,  ,  ). The bidirectional influence between motor systems and action-semantic processing is such that differences were observed in the same patients with Parkinson's disease before and after dopaminergic treatment ( ). Of the greatest relevance to the present dataset is our previous research, which demonstrated abnormalities and a deficit in action word processing in individuals with autism. A significant correlation was seen between hypoactivity for action words in motor cortex and slowness in a task of semantic processing: as activity in motor systems decreased in participants with ASC, reaction times for action word processing increased ( ). This was a very course-grained task, simply asking participants to categorise words as actions or objects, which may be why this impairment did not manifest in significantly greater errors. The fact that autistic participants were nonetheless significantly impeded in this very simple task suggests, however, that they might be substantially impaired in more complex or subtle action word processing tasks, as were the patients described above. The motor hypoactivity for action words that we had observed with fMRI was further corroborated with temporally precise combined EEG-MEG recording of autistic participants (Moseley et al., 2014). 

As we did not conduct a behavioural test of emotion word processing, we cannot here show a relationship between the hypoactivity seen in motor and limbic regions and emotion word processing errors or impairment. We would hypothesise that, as for action words, this activation plays a functional role in their processing — and would accordingly predict autistic participants to show category-specific deficits for emotion words when these are compared with other well-matched word stimuli. Modulation of motor systems certainly affects processing of emotion-related language ( ), such that lesions or disorder of these areas would be expected to produce impairments. 

Though we did not conduct our own behavioural test of word processing, the motor and limbic hypoactivity seen specifically for emotion words in this analysis is consistent with other autism research reporting difficulties understanding and using emotion words, and with general emotion processing impairments. At the neural level, it is consistent with the atypical structural features in limbic regions and primary motor cortex in ASC ( ), and with movement impairments in autism ( ). In order to investigate a functional connection between motor and limbic systems activity and emotion word processing, and thus link the present data with reported impairments, future research should investigate the overlap of movement impairment and alexithymia in ASC and directly test the correlation between hypoactivity and category-specific deficits in active behavioural tasks involving processing words related to emotions. In such an investigation, it would also be optimal to measure alexithymia directly by means of a specialised scale. We attempted to retrospectively collect data using the Toronto Alexithymia Scale (TAS-20:  ) after our study finished, but unfortunately had few respondents from our sample, such that the hypothesised relationship between motor/limbic hypoactivity and alexithymia itself (as opposed to the autism measure included in this study) remains tentative. Interestingly, the present study observed a significant correlation, whilst reading emotion words, between hypoactivity in the motor system and hypoactivity in the cingulate cortex (though not with activity in other regions examined, ruling out any general hypoactivity). Although causal primacy of emotion expression deficits (associated with atypical motor circuits) over emotion processing/recognition deficits (associated with atypical limbic cortices) cannot be supported by this data, the correlation between motor and limbic hypoactivity observed here does imply a relationship between the capacity to express one's emotions and the capacity to process and understand the emotions of the self and others, as implied in the idea of the self as proxy for emotion processing ( ). 

Examination of ASC through the prism of movement disorder was considered by   but has been overshadowed by studies of the more prominent social-communication symptoms. More recently, however, atypical sensorimotor circuits have been argued to have wider implications for ASC, as they are suggested to contribute in a simulative manner to mentalising ( ) and other aspects of social cognition such as empathy ( ). Alexithymia is just one indication of impairments in self-referential processing ( ), and the idea that the self is used as a proxy suggests that this impairment may be associated with the broader meta-representational deficit in autism. If conceptual understanding of emotion concepts requires the involvement of motor systems then these broad impairments may be a downstream reflection of fundamental abnormalities in motor circuits. Other social-communication impairments in ASC might similarly arise from motor dysfunction, given the relationship between motor, social and language development in childhood ( ,  ) and the early emergence of motor abnormalities prior to other features of ASC ( ,  ,  ,  ). In ASC, correlations have been noted between movement difficulties and impaired social-communication skills ( ). In addition, motor impairment predicts childhood and adolescent speech fluency and delay in both children with autism and their high-risk siblings ( ,  ). In a previous publication, we demonstrated an association between motor hypoactivity and a category-specific impairment for action words ( ). This study also found a correlation between motor hypoactivity and AQ scores, a notable finding given that the AQ largely measures the social difficulties and narrow interests in ASC and makes no reference to motor symptoms which would be naturally expected to correlate with motor hypoactivity.   study fits with the perspective that brain circuits involving motor systems may underpin many higher cognitive processes. 

Given this relationship between motor abnormality and ASC, the present work investigated the correlation between activity in motor areas evoked by emotion words and autistic traits. A highly significant correlation was seen between AQ scores in the ASC group and activity evoked by emotion words in the motor system bilaterally. This finding appeared following removal of two outliers, so further investigation with greater numbers is important to confirm this. It may be that impairment in emotion expression (dependent on the integrity of motor circuits controlling emotional behaviours) is a hallmark of autism and precedes and underlies the development of other symptoms, a perspective consistent with the aforementioned developmental primacy of motor symptoms of ASC. This suggestion requires further investigation in a non-correlational approach for statements of causal primacy to be justified. 

Consistent with the previous finding related to action word processing ( ), the current data demonstrates a relationship between autistic traits and motor system hypoactivity during processing of   another   word-type associated with motor systems ( ). As motor systems are typically involved in processing both action words and emotion words, the hypoactivity seen here is symptomatic of underlying abnormalities in motor circuits (and/or their connections) that correlate with ASC traits. It suggests a relationship between disorder of sensorimotor systems (and/or their connections) and the emotional-affective and socio-communicative difficulties seen in ASC. Further research is clearly necessary to elucidate a putative link between motor systems abnormality, emotion word processing deficits, and other socio-communicative symptoms of ASC. The role of motor systems in higher cognitive processes is increasingly recognised in neuroscience ( ,  ,  ,  ), and given the relationship between motor, cognitive and emotional processing, further study of motor impairments and their role in ASC may be timely and fruitful for interventions. 



## Conclusion 
  
Using event-related fMRI, we explored the representation of emotion words in comparison to abstract verbs and animal names in the typical population and people with ASC. Our data revealed substantial differences between participant groups at a whole-brain level: the control group showed significantly greater activity for emotion words in motor cortex and limbic regions such as the cingulate and the basal ganglia, all of which have previously been implicated in emotion and emotion word processing. In addition, more thorough ROI analysis of temporal, cingulate and motor regions revealed a category-specific reduction for emotion words in the cingulate cortex and the motor system — both regions previously implicated in emotion word processing. This hypoactivation is consistent with ASC deficits in emotion expression and mentalising outside the language domain. We suggest this may constitute an underlying neural substrate for impairments in emotion word processing, which seems to rely on these motor and limbic cortical areas. We also report a significant correlation between motor hypoactivity in ASC and the expression of autistic traits. 


## Funding 
  
This work was supported by the   (MC_US_A060_0034, U1055.04.003.00001.01 to F.P., MC_US_A060_0043, MC-A060-5PQ90 to Y. S., MRC studentship to R.M.). 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-16'>
<h2>16. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/21625492/' target='_blank'>21625492</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Perception of Biological Motion in Schizophrenia and Healthy Individuals: A Behavioral and fMRI Study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2011</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0019971</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3098848/' target='_blank'>3098848</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study in which healthy adult controls (n=10) performed a social-perception task (biological motion categorization—Perception and Understanding of Others). fMRI data were collected while participants judged biological vs. scrambled/perturbed human motion. Although main analyses focus on ROIs (STSp and MT), the paper also reports whole-brain analyses (block-design localizer contrasts used to localize STSp/MT across the whole brain and an exploratory whole-brain search for hits vs. correct rejections), so results are not limited to ROI-only reporting. Healthy participant results are reported separately. Participants are adults and within the target age range. Therefore the study meets the inclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.85</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
## Background 
  
Anomalous visual perception is a common feature of schizophrenia plausibly associated with impaired social cognition that, in turn, could affect social behavior. Past research suggests impairment in biological motion perception in schizophrenia. Behavioral and functional magnetic resonance imaging (fMRI) experiments were conducted to verify the existence of this impairment, to clarify its perceptual basis, and to identify accompanying neural concomitants of those deficits. 


## Methodology/Findings 
  
In Experiment 1, we measured ability to detect biological motion portrayed by point-light animations embedded within masking noise. Experiment 2 measured discrimination accuracy for pairs of point-light biological motion sequences differing in the degree of perturbation of the kinematics portrayed in those sequences. Experiment 3 measured BOLD signals using event-related fMRI during a biological motion categorization task. 

Compared to healthy individuals, schizophrenia patients performed significantly worse on both the detection (Experiment 1) and discrimination (Experiment 2) tasks. Consistent with the behavioral results, the fMRI study revealed that healthy individuals exhibited strong activation to biological motion, but not to scrambled motion in the posterior portion of the superior temporal sulcus (STSp). Interestingly, strong STSp activation was also observed for scrambled or partially scrambled motion when the healthy participants perceived it as normal biological motion. On the other hand, STSp activation in schizophrenia patients was not selective to biological or scrambled motion. 


## Conclusion 
  
Schizophrenia is accompanied by difficulties discriminating biological from non-biological motion, and associated with those difficulties are altered patterns of neural responses within brain area STSp. The perceptual deficits exhibited by schizophrenia patients may be an exaggerated manifestation of neural events within STSp associated with perceptual errors made by healthy observers on these same tasks. The present findings fit within the context of theories of delusion involving perceptual and cognitive processes. 

 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (62266 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Humans are remarkably adept at perceiving the actions and intentions of others, an especially important skill befitting out highly social nature  . Called biological motion perception, this skill has been extensively studied in the laboratory using point-light (PL) animations of human activity portrayed exclusively by dots of light depicting the trajectories of the limbs of an actor's body  . Upon viewing PL animations, most people have no trouble perceiving subtle characteristics of the PL actor including the actor's gender  ,  , identity  , and social signals such as mood  . This paper deals with perception of biological motion in people with schizophrenia, a psychotic disorder characterized by debilitating deficits in a multitude of cognitive and social domains. 

Psychophysical studies indicate that schizophrenia patients exhibit deficits on a variety of visual tasks including judgment of spatial location  , discrimination of spatial frequencies  , and detection of visual motion  – . One particularly intriguing deficit uncovered in recent work from our laboratory was that schizophrenia patients exhibit impaired performance on a task involving discrimination of ordinary PL sequences of biological motion from sequences in which the spatial location of the dots were perturbed  . In this study, we used a discrimination task in which, on each test trial, patients viewed either a PL animation of a person engaged in one of several, familiar activities (e.g. walking or running) or an animation consisting of the same PL motions spatially and temporally scrambled to perturb the normal kinematics of the activity; the order of animations over trials was random and following each trial the patient categorized the animation as biological or perturbed. Signal detection analyses revealed significantly lower categorization performance (  d  ') by the schizophrenia patients compared to matched control participants, and this reduction in performance arose primarily from their abnormally high false alarm rates (i.e., judging a scrambled sequence as normal biological). These results imply that patients may be generally less sensitive to the kinematics defining normal, coordinated motion of the human body. If people with schizophrenia are indeed less sensitive to the kinematics defining human social actions, this could represent a significant perceptual component related to the multiple deficits in the social domain in schizophrenia  . Such a social perceptual deficit could also imply the existence of abnormalities in brain structures thought to be involved in perception of biological motion  . 

Because of the potentially important implications of our initial results, we performed three experiments aimed at documenting the nature and possible neural bases of impaired perception of biological motion in schizophrenia, using refined psychophysical techniques coupled with fMRI brain imaging. Experiments 1 and 2 were designed to elucidate the perceptual bases of impaired biological motion perception in schizophrenia. Results from those two experiments, in turn, set the stage for Experiment 3. This was a brain imaging study focusing on the posterior portion of the superior temporal sulcus (STSp), a brain region widely considered to be a lynchpin in a network of areas involved in registration of socially relevant sensory information  – . 


## Experiment 1: Detection of biological motion embedded in noise 
  
In Experiment 1 we used a two-alternative, forced-choice method (2AFC) to estimate thresholds for detection of biological motion perception for PL sequences in noise dots that obscured the spatio-temporal coherence of the dozen or so PL dots describing human activity  – . Two successive motion sequences were presented, one in each of two intervals defining a trial: one interval contained a dot sequence defining a biological activity in noise and the other contained a scrambled version of that sequence also embedded in noise, and the participants indicated which of the two intervals contained a biological sequence. By varying the number of noise dots over trials using a staircase procedure, we determined the minimum signal-to-noise-ratio supporting above chance performance on this 2AFC task requiring discrimination of PL biological motion. 

### Materials and Methods 
  
#### Ethics Statement 
  
In this and the following two experiments, written informed consent was obtained from all participants after they were given a complete description of the study. The Institutional Review Board of Vanderbilt University approved the protocol and consent procedure. 


#### Participants 
  
Fifteen outpatients (7 females and 8 males) who met the DSM-IV   criteria for schizophrenia were recruited from private psychiatric facilities in Nashville, Tennessee. Exclusion criteria were head injury, neurological disorders, substance use within the past 6 months, and IQ<85. Clinical symptoms were assessed with the Brief Psychiatric Rating Scale (BPRS) . Positive and negative symptoms were assessed using the Scale for Assessment of Positive Symptoms (SAPS) and the Scale for Assessment of Negative Symptoms, respectively  . All patients were taking atypical antipsychotic drugs (risperidone, olanzapine, or clozapine) at the time of testing. 

Twelve healthy and medication-free controls (5 females and 7 males) were recruited from the same local community. They had no DSM-IV Axis I diagnosis based on the Structured Clinical Interview for DSM IV (SCID)  . Exclusion criteria were history of schizophrenia in themselves or in their families, head injury, neurological disorders, substance use within the past 6 months, and IQ<85. Control participants were also screened before the experiment to rule out elevated schizotypy using the Schizotypal Personality Questionnaire (SPQ)  ; none of those volunteers had to be rejected on those grounds. Mean (SD) SPQ score was 13.3 (7.2). 

All participants had normal or corrected-to-normal visual acuity, and they wore their refractive correction during testing. There were no statistically significant group differences in age, IQ, handedness, or education level. Demographic information is summarized in  . 
   The demographic data.        

#### Stimuli 
  
Animations consisting of black dots presented against a white background were presented on a CRT monitor (120 Hz, TOTOKU Calix CDT2141A, Japan) controlled by a PowerMac G5 computer (Apple Inc, Cupertino, CA) running Matlab© (Mathworks Inc. Natick, MA) and the Psychophysics Toolbox  ,  . The experiment was conducted in a dark room illuminated by the screen only, with a 64 cm viewing distance maintained by stabilizing the observer's head using a chin/head rest. Biological motion animations consisted of 12 dots denoting the locations of the head, torso and joints of a human body engaged in one of 24 distinct activities. Scrambled motion sequences of each of those 24 activities were created by randomizing the spatial locations of the dots in the first frame of a sequence. The difficulty in discriminating biological from scrambled animations was manipulated by presenting each animation within a field of noise dots (see  ). The motion trajectories of the noise dots corresponded to those of biological or scrambled motion sequences on the same trial. This form of masking is particularly effective in degrading perception of biological motion  ,  . 
   Experiment 1: Detection of biological motion in noise.  
A. Each trial consisted of two successive 1 sec presentations of PL animations (separated by a 0.5 sec blank period), with one interval containing biological motion in noise and the other interval containing scrambled motion in noise; the scrambled motion on each trial was always derived from the biological motion presented on that trial. The left panel shows one frame depicting biological motion in the first interval (black dots indicate biological motion) and the right panel a frame of scrambled motion in the second interval. In the actual experiment all dots appeared as black against a white background. Noise dots had the same local motion trajectories as those of the biological or scrambled motion on that trial. The set of biological motion sequences totaled 24 distinct activities: 5 walking (stairway walking, climbing, crossing a small object, and 2 plain walking with different viewing angle), 4 jumping (standing jump, leaping, rope-jumping, and high-jumping), 4 kicking (toward front, side, and 2 soccer kicking), 2 running (plain and turning around), 6 throwing (3 overhead and 3 under-throwing), and 3 crouching. B: Results of the biological motion detection task. Mean detection thresholds for the two groups are shown, together with error bars indicating ±1 standard error of the mean (SE). 
  

#### Task 
  
On each trial of this 2AFC task, the participant maintained fixation on a small cross located at the center of the display monitor while viewing two successive, 1 sec sequences (separated by 0.5 sec blank interval) defining a trial. One interval contained the dot sequence defining a biological activity in noise and the other contained a corresponding scrambled sequence within the same level of noise. Following the two successive presentations constituting a trial, the participant pressed one of two keys on a computer keyboard to indicate which of the two intervals contained the biological sequence, guessing if necessary. Auditory feedback was provided following incorrect responses. The number of noise dots presented on a given trial was governed by a two-up/one-down staircase procedure that converges onto the noise level producing approximately 71% correct performance. The staircase was terminated after 16 reversals, and the threshold was estimated as the average number of noise dots over the last six reversals. A sequence of trials began with 20 noise dots, and the noise levels were incremented and decremented in steps of 6 noise dots per change for the first 12 reversals in the staircase and in steps of 3 noise dots per change after that. 

The size of each dot was 5-arc min, and the average dot speed within a sequence was 4°/sec. The entire array of dots, noise dots included, appeared within a virtual square region approximately 11° on a side, and the cluster of 12 dots defining biological or scrambled motion fell within a square region subtending approximately 7° on side centered on the fixation mark. The exact spatial location of the biological figure and the corresponding scrambled figure was varied from trial to trial by 1.4 deg visual angle around the center of the noise field; this maneuver made it impossible for participants to monitor just a small subset of dots to judge which interval contained the biological sequence. 



### Results 
  
Mean (SE) noise levels (estimated threshold) are shown in  , and those values were were 40.83 (4.39) and 55.96 (4.36) for the schizophrenia group and for the control group, respectively. This difference is statistically significant (t(26) = 2.43, p<0.03). Response times were not recorded on a trial-by-trial basis, but the total elapsed time was not significantly different between groups (t = 1.22, p = 0.23). It is unlikely, therefore, that the performance differences are attributable to differences in the length of time taken to arrive at a decision following each trial. We also analyzed the trial-by-trial performance of each participant, to learn more about the pattern of correct and error responses. The mean (SE) number of trials for all staircases was 62.31 (2.31) in the control group and 56.33 (2.11) in the schizophrenia group; this difference is not statistically significant (t = 1.91, p = 0.067). A participant had to be correct on the first 2 trials of the session for the staircase to proceed to the next level of noise. Eight out of 12 control participants responded correctly on the first two trials, compared to only 5 out of the 15 patients. This difference was significant (Pearson χ2 = 4.41, p = 0.036). Thus individuals in the schizophrenia group not only had more difficulty discriminating PL sequences in noise, they also performed worse on the easier trials. These early errors are not surprising, since our earlier study   found that patients tended to confuse scrambled and biological motion even in the absence of noise. 

There were no significant correlations between performance on the task and 1) symptom severity (BPRS:   r   = 0.17,   p   = 0.57; SAPS:   r   = 0.16,   p   = 0.58;   r   = −0.14,   p   = 0.63) 2) other demographic variables (age: r = −0.22, p = 0.43; education: r = 0.24, p = 0.39; IQ: r = −0.02, p = 0.95; illness duration: r = −0.23; p = 0.46; Edinburgh: r = 0.10, p = 0.72) and 3) medication (r = −0.09; p = 0.73). 

These results indicate that schizophrenia patients experienced greater difficulty distinguishing biological from non-biological motion sequences when those sequences appeared within an array of distracting noise dots, compared with healthy controls. Specifically, the level of noise had to be approximately 30% lower for schizophrenia patients to perform at the same level of accuracy as controls. One could argue that this deficit is attributable to a more general impairment involving perceptual organization and figure/ground segmentation. Indeed, schizophrenia patients exhibit impaired performance on some tasks requiring integration of spatially distributed visual features  ,  , although they perform equivalently to healthy individuals on other perceptual organization tasks  ,  ,  . Successful discrimination performance in the present experiment requires spatiotemporal integration of the PL motion tokens signifying a given human activity, and that integration process also depends on successful figure (PL motion)/ground (noise) segregation. 

To target the process of spatiotemporal integration that is not confounded by figure/ground segregation, we employed an entirely different task without noise elements in the second psychophysical experiment: a more subtle, challenging task that depends crucially on the ability to judge spatiotemporal coherence in PL animations that are uncontaminated by extraneous noise dots. Because it was impossible to create these kinematically perturbed animations adaptively in real time, we had to administer this task as a method of constant stimuli, not an adaptive staircase procedure. 



## Experiment 2: Perceptual discrimination of perturbations in biological motion sequences 
  
In Experiment 2, we compared how well schizophrenia patients performed, relative to healthy controls, on a task involving discrimination of pairs of PL sequences that differed in their degrees of spatial perturbation of the dots defining a biological activity. With these kinds of sequences, small amounts of perturbation preserve the gross impression of biological motion only up to some degree of perturbation, after which the sequences look incoherent. On each trial, two differently perturbed PL sequences generated from the same normal biological motion were presented simultaneously and the participants were asked to indicate which one of the two motion sequences looked more normal. 

### Materials and Methods 
  
#### Participants 
  
Participants included all individuals in Experiment 1 along with 6 new participants (2 patients and 4 controls). The two groups were matched demographically, and those demographic data are shown in  . 
   The demographic data.        

#### Stimuli 
  
A series of parametrically perturbed motion sequences was created from 10 different PL animations (listed in the caption for  ). The graded degrees of perturbation were produced in the following way (see  ). The starting frame of a given sequence (black dots in  ) was used to create a corresponding 100% scrambled animation frame in which the initial positions of each dot were spatially randomized within the confines of a virtual display window (gray dots). Next, varying degrees of perturbation from a normal sequence were created by locating each and every dot of an animation sequence a given distance between its normal and scrambled location; animations were generated for each of four values of perturbation ranging from 15% to 60% in steps of 15% (these values were selected based on pilot work). For each of the 10 biological activities we created exemplars of each of the 4 degrees of perturbation, and these exemplars were combined to create the pairs ( ). 
   Experiment 2: Discrimination of perturbation of biological motion.  
A: A series of parametrically perturbed motion sequences was created from 10 different PL animations each depicting a different human activity. These ten different PL animations comprised 2 portraying jumping (standing jump, rope-jumping), 3 kicking (toward front, toward side, and soccer kicking), 3 throwing (tossing, bowling, overhead throwing), 1 crouching for high jump, and 1 backward walking. In this example, black dots indicate the dots forming a single frame of a normal biological PL sequence and gray dots illustrate the corresponding frame of spatially scrambled version of this sequence. For example, dot A' indicates a new location of dot A when the motion is 100% spatially scrambled. The position denoted as (a) corresponds to an intermediate position that divides the distance between A and A' in the ratio of 15∶85. Therefore, when the position ‘(a)’s are taken from all the other pairs of biological-scrambled dots, a sequence containing 15% perturbed biological motion is generated. In the same way, (b),(c), and (d) represent the dot positions of 30%, 45%, and 60% perturbed motion. B: Single frame exemplars of the four discrimination conditions. Over trials, these pairs of animations portraying differing degrees of perturbation were presented in random order, and following each trial the participant indicated which one (left or right) was closer to unperturbed human motion. The % values below each figure refer to the percent of spatial perturbation. C: Performance (accuracy of discrimination) on the task in the schizophrenia group (filled symbols) and the healthy control group (open symbols). Error bars indicate ±1 standard error of the mean (SE). Chance performance on this 2AFC task corresponds to 50% correct. 
  

#### Task 
  
Participants were tested using a two-alternative, spatial forced-choice procedure. On each trial, two PL sequences were presented simultaneously for 1 sec, to the left and right of a central fixation mark. Each pair always comprised the same biological activity but the two sequences always differed by 15% in degree of perturbation. Thus on each trial, the participant saw pairs comprising 1 of 4 possible conditions: 0% vs. 15%, 15% vs. 30%, 30% vs. 45%, and 45% vs. 60%. Following each presentation, the participant indicated which motion sequence looked more normal by button press, guessing if necessary. Forty test trials were devoted to each pair of perturbation differences, with the order of trials randomized. Prior to formal testing, each participant viewed multiple examples of the various degrees of perturbation as well as examples of all of the normal biological motion. The two motion sequences presented on each trial fell within a rectangular region subtending approximately 9° (width) and 6° (height). During the presentation of the PL pairs, the participant was allowed to successively fixate the two sequences if desired. 



### Results 
  
Mean (SE) accuracy levels for each perturbation condition are shown in  , and here it can be seen that even with small degrees of perturbation participants in both groups made errors. A repeated measures ANOVA revealed a significant main effect of perturbation (F(3,93) = 99.93, p<0.001), confirming that all participants had increased difficulty discriminating pairs of animation containing greater degrees of perturbation. A significant main effect of diagnosis was also confirmed by ANOVA (F(1,31) = 28.99, p<0.001): schizophrenia patients were less accurate in discriminating two differently perturbed motion sequences compared to healthy controls. The interaction between diagnosis and perturbation condition was also statistically significant (F(3,93) = 5.17, p<0.01), and this is obvious from the graph: healthy controls showed an approximately linear decrease in discrimination accuracy that fell to the chance level only for the pair of 45% vs. 60%, whereas schizophrenia patients fell to chance for the 30% vs. 45% stimulus pair. We also looked at each individual's performance at each of the four perturbation conditions, to calculate how many observers in the two groups performed above chance as defined by binomial distribution (i.e. 26/40 or greater % correct). Results shown in   point to the same conclusion: patients found this task generally more difficult than controls except at the highest degree of perturbation where nearly all individuals found the task to be impossible. 
   The number of subject who performed above chance accuracy of binomial distribution in each perturbation level.        
In this experiment each trial involved presentation of a pair of PL animations portraying the same activity at two different levels of perturbation, and those PL animations could be any one of ten different activities. Are the group differences in performance on this task dependent on the particular activity being portrayed? To answer that question we computed for each observer the percent-correct performance for each of the ten animations separately, pooling over the different degrees of perturbation (except for the pair of sequences where performance was at chance for both groups). The results of that analysis, shown in  , confirm that degree of perturbation was more difficult to distinguish for some PL animations compared to others, but the pattern of results was the same for healthy controls and patients, with the correlation between groups being highly significant (r = 0.85, p = 0.002). The variations in task difficulty associated with the different animations, in turn, led us to wonder whether those variations were related to the amount of body and limb motion associated with the different activities. To estimate the overall amount of motion in each of the ten motion exemplars, we derived an index of motion energy for each exemplar defined as the total angular deviation produced by each dot of a given unscrambled animation during one cycle of the activity being portrayed. Those index values, also shown in   for each motion type, confirm what is obvious from visual inspection of the animations, namely that some entail larger body and limb motions than others. But the correlation between these index values for each motion type and the associated percent-correct performance for each type indicates that the two factors are unrelated, both for healthy participants (r = −0.11, p = 0.76) and for patients (r = −0.03, p = 0.92). 
   Experiment 2: Performance for each distinct activity.  
Each activity animation was quantified in terms of the total motion energy in that animation (defined by the total excursion of dots over space and time during the 1 sec presentation). The motion energy of each animation is speicified by the y-axis on the left-hand side of the graph, and the animations are ordered from most to least motion energy along the x-axis. (1 = standing jump; 2 =  kicking side; 3 = crouching jump; 4 = soccer kicking; 5 = kicking front; 6 = backward walking; 7 = bowling; 8 = rope jumping; 9 = tossing; 10 = overhead throwing). The histogram bars show average discrimination performance associated with each activity pooled across all perturbation pairings except the most extreme perturbations where performance on the task was impossible. Filled bars are for schizophrenia patients and open bars for healthy controls. There is no correlation between performance and total motion energy. 
  
We examined whether patient performance was related to symptom severity. Here we found that performance (mean accuracy of the scrambling conditions excluding 45% vs. 60% condition) and symptom severity were not significantly correlated (BPRS: r = 0.31, p = 0.91, SAPS: r = −0.13, p = 0.96, SANS: r = 0.37, p = 0.15). Other demographic variables were also uncorrelated with performance (age: r = 0.198, p = 0.45, education: r = 0.24, p = 0.36, IQ: r = 0.39, p = 0.13, handedness: r = 0.17, p = 0.51, illness duration: r = 0.09, p = 0.74, medication: r = −0.12, p = 0.63). 

One possible cause of the observed deficit of biological motion perception is that patients may be generally less sensitive to the spatio-temporal coherence defining normal body movements. According to this view, schizophrenia patients might need more salient spatio-temporal coherence to gain an impression of biological motion; sequences with relatively large degrees of perturbation appear equally disordered and therefore indiscriminable. Alternatively, it could be that perturbed sequences strongly resemble coherent biological motion to the patients, to the extent that both sequences of a pair look normal and hence indistinguishable. The higher false alarm rates exhibited by schizophrenia patients in our previous study and in the behavioral task of Experiment 3 are certainly consistent with this second alternative. In the   we consider this second alternative in greater detail. 

The results from Experiments 1 and 2 set the stage for examining possible neural concomitants of the impaired ability of schizophrenia patients to discriminate biological motion sequences, a heretofore-unexamined question. 



## Experiment 3: An event-related fMRI study of biological motion perception 
  
From human brain imaging studies, there is a growing body of evidence for the existence of a network of dorsal and ventral stream cortical areas involved in the analysis of kinematic information defining human action  . One key component in that network is found in the posterior portion of the superior temporal sulcus (STSp). Within this area, neural responses are stronger when one views motion of a human figure or human-like robots  , PL biological sequences  ,  ,  ,   or biological motion in noise  . In contrast, STSp is not strongly activated by scrambled PL sequences, by isolated pendular motions or by mechanical motions lacking purposeful meaning  . The behavioral results from Experiments 1 and 2 naturally lead to the following question: Are patterns of brain activation in schizophrenia different from those in healthy individuals? 

In Experiment 3, we used event-related fMRI to measure the BOLD activity levels associated with viewing biological motion sequences while participants–schizophrenia patients and normal controls–performed a biological motion discrimination task that allowed us to analyze separately brain activations measured on correct trials and error trials. For brain scanning we targeted STSp as well as motion-sensitive area MT, a neighboring visual area that presumably implicated in deficient motion perception in schizophrenia  ,  ,  ,  . 

### Materials and Methods 
  
#### Participants 
  
Ten outpatients with schizophrenia (4 females and 6 males) and ten healthy controls (5 females and 5 males) participated in the experiment. Summary of demographic information is shown in  . 
   The demographic data.        

#### Stimuli 
  
The same series of 24 distinct biological activities and corresponding spatially scrambled motions used in Experiment 1 were presented at the center of the screen (note that, unlike in Experiment 1, these sequences were not embedded in noise). Each PL animation fell within a virtual rectangular region subtending approximately 3.0×6.0° visual angle. Animations consisted of 20 frames displayed within a 1 sec period (50 msec/frame). In addition to the normal biological motion and completely scrambled motion sequences, a series of partially (37%) perturbed motion sequences was also used. The spatial perturbation value of 37% was selected based on the result from Experiment 2: schizophrenia patients performed at chance level when required to discriminate 30% vs. 45% perturbed biological motion, whereas controls exhibited above chance accuracy (65.47%) for this pair of perturbations ( ). Since only one sequence was displayed per trial, we decided to use the degree of scrambling falling midway between 30% and 45% perturbation. 


#### Functional localization of STSp and MT 
  
Preceding the event-related fMRI scans, we used conventional displays and subtraction techniques to localize areas STSp and MT. STSp was identified by comparing the BOLD signals associated with viewing biological and scrambled motion animations in a block-designed procedure ( ). Each participant viewed alternating biological and scrambled motion blocks (7 blocks each lasting 14 sec). In each block, seven 1 sec animations were displayed with an inter-stimulus interval of 1 sec. To maintain the observers' attention, each block required performance of a 1-back task in which observers were required to press a button whenever the current motion sequence was identical to the one appearing in the immediately preceding 1-sec presentation; the probability of a repeated sequence was 0.50. The scan lasted 316 sec, with the initial 8 sec (4 volumes, 1TR = 2 sec) being discarded from analyses to allow for MR saturation. 
   Experiment 3: Localization of regions of interest.  
A. Stimuli and procedures used to localize area STSp. Shown on the left are examples of PL biological motion and scrambled motion, and on the right is shown schematically the block-designed runs for STSp localization. B. Stimuli and procedures used to localize area MT. Dots moving radially inward and outward and static dots were presented in block-designed runs for MT localization. C. Inflated whole-brain images (both hemispheres for one patient and for one healthy control) showing regions of interest identified using the localizers described above. 
  
To localize MT, the participants viewed fourteen motion blocks interleaved with fourteen static dot blocks and pressed a button at every point of block switching ( ). The scan lasted 300 sec. The motion sequence consisted of 380 dots (black against a light gray background) that moved inward and outward from the center of the display. The entire array of the dots fell within a virtual circular region subtending 13° visual angle. The static dot field had the same number of dots, but consisted of only 1 frame. Each dot was approximately 6-arc min in size. 


#### Event-related fMRI task 
  
The event-related design for the biological motion task comprised nine runs each containing 24 trials consisting of eight biological, scrambled, and 37% scrambled motion sequences in random order ( ). We elected to use a constant inter-stimulus interval of 11 sec, to insure that the hemodynamic response associated with a given stimulus presentation had returned to baseline before the next presentation  . The participant was always aware of the timing of the next, forthcoming stimulus because the fixation cross changed size 2 sec before that event. Immediately following each stimulus presentation, participants judged whether the given motion depicted a human activity or not by pressing one of two pre-assigned buttons of the hand-puck being worn in the scanner. The total number of trials was 216, and participants were allowed to rest between runs if they so requested. 
   Experiment 3: Event-related portion of brain imaging study.  
A. The schematics of successive animation frames shown on the left are examples of the three categories of PL animations presented in an event-related fMRI design shown on the right. B. Mean(SE)   d  ' on the biological motion task performed during the event-related functional scan. C. Hit and false alarm rates associated with the d' values shown in panel B. 
  

#### Image acquisition 
  
All brain images were collected on a Philips Intera Achieva 3T MRI scanner located at the Vanderbilt University Medical Center, Nashville, TN. High-resolution T1 anatomical images were collected for each participant (170 slices, 1.0×1.0×1.0 mm). Functional images (single-shot EPI, TR = 2000 ms, TE = 25 ms, flip angle = 90°, matrix = 128×128, FOV = 240×240 mm) were acquired over the whole brain, parallel to AC-PC line (25 slices, 1.875×1.875 mm in plane, 4.5 mm thick with 0.45 mm gap). Visual stimuli were presented using a DLP projector connected to a Macintosh G4 computer (Apple Inc., Cupertino, USA). The projector's image was back-projected onto a screen located at the observer's feet and viewed through a periscope mirror attached to the head coil. 


#### Image analysis 
  
Imaging data were preprocessed and analyzed using Brain Voyager QX 1.10 (Brain Innovations, Maastricht, The Netherlands). The anatomical volumes were transformed into stereotaxic space  , and functional volumes for each participant were aligned to these transformed anatomical volumes. Functional volumes were also preprocessed following procedures including realignment, three-dimensional motion correction, linear de-trending, high-pass temporal frequency filtering, and spatial smoothing with a 4 mm FWHM spatial filter. 

To localize regions of interest (ROIs), the general linear model (GLM) was applied to the time-series of task-related functional volumes. ROIs for each individual were then defined as contiguous voxels within the anatomical region of cortex corresponding to the caudal portion of the superior temporal sulcus that were significantly activated by biological motion relative to scrambled motion at a false discovery rate (FDR) of q<0.05, or p-value (uncorrected) lower than 0.003 (if STSp is not successfully localized at the given FDR). The same analysis was applied to voxels in the general anatomical region of the human MT+ complex, this time contrasting activations to optic flow and static dots. Among observers the numbers of voxels identified by these methods ranged from 15–174 in STSp and 38−263 in MT+. 

To analyze the functional imaging data, the design matrix (reference time course) was defined to include 4 predictors based on each individual's behavioral response: (1) activation associated with hits (“biological” response to biological motion), (2) activation associated with correct rejection (“scrambled” response to scrambled motion), (3) activation associated with false alarms (“biological” response to scrambled motion), and (4) overall activation to 37% scrambled motion. While there is no objectively correct answer for trials involving 37% scrambled motion, we initially intended to analyze the fMRI results for those trials based on observers' perceptual judgement (“biological” vs. “scrambled”); as reported in the Results, however, there were too few “biological” responses to make that possible. Miss trials (“scrambled” responses to biological motion) also had to be excluded from fMRI analyses because of the paucity of these trials. Within the defined ROIs, the voxels coupled with the event-related trials were averaged to create a single time series for each condition (predictors) in each individual. MR signal levels coupled with each condition were averaged to create an estimate of BOLD activity through the process of event-related averaging in Brain Voyager QX. Percent change in BOLD signal associated with each condition was defined as difference between baseline (activation at the stimulus onset) and the peak activity following stimulus onset. That peak was identified from the actual BOLD signal values plotted over time, not estimated from fitted hemodynamic response functions. 



### Results 
  
#### Behavioral results 
  
On the biological motion and scrambled motion trials, schizophrenia patients had significantly lower discrimination sensitivity (  d  ') compared to healthy controls ( ), consistent with our earlier study  . Mean (SE)   d  ' was 2.54 (0.4) in patients and 3.82 (0.32) in controls (t(18) = 2.45, p = 0.024). Both groups had high hit-rates (controls: 98.4 (1.08)%, patients: 94.6(3.42)%, p = 0.2). The difference in the incidence of false alarms was large (Cohen's   d =   0.75) but failed to achieve statistical significance (controls: 19.7(5.8)%, patients: 37.7(9.7)%, p = 0.13,) (see  ). Behavioral results from the 37% scrambled motion trials reveal that patients and controls tended to categorize these animations as scrambled, although the incidence of biological responses was larger in the patient group (19%, on average) compared to the control group (4%, on average). Strictly speaking, these “biological” responses cannot be categorized as incorrect, because sequences with 37% scrambling do look more biological than 100% scrambled sequences. (In informal pilot testing of controls and schizophrenia patients, all participants rated both 30% and 45% sequences as more human-like than 60% scrambled sequences, so 37% is undoubtedly seen as different from scrambled.) Still, the higher incidence of “biological” responses from schizophrenia patients viewing the 37% scrambled sequences certainly comports with results from our earlier study   where patients had higher false alarm rates than normal controls. Unfortunately, the number of these kind of trials was insufficient to permit analysis of imaging data on trials where 37% scrambled was judged biological. 

The behavioral performance (as indexed by d') of the patients measured while they were in the scanner was not significantly correlated with the severity of their clinical symptoms as indexed by rating scales (BPRS, SAPS, and SANS). 


#### Localization of STSp and MT 
  
In nine healthy participants, the STSp was functionally localized by subtracting activation to scrambled motion from activation to biological motion at the threshold of q(FDR)<0.05. In the tenth healthy control participant, STSp was localized by applying p<0.003 (uncorrected) because the area was not clear at q(FDR)<0.05. Among the ten members of the schizophrenia group, STSp was localized in six individuals at the threshold of q(FDR)<0.05. For two other patients, that threshold level had to be adjusted to p<0.003 (uncorrected) to localize STSp. For the remaining two patients, STSp could not be localized even by this more lax criterion. As an alternative, the location of STSp in their brains was estimated by identifying significant BOLD activations during biological motion blocks relative to baseline and then delimiting the activated voxels to just those successfully localized in other eight patients. 

Area MT was successfully localized in all participants by contrasting activation to optic flow stimuli with that to a static dot field. 

Mean (SD) Talairach coordinates of the two ROIs are shown in  , which is similar to those of a previous study  . For reference,   shows those ROIs–STSp and MT–in one normal control and one schizophrenic patient. 
   Talairach coordinates of the defined ROIs.        

#### Event-related activity in STSp 
  
Group averaged peak BOLD responses for hit, correct rejection, and false alarm trials are shown in  . We have no control, of course, over the number of trials contributing to these three categories, for those categories are defined by the stimulus   and   by the participants' responses. Because hit rates were higher than false alarm rates for both groups, more fMRI BOLD signal estimates comprise the responses associated with hits than with the other two categories, but this is true for both healthy controls and patients. Moreover, a multifactorial repeated measures ANOVA confirmed that overall activations across these three categories did not differ significantly between groups (F(1,30) = 0.031, p = 0.86). The main effect of the signal detection category was not significant, either (F(2,60) = 0.93, p = 0.40), but the interaction between signal detection category and diagnosis was significant (F(2,60) = 4.57, p = 0.014). ANOVA with two selected categories also revealed significant interaction effects (hit vs. correct rejection: F(1,30) = 6.89, p = 0.01; correct rejection vs. false alarm: F(1,30) = 9.63, p = 0.004). These statistical analyses confirm the impressions portrayed by the patterns of results seen in the summary data in  . 
   Experiment 3: Brain imaging results from STSp.  
A: Average time-series associated with each of three signal detection categories (hit, correct rejection, false alarms) in controls (left) and patients (right). Time value 1 denotes stimulus onset (TR = 2 sec). B: Each histogram plots, for patients and healthy controls, the peak BOLD signal levels (1 SE) associated with each of the three signal detection categories. C. Same as panel B, with data removed for the two schizophrenia patients for whom STSp localization was based on anatomy, not differences in activations on the STSp localizer. 
  
Summarizing those results for the two groups separately, healthy individuals produced significantly greater STSp activation on hit trials (biological motion perception) than on correct rejection trials (scrambled motion perception) (F(1,16) = 12.05, p = 0.003). Interestingly, STSp activations on false alarm trials were not significantly different from activations on hit trials (F(1,16) = 1.22, p = 0.29), suggesting that people with strong STSp activation on a given trial tend to perceive the animations presented on those trials as biological motion. This correlation between perceptual state and brain activation has been reported for other visual tasks as well  , and it is a point we return to in the  . On the other hand, schizophrenia patients did not show differential activation for the three signal detection categories: levels of STSp activation within patients were not significantly different across hits, correct rejections and false alarms (F(2,24) = 0.512, p = 0.65). The same conclusion is reached when we perform pair-wise comparisons of hits to false alarms (t(12) = 0.21, p = 0.84), hits to correct rejections ( t(12) = −0.72, p = 0.49) and correct rejections to false alarms (t(12) = 1.107, p = 0.29). This absence of differential activation in patients quite plausibly could contribute to their poor ability to discriminate biological motion from scrambled motion, for within STSp those two categories of animations produce highly similar levels of activity. 

It is natural to wonder why STSp in patients showed no differential activation on hit and correct rejection trials event though the two categories of PL animations presented on those trials–biological and scrambled–were used successfully in 8 out of 10 patients to identify STSp on the localizer trials. These differential results, we surmise, are attributable to the fact that block designs typically generate more robust BOLD signals than do event-related designs. This was certainly true for our experiment: average peak activations (biological and scrambled) for STSp in patients averaged 0.59% in the block design but only 0.4% in the event-related design. The tasks, too, were different for the two designs, although it is not obvious why the one-back task (used in the block design) would promote differences between scrambled and biological whereas the categorization (used in the event-related design) would not. We will consider the general question of task performance and event-related imaging results further in the  . 

As mentioned earlier, STSp was not successfully localized using conventional statistical methods in two of the ten schizophrenia patients. To be sure their results were not responsible for the lack of BOLD signal differences between scrambled and biological sequences in the schizophrenia group, we reanalyzed the group data with those two individuals' data removed (n = 8). This additional analysis yielded the same pattern of results ( ): the main effects of diagnosis and of signal detection category were not significant (F(1,28)<0.001, p = 0.99; F(2,56) = 0.67, p = 0.52, respectively) and the interaction effect was significant (F(2,56) = 4.22, p = 0.02). Interaction effects between two signal detection categories (hit vs. correct rejection; correct rejection vs. false alarm) were also significant (F(1,28) = 5.2; p = 0.03; F(1,28) = 9.32, p<0.01, respectively). We are thus confident that the two patients in whom STSp was not conventionally localized were not the sole source of the overall differences between patients and normal controls. 

As mentioned before, the paucity of “biological” responses in the 37% scrambled condition precluded statistical analyses of the fMRI results for this condition contingent on the perceptual report. We were able, however, to perform group comparisons of the overall activation levels for this stimulus condition irrespective of response category, and those activations did not differ between the groups (t(30) = 0.93, p = 0.36). 

Clinical symptom scores from the schizophrenia patients were not significantly correlated with STSp peak activation in any signal detection category. 


#### Event-related activities in MT 
  
The same analysis procedures were applied to MT activations measured during the biological motion task (see  ). There was no significant group (diagnosis) difference in overall activation (F(1,35) = 2.24, p = 0.14), nor a significant main effect of signal detection category (F(2,70) = 1.43, p = 0.25). Unlike STSp activation, the diagnosis×signal detection category interaction effect was not significant (F(2,70) = 0.18, p = 0.84), indicating that MT activation is not associated with stimulus type or observer's response. 
   Experiment 3: Brain imaging results from MT.  
Same format as in  . 
  
To learn whether MT activity level is related to STSp activation, we computed the correlation between peak activations between the two areas. In healthy controls, there were no significant correlation between STSp and MT activation in any of signal detection categories. In patients, the correlations between STSp activity and MT activity for hit trials and correct rejection trials were not significant. There was a significant correlation on false-alarm trials, but it was restricted to the left STSp and MT (r = −0.88, p = 0.047 in left; r = 0.25, p = 0.51 in right). However, the sample size was small: left STSp was localized in only 5 patients, including one who exhibited extraordinarily strong activation. In general, we see no strong indication that MT activation predicts responses in STSp when results are analyzed contingent on the participants' responses to given categories of stimuli. 




## Discussion 
  
The behavioral experiments confirm that schizophrenia patients, compared to healthy controls, experience difficulty distinguishing biological motion from non-biological motion sequences. We have now seen these group differences on three complementary tasks: simple categorization of sequences as biological or scrambled (Reference 13, and the behavioral component of Experiment 3), discriminating biological from scrambled in the presence of distracting noise (Experiment 1) and discriminating biological motion sequences in which the spatio-temporal coherence of the dots defining kinematics is perturbed (Experiment 2). Moreover, we have identified a potential neural correlate of this deficit in the BOLD signals measured from STSp, a brain area known to be involved in perception of biological motion. 

Can these results be attributed to the fact that all patients in this study were taking antipsychotic medication at the time of testing and scanning? Past perceptual and cognitive studies with schizophrenia patients have not found significant differences in performance between medicated and non-medicated patients (e.g.  ), nor have they found a significant correlation between medication and performance  , which is what we too observed in the present study. We are, therefore, disinclined to believe that medication alone is the sole factor responsible for our patients' performance deficits. What, then are the reasons for these deficits? In the following paragraphs we consider alternative interpretations of these findings. 

Starting with the psychophysically measured perceptual deficits in schizophrenia patients, it is reasonable to ask whether they are unique to biological motion or, instead, stem from a more general problem in motion perception. Indeed, earlier work has shown that schizophrenia patients require stronger translational motion signals to discriminate direction of motion in random-dot cinematograms (RDC) containing signal and noise dots  . And it is true that our masking study involved detecting biological motion figures embedded in dynamic noise dots, similar to the conventional RDC task. For several reasons, however, we believe that the deficits perceiving biological motion go beyond simply a deficit in perceiving signal dots within noise. First, the discrimination task (Experiment 2) did not involve noise dots, yet deficient performance was observed. The same is true for our earlier task   and for the behavioral task employed in our brain imaging study (Experiment 3). Second, the stimulus information supporting detection of weak translational motion within fields of random dots is fundamentally different from the information specifying the hierarchical, pendular motions of dots creating the vivid impression of biological motion. Third, these two disparate forms of motion perception appear to be mediated by distinct neural mechanisms as evidenced by their different integration time constants  , their dissociation consequent to brain damage  – , and the different activations they produce during imaging studies in normal people (e.g.  ). Fourth, neither controls nor patients showed differential MT activation contingent on signal detection categories, and furthermore, we found no meaningful correlations between MT and STSp peak activations in either group. These observations imply that the neural events critical for perception of coherent, translational motion differ, at least in part, from those involved in biological motion perception  ,  . Based on four these reasons, we believe the deficits observed on these various tasks involving biological motion sequences are not attributable solely to difficulties perceiving motion in general but, instead, arise from impairments in extracting the kinematics unique to biological motion and effectively isolated using PL animations. 

Is it possible that this deficit in perception of biological motion perception in schizophrenia patients is related to a more general problem involving visual grouping of spatially distributed visual elements? We know, for example, that chronic schizophrenic patients are impaired in their ability to recognize objects portrayed in fragmented images in which portions of the contours defining the objects are invisible  . This task presumably taps into an ability to fill in missing information using a contour interpolation processes. Perceiving biological activity from PL animations could also be construed as involving interpolation of missing information, in this instance information ordinarily available when viewing whole-body movements and not just the movements of select portions of the body designated by PLs. We have no quarrel with this way of characterizing the nature of the task, and we are intrigued by findings implicating impaired dorsal stream processing as a correlate of deficits in perceiving fragmented objects by schizophrenia patients  . After all, STSp is a component of this broad dorsal stream network. We are reluctant to conclude, however, that the neural processes involved in perceiving static fragmented figures are the same as those responsible for perception of dynamic activity portrayed by PL sequences since the latter, but not the former, requires integration of information over time as well as over space. It would be interesting indeed to examine correlations in performance on these rather different tasks in schizophrenia patients and, for that matter, in healthy controls. 

In a related vein, it is conceivable that the difficulties experienced by schizophrenia patients when viewing PL animations is somehow related to the well-established abnormalities in temporal integration in these patients  ,  . Perhaps in our tasks the 1-sec presentation durations, while adequate for healthy controls, are simply too brief for sufficient visual processing by the patients. We doubt that the presentation duration limited their ability to fixate the displays, for in two of our tasks (Experiments 1 and 3), the PL animations were presented at fixation. In the task involving simultaneous presentation of two animations, saccadic eye movements would be required to achieve successive glances of the stimuli, but existing evidence indicates that simple saccadic eye movements are intact in schizophrenia patients  – . But it is possible that limitations in integration of visual information over time contribute to the perceptual deficits documented in our study. Indeed, it is known that temporal summation for perception of biological motion extends beyond one second  , so an impairment in temporal integration could place patients at a disadvantage relative to healthy controls. It could be informative to assess temporal integration in perception of biological motion in patients, by systematically varying exposure duration. 

Turning now to the brain imaging results, in healthy control participants STSp activation was stronger when biological motion was perceived correctly (hits) than when scrambled motion was perceived correctly (correct rejection). This merely confirms what was already known, namely that STSp selectively responds to biological relative to scrambled PL sequences  ,  ,  ,  . In contrast, however, schizophrenia patients showed comparable levels of event-related activations in STSp across all signal detection categories, including those where the stimulus involved presentation of scrambled motion. For that matter, we also had more difficulty pinpointing STSp in a couple of our schizophrenia patients using our localization procedure that contrasts biological and scrambled sequences in a simple block design. At present we can only speculate about possible reasons why STSp in these patients produced strong, undifferentiated responses to these different categories of PL animations. It is well known that schizophrenia is characterized by reduced grey matter volume in a variety of brain areas including the superior temporal lobe. Moreover, there is growing evidence that schizophrenia is associated with disordered neural connectivity among brain areas (see review  ). To the extent that those connections mediate inhibition of during task-related activities  , we might expect schizophrenia patients to exhibit reduced suppression of activity within brain areas important for registering information kinematics, just as a lack of suppression may underlie their poorer performance on working memory tasks  . 

Given these event-related results from schizophrenia patients, it is natural to wonder what neural information they were using when trying to perform the behavioral tasks we administered to them. After all, their behavioral performance, while reduced relative to normal controls, implies that they could distinguish scrambled from biological sequences at above chance levels. One possibility is that brain areas other than STSp contain neural responses sufficient to signify the nature of the PL animation being viewed  . To evaluate that possibility, we looked throughout all brain volumes scanned during event-related brain imaging in our schizophrenia patients, in search of voxels showing reliable signal differences between hit trials (when biological sequences were judged biological) and correct rejection trials (when scrambled sequences were judged scrambled). That whole brain analysis turned up just a few, small clusters of voxels showing significant activation differences. None of those clusters, however, were located within neural structures associated with biological motion activations in normal individuals, leading us to conclude that they were chance differences arising from the multiple comparisons we performed in this analysis. 

Alternatively, it is conceivable that on given trials STSp in schizophrenia patients can produce patterns of neural activity that correctly signify the category of animation being viewed (e.g., biological). This possibility is not incompatible with our event-related fMRI results, for those results comprised peak levels of activation averaged over multiple trials for each of the signal detection categories. 

One potential clue about the possible involvement of STSp in the performance of schizophrenic patients may come from reconsideration of the false alarm trials and the accompanying brain activations in STSp. Recall that strong STSp activation was observed in healthy individuals on false alarm trials, i.e., error trials on which scrambled motion sequences were seen as biological. Perhaps, then, perceptual errors on false alarm trials-seeing something that is not actually there-are manifestations of neuronal activity ordinarily involved in registering the presence of biological motion. Continuing this line of reasoning, we now know that in schizophrenia patients scrambled sequences produce activations as large as those produced by biological motion sequences, which could well be responsible for their higher false alarm rates on the biological vs. scrambled categorization task (Experiment 3 and Reference 13) and for their general difficulty discriminating biological from scrambled sequences in noise (Experiment 1) or discriminating sequences differing in degree of scrambling (Experiment 2). What we are suggesting, therefore, is that the deficits in biological motion perception in patients are an exaggerated manifestation of the neural events within STSp associated with perceptual errors sometimes made by healthy observers on these same tasks. 

Given this possibility, what can we conclude about the origins of the strong STSp activations on false alarm trials? First, it is possible that intrinsic neural noise causes activity levels in STSp to fluctuate spontaneously over time, the consequence being that activity induced by a suboptimal stimulus achieves abnormal levels that mimic activity patterns ordinarily associated with a coherent biological event. This account, however, cannot explain why, in healthy individuals, STSp activity is elevated during visual imagery. Instead, imagery and false alarm-associated activations could result from top-down influences on perception of biological motion, of the sort suggested by earlier work  – . For example, efficiency of biological motion processing is strongly influenced by action categories: certain familiar actions (e.g. walking) are generally recognized more quickly and more accurately. This has led to the proposal that high-level vision contains “selective movement filters”   or “sprites”   that embody models of common actions exhibited by familiar objects including people. Through top-down processes such as attention, these high-level schemas can modulate weak, ambiguous or noisy motion signals and, thereby, bias perception in favor of familiar actions under conditions like those used in our studies (e.g.  ) One possible candidate for the neural locus of these high-level representations is the inferotemporal sulcus (ITS), an area implicated in object recognition  ,  , visual imagery  , and perception of shape configuration  . ITS is also known to be responsive to biological motion  , suggesting that reciprocal connections between STSp and ITS could form at least part of the network involved in top-down influences on perception of biological motion. Regardless of the details of that network, it is clear that such top-down influences may well mediate the strengthened activation within STSp associated with false alarm trials. 

To end on a speculative note, our results may fit into the larger discussion about the nature of delusion, a discussion that centers around two themes: faulty perception vs. faulty cognition. The perceptual account explains delusions as the rational explanation of anomalous perception (in other words, the best, correct interpretation of noisy, poor quality sensory data: see  ). On the other hand, more cognitive account posits that those with abnormal beliefs tend to have cognitive biases that result in faulty hypothesis testing and jumping to conclusions (e.g.  – ). In fact, however, the two accounts could go hand in hand: poor quality sensory data necessitate increased involvement of cognitive processes to make sense of the world. Indeed there is evidence for complex interaction between cognitive and perceptual information processing that may account for hallucinatory and delusional experiences (e.g.  – ). Visual information processing is abnormal in schizophrenia (see  – ) and structural abnormalities have also been observed in the visual cortex  . Given that the quality of sensory data in these patients is compromised, they may need to rely more heavily on higher cortical regions (e.g., frontotemporal regions) to make sense of their visual world. Indeed It has been observed that schizophrenic patients give greater weight to top-down expectations on perception than normal controls do  . 

Construed in this context, what we have found in our study is that people with schizophrenia tend to “see” living things in randomness and this subjective experience is correlated with an increased activity in the STSp. This finding is broadly in agreement with past behavioral results suggesting that psychotic or psychosis-prone individuals tend to see meaning where there is none (e.g.  ), perhaps because they adopt a more lenient criterion for distinguishing perception and imagination owing to abnormal up-regulation of dopamine neurotransmitter  . In the case of biological motion perception, these self-generated, false impressions of meaning can have negative social consequences, in that schizophrenia patients may misconstrue the actions or intentions of other people. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-17'>
<h2>17. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/28947790/' target='_blank'>28947790</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> The effect of sleep restriction on empathy for pain: An fMRI study in younger and older adults</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Sci Rep</p>
<p><strong>Publication Year:</strong> 2017</p>
<p><strong>DOI:</strong> 10.1038/s41598-017-12098-9</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5612991/' target='_blank'>5612991</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of empathy for pain, a social-related task (Perception and Understanding of Others). It reports data from healthy volunteers and includes a young participant group aged 20–30 (within the 17–65 inclusion window). Whole-brain analyses are reported (pain>no pain and pain>baseline contrasts with FWE-corrected results and whole-brain maps available), alongside ROI analyses. No exclusion criteria are violated (not limited to ROI-only results and not reporting only clinical groups). Therefore the study meets all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Age and sleep both affect emotional functioning. Since sleep patterns change over the lifespan, we investigated the effects of short sleep and age on empathic responses. In a randomized cross-over experimental design, healthy young and older volunteers (  n   = 47 aged 20–30 years and   n   = 39 aged 65–75 years) underwent functional magnetic resonance imaging (fMRI) after normal sleep or night sleep restricted to 3 hours. During fMRI, participants viewed pictures of needles pricking a hand (pain) or Q-tips touching a hand (control), a well-established paradigm to investigate empathy for pain. There was no main effect of sleep restriction on empathy. However, age and sleep interacted so that sleep restriction caused increased unpleasantness in older but not in young participants. Irrespective of sleep condition, older participants showed increased activity in angular gyrus, superior temporal sulcus and temporo-parietal junction compared to young. Speculatively, this could indicate that the older individuals adopted a more cognitive approach in response to others’ pain. Our findings suggest that caution in generalizability across age groups is needed in further studies of sleep on social cognition and emotion. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (42858 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Empathy is a social skill needed for interaction with other people. Empathy can be defined as spontaneously sharing another person’s feeling while being aware of the source of the emotion . This function is vital in people-oriented occupations. Many of these occupations, such as healthcare or police, involve sometimes irregular work hours and sleep loss, a potential cause of disturbed emotions . Whether social emotions, such as empathy, are affected by sleep loss, is however not known. The brain networks underlying empathy are well-studied mainly in younger adults, and the same holds true for most research on sleep and emotion. In spite of changes in both sleep  and emotional functioning in elderly humans , the role of adult aging in sleep-induced emotional modulation is uncharted. 

Sleep restriction in young adults has been shown to be associated with increased amygdala activation in response to negative stimuli , and decreased functional connectivity between the prefrontal cortex and amygdala , suggesting decreased capacity for emotional control. Because sleep restriction affects emotional processes engaged during social emotions , an effect of disturbed sleep on empathy can be expected. A common model for empathy involves shared emotions  and several studies have demonstrated that seeing another person in pain leads to a subjective emotional response and activates the anterior insula (AI) and anterior midcingulate cortex (aMCC) bilaterally . The network involved in empathy partially overlaps with processing of self-experienced pain , but possibly with a different underlying pattern . In the early study by Singer   et al  ., activity in anterior insula was found to be correlated to self-rated trait empathy , but few other studies have replicated this correlation . Activation of self-related systems is believed to allow emotional understanding of others, and to contribute to successful social interaction . In spite of high relevance in both occupational and social settings, only one experimental study has studied sleep and empathy, reporting decreased self-reported empathy after sleep restriction . No study has to our knowledge investigated effects of sleep restriction on neural substrates of empathy, nor the impact of age in this context. 

Older adults sleep less compared to younger, and sleep disturbances are more common in the elderly . Conversely, older individuals are less affected by day-time sleepiness after sleep restriction . In sleep restriction studies, older participants have shown less effects of restricted sleep on cognitive outcomes . This could be true for emotional outcomes as well, but no study has so far investigated the interaction between aging, sleep, and social emotions. 

During healthy aging, changes in emotional functioning are observed, such as decreased capacity to detect emotions in others, and positive bias in attention and memory . Behavioural studies suggest an increase in empathic capacity in older individuals . Results are however inconclusive , and studies that use physiological outcomes are lacking. One functional magnetic resonance imaging (fMRI) study investigated emotional empathy for pain in 3 age groups (age: 20–35, 40–55, 65–80), claiming evidence for empathy-related decreased activity in AI and aMCC with older age . 

As manifested in behavioural as well as neural measures, both age and sleep thus affect many emotional processes . However, associations between sleep and empathy, as well as the interaction between sleep and age in relation to empathy, are almost entirely lacking. The present study thus aimed to investigate the interplay between age and sleep restriction on self-reported and neural responses to pain in others. We hypothesized that sleep restriction causes decreased ratings of vicarious unpleasantness and decreased responses in AI and aMCC to others’ pain. In the preregistration (see below), this was formulated as follows: 1. Partial sleep deprivation (PSD) will cause decreased ratings of unpleasantness, 2. Pain stimuli will cause greater BOLD responses in the anterior insula (AI) and anterior/middle cingulate cortex (ACC/MCC) than control stimuli and PSD will interact with this increase to cause lesser increases to pain stimuli. Given the sparsity of previous research at study preregistration, no specific hypotheses regarding expected differences between younger and older participants in empathic responses, and age*sleep restriction effects on empathy, were registered. A complete list of preregistered hypotheses addressed in this manuscript is presented in the supplement. 


## Methods and Materials 
  
### Design 
  
In a randomized cross-over design, healthy volunteers underwent MRI scanning on two occasions approximately one month apart after normal sleep and sleep restriction in a counter-balanced fashion (see below). In the sleep restriction condition, participants were instructed to sleep 3 hours in the end of their normal sleep period. MRI scanning took place in the following evening, starting between 5 PM and 8 PM. The study was carried out as part of a larger project, see ref. , with data collected between 121203 and 140429. At each occasion, the experiment lasted for about three hours and included three different emotional paradigms, as well as two resting state sessions, see ref.  for details. The experiment reported here was performed after an experiment on emotional mimicry and before an emotional regulation task for all participants. The study was approved by the Regional Ethics Review board of Stockholm (2012/1870-32) and preregistered at clinicaltrials.gov (  NCT02000076  ) with a separate hypotheses list published at Open Science Framework (  https://osf.io/bxfsb/  ), where the present experiment is referred to as “HANDS”. Experiments were performed in accordance with the Declaration of Helsinki and applicable local regulations. Preliminary results from this study have been previously reported . 


### Participants 
  
Participants were recruited through the website   www.studentkaninen.se  , by posters at university campuses, and by a newspaper advertisement. We started recruiting young participants in December 2012. We used the following inclusion criteria: age 20–30 or 65–75 years, right-handedness, habitual bedtime between 22:00 and 01:00 on weekdays, adequate visual acuity (or mild hyperopia/myopia <5 dioptres), fluent in Swedish and living in the Stockholm area. We also used the following exclusion criteria: current or past psychiatric or neurologic morbidity, regular use of nicotine, studying or working in medicine, psychology, health care or behavioural sciences, consumption of >4 cups of coffee (or a corresponding amount of caffeine) per day, magnetic implants, colour blindness, diabetes, hypertension, use of any psychoactive drugs, self-reported claustrophobia or past heart surgery. Participants were also screened using the Insomnia Severity Index (ISI) and the Hospital Anxiety and Depression Scale (HADS) and excluded if they had ISI ≥ 15 or HADS-Depression ≥8. When we started recruiting older participants (in October 2013), we added the exclusion criterion self-reported snoring or sleep apnea symptoms more than 3 times a week. Since obstructive sleep apnea syndrome (OSAS) disturbs sleep and is more common in older people, not screening for this would have possibly introduced a confounding factor. Before that, one young participant, who reported snoring regularly 3–4 times a week, was included and was not subsequently excluded from analyses. Criteria were verified when participants arrived for the first MRI scanning session. Forty-seven young and 39 older participants were included in at least one analysis (Fig.  ). All participants gave written informed consent, and were compensated with a minimum of 2500 SEK (approximately 300 USD). Thirty-eight young and 33 older participants were included in all analyses, see below.   
Inclusion flowchart showing participants screened and enrolled in the experiment. 278 young and 226 old participants were screened and 54 young and 44 old were enrolled in the experiment. One young participant and 3 old participants were excluded during the experiment after we discovered that they did not fulfil criteria. Four young participants were excluded from all analyses due to pathological findings on MRI. One young participant cancelled her participation after sleep intervention due to a headache. One young participant panicked in the scanner and 2 old participants were unable to undergo the experiment due to claustrophobia. We aimed for 30 participants with complete data in each group, and there was more data loss/drop out in the younger group. 
  


### Rating scales and demographic measures 
  
Participants were characterized using rating scales and demographic measures . Interpersonal Reactivity Index (IRI)  and Psychopathic Personality Inventory-Revised (PPI-R)  were used at baseline to characterize trait empathy and psychopathy. The Swedish translation of the IRI has been validated , and we investigated the subscale empathic concern (IRI-EC) as a predictor for empathic responding. The rationale behind this was that in the Swedish validation, confirmatory factor analysis showed that the four subscales only distribute over two factors, one of which consists of the empathic concern subscale . For PPI-R we used the subscale coldheartedness. Participants rated their sleepiness several times during the experiment using the Karolinska Sleepiness Scale  and for this experiment we used the sleepiness rating immediately following the fMRI paradigm. 


### Randomization and sleep intervention 
  
Participants were randomized in blocks of 4 to have sleep restriction on the first or second night. In the final sample, 26 of the younger and 20 of the older participants started with the full sleep condition and 21 of the younger and 19 of the older started with the sleep restriction condition. During the nights before both fMRI sessions, polysomnography was recorded in the homes of the participants  (results reported in Åkerstedt, submitted). Participants were instructed to either sleep as usual or for 3 hours before their normal time of rising, respectively. Successful intervention was defined by total sleep time >4 hours in the full sleep condition, <4 hours in the sleep restriction condition, and a difference between the two conditions >2 hours. Four young participants and 5 old participants did not fulfil these criteria and were therefore not included in analyses of the effect of sleep restriction. For 4 young eligible participants and 4 old eligible participants, these criteria could not be based on polysomnography, because of incomplete data. For these, subjective reports of sleep length (sleep diaries) were used. Researchers performing fMRI were blinded to participants’ sleep condition. 


### fMRI paradigm and behavioural data acquisition 
  
Participants were shown 20 colour pictures of hands being pricked by needles and 20 pictures of hands being touched with a Q-tip (Fig.  ). This is a well-established stimulus set used in previous studies of empathy for pain  and we will refer to the stimuli as “pain” and “no pain” respectively. The pain stimuli have been shown to activate aMCC and AI bilaterally, in a pattern similar to that seen in studies where pain has been inflicted to a person present in the same room . The stimulus set is available at   https://doi.org/10.6084/m9.figshare.3490421.v1  . Participants rated the intensity of unpleasant affect experienced while seeing each stimulus on a visual analogue scale from 0 to 100 by moving a cursor, using a box with 3 buttons (move right, move left and respond) in their right hand. Participants were instructed that 0 would represent no unpleasantness and 100 would represent the worst imaginable unpleasantness. This rating measure has been successfully used before to measure vicarious (shared) affect, a central component of empathy . The cursor was shown at different starting points on every trial to avoid anchoring bias. Stimuli were shown using Presentation software (  www.neurobs.com  ) through eye-tracker goggles (VisualSystem, NeuroLab  )  , adjusted for participants’ visual acuity. Participants’ ratings were recorded using Presentation software. It has been estimated that as many as 30% of subjects may fall asleep during resting state scanning, even during non-sleep deprived conditions , and we therefore verified that no participants fell asleep during the experiment using an eye-tracker, which was also used to record pupil diameter. Heart rate was recorded using a pulse oximeter on the left middle finger.   
fMRI task. Stimuli showing either pain (needles) or no pain (Q-tips) were shown for 3.5 seconds and perceived unpleasantness was rated after each stimulus. 
  


### Analyses of participants’ ratings 
  
Effects of stimulus type (pain or no pain), sleep condition (full sleep or sleep restriction) and age group (young or older) on rated perceived unpleasantness were investigated using mixed effect models, to handle variance due to repeated measures in the same subjects and slightly unbalanced group sizes. A random intercept was modelled for each subject and stimulus type and sleep condition were entered as fixed within-subjects effects. Age group was modelled as a fixed between-subject effect. All fixed effects were allowed to interact. Results are reported as model estimates in original units (ratings from 0 to 100) with 95% confidence intervals. To control that observed results were not due to possibly confounding variables, test time type (whether participants were scheduled early or late in the evening), session (1st or 2nd scanning), and sex were added sequentially as covariates. Sex and session interacted significantly with stimulus type. In general, unadjusted results are reported. Adjusted results are only shown when differing from unadjusted. Since we did not expect any unpleasantness for the no pain stimuli, introducing a floor effect and unequal variance, the main analyses were performed stratifying for stimulus type. 

Possible predictors for empathic responses (self-rated empathy, self-rated psychopathy and self-rated sleepiness) were included as fixed effects one by one in the model. The same procedure was followed for potential habituation effects, where stimulus number was included as a fixed effect. Differences in variability for ratings were investigated using mixed effects models, since we thought that sleep restriction might affect accuracy in responding. Behavioural data were analysed using R version 3.3.0  and scripts can be found at   https://doi.org/10.5281/zenodo.846863  . 


### Analyses of pupil diameter and heart rate 
  
Heart rate recordings were manually inspected for quality and sessions of poor quality were excluded. As described in ref.  , time courses were inspected for each participant and recordings judged as excessively noisy were excluded (  n   = 22, 14%). Heart rates <40 beats per minute (bpm) or >100 bpm were considered non-physiological and were censored. Recordings with less than 50% of data remaining would have been excluded at this stage, but were not present (  n   = 0). Where possible, censored data were imputed using carry-forward of the last non-censored heart rate, which is likely to be a conservative procedure when investigating event-related responses, since it will tend to underestimate changes. 4% of data were censored, out of which 78% were imputed. For each stimulus, heart rate was normalized to the baseline 4 seconds before stimulus onset, and averaged for a window 3.5–5.5 seconds after stimulus onset (poststimulus window). These values were entered into mixed-effects models. The final dataset contained 4578 observations from 115 sessions in 68 subjects. 

Pupil diameter recordings were discarded where height or width were <0.1 mm or >0.3 mm, or where the first derivative was <−3 or >3, indicating loss of tracking e.g. due to eye blinks. For events where at least half the data were retained in a window from −4 to 10 seconds after stimulus onset, height and width were interpolated using loess regression. Pupil diameter was calculated as an average of recorded height and width, was normalized to the baseline 4 seconds before stimulus onset, and averaged across time for windows 0–3.5 and 3.5–5.5 seconds after stimulus onset. These values were entered into mixed-effects models. The final dataset contained 2507 observations from 102 sessions in 73 subjects (38% of data retained from all 166 recorded sessions). 


### Magnetic resonance image acquisition and preprocessing 
  
Imaging data were acquired using a 3.0 T scanner (Discovery MR750, GE) and an 8-channel head-coil. Foam wedges, earplugs, and headphones were used to reduce head motion and scanner noise. We acquired T1-weighted structural images with whole-head coverage, TR = 6.4 s, TE = 2.8 s, acquisition time 3.58 min and flip angle = 11°, without fat suppression at both sessions. Structural scans were inspected and the one with best quality was used in fMRI data preprocessing. Functional images were acquired using gradient echo-planar-imaging (EPI), TR = 3 s, TE = 34 ms, flip angle = 80°, slice thickness 2.3 mm with 0.1 mm spacing, axial orientation, frequency direction R/L, interleaved bottom up. Higher order shimming was performed and the number of dummy scans before the experiment was 5. The number of slices was 45 or 46. Field of view was placed so that the lowest slice was at the lower margin of the pons. B0 maps were acquired for 40 of the young and 37 of the older participants at both sessions, dTE 2 s. Some additional participants had a B0 map for one of 2 sessions, but to avoid confounding between sessions those were not used. 

Imaging data were analysed using SPM12 (  http://www.fil.ion.ucl.ac.uk/spm/software/spm12/  ) running on Matlab2014 (MATLAB 2014, The MathWorks, Inc., Massachusetts, United States). Voxel displacement maps were created from B0 maps using the real and imaginary option in the Fieldmap toolbox. Functional images were preprocessed separately for each session. Images were slice-time corrected with slice no 2 as reference using sinc-interpolation, followed by realignment and unwarping, with 2nd degree B-spline interpolation using a voxel displacement map when possible (see above). Movement parameters were converted to framewise displacement time series, defined as the sum of the absolute values of the derivatives of the six realignment parameters after rotational displacements were converted from degrees to millimetres by calculating displacement on the surface of a sphere of radius 50 mm. Mean framewise displacement did not differ significantly between age groups or sleep conditions and is presented in suppl. Figure  . 

Functional and structural images were co-registered, structural image was set as reference image, mean EPI as source image and all EPI images as “other”. Structural images were segmented and a group specific template was created using DARTEL with default settings in SPM12 . Functional images were then normalized to MNI space using flow fields from the previous step through the DARTEL tool. This routine includes an initial affine registration of the DARTEL template with the tissue probability map data released with SPM. Smoothing was performed with a FHWM 8 × 8 × 8 mm kernel. Voxel size after preprocessing was 1.5 × 1.5 × 1.5 mm. All structural images and the first functional image in each session were inspected before, during, and after preprocessing. Scripts used in the preprocessing, as well as in the analyses can be found at   https://zenodo.org/record/846863#.WZyEsCig9nI  . 


### Analysis of fMRI data 
  
Fixed effects models at 1st level included regressors for pain and no pain stimuli, convolved with the canonical hemodynamic response function. Rating events as well as button presses and movement parameters were included as regressors of no interest. Contrasts of interest were pain>no pain, pain>baseline and no pain>baseline, to investigate effects of sleep restriction and age on both pain stimuli and control stimuli. 

At 2nd level, one sample t-tests were used to investigate main effects of stimulus type across age groups and sleep conditions. F contrasts were used to test effects of sex, test time type, and session as covariates. At a significance level of   p   < 0.001 uncorrected, none of the covariates showed significant effects in relevant areas on the main contrast pain>no pain, and main analyses were performed without controlling for them. 

To investigate effects of sleep condition and age group on 1st level contrasts, we used a flexible factorial design. Sleep condition was entered as a within-subject factor and age group as a between-subject factor. To confirm directions of interaction effects, mean contrast values were extracted from significant clusters and plotted. 

To test the hypothesis that sleep restriction would cause less AI and aMCC activity, we defined regions of interest as spheres with a radius of 10 mm around peak coordinates from the meta-analysis by Lamm   et al  . , as done in ref.  . Mean contrast values for pain>no pain in these regions were extracted per subject and session and entered in mixed effects models. To test associations between activity in AI and aMCC and IRI-EC and PPI-R, these variables were separately added to the models. 

To test the association between rated unpleasantness and fMRI responses an alternative 1st level model was created, in which participants’ ratings of perceived unpleasantness were entered as parametric modulators for pain, and brought to 2nd level for a 1 sample t test. Statistical maps from second level analysis can be found at   https://neurovault.org/collections/1219/  . When not stated differently,   p   < 0.05 at peak level was considered significant. For analyses including sleep and age, results are reported at   p   < 0.001 unc. in tables and figures for illustrative purposes. Cluster corrected statistics are provided in supplement. 


### Data availability 
  
The datasets analysed in the current study are available at   https://doi.org/10.5281/zenodo.846863   and in the OpenfMRI repository at   https://openfmri.org/dataset/ds000201/  . 



## Results 
  
### Characteristics of participants 
  
Descriptive statistics of rating scales, sleep measures and demographic data are presented in Table  . KSS ratings showed increased sleepiness after sleep restriction, reported as effect estimates in original units with 95% CI (1.6 [2.2, 1.1],   t  (169),   p   < 0.001, Table  ). Ratings of sleepiness and sleep measures are reported in detail in Åkerstedt   et al  . (submitted).   
Demographic data. Continuous values are reported as means with standard deviations, unless otherwise indicated. 
  
Categorical data are reported with percentages. Sleep measures are reported in minutes. 
  


### Ratings of unpleasantness 
  
#### Overall model 
  
Results are reported as effect estimates (rated unpleasantness) in original units with 95% CI. In an overall model, the three-way interaction stimulus type*sleep condition*age group was not significant (2.24 [−1.52, 5.99],   p   = 0.24). Effects of stimulus type (36.95 [36.01, 37.89],   p   < 0.0001) and stimulus type*age group (7.79 [5.91, 9.66],   p   < 0.0001) were strong. All other effects were non-significant. Results are shown in Fig.  .   
Ratings of perceived unpleasantness. Means and 95% CI. 
  


#### Pain stimuli caused increased unpleasantness compared to no pain stimuli 
  
Pain stimuli were rated as causing a more unpleasant experience than no pain stimuli, both for young (32.5 [31.4, 33.7],   p   < 0.001, Fig.  ) and older (38.8 [37.4, 40.1],   p   < 0.001, Fig.  ) participants, confirming expected vicarious responding. There was a small increase in rated unpleasantness for pain stimuli over the time-course of the scanning session (3.7 [1.8, 5.6],   p   < 0.001), but not for no pain stimuli (0.6 [−0.4, 1.7],   p   = 0.2). For no pain stimuli, participants generally did not report any unpleasantness (median 0, interquartile range 0–2). 


#### Sleep restriction caused increased unpleasantness in older, but not younger, participants 
  
For pain stimuli, age group interacted with sleep condition (3.1 [0.8, 5.5],   p   = 0.01, Fig.  ). When decomposed by age group, older participants reported increased unpleasantness (2.1 [0.2, 4.0],   p   = 0.03, Fig.  ), whereas no significant effect was seen in young participants (−1.1 [−2.5, 0.4],   p   = 0.16, Fig.  ) after sleep restriction. Across age groups, the effect of sleep restriction on unpleasantness in response to pain stimuli was not significant (0.5 [−0.7, 1.7],   p   = 0.4, Fig.  ). As reported above, age group and stimulus type interacted significantly in the full model. Across sleep conditions, older participants reported more unpleasantness to the pain stimuli, compared to young, but the difference was not significant (6.2 [−5.3, 17.7],   p   = 0.29, Fig.  ), hence the significant age group*stimulus type interaction. There was no significant main effect of age group on no pain stimuli (0.5 [−3.4, 4.5],   p   = 0.78, Fig.  ), nor any age group*sleep condition interaction (0.9 [−0.3, 2,2],   p   = 0.2). There was no effect of sleep restriction on perceived unpleasantness to no pain stimuli across age groups (−0.5 [−1.1, 0.1],   p   = 0.15, Fig.  ). 

Sleep restriction did not cause any change in variability in ratings for pain (−0.2 [−1.9, 1.5],   p   = 0.81) or no pain (1.2 [−0.4, 2.8],   p   = 0.16). Variability in ratings did not differ between age groups, neither for pain (−0.7 [−3.5, 2.1],   p   = 0.60), nor no pain (−0.1 [−2.6, 2.4],   p   = 0.93). 


#### Trait empathy predicted ratings of unpleasantness 
  
In an unadjusted model, self-rated empathy (IRI-EC) interacted with stimulus type (6.6 [4.8, 8.4],   p   < 0.0001). However, no association between rated unpleasantness and IRI-EC was seen in pain (6.6 [−4.9, 18.0],   p   = 0.3, suppl. Figure  ) or no pain (−0.2 [−4.2, 3.7],   p   = 0.9, suppl. Figure  ) when analysing the conditions separately. When including sex in the full model, the interaction was no longer significant (−0.9 [−2.9, 1.1],   p   = 0.37). Self-rated psychopathy (PPIR, coldheartedness) interacted with stimulus type (−1.1 [−1.27, −0.96],   p   < 0.0001). No association between rated unpleasantness and coldheartedness was seen in pain (−0.9 [−1.9, 0.11],   p   = 0.08) or no pain (0.23 [−0.12, 0.59],   p   = 0.20). 



### Heart rate and pupil diameter 
  
#### Sleep restriction was associated with increased pupil constriction 
  
Inspection of pupil diameter responses confirmed that stimulus onset was followed by constriction, as expected due to more light reaching the retina (suppl. Figure  ). Pain stimuli displayed on inspection a time-course with less constriction (suppl. Figure  ) and sleep restriction a time-course with more constriction (suppl. Figure  ). When diameter change was averaged over events and entered into a regression model with the tree-way interaction between stimulus type, restriction condition, and age group, only the effect of pain vs no pain was statistically significant (0.004 mm [0.002, 0.005],   p   < 0.001, suppl. Figure  ), indicating that pain stimuli were associated with less constriction. In a reduced model not including age group, the effect of sleep restriction was −0.003 mm [−0.006, −0.000],   p   = 0.04], indicating that sleep restriction was associated with more constriction. 


#### No effect of sleep restriction on heart rate 
  
Inspection of heart rate responses confirmed that stimulus onset was followed by deceleration, as expected due to processing of emotionally salient stimuli (suppl. Figure  ). Pain stimuli displayed on inspection a time-course with less deceleration (suppl. Figure  ) and sleep restriction a time-course with more deceleration (suppl. Figure  ). When heart rate was averaged over events and entered into a regression model with the three-way interaction between stimulus type, restriction condition, and age group, no effects were statistically significant (suppl. Figure  ). 



### fMRI results 
  
#### Pictures of pain in others activated bilateral AI and aMCC 
  
In the contrast pain>no pain, increased activity was observed in bilateral AI and aMCC (Table  , Fig.  ). Moreover, increased activity was observed in parietal and occipital areas, around the frontal gyri and in the thalamus. These activations overlaps with results of a meta-analysis of empathy for pain studies . As both sleep restriction and age group might affect responses to control stimuli, confounding other analyses, we also investigated the contrast pain>baseline (fixation cross and blank screen). This contrast resulted in activity similar to the contrast pain>no pain, but showing larger clusters (Fig.  , Table    
Pain>no pain for all subjects across sleep conditions, thresholded at 0.05 FWE corrected and only clusters with >20 voxels are reported. 
  
Anatomic labels are shown for peak coordinates and were defined using the automatic anatomic labelling in MRIcron. 
  ).   
Figures showing main effects of stimulus type across all subjects and sleep conditions. (  A  ) Pain>no pain across all subjects and sleep conditions, thresholded at p < 0.05 FWE for the whole brain. Activity was observed in AI and aMCC. (  B  ) Pain>baseline across all subjects, p < 0.05 FWE. Activation maps include AI and aMCC, but larger areas. (  C  ) Regions of interest in AI (−40, 22, 0 and 39, 23, −4) and aMCC (−2, 23, 40) based on coordinates from the meta-analysis by Lamm   et al  . with 10 mm spheres around each coordinate. 
    
Pain>baseline for all subjects across sleep conditions, thresholded at 0.05 FWE corrected and only clusters with >20 voxels are reported. 
  
Anatomic labels are shown for peak coordinates and were defined using the automatic anatomic labelling in MRIcron. 
  


#### Sleep restriction did not affect BOLD responses to pain in others 
  
No voxels showed a main effect of sleep condition, neither for the contrast pain>no pain nor for pain>baseline (  p   < 0.05 FWE). With a more liberal threshold (  p   < 0.001 unc), full sleep compared to sleep restriction (pain>no pain) yielded increased activity in 4 small voxel clusters that were judged as random findings, because of their small sizes (available at   https://doi.org/10.5281/zenodo.846863  ). To test the specific hypothesis that sleep restriction inhibits AI and aMCC responses, a region of interest analysis was performed for the contrast pain>no pain, see Fig.   for ROIs. In the ROI analysis, we found no effect of sleep restriction in AI (right: (−0.12 [−0.45, 0.20],   p   = 0.45, left: (0.03 [−0.31, 0.37],   p   = 0.88) nor aMCC (0.05 [−0.26, 0.34],   p   = 0.78), results presented as parameter estimates in original units (contrast values) with 95% CI. 



### Older participants showed more activity in the angular gyrus 
  
Pain>no pain in older participants compared to young yielded increased activity in the angular gyrus bilaterally, superior temporal sulcus (STS) and temporo-parietal junction (TPJ) and around the calcarine fissure (  p   < 0.05 FWE, Fig.  , Table  ). Both pain and no pain stimuli compared to implicit baseline caused increased activity in the fusiform gyrus in older compared to younger participants (  p   < 0.05 FWE, Table  , Fig.   and suppl. Figure   and suppl. Table  ).   
Age effects. (  A  ) Older>young for the contrast pain>no pain, 0.001 uncorrected for illustration. Older participants showed more activity in bilateral angular gyrus compared to young participants. (  B  ) Older>young for the contrast pain>baseline, 0.001 uncorrected for illustration. Older participants showed more activity in bilateral fusiform gyrus compared to young participants. 
    
Effects of age. All tables show data thresholded at 0.001 uncorrected, only clusters with>20 voxels are shown. 
  
Anatomic labels are shown for peak coordinates and were defined using the automatic anatomic labelling in MRIcron. A. The contrast older>young for pain>no pain, B. The contrast young>older for pain>baseline. C. The contrast older>young for pain>baseline. 
  

With a threshold of p < 0.05 FWE, age group did not interact with sleep condition. However, with a more liberal threshold at p < 0.001 unc., clusters on the border between anterior and posterior insula showed an interaction effect for the contrast pain>baseline (  p   < 0.001 unc., Fig.  , Table  ), consistent bilaterally. In these clusters, older participants showed more activity in the contrast pain>baseline after sleep restriction, whereas young participants showed decreased activity after sleep restriction.   
Showing age x sleep interaction for the contrast pain>baseline in a cluster in bilateral insula. After sleep restriction, older participants showed increased activity in pain>baseline compared to normal sleep, whereas younger participants showed decreased activity for the same contrast after sleep restriction compared to normal sleep. (  A  ) Sleep x age interaction on pain>baseline, thresholded at 0.001 uncorrected. Pink lines indicate areas known as the empathy network from the meta-analysis by Lamm   et al  . (  B  ) Mean contrast values for pain>baseline extracted from clusters in insula per subject and session and plotted per age group and condition. No post hoc test was performed on these extracted values, since they were extracted based on the interaction and thus would result in “double-dipping”, inflating results. 
    
Table showing the interaction contrast age group*sleep condition for pain>baseline, thresholded at 0.001 uncorrected, only clusters with>20 voxels are shown. 
  
Anatomic labels are shown for peak coordinates and were defined using the automatic anatomic labelling in MRIcron. 
  

#### Neither rated unpleasantness nor trait empathy predicted fMRI responses 
  
No voxels showed an effect of rated unpleasantness to stimuli. Self-rated empathy (IRI-EC) did not predict responses in AI (right: (−0.09 [−0.29, 0.17],   p   = 0.38, left: (−0.14 [−0.34, 0.07],   p   = 0.19)) or aMCC (−0.04 [−0.27, 0.18],   p   = 0.57) for pain>no pain, results presented as parameter estimates in original units (contrast values) with 95% CI. Self-rated psychopathy (PPI-R, coldheartedness) did not significantly predict responses in AI (right: (0.01 [−0.01, 0.02],   p   = 0.46, left: (0.01 [−0.00, 0.03],   p   = 0.15)) or aMCC (0.01 [−0.01, 0.03],   p   = 0.39) for pain>no pain. 




## Discussion 
  
This study investigated the effect of sleep restriction on empathic responses to pain in older and younger participants. Across age groups, there was no significant effect of sleep restriction on empathic responding. Older participants had higher activity in angular gyrus, STS, TPJ and calcarine fissure in response to pain, contrasted to no pain, in others. Age group and sleep interacted so that sleep restriction caused increased unpleasantness to pain in older participants and no effect in young. In voxel clusters in bilateral posterior insula, sleep restriction tended to cause increased activity in older and decreased activity in young participants, when pain stimuli were contrasted to a baseline, but not when contrasted to no pain stimuli. Behavioural and imaging results could therefore indicate that aging affects both how we respond to pain in others and possibly how sleep modulates emotional responses. 

Most studies of sleep and emotion have been performed with young participants, in spite of the fact that normal sleep and the effects of sleep restriction change with aging . At an uncorrected threshold, sleep and age group interacted in clusters in posterior insula. The clusters were large and bilateral, but only partly overlapped with the core empathy network observed in previous studies of empathy, and the effects did not survive a whole-brain FWE correction, limiting interpretation. For ratings of unpleasantness, a significant interaction between age group and sleep condition was seen. However, when decomposed, the effect was only significant in the older participants. Although both behavioural and fMRI effects were ambiguous, they are consistent with the interpretation that sleep deprivation affects younger and older participants differently, which would call for caution in generalization across age groups in this area of investigation. Whether potential differences in how younger and older participants respond to sleep restriction depend on the microstructure of the sleep itself, or the function of sleep in recovery needs further attention. 

Most effects of sleep restriction on emotional processing in the brain have been investigated in relation to changes in amygdala reactivity , while empathic computations rely more on structures in AI and aMCC . Only one previous study  reported decreased self-reported empathy after sleep restriction in young volunteers (mean age = 22), inconsistent with the results of the present study. Regarding emotional recovery, REM sleep has been argued to be of certain importance . In the present study, we did not completely abrogate this sleep phase, potentially still allowing some recovery during the experimental night. Whether the brain network underlying empathy is relatively resistant to sleep loss, or whether an impact of sleep deprivation on empathy would arise with a stronger manipulation that e.g. completely eliminates REM, needs to be further studied. 

An important aim of the study was to investigate the effect of age on responses to pain in others, and the results indicate greater behavioural responses in older age. This is contrary to what was found by Chen   et al  . , who investigated empathy for pain in three different adult age groups. In addition, unlike Chen   et al  ., we found no effects of aging on empathic responses in AI or aMCC. As noted above, older participants however showed increased activity in an area including angular gyrus, TPJ and STS bilaterally, as well as around the calcarine gyrus in response to pain as compared to no pain stimuli. The clusters show some overlap with a proposed theory of mind network  and could in speculation indicate an increased recruitment of areas associated with cognitive  aspects of empathy (i.e. theory of mind) in older participants when exposed to others in pain, even though this interpretation needs to be tested. Another possible explanation is that older participants are less used to the type of stimuli used, and that this activity represents increased perceptual vigilance. It could partly also represent compensatory recruitment of brain areas in the older group . Older participants have on average less grey matter , possibly affecting the shape and amplitude of the BOLD signal. Since the BOLD signal generally decreases with aging , we suggest that increased BOLD signal in our older participants could potentially reflect an even larger difference in underlying neural activity. 

Pain stimuli caused greater BOLD responses in the AI and aMCC than control stimuli, thus validating the paradigm in which the effects of sleep and age on empathy was studied . However, activity in AI and aMCC was not related to ratings of trait empathy or to ratings of unpleasantness during the experiment. This has in fact been the case in most earlier studies of empathy , contrary to an early report of the opposite . 

### Strengths and limitations 
  
Many studies of sleep and emotion use total sleep deprivation with stronger assumed effects on behaviour and brain function. Partial sleep restriction is however a more ecologically valid condition, and the use of this protocol therefore increases generalizability. Another disadvantage with total sleep deprivation is that it increases the risk of participants falling asleep in the scanner. In fact, this is implicated as a major confounder in fMRI studies , and the present protocol was piloted to balance sleepiness with the risk to fall asleep during imaging. Our data show that reducing sleep to 3 hours induced considerable sleepiness, which shows that the manipulation was successful. Another strength of the study was the fact that participants were monitored with polysomnography at home. Thus, the participants’ actual sleep was carefully checked, which to our knowledge has not been the case in many sleep restriction studies. Another critical issue in imaging research is statistical power . The sample size in this study is larger than in any other study of effects of sleep manipulations on emotional outcomes, using fMRI, of which we are aware. Still, as the effects of interest may be weak, power may still be an issue. This would especially apply to interactions, where power is further diluted. On the other hand, we pre-registered a list of hypotheses in an attempt to restrict the analyses, reducing the risk of confusing exploratory and confirmatory data analysis. We investigated age effects in a cross-sectional manner, which introduces a risk that the observed effects are not caused by aging itself, but rather by a generational effect (of for example history of pain in self or others, attitudes to pain or exposure to violent pictures). Also, a “healthy volunteer effect”  can be expected in the present design, introducing a selection bias in the older sample. On the other hand, the present sample displays low risk for other confounders such as morbidity related to aging, in other words isolating the effects of age in this respect. 



## Conclusions 
  
Despite strong effects on sleepiness, shortened sleep did not have a uniform effect on empathic responding across age groups. In older participants, sleep restriction caused increased perceived unpleasantness to pain in others, whereas no effect was seen in young. No effect of sleep restriction was found in the core empathy network (AI and aMCC). Compared to younger, older participants showed more activity in additional brain areas, including angular gyri, STS and TPJ, in response to pain in others. The pattern of results suggests a complexity in the way age interacts with empathic processing and possibly also with effects of sleep restriction on empathy. This is likely relevant also for the effect of sleep on other domains of emotional processing and calls for caution in generalizability of findings across age groups. It is also necessary to study how sleep-emotion effects translate to prosocial behaviour, and whether this has any implications for health care professions, patients with disturbed sleep or the general population. 


## Electronic supplementary material 
  




 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-18'>
<h2>18. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/29915004/' target='_blank'>29915004</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Concrete versus abstract forms of social concept: an fMRI comparison of knowledge about people versus social terms</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Philos Trans R Soc Lond B Biol Sci</p>
<p><strong>Publication Year:</strong> 2018</p>
<p><strong>DOI:</strong> 10.1098/rstb.2017.0136</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6015823/' target='_blank'>6015823</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This paper reports fMRI data (three studies, combined n=59 healthy adult participants) using social-related tasks (person knowledge: famous faces/names; and socially relevant concept words) and modality-matched non-social controls. Whole-brain analyses are reported (social > non-social contrasts with voxelwise thresholds and cluster correction), in addition to ROI analyses. Participants are healthy adults and results for healthy groups are reported separately. The tasks clearly probe social processing (perception/understanding of others, social concepts). No exclusion criteria are met (not ROI-only; not patient-only). Therefore the study meets all inclusion criteria for the review.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
The anterior temporal lobes (ATLs) play a key role in conceptual knowledge representation. The hub-and-spoke theory suggests that the contribution of the ATLs to semantic representation is (a) transmodal, i.e. integrating information from multiple sensorimotor and verbal modalities, and (b) pan-categorical, representing concepts from all categories. Another literature, however, suggests that this region's responses are modality- and category-selective; prominent examples include category selectivity for socially relevant concepts and face recognition. The predictions of each approach have never been directly compared. We used data from three studies to compare category-selective responses within the ATLs. Study 1 compared ATL responses to famous people versus another conceptual category (landmarks) from visual versus auditory inputs. Study 2 compared ATL responses to famous people from pictorial and written word inputs. Study 3 compared ATL responses to a different kind of socially relevant stimuli, namely abstract non-person-related words, in order to ascertain whether ATL subregions are engaged for social concepts more generally or only for person-related knowledge. Across all three studies a dominant bilateral ventral ATL cluster responded to   all   categories in   all   modalities. Anterior to this ‘pan-category’ transmodal region, a second cluster responded more weakly overall yet selectively for people, but did so equally for spoken names and faces (Study 1). A third region in the anterior superior temporal gyrus responded selectively to abstract socially relevant words (Study 3), but did not respond to concrete socially relevant words (i.e. written names; Study 2). These findings can be accommodated by the graded hub-and-spoke model of concept representation. On this view, the ventral ATL is the centre point of a bilateral ATL hub, which contributes to conceptual representation through transmodal distillation of information arising from multiple modality-specific association cortices. Partial specialization occurs across the graded ATL hub as a consequence of gradedly differential connectivity across the region. 

This article is part of the theme issue ‘Varieties of abstract concepts: development, use and representation in the brain’. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (46740 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## . Introduction 
  
The neural organization of conceptual knowledge (or semantic knowledge) has long been a fundamental issue in cognitive neuroscience, with much debate on the degree to which representations are segregated by modality and category. On the one hand, researchers have emphasized cortical specialization for specific modalities and categories of knowledge [ – ]. Other researchers, while not denying these specializations, have argued that true conceptual knowledge additionally requires a transmodal level of representation that integrates across modalities and possibly categories [ – ]. Recent neuroimaging studies using multivariate techniques have also identified brain regions that process transmodal semantic information [ – ]. Here, we investigated the organization of knowledge in the anterior temporal lobes (ATLs), a region that has emerged as a key contributor to conceptual representation [ , – ]. 

Currently, there are different literatures that propose contrastive hypotheses about the ATLs, yet their predictions have never been directly compared. The hub-and-spoke theory holds that the ATLs form a pan-category transmodal ‘hub’ that develops coherent conceptual representations through interaction with distributed information sources [ , , , , ]. This theory stems from studies of semantic dementia (SD) patients who exhibit a selective yet progressive multimodal, pan-category impairment of semantic knowledge, following bilateral ATL atrophy [ – ]. Performance on semantic tasks in SD patients is correlated with the amount of atrophy and hypometabolism in the ventrolateral ATLs [ ]. SD patients exhibit generalized deficits across different conceptual categories, including concrete and abstract words [ – ], living and non-living items [ , ], and people [ ]. Recent fMRI, rTMS and subdural grid-electrode explorations also directly implicate the ATLs as a transmodal, pan-category hub [ , , – ]. 

Conversely, a separate literature proposes that the ATLs are involved in processing socially relevant semantic cognition [ – ]. This account is consistent with long-standing observations that the ATLs are part of a wider network involved in social cognition in humans and primates [ – ]. The question of what constitutes a ‘social concept’ is an important one, and remains relatively ill-defined in the literature. Within the existing literature ‘social cognition’ encompasses topics such as (but not limited to) recognizing conspecifics (people, most commonly from a face) [ – ], processing socially relevant words [ , , ], recognizing emotions [ – ] and understanding the intention of others (theory of mind; [ , , ]). In this paper, we used the term ‘socially relevant concept’ to refer to semantic information which has social connotations/implications. While the definition of socially relevant concepts remains broad and ill-defined, several groups have proposed that all or part of the ATLs selectively code social concepts, including person (face) knowledge and emotional concepts [ , , , , , ]. Indeed deficits in social behaviour are often observed in SD patients, including social awkwardness, person recognition deficits and a loss of empathy [ – ]. These findings could reflect either a dedicated role of ATL regions in social concepts and/or the contribution that a more generalized ATL semantic system might play in activation of all concepts including social items. In a novel extension from the clinical findings to fMRI, Zahn   et al.   [ ] demonstrated that activation associated with socially related words (e.g. polite) versus non-social words (e.g. nutritious) was localized to the right anterior superior temporal gyrus (aSTG) in neurologically intact participants. However, a direct replication of the Zahn   et al.   [ ] task found greater activation for social > non-social words in the left aSTG, rather than in the right aSTG [ ], suggesting that both ATLs may play a role in the task. This finding of differential activation in the aSTG for social concepts was replicated in a recent study which employed more stringent matching of the stimuli [ ]. Indeed the potential role of the left as well as the right ATL in social concepts was underlined by the study of Chan   et al.   [ ], which, in a formal exploration, found social and behavioural deficits in both left > right and right > left SD patients (with a greater proportion of right > left, albeit more severe, SD patients showing social and behavioural deficits). 

Potentially related to the argument that the ATLs show a category effect for socially relevant concepts, a third literature proposes that the ATLs are selectively involved in face processing [ , – ], perhaps in the function of linking familiar faces to stored semantic knowledge [ ]. In support of this, congenital prosopagnosia has been linked to reduced (ventral) ATL volume, and damage to the right ATL can result in greater deficits in face recognition than for other categories [ – ]. Likewise, some fMRI studies have shown that the ATLs bilaterally (though more commonly in the right hemisphere) respond more to faces than non-face objects [ , , ]. This face-related ATL activation has been proposed to be the human homologue to the ‘anterior temporal face patches' recently observed in macaques [ , , – ]. However, the necessarily selective focus on face processing in these studies means that their results are based solely on visual stimuli. Therefore, it is unclear whether the face-related ATL region responds selectively to faces or to transmodal person knowledge [ ]. 

These neuroimaging datasets—general semantics versus social semantics versus face representation—have emerged in parallel and thus a critical question that arises is whether they report activations in the same or different regions within the ATL. Formal analysis of the current literature does allow us to answer this question. Specifically, in  , we report peaks from a number of studies investigating either general semantic knowledge or face representation. The two sets of studies report rather similar (and typically bilateral) peaks, although peaks from the face-related studies are, on average, more anterior/medial along the ventral surface (approx. 1 cm away). Based on these data, it is difficult to distinguish between two interpretations: (1) that faces activate the same ATL regions as other meaningful stimuli but perhaps do so more strongly, or (2) that there are subdivisions within the ATLs which respond differently, with a more anterior/medial area being face-selective.
   
Peak MNI coordinates taken from the general semantics literature and face-selective literature. 
  

This study was designed specifically to draw these three currently separate literatures together in order to understand the role of various ATL subregions in the representation of different kinds of social versus non-social concept. Specifically, we conducted the first comparison of ATL responses to different kinds of socially relevant concepts using three datasets which all used neuroimaging sequences tailored to acquiring signal in the ATL and used appropriate control conditions. First, we compared ATL activation to people versus another conceptual category across different modalities (Study 1). Next, we verified the ATL responses to people-related knowledge using another modality of presentation (famous names presented as written words; Study 2), in order to replicate and extend the findings of Study 1 in a separate dataset. Finally, we compared activation within the ATLs to different classes of socially relevant concepts (e.g. socially relevant words) to assess whether activation to socially relevant concepts is consistent or whether there is selective activation for social knowledge versus other kinds of semantics (Study 3). We also compared activation within the ATL between abstract socially relevant words versus concrete socially relevant words (i.e. famous names from Study 2). 


## Method 
  
We compared data from three studies, each exploring different examples of socially relevant concepts ( ). Two of the three studies explored the perception/representation of person knowledge (Study 1 and Study 2), and one study explored written words depicting (abstract) socially relevant concepts (Study 3). Study 1 was used to compare socially relevant concepts (faces, spoken names) versus a well-established control condition (landmarks) to identify socially relevant activations in the ATLs. Study 2 was used to verify whether the findings of Study 1 could be replicated and extended to another modality of presentation (famous names presented as written words). Study 3 was used to assess whether the findings from famous people generalized to other socially relevant stimuli (i.e. socially relevant concept words).
   
Social and non-social semantic conditions included in Studies 1–3. 
  

### Stimuli and tasks 
  
Data were collected from three separate fMRI studies (  n   = 59). All of the participants in the three studies were unique. Each study consisted of at least one social semantic condition, one non-social semantic condition from the same modality, and a modality-matched non-semantic control task. All three studies used a PC running the E-Prime software (Psychology Software Tools, Pittsburgh, PA) for presentation of stimuli and recording of responses. For behavioural results across all three studies, see electronic supplementary material, table S1. 

#### Study 1: stimuli, tasks and procedure 
  
Study 1 (  n   = 20) consisted of pictures and spoken names of famous people and famous landmarks. Landmarks were chosen as comparison categories for people because landmarks are highly prominent within the visual perception literature as a contrast for faces and, like faces, are also classified as ‘unique entities’ [ ]. Study 1 also contained data from a third non-unique conceptual category (animals); however, these data will not be discussed here. Each conceptual category (people, landmarks) contained 72 stimuli, which were presented twice during scanning, once as a picture and once as a spoken name. Stimuli were presented in two modalities to address a discrepancy in the literature: studies proposing that the ATLs are involved in face processing have exclusively used visual stimuli and do not make explicit predictions about whether this area is visually selective or transmodal [ , ]. This stands in contrast to the general semantic literature which provides evidence that the ATLs respond across multiple modalities for multiple categories [ , , ]. Visual and auditory control conditions were used to account for low-level sensory effects and to provide an attention-demanding baseline condition, which is a crucial factor for observing ATL activations [ , ]. The visual control items were generated by scrambling 72 images from the three conceptual categories; these were created using the Java Runtime Environment ( ) by scrambling each image into 120 pieces and rearranging them in a random order. The auditory control condition consisted of 6 phase-scrambled auditory tones. Stimuli were presented in blocks of the same condition to participants in the scanner and the task was a nationality judgement task (Is the stimulus European or Non-European?). For the control conditions, participants were used to make ‘high/low’ decisions for each stimulus (Is the scrambled image high or low on the screen?’, ‘Is the tone high or low in pitch?). To ensure the semantic and control tasks were matched for eye movements, the visual semantic conditions were also randomly presented above or below the fixation cross. 

Participants completed three functional scans, with a total scan time of 36 min. During scanning, stimuli were presented in a block design. Each functional scan contained alternating blocks of visual or auditory stimuli from one condition; half of the runs started with an auditory block (A – V – A – V) and half the runs started with a visual block (V – A – V – A); this order was counterbalanced across participants. Each block contained 6 trials. Each stimulus was presented sequentially and in isolation for 2500 ms, with an inter-stimulus interval (ISI) of 500 ms. The eight experimental conditions (6 semantic + 2 control conditions) were sampled 12 times in a counterbalanced order, giving a total of 96 blocks. At the start of each block, a written word probe prompted participants as to which task was coming up. Visual stimuli were presented via a mirror mounted on the head coil, angled at a screen at the foot of the scanner bed. Auditory stimuli were presented via noise cancelling headphones (MkII+ headphones, MR confon GmbH;  ) in conjunction with ear plugs, to reduce scanner noise. To ensure that the auditory stimuli were intelligible for each participant, practice trials were run while the scanner was active and the sound level was adjusted as necessary. 


#### Study 2: stimuli, tasks and procedure 
  
Study 2 (  n   = 20) also involved semantic judgements regarding famous people, this time incorporating pictures and written words (names). On each trial participants were presented with a probe item and asked to decide which of the two alternatives shared the same occupation. Each stimulus triad was presented simultaneously. In each triad all stimuli came from the same gender and nationality. Alongside this condition there was a non-social semantic association task, consisting of a variant of the widely used Camel and Cactus test [ ]; here the task was to pick which of the choice items is associated with the probe item. To match the occupation matching task, items were presented either as pictures (CCp) or written words (CCw). Different items were used in the word and picture versions of the Camel and Cactus and occupation matching task to avoid priming effects. Each condition consisted of 33 trials. Again, modality-specific non-semantic control tasks were included in Study 2, namely scrambled versions of the famous faces/names and Camel and Cactus pictures/words. Participants were instructed to choose which of the choice items was identical to the probe. The data reported here form part of a larger study comparing brain activation in control participants to a set of post-surgical temporal lobe epilepsy (TLE) patients. As part of the larger study, control participants saw each of the semantic conditions twice, once at a speed typical for a healthy population (‘standard speed’; 2.5 s/triad) and once at a slower speed (5 s/triad); although importantly the items used in both scans were different to avoid priming effects (i.e. items which were presented as a picture in the ‘standard’ speed scan were shown as written words in the ‘slower’ speed scan). The slower speed was used in relation to the behavioural slowing seen in the patient group and thus to allow direct comparison between the data from the patients to the control group. For the purposes of the current reanalysis only the ‘standard’ blocks were entered into the analysis to match the task demands to the other studies. 

Study 2 consisted of four functional scans, each with a total scan time of 8.45 min. During scanning, stimuli were presented in a block design. Each functional scan contained stimuli from one semantic condition (CCw, CCp, famous names or famous faces) and from the relevant baseline condition (scrambled pictures or scrambled words). This was done to avoid task-switching effects in the scanner. Each block contained three trials from one experimental condition. Each stimulus and the response screen were presented for 5000 ms, with an ISI of 500 ms. The two experimental conditions (semantic and baseline) were sampled 11 times per functional scan in a counterbalanced order, giving a total of 22 blocks per scan. The order of the scans was randomized and counterbalanced across participants. Stimuli were presented visually via a mirror mounted on the head coil, angled at a screen at the foot of the scanner bed. All participants underwent practice trials before beginning the scan to familiarize them with the tasks. 


#### Study 3: stimuli, tasks and procedure 
  
The data from Study 3 (  n   = 19) were taken from a previously published investigation of socially relevant concepts in the ATL [ ]. Briefly, Study 3 presented participants with written synonym judgement decisions. Stimuli were either socially relevant concept words (e.g. bright) or non-social abstract concept words (e.g. edition), matched closely for psycholinguistic properties including frequency, imageability and semantic diversity (see Binney   et al.   [ , ] for full details of stimulus matching). Each condition consisted of 48 triads. In all conditions participants were instructed to choose which of the two choice words was associated with the probe word. The non-semantic control condition was a number judgement task; a triad of numbers was presented on screen and participants were instructed to choose which of the two choice numbers was closer in numerical value to the probe number. 

For Study 3 a block design was used, each block lasting 13.5 s and consisting of three trials from the same experimental condition. Each trial began with a fixation cross presented in the centre of the screen for 500 ms, followed by a stimulus triad (probe and choice words simultaneously). The stimuli remained on the screen for a fixed duration of 4000 ms after which the next trial began. Participants responded by pressing one of two buttons on an MR-compatible response box. Study 3 consisted of two 15 min functional runs separated by a 10 min interval. Each run contained 16 blocks of the number judgement task and 16 blocks of the three semantic judgement conditions. All conditions were presented in a pseudo-random order. 



### Scanning 
  
#### Imaging parameters 
  
Traditionally, imaging the ventral ATLs has been problematic because of a number of technical issues including the nature of the baseline contrast tasks as well as gradient-echo EPI signal dropout and distortion [ , ]. These issues have been tackled through recent methodological developments [ , ]. Across all three studies reported here, the core semantic task was contrasted against an active baseline (see above) using either dual-echo EPI imaging Study 1 + 2 [ ] or spin-echo EPI imaging Study 3 [ ] to improve signal in the ATLs. 

For Study 1 and 2 all scans were acquired on a 3T Phillips Achieva scanner, with a 32-channel head coil with a SENSE factor of 2.5. A dual-echo EPI sequence was used to improve the signal-to-noise ratio (SNR) in the ATLs [ ]. Using this technique, each scan consisted of two images acquired simultaneously with different echo times: a short echo optimized to obtain signal from the ATLs and a long echo optimized for good whole-brain coverage. The sequence included 31 slices covering the whole brain with repetition time (TR) = 2.8 s, echo times (TE) = 12 and 35 ms, flip angle = 85 , FOV = 240 × 240 mm, resolution matrix = 80 × 80, slice thickness = 4 mm and voxel size = 3 × 3×4 mm. All functional scans were acquired using a tilt, up to 45° off the AC–PC line, to reduce ghosting artefacts in the temporal lobes. In Study 1, functional scans were collected in three 12 min runs; each run acquired 255 dynamic scans (including two dummy scans, which were excluded). In Study 2, functional scans were collected in four 4.3 min runs; each run contained stimuli from one of the four semantic conditions (faces, written names, CCp, CCw) and one of the modality-appropriate non-semantic control conditions and acquired 88 dynamic scans (including two dummy scans, which were excluded). To address field inhomogenities, a B0 field-map was acquired using identical parameters to the functional scans except for the following: TR = 599 ms, TEs = 5.19 and 6.65 ms. A high-resolution T1 weighted structural scan was acquired for spatial normalization, including 260 slices covering the whole brain with TR = 8.4 ms, TE = 3.9 ms, flip angle = 8°, FOV = 240 × 191 mm, resolution matrix = 256 × 206, voxel size = 0.9 × 1.7 × 0.9 mm. 

Study 3 used spin-echo data acquisition combined with post-acquisition distortion correction [ ]. This imaging sequence has been used previously to demonstrate robust ATL activation for a variety of semantic tasks [ , , , , ]. All scans for Study 3 were acquired on a 3T Philips Achieva scanner using an 8 element SENSE head coil with a sense factor of 2.5. The spin-echo EPI fMRI sequence included 31 slices covering the whole brain with echo time (TE) = 70 ms, time to repetition (TR) = 3200 ms, flip angle = 90°, 96 × 96 matrix, reconstructed resolution 2.5 × 2.5 mm and slice thickness 4.0 mm. 550 images were acquired in total, collected in two runs of 15 min each. Following the method of Embleton   et al  . [ ] for distortion-corrected spin-echo fMRI, the images were acquired with a single direction k space traversal in the left–right phase encoding direction. In between the two functional runs, a brief ‘pre-scan’ was acquired, consisting of 10 volumes of dual direction k space traversal SE EPI scans. This gave 10 pairs of images matching the functional time series but with opposing direction distortions (10 left–right and 10 right–left). These scans were used in the distortion correction procedure (see below). A high-resolution T2-weighted turbo spin-echo scan with an in-plane resolution of 0.94 mm and slice thickness of 2.1 mm was obtained as a structural reference to provide a qualitative indication of distortion correction accuracy. In addition, a high-resolution T1-weighted 3D turbo field echo inversion recovery image was acquired (TR ≈ 2000 ms, TE = 3.9 ms, Inversion time (TI) = 1150 ms, flip angle 8°, 256 × 205 matrix reconstructed to 256 × 256, reconstructed resolution 0.938 × 0.938 mm and slice thickness of 0.9 mm, SENSE factor = 2.5), with 170 slices covering the whole brain. This image was used for estimating transforms to warp functional images into standard stereotactic space. Full details of the distortion correction technique and preprocessing steps for Study 3 can be found here [ ]. 


#### fMRI data analysis 
  
For all three studies, data were analysed to compare the ‘social’ conditions to the ‘non-social’ conditions in the dataset ( ). For Study 1, the social condition was the faces and spoken names of famous people, and the non-social condition was pictures and spoken names of famous landmarks. For Study 2 the social condition was the faces and written names of famous people, and the non-social condition was the picture and word version of the Camel and Cactus test. For Study 3 the social condition was the socially relevant concept words, and the ‘non-social’ condition was the abstract non-social concept words. 

Data were motion-corrected and co-registered to the anatomical T1. Images were also spatially normalized to the MNI standard space and resampled to 3 × 3 × 3 mm dimensions, and smoothed using an 8 mm Gaussian FWHM kernel. First- and second-level analyses were carried out using SPM8 (Wellcome Department of Imaging Neuroscience, London;  ). At the first level, data for each study were entered into separate general linear model analyses by modelling each condition (social, non-social, non-semantic control) as a separate regressor using a boxcar function convolved with the canonical haemodynamic response function. Contrasts were calculated for each condition (social, non-social) versus the modality-relevant non-semantic control condition. At the second level, the data from each study were entered into separate one-way ANOVA models. The contrasts of interest were social > non-social semantics in each of the three studies ( ). ‘Social > non-semantic baseline’ + ’Non-Social > non-semantic baseline’ contrasts were also calculated at the second level (electronic supplementary material, figure 1). Unless otherwise stated, for Studies 1 and 2 a voxel height threshold of   p   < 0.001, cluster-corrected using an FWE   p   < 0.05 was used. For Study 3 an uncorrected voxel height threshold of   p   < 0.005 was used as per the originally reported results [ ].
   
Whole-brain analysis of Studies 1–3. Regions in blue show stronger activation for social > non-social semantic conditions, regions in red show stronger activation for non-social versus social semantic conditions. 
  

To explore differential activation across a set of ATL regions for different categories of social information, we created four   a priori   ROIs using the Marsbar toolbox [ ]; each ROI was 6 mm in diameter. The first ROI was a region commonly activated in functional imaging studies of semantic cognition [ , , ]. This ventral ATL ROI [MNI: −36 −15 −30; 36 −15 −30] was localized in Binney   et al.   [ ]. The next two regions were chosen because they are often reported in studies investigating the role of the ATL in face processing: (a) the temporal pole (TP), a region slightly anterior and medial to the vATL ROI and (b) the anterior middle temporal gyrus (aMTG), a region on the lateral surface of the ATL. Both the TP (ROI no.2) and aMTG (ROI no.3) were localized from a meta-analysis of 17 studies investigating face recognition in the ATLs (coordinates reported in  ). We used activation likelihood estimation (ALE) analysis [ ], a method that extracts coordinates from a set of neuroimaging studies and estimates the likelihood of activation across each voxel in the brain. The resultant ‘activation likelihood maps' can then be viewed on a standard brain. The ATL peaks from 17 ‘face-selective’ studies (  ) were entered and an overall activation likelihood map was generated to show ATL coverage. This was thresholded using a false discovery rate (FDR) of   p   < 0.05 to correct for multiple comparisons. Four peak MNI regions of activation likelihood were extracted (TP ROI no. 2: −37 4 −29; 31 1 −25, aMTG ROI no. 3: −59 −7 −18; 61 −1 −16). The fourth   a priori   ROI was the aSTG [MNI: −51 16 −27; −51 16 −27]; this subregion of the ATL has been previously associated with social processing [ , , ]. Coordinates were taken from Ross & Olson [ ] using a contrast comparing social versus animal concept words. The coordinates were converted from Talariach to MNI space using the tal2icbm_spm.m function. 




## Results 
  
### Whole-brain analysis: are there regions of the anterior temporal lobe which respond more to socially relevant concepts? 
  
First, we investigated whether there were subregions of the ATLs which responded more to socially relevant concepts compared to other types of semantic information. Regions involved in socially relevant semantic knowledge were identified using the whole-brain contrast social > non-social semantics in each of the three datasets separately. Peak activations for each study are listed in  .   shows a network of regions activated by the socially relevant semantic conditions (blue) across the three datasets. For Study 1 person-related clusters were primarily localized in the right hemisphere, including the ventral aspect of the ATL/TP, precuneus, orbitofrontal cortex, hippocampus, anterior middle temporal gyrus (aMTG) and the temporo-parietal junction ( ). These regions (with the exception of the orbitofrontal cortex and ATL) are in line with the findings from previous studies of conceptual category representation, which showed transmodal responses to person knowledge in the precuneus [ , ], suggesting these regions may play a specific role in processing more socially salient semantic knowledge. No other category differences were localized in the ATLs (i.e. non-social > social). Activation to transmodal landmarks were widespread, and included bilateral parahippocampal gyri, precuneus, lateral occipital cortex and left inferior frontal gyrus ( ).
   
Peak coordinates from the whole-brain analysis across each of the three datasets. 
  

For Study 2, an identical pattern of activation was observed in the midline structure of the orbitofrontal cortex and the precuneus; however, at this threshold there were no significant clusters in the temporo-parietal junction or the ATL. Activation to the CCT was localized to the left posterior temporal cortex, left lateral occipital cortex and left inferior frontal gyrus. Study 3 also showed stronger activation for socially relevant concepts in the left temporo-parietal junction, including the supramarginal gyrus and the posterior MTG, which extended into the posterior insula cortex. There were also two medial occipital clusters, a left hemisphere cluster in the superior aspect of the cuneus and a bilateral cluster peaking at the lingual gyrus. There was also a cluster in the left inferior frontal gyrus. 

Across all three studies there was significant overlap across the ATL and the brain more widely (pink) between the contrasts ‘social > control’ and ‘non-social > control’ (electronic supplementary material, figure S1) when comparing the conditions of interest over the non-semantic baseline, providing support for the hypothesis that both types of semantic information are processed by similar subregions of the ATL. 


### ROI analysis: do anterior temporal lobe subregions respond to transmodal person knowledge or face information? 
  
Next, we investigated whether the ATL subregions identified in the whole-brain analysis responded selectively to   transmodal   person knowledge, based on previous research showing that the ATL is activated by famous names as well as faces [ , ]. To do this, we used   a priori   ROI analysis, using peaks taken from the previous literature. Data from Study 1 and Study 2 were analysed using 2 category (social, non-social) × 2 modality (picture, spoken/written) ANOVAs in each region of interest. 

 shows a gradient of activation across the ATLs in Study 1. This functional gradient progresses from a transmodal, pan-category response in the vATL ( , ROI 1) to a modality-selective (auditory) response in the aSTG ( , ROI 4). The   a priori   vATL ROI (no.1) responded to both social and non-social category information in equal measures, as well as visual and auditory information. In line with this, the category×modality ANOVA showed no significant main effects of category or modality in either hemisphere. This replicates previous findings of transmodal responses in the vATL [ , ]. However, there was a significant category×modality interaction in the left vATL (  F   = 14.90,   p   = 0.001). This interaction may be driven by an intrinsic word length effect for the names of landmarks versus people (16.2 characters versus 12.7 characters;   t   = 5.31,   p   < 0.001); this intrinsic nature of the stimuli could have increased the difficulty of processing for the names of landmarks leading to a greater activation. No significant interaction was found in the right vATL.
   
ROI analysis results for Study 1. Results are shown for four ROIs derived from the literature. Blue bars represent the social conditions and grey bars represent the non-social conditions. All bars show the relative activation for each condition of interest compared to its matched non-semantic control condition. Error bars show standard error. 
  

In contrast to the transmodal, pan-category results in the vATL, the more anterior TP ROI (no. 2), particularly in the right hemisphere, showed selective activation for faces and spoken names of people, as well as the spoken names of landmarks. In the right hemisphere, the category × modality ANOVA showed a significant main effect of category (  F   = 5.13,   p   = 0.04), reflecting overall increased responses to person knowledge compared to landmarks. There was also a significant category×modality interaction in the right hemisphere (  F   = 7.42,   p   = 0.01). In the left hemisphere, there was a main effect of modality (  F   = 14.64,   p   = 0.001), reflecting overall increased responses to auditory stimuli compared to visual stimuli. The peak coordinate reported here (TP peak in Study 1: −45 7 −36; 38 3 −37) aligns well with previously reported coordinates in the face-processing literature ( ; ROI no. 2), indicating that the anterior vATL region responds to transmodal person knowledge, rather than face knowledge specifically [ ]. 

Extending dorsally into the aMTG (ROI no.3), the same pattern of activation for faces and spoken names of people and the spoken names of landmarks remained. This was illustrated in a significant category×modality interaction in the right hemisphere (  F   = 11.69,   p   = 0.0003). This effect trended towards significance in the left hemisphere (  F   = 3.54,   p   = 0.08). In both hemispheres, there was a significant main effect of modality (left:   F   = 16.87,   p   = 0.0001; right:   F   = 48.26,   p   < 0.0001), driven by the stronger response to auditory stimuli compared to visual stimuli. Again, coordinates from this region align with those previously reported in the face-processing literature ( ; ROI no. 3); however, the overall response to auditory stimuli may reflect this region's proximity to auditory processing areas in the superior temporal gyrus. 

By contrast, in the aSTG (ROI no.4) there was no longer a category effect for social > non-social stimuli; instead this region responded selectively to the auditory conditions regardless of category (main effect of modality; left:   F   = 21.53,   p   < 0.0001; right:   F   = 10.10,   p   = 0.005). The main effect of category was not significant in either hemisphere (left:   F   = 1.14,   p   = 0.30; right:   F   = 0.71,   p   = 0.41). 

The main finding from Study 1, therefore, was of two clusters in the vATLs, both transmodal in nature, one dominant area which responded to all conceptual categories, including people ( , ROI no. 1), and another more anterior ‘person-related’ cluster ( , TP ROI no. 2). Across the ATLs a gradation from a transmodal effect to an auditory selective response was shown, peaking in the aSTG (ROI no. 4). 


### Does the pattern of activation shown in Study 1 replicate across different modalities of person knowledge? 
  
 shows the ROI results for Study 2. Here, the vATL ROI showed the same pattern of activation as in Study 1—responding regardless of stimulus category and modality of presentation (picture versus written word). The only significant effect in the category×modality ANOVA was a main effect of modality in the right vATL (  F   = 6.34,   p   = 0.02). This was driven by reduced responses to written words (names and written versions of the Camel and Cactus) in the right hemisphere. This finding aligns with previous reports that written words produce a left lateralized response within the ATLs, whereas pictorial information produces bilateral ATL responses [ ]. The only other region to show a significant effect in Study 2 was in the left aMTG, which showed a significant main effect of category (  F   = 8.49,   p   = 0.009); this was driven by a greater response to social > non-social stimuli. This effect trended towards significance in the right hemisphere (  F   = 3.69,   p   = 0.07). Critically, the aSTG, which in previous studies has shown a category effect for socially relevant (abstract) concept words [ , ], showed no significant interaction for socially relevant concrete words (i.e. famous names) in either the left (  F   = 0.23,   p   = 0.64) or right hemisphere (  F   = 1.80,   p   = 0.20).
   
ROI analysis results for Study 2. Results are shown for four ROIs derived from the literature. Blue bars represent the social conditions and grey bars represent the non-social condition. All bars show the relative activation for each condition of interest compared to its matched non-semantic control condition. Error bars show standard error. 
  


### Do anterior temporal lobe subregions also respond to different kinds of social semantic information? 
  
Finally, we asked the question whether the pattern of results shown for famous people generalize to other kinds of socially relevant semantic knowledge. For this question, data previously published comparing activation for socially relevant words [ ] were plotted in the same ROIs. Paired t tests were used to compare the social versus non-social concepts.   shows the results from Study 3. Again the vATL responded equally to social and non-social concept words (left =   t   = 0.36,   p   = 0.72; right =   t   = 1.65,   p   = 0.12), replicating the pattern of results shown in Study 1 ( ) and Study 2 ( ). The only regions which showed a category effect were the right aMTG (paired   t   test:   t   = 3.17,   p   = 0.005) and the right aSTG (paired t test:   t   = 2.72,   p   = 0.01), as reported in the original paper [ ].
   
ROI analysis results for Study 3. Results are shown for four ROIs derived from the literature. Blue bars represent the social conditions and grey bars represent the non-social condition. All bars show the relative activation for each condition of interest compared to its matched non-semantic control condition. Error bars show standard error. 
  



## Discussion 
  
This study explored the neural organization of conceptual knowledge in the ATLs. One prominent view holds that the ATLs contribute to semantic representation in a pan-category manner [ , , ], while, in parallel, other researchers have proposed the ATLs respond selectively to socially relevant concepts [ , , , ] including faces [ , , ]. For the first time, we directly compared the predictions of these different accounts of ATL function by using neuroimaging protocols that improve signal in the ATLs [ , ]. The principal finding was graded variation in ATL function. One dominant, bilateral vATL cluster responded in a pan-category and transmodal manner, overlapped with peaks reported in previous semantic studies. A second, more anterior, bilateral vATL cluster responded more weakly albeit preferentially to transmodal person knowledge and coincided with peaks reported in the face recognition literature ( ; tables   and  ). Critically, the pan-category region responded more strongly in all conditions (including person knowledge) than the anterior person-related cluster. Thus the organization of vATL function does not seem to reflect a series of mutually exclusive category-selective regions but rather one in which a dominant core vATL is joined in processing people-related knowledge by the more anterior subregion. Finally, a region in the aSTG responded to socially relevant abstract words but not to socially relevant concrete words (e.g. famous names). This region also responded to all auditory inputs in a similar manner. 

These results can be accommodated by a graded version of the hub-and-spoke model of semantic representation [ , , ]. The pan-category, transmodal responses within the core vATL accord closely with previous studies, using clinical and cognitive neuroscience methods, which implicate this area as the centre point of a transmodal representational ‘hub’ for conceptual knowledge [ , – , ]. On this view, the ATL-hub interacts with various distributed regions (coding modality-specific sources of information) to form coherent, generalizable concepts [ , , , ]. Damage to the ATLs in SD not only generates a pan-category, transmodal semantic deficit [ ], but also the degree of vATL hypometabolism correlates with their level of semantic impairment [ ]. Our findings also accord with multivariate neuroimaging studies showing that vATL voxels code not only the conceptual convergence of multiple sensory features e.g. colour/shape; [ ] but also conceptual knowledge for different exemplars, independently of their conceptual properties e.g. how/where an object is used [ ]. An important corollary of this graded hub-and-spoke theory is that the distinct vATL peaks localized here do not represent separate functional modules in the traditional sense. Instead, we believe that they are markers of continuous, graded information coding within the ATLs. 

The transmodal, person-related responses in the (right) anterior vATL subregion (TP; ROI no. 2) can be accounted for by previous proposals that the ATLs are not entirely homogeneous in their function but instead develop graded specializations as a function of differential connectivity to extra-temporal regions [ , , , , , ]. According to this ‘graded’ hub-and-spoke theory, the core vATL is transmodal and pan-category because it is the centre point of multimodal inputs/outputs. Moving away from this core region, functions become increasingly influenced by one or more dominant inputs/outputs reflecting stronger connectivity to a specific neighbouring sensorimotor/verbal region [ , ]. Extending this line of argument, the   anterior   vATLs might play an important role (in addition to the core region) in representing socially relevant concepts (e.g. person knowledge), because of connections to limbic and orbitofrontal cortices via the uncinate fasciculus [ – ]. This is in line with studies indicating that temporo-polar regions contribute to the representation of social and emotional concepts [ , , , ]. The role of such ATL–limbic connectivity in person knowledge remains an intriguing area for future research. Consistent with this hypothesis, other structures implicated in social cognition, including the orbitofrontal cortex and precuneus, also showed transmodal person-related responses ( ). These regions are consistent with studies exploring conceptual category representation across the whole brain [ , ]. Importantly, the graded hub-and-spoke approach does not preclude the presence of other category-preferential responses within the ATLs, based on their particular patterns of connectivity [ , – ]. 

The laterality of ATL responses to conceptual knowledge is currently highly debated [ , – ]. Some studies indicate that patients with right ATL lesions are more likely to be prosopagnosic than those with left ATL damage [ , , ]. Electrophysiological recordings from patients with intractable epilepsy have also revealed face-selective electrophysiological potentials in the right vATL [ ]. Here, we found that activations for person knowledge in the ATLs were highly bilateral. This also follows data that patients with ATL atrophy/resection show a transmodal person deficit [ , – ]. In addition, there were subtle hemispheric variations in the person-selective ATL regions. While the right vATL exhibited equivalent activation for faces and spoken names, the left was more active for the spoken names. This is consistent with studies suggesting that the left ATL is somewhat more important for retrieving knowledge from verbal input including people's names [ , , , – ] as well as being critically involved in generating names of all types from semantic knowledge [ , , , ]. 

This study also helps to resolve another conundrum posed by the literature: the general semantics literature has suggested that the vATL is a transmodal region, whereas the face-processing literature has implicated this region, specifically, in recognition of faces. The use of visual stimuli may have been based on the assumption that the vATLs are a purely visual region because of their anatomical positioning at the apex of the visual ventral stream [ , ]. Indeed, studies have shown connectivity between the vATLs and face-selective regions in the posterior fusiform gyrus [ , , ], and disruption of this anterior–posterior connectivity has been implicated in congenital prosopagnosia [ , ]. The transmodal responses observed here and in other studies using a variety of neuroscience methods [ , , , ] suggest that in addition to the strong visual input to the vATLs, it also receives input from other modalities, consistent with previous findings of transmodal responses to faces and names [ ]. This study bridges, therefore, between the face-processing and semantic processing literatures by showing   transmodal   person-related vATL activation [ , , ]. In keeping with the graded hub-and-spoke model, these findings suggest that the vATLs support the coding of coherent, transmodal semantic representations of people (alongside other categories of concept)—a proposal that accords with models of familiar face processing [ ]. 

The responses to socially relevant abstract words in the aSTG is a highly replicable result, albeit with some debate regarding the laterality of response [ , , , , ]. More recently, the causality of this region in processing social concepts has been confirmed using transcranial magnetic stimulation [ ]. In this study, we were able to show that this region does not respond selectively to other kinds of socially relevant words, in particular the names of famous people (Study 2). This difference between abstract and concrete social concepts might reflect the gradient of concreteness previously shown across the ATLs [ ]. In a functional imaging study the authors showed that abstract words activated aspects of the dorsolateral ATL and inferior frontal cortex relatively more than concrete words; by contrast, concrete words activated aspects of the ventromedial ATL relatively more [ ]. The interpretation of this gradation was that it reflected the underlying properties of the words; concrete words are more associated with visual information, whereas abstract words are associated more with auditory–verbal information and might require greater executive control. In this study, one explanation for the result that famous names activate the vATL more may be that names of people are more intrinsically linked to a mental image of their corresponding face. This visual information may be lacking when associated with abstract words describing social concepts (e.g. polite). 

In conclusion, an emerging literature suggests the vATLs exhibit face-selective responses [ , ]. Our results indicate that this picture is incomplete. An anterior vATL region does respond to images of people but does so equally strongly for their spoken names, indicating a transmodal role in the representation of person knowledge. Slightly posterior to this site, the ‘core’ vATL responds even more strongly and equally for all conceptual categories. This study provides clear evidence in favour of the ATL as a graded transmodal hub which supports coherent conceptual representation across all categories and modalities [ ]. Variation of function in this region reflects graded changes in its connectivity to other brain areas, including ATL–limbic connections, which may be critical for socially relevant concepts including people. Given the inherent broad definition of what constitutes ‘social concepts’, future research should compare and contrast the activation within and across the ATLs with regard to other exemplars of socially relevant concepts. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-19'>
<h2>19. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/23300517/' target='_blank'>23300517</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Social Cognition, the Male Brain and the Autism Spectrum</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2012</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0049033</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3530576/' target='_blank'>3530576</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study used fMRI while participants performed social-related tasks (approachability and intelligence judgements from faces). It reports data from healthy adult participants (n=47; ages within 17–65) and presents whole-brain second-level random-effects analyses for the social versus gender contrasts (with cluster-level correction reported), satisfying the whole-brain requirement. Although an additional ASD group was included, healthy participants’ results are reported separately. The paper also includes some ROI analyses for a targeted ASD vs control comparison, but these are supplemental and do not preclude inclusion because whole-brain results are available. Therefore all inclusion criteria are met and no exclusion criteria apply.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Behavioral studies have shown that, at a population level, women perform better on tests of social cognition and empathy than men. Furthermore Autism Spectrum Disorders (ASDs), which are characterized by impairments in social functioning and empathy, occur more commonly in males than females. These findings have led to the hypothesis that differences in the functioning of the social brain between males and females contribute to the greater vulnerability of males to ASD and the suggestion that ASD may represent an extreme form of the male brain. Here we sought to investigate this hypothesis by determining: (i) whether males and females differ in social brain function, and (ii) whether any sex differences in social brain function are exaggerated in individuals with ASD. Using fMRI we show that males and females differ markedly in social brain function when making social decisions from faces (compared to simple sex judgements) especially when making decisions of an affective nature, with the greatest sex differences in social brain activation being in the inferior frontal cortex (IFC). We also demonstrate that this difference is exaggerated in individuals with ASD, who show an extreme male pattern of IFC function. These results show that males and females differ significantly in social brain function and support the view that sex differences in the social brain contribute to the greater vulnerability of males to ASDs. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (25721 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Previous behavioural studies have suggested that women perform better in tests of social cognition and empathy than males  – , although these findings have not been without controversy. Studies using questionnaires have shown that women score more highly than men on measures of empathy and social function  ,  ,  , but such self-report measures may be influenced by differential motivation rather than true biological differences in social performance. Experimental evidence of sex differences in social function has been obtained from studies looking at facial emotion expression processing which have suggested a female advantage in decoding emotional expressions from faces and from the eye region alone  ,  ,  ,  . However sex differences in facial emotion processing are generally subtle and restricted to low-intensity emotions  . 

Imaging studies have provided additional evidence of sexual dimorphism in regions which contribute to social functioning. Longitudinal structural imaging studies have demonstrated sex differences in the trajectory of brain development, with females showing earlier overall cerebral development and greater relative frontal lobe grey matter volumes  . Cross-sectional studies in adults have confirmed that females have larger relative volumes of a number of brain regions implicated in social function including the inferior frontal cortex (IFC)  – , cingulate cortex  ,   and inferior parietal cortex  ,  ,  , whilst men have larger relative volumes of the amygdala  ,   and cerebellum  ,  . There have been fewer functional imaging studies that have investigated sex differences in the social brain but investigations of face processing have suggested a degree of sexual dimorphism in brain function which depends in part on the nature of the stimuli used  – . 

Sexual variation in social brain regions is potentially of relevance to autism spectrum disorder (ASDs) which are characterised by impairments in social cognition and are at least four times more common in males than females  . People with ASD score lower on questionnaire measures of empathy than healthy males (who in turn score lower than healthy females)  , and perform relatively poorly on tests of emotion recognition and social judgement  ,  . Furthermore individuals with ASD have been found in some studies to display an exaggerated male pattern of neuroanatomy  ,   and there is evidence from functional imaging studies that individuals with ASD may exhibit a male pattern of brain activation in regions including the IFC  ,  . 

In view of existing evidence that men and women's social functioning may differ at a neural level, and that those with ASD may have an exaggerated male pattern of social brain function, in the present study we sought to determine whether males and females differ in terms of social brain function while viewing faces during fMRI, and to relate these findings to brain activation in individuals with ASD. 


## Results 
  
### Male and female brain activation during social judgement 
  
We compared male and female brain activation during social judgement in forty seven volunteers (25 males and 22 females). All participants completed two social judgement tasks during the fMRI session. In the first task participants were asked to rate whether faces appeared approachable or not, a primarily affective social decision. In the second task participants rated faces according to whether they appeared intelligent or not, a primarily cognitive social decision  . A matched perceptual control condition was used for both tasks, which consisted of determining male or female sex from the same faces, counterbalanced across participants. There were no difference between the sexes in terms of accuracy of performance in wither the approachability task (gender judgements F  = 0.40, P>0.5; approachability judgements F  = 0.50, P>0.4) or intelligence task (gender judgements F  = 0.02, P>0.8; intelligence judgements F  = 0.04, P>0.8) ( ). In terms of reaction times male participants were slightly, but significantly, slower than females in making social judgements of both approachability (F  = 4.24, P = 0.046) and intelligence (F  = 4.75, P = 0.035) from faces ( ). There was however no difference between the sexes in reaction times for sex judgements during either task (P>0.2 in all cases) ( ). 
   Behavioural performance in the approachability and intelligence judgement tasks.        
Analysis of the fMRI data revealed marked differences in the function of male and female brains during affective social decision-making. Male participants showed increased brain activation when making social judgements of approachability compared to simple judgements of sex, with activation differences localized to regions of the social brain including the medial prefrontal and bilateral inferior frontal cortices (  and  ). However, strikingly, female participants did not show this increase in brain activation when making approachability judgements compared to perceptual judgements of the face's sex (  and  ). Direct comparison of brain activation in males and females revealed a significant difference between the sexes in the left inferior frontal cortex (IFC) (Peak −50, 22, 8; total extent 678 voxels; T = 3.56; cluster Pcorr = 0.034;  ,   and  ), with males showing greater left IFC activation. Males and females also showed a different relationship between social brain activation and empathy, with males showing a positive whole brain correlation between left IFC activation and empathy scores (EQ) during approachability judgements (Peak −52, 12, −2; extent 743 voxels; T = 4.03; cluster Pcorr = 0.022;  ) which was not seen in females. Men and women did not differ in brain activation when making judgements of intelligence from faces, suggesting that the sex differences in social brain function are not seen in social decisions that are less related to appraisal of affective state and potential threat ( )  . These findings demonstrate that men and women differ in social brain function with particularly marked differences between the sexes evident in the left IFC during judgements of approachability. 
   Brain activation during approachability judgements in A) males and B) females (SPM thresholded P<0.001).  
C) Between group comparison showing greater activation of inferior frontal cortex (IFC) in males than in females during approachability judgements (SPM thresholded P<0.005). 
     Convergent activation changes in the left inferior frontal cortex in males and individuals with ASD.  
Red scale indicates regions showing greater activation in males than females. Blue scale indicates regions showing greater activation in participants with ASD than controls. Green scale indicates regions correlating with empathy in males. A) Transverse view, B) Coronal view, C) Saggital view. All contrasts thresholded at T>2.5. 
     Regional brain activation during the approachability task for males and females (contrast of approachability judgements versus gender judgements).           Regional brain activation during the intelligence task for males and females (contrast of intelligence judgements versus gender judgements).        
We further investigated whether there were any differences between males and females in brain activation during social judgements or judgements of sex from faces compared to the baseline rest condition could account for these sex differences ( – ). There were no differences between males and females in brain activation in the IFC region when social/sex judgements were compared to the baseline rest condition, indicating that the sex differences in IFC activation did not arise from differences in response to the sex-judgement comparison condition ( – ). It is however interesting to note that females showed bilaterally greater activation of the insula when making simple sex judgements from faces (compared to baseline rest) in the approachability task, suggesting that females do process facial information differently to males even when not explicitly making higher-order social judgements (  and  ). These differences in activation between sexes were however in a different region from those seen in the more constrained contrast of approachability judgements versus sex judgements and therefore could not account for the observed differences in IFC activation seen between the sexes. 
   Regional brain activation during the approachability task for males and females for sex judgements compared to the baseline rest condition.           Regional brain activation during the approachability task for males and females for social judgements compared to the baseline rest condition.           Regional brain activation during the intelligence task for males and females for sex judgements compared to the baseline rest condition.           Regional brain activation during the intelligence task for males and females for social judgements compared to the baseline rest condition.        

### Social brain activation during social judgement in ASD 
  
We next investigated brain activation during social judgement in Autism Spectrum Disorders (ASD). Twelve males with a diagnosis of ASD and twelve healthy male controls males participated in the study. Participants were matched in terms of age, handedness and IQ. Individuals from the ASD group showed significantly higher levels of autistic symptoms as assessed on the autism quotient (AQ) (P<0.001)  ,  . All participants completed the approachability task during fMRI scanning. There was no difference between the groups in terms of accuracy of task performance for either sex judgements or social judgements (F  = 0.75, P>0.3 and F  = 2.37, P>0.1 respectively) or in terms of reaction times for either gender or social judgements (F  = 0.80, P>0.3 and F  = 0.75, P>0.3 respectively) ( ). Individuals with ASD showed greater activation of the left IFC during approachability judgements (compared to judgements of sex) than healthy males (Peak −36, 36, −14 with secondary peak at −50, 20, 0; cluster extent 210 voxels; peak T = 4.32; cluster Pcorr = 0.049 within bilateral IFC mask;  ), paralleling the difference in IFC activation seen between healthy male and female participants ( ). 
   Comparison of brain activation during the approachability task between the ASD group and matched male control participants.        


## Discussion 
  
In the present study we demonstrate sex differences in social brain function while making judgements of approachability from faces which are greatest in the left inferior frontal cortex (IFC). We further demonstrate that differences in activation in the IFC region differentiate men with ASD from neurotypical males. Notably these differences were evident despite matched accuracy of task performance, controlling for an important potential confound. Overall these studies demonstrate significant sexual dimorphism in social brain function which may contribute to the greater vulnerability of males to ASD. 

The IFC is part of the social brain network and has been previously been shown to be activated when individuals make social judgements from faces  ,  . Lesion studies have found that damage to the IFC impairs emotional empathy but not cognitive empathy, as assessed by self-report questionnaires, facial expression identification tasks, and theory of mind tasks  . The IFC is considered part of the fronto-parietal mirror neuron system, which may have a role in understanding the mental states of others (for reviews see  ,  ), although mirror neuron function was not explicitly tested in the present studies. 

Sex differences in the IFC have been identified in both structural and functional imaging studies. Structural MRI studies have shown that women have larger regional grey matter volumes in a number of regions related to social information processing including the IFC  – ,  ,  , and have greater cortical folding in the IFC and parietal cortex  . Self-reported social co-operativeness has been found to correlate with volume of the posterior IFC bilaterally and the left anterior medial prefrontal cortex  . These findings were partially replicated by Cheng et al., 2009   who found larger female grey matter volumes in the right posterior IFC (pars opercularis), right inferior parietal lobule and right medial prefrontal cortex, and that volumes in all these regions correlated with self-reported empathy. 

Functional MRI studies have also provided evidence of sex differences in the IFC. fMRI studies have shown greater female activation of the right IFC during evaluation of facial emotion  , of the left IFC during attribution of likely facial emotion   and of the IFC bilaterally during the “Reading the Mind in the Eyes” test  . Sex related activation differences may vary with social stimulus: men showed greater activation than women in the left IFC and associated brain regions when viewing contemptuous faces, but women showed greater activation in the left IFC when viewing disgusted faces  . Aleman and Swart   suggested this could be related to a greater male interest in social hierarchy. Possibly consistent with this, men were found to activate the right IFC more than women when viewing children's faces contrasted with adult faces  . 

Our finding of increased male left IFC activation when judging approachability may reflect the implicit requirement to assess potential threat and social dominance contained within an assessment of approachability. Alternatively, it may be that men are less efficient at making such affective judgements, and require greater regional blood flow for their completion. It is not however possible to fully elucidate the explanation for the differences in IFC activation between males and females within the current dataset. It is interesting to note that there was a positive correlation between empathy scores (as measured by the EQ) and IFC activation within males but not females. One potential interpretation of this finding would be empathic males have adapted to underlying differences in the social brain (especially the IFC) between males and females by showing greater recruitment of this brain region during social tasks. However full exploration of these possibilities would require further studies with parametric variation of both sex of participant and task difficulty. 

The key finding of our second study is that men with ASD also show greater blood flow to the left IFC than neurotypical men while performing the same test of approachability from faces. This is consistent with previous work implicating the IFC in ASD. The IFC (pars opercularis) has been found to be smaller in ASD by voxel based morphometry  ,  , manual tracing   and automated cortical thickness assessment  . IFC volume reductions in ASD have also been found to correlate with observer rated social impairment  ,  . 

Previous fMRI studies have also implicated the IFC in ASD. Reduced IFC activation has been reported in people with ASD performing the “Reading the Mind in the Eyes” test   and reduced right pars opercularis activity in children with ASD viewing facial emotions, which correlated with severity of observer rated social impairment  . In contrast, during irony comprehension children with ASD were found to show greater activation in the right IFC  . This may reflect the interaction of task difficulty with brain activation in dysfunctional brain regions, whereby easier tasks are associated with more activation than controls, and harder tasks with lesser activation. Such an effect has been observed for other frontal brain regions and tasks in other neuropsychiatric conditions. For example patients with schizophrenia show a leftward shift in the relationship between dorsolateral frontal activation and task load during working memory tasks  . 

It is striking that the left IFC, which showed the greatest activation difference between men and women during a test of social judgement, also showed a significant difference in activation between individuals with ASD and controls in the same experimental paradigm. These findings support the view that differences in social brain function between the sexes contribute to the higher rates of ASDs seen in males, potentially through convergent effects on the function of the IFC. The results are also consistent with the “extreme male brain theory” of autism which suggests ASDs are associated with an exaggeration of normal male vs female neural and psychological differences, possibly due to heightened exposure to prenatal androgens, or by the cumulative action of risk genes differentially expressed in males and females  . However the results are also compatible with a more general convergence of sex differences in social brain function with neural risk for ASD. 

We note some limitations to the current study. Firstly, the task used tested only a restricted range of social cognitive function (the judgement of particular attributes from static images of faces) and therefore the broader generalisability of these findings needs to be determined in further studies. Secondly, we did not include females with ASD and therefore we cannot draw conclusions about social brain function in this important (although less common) group. 

In summary, the present results demonstrate a marked difference in social brain function between men and women which is accentuated in individuals with ASD, suggesting a neurobiological substrate for the increased rates of ASDs in males. 


## Materials and Methods 
  
### Ethical approval 
  
All participants gave written informed consent approved by the Lothian Research Ethics Committee. Participants were able to withdraw from the study at any stage. Participants who withdrew from the study remained eligible for all treatments (where required) and were not disadvantaged in any way. 


### Participants and behavioural measures 
  
Forty-seven healthy control participants were recruited (25 males and 22 females) for the first study comparing social brain activation in males and females. The groups were well matched in terms of age (males mean 32.7 years (SD = 8.1); females mean 31.7 years (SD = 9.0)), years of education (males mean 16.6 years (SD = 2.1); females mean 16.8 years (SD = 1.8)) and NART IQ (males mean 117.9 (SD = 6.4); females mean 116.1 (SD = 6.0)) (P>0.3 for all). All participants were right handed. Exclusion criteria included a history of neurological or psychiatric disorder, substance dependence and factors precluding MRI scanning. All participants completed questionnaire measures of empathy and systematizing using the using the empathy quotient (EQ) and systematizing quotient (SQ). Mean scores by gender were: males EQ 45.3 (SD = 9.9); SQ 34.9 (SD = 10.0); females EQ 50.4 (SD = 8.2); SQ 21.6 (SD = 9.7). 

For the second study investigating the social brain activation in ASD we recruited 12 new male healthy control participants and 12 male individuals with ASD. One individual with ASD was excluded from analysis due to scanner artefacts. Additional exclusion criteria were as above. Groups were matched in terms of age (ASD group mean 36.6 (SD 12.0), control group mean 35.1 (sd 10.3)) and IQ (ASD group mean 105.8 (SD 20.8), control group mean 109.3 (sd 10.5)). All subjects were right handed. All individuals in the ASD group were interviewed by a clinician and case notes were reviewed to confirm a DSM-IV diagnosis of Asperger's syndrome (8 individuals) or high functioning autism (4 individuals). Autistic symptoms were rated in all participants using the Autism Quotient (AQ). AQ scores in the ASD group were mean 33.5 (SD 7.0) and in the control group were mean 14.3 (SD 3.8). In addition both the ASD group and the control group also completed the EQ (mean scores: 33.5 (SD 8.3) and 50.5 (SD 11.4) respectively) and SQ questionnaires (mean scores: 32.1 (SD 17.8) and 32.6 (SD 9.8) respectively). 


### Task Design 
  
The approachability and intelligence judgement tasks were performed as described previously  . In the approachability task, participants had to decide whether faces appeared ‘not approachable’ or ‘very approachable’. In the intelligence task, participants had to decide whether the faces appeared ‘not intelligent’ or ‘very intelligent’. Faces were selected from a large battery of 1000 face images to represent the extremes of each social dimension. 

The stimuli were colour photographs of Caucasian male and female adult faces selected from a previously collected database of 1000 photographs of faces of non-famous people  . All the pictures were cropped around the face and hair, so that the minimum possible clothing and background were visible. The photographs were all adjusted to the same height (150 pixels; approximately 5 cm on the screen display), while the width varied slightly. No other attempt was made to standardise the pictures. Instead, the database included photographs that covered a wide range of adult ages, poses, and expressions, so that as many as possible of the naturally occurring cues would be present in the images. All the photographs had been rated on several characteristics with 1 to 7 point scales for all characteristics. The faces were highly reliably rated on both social dimensions across all raters (P<0.01; Cronbach's alpha 0.79 for approachability judgements and 0.75 for intelligence judgements). Faces representing the extremes of each social dimension were selected as stimuli for the neuroimaging task. There was a low overall correlation (0.26) between decisions made on the approachability and intelligence judgement tasks, suggesting that these tasks test different dimensions of social judgement  . 

Two sets of facial stimuli (A and B) were assembled for each task. The sets consisted of 18 male and 18 female faces each. The faces of each sex were selected to maximise the difference across each social dimension examined (for example, in the approachability condition, 9 high approachability faces and 9 low approachability faces of each gender per set). For each participant one set of faces was used for social judgements and the other set of faces was used for gender judgements. The use of the stimulus sets was counterbalanced across participants such that half the participants made social judgements from stimulus set A and control gender judgements from stimulus set B and half the participants made social judgements from stimulus set B and control gender judgements from stimulus set A  . 

Each task consisted of two runs of six 25 s blocks per run, with blocks of social judgements (“social” condition) alternating with blocks of gender judgements (“gender” condition). All blocks were separated by a 12.5 s rest period. Six faces were shown per block. The alternative response choices were shown on the screen (eg “not approachable” and “very approachable”) and participants had to press a button to indicate which response they felt was most appropriate for each face shown. Responses on the social judgement tests were scored according to their agreement with normative studies and reaction times were recorded for all participants  ,  . Task order was counterbalanced across participants. 


### Image Acquisition and Analysis 
  
Imaging was performed on GE 1.5TE Signa scanner (GE Medical). Functional scanning comprised 99 volumes per run (Field of View 22 cm; Time to Echo (TE) 40 ms; Volume acquisition time (TR) 2.5 s). Axial slices were acquired with a thickness of 5 mm and matrix size of 64×64. EPI images were reconstructed offline in ANALYZE format (Mayo Foundation, Rochester, MN, USA). Image processing was conducted using SPM2 (  http://www.fil.ion.ucl.ac.uk/spm/software/spm2/  ). Pre-processing consisted of re-orientation of the images and realignment to the mean EPI image. Within-scanner movement was examined and an exclusion criterion of movement>3 mm over less than 20 consecutive images was applied. No subjects were excluded due to excessive movement. Images were subsequently normalised to the standard Montreal Neurological Institute EPI template and smoothed using a Gaussian kernel (8 mm  full-width at half-maximum). The participant's data were filtered in time using a high pass filter (150 s cut-off) and temporal autocorrelations were accounted for by using an AR(1) model  . 

Statistical analysis was performed in SPM2. At the individual participant level the data for each task were modelled with the three conditions (“social”, “gender” and “rest”) each modelled by a boxcar convolved with a canonical haemodynamic response function. Movement was modelled as a covariate of no interest. Contrast images were generated for each participant for the contrast of interest (“social” versus “gender”). Contrast images were entered into second-level random effects analysis using t-tests to examine within-group and between-group effects. Within group regression analysis was performed to determine brain regions in which activity correlated with empathy quotient scores (EQ) and systematising quotient scores (SQ)  ,  . 

Statistical maps were thresholded at P<0.001 uncorrected for within group analysis and P<0.005 for the between group and regression analyses. Regions were considered significant at P<0.05 at the cluster level, corrected for multiple comparisons across the whole brain. Region of interest analysis was conducted to examine the hypothesis that inferior frontal cortex activation differed between ASD group and controls, based on results from the male-female comparison, using an anatomically derived region of interest derived from the aal atlas (WFU PickAtlas) comprising all divisions of the inferior frontal cortex bilaterally  ,  . 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-20'>
<h2>20. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22062191/' target='_blank'>22062191</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Autism spectrum traits predict the neural response to eye gaze in typical individuals</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Neuroimage</p>
<p><strong>Publication Year:</strong> 2012</p>
<p><strong>DOI:</strong> 10.1016/j.neuroimage.2011.10.075</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3315678/' target='_blank'>3315678</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This fMRI study tests social processing (eye-gaze/social attention) in a group of healthy typical adults (N=18; age 18–30), meeting the age and healthy-participant criteria. The task is explicitly social (gaze perception/inferring others’ attention/intentions). Whole-brain second-level analyses are reported (SPM random-effects GLM with voxelwise thresholds and FDR correction), and results from whole-brain contrasts are provided; ROI analyses are additionally reported but do not replace whole-brain results. No exclusion criteria are violated. Therefore the study meets all inclusion requirements for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Autism Spectrum Disorders (ASD) are neurodevelopmental disorders characterised by impaired social interaction and communication, restricted interests and repetitive behaviours. The severity of these characteristics are posited to lie on a continuum extending into the typical population, and typical adults' performance on behavioural tasks that are impaired in ASD is correlated with the extent to which they display autistic traits (as measured by Autism Spectrum Quotient, AQ). Individuals with ASD also show structural and functional differences in brain regions involved in social perception. Here we show that variation in AQ in typically developing individuals is associated with altered brain activity in the neural circuit for social attention perception while viewing others' eye gaze. In an fMRI experiment, participants viewed faces looking at variable or constant directions. In control conditions, only the eye region was presented or the heads were shown with eyes closed but oriented at variable or constant directions. The response to faces with variable vs. constant eye gaze direction was associated with AQ scores in a number of regions (posterior superior temporal sulcus, intraparietal sulcus, temporoparietal junction, amygdala, and MT/V5) of the brain network for social attention perception. No such effect was observed for heads with eyes closed or when only the eyes were presented. The results demonstrate a relationship between neurophysiology and autism spectrum traits in the typical (non-ASD) population and suggest that changes in the functioning of the neural circuit for social attention perception is associated with an extended autism spectrum in the typical population. 
   Highlights  
► Autistic spectrum might extend to typically developing (TD) individuals. ► We studied TD individuals with varying Autism Spectrum Quotient (AQ). ► AQ correlated with BOLD response to viewing variable vs. constant eye gaze. ► AQ did not correlate with response to directional control stimuli. ► Neurophysiology and autism spectrum traits are associated in non-AS individuals. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (30795 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Autism spectrum disorders (ASD) are characterized by abnormal social interaction and communication, severely restricted interests and repetitive behaviour. ASD have a range of clinical phenotypes from mild to severe, however an even wider continuum of social-communicative ability has been proposed extending into the general or typical population ( ). Initial support comes from studies demonstrating that the degree of autistic traits measured by Autism Spectrum Quotient (AQ;  ), in both ASD and typical populations, is related to performance on behavioural tasks that show impairments in ASD, including self-focussed attention ( ), the ability to draw mentalistic inferences from the eyes ( ), and attentional cueing from eye gaze ( ). However, stronger evidence for a continuum extending into the typical population would involve a demonstration that the neural response to these sorts of social tasks or stimuli is related to typical participants' scores on the AQ. 

Neuroimaging has shown structural and functional impairments in ASD in ‘social’ brain regions involved in processing goal-directed actions and biological motion (superior temporal sulcus, STS), theory of mind (medial prefrontal cortex; mPFC and temporo-parietal junction; TPJ), and emotion (amygdala) (see reviews in  ). A number of these areas, together with components of the attention system, are recruited during gaze perception ( ), and we will refer to them as the ‘social attention’ network. Since individuals with ASD also show an abnormal neural response to gaze cues ( ), gaze perception provides a well-grounded model for studying neurophysiological correlates of the autistic spectrum in the general population. Our recent work in typical participants showing that individual differences in AQ predict changes in the structure and function of the posterior STS (pSTS), a central component of the social attention network, provides further reason to predict that a relationship between AQ and the social attention network might be found ( ). Specifically, this study found a reduction in white matter in pSTS of individuals with higher AQ scores. This was accompanied by an increased task-independent deactivation in high-AQ subjects, akin to ‘resting state’ activity, in the same area of pSTS. Here we investigate whether the BOLD response in the pSTS region, and wider components of the social attention network with which it is connected ( ), show a significant relationship with AQ in response to viewing gaze stimuli. This would provide the first direct evidence that individual variation in autism spectrum traits in typical participants impact on the neural correlates of social processing. We addressed this in the context of a functional magnetic resonance imaging (fMRI) study. 

Participants viewed epochs of faces gazing in ‘variable’ directions (i.e., left, direct, and right) or a constant direction (e.g., all left), implying rapid changes in their focus of attention or interest, or no change, respectively ( ). A second, control condition comprised ‘variable’ and ‘constant’ epochs of oriented heads with eyes closed, thus physical direction was again variable or constant but without concomitant changes in the faces' focus of attention and interest. ASD is known to impact primarily on the ability to draw mental inferences from social attention cues (e.g., that a person is   interested   in something to their left) rather than discrimination of their perceived physical direction ( ). Consequently, an effect of AQ on the social attention network was predicted to be most apparent for a comparison of the variable versus constant gaze conditions because mental inferences regarding the faces' should be greater for the rapidly changing foci of interest conveyed by the variable gaze condition relative to the constant gaze condition in which the focus of interest remained fixed. In contrast, we predicted that an effect of AQ should be absent for a comparison of the variable versus constant head conditions because heads with eyes closed convey directional information only. 

Our study also included a third ‘Eyes only’ condition in which gaze was again variable or constant but only the eyes were visible. For this condition we predicted a reduced or absent relationship with AQ for a comparison of the variable and constant conditions since previous research has shown that perception of gaze direction, or gaze following, is heavily influenced by the orientation of the head. For example, significant gaze cueing to the left (or right) has been reported using gaze cues in which the heads are rotated to the left (or right) and the gaze directed towards the observer ( ). Moreover, these effects were significantly larger than those observed using leftward (or rightward) oriented heads with their gaze oriented in the same direction as the heads. This suggests that the cueing effect is not dependent on the direction of the gaze alone, but is contingent on directional cues conveyed by the head   and   eyes. 


## Materials and methods 
  
### Participants 
  
Eighteen right-handed typical, healthy volunteers (4 males; aged 18 to 30 years; mean age = 24 years) with normal or corrected to normal vision participated in the study in return for payment. Individuals with a history of neurological or psychiatric disease or currently taking medication affecting the central nervous system were excluded. All provided written informed consent as a part of a protocol approved by the Suffolk Research Ethics Committee. Participants completed the AQ before scanning. This questionnaire contains 50 questions measuring the extent of autism spectrum characteristics, and has good test–retest reliability and internal consistency ( ). 


### Design and procedure 
  
Stimuli and design are summarized in  . The stimuli were prepared from 10 computer-generated faces (5 males and 5 females). Participants were shown three types of facial stimuli. A ‘Gaze’ condition comprised full-face views of faces with eyes oriented 25° left (L), 0° (direct), or 25° right (R). In a second ‘Heads’ condition, heads with eyes closed were oriented 25°L, 0°, or 25°R. In a third, ‘Eyes only’ condition, the gaze was again oriented 25°L, 0°, or 25°R, however, the majority of the head was masked leaving only the eyes visible. The facial stimuli were presented in 15 s epochs containing six presentations of one of the three facial stimulus types. The epochs were divided into two further conditions — ‘variable’ and ‘constant’. For example, in the ‘constant’ condition for the Gaze stimuli, all faces displayed the same gaze direction (i.e. all 25°L, all 0° or all 25°R), whereas the variable condition comprised continually changing gaze directions (i.e. 25°L, 0° and 25°R in random order). Similarly, the variable and constant conditions for the Heads and Eyes-only stimuli showed different or repeated head and gaze orientations. 

Each facial stimulus was presented for 2 s, followed by a 500 ms blank screen to prevent apparent motion. Consecutive faces never showed the same identity. The task was to categorize the gender of each face. Seven epochs of each category were presented. The order of epochs was fixed for each participant (e.g. gaze, heads, eyes-only, gaze …) counterbalanced across participants. The face epochs were interleaved with 10 s epochs of house images. This helped to reduce activation in the gaze network between face conditions and acted as a baseline condition. Note that houses were used in preference to a fixation (rest) condition because activation at rest varies between individuals with Autism and typical controls in brain areas associated with social processing, and is correlated with AQ in typical participants ( ). To reduce task switching, participants were also asked to categorize the gender (‘masculine’ vs. ‘feminine’) of the house stimuli. Pilot testing showed that participants were readily able to categorise houses with these labels. The total task duration was 33 min and 50 s. The stimuli were presented via an angled mirror above the participants' eyes. The mirror reflected images back-projected onto a translucent screen in the bore of the magnet behind the participants' head. All participants practised the task outside the scanner prior to the experiment. 


### Image acquisition and preprocessing 
  
MR imaging was performed with a 3-Tesla Tim Trio Magnetic Resonance Imaging scanner (Siemens, Germany) with a head coil gradient set at the MRC Cognition and Brain Sciences Unit. Whole-brain data were acquired with an echo-planar T2*-weighted (EPI) imaging sequence, sensitive to the blood–oxygen-level-dependent (BOLD) signal contrast (40 oblique slices, 3 mm slice thickness; TR = 2424 ms; TE = 30 ms; flip angle = 78°; FOV 192 mm; voxel size = 3 × 3 × 3 mm). The first 3 volumes were discarded to allow for equilibration effects. T1-weighted structural images were acquired at a resolution of 1 × 1 × 1 mm. Data were preprocessed and analyzed using SPM5 software (  www.fil.ion.ucl.ac.uk/spm/  ). The EPI images were sinc interpolated in time to correct for slice time differences and realigned to the first scan by rigid body transformations to correct for head movements. EPI and structural images were coregistered and normalized to the T1 standard template in MNI space (Montreal Neurological Institute (MNI) — International Consortium for Brain mapping) using linear and non-linear transformations, and smoothed with a Gaussian kernel of FWHM 8-mm. 


### Analysis of regional effects 
  
A random effects model was implemented using a two-stage process, of within (first level) and between (second level) subjects modelling, in turn. This random-effects analysis assessed effects on the basis of inter-subject variance and thus allowed inferences about the population that the participants were drawn from. For each participant we used a GLM to assess regionally specific effects of task parameters on BOLD indices of activation. The model included two experimental factors — stimulus type (Gaze, Heads, and Eyes-only) and presentation format (variable vs. constant); effects of no interest (realignment parameters) were also included to account for motion-related variance. Low-frequency signal drift was removed using a high-pass filter (cutoff 128 s) and AR(1) modelling of temporal autocorrelations was applied. 

The individual contrast images were generated using the following contrasts: i) variable versus constant gaze, ii) variable vs. constant heads, and iii) variable vs. constant eyes-only. The second level analyses used these contrast images in new GLMs with AQ as a regressor (plus a constant term), from which we generated statistical images, i.e. SPM-t maps, of voxels showing positive or negative relationships with AQ. With balanced designs at the first level (i.e. similar events for each subject, in similar numbers) this second level analysis closely approximates a true mixed effects design, with both within and between subject variance. A recent meta-analysis identified that perception of others' gaze engages a network of regions comprising the pSTS/TPJ, fronto-parietal attention system, amygdala, and dorsal medial prefrontal cortex ( ). The relationship between AQ and activation in this network was assessed with a threshold of p < 0.05 whole-brain FDR correction and minimum cluster size of 20 voxels. 



## Results 
  
### Behavioural data 
  
The distribution of the AQ scores was as follows: range = 7–33,   M   = 16.80,   SD   = 7.60. The mean accuracy for gender classification of faces was high (86%) and exceeded chance level (50%) for all task conditions,   p  s < 0.05. However, accuracy varied slightly across task conditions,   F  (2,34) = 5.50,   p   < 0.01, η  = 0.24 (  M   = 91%,   M   = 81%,   M   = 88%). As would be expected, accuracy for eyes-only condition was lower than that for the gaze (  p   < 0.01) or head (  p   < 0.01) conditions, for which the full face was visible; the gaze and head conditions did not significantly differ (  p   > 0.05). Median latencies for correct responses were also influenced by condition,   F  (2,34) = 34.48,   p   < 0.001, η  = 0.67 (  M   = 612 ms,   M   = 774 ms,   M   = 613 ms). Latency for eyes-only condition was longer than that for the gaze (  p   < 0.01) or head (  p   < 0.01) conditions, with no differences between the latter two conditions (  p   > 0.05). Neither the accuracy nor the response latency correlated with the AQ scores,   r  s < 0.3,   p  s > 0.4. Accuracy and RTs were not analyzed for the house trials because responses could not be categorised as correct and incorrect. 


### fMRI data 
  
The second-level contrasts for variable vs. constant gaze, variable vs. constant heads and variable vs. constant eyes-only (or vice versa) did not yield any significant effects. Consistent with our hypothesis, however, the variable vs. constant gaze comparison yielded significant positive correlations with the AQ ( ) in a number of regions of the gaze perception network, including right pSTS (50, − 50, 18,   T   = 4.38), intraparietal sulcus (IPS) (34, − 48, 60,   T   = 4.43), bilateral amygdala (left: − 26, − 8, − 12,   T   = 4.37; right: 26, − 4, − 14,   T   = 3.81) and right TPJ (52, − 58, 8,   T   = 4.38). Additional cortical clusters were observed in the vicinity of the MT/V5 (− 42, − 66, 2,   T   = 7.87) and inferior parietal lobule (IPL) and supramarginal gyrus (SMG) (− 42, − 30, 36,   T   = 4.35). Other regions that survived our a priori threshold are summarised in  . 

Following the request of one of the reviewers, a secondary ROI analysis (see Supplementary  ) using independently defined ROIs confirmed that AQ correlated significantly with BOLD response to gaze specifically in regions that prior studies have linked with gaze and face perception (OFA, FFA, pSTS, IPS and amygdala) as well as mentalizing (TPJ),   p   < 0.05 FWE small-volume corrected. In contrast to the gaze condition, AQ scores did not significantly correlate with activation to the variable vs. constant heads and variable vs. constant eyes-only conditions in any brain region, even at reduced threshold (  p   < 0.05, uncorrected). 

As the AQ can be split up into five subscales measuring different domains (social skills, attention switching, attention to detail, communication and imagination), we tested whether the scores for these domains would also show correlations with the variable versus constant gaze/heads/eyes only contrasts. The overall pattern was similar to that observed with the composite AQ score. Once again, the scales only correlated with the response to variable versus constant gaze, and not with variable versus constant heads or eyes-only. The correlations were also smaller in magnitude on average than those for the composite score. This may be because the range of the subscale scores is truncated in comparison with the composite AQ score. Subscales for attention to detail, imagination and social skills showed the largest correlations with the variable versus constant gaze contrast, while attention switching and communication showed the smallest correlations (see Supplementary  ). 

Finally, it is possible that the correlation between AQ scores and activation to variable versus constant gaze was due to an increased response to variable gaze, a decreased response to constant gaze, or both. To explore this further, we examined the correlation between AQ and i) responses to variable gaze vs. house stimuli and ii) constant gaze vs. house stimuli. This demonstrated that for the same regions as shown in  , AQ correlated   positively   with variable gaze versus houses and   negatively   with constant gaze versus houses ( ). 



## Discussion 
  
Our study shows that in typical individuals, the neural response to eye gaze across the social attention network (pSTS, TPJ, amygdala, IPS, SPL, and SMG) is closely related to the number of autism spectrum characteristics they display. The overlap between these AQ-dependent responses and the network for social attention identified by recent meta-analysis ( ) is illustrated in  . Although functional imaging studies have not revealed a specific neural marker of ASD, they have consistently shown abnormal functioning of a number of the same regions that showed AQ-dependent changes in BOLD response in the present study, namely the TPJ, STS and amygdala (see reviews in  ).   showed that relative to typical controls, individuals with ASD show less activation to eye gaze cues in areas such as the pSTS. At first sight then, it is surprising that we found a positive association between AQ and the hemodynamic response to variable versus constant gaze. However, our results accord with recent research showing that AQ scores in neurotypical individuals were   positively   related to the change in BOLD response in pSTS produced by a measure of task-independent deactivation ( ). The same study also showed that AQ was   negatively   correlated with white matter (WM) volume in a very similar region of pSTS (52, − 42 12) which also falls reasonably close to the region where the AQ-dependent pSTS responses were found in the present study (68, − 42, 24; Euclidian distance between the peaks = 20 mm). 

 suggested that the enhanced BOLD signal in high AQ participants might reflect a compensatory response for their reduced pSTS WM volume. A similar inverse relationship between WM integrity and increased BOLD response has been seen in the early stages of multiple sclerosis (MS), which is characterised by damage to WM tracts ( ). Notably, however, after a critical point of white matter deterioration   reduced   BOLD response is found in the later stages of this disease. We do not wish to draw parallels between ASD and degenerative disorders, but rather simply to highlight that the relationship between BOLD response and brain structure is not necessarily positive. It is therefore possible that white matter integrity is negatively correlated with autistic traits throughout the whole AQ range from typical individuals to those with ASD ( ), whereas the BOLD response to social stimuli might show an inverted u-shaped relationship with AQ scores. Hence, increased BOLD response in neurotypical individuals with higher AQ scores could reflect compensatory mechanisms as these individuals may require more cognitive resources to process gaze and other social cues than people with lower AQ scores. However, after some critical point in the AQ distribution (e.g. close to the clinical cut-off) this compensatory processing might fail, at which point, increasing AQ scores begin to show a   negative   association with BOLD responses, resulting in an inverted U-shaped association between AQ and BOLD when the full range of AQ scores are considered. Such an association could reconcile our findings with clinical studies showing decreased BOLD responses to social cues in ASD ( ). In line with this prediction, an inverted-u-shape relationship has already been observed between self-referential cognition and AQ, reflecting a positive association in controls and a negative association in people with ASD ( ). Future research involving both typical and ASD populations should therefore address whether the association between AQ and both the BOLD response and anatomical structure of pSTS across the entire AQ range. 

The above explanation is by no means the only possible factor that could underlie the positive relationship between AQ and BOLD response to eye gaze. As far as we are aware, the only previous study showing an abnormal BOLD response to a comparison of two gaze cues in people with ASD used a very different task in which a face directed its gaze towards or away from the position of an object in the display ( ), depending on the location of the object (i.e., the gaze was the same for both conditions). While Pelphrey and colleagues found reduced pSTS activation in individuals with ASD relative to controls, we cannot discount that people with autism might show increased activation in response to the variable versus constant Gaze conditions used in the current study. In this respect, the important result is that AQ scores were correlated with the activity of a network of regions implicated in gaze processing, rather than the direction of the correlation. 

Our study also suggests that the direction of the relationship between BOLD and AQ may be influenced by the nature of the stimuli. Relative to the house baseline, variable gaze showed a positive relationship with AQ, whereas constant gaze showed a negative relationship; indicating that the overall positive correlation was composed of positive and negative associations between AQ and activation to variable and constant gaze conditions, respectively. This may be explained by the relative extent to which processing variable and constant gaze engages the social attention network in low and high AQ participants. 

### Autism spectrum traits modulate the activity of the social attention network 
  
Hemodynamic response and AQ scores showed a positive correlation with a number of regions in the social attention network. Next, we deal the potential role of each. The pSTS region has been implicated widely in perception of social stimuli (as reviewed by  ), and its involvement in eye gaze perception is well documented ( ). However, recent studies point to its involvement in analyzing behavioural outcomes and intentionality of human actions ( ). Understanding intentions of others from social cues such as gaze is often impaired in autism ( ), and recent imaging studies have found that when compared to controls, individuals with ASD show an abnormal pSTS response to the perceived intentionality of gaze shifts ( ) or abstract shapes moving interactively with implied intentionality (such as chasing or teasing,  ). The present data from typical individuals accord with these results, as we observed the AQ-correlated pSTS response only for the gaze condition, in which the eyes convey a clear intention of looking at, or being interested in, various locations. All in all, these findings fit well with the proposal that functional changes in the pSTS region may underlie some of the social perception dysfunctions in ASD ( ). Interestingly, ROI analysis also confirmed that AQ modulated BOLD responses to gaze in the FFA (see supplementary  ). This accords with findings showing that FFA is involved in processing eye gaze ( ), and is in line with the proposal that the ventral face perception route may also significantly contribute to the processing of changeable facial cues (see reviews in  ) 

By contrast, AQ did not correlate with the change in BOLD response in the head condition in which the eyes were closed, thus conveying no intention of attending anywhere. Given that cueing effects from averted gaze are maximal when they are presented in the context of a full-face view of the head ( ), it is interesting that the correlation was also absent for the eyes-only condition where head direction information was not available. It is therefore possible that the present results reflect the activity of cells coding both head and gaze direction information, and their interactions with other components of the social attention network ( ). Alternatively, the eye region alone may constitute a less natural, ‘less social’ stimulus than gaze shown in the context of a fully visible head. 

It is also interesting to note that pSTS activation was not observed for the group-level analyses of variable vs. constant gaze or variable vs. constant eyes-only contrasts. Although many studies report pSTS activation in gaze perception tasks ( ), some don't ( ). Furthermore, even when effects are observed they tend to be small, suggesting variable evidence exists across subjects. On the basis of the present results showing AQ-dependent pSTS responses to gaze, AQ score might be a factor in determining whether or not the eye gaze perception systems respond to gaze stimuli. In other words, it is possible that the variability in AQ scores in the typical population may account for discrepant findings in the gaze perception literature. For example, relative increases and decreases in pSTS activation in participants scoring high and low on the AQ questionnaire respectively, as shown here, may result in no overall mean change in BOLD response in this region. In this respect, it is worth emphasising that the main effect of an experimental manipulation and its correlations with proxy variables, such as personality scores, measure different things and are statistically distinct. Main effects can occur in the absence of correlations, and vice versa (see review in  ). 

Although TPJ is not typically associated with gaze perception, it has been consistently linked with mentalizing or theory of mind processing ( ), and with directing attention to behaviourally salient events ( ). In the context of the present study, it seems plausible that the association between AQ scores and TPJ activation might reflect individual differences in the spontaneous tendency to draw mentalistic inferences from eyes, given that spatial reorienting (as indexed by the Posner cueing task) is typically intact in autism ( ). AQ was also correlated with activation in the vicinity of the motion-sensitive MT/V5 complex which has been proposed to constitute an initial stage in processing dynamic facial characteristics, including gaze shifts ( ). A magnetoencephalographic study has also shown that MT/V5 may extract social information conveyed by the eyes within 160 ms post-stimulus, as it shows stronger responses to faces that establish gaze contact rather than gaze aversion ( ). The AQ-dependent MT/V5 activation shows that autistic traits could influence even the very early, dynamic face processing stages. This raises the possibility that facial processing deficits observed in ASD (see  ) could be partially accounted for by deficits in extracting motion cues from faces, although this would need to be verified with studies of individuals with ASD. 

Several studies suggest that the amygdala's role in gaze perception relates to drawing mentalistic inferences from eyes ( ) and detecting or monitoring gaze contact ( ), but its exact contribution is currently unclear. ASD does not typically impair discrimination of others' gaze direction, but hampers the ability to infer others' mental states (e.g., intentions) from their gaze ( ). Taking this dissociation into account, the AQ-dependent amygdala activation found in the current study seems likely to reflect the amygdala's role in attaching social or affective salience to perceived gaze direction, rather than gaze direction encoding per se. The amygdala correlation with AQ is also consistent with Baron-Cohen's proposal that amygdala dysfunction could be one of the potential precursors to ASD ( ). 

Previous research has shown that circuits involved in visual attention are also engaged by viewing changes in gaze direction. The IPS forms part of the dorsal attention system which is thought to underlie attentional target selection ( ).   proposed that the IPS could also subserve attention orienting from seen gaze direction. In line with this proposal, single-unit recordings in macaques ( ) have indeed established that some neurons in the lateral intraparietal area (LIP; the lateral wall of the monkey IPS) increase their firing rate, while others reduce their firing rate, when the monkey views an image of a conspecific gazing towards the cell's response field. Similar effects are also observed when the monkey overtly looks at the corresponding locations, suggesting this regions' involvement in mirroring others' gaze. A number of behavioural studies in humans have found that viewing averted gaze triggers an involuntary shift of covert or overt attention towards the gazed-at location (for a review see  ). Although attention orienting was not measured behaviourally in our study, it is plausible that the AQ-dependent response in the IPS reflects the relationship between AQ and the tendency to imitate others' gaze behaviour ( ). In addition to the IPS, AQ-dependent activation of the IPL and SMG was also observed. The role of these regions in governing goal-directed shifts of attention is well established ( ), and a recent meta-analysis of fMRI studies on autism ( ) showed that individuals with ASD show reduced IPL and SMG activations in non-social attentional tasks. 

Finally, it must be noted that although there was a considerable overlap between the social attention network ( ) and AQ-modulated BOLD responses to gaze in the present study ( ), some of the activation foci clearly fall outside the social attention network. It is therefore possible that AQ also influences certain ‘gaze-independent’ neural mechanisms. However, this seems unlikely, given that AQ was not correlated with responses to variable versus constant heads and eyes-only conditions. Perhaps a more likely explanation is that AQ modulated responses in brain regions that are not part of the ‘core’ network for social attention perception, but are nevertheless recruited during certain gaze perception tasks such as the one used in the present study. 



## Conclusions 
  
We have shown that individual differences in autism spectrum traits in typical individuals are correlated with brain responses to observed shifts in gaze direction in key components of the brain circuit for eye gaze perception ( ), as well as those involved in inferring others' mental states ( ). Dysfunction in these same regions is also systematically observed in individuals with ASD. Our results therefore provide support for the existence of a broader autistic spectrum that extends into the typical population ( ). The data also demonstrate that neural processing of eye gaze is not fully homogenous across typical participants, as individual differences in social-cognitive processing styles indexed by AQ have a profound influence on the neural processing of eye gaze. Thus, in addition to furthering our understanding of the neurobiological basis of the extended autism phenotype, our results demonstrate that studies of eye gaze perception in typical individuals should take into account that a significant proportion of between-subject variance has a meaningful psychological basis. The identification of a cortical network influenced by AQ may be important in furthering our understanding of the neurobiological basis of deficits in the processing of social cues. Future studies on the development and functional connectivity of this network across the entire autism spectrum range could contribute to our understanding of neural markers of the development of ASD. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-21'>
<h2>21. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/28855682/' target='_blank'>28855682</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> How spontaneous brain activity and narcissistic features shape social interaction</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Sci Rep</p>
<p><strong>Publication Year:</strong> 2017</p>
<p><strong>DOI:</strong> 10.1038/s41598-017-10389-9</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5577167/' target='_blank'>5577167</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study reports task-based fMRI of a social-related paradigm (anticipation of touching an animate human vs an inanimate mannequin), involving social processing (perception/understanding of others). Participants are healthy adults (n=32, ages 21–33; task fMRI completed by 21), so healthy group results are reported separately. Crucially, the authors present whole-brain, voxelwise analyses (paired-sample t-tests, FDR-corrected maps) and whole-brain covariate analyses with narcissism scores; ROI analyses are supplemental. No exclusion criteria apply (not ROI-only; not clinical-only). Therefore it meets all inclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
There is an increasing interest in how ongoing spontaneous brain activity and personality provide a predisposition for the processing of environmental demands. It further has been suggested that the brain has an inherent sensitivity to the social environment. Here we tested in healthy volunteers if spontaneous brain activity contributes to a predisposition for social behavior and how this is modulated by narcissistic personality features associated with poor interpersonal functioning. Functional magnetic resonance imaging included a resting state and an experimental paradigm focusing on the anticipation of actively touching an animate (human hand) versus an inanimate target (mannequin hand). The experimental task induced a significant modulation of neural activity in left postcentral gyrus (PostCG), right culmen and, co-varying with narcissistic features, in right anterior insula (AI). Neural activity in anticipation of the animate target significantly correlated with spontaneous activity during the resting state indexed by the Power Law Exponent (PLE) in PostCG and AI. Finally, the correlation between spontaneous and task-induced activity in AI was mediated by narcissistic features. These findings provide novel evidence for a relationship between intrinsic brain activity and social behavior and show how personality could contribute to individual differences in our predisposition to approach the animate world. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (36737 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Since the early infancy we act in a social environment where we need to distinguish between the animate and the inanimate . This suggests an inherent sensitivity of our brain to the social environment . Conspecifics are intentionally approached as being similar to our selves, with similar inner experiences . Correspondingly, social interactions induce neural activity in sensorimotor and affective circuits which allows us to predict and understand others’ sensory experiences . 

Moreover, our personality is shaped by early interactions with the animate world . The narcissistic personality trait reflects a predisposition for individual differences in social functioning being specifically associated with an inflated sense of self/self-centeredness and dysfunctional interpersonal functioning . On a psychological level, individuals with pathological narcissism may be capable of social processing, but are disengaged from it . 

However, neither the exact neural mechanisms of the brain’s predisposition for intersubjectivity nor the role of differences in personality features such as narcissism are clear, yet. 

Stimulus-induced neural activity has recently been traced to the brain intrinsic or spontaneous activity . Raichle  proposed that the brain maintains an intrinsic state of preparedness for anticipating or predisposing the demands placed continuously over time. Indeed, it has been shown that spontaneous activity modulates variability in task-induced activity in sensory cortices . 

The brain’s spontaneous activity as measured in the resting state (when a participant is awake but not involved in a specific task) shows a complex temporal structure characterized by long-range temporal correlations (LRTCs) . LRTCs are related to a higher time-lagged autocorrelation indicating that the past pattern of a system has a stronger influence on its future dynamics . Concerning functional magnetic resonance imaging (fMRI), previous studies showed that the power law exponent (PLE) can provide a robust and reliable measure of LRTC’s . Higher LRTC’s are indexed by a higher PLE, and imply stronger low-frequency Blood Oxygen Level Dependent (BOLD) signal fluctuations and higher glucose metabolism in the brain . 

Initial functional brain states defined in terms of LRTC’s could influence the processing of upcoming stimuli in the environment. Indeed, recent studies demonstrated that the degree of the spontaneous activity’s LRTCs predisposes the neural processing of motor  and sensory (i.e., auditory and visual)  stimuli. 

Departing from this background, the present study aims at 1) testing whether task-induced activity during social interaction can be predicted by the spontaneous activity of the brain; 2) to investigate how narcissistic individual differences could mediate the relationship between spontaneous and task induced activity. 

In addition to resting state functional magnetic resonance imaging (fMRI), we applied a social interaction fMRI task requiring participants to actively touch an animate (another individual) or inanimate target (a mannequin). Touch plays an incipient role in intersubjectivity , being involved in social interactions already during the earliest stages of life . Furthermore, somatosensory (e.g. postcentral gyrus, inferior parietal gyrus) and affective (e.g. anterior insula, cingulate and orbitofrontal cortices) circuits are involved both in our own experience of touch and in the perception of others being touched . 

The experimental paradigm focused specifically on the anticipation of animate versus inanimate touch, anticipation referring to the time window preceding the action while already neurally encoding the action including its target . Thus, anticipation reflects a transition phase from a resting state to actual social interaction characterized by the emergence of internally generated behavior without realizing any overt action. 

For data analyses, firstly, regions of interest (ROIs) were defined based on the fMRI task (anticipation of animate versus inanimate touch). Secondly, the resting state PLE was calculated for these ROIs and its association with task-induced brain activity was tested. Thirdly, it was investigated if spontaneous and task-induced activity showed neural overlap in their correlation with narcissism. Fourthly, it was tested if the relationship between spontaneous and task-induced activity was modulated by narcissism. 

We hypothesized that task induced activity in sensorimotor and affective brain regions in anticipation of touching the animate target, but not the inanimate target, co-varied with spontaneous activity in terms of LRTC’s during a preceding resting state period, whereas narcissistic features could modulate this relationship. 


## Methods 
  
### Participants 
  
Thirty-two right-handed male participants (age 21–33; Mean = 25.4; standard deviation = 2.82) were recruited in this study. All participants had normal or corrected-to-normal vision capabilities. None of the participants reported a history of neurological or psychiatric disease, or substance abuse. Written informed consent was obtained from all participants after full explanation of the study procedure, in line with the Declaration of Helsinki. Ethics Committee for Biomedical Research of the provinces of Chieti and Pescara approved the experimental protocol. Participants were paid. 


### Data acquisition 
  
fMRI data were acquired by a Philips Achieva MRI scanner at 3 T (See Supplementary Information for more details). All 32 subjects completed the resting state fMRI acquisition. Twenty one out of the 32 participants (age 21–30; Mean = 24.9; standard deviation = 2.45) also completed task fMRI acquisition. In addition to fMRI scanning, all 32 participants completed the Pathological Narcissism Inventory, a 52-item multidimensional self-report measure which was designed specifically to assess both grandiose (NG) and vulnerable (NV) narcissism in the healthy and pathological population . fMRI scanning details and additional information about the PNI can be found in the Supplementary Information. 


### Experimental Procedure and Materials 
  
#### Resting state-fMRI 
  
During the two resting state-fMRI runs (6 minutes each), participants were instructed to watch a white fixation cross presented on a black screen, think of nothing in particular and keep their eyes open (they were monitored through a video camera placed in the MRI room). 


#### Task-fMRI 
  
The experimental task is based on that used in previous research  and is described in detail in the Supplementary Information. Briefly, during the task fMRI runs (8 runs of 7.8 minutes each), the participant completed a series of touch and no-touch trials. Trial order was randomized. Each trial, either touch or no-touch, started with a visual cue (1000 ms) consisting of a black and white line drawing followed by an attendance signal (red cross for 3000 ms). The drawing indicated the target of the touch (what had to be touched by the participant), that is, an animate (the hand of another volunteer who was standing next to the scanner) or an inanimate target (a mannequin hand). In the no-touch trials (60%), the red cross became black indicating to do noting and wait for the next trial. In the touch trials (40%), the cross became green for 6000 ms and the touch needed to be performed with a brush covert with either velvet (inducing a pleasant sensation when brushing on someone’s skin) or sandpaper (inducing an unpleasant sensation when brushing on someone’s skin). 

Since it was not predictable for the participant whether he actually had to perform the touch after the attendance signal, he was forced to be prepared to touch either the animate or the inanimate target after every visual cue. Therefore, the no touch trials allowed to study the anticipation of touching the animate or the inanimate target without the presence of any overt movements of the participant. 

Thus, two main conditions could be distinguished: the anticipation of touching an animate target (48 trials) and the anticipation of touching an inanimate target (48 trials). 

This task essentially differs from the previous studies for various aspects: 1) by adding the affective component through the valence of the touch (pleasant and unpleasant) the intrinsic link between emotion, self-related processing and social interaction was more specifically considered; 2) a slow event-related fMRI design was used (ITIs = 14000/16000/18000 ms) instead of fast event-related fMRI design; 3) the task was preceded by resting state runs (two independent 6 min-task free fMRI scans acquired before any task) to study the relation between rest and task conditions. 


#### Task fMRI analysis 
  
Pre-processing procedures of the fMRI data were implemented in Analysis of Functional NeuroImages software  and are described in the Supplementary Information. 

The contrast of principal interest concerned the anticipation of touch an animate target versus the anticipation of touch an inanimate target (is there a difference in the anticipation of touching a human animate hand in contrast to an inanimate mannequin hand?). A whole brain voxelwise paired-sample t-test was performed according to a random effect model to compare neural activity related to the anticipation of touching the animate target and to the anticipation of touching the inanimate target. 

Additionally, to test whether individual differences in the neural activity during the task were related to narcissism, whole brain analyses were performed comparing the neural activity during the anticipation of touching the animate target or the inanimate target with baseline, while using the PNI subscales of NG and NV as covariates. 

Statistical thresholds for all group statistical maps were set at q < 0.05 after False Discovery Rate (FDR) correction to search for modulations of brain activity by the different targets. The coordinates of the voxel clusters showing statistically significant effects were compared with the Talairach atlas available in AFNI software to label them in terms of anatomically defined regions and Brodmann’s areas (BA). 

To explore whether there were statistically significant modulations of BOLD response for the performance of an animate target and an inanimate target touch (touch trials) in the regions of interest (ROIs) modulated by the anticipation of touch, we performed a ROI based analysis. Avoiding circularity in the analysis, individual beta values were extracted from the voxel clusters (ROIs) showing a significant effect regarding the above described whole brain analysis for the anticipation of touch, that is, the no-touch trials. Beta values for each of these independent ROIs were then calculated from the average signal time course of the voxels included in each ROI concerning the performance of touch, that is, the touch trials. A paired-sample t-test was performed on the beta values regarding performance of an animate target touch and an inanimate target touch to establish if there also was a significant difference in neuronal response during touch performance regarding the ROI’s previously associated with the anticipation of touch. 



### Resting-State fMRI Analysis: Power Law Exponent (PLE) 
  
Power Law Exponent (PLE) analysis, as a measure of the temporal structure of low-frequency fluctuations , was performed on the resting state fMRI runs . PLE is considered suitable for the measure of scale free dynamics of fMRI data . Comparing different methods for computing fMRI time series complexity, Rubin and colleagues  demonstrated power spectrum based methods such as PLE being among the most robust measures. 

Scale-free dynamics are mathematically characterized by a power spectrum following the formula P ∝ 1/f , where P is power, f is frequency, and β is called the “power-law exponent” . After pre-processing, the time course per voxel was normalized to zero mean and unit variance (z-value) . Using methods previously optimized for fMRI , the normalized power spectrum of the fMRI signal was computed for each voxel using AFNI program: 3dPeriodogram. Similar to Welch’s method, the power spectra of the two resting state runs were averaged to reduce noise caused by imperfect and finite data, in exchange for reducing the frequency resolution. The power spectrum of the BOLD signal was further smoothed with a Hamming window (HM) of 7 neighboring frequency bins (HM = 7) . The averaged power spectra across voxels within the a priori ROIs (left PostCG, right culmen and right AI established before on whole brain analysis comparing different targets during the anticipation of touch) were extracted for each participant. The power spectrum was fitted with a power-law function P ∝ 1/f  using a least-square estimation (in a log frequency by log power plot) in the frequency range of 0.01~0.1 Hz . Finally, the power-law exponent, β, of each participant’s ROI was defined as the slope of the linear regression of log-power on log-frequency. 

In addition, we performed three different control analysis:   
To test the goodness of fit for scale invariance in the fMRI signal from particular region of interests we adapted a goodness of fit test developed for testing power-law distributions  and used by other authors in fMRI studies . For each ROI, its time series were extracted for each subject and subjected to PLE analysis for the resting state runs. 1000 time series of fractional Gaussian noise (fGn) with the same length and standard deviation as the original ROI time series were generated. Fractional Gaussian noise is a parsimonious model of stationary scale-free dynamics . Each synthetic fGn time series was subjected to the same PLE analysis as the original resting state data. The p value is defined as the fraction of synthetic time series with standard deviations of residuals from best fit that is larger than the original standard deviations of residuals from best fit of the fMRI time series. The larger the p value, the more plausible the fGn model is for representing the original fMRI time series, and the better the fit of the original data to a scale-free distribution. The hypothesis that the fMRI signal is scale free is plausible if the resulting p‐value is greater than 0.1, otherwise it is ruled out . 
  
To confirm the robustness of our frequency domain analysis (PLE) we also independently calculated the Hurst exponent in the time domain with detrended fluctuation analysis (H-DFA)  as a control index and calculated their correlation. 

Specifically, DFA measures the scaling of the root-mean-square fluctuation of the integrated and linearly detrended signals, F(T), as a function of time window size, T. The fluctuation F(T) is of the form F(T) = T , where H is the scaling exponent. 
  
Finally, we applied different Hamming Windows (HM = 3, 5, 9, 15) on the PLE calculation to test if the correlation between resting state activity (PLE) and task induced activity could be affected by different smoothing parameters. 
  


### Relationship between resting-state activity and task induced activity 
  
To establish if there was an association between resting state activity (PLE) and task induced activity in the ROIs, we performed Spearman correlation analyses (participant-based) with a 95% confidence interval (CI) based on 1000 bootstrap samples between resting state activity (Beta values) and task-activity (Beta values) for either anticipation of animate target or inanimate target. Bonferroni correction for multiple comparisons was performed on the obtained correlation coefficients, such that only   p   values (before correction) were considered significant below p < 0.05/number of calculated correlations. 

In addition to bootstrapping, the correlation was also controlled for all leave-one-out cohorts (N analyses with N-1 participants where each participant is excluded at a time). 


### Conjunction analysis: resting state activity and task induced activity with narcissistic features as covariates 
  
It was tested if the relationship between spontaneous activity and task-induced activity is modulated by PNI scores. Firstly, a whole-brain, voxel-wise conjunction analysis was performed to establish whether there was an overlap between brain regions in which task-induced and spontaneous activity both co-varied with narcissistic features. A random effect analysis of the overlap between the two contrasts was based on the minimum statistic compared with the conjunction null . This method controls the false positive error for conjunction inference and tests for common activations by creating the intersection of statistical maps thresholded at a specific alpha rate. 

Subsequently, a ROI-based partial correlation analysis was performed using the voxel clusters in which both task-induced activity and PLE correlated with NG or NV as obtained by the conjunction analysis. Specifically, the pair-wise relationships between PNI scores, and task-induced activity (beta scores of task-induced activity during the anticipation of animate touch) and spontaneous activity (beta scores of resting state PLE) in the ROIs were analyzed, while controlling for the third variable. 



## Results 
  
### Task fMRI data analysis: anticipation of animate target versus anticipation of inanimate target 
  
A whole brain voxel-wise paired-sample t-test between anticipation of the animate target and the inanimate target (“no touch trials”) elicited a significant effect in left postcentral gyrus (PostCG) and right culmen (t = 3.965; p = 0.0005; FDR corrected q = 0.05) (Fig.  , Table  ).   
Task-induced activity: (  a  ) Group statistical maps of whole brain voxelwise t-test between anticipation of animate target vs. anticipation of inanimate target (t = 3.965; FDR corrected, q = 0.05). (  b  ) Graphs of Beta values and Standard Errors extracted from activation clusters depicted in (  a  ). 
    
Brain regions showing a modulation of BOLD response by different experimental conditions and statistical information for the direct contrast between the anticipation of the animate target versus the anticipation of the inanimate target (FDR corrected), for the direct contrast between the anticipation of the animate target versus baseline (FDR corrected) and for the conjunction whole brain analysis between anticipation of animate target vs. baseline with covariate PNI-NG ∩ Resting state PLE vs. baseline with covariate PNI-NG. 
  
LH = left hemisphere; RH = right hemisphere. C-Mass Coordinates refer to Talairach space. PNI = Pathological Narcissistic Inventory; NG = Narcissistic Grandiosity. 
  

A single subject analysis for the anticipation of animate vs. inanimate target in four randomly selected single participants elicited a significant effect in left PostCG (Supplementary Figure  ). 

Examining the graphs, specifically for the anticipation of touching an animate target, we observed no appreciable modulation of BOLD response, compared to baseline, in the left PostCG, whereas a suppression of BOLD response (deactivation) was detected in the right culmen. By contrast, for the anticipation of touching the inanimate target we observed an increased activation, compared to baseline, in the left PostCG, but no appreciable modulation of activity, compared to baseline in the right culmen. 

An exploratory ROI-based analysis yielded the opposite pattern during touch performance (Fig.  ). Specifically, we found a significant difference between the two conditions (touch of an animate target and touch of an inanimate target) both in the left PostCG (p = 0.001) and for the right culmen (p = 0.001). In detail, we observed a greater activation in left PostCG as well as in right culmen during the active touch of the animate target compared to the inanimate target.   
Task-induced activity: ROI based analysis on touch performance in activation clusters obtained by the whole brain voxelwise t-test on the “no touch trials” (touch anticipation; Fig.  ). Bars represent the mean beta value across subject and Standard Error. * indicates p < 0.001. 
  

Regarding the co-variance with PNI scores, voxel-wise, whole brain one-sample t-tests on the anticipation of touching the animate target (versus baseline) with NG and NV as covariates elicited a significant effect of NG on BOLD responses in the right anterior insula (AI) (t = 3.828; p = 0.0005; FDR corrected q = 0.05) (Fig.  ), while no significant modulation was reported for NV.   
Task-induced activity: Group statistical maps of a whole brain voxelwise t-test between anticipation of animate target vs. baseline with PNI-narcissistic grandiosity (NG) as covariate (t = 3.965; FDR corrected, q = 0.05). 
  

Confirming that the relationship between task-induced activity and PNI scores was specific for the animate target, the same analysis on the anticipation of touching the inanimate target (versus baseline) with NG and NV as covariates yielded no significant effects (t = 3.621; p = 0.001; uncorrected). 


### Correlation between PLE and task induced activity 
  
The PLE values across participants (n = 32) in the left PostCG (mean = 0.44; SD = 0.27), in right culmen (mean = 0.37; SD = 0.23) and in right AI (mean = 0.43; SD = 0.19) are in accordance with previous studies . 

Correlations between resting state PLE and task induced activity were calculated, that is, for task-induced activity in anticipation of the animate and the inanimate touch, in left PostCG, right culmen and right AI (Fig.  ).   
Scatter plots showing predictive power (Spearman correlation) of PLE during the resting state for individual task induced activity in PostCG, culmen and AI ROIs during the anticipation of touching the animate and the inanimate target.   p   values reported in the figure are Bonferroni corrected. 
  

A negative and significant correlation between resting state PLE and task induced activity during the anticipation of touch the animate target was observed in left PostCG (r = −0.684, p = 0.006 Bonferroni corrected; 95% CI Lower: −0.874 Upper: −0.332; S.E. = 0.141) and in right AI (r = −0.592, p = 0.03 Bonferroni corrected; 95% CI Lower: −0.822 Upper: −0.217; S.E. = 0.154), but not in right culmen (r = −0.142, p = 0.540 – p = 0.54, uncorrected; 95% CI Lower: −0.600 Upper: 0.283; S.E. = 0.231). 

The correlation between PLE and task induced activity was also controlled for all leave-one-out cohorts (N analyses with N-1 participants where each participant is excluded at a time) and this procedure didn’t affect significance of the correlation coefficients for PostCG (min: r = −0.699 p = 0.001; max: r = −0.550, p = 0.012) and for AI (min: r = −0.668 p = 0.001; max: r = −0.543, p = 0.013). 

No significant correlation between resting state PLE and task induced activity during the anticipation of touch the inanimate target was observed in left PostCG (r = −0.342, p = 0.130 95% CI Lower: −0.686 Upper: 0.152; S.E. = 0.211), right culmen (r = 0.175, p = 0.447; 95% CI Lower: −0.339 Upper: 0.641; S.E. = 0.244) and right AI (r = −0.514, p = 0.017; 95% CI Lower: −0.867 Upper: 0.019; S.E. = 0.236). 

Hotelling-Williams test  was performed to test the equality of two correlation coefficients obtained from the same sample, with the two correlations sharing one variable in common. The test resulted significant for PostCG (z = 2.736; p = 0.006) indicating that the correlation between beta of animate touch anticipation and resting state PLE was significantly stronger than the correlation between beta of inanimate touch anticipation and resting state PLE. The difference was not significant for AI (z = −0.421; p = 0.673) and culmen (z = −1.112; p = 0.266). 


### PLE control analyses 
  
(1) Simulating 1000 time series with a stochastic Gaussian process of known long-range temporal dependence, we first showed that the fMRI signal is scale-free by analyzing the goodness of fit indices (left PostCG p = 0.25; right AI p = 0.22; right culmen p = 0.23). Thus, PLE is a suitable measure to quantify the scaling exponent of the fMRI signal. 

(2) To further validate the PLE that based on the frequency-domain approach, we applied a time-domain method (DFA) to test for their correlation. As expected, we observed a strong correlation between the two measurements in all the ROIs (for left PostCG, r = 0.722, p = 0.00001; for right culmen, r = 0.804, p = 0.00001; for right AI, r = 0.762, p = 0.00001). 

(3) To test the robustness of our results, we applied different smoothing parameters to determine the PLE values, more specifically by varying Hamming window size (HW = 3, 5, 9 and 15). These analyses showed that the correlation of PLE and task induced activity in Post CG and AI for the anticipation of the animate target was not affected by different HMs (Table  ).   
Statistics of the correlation between the Resting state PLE and task induced activity (Beta) in Left Postcentral gyrus, Right Culmen and Right Insula for the Anticipation of the Animate target and Inanimate target. 
  
HM = Hamming window size; LH = Left Hemisphere; RH = Right Hemisphere. *p < 0.008 after Bonferroni correction for multiple comparisons. 
  


### Conjunction analysis and partial correlations between Narcissistic Grandiosity, Resting State PLE and task induced activity for the anticipation of the animate target 
  
Conjunction analysis showed that right AI activity co-varies with NG both during a resting state (spontaneous activity indexed by PLE) and during task-induced activity (BOLD responses to the anticipation of the animate target) (Fig.  ; t = 7.820; p = 0.00000001). The same analysis using NV as covariates yielded no significant effects (t = 2.750; p = 0.01; uncorrected).   
Conjunction contrast between the anticipation of the animate target vs. baseline with covariate Narcissistic Grandiosity and resting state vs. baseline with covariate Narcissistic Grandiosity. 
  

Since spontaneous activity, task-induced activity and NG score all co-varied in AI, partial correlation coefficients were calculated to provide more insight in their interrelationship. 

Partial correlation yielded a significant positive association between PLE and NG, while controlling for task-induced activity (r = 0.475; p = 0.03; 95% CI Lower: 065 Upper: 0.813; S.E. = 0.189), a significant negative association between NG and task induced activity, while controlling for PLE (r = −0.593; p = 0.006; 95% CI Lower: −0.839 Upper: −0.077; S.E. = 0.203), but no significant association between PLE and task induced activity, while controlling for NG (r = −0.129; p = 0.588; 95% CI Lower: −0.563 Upper: 0.423; S.E. = 0.260) (see Fig.  ).   
Partial correlations model showing the statistic of each correlation controlling for the effect of the third variable in the model. 
  



## Discussion 
  
In the present study, we aimed to investigate whether task activity induced by the anticipation of social behavior (touching an animate target) could be related to the spontaneous activity of the brain during a preceding resting state period, and if this relationship may be mediated by narcissistic traits, particularly NG and NV. 

The main results showed that task-induced activity during the anticipation of the animate target (but not of the inanimate target) in left PostCG and right AI negatively correlated with the degree of LRTCs during a preceding resting state: the stronger the PLE in spontaneous activity in left PostCG and AI, the weaker the BOLD response in the same regions for the anticipation of the animate target (see Fig.  ). Interestingly, neural activity in right AI consistently correlated with NG, both during the resting state (PLE) and during task performance (BOLD responses in anticipation of the animate target). Additionally, NG was found to modulate the relationship between spontaneous and task induced activity in the right AI. These data provide, to our knowledge for the first time, evidence for a relationship between intrinsic brain activity and the anticipation of social interaction as well as for how this relationship could be influenced by personality features.   
Proposed model of the study visualizing the relationship between intrinsic activity brain activity, task induced activity and the modulation by narcissistic traits. In this model the anticipation is considered as a transitional phase between internal and external where the individual is aware of the external stimuli and is generating internally the behavior without realizing any overt action. 
  

With respect to the rest-task relationship, the detected negative relationship between resting state and task-induced activity is consistent with previous studies showing that the temporal structure of intrinsic brain activity during a resting state can provide a predisposition that shapes our interactions with the world . 

Our finding that individuals with stronger LRTC’s in PostCG and AI during a resting state show weaker task-evoked BOLD responses in the same regions during the anticipation of animate interaction, suggests that an individual’s spontaneous brain state defined in terms of LRTC’s might predispose the preparedness for social stimuli in these brain regions. 

The result that only the activity induced by the anticipation of the animate target touch, but not of the inanimate target touch, correlates significantly with the temporal structure of the endogenous brain activity in PostCG and in AI is in line with the idea that other individuals are approached as entities with similar inner experiences as our self . Indeed, PostCG and AI have been associated with the perception of one’s own as well as others’ sensations and feelings . Moreover, behavioral results based on “similarity” and “spontaneous social awareness” ratings of touch performance (see Supplementary Figure  ) showed that there is a significant difference in approaching the other (i.e. the animate target) as an entity with similar characteristics of our self, compared to the mannequin. 

Hence, the detected relationship between the spontaneous activity and task-induced activity in PostCG and AI supports the hypothesis that others’ bodily experiences might be already internally formulated, as something related to one’s own experiences and that sensory and affective circuits contain a memory trace of it . This seems to be in line with the finding that bodily arousal, linked to psychophysiological states, is associated with spontaneous brain activity during the resting state . 

Regarding the relationship between the anticipation and the performance of animate and inanimate touch, PostCG and culmen differentiated between the anticipation of animate and inanimate touch. These regions overlap with those consistently reported in research on sensory anticipation and action prediction . According to research on sensorimotor prediction, such sensory activity anticipating the consequences of an action, like touching, may attenuate activity induced by sensory stimuli . 

Considering this literature, we suggest that a similar predictive mechanism supported by internal simulation may apply to the anticipation of others’ sensations induced by one’s actions . In agreement with this, anticipatory activity in PostCG and culmen showed weaker responses for animate touch anticipation, compared to inanimate touch anticipation, whereas an exploratory ROI-based analysis of BOLD responses during actual touch performance showed the opposite pattern of activity in these regions: increased activity during animate touch performance, compared to the inanimate touch performance. Accordingly, also Gazzola and colleagues  showed increased activity in SI during (passively perceived) affective social touch. Moreover, it is interesting to note that somatosensory activity in SI also supports subjective self-perception induced by tactile stimuli . 

Finally, concerning individual levels of narcissism, our data showed that activation specifically for the anticipation of the animate target negatively co-varies with NG in right AI. As evidenced by a conjunction analysis, also spontaneous activity correlated with NG in the same voxels in AI. Partial correlations were performed concerning the relationships between task-induced and spontaneous activity in this AI cluster, and NG. These correlations indicated that the relationship between neural activity in anticipation of the animate target and spontaneous activity during a resting state in AI is no longer significant when controlling for NG, while task-induced activity during the anticipation of the animate target and spontaneous activity during a resting state in AI independently correlate with NG. 

On the one hand, the positive correlation between NG and LRTC’s in AI during the resting state period may be interpreted as an increased preoccupation for the self, more specifically the bodily and interoceptive self  during a rest/mind-wandering period . For instance, recent imaging studies showed recruitment of the right anterior insula during tasks focusing on the self  . On the other hand, the negative correlation between NG and task activity elicited by the animate target in AI may be interpreted as a consequent reduced activity regarding other individuals. This hypothesis is also supported by the proposed role of AI as part of the salience network  in constituting a crossroad switch between the internal and the external activity of the brain . Fan and colleagues  specifically showed a decreased deactivation of AI during processing of emotional faces in individual high on narcissistic trait. The authors interpreted their data as indicative of an increased of self-focus and disengagement from empathic processing in narcissistic individuals. The present results extend these findings by showing that higher NG may be related to an increased internal predisposition accompanied by a motivation-based disengagement from social processing . 

Thus, these results provide further insight into how personality features may influence brain activity anticipating social interaction. We propose that narcissism could function as a factor mediating between internal processing, related to the self, and external sensory information related to the social world. 

Some limitations of the study have to be mentioned. Firstly, we studied the relationship between resting state fMRI and task-induced BOLD responses . It can be argued that this approach is correlational and not directly addresses rest-task interactions . However, because we were interested in how individual spontaneous brain activity patterns could constitute an a priori predisposition for social behavior, intrinsic activity during an independent resting state could be indicated as a more appropriate measure than pre-stimulus activity or background intrinsic activity during task-performance in this context. Nevertheless, further studies have to address direct rest-task interaction integrating these alternative measures that are highly informative for deepening the interaction between endogenous activity and task-induced responses. 

Secondly, it can be argued that AI is not a region primarily involved in the discrimination between the animate and the inanimate target. However, AI could be specifically related to grandiose (but not vulnerable) narcissistic features during both the resting state and the anticipation of the animate target. Since NG is characterized by self-serving focus and a motivational based disengagement, it could be speculated that this relation expresses a more general disengagement from the external world in high NG participants. Although this might be not primarily related to the qualification of the target, it possibly is more pronounced for social processing . Further studies would be necessary to clarify this issue more directly. 

Thirdly, our sample was not constituted by clinical individuals and further research has to expand this study to clinical samples of pathological narcissism. However, our data lend support to the concept of narcissism as a continuum between healthy and pathological forms reflecting adaptive and maladaptive personality organization, respectively . 

In conclusion, our research sheds a novel light on how social task activity can be related to the spontaneous activity of the brain and how this interaction may be modulated by individual personality differences. Future research will need to expand this study to modalities of social interaction other than touch, and to other relevant aspects of personality which may modulate our way to relate with our self and with other individuals. 


## Electronic supplementary material 
  




 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-22'>
<h2>22. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/25461818/' target='_blank'>25461818</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Identifying Autism from Neural Representations of Social Interactions: Neurocognitive Markers of Autism</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2014</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0113879</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4251975/' target='_blank'>4251975</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study includes an fMRI task explicitly probing social-related processing (thinking about interpersonal social interactions; measures of self-related social cognition). It reports data from a healthy control group of adults (17 age- and IQ-matched controls; young adults within 17–65) alongside an autism group, with results for controls presented separately. Analyses are not limited to ROIs: whole-brain approaches were used (SPM GLM contrasts across the brain are reported) alongside multivariate/factor-analytic and classification methods that used whole-brain voxel sets. Thus all inclusion criteria are met (social task, healthy adult participants, whole-brain analyses). No exclusion criteria apply.</p>
<p><strong>Fulltext Confidence:</strong> 0.93</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Autism is a psychiatric/neurological condition in which alterations in social interaction (among other symptoms) are diagnosed by behavioral psychiatric methods. The main goal of this study was to determine how the neural representations and meanings of social concepts (such as   to insult  ) are altered in autism. A second goal was to determine whether these alterations can serve as neurocognitive markers of autism. The approach is based on previous advances in fMRI analysis methods that permit (a) the identification of a concept, such as the thought of a physical object, from its fMRI pattern, and (b) the ability to assess the semantic content of a concept from its fMRI pattern. These factor analysis and machine learning methods were applied to the fMRI activation patterns of 17 adults with high-functioning autism and matched controls, scanned while thinking about 16 social interactions. One prominent neural representation factor that emerged (manifested mainly in posterior midline regions) was related to   self  -representation, but this factor was present only for the control participants, and was near-absent in the autism group. Moreover, machine learning algorithms classified individuals as autistic or control with 97% accuracy from their fMRI neurocognitive markers. The findings suggest that psychiatric alterations of thought can begin to be biologically understood by assessing the form and content of the altered thought’s underlying brain activation patterns. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (54063 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Psychiatric disorders of thought are usually characterized and diagnosed on the basis of clinical assessment of an individual’s verbal and physical behavior. This is the conventional way to assess a thought disorder. However, recent advances in brain reading have made it possible to identify neurocognitive representations based on the underlying brain activation patterns assessed with fMRI  – . These innovations have advanced from merely associating an activation pattern with a particular thought to decomposing the activation pattern into its neural and psychological components. For example, the activation pattern corresponding to the thought of a banana consists of components representing how one holds a banana (indicated in several premotor areas) and how one eats a banana (represented in eating-related areas). Another example is that the thought of an emotion such as sadness can be identified in terms of the neural representation of its valence, degree of arousal, and sociality  . Thus it has become possible to assess the content of a thought in neurotypical populations. 

In our study, this approach was applied to characterize the   altered   neural representation of social concepts in autism, known to be disordered in terms of psychiatric diagnosis. If certain types of social concepts are altered in autism, it may be possible to (a) detect the alterations and possibly interpret them as diagnostic of autism; and (b) understand the biological and psychological nature of the alterations in terms of the underlying dimensions of neural representation; and (c) make use of the understanding to develop therapies that ameliorate the alteration. Furthermore, if the approach is successful with respect to autism, it may hold promise for application to other psychiatric disorders. 

One of the largest challenges in autism research is to determine the relation between the psychological alterations in autism (assessed in behavioral and psychiatric studies) and the neural alterations (assessed in neuroscience and particularly brain imaging studies). Because the social alterations are often the most prominent ones in autism, fMRI studies of autism have investigated the relation between brain and behavior with respect to several different types of social processing. One of the earliest-studied social functions investigated with fMRI was face perception, during which it was found that the fusiform face area (a brain region associated with the processing of faces) activated abnormally in autism  . A second type of social task in which altered activation was found in autism was in Theory of Mind processing in which participants must understand the mental state of another individual (and in which there is altered activation in autism in the medial frontal and temporoparietal junction regions)  . 

A third type of autism alteration involved in social processing (and arguably the most central one) concerns the altered conception of   self   (see Uddin   for a review). The altered conception of   self   in autism is at the focus of the current study. Since its first description by Kanner  , autism has always been prominently associated with a disruption of the social relation between   self   and others. In fact, the word   autism   stems from the Greek   autos   meaning   self.   Although   self   representation may have several types of components, such as visual self-recognition and perspective, the facet of   self   that seems most altered in autism is the relating of oneself socially to others. Individuals with autism exhibit atypical social behavior, manifested as disproportionate self-focus in social interaction with others. Hence the current study investigated a number of social (dyadic) interactions, using a neurosemantic paradigm in which participants are asked to think about a concept such as   to insult,   while their brain activation was assessed with fMRI. 

Several fMRI studies of autism that have involved   self  -related cognition have found disruption of the brain activation in midline cortical structures (ventromedial prefrontal, middle and posterior cingulate), as summarized in a recent review  . One example is that in participants with autism there is a failure to reduce the activity in midline structures during the performance of a cognitive task  , which has been attributed to a reduction of   self  -referential processing in the resting state in autism  . Another example of unusual   self  -related disruption in children with autism is the use of the pronoun   you   to refer to themselves, echoing the use of that pronoun by others to refer to the child, as first noted by Kanner  . This language behavior is ascribed to an errorful assessment of the relation between the   self   and another person. Consistent with Kanner’s observations, an fMRI study of pronoun processing in adult participants found diminished functional connectivity in autism between a frontal region (right anterior insula) and the precuneus (a posterior midline) region as well as altered activation levels in the precuneus  . Several other studies have found the precuneus to be involved in the representation of   self  ,  ,  ,  ,  . Taken together, these types of findings indicate disruption of   self  -related processing in autism associated with the precuneus and frontal regions. 

Findings of mean differences between autism and control groups in brain anatomy or brain activity have led more recently to classification studies in which participants are automatically (i.e. using an algorithmic statistical technique) classified as autistic or control based on such measures  ,  ,  ,  . Based on the structural grey matter anatomy measures, it was possible to classify the group membership with 85% accuracy  . With the voxel-based morphometry approach, the accuracy was 90%  . One study performed autism membership classification based on resting state connectivity data, producing an accuracy of 79% (and for the sub-group under 20 yrs, 91%)  , whereas another study obtained an accuracy of 96%  . There is apparently something distinctive about the brain structure and brain activation in autism. However, neither of these approaches relates a brain property to a specific type of concept or thought that is altered in autism. The current study examines whether such classification is possible based on the neural representations of interpersonal social interactions, which might be expected to be altered in autism. In effect, the study seeks specific neurocognitive disruptions directly related to thought alterations and not simply biological markers of the thought disorder. We asked whether it is possible to distinguish autism from control participants based on their neural activation patterns during their consideration of various social interactions, examining whether the   self   components of social representations are altered in autism. 

In addition to relating altered neural activation patterns to social concepts, the study attempted to determine what anatomical alterations in autism might be associated with the psychological alterations in the conception of   self  . One theory of autism relates the disorder’s behavioral and brain activation symptoms to altered frontal-posterior anatomical connectivity in the cortex, compromising the communication bandwidth between frontal and posterior areas  . The white matter tract that provides such connectivity between some of the main frontal and posterior midline regions involved in the representation of   self   is the cingulum bundle, whose structural properties can be measured noninvasively using magnetic resonance-based imaging of the diffusion of water molecules. An alteration in the representation of   self   could be due to the quality of this white matter tract. An a priori hypothesis was that the degree of alteration in the representation of   self   in individuals with autism would be related to the quality of their cingulum bundle. To examine this relation, diffusion images of this tract were obtained, in addition to the fMRI activation evoked by thoughts of various social interactions. 

Another hypothesis was that the degree of alteration in the representation of   self   in individuals with autism would be related to behavioral measures of various social abilities, such as face processing and Theory of Mind (c.f.  ). To test this hypothesis, appropriate neuropsychological measures were acquired for participants with autism. 

Autism is rightly considered to be a heterogeneous disorder, with suggestions made that it be referred to as “the autisms”  . There are anecdotal comments that every person with autism is autistic in their own way. Although autism is undoubtedly heterogeneous, a striking finding in brain reading studies of neurotypical people is the high degree of commonality (homogeneity) of neural representations of concepts across individuals. A classifier trained to identify the thoughts associated with physical objects like a banana from the neural activation patterns of a group of participants can then identify, with reasonable accuracy, the thoughts of a new participant whose data were not included in the training  . This activation commonality probably arises because of the commonalities in the structure, function, and experience of human brains as they process information related to physical objects. But how would a psychiatric or neurological disorder affect the commonality among the members of the affected population, particularly in a domain of thought that is altered in the disorder? Given the apparent heterogeneity of autism, should there thus be less commonality among people with autism than among people without autism when they are thinking about social concepts? That is, if autism entails altered conceptions of social interactions, are the alterations heterogeneous across people with autism or is there a commonality? New machine learning methods allow a comparison of the commonality within the autism and the control groups. 

The central issue remains whether it is possible to identify a participant as autistic, not just on the basis of a fortuitous statistical relation, but on the basis of some fundamental alteration of the brain activity that underpins particular types of thought that are among the defining characteristic of the disorder. 

Below we first apply factor analysis to reduce the dimensionality of the brain activation evoked by the various social interactions. Then we perform classification of the multivoxel patterns that correspond to particular social interactions in order to identify the interaction and to distinguish the neural patterns of the two groups. The advantages of the approach are that it 1. focuses on the representations of social interactions, which are likely to be altered in autism and which like other concepts, are neurally represented by multiple voxels in multiple regions, and 2. is capable of detecting group differences in the activation patterns of multiple voxels in multiple regions. 


## Materials and Methods 
  
The study acquired fMRI-measured brain activation patterns of 17 young adults diagnosed with high-functioning autism and 17 age and IQ-matched control participants as they thought about the referent of 8 social interaction verbs (  compliment, insult, adore, hate, hug, kick, encourage, humiliate  ), considered from two perspectives (either the agent of the action or the recipient), for a total of 16 social interaction items. There were 6 presentations of such 16-item blocks. 

### Ethics statement 
  
The study protocol was approved by the University of Pittsburgh and Carnegie Mellon University Institutional Review Boards. All participants gave their informed written consent. 


### Participants 
  
The participants’ demographic information is shown in  . The diagnosis of autism was established using the   Autism Diagnostic Observation Schedule   (ADOS;  ), the   Autism Diagnostic Interview-Revised   (ADI-R;  ) using DSM IV criteria and confirmed by expert clinical opinion. All participants were required to be in good medical health. Seven of the autism participants took medications on the day of the scan (six of these taking selective serotonin re-uptake inhibitors, three taking ADHD medications, two taking blood pressure medications, and three taking one of prostate enlargement, hypothyroidism, or allergy medication). Potential participants with autism were excluded if they had an identifiable cause for their autism such as fragile-X syndrome, tuberous sclerosis, or fetal cytomegalovirus infection or were found to have evidence of prematurity, birth asphyxia, head injury, or a seizure disorder. Exclusions were based on neurologic history and examination, physical examination, and chromosomal analysis or metabolic testing, if indicated. The control participants were community volunteers and were group-matched to the participants with autism on age, gender, race, and all three IQ scores, Verbal (VIQ), Performance (PIQ), and Full-scale (FSIQ) as determined by administration of the Wechsler Abbreviated Scales of Intelligence (WASI;  ). Potential control participants were screened by questionnaire, telephone, face-to-face interview, and observation during initial testing and were excluded if they had a current or past history of prematurity, psychiatric and neurologic disorders, birth injury, developmental delay, school problems, acquired brain injury, learning disabilities, or medical disorders with implications for the central nervous system. Exclusionary criteria also included a history in first degree relatives of autism, developmental cognitive disorder, affective disorder, anxiety disorder, schizophrenia, obsessive compulsive disorder, or other neurologic or psychiatric disorder thought to have a genetic component  .   One of the control participants took allergy and asthma medication and another participant took an antibiotic on the day of the scan. 
   Age, IQ, handedness, and gender of the participants.        
Handedness was determined with the Lateral Dominance Examination from the Halstead-Reitan Neuropsychological Test Battery  . Thirteen members of each group were right-handed; two of the autism and none of the control participants were female. 

Prior to in-scanner testing, each participant was familiarized with the task, and used an MRI simulator scanner to acclimate themselves with the scanner environment. The 34 included participants were tested in two epochs. In the first epoch, 9 participants with autism and 9 controls were scanned using a Siemens Allegra scanner, with 21 additional participants excluded from the analysis (as described below). Because the yield was low (18/39) in the first epoch largely due to excessive head motion, the pre-scanning training to reduce head motion was substantially enhanced in the second epoch. The yield for the second epoch (16/20) was greatly improved. In the second epoch, 8 autism and 8 control participants were scanned using a Siemens Verio scanner with 4 additional participants excluded (using the same criteria). 

The data from the 25 excluded participants (12 with autism and 13 controls) had been affected by either excessive (above 3.5 mm) head motion (6 with autism and 3 controls) or lack of attention to the stimulus in a substantial number of trials (6 with autism and 10 controls). Participants in such studies comment that occasionally their mind wanders when processing some items, and we have previously found such inattention to be characterized by an abnormal occipital activation time course. Consequently, participants in whom the abnormality (measured as a low correlation with a typical occipital activation time course) was frequent (occurring in more than 70% of the items) were excluded. (Calculations are shown in  ). 


### Image acquisition 
  
Functional images were acquired on a Siemens Allegra 3.0T or a Siemens Verio 3.0T MRI scanner (Siemens, Erlangen, Germany) using the same gradient echo EPI sequence with TR = 1000 ms, TE = 30 ms and a 60° flip angle. Seventeen 5-mm thick oblique-axial slices were imaged with a gap of 1 mm between slices. The acquisition matrix was 64×64 with 3.125×3.125×5 mm voxels. High angular resolution diffusion images (HARDI) were acquired using a diffusion-weighted, single-shot, spin-echo, EPI sequence (TR = 5300 ms) and processed using FSL tools and diffusion toolkit software  . (See   for details). 


### Stimuli and paradigm 
  
The stimulus set of eight verbs referring to interpersonal actions (  compliment, insult, adore, hate, hug, kick, encourage, humiliate  ) was presented one at a time, with instructions to think about the nature of the interaction from either the perspective of the agent (e.g., the participant insulting someone else) in a dyadic situation, or from the perspective of the recipient (e.g., being insulted by someone else), for a total of 16 different social interactions. Each block of 16 interactions (8 verbs × 2 perspectives) was presented 6 times. In each block, the two perspectives were presented separately and always in the same order for a given participant (and balanced across participants), while the 8 verbs within each perspective were presented in different random orders. There was a 10 s rest interval between blocks and also between perspectives within a block. The mean interval between the two consecutive presentations of the same verb was 66 s, and the maximum interval was 115 s. 

Each stimulus verb was presented on the screen for 3 s, followed by a 4 s rest period, during which the participants were instructed to fixate on an X displayed in the center of the screen. There were four additional presentations of a fixation condition X, 24 s each, distributed across the session to provide a baseline measure of activation. 

Participants were asked to think about the most salient properties of the interaction that the verbs described, for example, whether the action is intentional or not, the reaction it may evoke, and the context in which it occurs, to encourage consideration of multiple attributes of the dyadic social interaction. Participants were asked to think of the same attributes each time they saw a given verb. To encourage the consideration of a consistent set of attributes, prior to the scanning session participants were asked to write down the attributes of each verb in each mode/role. However, there was no attempt to induce consistency across participants. 


### Neuropsychological tests 
  
To assess the social processing abilities of the autism participants, the Benton Facial Recognition Test  , WMSIII Faces II  , and Reading the Mind in the Eyes   were administered. 


### fMRI processing 
  
The fMRI data were preprocessed with SPM2  . For each participant, functional images (about 15,000 voxels) linked to every instance of the 16 social interaction terms were computed and served as input data for the following analyses (see   for further details of fMRI data preprocessing). 


### Factor analyses 
  
To assess the neural representation of social interactions, a two-level, exploratory factor analysis (FA), as described in previous research  , was applied separately for each group. This dimension reduction approach aims to identify the relatively sparse set of cortical regions and voxels whose neural activity varies reliably across the set of stimulus items, while representing the relevant neural activity for each participant in a way that allows multiple participants’ data to be aligned and compared. The choice of parameter values in the procedure was determined by search and convergence in several previous studies. For example, the total number of voxels ultimately involved in the analysis, 135, is small, relative to the entire brain volume. However, our previous studies showed that increasing this number failed to substantially improve the classification accuracy and at some point the accuracy begins to decrease with additional voxels  . Several of the arbitrary-looking procedures below are the result of optimizations performed in several previous studies. 

The details of the factor analysis procedures (starting with the initial selection of 135 voxels per participant and ending with the uncovering of 4 major factors per group, together with the associated brain locations), are reported in the  . 

The FA procedure for a group of participants is illustrated in  . The 135 most stable voxels distributed across 5 brain areas were algorithmically selected for each participant. The first-level FA was performed separately for each participant, resulting in 7 first level factors (Fa-Fg,  ). (The number of first-level factors was fixed at 7, which was the modal number of factors for all participants based on the Kaiser criterion). These factors were characterized by their vector of scores for the 16 items and their associations with specific subsets of the initially selected 135 voxels. The goal of the first-level FA was to find the participant-specific distributed brain networks involved in the representation of social interactions. 
   Schematic diagram of the two-level exploratory factor analysis procedure.  
The first level factor analyses are performed separately for participants 1–13. In these analyses, the activation levels of 135 voxels (marked as red, green, and blue circles for the 3 participants) distributed throughout the brain are expressed via 7 factors (Fa-Fg), and some (but not all) of the voxels are linked to these factors. The second, group-level FA in turn expresses the 13×7 first-level factors in terms of 4 group factors (GF1–GF4). For each of these factors, the originating voxels are spatially clustered. A cluster of such voxels (characterized as a sphere) contains voxels that were initially selected from many (typically all) of the participants. The six largest spheres per factor were treated as the factor-associated brain locations. 
  
The second, group-level FA then attempted to find the components of these networks that were common across participants within each group. The group-level factors (GF1–GF4,  ) were also characterized by their vector of scores for the 16 items and their associations with specific subsets of the first-level factors, and, through these associations, to subsets of originally selected voxels. The spatially contiguous clusters of these voxels (factor-associated brain locations in  ) defined the brain locations of the neural representation components corresponding to the group factors. The number of factors in the group-level FA was limited to 4, beyond which they were not easily interpretable, and the locations were limited to the 6 largest clusters (characterized as spheres) per factor. 

The only outcome of the factor analysis that was used in the subsequent machine learning (described below) was the set of locations (centers and radii) of the factor-related spheres. The features (voxels) used in the classification came exclusively from these factor-based spheres (but were subject to additional criteria). 


### Machine learning analyses 
  
Gaussian Naïve Bayes (GNB) classifiers with factor-based features were used to classify participants’ group membership and separately, to identify the 16 social interactions (see   for the details of machine learning computations). 

#### 1. Group membership classification 
  
This classification was performed separately for each participant, training the classifier on the remaining participants, and deriving the features from the locations of the semantic factors that emerged from the factor analyses. Specifically, the features were derived from the union of the 3 semantic factor locations from the autism group’s analysis with the 3 semantic factor locations from the control group’s analysis. Thirty-six spherical volumes were created (from 2 groups, 3 factors, 6 spheres per factor; each sphere was defined by voxels with the highest loadings for the factor). Each sphere was characterized by the activation levels of its representative voxels across the 16 social interactions derived from the participants’ responses. The 16 activation levels of the 5 most stable voxels in a sphere were averaged and then converted to z-scores. (The stability of a voxel was defined as the similarity (correlation) of its pattern of activation responses to the set of 16 interactions across the 6 presentation blocks.) The same procedure was applied to all participants, including the test participant, resulting in a set of features consisting of 576 values (36 spheres x 16 stimulus items) for each participant. Only 115 of these features were used, namely those with the largest absolute value difference between the group means in the training set (any number of features between 80 and 290 resulted in the same classification accuracy of 0.97). The machine learning procedure trained the classifier on these data from 33 of the participants (each labeled as autistic or control), and then it attempted to classify the remaining participant. In each of these 34 iterations of classification, the training and test data were kept completely separate, including 34 separate factor analyses. 


#### 2. Classification of individual social interactions 
  
The second type of classification attempted to identify to which of the 16 social interactions a given brain image corresponded. The latter classification was performed both within participants (re-iteratively dividing the participant’s data into training and test sets) and across participants in a group (training the classifier on data from 16 participants and identifying the social interactions in the data of the 17th, left-out participant). (see   for details). 




## Results 
  
### Overview of main findings 
    
The neural activation patterns associated with social interaction concepts such as   hug   and   adore   in individuals with high-functioning autism lack a subcomponent of neural activity in posterior cingulate/precuneus, which is strongly evident in control participants. This finding emanated from a factor analysis of the activation patterns of 135 automatically selected voxels (volume elements, each 59 mm ) from each participant distributed throughout their brain. For reasons discussed below, we interpret this subcomponent of neural activity as associated with   self  -related cognition. 
  
The individuals in the autism and control groups can be identified as such automatically with high specificity and sensitivity by a machine learning classification of the neural activity associated with these social concepts. This result was obtained when a machine-learning classifier based on the factor analyses and trained on the data of all but one left-out participant was able to correctly predict whether or not that participant had autism in 33 of 34 (97%) of the cases. 
  
An individual’s neural representation of a particular social interaction (out of the 16) can be reliably identified at far above chance level by a machine learning classifier that has been trained on the neural activity from the   same individual   in an independent set of trials, indicating a systematic relation between brain activity and the thought about a particular social interaction. 
  
An individual’s neural representation of a particular social interaction can similarly be reliably identified at far above chance level by a machine learning classifier that has been trained on the neural activity of   other members   of their own group, indicating a commonality of neural representations across individuals. This outcome attests to the similarity of the alteration across people with autism. 
  
The degree of alteration of the neural representation of   self   in an individual with autism is correlated with the quality of the brain connective anatomy (cingulum bundle) joining regions associated with the representation of   self   (frontal and posterior midline brain areas). The degree of alteration is also correlated with behavior (face processing ability as measured with the Benton Facial Recognition Test   and other tests), thus providing a multi-tiered account linking the neural activity, brain anatomy, and behavior associated with an individual autistic participant’s thoughts about a particular social interaction. 
  
This summary of results provides an overview but the details follow below. 


### Factor analysis results 
  
The main group difference was the presence of a factor in the control group’s activation with strong representation in the posterior cingulate/precuneus area, a factor that was absent in the participants with autism. We interpret this factor in the control group as being involved in   self  -related cognition, for two reasons. First, one of the main brain locations associated with this factor, the superior midline areas of posterior cingulate and precuneus, has been activated in many previous fMRI studies when a thinking task involved consideration of the   self  , and furthermore, several studies have reported that in autism this component of neural activation is disrupted  ,  . (The voxel locations most associated with the factor in this area are shown in  . The complete set of 6 cortical locations for this factor and the other factors are shown in Table S1 in  .). 
   Posterior midline   self   factor location.  
A. Location of the voxels (circled) derived from the factor analysis of the Control Group that defined the posterior cingulate/precuneus sphere of this group’s   self   factor. Voxels in this cluster (with MNI x-coordinates extending from 0 to −9) are shown projected on the mid-sagittal plane. (The coordinates and radii of all 6 spheres associated with this factor are shown in Table S1 in  ). B. Mean activation in midline brain structures for the verb   hug   (averaged over agent and recipient roles) for the two groups, differing in posterior cingulate/precuneus. The verb   hug   was chosen for illustration here because of the salience of hugging as a social interaction in autism, where enveloping pressure is sometimes desired but without physical contact between oneself with another person, as in Temple Grandin’s squeeze machine  . The depiction of the activation in this slice for all of the other verbs was very similar to   hug  , for both groups. 
  
The second facet of the results that is consistent with the interpretation of the   self  -related factor is the ordering of the 16 social interactions by their factor scores for this factor, particularly the items at the two extremes of the 16-item ordered list. The two items with the highest factor scores were   hate   in the agent role and   humiliate   in the recipient role (followed by   hate  /recipient and   insult   in both roles). The two lowest-ranking interactions were   kick   in the recipient role and   kick   in the agent role. By contrast, the autism group had no factor that ordered the interactions similarly nor which had a substantial posterior cingulate factor location, indicating a diminished degree of representation of the   self   in autism in the context of these social interactions. 

 shows the difference between the two groups for the verb   hug   in the agent role, indicating the relative absence of activation in posterior cingulate/precuneus in autism compared to the control group. Although it was previously known that there is sometimes abnormally low activation in autism in the posterior midline areas, the new results here indicate much more precisely how this region’s role is modulated by the degree of   self  -involvement in the control group, and hence what is altered in the autism group. 

Regardless of this factor’s precise interpretation, the coding of the social interactions by this factor and the others makes it possible to identify whether an individual participant belongs to the autism or control group, and furthermore to identify which social interaction he or she is thinking about at a given time, as described below. 

In the autism group’s activation, the comparably ranked factor appears to instead encode how physical the actions were. We base this interpretation on the main brain regions associated with the factor, particularly L precentral (a motor-related area) and L postcentral (a somatosensory area). The four interactions with the highest scores from this factor are   kick   in both roles,   hug   in recipient role, and   encourage   in the agent role, all of which entail a physical action). The four lowest-ranked interactions were   hate   and   insult   in both roles. 

The remaining three factors were similar between the two groups. We interpret these three factors as coding for the positive or negative valence of the social interaction, the accessibility/familiarity of the interaction, and the length of the verb name, factors which we describe in turn. 

The social valence factor assigned high factor scores to socially positive interactions (e.g.   adore, compliment  ) and low scores for negative interactions (e.g.   humiliate, hate  ). The valence factors of the two groups were very similar, assigning highly correlated (r = .96) factor scores to the 16 interactions. The brain locations for this factor included caudate and putamen for both groups. 

The factor interpreted as accessibility or familiarity produced factor scores for the 16 interactions that were highly correlated (r = .89) between the two groups. Furthermore, the brain locations associated with this factor, very similar for the two groups, included regions that are part of the default mode network, particularly middle cingulate, R angular gyrus, and R superior medial frontal. Our interpretation of this factor is based in part on the assumption that the more accessible the social interaction was, the more resources were left over to activate the default network. According to this interpretation, activation of the default mode network here is not an indication that these regions are semantically encoding familiarity, but that their pattern of activation is a byproduct of the ease or difficulty of semantic access. For example, for the control group, interactions with the highest accessibility/familiarity scores were   compliment   and   hug   whereas   insult   and   adore   had the lowest scores. 

The word length factor was extremely similar for the two groups both in terms of the brain locations (strongly associated with L and R Occipital pole for both groups) and factor scores for the 16 interactions (their correlation was r = .99) which were also highly correlated with the number of letters in the verb name (r = .98 for both groups), with   compliment   and   hug   anchoring the factor for both groups. The 4 factors together accounted for 41.8% of the variation for the autism group and 43.0% for the control group, with most of the factors accounting for similar amounts (9.3–10.6%), except for the word length factor which accounted for slightly more (13.3% for autism; 13.2% for controls). 

In summary, the factor analyses indicate a major group difference, namely that the autism group lacked a   self   factor and instead had a factor corresponding to the verbs’ impersonal semantic (abstract-physical) properties. 


### Classification of participants as autistic or control 
  
A machine learning classifier (GNB) that was based on the union of the two groups’ factor analyses (minus the participant being classified) was able to identify each participant as autistic or control with very high accuracy (33 of 34 or 97% of participants correctly classified), misclassifying one participant with autism as a control. The features of this classifier were derived from 3 factors from the autism group’s factor analysis (  physical-abstract  ,   social valence  , and   accessibility  ) and 3 factors from the control group (  self  ,   social valence,   and   accessibility  ), excluding the word length factor, which was very similar for the two groups. The pattern of brain activation levels for the 16 interactions in the set of 36 locations associated with the factors reliably distinguished the two groups. This outcome confirms the postulated differential neurocognitive representations of social interactions for the two groups, and indicates the substantial diagnostic potential of this approach. 

In summary, the differences in the ways that people with autism in this sample neurally represent interpersonal interactions can be used by a classifier to identify a person as having autism or not, with high accuracy. 


### Classification of social interactions 
  
It was possible to identify which of the 16 social interaction items a participant was thinking about, based on the neural representation of the 4 factors that emerged from each group’s factor analysis. A GNB classifier was trained on an independent subset (4 of the 6 presentation blocks) of each participant’s own data and then tested on their remaining subset (the mean of the other 2 presentations blocks). Each of the 16 items was characterized by its activation level in 24 spheres (6 spheres for each of the 4 factors) for that participant group. The resulting mean rank accuracies (hereafter, accuracies) for classifying the 16 items were reliably (  p  <.001) above chance level (0.56) for all participants (with mean accuracies of 0.71 for the autism group and 0.68 for the control group). The successful classification of individual social interactions indicates that the factor analysis captured important components of their neurosemantic representation. 

Another striking finding was the ability to identify which of the 16 social interactions a participant with autism was thinking about by training the classifier exclusively on the factor analysis-guided activation data of the other autistic participants (again using the same 4 factors from the autism group). This classification produced a mean rank accuracy of 0.82 in the autism group, with all 17 autism participants’ social interaction classification accuracies falling reliably (  p  <.001) above chance level (0.72). (The higher mean classification accuracies across participants than within participants may be due to the larger amount of training data in the former case). That the representation of a social interaction in a participant with autism could be decoded by training a classifier solely on data from other people with autism indicates substantial commonality of the neurosemantic alterations across people with autism. Despite the well-known heterogeneity of autism, the alteration of the neural representation of these social concepts is apparently similar across the autism participants. 

Similarly, there was commonality across the control participants, where the corresponding classification produced a mean accuracy of 0.77, with 16 of 17 control participants’ classification accuracies falling reliably (  p  <.001) above chance level. 


### Relation to anatomical connectivity and behavioral measures of social processing 
  
Diffusion imaging was used to determine whether the altered representation of   self   in autism is related to the quality of the cingulum bundle, the anatomical tract that connects the frontal and posterior regions involved in the representation of   self.   The measure of each autism participant’s cingulum tract quality was the mean density across all voxels in the tract (computed from MNI-space density maps representing the number of fibers passing through each voxel in the tract  . The measure of an autism participant’s rudimentary degree of representation of the   self   was the mean stability of their 3 most stable voxels in the main location (posterior cingulate/precuneus) of the control group’s   self   factor. The L cingulum tract density measure (corrected for participants’ age) was positively correlated (  r   = .50, p<0.05) with the rudimentary degree of representation of   self.   (The correlation for the R cingulum tract was lower and not reliable, but in the same direction,   r   = .17). This result indicates that better anatomical connectivity in a participant with autism between posterior and anterior midline areas (both of which have been involved in   self  -related activity in previous studies) was associated with stronger rudiments of a   self   factor. 

The strength of these   self   rudiments (corrected for participants’ age and full scale IQ) was also positively correlated with each of the behavioral measures of social processing: the Benton Facial Recognition Test score (  r   = 0.72,   p  <.05)  , as shown in  ; WMS III Faces II (r = .69,   p  <.05); and Reading the Mind in the Eyes (r = .78,   p  <.005). In addition, the correlation of the   self   rudiments with the ADOS social total was -.21 n.s. (the negative correlation is in the expected direction). The indicated p-values are Bonferroni-corrected for the 4 comparisons. 
   Degree of alteration of   self  -related activation in autism (estimated by its stability in posterior cingulate/precuneus) and its relation to social processing ability measured by the Benton Facial Recognition Test  .  
Both measures were adjusted for participants’ age and full scale IQ. One participant with autism did not have a Benton Test score. 
  

### Conventional general linear model (GLM) analyses 
  
GLM contrasts revealed none of the main findings of the multivariate approach. A between-group SPM contrast (Autism-Control) (all social interactions – fixation), explored with an uncorrected threshold of p = 0.001 and extent threshold of 5 voxels showed essentially no group differences (the autism group’s activation was higher in two small clusters (6 and 7 voxels) located in right superior and middle frontal gyri). The within-group contrasts (all social interactions-fixation) showed activation in similar areas for the two groups, including left inferior frontal gyrus, left superior temporal gyrus, superior frontal, left middle frontal and middle temporal, left inferior parietal areas, and bilateral occipital pole, as shown in  . The group with autism additionally activated right inferior frontal gyrus, middle frontal and middle temporal areas. 
   Social Interactions-Fixation contrasts for the two groups.  
The uncorrected   p  -threshold is 0.001 and the extent threshold is 5 voxels for both groups. 
  


## Discussion 
  
The main finding provides a plausible biological basis for the psychological phenomenon of altered conceptions of social interaction in autism. The factor analyses indicate the autism group lacked a   self   factor and instead had a factor corresponding to the verbs’ impersonal semantic (abstract-physical) properties. The participants with autism may have viewed the social interactions referred to by the verbs as though they themselves were a spectator (like an “anthropologist on Mars,” as described by Temple Grandin, referring to how a person with autism might view complex social interactions without self-involvement  ). This new approach to characterizing the nature of thought alterations provides a new meaning to the concept of   biomarker  , which is usually thought of as a biological marker of a biological state. Here we see a set of brain activation patterns constituting a biological marker of a set of   altered cognitive states   corresponding to conceptions of social interactions. The biological alteration in the brain activity corresponding to the alteration of the thought pattern can be considered a neurocognitive marker of autism. This overview provides a guide to the discussion section but the detail and substantiation follow below. 

The neurosemantic group difference is much weaker in non-social semantic domains. A small pilot study of 6 adults with autism and 6 controls examined whether the two groups differed to a similar extent in their neurosemantic representations of 10 tools and 10 dwellings  , two semantic domains that might be expected to be represented rather similarly in autism and in controls. Approximately similar machine learning methods produced substantially less accurate group membership classification, identifying group membership correctly for no more than 7 of the 12 participants (chance level accuracy would be 6 of 12), failing to find a statistically reliable group difference in the neural representation of concrete objects. 

Although the current findings with only 34 participants must be treated with caution, they help close the loop relating   brain activation patterns   and   brain anatomy   in autism to   thought   and   behavior  , suggesting a causal path. The evidence we have reported above shows that (a) the group differences in activation patterns in response to social interactions are sufficient for automated identification of autism; (b) the main distinction of the autism activation pattern was the near absence of systematic activation in a midline posterior cingulate/precuneus region associated with the representation of   self,   indicating a lack of psychological self-involvement in these social representation; (c) furthermore, in individuals with autism, the residual strength (stability) of the   self  -related activation rudiments in this brain area was correlated with the density of fibers connecting that area to a frontal region, which is also involved in   self  -related cognition; and the residual strength of the   self  -related activation rudiments was also correlated with behavioral measures of the autism participants’ social processing ability. The correlation with anatomy may be of particular interest because recent genomic research has uncovered several genetic alterations (copy number variants and single nucleotide variants) sometimes found in autism that are capable of altering axonal development and maintenance during early neurodevelopment, potentially leading to altered connectivity in the affected axonal tracts  ,  ,  . Thus, alterations in frontal-posterior brain connectivity may underlie the altered social behavior and brain activation observed in autism. 

One extension of this approach may be to the study of alterations in autism of thoughts of emotions. A recent brain-reading study has applied this method to identifying which of 18 emotions a neurotypical participant was experiencing, finding (a) high identifiability of emotions; (b) high commonality across participants; and (c) a set of 3 neural factors underlying the emotions (valence, intensity, sociality)  . These findings suggest that it should be possible to assess alterations in emotion representations in autism and other disorders using the current approach. 

### Study limitations 
  
Despite the very high sensitivity and specificity of the approach (33/34 or 97% of participants classified correctly), the study has clear limitations. First, the current paradigm, requiring significant cooperation during thoughts about social interactions, would be difficult to apply to participants with lower-functioning autism. Second, it is not yet known whether this type of classification can differentiate autism from other special populations, such as those with other developmental and neurological disorders. Furthermore, it would be desirable to develop a neurosemantic screening battery that contains a variety of items capable of evoking altered representations in a number of psychiatric disorders, along with a classifier that accurately identifies the disorder of individual participants. Each disorder could then be identified or diagnosed on the basis of its own characteristic alterations of thought. Because of the many co-morbidities among psychiatric disorders, one might expect classification of some individuals into more than one category. Fortunately, these limitations have the potential of being overcome through further research efforts. 


### Factor analysis implications 
  
There are several implications of the various factor analyses, most generally indicating that it is feasible to determine the underlying dimensions of neural representation of social concepts. Despite the fact that a concept evokes activation in many different locations, it is possible to apply dimension reduction techniques like factor analysis or principal components analysis to converge on a small set of factors or dimensions that can account for much of the systematicity of the activation. In the case of the 16 social interactions examined in the current study, the three dominant dimensions were the   self  -related factor for the control group or the physicality factor for the autism group, as well as the positive/negative valence of the interaction and the accessibility/familiarity of the interaction. These are proposed to be the underlying dimensions of the neural representations of social interactions. The names we have given each of the factors reflect our interpretations of them, which in turn are based on the each factor’s associated brain locations and its ordering of the 16 interactions. Because social interactions seem such an intrinsic concern of the human mind, it seems plausible that there exist a core set of dimensions for thinking about them. 

Regardless of the interpretability of the recovered underlying dimensions in a neural representation space, the mere presence of such factors, common over participants, suggests the possibility of there being a small number (say 50–200) of fundamental neural dimensions of representation that underlie all concepts. In effect, these dimensions would constitute a basis set, from which the representation of any concept could be constructed. It would remain to be seen whether any such basis set would be exclusively biologically given or whether there could also be experience-based dimensions that are part of the basis set. The idea of a basis set of this type is highly speculative, but as brain imaging research progresses it will become increasingly possible to assess. 

One of the assumptions of this study was that the thought alterations in autism are underpinned by a perturbation of some fundamental dimension of neural representation, which the results suggest may be the   self  -related dimension. More generally, it is possible that other psychiatric disorders may be characterized by a perturbation of a particular neural dimension of representation. For example, it is possible that paranoia may be characterized by a perturbation (overactivity) of a threat-detection dimension of representation. Perhaps psychiatric disorders that are currently characterized by verbal descriptions of altered behavior and thoughts may someday be characterized by altered neural dimensions of representation that can be localized to particular sets of brain regions that represent a particular property. 

The finding of a commonality of representation among the participants with autism reveals a facet of autism that stands in contrast to the well-known heterogeneity of the disorder. Although people with autism surely differ enormously among themselves, they must nevertheless have something in common. Almost everyone with autism has some alteration in social processing, but the form of the altered behavior can differ among people, for a variety of reasons, from people developing idiosyncratic coping strategies to people having different mixtures of gene alterations. But there has to be something at the core of the disorder that may be a defining characteristic. Many studies have characterized the behavior or the brain activation in autism as being altered, but often without specifying the nature of the alteration in terms that speak to its commonality across people with autism. The current results provide a possible core property, the neural representation of social interactions, that is altered similarly across participants with autism, namely in that the representation of   self   is largely absent. 

This finding supports theories of autism that postulated altered representation of   self   in autism  ,  . The correlation between the alteration of   self  -representation and the density of the cingulum bundle (which anatomically connects frontal and posterior regions involved in the representation of   self   is also consistent with the theory of frontal-posterior underconnectivity in autism  . 

The contribution of the machine learning is its demonstration that the factors and their locations are capable of accurately discriminating between participants with and without autism. The outcome of the factor analysis itself indicates that the dimensionality of the fMRI data can be reduced, but it does not provide evidence that the resulting dimensions are meaningful or useful. The machine learning provides this demonstration, showing that one of the emerging dimensions, namely   self  -representation, characterizes autism sufficiently well to enable accurate classification. Not for the first time, the multivariate machine learning analysis showed greater sensitivity to systematic activation differences than did univariate GLM contrasts. 

One potential application of the current approach is to provide a biological measure of altered social processing in autism that can augment conventional structured-interview measures, as well as neuroanatomical and brain activity biomarkers of autism. A second potential application is to provide a precise enough characterization of altered social representations in autism to allow the design of targeted therapies and neuropsychiatric diagnostic procedures. Furthermore, both applications of this approach may be feasible with other psychiatric disorders which entail a systematic alteration of particular concepts, such as delusions. But the most far-reaching scientific significance is that psychiatric alterations of thought can begin to be biologically understood in light of their direct psychological consequences using brain imaging techniques in combination with machine learning analyses. 



## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-23'>
<h2>23. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/26197051/' target='_blank'>26197051</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Abnormal Social Reward Responses in Anorexia Nervosa: An fMRI Study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2015</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0133539</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4510264/' target='_blank'>4510264</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study using a social judgment task (acceptance/rejection feedback) — a social-related processing paradigm. It includes a healthy control group (n=20, females, mean age 28.15) with results reported separately (within-group activations for controls are presented). Analyses are whole-brain voxel-wise second-level tests (SPM8 two-sample t-tests across the brain) with cluster-level correction (Alphasim/Family Wise Error correction) rather than ROI-only reporting. Therefore all inclusion criteria are met and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Patients with anorexia nervosa (AN) display impaired social interactions, implicated in the development and prognosis of the disorder. Importantly, social behavior is modulated by reward-based processes, and dysfunctional at-brain-level reward responses have been involved in AN neurobiological models. However, no prior evidence exists of whether these neural alterations would be equally present in social contexts. In this study, we conducted a cross-sectional social-judgment functional magnetic resonance imaging (fMRI) study of 20 restrictive-subtype AN patients and 20 matched healthy controls. Brain activity during acceptance and rejection was investigated and correlated with severity measures (Eating Disorder Inventory -EDI-2) and with personality traits of interest known to modulate social behavior (The Sensitivity to Punishment and Sensitivity to Reward Questionnaire). Patients showed hypoactivation of the dorsomedial prefrontal cortex (DMPFC) during social acceptance and hyperactivation of visual areas during social rejection. Ventral striatum activation during rejection was positively correlated in patients with clinical severity scores. During acceptance, activation of the frontal opercula-anterior insula and dorsomedial/dorsolateral prefrontal cortices was differentially associated with reward sensitivity between groups. These results suggest an abnormal motivational drive for social stimuli, and involve overlapping social cognition and reward systems leading to a disruption of adaptive responses in the processing of social reward. The specific association of reward-related regions with clinical and psychometric measures suggests the putative involvement of reward structures in the maintenance of pathological behaviors in AN. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (38111 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Anorexia nervosa (AN) is a severe and disabling psychiatric disorder. With limited evidence-based treatments available, at least 25% of patients show poor clinical outcome and high levels of functional and social impairment [ – ]. These data highlight the need for a better understanding of the underlying pathophysiological bases of AN, including the identification and precise delineation of the complex neural systems involved [ ]. Current theoretical models describe AN as a multifactorial disorder [ , ] and, social factors, including both the impact of social environment and how individuals interact and process social information, are considered highly relevant to the development, maintenance and prognosis of the disorder [ , ]. Indeed, AN patients generally struggle to maintain interpersonal social relationships, with evidence of social difficulties and social anxiety symptoms, both in the premorbid state and after the disorder’s onset [ , ]. However, little is known about the neural substrates responsible of these abnormal responses to social stimuli or their relevance in the disorder. 

Reward-based processes have been highlighted as powerful and natural modulators of social interactions [ , ]. Indeed, social information is acquired using the same mechanisms of basic reward-based learning, (e.g. reward evaluation and associative learning) [ ], such that past social experiences are used to predict future social outcomes, attempting to maximize rewards and avoid punishments [ ]. At the neural level, reward- and punishment-based learning involves midbrain dopaminergic neurons sending large-scale projections to the ventral striatum, the amygdala, the ventromedial prefrontal cortex, the orbitofrontal and frontal opercula-insular cortices [ , – ]. All these regions have been involved in reward response prediction, either to primary (e.g. the taste of food) or more complex reinforcements such social stimuli [ ]. For example, the reward system has been shown to respond to gaze direction, images of romantic partners and even to the experience of being liked, among others [ , ]. Direct comparisons between social and other stimuli have also shown the overlapping nature of reward system responses to a broad variety of rewards [ , ]. Given the complex nature of social relationships, which require the integrated participation of a number of functions (e.g. social cognition, emotion processing and regulation [ , ]), these tasks have also shown to activate the reward system in conjunction with other areas, for example those involved in theory of mind and self-related regions [ ]. 

In AN, increasing evidence has suggested altered responses of this so-called brain reward system. Early studies suggested a rewarding effect of starvation itself through an hypercortisolemic and hyperdopaminergic state [ ], and, in the same line, the animal model of self-starvation/activity-based anorexia (ABA) has implicated imbalances in the brain reward system in AN, driven merely by modifications in food consumption and starvation [ ]. Further development of conditioned processes based on this aberrant reward-system response have been also implicated in the pathophysiology of AN, where primary rewarding stimuli (such as food) might become aversive, and negative stimuli might become rewarding, as suggested by the   contamination reward theory   [ , ]. Biological evidences of this imbalance have come mainly from alterations in the concentrations of dopamine and its D2 receptor found both in AN patients and recovered subjects [ , ], as well as from functional magnetic resonance (fMRI) studies, which have shown abnormal responses of regions such as the ventral striatum, the anterior insula and the ventromedial prefrontal cortex [ , , ]. For example, the ventral striatum has been found to present either a dysfunctional hyperactivation to the visualization of underweight bodies [ ], an exaggerated [ , ] or a decreased [ ] response to pleasant/sweet tastes, and even found to be non-discriminative between wins and losses in a monetary reward task [ ]. These findings have been proposed as a potential trait marker of the disorder, given the presence of abnormal responses to disorder-specific and disorder-nonspecific stimuli [ ] in both ill and recovered AN patients [ ]. In the context of social stimuli, AN patients might present similar alterations in their responses to reward. Data from behavioral studies have suggested a negative bias in social relationships: patients with AN perceive low reward from- and are avoidant of- social contexts and are oversensitive and attention-biased towards rejection [ , – ]. These behavioral responses are modulated by the so-called approaching/avoidance systems [ , ], which in AN might be affected though alterations in personality traits linked to these systems [ ]. Specifically, AN present consistent heightened scores in   sensitivity to punishment   and putative alterations in   sensitivity to reward  , thought to be vulnerability factors inherently associated with the illness [ – ]. Taken all together, the question arises as to whether altered brain reward responses are implicated in the processing of social stimuli in AN, and if present, whether they involve the same areas found to be altered for non-social rewards or expand to an extended network. Likewise, there are scarce evidences regarding the level to which sensitivity to reward and punishment might be modulating the responses to social stimuli. 

We therefore investigated brain responses to social reward (acceptance) and punishment (rejection) in patients with restrictive-subtype AN in an fMRI experiment. Specifically, we used a modified version of a peer-oriented social judgment paradigm [ , ], previously shown to activate reward- and social processing- related brain regions, including the ventral striatum, the insular cortex and dorsal and ventromedial prefrontal cortices. We hypothesized that AN patients, when receiving socially rewarding peer feedback, would demonstrate reduced activity in these regions. When they received negative feedback we considered two possible outcomes. Considering AN heightened sensitivity and attention-bias to punishment and social rejection, one possibility would be to detect increased activation of regions engaged in attentional processing or in social rejection (e.g. the dorsal anterior cingulate and anterior insula cortices [ ]). Alternatively, we might find evidences for a primary dysfunctional enhancement of reward-related activity, as has been found for other non-naturally rewarding stimuli in AN [ ]. We also anticipated an interaction between reward brain areas and sensitivity to reward and punishment and explored whether an abnormal brain response to social reward/punishment would be modulated by the severity of the disorder. 


## Material and Methods 
  
### Participants 
  
Twenty female patients with Anorexia Nervosa, restricting subtype [ ] (mean age 28.40 years; SD 9.30 years) were recruited consecutively from admissions at the day patient program, Eating Disorders Unit of Bellvitge University Hospital, Barcelona between 2011 and 2012. Diagnoses were conducted by experienced psychologists/psychiatrists (E.V., I.S., F.F-A.) following DSM-IV TR criteria and using a semi-structured clinical interview (Structured Clinical Interview for DSM-IV Axis I Disorders) [ ]. Five patients (25% of the sample) were on pharmacological treatment, as described elsewhere ([ ];  ). Comorbid psychiatric disorders—including any other eating disorder-, any neurological condition and abuse of any substance with the exception of nicotine were exclusion criteria. None of the patients met criteria for hospital admission at the time of scanning on the basis of physical consequences of excessive starvation. 
   Demographic and clinical description of the subjects included in the sample.        
20 healthy controls (20 females, mean age 28.15, SD 8.62) were recruited from the same sociodemographic area and matched by gender, mean age, handedness and mean educational level with the patients ( ). Controls were screened in order to exclude any psychiatric or other medical condition by means of the General Health Questionnaire (GHC-28, [ ]) and a clinical semi-structured interview [ ]. None of the controls presented subthreshold symptoms for any eating disorder and their body mass index (BMI) was within the normal range. 


### Ethics statement 
  
The ethical committee of clinical research (CEIC) of the Bellvitge University Hospital approved the study protocol, which was in compliance with the national legislation and the principles expressed in the Declaration of Helsinki. All participants gave written informed consent after detailed description of the study. 


### Clinical measures 
  
For all participants, severity of symptoms and psychological features involved in eating disorders were assessed with the self-reported Eating Disorder Invertory-2 (EDI-2) scale [ ]. The Sensitivity to Punishment and Sensitivity to Reward Questionnaire (SPSRQ) [ ] and the Liebowitz Social Anxiety Scale (LSAS) [ ] were also collected. Additionally, measurements of depressive and anxiety symptoms were collected by means of the Hamilton Depression Rating Scale (HDRS [ ]) and the Hamilton Anxiety Rating Scale (HARS [ ]). 


### Social Judgment Task 
  
A modification of the task originally reported in Davey et al.[ ] was used in the current study. Participants were assessed on two different days, approximately five days apart. On the first day, participants were asked to participate in a multi-center study about the influence of first impressions on deciding whether or not people would like to meet someone. They were presented a face database containing 70 people's faces with neutral expression (35 male and 35 female faces)—supposed to be study’s participants from other collaborating centers- and were asked to decide if they would like to meet them or not (  acceptance/rejection  ), rating their decision in a 10-point Likert-type scale—10 being the maximum for liking to meet someone (  score pre-scanning  ). Likewise, participants had a photograph taken, which was supposedly sent and reciprocally scored by the database participants. This feedback was given during the fMRI scanning on the second day of assessment. In reality, the face database integrated pictures selected from a larger pre-existing and public available face database [ ], and at the end of the experiment, participants were debriefed about the deception involved. 

During the fMRI scanning, participants viewed a total of 54 of the 70 rated on the first assessment day. Each picture was presented for 8 seconds, and during the last 6 seconds a feedback symbol (a happy, sad or neutral draw of a face) was additionally displayed on the top right corner of the picture ( ). Participants were instructed that happy face symbols indicated acceptance, and sad faces rejection. Neutral faces appeared when people supposedly could not be contacted to give feedback, which formed the control condition of the experiment. The 54 presented faces and the feedback responses were pseudo-randomly determined to ensure good balance between gender (27 male, 27 female) and between the three conditions (17 acceptance responses, 18 rejection responses and 19 control condition responses). The paradigm was presented visually on a laptop computer running E-Prime software on Windows (Psychology Software Tools, Inc., Sharpsburg, PA, USA,   www.pstnet.com  ). Magnetic resonance imaging-compatible high-resolution goggles were used to display the stimuli. 
   Diagram of the Social Judgment Task used in the fMRI session.  
Participants received social feedback based on the willingness to be met by other participants. Each facial stimulus (represented in by ovals instead of the originally presented faces) was presented for a total of 8 second-blocks, with an overlapping feedback symbol during the last 6 seconds. Acceptance, rejection or no-feedback (control condition) was indicated by a happy, sad, or neutral draw of a face. Originally presented images were contained in a preexisting face database: Martinez AM, Benavente R. The AR Face Database CVC Tech. Report #24 [Internet]. 1998. Available:   http://www2.ece.ohio-state.edu/~aleix/ARdatabase.html  . 
  
After the scanning session, participants were presented again with the complete face database (70 faces). For each face, they were asked to recall if it appeared during the scanning and in each case what type of feedback the person had given. Participants were also asked about the first impression they had of each face on the first day (10-point Likert-type scale,   score post-scanning  ). This assessment allowed exploration of potential attention and memory biases. A visual analogue scale was used to evaluate how they felt after receiving each one of the three types of feedback (scores ranging from 0 to 10). Finally, after debriefing about the nature of the study, participants were asked to rate how much they believed they had received true feedback (scores ranging from 0 to 10). 


### Behavioral measures 
  
Accuracy of recall on which faces had been displayed during the MRI session was compared between groups using a two-sample   t  -test. Next, the number of correctly remembered feedback responses was compared across groups and conditions by means of a mixed-design ANOVA analysis: task condition (acceptance, rejection, neutral) was included as the within-group variable and group (controls, patients) as the between-group variable (3x2 mixed ANOVA). Then, to compare, between groups, score changes across the two time points (pre-and post- scanning) and the three conditions, a second ANOVA analysis was conducted, with task condition and pre-post scores as the within-group variables, and group as the between-group factor (3x2x2 mixed ANOVA). Additionally, a similar 3x2 ANOVA was conducted to compare, between-groups and conditions, how the subjects felt when receiving each type of feedback. Finally, a two-sample t-test was conducted to compare, between-groups, how much they believed they were being truly evaluated. Behavioral analyses were performed in Statistical Package for the Social Sciences (SPSS) v20 on a Windows platform. Level of significance was set at p<0.05. 


### Imaging acquisition and preprocessing 
  
A 1.5-T Signa Excite system (General Electric Milwaukee, WI, USA) magnetic resonance, equipped with an 8-channel phased-array head coil and single-shot echoplanar imaging software was used. The functional sequence consisted of gradient recalled acquisition in the steady state (repetition time (TR) = 2000 ms, echo time (TE) = 50ms and pulse angle, 90°) in a 24 cm field of view, 64 x 64 pixel matrix and a slice thickness of 4mm (inter-slice gap, 1.5 mm). A total of 22 interleaved sections, parallel to the anterior—posterior commissure line, were acquired to generate 216 whole-brain volumes, excluding four initial dummy volumes to allow the magnetization to reach equilibrium. 

Data were processed on a Macintosh platform running Matlab version 7.14 (The MathWorks, Inc) and statistical parametric mapping software version 8 (SPM8). Within participants, time-series of acquired images were initially realigned to the mean image by using a least squares and a 6-parameter (rigid body) spatial transformation. Images were then normalized to the standard echoplanar imaging (EPI) template in SPM and resliced in Montreal Neurological Institute (MNI) space (resulting voxel size 2 mm ). Finally, they were smoothed with an 8 mm isotropic Gaussian filter. All image sequences were routinely inspected for potential movement or normalization artifacts. 


### Imaging processing and imaging analyses 
  
For each participant, the onset and offset timing of the conditions (each 6-second block of the acceptance, rejection and neutral conditions, as well as the first 2-seconds of no-feedback), was convolved with a canonical hemodynamic response function to model the acquired BOLD signal. A high-pass filter was used to remove low-frequency noise (cut off period = 1/128 Hz). At a first single-subject level of analysis, contrasts were defined as: i) the acceptance condition   minus   the control condition; and ii) the rejection condition   minus   the control condition. Within-group contrast images were then carried to a mixed effects second-level, creating two-sample t-tests at each voxel to compare between-group brain activations. 

Statistical analyses at the second level involved a combination of voxel and cluster correction methods providing a significance level equivalent to a Family Wise Error corrected p (pFWE)<0.05. Specifically, individual voxel threshold was set at an uncorrected p<0.005, while minimum spatial cluster extent (min. K ) required to satisfy a pFWE<0.05 was determined by 1000 Monte Carlo simulations using the Alphasim algorithm as implemented in the SPM RESting-state fMRI data analysis Toolkit (REST) toolbox in Matlab [ ]. Other input parameters included a connection radius of 5 mm and the actual smoothing value of each statistical comparison (between 13 and 16mm). Cluster extents were determined using a whole-brain mask for within-group activations and single masks containing combined (both groups) brain activations for the between-group comparisons (whole brain mask: 337,701 voxels, min. K  = 124 for acceptance, min K  = 147 for rejection; masks with combined brain activations: 4,568–27,851 voxels; min. K  ranged between 29–99). 

Additional analyses were conducted to explore the relationship between clinical measurements and brain activations during task performance. Firstly, to assess for potential and differential associations between sensitivity to reward/punishment and brain activations between groups, SPSRQ scores were included in two separate between-group interaction analyses (sensitivity to reward during acceptance and sensitivity to punishment during rejection). Secondly, brain activations in patients were correlated with EDI-2 scores in two separate regression analyses (acceptance, rejection). Levels of significance were set based on the same cluster correction methods used for the main analyses. For the interaction SPSRQ analyses, masks contained the combined activation of patients and controls in both the acceptance and rejection, while separate masks containing patients' activations during the acceptance and the rejection conditions were used for the correlation analyses with EDI-2 (masks contained between 4,787–36,673 voxels; min. K  = 4–118). Age and depressive symptoms (see below) were included as nuisance covariates in all the analyses. 



## Results 
  
### Clinical and demographic variables 
  
There were no statistically significant differences in age, handedness or educational level between patients and controls. As expected, body mass index (BMI) and EDI-2 measurements were significantly different in patients and controls, with lower mean BMI and higher mean EDI-2 scores in patients. 

SPSRQ subtest scores indicated higher sensitivity to punishment in patients, with no differences in sensitivity to reward. Higher LSAS scores were also found in patients although differences did not survive Bonferroni correction for multiple testing. Similarly, depressive and anxiety symptoms were higher in patients compared to controls, but Bonferroni-corrected statistical significance was only observed for depressive symptoms ( ). Since anxiety and depressive symptoms were highly correlated (r = .86, p< .001), we only included depressive symptoms as a nuisance covariate in our analyses. 


### Behavioral measures 
  
Both groups remembered with high accuracy which faces appeared during the fMRI task (AN patients: 69%, Controls: 65%). There were no interaction effects or between-group differences in the accuracy of recall to the different types of feedback; however, across conditions, all participants more accurately remembered being rejected in comparison to being accepted (p <.001) or receiving no feedback (p <.001; condition effect: F(2,76) = 16.54, p <.001). Similarly, there were no interaction effects or between-group differences in the   pre   and   post-scanning scores   across conditions, and all participants gave both higher   pre   and   post-scanning   ratings to faces that provided rejection feedback compared to acceptance or no feedback (both p <.001; condition effect:   F  (2,76) = 36.43, p <.001). 

There were no interaction effects or between-group differences on how participants felt after receiving any type of feedback, and all of them liked more being accepted than rejected (p <.001) or receiving no feedback (p <.001; condition effect: F(2,74) = 83.32, p <.001). All participants indicated that they believed the participant ratings were genuine (mean (SD) out of 10: AN patients: 9.4 (1.30); Controls: 9.12 (1.21)). The results are summarized in  . 


### Imaging results 
  
#### Main analyses: within-group results 
  
In response to acceptance feedback, both groups showed an overlapping activation of the dorsal and ventral medial prefrontal cortices. Controls presented an additional activation of the ventral striatum and bilateral anterior insular cortices, whereas patients showed an additional activation of an area including the parahippocampal gyrus, hippocampus and amygdala. 

Conversely, both groups presented a similar pattern of brain activation in response to rejection, with enhancement of the dorsomedial prefrontal cortex, anterior insular cortices and primary and secondary visual areas. Patients showed an additional activation of the ventral striatum, specifically in the ventral part of the caudate nucleus ( ,  ). 
   Within and between-group activations of extended brain regions during the performance of the task.           Within and between-group brain activations during acceptance and rejection feedback.  
Brain hyperactivations (i.e. contrast acceptance/rejection>control condition) are depicted in yellow and deactivations (i.e. contrast acceptance/rejection<control condition) are in blue. A and B represent within-group activations in A = controls and B = patients. Below, results for the comparison controls>AN patients and for the comparison AN patients>controls. Color bars represents T value, only for between-group comparisons. Images are displayed in neurological convention (left is left). 
  

#### Main analyses: between-group results 
  
In response to acceptance, patients showed significantly decreased activation in a dorsomedial prefrontal cortex (DMPFC, Brodmann area 8-BA8-, extending to BA9) compared to controls. By contrast, patients showed increased activation of the left secondary visual cortex (parastriate BA18) during rejection ( ,  , and  ). 


#### Interactions with clinical variables 
  
In response to acceptance feedback, sensitivity to reward was differentially associated—between groups—with activity of bilateral frontal opercula-anterior insula cortices (negative association in patients), and the dorsomedial and dorsolateral prefrontal cortices (BA8, BA10; positive association in controls;  ,  ). No areas of between-group interaction were found in response to rejection feedback. 
   Interactions between Sensitivity to Reward and brain activations during the acceptance condition.  
Color bars represents T value. Images are displayed in neurological convention (left is left). Scatter plots represent Pearson's correlations between sensitivity to reward scores and the extracted mean eigenvalues in each relevant cluster: A. Dorsolateral prefrontal cortex. B. Left orbitofrontal-anterior insula cortex. C. Right orbitofrontal-anterior insula cortex. D. Dorsomedial prefrontal cortex. A results table is included, showing peak coordinates of each cluster and their corresponding statistics. (): Two outliers were detected based on the Tukey’s Outlier Filter. Although depicted in the figure, they were removed from correlation analyses. 
  
There were no associations between symptom severity measured with the EDI-2 and brain activation observed in response to acceptance feedback. By comparison, symptom severity was both positively and negatively associated with brain activation observed in response to rejection feedback. Specifically, positive correlations were observed between symptom severity and ventral striatal-located at the ventral part of the caudate nucleus-, dorsomedial prefrontal (BA8), and visual cortical (BA17-BA18-BA19) activations, while negative correlations were observed with dorsolateral prefrontal cortex activation ( ,  ). 
   Associations between EDI-2 scores and brain activity in AN patients during rejection feedback.  
Color bars represents T value. Images are displayed in neurological convention (left is left). Scatter plots represent Pearson's correlations between EDI-2 scores and the extracted mean eigenvalues in each one of the significant clusters. A results table is included, showing peak coordinates of each cluster and their corresponding statistics. 
  
Several post-hoc analyses were conducted. First, and given the associations between illness duration and reward responses in other disorders [ ], we extracted mean signal values from regions with significant results and correlated them with illness duration and age at onset, finding, however, no significant associations ( ). Second, and because of the high prevalence of social anxiety in AN, social anxiety (LSAS) scores were included in correlation analyses using the same approach as for severity measures, to explore whether this putative contributing factor would be independently associated with brain responses to social acceptance and rejection. However, there were no associations emerging from these correlation analyses. Finally, to control for potential effects of treatment over brain activity during feedback presentations, we repeated all the above analyses excluding the 5 patients under pharmacological treatment (12.5% of the sample, 25% of the patients). Most of the results were replicated, except, for the patient group, the association between severity and brain activation during rejection at the dorsolateral prefrontal and visual cortices (BA19). Despite the lost of statistical power, the rest of results were replicated with reductions of the size of clusters with significant voxels-which therefore affected cluster-based corrected significance-, mainly at the level of bilateral anterior insula and dorsomedial prefrontal cortices in the sensitivity to reward interaction analysis (  and legend). 




## Discussion 
  
The results of the present study suggest that alterations in reward responses to social stimuli in AN involve an overlapping network of social cognition, attentional and reward-processing areas, highlighting the tight involvement of large-scale and distributed networks in complex processes such as social feedback evaluation [ , ]. Interestingly, the activation of reward-related structures in both conditions showed paradoxical associations with either the severity of the disorder or sensitivity to reward scores, suggesting their implication in disorder-related dysfunctional processing of social reward. Alterations in brain responses to reward and punishment, which have been implicated in the pathophysiology of AN, might also relevantly contribute to the dysfunctional social relationships experienced by AN patients. Although other factors such as social anxiety symptoms might modulate responses to reward in this context, the lack of associations between brain activations to reward/punishment and LSAS scores gives further relevance to the associations found with the severity of AN. 

An extensive cluster located in the dorsomedial prefrontal cortex (DMPFC), which is commonly activated by social feedback [ ], was non-specifically activated in both groups and in both conditions. Nevertheless, AN patients showed hypoactivation within this region during positive feedback. The DMPFC participates in social-cognition processes such as self-reference and reflective self-knowledge [ ], making inferences about how we are viewed by others [ – ], and in inhibiting the tendency of using oneself as a reference during social judgments [ ]. DMPFC hypoactivations have been observed in AN patients during the performance of related tasks, such as theory of mind (attribution of intentions, BA10) [ ] and self-appraisal (BA6, [ ]). Additionally, the medial part of BA8 has been associated with tolerance to uncertainty [ , , ] which, in social contexts, seems necessary for adaptively inferring other's mental state given the unpredictability of other's minds [ ]. Reduced DMPFc activation in patients during acceptance suggests that self-evaluative processes and inference of other's mental states might be particularly disrupted in AN during rewarding social feedback, consistent with the reduced perception of reward value in AN [ , ], and indicating a general inhibitory-motivational response to social reward. Moreover, this response might be also associated with low tolerance to uncertainty and increased perception of lack of control in social relationships in AN patients [ ], suggested to be compensated by increased control over eating, body shape and weight [ , ]. Since there was a positive association between DMPFc activity and EDI-2 scores during rejection, the opposite process—i.e increased motivational response through the engagement of the DMPFc- might be occurring when receiving negative feedback, although no between-group differences in DMPFc were found for this condition. 

During rejection, the pattern of activations was more similar between groups. Activation of the attention-network (visual cortex), together with behavioral results—rejection responses were better remembered—suggests increased attention during rejection in both groups. However, AN patients presented hyperactivation of left parastriatal visual regions, which were additionally correlated with the severity of the disorder. These results are consistent with attentional biases to negative social stimuli found in behavioral studies of AN [ , ], and might again indicate a distorted motivational drive towards negative stimuli. In other disorders, such as depression and anxiety, attentional biases towards negative stimuli have been found to increase and maintain the pathological state, but also to be modifiable [ ]. Attentional bias modification strategies have been suggested in AN, and might be particularly helpful in changing cognitive biases to negative social stimuli through modification of attentional pathways [ ]. Consistent with previous hypotheses, our results suggest the relevance of combined alterations in social motivation and visual orienting brain areas contributing to impaired interpersonal relationships in AN, similar to what has been observed in other disorders [ , ]. 

We additionally observed a between-group differential pattern of associations between brain responses and sensitivity to reward. It is worth mentioning that these differences were found even though there were no differences in sensitivity to reward scores. Indeed, while it is reasonably well established that AN patients present higher sensitivity to punishment, evidences for sensitivity to reward are mixed, and, if present, they might be more relevant in samples composed by purgative rather than restrictive subtype patients [ , ]. However, these negative findings in the drive for rewards are not incompatible with alterations in either the reward perceived or in the interaction between the drive and perceived reward from social relationships. In our study, while control participants with high reward sensitivity engaged cognitive-control structures—possibly regulating an elevated motivational drive during positive feedback—AN patients showed a negative association between insula activation and sensitivity to reward. Neurobiological models of sensitivity to reward suggest its encoding in a cortico-limbic system including the reward loop linking the midbrain and ventral striatum with the prefrontal cortex [ ], and, among them, the anterior insula has suggested to be more specifically involved in social rewards [ ]. This region has been strongly hypothesized to be involved in the pathophysiology of AN [ ], and some studies have found insula hypoactivation during the processing of primary rewarding stimuli both in ill [ ] and recovered AN patients [ , ]. Indeed, these results suggest that in AN patients there is a disruption of the expected association between incentive motivation and the hedonic insular involvement in reward [ , ]. Such uncoupling of   wanting   from   liking   has been previously proposed in AN in other contexts [ ] and might indicate here a dysfunctional compensatory response to a natural motivational drive for social rewards [ ]. According to our results, besides its implication in altered processing of basic rewards in AN, anterior insula may also lose control over more complex reward-related responses, such as those dependent on social feedback. 

Finally, the ventral striatum (VS) activation during rejection feedback was associated with the EDI-2 scores. This association was only found during rejection, and might be evidence of aberrant functioning of this system during social interactions in AN, similar to the observed VS activation when patients viewed emaciated bodies [ ], or received losses in a monetary task [ ]. Interestingly, the results were mainly located in the ventral part of the caudate nucleus, which has shown its involvement in reward processing particularly when feedback is involved and in the context of social learning [ ]. In any case, while the above findings seem to imply that the suggested aberrant response of this structure to a range of rewards might be also mediating altered social reward-based responses, other explanations should be also taken into account. For example, VS activity might be compensating for emotional pain associated with rejection, similar to VS activation in placebo-induced analgesia [ ]. The specific contribution of these factors, however, requires further investigations. 


## Limitations 
  
Our sample size was relatively modest and replication is required. However, we assessed for the first time brain responses in AN patients during social feedback, as well as their association with clinical and personality variables. Secondly, we included patients on current pharmacological treatment. Although it is unclear the direction in which treatment might bias these specific results, the exclusion of the 5 medicated participants—and despite the lost of statistical power- did not substantially modified our main results. However, medication effects cannot be ruled out, suggesting there is a need for further evaluation of this issue. Thirdly, we did not conduct a metabolic study in our protocol, which could have allowed a better characterization of the sample and the investigation of putative associations between altered metabolic variables and our findings. However, Day Unit recruitment—patients with BMI≥14 in our centre, with better metabolic profiles-, was conducted in order to minimize possible confounding effects of malnutrition on both task performance and BOLD signal. Fourthly, our study was restricted to low-weight adult AN females, with no comorbidities, and used a cross-sectional design. It will be interesting for future studies to test our results in other populations, such as patients with comorbidities, men, or adolescent samples. Moreover, although we did not find associations between our results and age at onset or illness duration, it would be equally interesting to assess the involvement of these alterations in the onset of the disorder, as well as their impact on the prognosis and outcome of patients, and whether they persist after weight restoration and symptom recovery. Longitudinal studies, the study of patients who have recovered, or intermediate phenotypes, might be of particular interest in answering these questions. 


## Conclusions 
  
Our results suggest a possible link between altered patterns of social relationships in AN and dysfunctional reward-related brain responses. These alterations might be of relevance in the maintenance of social maladaptive responses and eventually in the persistence of the disorder, and might help to explain the elevated resistance to change in patients with AN. Although alterations to functioning of the reward system have been highlighted recently in several psychiatric disorders, given the rewarding nature of food and the involvement of the reward circuit in food consumption (i.e. insula and frontal operculum, ventral striatum and amygdala, midbrain and frontal cortex) [ ], these associations are of particular relevance for eating disorders such as AN [ ]. In view of our findings it would be interesting for future studies to test the effectiveness of reward-processing-focused treatments, which might be easily included in therapies such as cognitive remediation or fMRI-based neurofeedback training. For example, patients with anorexia nervosa might be trained to engage specific structures (e.g. DMPFc, ventral striatum) in front of social rewarding contexts such as social approval [ ], which might ultimately improve their social responses and functional impairment. However, to our knowledge, there have been no studies using neurofeedback in AN, and the use of neurofeedback with complex stimuli such as social responses is still a field in development [ ]. Additionally, it would be also of interest to examine other aspects of reward processing in social settings, such as the influence of reward expectations and prediction error in social relationships. Similar paradigms might also be interesting in the context of current trials on oxytocin [ ], to evaluate treatment-mediated changes in the processing of social stimuli in AN. 


## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-24'>
<h2>24. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/18958158/' target='_blank'>18958158</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Neural Correlates of Enhanced Visual Short-Term Memory for Angry Faces: An fMRI Study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2008</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0003536</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/2568825/' target='_blank'>2568825</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study in healthy adult participants (n=35, mean age 29, within 17–65 range) that investigated processing of facial emotion and identity in a visual short-term memory task. The task probes social-relevant constructs (perception and understanding of others; emotional face processing/social communication). Analyses included whole-brain, random-effects ANCOVA and whole-brain contrasts (FDR-corrected), with reported whole-brain results (emotion and load effects and emotion-by-load contrasts). Results for healthy participants are reported separately and no ROI-only restriction applies. Therefore the study meets all inclusion criteria and violates no exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.93</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
## Background 
  
Fluid and effective social communication requires that both face identity and emotional expression information are encoded and maintained in visual short-term memory (VSTM) to enable a coherent, ongoing picture of the world and its players. This appears to be of particular evolutionary importance when confronted with potentially threatening displays of emotion - previous research has shown better VSTM for angry versus happy or neutral face identities. 


## Methodology/Principal Findings 
  
Using functional magnetic resonance imaging, here we investigated the neural correlates of this angry face benefit in VSTM. Participants were shown between one and four to-be-remembered angry, happy, or neutral faces, and after a short retention delay they stated whether a single probe face had been present or not in the previous display. All faces in any one display expressed the same emotion, and the task required memory for face identity. We find enhanced VSTM for angry face identities and describe the right hemisphere brain network underpinning this effect, which involves the globus pallidus, superior temporal sulcus, and frontal lobe. Increased activity in the globus pallidus was significantly correlated with the angry benefit in VSTM. Areas modulated by emotion were distinct from those modulated by memory load. 


## Conclusions/Significance 
  
Our results provide evidence for a key role of the basal ganglia as an interface between emotion and cognition, supported by a frontal, temporal, and occipital network. 

 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (35900 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Visual short-term memory (VSTM) is an active system that temporarily stores and updates information over a period of a few seconds. It is particularly useful for maintaining a constant and coherent percept of the world in the face of eye, head, and object motion. In contrast, long-term memory (LTM) is a system dedicated to storing information over hours, days, and even decades; it is essential for learning and developing knowledge and skills. 

Although it is well established that LTM is enhanced for images with an emotional, particularly negative, content  – , an effect thought to be driven by neural communication between LTM and limbic systems  , the question of whether information to be retained in VSTM is influenced by its emotional content, and which brain mechanisms might be involved, has received little attention and results are varied. One study found no effect of valence on STM for fearful versus neutral faces, nor for taboo versus neutral words  . Two studies using emotive images from the International Affective Picture System (IAPS) found an influence of valence on STM. In one, participants judged the relative emotional intensity (“higher” or “lower”) of two successively presented images that were matched for valence (positive or negative) and were separated by a 3 second retention interval  . Young participants were more likely to make accurate relativity judgments for negative compared to positive images (accuracy was based on whether judgments matched previously established ratings obtained from an independent group of young participants). The authors interpreted this to reflect enhanced STM for negative images, and report the opposite effect with older participants. However, their task was not a direct test of the effect of valence on STM for visual content per se. In a functional magnetic resonance imaging (fMRI) study, participants were required to state whether a positive, negative, or neutral image seen 11.5 seconds earlier was present or not in an array of nine valence-matched images  . Increased activity in dorsolateral prefrontal cortex (DLPFC) and decreased orbitofrontal cortex (OFC) activity was found for positive versus negative images, but these data are difficult to interpret because task accuracy during scanning did not show a difference in STM for positive (65%) versus negative (65%) images. The above studies, while interesting in measuring responses to emotional stimuli, provide little clear insight into whether visual information with an emotional content can influence VSTM and, if so, what brain mechanisms might be involved. [Note that because our aim is to measure the neural correlates of information retained in VSTM with an emotional versus neutral content, we do not review here studies of the effect of emotional distraction or induced mood state on VSTM for neutral stimuli.] 

Previous behavioural research of ours   has shown that VSTM for face identities is significantly enhanced when faces display an angry compared to a happy or neutral expression. We replicated this result a number of times and were able to eliminate several possible accounts of the effect. We showed that that the anger benefit for faces in VSTM was not due to low-level feature recognition: inverting the faces abolished the effect; a perceptual discrimination task in which participants stated whether two faces matched identity or not showed no difference in accuracy or reaction time between angry, happy, or neutral face conditions. We also showed that heightened physiological arousal is unlikely to underpin the effect: the presence of calming or energizing background music during the task did not differentially influence VSTM nor interact with emotional expression conditions, suggesting that enhanced VSTM for angry faces is valence-driven. Perceptual encoding limitations were excluded as an account because the angry benefit remained present when the original study time of 2000 ms was doubled. Finally, the effect was replicated using a different set of faces from another database that were also equated for expression intensity, providing evidence that enhanced VSTM for angry faces is not specific to the faces used, nor due to the potential for angry faces to be more intense in expression than happy or neutral faces. 

In the current study, we again used angry, happy, and neutral faces to investigate the neural correlates of VSTM for information with an emotional versus neutral content. Faces are well suited for this purpose because not only are they ecologically valid, they also allow the presentation of differently valenced emotional information in the same individual exemplars. This reduces variability of low-level featural information among different emotion conditions, a factor that may have confounded results of previous studies using IAPS pictures  . Another person's emotional facial expression can convey critical information about his/her internal mood state and, in turn, affect one's own behavioral decisions, e.g., whether to approach or avoid, or what manner of speech to adopt. Successful and appropriate face-to-face interactions depend not only on recognition of emotional expression, but often also require accurate face identification. Critically, our ability to select an appropriate social response in a timely and effective manner depends on our ability to identify who is expressing what emotion, and this information must be retained in memory for a period sufficient to develop an action plan. Thus, storage of face identity information in VSTM forms a crucial bridge between immediate encoding of emotionally charged information and execution of appropriate behavior. 

Here, during fMRI participants were required to memorize between one and four angry, happy, or neutral faces for 2,000 ms (the number of faces to be remembered is termed   face load  ), and one second later they were asked to report whether a single face probe matched in identity to one of the previous to-be-remembered faces or not ( ). All faces (at both encoding and retrieval) in any one trial displayed the same emotion, thus emotional expression of the to-be-remembered faces was task-irrelevant. Our aim was to specifically examine the neural correlates of the angry benefit for faces in VSTM and determine how emotion and memory systems in the brain might interact to produce this effect. By manipulating face load, we were also able to examine any interactions between load and expression conditions. We predicted that the angry face benefit in VSTM is likely to recruit an interplay of brain regions involved in emotion processing, such as the amygdala, basal ganglia, and insula  – , short-term memory, such as the prefrontal cortex  , and face processing, such as the fusiform gyrus   and superior temporal sulcus  . 
   Here is an example trial procedure (load 3 shown as illustration).  
Between one and four faces (all expressing either angry, happy, or neutral emotion) were shown for encoding for 2000 ms, followed by a 1000 ms blank retention/maintenance phase, and a 2000 ms retrieval phase in which participants stated whether a single probe face had been present or not in the previous display. All faces in any one trial (i.e., at encoding and retrieval) displayed the same emotion. A jittered inter-trial interval (ITI) of between 4000 ms and 6500 ms separated each trial. 
  

## Methods 
  
### Participants 
  
Thirty five right-handed healthy volunteers (mean age 29 years; 15females) from the student and community panels in Bangor participated in return for £20. Subjects reported no history of neurological or psychiatric disorder, had normal or corrected to normal vision, and provided informed written consent prior to participation. The study was approved by the School's ethics committee in Bangor. 


### Stimuli 
  
Greyscale face images of six adult males each expressing three emotions (angry, happy, and neutral) were used  . Each image subtended approximately 1.43°×1.36°. Scrambled greyscale face images, selected at random from a set of eight different scrambled images, were used to fill memory display locations on trials in which fewer than four faces were presented. 


### Experimental Procedure 
  
Participants were oriented to the centre of the computer screen by a small fixation cross presented for 1,000 ms and instructed to maintain fixation throughout each session in order to minimize eye movement artefacts in the functional data. To signal the start of a trial, the fixation cross increased in size for 1,000 ms, after which it returned to its original size for another 1,000 ms. On each trial, between one and four faces, each expressing the same emotion (angry, happy, or neutral) were presented for 2,000 ms in a 2×2 memory matrix with fixation at the centre. The centre of each image within the matrix was positioned at a visual angle of approximately 1.27° from fixation to ensure that the faces display was foveal, and thus minimize eye movements. Previous research has established that 2,000 ms is sufficient time to encode four faces  ,  . On trials in which fewer than four faces were presented, all other matrix locations were occupied by a scrambled face. Face locations were randomised within the matrix. After a 1,000 ms blank retention interval during which only the fixation cross was present, a single face probe (expressing the same emotion as the preceding matrix) was displayed in the centre of the screen for 2,000 ms. Participants were required to state, within the 2,000 ms single probe presentation duration, whether the probe person had been present or not in the immediately preceding display (50% probe present). The task involved an identity decision, thus emotional expression was irrelevant to the task. Participants used their right hand to respond “yes” or “no” using a simple button press. Feedback was not provided. A jittered fixation inter-trial interval (ITI) of between 4,000 and 6,500 ms separated each trial ( ). 

Sixteen experimental trials were presented for each load (1,2,3,4) in each emotion condition (angry, happy, neutral) in a pseudo-random order, resulting in 192 trials in total (event-related design). In order to minimize subject fatigue, the experiment was separated into four separate scanning blocks of 48 trials each, within a single scanning session. Each block lasted approximately 11 minutes. Before the main experiment began, participants were given a short practice session outside the scanner. 


### Data Acquisition 
  
Behavioural data were acquired with a 14-inch Dell Latitude D610 laptop (32-bit true colour; resolution 1280×1024 pixels). The tasks were generated by E-Prime software  . fMRI data were acquired with a Philips 1.5T MRI scanner with a SENSE parallel head coil. We used a gradient echo echoplanar sequence sensitive to the blood oxygen dependent (BOLD) signal (TR = 2,000 ms; TE = 40 ms; matrix size = 96×96; FOV = 256×256 mm ; voxel size = 3×3×3 mm ; 90° flip angle; 20 axial slices). Two dummy volumes were acquired before each scan block to reduce possible T1 saturation effects. During the VSTM faces task, the fMRI sequence was synchronized with the fixation cross at the start of each trial (see  ). Anatomical data was acquired with a high resolution T1-weighted three-dimensional (3D) volume (1×1×1 mm ), and used for coregistration of functional data. 


### Data Analysis 
  
#### Behavioural Data Analysis 
  
False alarm rates in all emotional expression conditions varied significantly as a function of face load, so we converted hits and false alarms into dprime (d') scores in order to provide a more sensitive measure of signal detection. d' is the z-normalised hit rate (probability of ‘yes’ responses when the probe was present) minus the z-normalised false alarm rate (probability of ‘yes’ responses when the probe was absent) [d' =  Hit Rate –  False Alarm Rate]. 


#### FMRI Data Analysis 
  
Functional data were preprocessed and analysed using the BrainVoyager 1.79 software. We applied slice scan time correction using sinc interpolation and ascending slice scanning order, 3D motion correction using trilinear interpolation, spatial smoothing (8 mm Gaussian kernel), and a temporal high pass filter (3 cycles per time course). Three-D anatomical scans were transformed into Talairach space  , the parameters of which were applied to the coregistered functional data. 

All but one subject completed all four VSTM task runs (one subject completed only three runs due to technical scanning problems), and runs that were unsuitable for analysis were excluded from analysis (two runs in each of two subjects revealed head movements greater than 5 mm). In total, 135 z-normalised volume time courses were entered into a whole brain, random effects analysis of covariance (ANCOVA). Motion-corrected covariates were included in the model in order to optimize the elimination of task-correlated motion artifacts and maximize sensitivity to true activations  , and to reduce inter- and intra-subject variability  . Functional data from all phases of the VSTM task (excluding the ITI) were entered into the analysis model: no distinctions were made between encoding, maintenance, or retrieval phases. In all analyses, regions of activation were determined using the False Discovery Rate (FDR) significance threshold of <.05. To examine emotional expression effects, we computed a repeated-measures ANCOVA (three within-factor levels: angry, happy, neutral) to assess the main effect of emotion, and we also computed specific emotion contrasts (angry - neutral, angry - happy, happy - neutral). In each identified emotion cluster, we conducted random effects GLM region of interest (ROI) analyses to extract beta values that were subsequently applied to statistical comparisons between emotional expression conditions, and correlated with VSTM task performance values. VSTM load effects were examined by contrasting loads 4, 3, and 2 with load 1. A repeated-measures ANCOVA with emotion and load as within factors assessed whether an emotion by load interaction was present at the whole brain level. 


#### Correlation with behavioural data 
  
To examine whether there were any correlations between the magnitude of the angry face effect and brain activity levels, we used the mean behavioural dprime score across all face loads for each emotional expression condition to calculate difference scores for angry minus happy and angry minus neutral face contrasts (based on the angry face advantage observed in the behavioural results). These performance difference scores were correlated with related beta difference scores extracted from emotion-sensitive brain areas. To examine whether there were any correlations between STM capacity and brain activity levels, we calculated Cowan's K capacity estimates at each load [load*(hits – false alarms)]  , averaged across emotion conditions, with related beta values extracted from load-sensitive brain areas. K and beta values were concatenated across all loads for this statistical comparison. Pearson's correlation coefficient (r ) was used in all cases. 




## Results 
  
### Behavioural Results 
  
We conducted an emotion (angry, happy, neutral) by load (1, 2, 3, 4) repeated-measures ANOVA on the behavioural data, expressed in d' values. Consistent with our previous findings  , we found that VSTM performance was significantly modulated by emotional expression,   F  (2, 68) = 3.17,   p   = .048, and that angry faces were significantly better remembered than happy faces (  p  <.05) ( ). It is clear from   that the effect of emotional expression appears most pronounced at face loads 2 and 3, likely due to the fact that we can only store about two face identities in VSTM at any one time  . When only face loads 2 and 3 are analysed, the main effect of emotion becomes more significant (  F  (2, 16) = 4.01,   p   = .02) and the difference between angry and neutral faces also reaches significance (  p  <.05). A significant main effect of face load was observed,   F  (3,102) = 120.38,   p  <.001, but its interaction with emotional expression was not significant,   F  (6, 204)<1.0. 
   Behavioural performance on angry, happy, and neutral trials for all four face loads are displayed as d' (dprime) values.  
A maximum d' value of 4.66 indicates 100% performance, while a d' value of zero indicates performance at chance (50%). Participants performed significantly better on the VSTM task when the identities of angry faces were to be remembered, compared to happy or neutral faces. VSTM performance declined as face load increased for all emotional expression conditions. Bars represent±1 standard error. 
  

### Functional Imaging Results 
  
#### Emotion Effects 
  
Using whole-brain analysis of variance (ANOVA), and an FDR significance threshold of   p  <.05, we found a significant main effect of emotion in three areas of the right hemisphere: superior temporal sulcus (STS), prefrontal cortex (PFC) along the anterior inferior frontal sulcus (IFS), and globus pallidus internus (GPi) ( ). Talairach coordinates are provided in  . There was no main effect of emotion in the left hemisphere. ROI analyses revealed that the main effect of emotion in the STS, PFC, and GPi was driven by significantly enhanced blood oxygen level dependent (BOLD) responses to angry faces (in all regions: angry vs. happy,   p  <.001; angry vs. neutral,   p  <.001) ( ). There were no significant differences between happy and neutral face activations in any of these regions (  p  >.54 in all cases). 
  
(A) Three coronal brain slices show modulation of brain activity by emotional expression of faces in the VSTM task in the superior temporal sulcus (STS), prefrontal cortex (PFC) along the inferior frontal sulcus (IFS), and globus pallidus internus (GPi), all in the right hemisphere. (B) Beta values for each emotion and face load condition are plotted for the STS, PFC, and GPi. Activity is greater for angry vs. happy and neutral face expression conditions in all three brain regions. Bars represent±1 standard error. 
     Talairach coordinates and voxel cluster size values for the main effect of emotion (FDR<.05).      
The angry minus neutral functional contrast showed the same pattern of activation as the main effect of emotion (higher activity for angry than neutral faces in rSTS, rPFC, and rGPi), but in addition this contrast revealed significantly greater angry vs. neutral activity in bilateral fusiform gyrus (  p  <.001 in both cases) ( ). In the right fusiform, analysis of extracted beta values also revealed significantly greater activation for angry vs. happy faces,   p   = .02. There were no load effects in these regions. At whole-brain level, the angry minus happy functional contrast similarly revealed rSTS activity (higher for angry) but did not show any additional regions of activation. No regions showed greater activation for happy vs. neutral faces. Talairach coordinates for the specific emotion contrasts are provided in  . 
   Coronal view shows bilateral fusiform activity obtained from the angry minus neutral contrast (regions outlined by black squares).  
Activity is greater for angry compared to neutral faces. Bars represent±1 standard error. 
     Talairach coordinates and voxel cluster size values for specific emotion contrasts (FDR<.05).        

#### Correlation Between Behavioral and Functional data for Emotion Effects 
  
To test whether higher activation for angry faces reflected a generalized increase in response to angry faces or associated arousal levels, or whether it might represent the very brain mechanism that brings about the angry face benefit in VSTM, we investigated the relationship between brain activity and behavioral data. We correlated the behavioral scores (difference in d') for the angry minus happy and angry minus neutral differences with the corresponding beta value differences in each emotion-sensitive region. In GPi, behavioural difference scores significantly correlated with related beta difference scores in the angry-happy contrast,   r   = .44,   p   = .01 ( ), and marginally correlated with related beta difference scores in the angry-neutral contrast,   r   = .32,   p   = .06 ( ). Superior VSTM for angry faces was thus correlated with enhanced activity in the GPi, suggesting a key role for this region in the angry face benefit. There were no significant correlations between behavioural scores and beta values in STS, PFC, or fusiform regions. Because the behavioural angry vs. neutral benefit was driven by the differences at loads 2 and 3, we re-ran these correlations using just loads 2 and 3. We replicated the angry-neutral contrast marginal correlation between behavioural and brain data in the GPi (  r   = .33,   p   = .06), and additionally found a marginally significant angry-neutral contrast correlation in the right FFA (  r   = .29,   p   = .09) suggesting perhaps some role of this face processing region in the angry vs. neutral benefit. Correlations in all other emotion-sensitive regions yielded a   p  -value greater than .10. We also correlated these behavioural data with related activity in load-sensitive areas and found no significant results. 
   Better performance on the VSTM task for angry versus happy faces (A), and for angry versus neutral faces (B), was correlated with greater activity in the GPi.    

#### Load Effects 
  
We examined load effects by contrasting loads 4, 3, and 2 with load 1, with the view that higher activity at loads greater than 1 indicates a greater draw on resources used to encode and retain multiple face identities in VSTM. Several areas in bilateral dorsolateral, ventrolateral, and medial prefrontal cortex (DLPFC, VLPFC, MPFC), frontal eye field (FEF), inferior parietal sulcus (IPS), fusiform gyrus, and occipital cortex showed significantly higher activation when multiple faces were to be remembered compared to one face in both the right and left hemispheres ( ). These results conform to previous studies of face load in STM  . Interestingly, we replicated the dissociation of load effects between parietal and prefrontal areas described previously  , with activity in parietal areas peaking at load 3 and prefrontal activity rising further towards load 4 in a monotonic fashion ( ). This dissociation was supported by a significant load by region interaction between beta values in right parietal cortex and right PFC,   F  (3, 102) = 16.05,   p  <.001. Talairach coordinates for the load contrasts are provided in  . 
  
(A) Face loads 4 (blue), 3 (green), and 2 (red) were contrasted with face load 1. Several regions of the PFC, the frontal eye fields (FEF), inferior parietal sulcus (IPS), fusiform gyrus, and occipital cortex, in both left and right hemispheres, showed greater activity when multiple faces were to be remembered compared to just one face. Brain regions modulated by emotion in the right hemisphere (pink = emotion main effect; white = angry minus neutral contrast; brown = angry minus happy contrast) are overlain to illustrate the anatomical distinction between emotional expression and face load effects. Some anatomical landmarks are provided to aid navigation: superior frontal sulcus (SFS); inferior frontal sulcus (IFS); silvian fissure (SF); inferior parietal sulcus (IPS); occipito-temporal sulcus (OTS). (B) Beta values from each load condition (averaged across emotions) illustrate the contrast between a monotonic increase of activity with load in right PFC (x = 41, y = 29, z = 26) and peaked activation at load 3 in right parietal cortex (x = 18, y = −69, z = 43). Bars represent±1 standard error. 
     Talairach coordinates and voxel cluster size values for face loads 4 minus 1, 3 minus 1, and 2 minus 1 contrasts (FDR<.05).      
The spatial dissociation of emotion and face load effects on brain activation is particularly striking. Although both emotion and load effects were observed in parts of the right PFC, these areas did not anatomically overlap ( ). Similarly, the load effect in bilateral fusiform gyrus was anatomically different to fusiform activity modulated by the angry minus neutral contrast (the emotion region lies more anterior to the load region). Furthermore, a whole brain statistical analysis did not reveal any areas that showed an interaction between emotion and load. 


#### Correlation Between Behavioral and Functional data for Load Effects 
  
We also examined correlations between STM capacity estimates, as indexed by Cowan's K, and brain activation levels in load-sensitive areas. K capacity estimates (collapsed across emotion conditions) were: load 1 = 0.93 (  SE   = .02  )  ; load 2 = 1.48 (  SE   = .07); load 3 = 1.70 (  SE   = .11); load 4 = 1.71 (  SE   = .13). Significant or marginally significant positive correlations were found in all regions except left VLPFC and right fusiform ( ): as the number of faces stored in STM (K) increased, activity also increased. We correlated these K data with load activity in emotion-sensitive areas and found no significant results, confirming the spatial dissociation between emotion and load effects. 
   Correlation between STM capacity estimates (K) and related beta values in load-sensitive regions. r  values are provided with   p   values in brackets.      



## Discussion 
  
Our behavioral results show that VSTM is significantly enhanced for face identities when faces display an angry compared to a happy or neutral expression, replicating previous findings  . It has been suggested that effects of emotion on memory require time to emerge, allowing effective consolidation of such memories  . Yet here, as in our previous study, we show that the effects of emotion on memory can be more immediate – emotional expression can influence visual short-term memory for faces. 

In the present study, a network of emotion-sensitive areas comprised STS, PFC, and GPi, all in the right hemisphere, in keeping with the view that the right hemisphere is more involved in the processing and generation of emotions and affect than the left  ,  . The specific areas all fit into current models of emotion processing. The STS has been identified as a key area for the extraction of emotional information from faces  ,  ,   and more generally for the evaluation of others' intentions  . The STS has also been specifically implicated in processing various forms of anger  . Regions of the PFC have been implicated in experience   and observation   of negative mood, and higher activity in response to negative than positive images has been evidenced in regions of the right ventrolateral PFC specifically  . Integration of emotional state and STM processes in regions of bilateral PFC has also been reported  . The GPi, a subcortical structure, is a major part of the basal ganglia which, beyond their function in the extrapyramidal motor circuit, are involved in a variety of cognitive functions including emotion processing  . 

What is striking about the present findings is that the right STS, PFC, and GPi were specifically recruited in the service of VSTM for angry faces. The GPi seems to be the main region responsible for enhanced VSTM for angry faces, and this finding concurs with a recent study that showed a positive correlation between increased globus pallidus activity and increased STM capacity for simple objects  . This study also outlined the role of the globus pallidus as an attentional filter that allows only relevant information access to VSTM. It is possible in our study that enhanced GPi activity to angry faces in VSTM might reflect heightened attention to angry faces, driven by the saliency of potential threat. Threat (anger and fear) expressions have frequently been reported as especially good at capturing attention  – , even when task-irrelevant  . However, these studies involve the capture of attention of a single angry face in a display of differently valenced faces, while in our study all faces in any one VSTM trial displayed the same emotion, thus removing any such competition for attention between different expressions. Furthermore, there is also evidence of rapid attentional orienting to happy faces   and more generally to stimuli with high emotional relevance  . Perhaps attention was heightened in general during angry face trials, in order to facilitate encoding and maintenance of person identity information in VSTM in the context of potential threat. 

The prominent role of the GPi, which was the key area where neural activity was significantly correlated with behavioural performance, is in keeping with recent findings on the role of dopamine in recognition of angry expression. Selective impairment of angry face perception has been linked to: lack of dopamine in Parkinson's disease, which affects the information processing capacity of the GP  ,  ; treatment with antidopaminergic drugs  ; and deep brain stimulation of the subthalamic nucleus  , which is directly connected with the limbic part of the GP  . The present study shows that the GPi, one of the main relay stations of the basal ganglia, is not only responsive to emotional stimuli but aids their processing in a way that allows the effective handling of evolutionarily salient information. 

A specific angry vs. neutral contrast also revealed a role for the fusiform gyrus - a face-selective area   - in the angry benefit, wherein BOLD activity was higher for angry than neutral faces bilaterally and for angry than happy faces in the right hemisphere. Modulation of activity in the fusiform region by facial expression has been reported previously during passive viewing, identity matching, and emotion recognition tasks. For example, there is evidence that fearful  – , happy  ,  , and angry faces   elicit greater fusiform activity than neutral faces. However, our study is the first to report modulation of the fusiform gyrus by facial expression during a VSTM task. 

Traditionally, the amygdala has been implicated in the processing of emotional stimuli and in the long-term retention of emotional events or images wherein activity is often suggested to reflect heightened physiological arousal, which is thought to mediate emotional learning via direct and indirect neural pathways subserving short and long-term memory  . In our study, however, we did not find significant influence of the amygdala on the enhancement of VSTM for angry faces. There are a couple of explanations for this. First, the amygdala does not respond selectively to negative emotion: studies have shown activation in response to images of happy and neutral faces  . Thus, it is possible that the emotion contrasts computed here did not reveal modulation of the amygdala if all three emotions recruited this region to the same degree. Second, the angry face effect in VSTM is likely driven by image valence (i.e., negativity) rather than physiological arousal (i.e., excitability). In our previous behavioural study   we showed that music-induced arousal states did not modulate VSTM performance in general nor interact with expression conditions. We also found that arousal ratings, as measured by the Self-Assessment Manikin (SAM) rating scale  , did not differ between angry and happy faces. Our behavioural data thus make a general arousal account of enhanced VSTM for angry versus happy faces less likely. 

With regard to load modulated brain regions, higher activity in the fusiform gyrus can be explained by the larger number of faces in the memory encoding display, and may also reflect the involvement of this area in VSTM processes  . The activation increase in parietal and prefrontal areas reflects their role in supporting the attentional, encoding, and storage requirements of higher memory loads  ,  . Importantly, the bilateral fusiform regions that displayed load effects (e.g., load 4 – load 1; LH: x = −36, y = −66, z = −19; RH: x = 36, y = −66, z = −19) were anatomically distinct from the more anterior fusiform regions that displayed an angry face benefit (LH: x = −32, y = −42, z = −12; RH: x = 43, y = −43, z = −16). Face processing regions in the occipito-temporal cortex have been segregated previously into two distinct regions, the fusiform face area (FFA) and the occipital face area (OFA), the former located more anterior to the latter  . Our Talairach coordinates for the emotion- and load-affected fusiform regions correspond nicely with reported right hemisphere FFA and OFA coordinates respectively (FFA: x = 39, y = −44, z = −18; OFA: x = 39, y = −64, z = −20). None of the other load-related areas showed an additional modulation of their activity by emotional expression. This suggests that the enhancement of VSTM capacity by the angry expression operates mainly through the recruitment of emotion and face processing networks rather than through recruitment of additional neurons in the classical fronto-parietal STM network. The positive correlation between capacity estimates (K) and brain activation levels in most load-sensitive regions in the occipital, temporal, parietal, and frontal cortices, reflecting increased activity as the number of stored faces increased, suggests that activity in both low-level perceptual and higher-level cognitive areas is modulated by the amount of facial information stored in STM. 

We propose a new neural mechanism that supports the angry face benefit in VSTM by facilitating processing and extending memory capabilities. Studies have reported several areas of the fronto-parietal STM network that pose a bottleneck for memory storage at high loads because they cannot respond by further increasing their levels of activity  ,  ,  . Our study suggests that VSTM for faces is not only supported by the recruitment of areas that are modulated by load, but also by areas that respond categorically and automatically to the presence of a certain type of stimulus content, in this case, emotion. In the present study, enhanced VSTM capacity for angry faces would thus have been supported by communication between emotion-sensitive areas (STS, IFS, GPi, and FFA) and face identification and VSTM areas (PFC, IPS, OFA). 

Our findings also provide further perspective to the debate on whether or not there is independence between face identification and emotional expression decoding processes. While some studies have indicated dissociable neural representations for identity processing in the fusiform gyrus and facial expression processing in the anterior STS  ,  , others suggest that neural circuits underpinning identity and expression processes overlap  ,  . We show that, in VSTM at least, the impact of (angry) emotional expression on face identification tends not to be achieved by multi-functionality of one region but by communication between different process-specific regions responsive to face expression or load. The dissociation between anger and load effects in anterior (FFA) and posterior (OFA) regions of the fusiform gyrus respectively is a novel finding, and perhaps suggests a more complex, fine-grained functional organisation of this region in supporting both expression and face identification processes. 

Finally, our discovery of the pivotal role of the GPi at the interface between emotion and cognition may have profound implications for clinical neuropsychiatry. Deficits of social cognition, such as extraction of meaning from facial expressions, may be core elements of the psychopathology of schizophrenia and mood disorders. Whether these are linked to changes in the basal ganglia will have to be explored in future research. The basal ganglia also are the main target of deep brain stimulation for movement disorders and increasingly also for behavioural disorders, and a better understanding of their non-motor functions would be of great clinical importance. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-25'>
<h2>25. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/28592863/' target='_blank'>28592863</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Human cortical activity evoked by contextual processing in attentional orienting</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Sci Rep</p>
<p><strong>Publication Year:</strong> 2017</p>
<p><strong>DOI:</strong> 10.1038/s41598-017-03104-1</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5462779/' target='_blank'>5462779</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social-related processing (attentional orienting to social gaze vs arrow cues; cross-modal social voice target), conducted in healthy adults (n=22, mean age 22.95). The paper reports whole-brain analyses (with FWE correction) as well as ROI/small-volume analyses; it is not ROI-only. Results for the healthy participant group are clearly reported. All inclusion criteria are met and no exclusion criteria apply.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
The ability to assess another person’s direction of attention is paramount in social communication, many studies have reported a similar pattern between gaze and arrow cues in attention orienting. Neuroimaging research has also demonstrated no qualitative differences in attention to gaze and arrow cues. However, these studies were implemented under simple experiment conditions. Researchers have highlighted the importance of contextual processing (i.e., the semantic congruence between cue and target) in attentional orienting, showing that attentional orienting by social gaze or arrow cues could be modulated through contextual processing. Here, we examine the neural activity of attentional orienting by gaze and arrow cues in response to contextual processing using functional magnetic resonance imaging. The results demonstrated that the influence of neural activity through contextual processing to attentional orienting occurred under invalid conditions (when the cue and target were incongruent versus congruent) in the ventral frontoparietal network, although we did not identify any differences in the neural substrates of attentional orienting in contextual processing between gaze and arrow cues. These results support behavioural data of attentional orienting modulated by contextual processing based on the neurocognitive architecture. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (47097 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
The ability to assess another person’s direction of attention is paramount in social communication. For example, we are able to identify a person’s focus based on their eye gaze, thus enabling an understanding of other people’s inner state (such as thoughts, beliefs, and desires) . Similar to eye gaze, non-social stimuli also play important roles in influencing attention, such as an arrow on a road sign. However, compared with eye gazes, non-social directional stimuli are not helpful when making conclusions regarding someone’s cognitive state, such as speculating about what a person wishes to do. 

Over the past two decades, cognitive psychologists have focused on comparing the role of directional gaze and arrow cues in attentional orienting. These studies have typically investigated attentional orienting based on gaze and arrow cues using a modified version of Posner’s cueing paradigm . For example, Friesen and Kingstone  presented non-predictive gaze cues at the centre of a screen prior to the presentation of a peripheral target (right or left). Before the onset of the target, a centrally presented directional cue (e.g., eye gaze) appears on screen. Under valid conditions, the cue will accurately indicate the subsequent target location, whereas under invalid conditions, the cue will indicate the opposite location. A rapid response to a validly cued target indicates an allocation of attention (i.e., orienting) to the target location prior to target onset. In contrast, a delayed response to an invalidly cued target occurs when the onset of the target at the opposite location, indicating a reorienting of attention to the target. Previous studies  have commonly demonstrated that arrow cues automatically trigger attentional shifts in the same manner as gaze cues. These studies have demonstrated that both gaze and arrow cues trigger attentional shifts when they are counterpredictive of a target location , facilitate response time when discriminating the target following the cue , have comparable sensitivity to object-based selection  and the stimulus onset asynchrony between the cue and target . 

Recent neuroimaging studies regarding attentional orienting have attempted to investigate differences in cortical activity between gaze and arrow cues. These studies have focused on two attentional networks (reviewed by ). The dorsal frontoparietal network, with regions centred around the intraparietal sulcus (IPS), superior parietal lobule (SPL)/Brodmann’s area (BA)5, 7, and frontal eye field (FEF)/BA8, may be responsible for orienting of attention to a validly cued target in the cueing paradigm, but also for reorienting attention to an invalidly cued target . The ventral frontoparietal network, with regions centred on the temporoparietal junction (TPJ)/BA39, 40, 22 and ventral frontal cortex (VFC)/BA44, 45, 47 (including parts of the middle frontal gyrus (MFG) and inferior frontal gyrus (IFG)), may only be responsible for reorienting attention. Most previous studies  have demonstrated that the differences in cortical activity associated with social gaze and arrow cues are quantitative rather than qualitative, although some studies  have reported evidence suggesting different mechanisms for these cues. For example, Tipper   et al  .  reported attentional orienting to both eye gaze and arrow cues engaged extensive dorsal and ventral frontoparietal networks, but the magnitude of activation differed between these networks. However, these studies only examined the differences between gaze and arrow cues under simple conditions (e.g. a dot or letter as the target). Given that Birmingham and Kingstone  suggested that the apparent difference in attentional orienting between gaze and arrow cues might be distinguished only when the cues were embedded in a rich environment, it is thus important to examine the differences between gaze and arrow cues under more complex conditions. 

Some studies have highlighted the importance of contextual processing (i.e., the semantic congruence between the cue and target) in attentional orienting when using arrows or eye gaze as cues. Previous studies  have demonstrated that attentional orienting is facilitated through contextual processing when using arrows as cues. For example, Ristic   et al  .  examined attentional orienting based on whether facial gaze and arrow cues could be triggered through the contextual processing of cue-target colour contingencies. The results indicated that attentional orienting elicited by an arrow rather than an eye gaze was sensitive to colour-congruent target stimuli; an attentional orienting effect for blue arrows was only evident for blue targets. However, other studies  have demonstrated that attentional orienting with facial gaze was facilitated through a strongly contextual relationship between the cue and target when there was congruence in meaning between the cue and target. For example, Bayliss   et al  .  reported that compared with disgusted faces, the gaze direction of happy faces more effectively oriented attention to pleasant targets. These findings indicated that participants could employ contextual information in attentional orienting by arrows or eye gaze cues to effectively capture important information, although the context effect might be observed only when targets are presented at a specific context of colour and emotion for gazes and arrows. These findings raised a question regarding whether attentional orienting differs between eye gaze and arrow cues when these cues were influenced through contextual processing. 

At a neural level, researchers have shown activity in the TPJ and superior temporal sulcus (STS)/BA21, 22 associated with contextual processing in attention. Geng and Vossel  reviewed previous evidence, indicating that the TPJ (anatomically, the TPJ is strictly defined as the cortex at the intersection of the posterior superior temporal, supramarginal, and angular gyri) was engaged in terms of “contextual updating” in attention. For example, Weidner   et al  .  demonstrated that cortical activity in TPJ increased when the contextual processing of the relationship between the cue and target was incongruent as opposed to congruent (i.e., when the target-defining dimension (orientation or colour) was incongruently rather than congruently cued). Moreover, Noppeney   et al  .  observed that the activity in STS increased when a sound or speech target was incongruent (e.g., a car picture paired with the spoken word ‘owl’) as opposed to congruent (e.g., a cat picture paired with the spoken word ‘cat’) with prior visual information. This finding indicated that context also modulated the activity of STS. Consistently, when a strong relationship was established between the target word and a word sound that had been previously presented, the results showed the enhanced activation for thematically related categories (e.g., picture + frame) and response suppression for taxonomically related categories (e.g., chair + armchair) in the left STS . In the present study, we focused on these brain regions to examine the influence of neural systems in relation to gaze and arrow cues through contextual processing focused on the relationship between the cue and target in attentional orienting. 

In the present study, we examined the neural activity of attentional orienting with social gaze and arrows as cues using Posner’s cueing paradigm. Based on a previous study , two sounds (a social voice and a tone) were manipulated as targets to determine the contextual relationship between cue and target; that is, social gaze and social voice and arrow and tone as congruent meaning conditions, and social gaze and tone and arrow and social voice as incongruent meaning conditions. The aims of this study are as follows: (1) We first wanted to examine whether the influence of neural activity in TPJ and STS differed between gaze and arrow cues in response to contextual processing of the relationship between cue and target. (2) Furthermore, given that previous studies  have characterised the functional mechanisms of the orienting and reorienting of attention (i.e., valid and invalid conditions) in dorsal and ventral frontoparietal networks, respectively, we considered it important to specifically investigate these functional mechanisms and how they were modulated through the contextual processing of the relationship between cue and target. Specifically, if different neural activity was observed for gaze and arrow in response to the contextual processing of cue-target, we would subsequently examine whether the neural activity for attentional orienting differed with contextual processing between gaze and arrow cues at the dorsal and ventral frontoparietal networks, respectively. In contrast, if no difference between gaze and arrow was evident, we would then examine only the influence of neural activity for attentional orienting by contextual processing in both gaze and arrow cues in these two attentional networks. 


## Methods 
  
### Participants 
  
This research was approved by the local ethics committee of Capital Medical University, Beijing, China. No foreseeable risk to the participants was present, and personal identifying information was not collected. Participants provided written informed consent and background information. All procedures complied with the ethical standards of the 1964 Declaration of Helsinki regarding the treatment of human participants in research. In total, 22 volunteers (9 women, 13 men; mean ± SD age, 22.95 ± 2.61 years) participated. All participants were right-handed, as assessed by the Edinburgh Handedness Inventory , and had normal or corrected-to-normal visual and auditory acuity. 


### Stimuli 
  
Visual and auditory stimuli were almost identical to those used in a previous behavioural study (at a sound level comfortable to each participant) . Previous studies have demonstrated that female faces are less resemblance to angry expressions than male faces, and male faces are perceived as less likeable  and more powerful . To avoid any differential influence of expression (e.g., anger), a Japanese female face with neutral expressions was used for this task (Fig.  ). The image was obtained from a previous study , in which the emotional intensity of facial stimuli with neutral expressions was assessed. The results confirmed that these facial images were considered neutral rather than emotional. Based on these findings, it is reasonable to propose that the female face image in the present study conveyed neutral facial expressions. Moreover, three versions of each face were produced: one version with a direction of gaze straight ahead, another version with the pupils averted leftward, and a third version with the pupils averted rightward. The faces measured approximately 4.7° wide and 6.9° high. For the arrow cue, a symmetrical arrow was presented as the cue stimulus, with an arrowhead at one end and a tail at the opposite end. The arrows measured 4.7° in width by 1.7° in height and were light grey.   
Illustration of the stimulus presentation. 
  

Furthermore, two types of auditory stimuli were presented as targets. One type was sampled from a woman: an/i/voice sound (F0 frequency of 300 Hz), which is similar to the /iy/sound in English. The other type was a pure tone of similar frequency to the F0 voice (300 Hz), which was produced using the Audacity software package (  ver. 1.3.13; Audacity store.com  ). The duration of the stimulus presentation was 150 ms. 


### Apparatus 
  
These stimuli were generated on a computer and presented to the participants via a custom-built, magnet-compatible audio-visual system during magnetic resonance (MR) scanning. To attenuate the acoustic noise that accompanies fMRI (functional magnetic resonance imaging) scanning, shooting earmuffs were used. Participants viewed visual stimuli on a back-projection screen. The auditory stimuli were identical to those presented in a previous study  via an air-conductive tube to participants. Presentation software (ver. 10.2; Neurobehavioral Systems) was used to generate auditory and visual stimuli on a Windows computer. In addition, the participants generated their responses using a keypad (Current Designs Inc., Philadelphia, PA, USA). 


### Procedures 
  
The sequence of stimulus presentation is shown in Fig.  . For each trial, a fixation cross was initially presented for 300 ms in the centre of the screen. A neutral stimulus with a straight eye gaze (gaze trail) or transverse lines (arrow trail) was subsequently presented at the location. After 350 ms, a cue stimulus (gaze or arrow) in the right or left direction was presented in the centre of the screen. The stimulus onset asynchrony (SOA) between the auditory target and cue was fixed to 200 ms. Subsequently, an auditory stimulus target (voice or tone sound) was presented in the left or right ear for 150 ms through headphones. Consistent with previous studies , the participants were asked to answer quickly and precisely whether or not they heard the auditory target on the left or right side of the headphones by pressing the corresponding key on the switch keypad using their dominant index or middle fingers, respectively. Response times (RT) were measured in each trial. A standard procedure for the Posner’s cueing paradigm removed cue stimuli before a target stimulus appeared on the display. However, when using a facial gaze as a cue, many studies e.g. refs   and   also implemented a modified cueing paradigm in which the cue remained on the screen until a response was obtained or a set time had elapsed. For this study, we designed a contextual processing condition between the cue and target. To establish a strong and obvious contextual relationship between the cue and target, the cue remained until a response was obtained or 1000 ms had elapsed. The targets appeared randomly on the same or opposite side of the cue direction when the cue was directed left or right. The target appeared at the cued location in 50% of the trials. The participants were told that the cue did not predict the target location and were instructed to fixate on the centre of the screen in each trial. 

The fMRI analysis relied on a within-subject three factorial design, with the cue condition (gaze or arrow), context condition (i.e., the congruence of meaning between the cue and target, which could be congruent (social gaze and social voice or arrow and tone) or incongruent (social gaze and tone or arrow and social voice)), with validity condition (valid or invalid) as the repeated factors. Sixty trials were performed under each condition. Our experimental design was based on a mixed block/event-related paradigm, facilitating a more complete utilisation of the BOLD signal and enabling a deeper interpretation of how the regions of the brain function on multiple timescales . Consistent with a previous study , alternating blocks of experimental trials of cue condition and blocks of baseline were presented. Within the condition blocks, congruence trials were presented in a pseudorandom event-related distribution. 


### MRI acquisition 
  
The images were acquired using a 3.0-T Trio Tim Scanner-vision whole-body MRI system (Siemens, Erlangen, Germany) to measure activation using a head coil. The functional images comprised 33 consecutive slices parallel to the anterior-posterior commissure plane, covering the entire brain. A T2*-weighted gradient-echo planar imaging (EPI) sequence was used with the following parameters: TR = 2000 ms, TE = 30 ms, flip angle = 90°, field of view = 220 × 220 mm, matrix size = 64 × 64, and voxel size = 3.4 × 3.4 × 3.5 mm . The slices covered most of the brain, including the entire temporal cortex, but excluding the most inferior parts of the cerebellum. We also acquired high-resolution isotropic T1-weighted images (TR = 1900 ms, TE = 2.52 ms, flip angle = 9°, field of view = 250 × 250 mm, 176 sagittal slices, voxel size = 1 × 1 × 1 mm ). 


### Behavioural data analysis 
  
The data were analysed using the SPSS software package (ver. 21.0). Incorrect responses (1.76% of the trials) and RT of less than 100 ms or more than 1000 ms were excluded from the RT analysis (1.18% of the trials), and trials in which a response occurred prior to the target onset were also excluded. The mean RT under conditions was calculated for each participant. The mean RT was analysed using a three-way analysis of variance (ANOVA) with cue (gaze, arrow), context (congruent, incongruent), and validity (valid, invalid) as within-participant factors. To examine whether an interaction was significant, if present, a follow-up simple main effect (i.e. assessing the effect of each independent variable at each level of the other independent variable) analysis was conducted to interpret the result. 


### Image data analysis 
  
Data preprocessing and statistical analyses were performed using the Statistical Parametric Mapping software package (SPM12; Wellcome Department of Cognitive Neurology, London, UK;   http://www.fil.ion.ucl.ac.uk/spm/software/spm12  ) implemented in MATLAB 2013b (Math Works). The functional images from each run were realigned using the first scan as a reference to correct for head movements. The movement parameters generated during spatial realignment indicated that all subjects moved less than 2 mm during the course of the trial. The T1 anatomical image was preprocessed using an intensity inhomogeneity correction. Then, T1 anatomical images were coregistered to the first scan of the functional images. Next, the coregistered T1 anatomical image was normalised to the Montreal Neurological Institute space using a unified segmentation-spatial normalisation approach . The parameters from this normalisation process were subsequently applied to each of the functional images. Finally, these spatially normalised functional images were resampled to a voxel size of 2 × 2 × 2 and were spatially smoothed in three dimensions using an 8-mm full-width-at-half-maximum Gaussian kernel. 

We used random-effects analyses  to identify significantly activated voxels exhibiting interesting effects. First, we performed a single-subject analysis . The BOLD response was modelled as the neural activity, convolved with a canonical haemodynamic response function (HRF), which yielded regressors in a general linear model (GLM) for each condition. We used a high-pass filter comprising a discrete cosine basis function with a cut-off period of 128 to eliminate the artefactual low-frequency trend. To correct the global fluctuation related to motion artefacts, global scaling was conducted. Serial autocorrelation, assuming an AR (1) (first-order autoregressive) model, was estimated from the pooled active voxels with a restricted maximum likelihood procedure and used to whiten the data and design matrix . 

The contrast images from the first-level analyses from all subjects were subsequently used for the second-level group statistics. First, for each participant, the data were best fitted at every voxel using a combination of effects of interest. These data were delta functions representing the onsets of the eight conditions, given by the crossing of our 2 × 2 × 2 factorial design: cue (gaze, arrow) × context (congruent, incongruent) × validity (valid, invalid), convolved with the SPM12 haemodynamic response function. Second, based on the behavioural results, a 2 × 2 × 2 (cue × context × validity) factorial ANOVA was used to investigate the relationship between behavioural results and brain activation. Based on a methods analysis , the statistical maps exhibited a spatial extent threshold at p < 0.05, family-wise error (FWE)-corrected for multiple comparisons, and an intensity threshold at p < 0.001, uncorrected for multiple comparisons at the whole-brain level was used to protect against false-positive activations. The peak voxels of clusters exhibiting reliable effects are reported in MNI coordinates. We had an a priori hypothesis regarding the activity of contextual processing in TPJ and STS, and the influence of contextual processing in dorsal and ventral frontoparietal networks. Based on anatomical masks using the WFU Pickatlas tool, a small-volume correction was also employed to the a priori regions of interest, attributed to the anatomical structures in left/right hemisphere of the STS with BA21, 22, the IPS and SPL with BA5, 7, the FEF with BA8, and the IFG with BA44, 45, 47, separately. Consistent with the whole-brain level, we used small-volume correction at a voxel spatial extent threshold at p < 0.05, FWE corrected, and an intensity threshold at p < 0.001, uncorrected for multiple comparisons. Finally, to quantify neural responses with the influence of attentional orienting under context conditions, we used the MarsBaR software package  to extract percentage changes in BOLD signals for congruent and incongruent contexts under valid and invalid conditions, averaged across voxels with given regions of interest (ROI) using spheres with a radius of 8 mm. Then, the means of the percent signal change (PSC) between the conditions were compared using repeated-measures ANOVA. All statistics were calculated using the SPSS software package (ver. 21). 



## Results 
  
### Behavioural results 
  
The data pertaining to errors did not reveal any significant main effect or interaction (all   p   > 0.05), thus indicating that the participants suffered no speed-accuracy trade-off (Table  ).   
Mean response times (ms), standard deviations, and percent errors (%E) as a function of cue, context, and validity. 
  

The mean RT under each condition are listed in Table  , and the mean differences in RT between the invalid and valid conditions are shown in Fig.  . A three-factor repeated-measures ANOVA was used to analyse the RT. The analysis revealed a main effect of cue (  F   (1, 21) = 12.412,   p   = 0.002,   η   = 0.371), with faster responses under the eye gaze (339.7 ms) versus arrow (351.3 ms) condition. In addition, we also observed a significant main effect of context (  F   (1, 21) = 8.213,   p   = 0.009,   η   = 0.281), with faster responses under congruent (341.3 ms) versus incongruent (349.7 ms) conditions, and validity (  F   (1, 21) = 25.247,   p   < 0.001,   η   = 0.546), with faster responses under valid (334.8 ms) versus invalid (356.2 ms) conditions.   
Response times (RT) results in attentional orienting. Mean (with SE) RT presented for valid and invalid conditions as a function of a cue type condition (gaze or arrow). **  p   < 0.01. 
  

A significant interaction of context × validity was observed (  F   (1, 21) = 4.907,   p   = 0.038,   η   = 0.189), but no significant interaction was detected for cue × context (  F   (1, 21) = 0.166,   p   = 0.688,   η   = 0.008), cue × validity (  F   (1, 21) = 0.048,   p   = 0.828,   η   = 0.002), or cue × context × validity (  F   (1, 21) = 0.108,   p   = 0.746,   η   = 0.005). 

The   post hoc   test revealed a significant difference between context conditions under invalid conditions (  p   = 0.004) but not under valid conditions (  p   = 0.182) with a faster response for congruent (349.9 ms) versus incongruent (362.5 ms) under invalid conditions, indicating an RT benefit for targets that match the context (e.g. social) of the cue under invalid conditions but not under valid conditions. This result suggests that the disengagement of attention from cued locations is facilitated through contextual processing. These findings demonstrated that attentional orienting is modulated through contextual processing only under invalid conditions, enabling the investigation of the neural substrates underlying the behavioural response of the contextual processing between the cue and target in attentional orienting induced by gaze and arrow cues. 


### Supplementary analysis of the influenced by the gender 
  
Because previous studies have reported that gaze-triggered orienting is different between genders (e.g., refs   and  ), we added gender (male, female) as between-participant factor to supplement the influence of the gender based on the main (3-way) ANOVA of RT data analysis, although 22 participants were recruited with gender unbalance including 9 women and 13 men. The results found a significant interaction between gender and the validity (  F   (1, 20) = 9.591,   p   = 0.006,   η   = 0.324) but not between gender and other factors (all   F   (1, 20) ≤ 2.54,   p   > 0.1). However, the   post hoc   test did not reveal a difference between genders under valid or invalid conditions (both   p   > 0.1), although a faster response was observed for valid compared with invalid conditions in both male (323.5 vs. 335.6 ms,   p   = 0.017) and female (351.1 vs. 386.0 ms,   p   < 0.001) participants. Thus, the results of the present study suggest that attentional orienting through contextual processing was not influenced by the gender of the participants. 


### fMRI results 
  
Next, based on the behavioural results, we investigated the patterns of brain activation associated with cross-modal attention. In the primary analysis, we performed 2 cue conditions (gaze, arrow) × 2 context conditions (congruent, incongruent) × 2 validity conditions (valid, invalid) repeated-measures ANOVA. 


### Main effects of cue, validity, and context 
  
In a whole-brain analysis, the gaze trials evoked significantly greater activity than arrow trials in a many clusters of voxels. One of these clusters included the fusiform gyrus (BA 19), extending from the extra-striate visual areas into the occipital and temporal cortices (Supplementary Fig.  , Table  ). In contrast, greater activity for arrow than for gaze trials was observed in the right hemisphere of temporal lobe, including the middle temporal gyrus (BA 37), and the left hemisphere of occipital lobe, including the middle occipital gyrus (BA 19) (Supplementary Fig.  , Table  ). These results were consistent with previous evidence , thus indicating that gaze versus arrow cues increased activation in various occipital and temporal areas, whereas the reverse contrast evoked activation in occipital regions. 

Furthermore, in a whole-brain analysis, invalid gaze and arrow cues evoked a significantly larger response than valid gaze and arrow cues in the left frontal hemisphere and the limbic system, including the inferior and middle frontal gyrus, and the anterior cingulate (Supplementary Fig.  , Table  ). These results were also consistent with those of a previous study  that revealed common activity in the IFG by conjunction analyses to response gaze and arrow cues in attentional orienting. However, activation was not observed by valid versus invalid gaze and arrow cues. 

To highlight the neural underpinnings of RT modulated through contextual processing, we examined the difference between congruent and incongruent contextual meanings of the cue-target. The results of the whole-brain analysis indicated that the congruent condition evoked a significantly smaller response than the incongruent condition in the left hemisphere parietal, including TPJ (BA 40). Additionally, anatomical region-based small-volume corrections revealed significant activation in the temporal lobe, including STS (BA21/22). (Fig.  , Table  ) These findings indicated that activity in left TPJ and STS regions was associated with the contextual processing of the cue-target, but this activation was not observed in the congruent versus the incongruent condition. Furthermore, to examine the differences between gazes and arrows in contextual processing, we investigated whether the neural activity in these regions differed between gaze and arrow cues. The results revealed no significant difference between gaze and arrow cues, indicating that comparable neural activity was elicited by contextual processing between gaze and arrow, thereby influencing valid and invalid orienting within attentional orienting. Next, we assessed the cue condition, focusing on its influence in contextual processing for both gaze and arrow cues in attentional orienting.   
In response to incongruent versus congruent context conditions, exploratory whole-brain analysis indicating that the left TPJ is significantly activated, and small-volume-correction analysis showing that the left STS is significantly activated based on an anatomical mask. A voxel-wise spatial extent threshold   p   < 0.05, FWE-corrected, and an intensity threshold   p   < 0.001, uncorrected, were used. 
    
Main effect of incongruent condition: incongruent > congruent. 
  
BA = Brodmann’s area; FWE = family-wise error; a voxel-wise spatial extent threshold at   p   < 0.05, FWE corrected, and an intensity threshold at   p   < 0.001, uncorrected. 
  


### Interaction of context and validity conditions 
  
A 2 (context: congruent, incongruent) × 2 (validity: valid, invalid) ANOVA was performed to investigate the influence of activation by the contextual relationship of cue-target in attentional orienting networks. The results of the whole-brain analysis revealed a significant interaction in left hemisphere TPJ (BA 40). Additionally, anatomical region-based small-volume corrections revealed significant activation in the left hemisphere IFG (BA 47) regions (Fig.  , Table  ).   
(  a  ) In response to the interaction between context and validity conditions, exploratory whole-brain analysis showing left TPJ significantly activated, and small-volume-correction analysis showing left IFG significantly activated based on an anatomical mask. A voxel-wise spatial extent threshold   p   < 0.05, FWE corrected, and an intensity threshold   p   < 0.001, uncorrected, were used. (b) Mean (±SE) and percent signal changes (PSC) in the left hemisphere TPJ and IFG regions are shown. These areas are overlaid on the mean normalised structural MRI from all subjects in this study. n.s:   p   > 0.05; **  p   < 0.01. 
    
Interaction between context and validity conditions. 
  
BA = Brodmann’s area; FWE = family-wise error; a voxel-wise spatial extent threshold at   p   < 0.05, FWE corrected, and an intensity threshold at   p   < 0.001, uncorrected. 
  


### ROI analysis 
  
The results of the interaction were expanded using an ROI-based analysis. Figure   and Table   present the location and pattern of the response in all ROIs in which a signal change was extracted. These responses were located in left TPJ and IFG regions. The PSC in these regions was analysed using a 2 (context: congruent, incongruent) × 2 (validity: valid, invalid) repeated-measures ANOVA. A significant interaction was observed in the left TPJ and IFG regions. Moreover, the post hoc test revealed that PSC was smaller when the contextual meaning of cue-target was congruent vs. incongruent in all regions under invalid conditions (all   p   < 0.05) but not under valid conditions (Fig.  , Table  ). These results indicated that the influence of contextual processing on the neural activity for attentional orienting was observed under invalid conditions but not under valid conditions.   
ROI results. 
  
ROIs represent previously examined areas that exhibited a significant interaction between context and validity conditions in a 2 × 2 ANOVA (with a voxel-wise spatial extent threshold at   p   < 0.05, FWE corrected, and an intensity threshold at   p   < 0.001, uncorrected).   *p   < 0.05, *  *p   < 0.01. 
  



## Discussion 
  
We examined attentional orienting by gaze and arrow cues under a localising task in which participants were asked to indicate whether the target (voice and tone) was heard on the left or right side of the headphones. The combination of cues and targets varied across trials, reflecting contextual relationship processing, where the contextual meaning of the cue-target was congruent (social gaze and social voice and arrow and tone) or incongruent (social gaze and tone and arrow and social voice). Although the behavioural results showed no difference between gaze and arrow cues, a RT benefit was observed for targets matching the context of the cue under the invalid condition. This finding suggested that a disengagement of attention from cued locations was facilitated through contextual processing. Previous studies  have demonstrated that attentional orienting can be influenced by contextual processing when targets were presented in a specific context (e.g., colour or emotion) for gaze or arrow cues. Compared with a previous study  in which attentional orienting based on a contextual effect for gaze and arrow was investigated in the context of colour (i.e., schematic white/black eyes as the cue and a black square as the target), the present study examined attentional orienting through contextual processing using facial gaze and voice, which seems to more closely resemble a real-world environment. Furthermore, although another study  examined attentional orienting through gaze cues influenced by emotional context for 80 different images (e.g., a chimney image) as targets, the present study only manipulated two sounds as targets, potentially easing the establishment of a pairing between the cue and target. That is, the pairing of gaze and voice was easily established, and arrow and tone represented the other pair. Thus, the present study observed attentional orienting through contextual processing when using gaze and arrow as cues. Based on these findings, the results of the present study extended those of previous studies , indicating that attentional orienting through centrally presented cues, irrespective of cue characteristics (e.g. social or non-social), could also be modulated by contextual relationship processing between the cue and target. 

Importantly, consistent with the behavioural results, the main analyses of fMRI data revealed that neural substrates were not different in response to the contextual relationship processing of cue-target for gaze and arrow cues. Previous studies  have revealed that neural substrates in the regions of the TPJ and STS were associated with contextual processing. Consistently, to highlight the neural underpinnings of RT modulated by contextual processing, the results of the present study also demonstrated that the left STS and bilateral TPJ were specifically involved in contextual processing under both gaze and arrow conditions. The results also indicated that these regions were weakly activated when the relationship of cue-target was congruent (the expected target matching the context of the cue) compared with incongruent (the expected target non-matching the context of the cue). We suggest that these regions may be the locations of an inhibitory mechanism, which enhanced neural activity to suppress the processing of incongruent predictions for targets from cue stimuli. Given that the activity of these regions did not differ between social gaze and arrow cues, we further suggest that a comparable neural system was elicited by contextual processing for gaze and arrow cues and further influenced the attentional process. This idea is consistent with previous studies  that demonstrated the differences in attention to social and non-social cues were quantitative rather than qualitative. 

Interaction analyses in behavioural results indicated that a different pattern of attentional orienting by contextual processing was elicited for valid and invalid conditions. That is, a RT benefit was observed for targets matching the context (e.g. social) of the cue under invalid conditions, but not under valid conditions. We propose that the different patterns between valid and invalid conditions may be influenced through the overlap of the time window between contextual processing and attentional orienting. Electrophysiological studies have demonstrated that the activity of temporal staging differed between valid and invalid conditions . These studies reported an amplitude enhanced at P1 (a positive component at occipital electrode sites between 70 and 100 ms post-target onset) in attentional orienting with gaze as the cue under valid versus invalid conditions, whereas a greater amplitude at P3 (a positive component at central/parietal/midline electrode sites between 300 and 500 ms post-target onset) was observed under invalid versus valid conditions. However, in previous studies , the N300 (a negative component at frontal electrode sites at approximately 300 ms) - N400 (a negative component at central/parietal electrode sites at approximately 400 ms) wave reflected an updating of context information. For example, Demiral   et al  .  observed a stronger N300-N400 effect elicited through a semantic context when the contextual scene was presented before the target in a spatial attention task. Given that the pattern of attentional orienting by contextual processing differed between valid and invalid conditions, we suggest that this finding may be influenced through associations with the activities of temporal staging between the influence of attentional orienting (i.e. the mechanism of valid and invalid conditions) and the contextual processing component. Compared with the early stage (70–100 ms) under valid conditions, the time window of processing overlapped with that of contextual information and attentional orienting under invalid conditions at a later stage (300–500 ms), in which these processes could be integrated to suppress a violation of expectancies (the expected target matching the context of the cue) when the contextual relationship of cue-target was incongruent. In addition, we speculated that varying SOA conditions may influence expectations, and the patterns of attentional orienting by contextual processing for valid and invalid conditions could be modulated in the present experiment. That is, if the target was presented at a short SOA prior to the expectation of the subject, then attentional orienting by contextual processing may not be influenced under valid or invalid conditions, whereas if the target was presented at a long SOA after the expectation of the subject, then attentional orienting by contextual processing might be influenced under invalid conditions. 

Furthermore, the results of the interaction analyses in fMRI also demonstrated the influence of contextual processing on neural activity for attentional orienting under invalid but not valid conditions. Such neural activities were observed in the left hemisphere TPJ and IFG, an area in the ventral frontoparietal network that may be responsible for invalidity orienting (for reviews, see refs   and  ). As mentioned above, analyses of the fMRI data revealed that the left STS and TPJ were involved in the contextual processing of the relationship between the cue and target. The activity in the left TPJ region overlapped in processing the contextual relationship of cue-target and invalidity orienting in attention. Additionally, consistent with the pattern of neural activity for contextual processing in the left STS and TPJ, we observed that when the relationship of cue-target was congruent versus incongruent based on ROI analyses, less activity was observed in all of these brain regions. This result suggests that from the left TPJ to the IFG in the ventral frontoparietal network, neural signals for contextual processing were transferred to invalidity orienting in attention, in which the intrinsic connection pathway is present among these regions . Compared with incongruent conditions, we suggest that the lower activity in the ventral frontoparietal network when the contextual processing of the relationship between cue and target is congruent under invalid conditions may reflect a disengagement of attention from cued locations at a lower cost, which is readily elicited. This idea may explain the behavioural data obtained under invalid conditions, indicating that a lower cost is associated with processing when the contextual processing of the relationship between the cue and target was congruent versus incongruent; thus, participants could disengage attention from the cued location to rapidly capture a target. 

### Implications of the present study 
  
Previous behavioural studies  had demonstrated that attentional orienting by gaze or arrow cues could be modulated through contextual processing. Consistent with these studies, the behavioural results in the present study also revealed that RT in attentional orienting was modulated through contextual processing. In particular, we observed that attentional orienting was modulated through contextual processing under invalid conditions. Given that the present study identified the influence of the neural substrates by contextual processing under invalid conditions in ventral frontoparietal networks, we suggest that this finding may account for the behavioural data regarding attentional orienting through contextual processing based on the neurocognitive architecture. 

In addition, a behavioural study demonstrated impaired attentional orienting when the cue-target relationship is weak (i.e., incongruent context) in individuals with autism spectrum disorder (ASD) , a finding that raises a question regarding whether individuals with ASD exhibit impairment of gaze-triggered attention because activity is impaired in the neural mechanism in the ventral frontoparietal network. Given that impaired gaze-triggered attention may impede and differentially affect the development of the ability to understand the mental state of another individual in social communication , we suggest that an atypical function in the ventral frontoparietal network, particularly in the processing of contextual information, may be associated with the atypical development of social cognition, further suggesting an important direction for future studies combining brain imaging and treatment interventions for social processing deficits in individuals with ASD. 


### Limitations 
  
First, we tested attentional orienting by contextual processing using gaze and arrow as cues with two types of targets (social voice and tone) under only visual-auditory cross-modal conditions. Given the complexity of real life, future studies should examine attentional orienting by contextual processing using two types of targets under visual-visual unimodal or visual-tactile cross-modal conditions in which attentional orienting by contextual processing may also play an important role. 

Second, the present study involved two types of contextually related cues and targets. In contrast with faces and voices, which are immediately paired in a congruent context, the pairing of the tone and arrow might be influenced through the increasing number of trials throughout the experiment. To evaluate this possibility, all experimental blocks were divided into two parts (first and last half of the block), and a four-factor repeated-measures ANOVA (block × cue × context × validity) was used to analyse the RTs. Given that a significant 4-way interaction was observed (  F   (1, 21) = 5.09,   p   = 0.04,   η   = 0.195), two 3-way repeated-measures ANOVA (block × cue × context) was performed under valid and invalid conditions separately. Although no significant interaction was detected for block conditions under invalid conditions, (all   p   > 0.1), we observed that the main effect of context (  F   (1, 21) = 11.74,   p   = 0.003,   η   = 0.36) was significant with faster response to congruent than incongruent conditions (349.0 vs. 361.5 ms), thus indicating that contextual processing between the cue and target was immediately established at both gaze and arrow pairings. However, under valid conditions, although we observed no significant main effect of context (  F   (1, 21) = 1.41,   p   = 0.25,   η   = 0.063), a significant interaction of block × cue × context was observed (  F   (1, 21) = 12.67,   p   = 0.002,   η   = 0.38). The   post hoc   test revealed a significant difference between context conditions (  p   = 0.045) with a faster response to congruent than incongruent conditions (327.4 vs. 346.9 ms) when using arrows as cues in the last half of the block, thereby indicating that attentional orienting by contextual processing could be influenced by increasing the number of trials throughout the experiment under valid conditions when the tone target was matched with arrow cue. In the present study, attentional orienting was modulated through contextual processing under invalid conditions. Thus, we suggest that this effect may be elicited through immediately established pairing between arrow and tone, rather than increasing the number of trials in the experiment. However, future studies should investigate the mechanism of how contextual processing is influenced by increasing the number of trials through the experiment. 

Finally, in the present study, we directly contrasted the context conditions by gaze and arrow cues in invalid and valid trials to reveal differences in attentional orienting. Previous studies  manipulated a neutral cue (e.g. direct gaze) as a baseline condition to examine differences in the neural mechanisms between valid and invalid attentional orienting conditions. However, compared with a non-directional arrow as a neutral cue, Engell   et al  .  suggested that a direct gaze, as a neutral cue, was perceived as directional rather than non-directional, which was problematic in terms of comparing social versus non-social cueing in an fMRI study. Future research should investigate the need for a baseline condition in which the neural gaze and arrow cues involve no spatial information and have the same effect on neural activity, such as closed eyes and non-directional arrows. 



## Conclusions 
  
In this study, we observed that the response time in attentional orienting by gaze and arrow cues was modulated through contextual processing between the cue and target when contextually congruent and incongruent under invalid conditions in behavioural studies. Additionally, on the neural level, activity in the left TPJ and STS was observed with attentional orienting by gaze and arrow cues in response to contextual processing of the relationship between the cue and target. However, we did not observe any difference in the neural substrates between social gaze and arrows by contextual processing in attentional orienting. This finding adds further evidence in support of the notion that the differences in attention to social and non-social cues are quantitative rather than qualitative. Importantly, both behavioural and fMRI results indicated that the influence of contextual processing on neural activity for attentional orienting occurred under invalid conditions. Such an increase was observed in the ventral frontoparietal network when the cue and target were incongruent rather than congruent. This finding may provide an explanation for the behavioural data regarding attentional orienting by contextual processing based on the neurocognitive architecture. 


## Electronic supplementary material 
  




 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-26'>
<h2>26. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/24789353/' target='_blank'>24789353</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> The Neural Basis of Event Simulation: An fMRI Study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2014</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0096534</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4008581/' target='_blank'>4008581</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Meets all inclusion criteria: healthy adult participants (N=20 analyzed, mean age 20.65, right-handed, within 17–65 range) underwent task-based fMRI. The tasks probe social-related processing (explicit situational inference and future prediction) and stimuli included social situations (41/96 stimuli social), with separate analyses for social vs. non-social trials. Whole-brain analyses were performed using SPM8 with cluster-level correction (p<0.001 height, p<0.05 cluster-corrected) and additional reported contrasts (some results noted at uncorrected thresholds but whole-brain inference was used). Results for healthy participants are reported separately and are the focus. No exclusion criteria apply (not ROI-only; not limited to clinical groups). Therefore the study should be included.</p>
<p><strong>Fulltext Confidence:</strong> 0.93</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Event simulation (ES) is the situational inference process in which perceived event features such as objects, agents, and actions are associated in the brain to represent the whole situation. ES provides a common basis for various cognitive processes, such as perceptual prediction, situational understanding/prediction, and social cognition (such as mentalizing/trait inference). Here, functional magnetic resonance imaging was used to elucidate the neural substrates underlying important subdivisions within ES. First, the study investigated whether ES depends on different neural substrates when it is conducted explicitly and implicitly. Second, the existence of neural substrates specific to the future-prediction component of ES was assessed. Subjects were shown contextually related object pictures implying a situation and performed several picture–word-matching tasks. By varying task goals, subjects were made to infer the implied situation implicitly/explicitly or predict the future consequence of that situation. The results indicate that, whereas implicit ES activated the lateral prefrontal cortex and medial/lateral parietal cortex, explicit ES activated the medial prefrontal cortex, posterior cingulate cortex, and medial/lateral temporal cortex. Additionally, the left temporoparietal junction plays an important role in the future-prediction component of ES. These findings enrich our understanding of the neural substrates of the implicit/explicit/predictive aspects of ES-related cognitive processes. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (45347 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
To cope with dynamically changing physical and social environments, both current situations and future transitions must be inferred from fractionally perceived environmental information. Recently, such situational inferences have been proposed to be accomplished when partially perceived event features are associated in the brain to represent the whole situation  – . Those event features include information concerning objects, agents, actions, mental states, and places that constitute a situation. By matching those event features with the event knowledge constructed through the accumulation of experience, the most likely situation is inferred. At the same time, other event features likely to appear in that situation but not perceived at that moment are also inferred based on the event knowledge. Via such completion inference, the whole situation is represented in the brain as a simulation. The situational inference process explained above is called event simulation (ES). ES is thought to provide a common basis for various cognitive processes. Those include simple perceptual prediction, situational understanding/prediction previously termed “event schema/script”, or complex social cognition such as “theory of mind” or trait inference  ,  . Thus, clarifying the detailed neural basis of ES would contribute to our understanding of these cognitive processes. 

Although previous studies have assessed the neural basis underlying ES-related cognitive processes, such as language-based situational understanding  –  and social cognition (e.g., theory of mind (TOM) and trait inference)  – , no study has clarified the ES core, the process in which event features are integrated into a coherent representation of a situation. A few recent studies assessed this ES core more directly  – . In these studies, event features (e.g., objects, agents, and backgrounds) that constitute a situation were presented in words or pictures, and the brain regions that respond to successful integration of these event features were examined. These studies demonstrated that the ES core process recruits the medial prefrontal cortex (MPFC), retrosplenial cortex (RSC), inferior parietal cortex (IPL), dorso-lateral prefrontal cortex (DLPFC), ventro-lateral prefrontal cortex (VLPFC), parahippocampal cortex (PHC), middle temporal gyrus (MTG), and temporal pole (TP). 

Although previous studies have assessed the neural basis of ES as a whole, critical ES subdivisions and the neural basis of those subdivisions have not yet been clarified. For example, whether ES recruits similar or different neural substrates when occurring explicitly versus implicitly remains unclear. ES is sometimes conducted without an explicit intention to do so; this implicit aspect of ES has great significance. For example, in daily life, an individual will usually spontaneously notice his or her own situation. In this case, ES occurs implicitly. On the other hand, although this is often the case in a laboratory experiment, it is rare that an individual will need to explicitly understand a situation in daily life. When “implicit”, the aforementioned process is not assumed to be unconscious. Instead, it is characterized by its spontaneous activation via bottom-up input from the environment, regardless of explicit intentions to do so. Another example of the importance of the implicit aspect of ES is the fact that social phenomena such as stereotypes or prejudices are problematic due to their implicit nature  – . Because these phenomena depend on ES-based trait inference, clarifying the neural mechanisms underlying the implicit aspects of ES would contribute to understanding these social phenomena. In fact, implicit aspects of various cognitive processes and their neural substrates have attracted immense attention in recent years  ,  – . However, previous studies have not differentiated the neural basis of implicit ES from that of explicit ES. Of the above-mentioned studies that directly assessed the ES core, that by Bar et al. employed only an implicit task  . Other studies employed only explicit tasks  – . So, there is an urgent need to differentiate the neural basis of implicit and explicit ES by conducting a comparison in a unified experimental framework. In the present study, we differentiated between the neural substrates of implicit and explicit ES by assuming that two cognitive processes underpin implicit and explicit ES. The first process is recruited by implicit ES (implicit ES process) and is also recruited when ES is conducted explicitly, thus providing a common ground for implicit and explicit ES. The second process is recruited together with the implicit ES process in the explicit ES (explicit ES process). We differentiated brain regions specific to those processes using the following paradigm. In one condition, subjects were shown a picture set of contextually irrelevant objects and performed an object-name-matching task. Unknown to the subjects, contextually related objects, indicating a situation, were occasionally inserted to induce implicit ES. Brain regions that increased their activity in response to this insertion were assumed to be the neural basis of the implicit ES process. In the second condition, subjects were explicitly instructed to infer the situation indicated by objects to demonstrate explicit ES. Brain activation induced in the explicit condition was compared with that induced in the implicit condition to clarify the neural basis of the explicit ES process. Based on previous findings noted above, it was expected that ES as a whole would recruit the MPFC, RSC, IPL, DLPFC/VLPFC, PHC, MTG, and TP. More importantly, it was expected that implicit and explicit ES processes would recruit different subsets of these brain regions. 

Another important aspect of ES is the future-prediction component, but the neural basis underlying this component is not yet known. To cope with dynamically changing environments, not only must the current situation be inferred but the possible future situation must also be predicted. This predictive component plays an essential role in ES. Previous studies that assessed the neural basis of future prediction emphasized that common brain networks are recruited as in episodic memory recall, including the hippocampus, PHC, MPFC, VLPFC, RSC, precuneus, posterior cingulate cortex (PCC), and the temporo-parietal junction (TPJ)  – . Based on these findings, it has been suggested that future prediction and episodic memory recall both depend on a common ‘scene construction’ process  ,  . This process is similar to the completion inference process in ES, as it integrates event features into a coherent situational representation. In addition to this completion inference process, however, future prediction additionally demands representing unexperienced future situations as hypothetical ones. Previous studies have not dissociated this key component of future prediction from completion inference itself. Consequently, the specific neural substrate of this component is still unknown. As for the candidate neural substrates of this component, we expected that the TPJ plays a primary role among the regions previously indicated to be involved in future prediction. This is because the TPJ has been consistently indicated to be involved in representing hypothetical perspective or perspective differences in previous studies on TOM, perspective taking, and self-transcendence  – . In the present study, to extract brain regions specific to representing a hypothetical situation in future prediction, the following paradigm was used. In addition to the above-explained explicit task condition in which subjects were asked to infer a situation indicated by objects, we also used a future-prediction condition in which subjects were asked to predict future situations likely to happen after those indicated by the objects had already occurred. By comparing the brain activity induced under these two task conditions, this study aimed to clarify the neural basis of the future-prediction component of ES. 


## Materials and Methods 
  
### Subjects 
  
Twenty-three healthy volunteers with no psychiatric or neurological history participated in the present study. All were right-handed as assessed using Edinburgh Handedness Inventory  . Written informed consent was obtained from all subjects prior to their participation. Data from one subject were excluded due to head motion and from two subjects because they fell asleep in the scanner. Thus, data of 20 subjects (nine female and 11 male) with an average age of 20.65 years (SD = 2.13) were analyzed. The current study was approved by the ethics committee of the Tohoku University Graduate School of Medicine. 


### Cognitive task detail 
  
Subjects participated in the following three types of matching tasks in the scanner ( ). The first task was the Object task (starts with the cue “Same?”). Following the cue, a picture set comprising three object pictures was presented. After a 4.5-sec delay period, an object name (target) was presented. Subjects were instructed to judge the congruency of the picture set and target object name. If the object name matched one of the three objects the subjects observed in the picture set, they had to respond “yes” by pushing a button with their right index finger. Otherwise, they were told to answer “no” by pushing another button with their right middle finger. Unknown to subjects, this task included two conditions. In half of the trials, the three objects in the picture set were contextually unrelated (control, Con), whereas in the remaining half of the trials, these object pictures were contextually related and indicated a situation (e.g., milk a cow;  ) to trigger an implicit ES (implicit, Imp). The second task was the Situation task (starts with the cue “Situation?”) in which subjects observed an object picture set similar to the Imp of the Object task and a target word depicting a situation. Subjects were asked to explicitly understand the situation indicated by the pictures and to answer whether this situation matched the target word (explicit, Exp). The third task was the Future-prediction task (starts with the cue “After this?”). Again, an object picture set similar to those used in the Imp and Exp conditions was presented to subjects. This time, the subject was instructed to understand the current situation indicated by the pictures (e.g., making a birthday cake) and then infer the possible future situation (e.g., starting birthday party) likely to occur afterword (future prediction, Ftr). The subject responded “yes” if the target word correctly depicted a possible future situation. In all the above conditions, the time course of trials was identical. A 1.5-s cue was followed by a 0.5-s fixation delay and then the object picture set was presented for 4-s followed by a 4.5-s delay period. Subsequently, a target word was presented for 2.5-s followed by a 3.5-s inter-trial rest period. 
   Schematic depiction of a trial for each task and condition.  
In the Object task (cue “Same?”), the subject answered whether one of the three objects presented was congruent with the subsequently presented target word (i.e., object name). Three objects presented in the Con condition were contextually unrelated, and those in the Imp condition were contextually related and indicated a situation. In the Situation task (cue “Situation?”), the subject answered whether the target word was properly depicting the situation indicated by the object pictures. In the Future-prediction task (cue “After this?”), the subject answered whether the target word was properly depicting possible future events of the indicated situation. 
  
To extract the activation associated with the ES process itself (i.e., the activation induced during the picture presentation and subsequent delay) and the activation associated with the target response (i.e., the activation induced after target presentation) separately, “incomplete” trials, which were interrupted after the 4.5-s delay period by showing an “X” sign instead of a target word, were introduced. Subjects were instructed that if they observed the “X” sign, they did not need to respond to any question and were instructed to wait for the next trial. Half of the trials in each condition (Con, Imp, Exp, and Ftr) were randomly presented as incomplete so that subjects could not predict the interruption. The purpose of including these incomplete trials was to increase the orthogonality of the hemodynamic response models between the ES and target response phases. Without incomplete trials, those two models would have considerable degrees of correlation because the ES and response phases occur in a fixed order with a small time separation relative to the time constant of the hemodynamic response function. By including incomplete trials, we were able to observe what happened when the target response phase did not follow the ES phase in half the trials, which allowed us to separate the neural response patterns of these two phases in the analysis. Because only the ES phase was included in the contrast for purposes of statistical testing, the current results are free from the effects related to the target response phase (e.g., recognition of target, matching decisions, semantic priming) that might occur in target processing. 

Each subject underwent two task sessions with 48 trials each (12 trials for the conditions Con, Imp, Exp, and Ftr). Thus, 96 trials (Con: 24 trials; Imp: 24 trials; Exp: 24 trials; Ftr: 24 trials) were presented to each subject. Each condition (Con, Imp, Exp, and Ftr) appeared in a pseudo-randomized order. At the beginning of the experiment, all subjects underwent a practice session outside of the scanner and were assured that they could solve all tasks easily. In this practice session, 12 trials were presented for each of the Con, Exp, and Ftr conditions. In each condition, picture sets different from those used in the functional magnetic resonance imaging (fMRI) session were presented. 


### Post-scanning questions 
  
Following the scanning session, we assessed whether subjects noticed that object pictures were associated with a situation in the Imp condition to ensure that stimuli presented in the Imp condition elicited implicit ES even in the absence of an explicit task requirement. First, subjects were asked the following question: “Did you notice something when you were doing Object task?” Then, they were asked more directly, “Did you notice that sometimes object pictures were associated with a situation in the Object task?” They answered “yes” or “no”. 

Additionally, we determined the extent to which subjects were familiar with the situations they saw in the Imp, Exp, and Ftr conditions. Subjects were asked to rate familiarity using a four-point scale [1 (“Not at all familiar”) to 4 (“Very familiar”)] to ensure that the results were not confounded by differences in familiarity across conditions. 


### Stimulus preparation 
  
We prepared the stimulus sets for the fMRI task paradigm described above in accordance with the following principles. First, stimulus sets were prepared so that all experimental conditions (Con, Imp, Exp, Ftr) involved the same object picture stimuli when averaged across subjects. Thus, observed differences in neural activity across conditions could not be attributed to differences in stimuli-related factors such as low-level visual processing, the object recognition process, or contextual information inherent in the objects themselves. Second, stimulus sets were prepared so that each experimental condition involved different object picture sets at the individual level. This was essential to avoid any noise caused by repetition of the stimulus in different conditions. To meet these criteria, 96 object picture sets in which objects were contextually related to a situation were prepared. The 96 picture sets were divided into four subsets (A, B, C, and D). Thus, each subgroup comprised 24 picture sets. Thereafter, scrambled versions of each subset (Ascr, Bscr, Cscr, and Dscr) were created by shuffling objects within each subset and making them contextually unrelated. Such contextually unrelated scrambled subsets were allocated to the Con condition so as to prevent recognition of the situation in this condition. The other three original subsets were allocated to the Imp, Exp, and Ftr conditions, respectively (e.g., Ascr-Con, B-Imp, C-Exp, D-Ftr). Allocation of those subsets was counterbalanced across subjects. 

Specifically, the following two-stage preliminary experiments were conducted to create the stimulus set described above. Subjects were recruited from the same subject pool (i.e., students from the same university) used for the fMRI experiment. In all, 14 (5 female and 9 male) and 12 subjects (6 female and 6 male) who did not participate in the fMRI experiment participated in the first and second experiments, respectively. Information about the age of one subject in each experiment was missing due to registration failure, and data on the age of the remaining subjects in each experiment are provided below. The average ages for the first and second experiment were 20.92 years (SD = 1.44) and 19.36 years (SD = 0.92), respectively. In the first experiment, object picture sets from which both the current and future situations could easily be imagined were selected, yielding a total of 200 object picture sets. Object pictures were taken by digital camera or obtained from publicly available Internet sources. These objects were limited to non-human objects, such as commodities, vehicles, and animals. No human images (e.g., faces) were included except for ones that appeared as part of another object (e.g., magazine cover). Subjects viewed these 200 picture sets and answered the following two questions for each: 1) Q-scn: “Can you imagine a situation from this picture set?” and 2) Q-Ftr: “Can you imagine the future situation likely to occur after the situation indicated by this picture set?” Subjects answered these questions using a four-point scale [1 (“No, I can't imagine one at all”) to 4 (“Yes, I can imagine one easily”)]. To select picture sets that ranked highly on both questions, mean ratings for each question type were obtained for each picture set, picture sets were ranked according to the lower of the two rankings, and the 96 highest-scoring picture sets were chosen. The average subjects' Q-scn and Q-Ftr ratings for these selected picture sets were 3.94±0.08 [mean ± standard deviation (SD)] and 3.83±0.10, respectively. Subsequently, the 96 picture sets were divided into four subsets (A, B, C, and D) while balancing Q-scn and Q-Ftr scores between them. 

Next, scrambled versions of the object picture sets created above (Ascr, Bscr, Cscr, and Dscr) were generated, and we determined whether these scrambled versions would prevent recognition of the situation. In the second experiment, subjects viewed both the original and scrambled picture sets and rated the likelihood of imagining a situation from those picture sets using the same four-point scale described above. The average ratings of the original and scrambled picture sets were 3.85±0.09 and 1.16±0.15, respectively. A paired   t  -test indicated that scrambled picture sets scored significantly lower than the originals (  p   = 5.22×10 ). 

Among the final 96 picture sets, 41 (42.7%) depicted a social situation. Here, a social situation is defined as a situation in which human interaction or communication is evident   (e.g., wedding dress + tuxedo + wedding cake  =  wedding ceremony). As we noted above, stimulus sets were prepared so that all experimental conditions (Imp, Exp, and Ftr) involved the same stimuli sets when averaged across subjects. Thus, the proportion of social and non-social situations was totally balanced across these conditions. 


### fMRI measurement and image preprocessing 
  
Thirty-three gradient-echo images (echo time  = 25 ms, flip angle  = 78°, slice thickness  = 3 mm, slice gap  = 1 mm, field of view  = 200 mm, matrix size  = 64×64) covering the whole brain were acquired at a repetition time of 2000 ms using an echo planar sequence and a 3-T magnetic resonance scanner (Achieva Quasar Dual, Philips Medical Systems; Best, The Netherlands). 

For each subject, data were acquired in two scanning sessions. Excluding the first two “dummy” volumes for stabilization of the T1-saturation effect, 404 volumes were acquired in each fMRI session. The following preprocessing procedures were performed using Statistical Parametric Mapping (SPM8) software (Wellcome Department of Imaging Neuroscience; London, UK) implemented in MATLAB R2009b (MathWorks; Natick, MA, USA) for whole brain analysis: correction for head motion, adjustment of acquisition timing across slices, spatial normalization using the MNI template, and smoothing using a Gaussian kernel with a full width at a half-maximum of 5 mm. 


### fMRI data analysis 
  
The following series of subtraction analyses were conducted to differentiate the brain regions specific to the implicit and explicit ES processes and to clarify the neural bases specific to future prediction. First, brain regions specific to the implicit ES process were evaluated using the contrast (Imp–Con). In the Object task, subjects were engaged in the same task in both the Con and Imp conditions. However, in the Imp condition, object pictures were contextually indicating a situation, thereby inducing implicit ES. Hence, it was assumed that differential brain activation between these conditions reflected the implicit ES process. Second, brain regions specific to the explicit ES process were evaluated using the contrast (Exp–Imp). As the same object picture sets were shown to subjects in both the Exp and Imp conditions, these conditions commonly induced the implicit ES process. Conversely, only in the Exp condition was the explicit ES process additionally induced because subjects were required to conduct explicit ES in this condition. Hence, it was assumed that the differential brain activation between the Exp and Imp conditions reflects the explicit ES process. Finally, brain regions specific to future prediction were evaluated using the contrast (Ftr–Exp). The same object picture sets were shown to subjects in both the Ftr and Exp conditions. Similarly, both conditions required subjects to explicitly understand the situations indicated by those stimulus sets. Conversely, only in the Ftr condition were subjects additionally required to infer a future situation that is likely to occur after the current situation indicated by the stimulus. Thus, it was assumed that the differential brain activation between the Ftr and Exp conditions reflects a future-prediction component of ES. 

To conduct the series of subtraction analyses depicted above, a conventional two-level approach was adopted using SPM8. A set of regressors was generated by convolving a canonical hemodynamic response function provided by SPM8 with a series of epochs. For each condition (Con, Imp, Exp, and Ftr), the period from the time of picture set presentation to the end of the subsequent 4.5-s delay was modeled as the regressor of interest. Additionally, the target (or “X” mark) and inter-trial rest period were modeled individually as regressors of no interest. These regressors of no interest were not included in contrasts for statistical inference. A voxel-by-voxel multiple regression analysis of these regressors was applied to the preprocessed images for each subject. Statistical inference on contrasts of parameter estimates was then performed at the second-level between-subjects (random effects) model using a one-sample   t  -test. The statistical threshold was set to   p  <0.001 for height and corrected to   p  <0.05 for multiple comparisons using cluster size assuming the whole brain as the search volume  . Additionally, results surviving a threshold of   p  <0.001 without multiple comparisons in two regions are reported here; namely, the PHC and the TPJ. This is because their contribution to ES was expected based on previous findings (see the  ). 

To reject the possibility that the brain activation detected in the main subtraction analysis was due to the difference in task difficulty between conditions, an additional parametric modulation analysis using response times (RTs) as an explanatory variable was conducted. It was reasoned that if the brain activation detected in the main subtraction analysis reflected the difference in task difficulty or general cognitive load commonly recruited in the two conditions included in a contrast, then the activation of these regions should be correlated with RTs in the relative control condition of that contrast. The direction of the correlation should be positive if RTs in the target condition were longer than those in the relative control condition and vice versa. This possibility was evaluated as follows. A parametric modulation analysis was conducted that sought brain regions in which activity was correlated positively or negatively with RTs in each condition. This was performed by expanding the original model used in the main analysis by adding RTs for each condition as parametric modulators. Next, if RTs differed between the two conditions included in a contrast in the main analysis, we determined whether each peak voxel detected in that contrast also appeared as RT-correlated areas in the relative control condition at the statistical threshold of uncorrected   p  <0.05 in the second analysis. 

As the explicit ES process-specific brain regions revealed by the contrast (Exp – Imp) were well known social cognition-related regions (see  :  )  ,  , we examined whether this result was affected by the social factor of task stimuli (i.e., whether the object picture set indicated a social or non-social situation). To clarify this issue, we conducted another additional analysis in which the effects of (Exp – Imp) in social events and that in non-social events were tested separately. First, trials in Imp and Exp conditions were split into ones that indicated social and non-social situations (i.e., Imp_social, Imp_nonsocial, Exp_social, and Exp_nonsocial), and modeled as separate regressors, respectively. Then, the two contrasts (Exp_social – Imp_social) and (Exp_nonsocial – Imp_nonsocial) were tested. If the original (Exp – Imp) comparison was not affected by social factors and rather reflected general situational inference load, then both new social and non-social contrasts would replicate the activation pattern seen in the original comparison. Considering that sample trial number in each condition was reduced in this analysis, the statistical threshold was set to p<0.005 without multiple comparisons. 
   Activation areas specific to the implicit and explicit event simulation (ES) processes.  
All voxels except for the regions described below are significant at a statistical threshold of   p  <0.001, corrected to   p  <0.05 for multiple comparisons using the cluster size, assuming the whole brain as the search volume. The result of the left parahippocampal cortex in the explicit ES process is thresholded at   p  <0.001 (uncorrected). Error bars indicate standard deviations (SDs). IPL: inferior parietal lobule. PCC: posterior cingulate cortex. RSC: retrosplenial cortex. R: right. L: left. The coordinates in the Montreal Neurological Institute (MNI) standard space are indicated. 
  
The fMRI and behavioral data used in the above analysis are available to all interested researchers upon request (contact the corresponding author). 



## Results 
  
### Behavioral data 
  
The accuracies of the conditions Con, Imp, Exp, and Ftr were 96.25±6.33%, 95.00±6.28%, 97.50±3.92%, and 89.58±9.32%, respectively. A one-way analysis of variance (ANOVA) indicated a significant effect of condition;   F  (3,76) = 5.8678 (  p  <0.01).   Post hoc   Bonferroni's multiple comparison tests revealed that this difference was due to the lower accuracy in the Ftr condition than in the Con (  p  <0.05) and Exp (  p  <0.05) conditions. 

Second, the RTs for the Con, Imp, Exp, and Ftr conditions were 1059.62±214.51 ms, 998.61±197.03 ms, 1007.82±197.13 ms, and 1246.55±204.59 ms, respectively. A one-way ANOVA indicated a significant effect of condition;   F  (3,76)  = 39.418 (  p  <0.01).   Post hoc   Bonferroni's multiple comparison tests revealed that the RTs in the Ftr condition were significantly longer than were those in the Con (  p  <0.01), Imp (  p  <0.01), and Exp (  p  <0.01) conditions. Additionally, the RTs in the Con condition were longer than were those in the Imp condition (  p  <0.05). No statistically significant RT difference was found between the Imp and Exp or the Con and Exp conditions. 

Post-scanning questions revealed that subjects noticed that object pictures were associated with a particular situation in Imp condition. In response to the first question, 16 of 20 subjects (80%) mentioned that they saw some object picture sets that indicated a situation in the Object task. This proportion increased to 100% when subjects were more directly asked, in the second question. This clearly indicates that implicit ES was elicited in the Imp condition even in the absence of an explicit task requirement. 

Subjects' familiarity with situations presented in the Imp, Exp, and Ftr conditions were 2.73±0.72, 2.80±0.66, and 2.70±0.52, respectively. A one-way ANOVA revealed no statistically significant difference. Thus, the current results are not confounded by differences in familiarity. 


### fMRI data 
  
#### Implicit ES process-specific areas 
  
Implicit ES process-specific regions were evaluated using the contrast (Imp–Con). A statistically significant activation was found in the bilateral IPL, left middle temporal gyrus (MTG), bilateral anterior VLPFC, right DLPFC, and bilateral precuneus ( ;  ). In the right DLFPC region, the activation peak was located at the lower end of the middle frontal gyrus (MFG) whereas the cluster itself spread over both the MFG and inferior frontal gyrus. Because the 1  cluster right IPL reflected task difficulty between conditions rather than implicit ES processes (see below), the activation profile of the 2  cluster/1  peak (left IPL) is shown in  . 
   Clusters of activation.        

#### Explicit ES process-specific areas 
  
Explicit ES process-specific regions were evaluated using the contrast (Exp–Imp). A statistically significant activation was found in the dorsal/ventral MPFC and adjacent ACC, bilateral TP, left PCC and adjacent RSC, and left TPJ (  and  ). Additionally, a significant activation was found in the left PHC at a threshold of   p  <0.001 (uncorrected). Although this region did not survive the multiple comparisons analysis, it is reported due to the hypothesis describing PHC involvement in ES, which was based on previous findings (see the  ). The activation profile of the 1  cluster/1  peak (left PCC/RS) is shown in  . 


#### Future-prediction-specific areas 
  
Future-prediction-specific regions were evaluated using the contrast (Ftr–Exp). A statistically significant activation was found in the left TPJ at a threshold of an uncorrected   p  <0.001 ( ;  ). Although this region did not survive the multiple comparisons analysis, it is reported for two reasons: first, due to the hypothesis concerning TPJ involvement in future prediction (see the  ); second, the   p   value of this region after correction was close to significance (  p   = 0.06). The activation profile of the 1  cluster/1  peak (left TPJ) is shown in  . 
   Activation areas specific to future prediction.  
The result is thresholded at   p  <0.001, corrected to   p  <0.06 (  k   = 133) for multiple comparisons. Error bars indicate SD. TPJ: temporoparietal junction. R: right. L: left. The coordinates in the MNI standard space are indicated. 
  

#### Additional parametric modulation analysis 
  
Behavioral data showed that RTs differed between conditions in the contrast (Ftr – Exp). RTs in the Ftr condition were longer than those in the Exp condition. If the brain activation revealed by the contrast (Ftr – Exp) was caused by increased ‘general’ task difficulty or cognitive load reflected in longer RTs, then the activity of these regions should have been greater when trial RTs were longer even within the Exp condition. In other words, the activity in these regions should have been positively correlated with trial RTs in the Exp condition. We looked into this possibility by conducting an additional parametric modulation analysis which sought the brain regions in which activity was positively correlated with trial RTs in the Exp condition (thresholded at uncorrected p<0.05) and assessed whether the left TPJ peak revealed by the (Ftr – Exp) contrast fell within these regions; this was not the case. Thus, the left TPJ activity reflected a qualitative difference in cognitive processes between the Ftr and Exp conditions (i.e., future prediction) rather than an increase in general task difficulty or cognitive load. 

Similarly, RTs differed between conditions in the contrast (Imp - Con). This time, RT in the Imp condition was shorter than that in the Con condition. Thus, following similar logic as above, if brain activations revealed by the contrast (Imp – Con) just reflected a decrease in general task difficulty or cognitive load in the Imp condition, the activity in these regions should have been negatively correlated with RTs in the Con condition. We examined this possibility by conducting an additional parametric modulation analysis which sought the brain regions in which activity was negatively correlated with RTs in the Con condition (thresholded at uncorrected p<0.05) and assessed whether activation peaks found in the contrast (Imp – Con) fell within these regions. The right IPL, left MTG, and right anterior VLPFC met that criterion ( ; right-most column), indicating that these regions' activity could have reflected differences in general task difficulty or cognitive load between the Imp and Con conditions. In contrast, other regions revealed by the contrast (Imp – Con) reflected a qualitative difference in cognitive processes between these conditions (i.e., implicit ES process). 


#### Additional analysis to assess the effect specific to social situations 
  
Brain regions specific to the explicit ES process in social events and those specific to non-social events were separately evaluated by testing the contrasts (Exp_social – Imp_social) and (Exp_nonsocial – Imp_nonsocial), respectively. Both tests replicated similar activation patterns observed in the original (Exp – Imp) comparison (see  ). Thus, we suggest that the explicit ES process-specific regions we showed above ( ) reflect general situational inference processes rather than any social situation-specific factors. 




## Discussion 
  
In the present study, the neural basis of ES, or the process by which partially perceived event features are associated in the brain to represent the whole situation, was clarified. Two major findings were revealed by this study. First, implicit and explicit ES processes depend on different neural substrates. Second, the future-prediction component of ES increases the activity of the left TPJ among those ES networks. These issues are discussed in detail in the following sections. 

### Implicit versus explicit ES 
  
The present results suggest that implicit and explicit ES processes depend on different neural substrates. The implicit ES process, which provides the common ground for implicit and explicit ES, recruits the left anterior VLPFC, right DLPFC, bilateral precuneus, and left IPL. Conversely, the explicit ES process, which characterizes the explicit ES, recruits the dorsal and ventral part of the MPFC and its adjacent ACC, left PHC, bilateral TP, left PCC/RSC regions, and left TPJ. In addition to the regions stated above, the right IPL, left MTG, and right anterior VLPFC were also associated with the implicit ES network. However, those regions reflected the difference in task difficulty between conditions in that contrast rather than the ES itself. Thus, those regions are not discussed. 

The neural basis of implicit and explicit ES processes has not been distinguished thus far. The current findings provide the first evidence of such a dissociation and contribute to an understanding of the neural mechanisms underlying ES. Because ES provides the common basis for various cognitive processes from situational understanding to social cognition, clarifying its neural basis in terms of both implicit and explicit aspects is of great significance. For example, an understanding of the neural mechanisms underlying the implicit and explicit aspects of various social cognitive processes would be enriched. The difference between explicit and implicit processes in social cognition has been of great importance for many years, and clarification of the neural bases of these processes will have important ramifications  ,  ,  . The C-system/X-system model proposed by Lieberman   et al  . is well-known  ,  . This model comprises a list of brain regions recruited in implicit and explicit processes and was constructed by reviewing the literature on social cognition and related cognitive processes. In this model, the orbitofrontal cortex, basal ganglia, amygdala, lateral temporal cortex, and dorsal ACC regions are classified as the implicit/X-system. Conversely, the lateral prefrontal cortex, medial temporal lobe (MTL), rostral ACC/MPFC, and lateral/medial posterior parietal cortex (PPC) comprise the explicit/C-system. The current results provide additional information regarding this distinction of implicit/explicit systems from the viewpoint of ES. These findings confirm, in part, the present C-system/X-system model by showing that the explicit process recruits the MPFC, MTL, and PPC. Furthermore, within these regions, the lateral PPC was recruited not only by the explicit process but by the implicit process as well. The explicit and implicit processes activated different subregions within the lateral PPC. Similarly, it was found that different subregions in the medial PPC were recruited by the explicit and implicit processes, respectively. These findings will help to elaborate the current C-system/X-system model and might enrich our understanding of the neural substrates of social cognitive processes, particularly those such as stereotyping or prejudice, in which implicit aspects play a substantial role. 

The regional distinction of the implicit/explicit network revealed here is supported by previous studies investigating ES-related cognitive processes. For example, the present study revealed that the left anterior VLPFC is engaged in the implicit process, and lesions in the VLPFC are known to reduce implicit stereotypical attitudes  . Because stereotyping is one type of trait inference based on ES, this finding is consistent with the current findings. Similarly, a previous study demonstrated that the MPFC is engaged in the explicit theory-of-mind process, whereas the DLPFC is engaged in implicit theory-of-mind  . This distinction is also consistent with the current results. Further evidence has shown that the MPFC is involved in the explicit aspects of theory of mind. This region was activated more when subjects believed they were playing games with a human opponent compared with a computer program  ,  . Similarly, this region is known to be activated more in children than in adults when understanding others' minds, reflecting a greater explicit process in children  . 

Finally, the left PHC is engaged in the explicit ES process. This seemingly contradicts Bar   et al  .'s findings that the PHC is recruited during contextual processing of situation-related objects in the implicit task  . However, in the same study, the posterior part of the PHC processed place-related contextual information (e.g., a farm), whereas the anterior part processed more complex contextual information (e.g., a birthday), which is similar to the current findings. This anterior part was activated only when subjects were explicitly instructed to process such contextual information  . Actually, this anterior part was comparable to the region identified in this study; hence, the findings of Bar   et al  . are consistent with the present results overall. In short, the implicit/explicit ES network suggested in this study is well supported by previous reports and will enable generation of an overview of this phenomenon. 


### The left TPJ and future prediction 
  
The present results suggest that the left TPJ plays an important role in representing hypothetical situations, which characterizes future prediction. Because predicting future situations from fractionally perceived environmental information is essential to cope with a dynamically changing environment, clarifying the neural basis of such a process has great significance. Our suggestion is supported by the fact that the left TPJ was consistently involved in representing hypothetical perspective or perspective differences in previous studies on TOM, perspective taking, and self-transcendence  – . Interestingly, in the present study, left TPJ activation was also detected as an explicit ES process-related region, along with other regions such as the MPFC, TP, and PCC. We are not certain if this explicit ES process-related left TPJ is exactly the same region as the left TPJ we found to be future prediction-specific. If the explicit ES-process and future prediction recruit the same left TPJ region, it could be that the left TPJ basically engages in explicit ES, and when future prediction requires an additional load to represent a hypothetical situation, the left TPJ boosts its activity for perspective processing. In the present study, we observed future prediction-specific activity in the left but not right TPJ. This kind of left dominance has been reported in relation to the linguistic nature of the task in previous studies on perspective processing  ,  . In the present study, targets of the matching task were presented in words, so it is possible that after the subject inferred a future situation from object pictures they sought the proper word (i.e., name) for that situation. This linguistic load of the task could account for the TPJ's left dominancy in the present study. 

Given that subjects were less accurate and had a longer RT in the Ftr condition than in the Exp condition, one might think that the left TPJ activity identified with the contrast (Ftr – Exp) simply reflects the effect of general task difficulty or cognitive load which was relatively greater in the Ftr condition. However, we think this is unlikely because of the following reasons. First, we directly showed that activity in the left TPJ was not correlated with RTs, which reflect general cognitive load common to both the Ftr and Exp conditions, by conducting an additional parametric modulation analysis. Furthermore, previous studies showed that TPJ activity reflecting general cognitive load, such as attention or control demand, is right dominant  – . So, if the left TPJ activity in our study reflected an increase in general cognitive load in the Ftr condition, it would be unlikely for us to not to also observe this activity in the right TPJ. 

As subjects were required to match the future situation they inferred from object pictures to target in the Ftr condition task, one might think that the left TPJ activity observed in this condition would reflect subjects' intention to infer a future situation that the experimenter had in mind. However, we think that this is unlikely due to the following reasons. First, our task did not require subjects to hit the correct answer in the first place, and did not provide any feedback on hits or misses. Thus, subjects' motivation to infer the correct answer that the experimenter had in mind should have been very low. Second, if some of the subjects were inclined to infer how the experimenter labeled stimulus situations, then this should also be true in the Exp condition. Thus, it is unlikely that such a process is reflected in the activation derived from the comparison (Ftr – Exp). 



## Conclusions 
  
In conclusion, these findings show that implicit and explicit ES processes have different neural substrates and that the left TPJ plays an important role in the future-prediction process of ES. It is assumed that the implicit, explicit, and future-prediction sub-processes and their underlying neural substrates collaborate to support ES. Because ES is thought to provide a common basis for various cognitive processes ranging from simple perceptual prediction to complex social cognition, such as theory of mind, these findings enrich the understanding of the neural substrates of the implicit/explicit/predictive aspects of those cognitive processes. Moreover, it is proposed that these results provide a good reference point for future studies that aim to elucidate a unified explanation for these cognitive processes from the viewpoint of neuroscience. 


## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-27'>
<h2>27. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/18431500/' target='_blank'>18431500</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Cooperation and Deception Recruit Different Subsets of the Theory-of-Mind Network</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2008</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0002023</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/2295259/' target='_blank'>2295259</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study meets all inclusion criteria: it used functional MRI while participants performed a social-related Theory-of-Mind task (cooperation/deception scenarios — Perception/Understanding of Others). Participants were healthy adults (n=13, ages 22–38). The paper reports an exploratory whole-brain analysis (ToM conditions vs. non-ToM) and subsequently ROI analyses — meaning whole-brain results are available (inclusion allowed when both whole-brain and ROI analyses reported). No exclusion criteria apply (not restricted to clinical groups or ROI-only reporting). Therefore the study should be included.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
The term “theory of mind” (ToM) describes an evolved psychological mechanism that is necessary to represent intentions and expectations in social interaction. It is thus involved in determining the proclivity of others to cooperate or defect. While in cooperative settings between two parties the intentions and expectations of the protagonists match, they diverge in deceptive scenarios, in which one protagonist is intentionally manipulated to hold a false belief about the intention of the other. In a functional magnetic resonance imaging paradigm using cartoons showing social interactions (including the outcome of the interaction) between two or three story characters, respectively, we sought to determine those brain areas of the ToM network involved in reasoning about cooperative versus deceptive interactions. Healthy volunteers were asked to reflect upon the protagonists' intentions and expectations in cartoons depicting cooperation, deception or a combination of both, where two characters cooperated to deceive a third. Reasoning about the mental states of the story characters yielded substantial differences in activation patterns: both deception and cooperation activated bilateral temporoparietal junction, parietal and cingulate regions, while deception alone additionally recruited orbitofrontal and medial prefrontal regions. These results indicate an important role for prefrontal cortex in processing a mismatch between a character's intention and another's expectations as required in complex social interactions. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (41032 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
The term “theory of mind” (ToM) describes both the ability to understand and predict the behavior of other people by making inferences about their mental states, their intentions, feelings, expectations, beliefs or knowledge, and to cognitively represent one's own mental states  . It is widely acknowledged that ToM evolved in hominids in response to the increasing complexity of social interactions, representing a powerful cognitive tool to determine whether or not a conspecific is willing to cooperate and reciprocate  , or tends to intentionally deceive and defect at the expense of others  . In humans, this cognitive mechanism is more or less permanently “online”, to the extent that we sometimes ascribe mental states to inanimate objects such as cars, computers etc  . Given that ToM requires quite large computational resources, it is not surprising that a dysfunction of the ToM mechanism is involved in a variety of neuropsychiatric disorders, including autism and schizophrenia and may cause severely compromised social competence in patients with such conditions  – . 

A number of functional brain imaging studies have revealed that ToM involves an extended neural network located in the frontal, temporal and parietal lobes bilaterally  ,  . Specifically, ToM recruits several cortical midline structures, including the medial prefrontal cortex (MPFC), the anterior cingulate (ACC), and the precuneus as well as lateral areas of the middle temporal lobes (MTL), the temporoparietal junction (TPJ), the superior temporal sulcus (STS) and the temporal poles (reviewed in  ,  – ). The area extending from the anterior cingulate cortex to the anterior frontal pole, particularly the paracingulate cortex, is supposed to be engaged in self-reflection, person perception and in making inferences about others' thoughts  . Furthermore, regions near the temporoparietal junction (TPJ) are thought to be involved in reasoning about the contents of another person's mind  ,  , attribution of a character's actual belief or state of knowledge  ,   and the discrimination between self and others  . Although hemispheric specialisation has been observed, the results are contradictory: while some studies found selective activity in right TPJ  ,  , others showed left TPJ to be necessary for representing other persons' beliefs  ,  . The mPFC and the ACC are thought to help distinguish self from other, to be engaged in error monitoring, and to differentiate salient from non-salient stimuli  ,  ,  . The role of the precuneus is less well known, but this brain area seems to be important for the experience of agency and self-consciousness  ,  . The temporal regions around the STS contain mirror neurons that play a decisive role in imitation and learning as well as in recognition of intentional movements  ,  . In addition, amygdalar, insular and orbitofrontal activity may contribute the affective “tone” to the evaluation of thoughts and intentions  . For example, the insula has been shown to be activated if unfairness is being recognised  . 

A prototypical task used in ToM research has been the ”false belief task”, which requires the subject to predict where a character will look for an object that has been displaced by another character unbeknownst to the first character. While successful performance in this task is considered a milestone in the development of ToM in young children  ,  , it does not entail “higher order” processes in the framework of interpersonal expectations and intentions such as beliefs of a character about the mental states of a third party–which is crucial to determine whether or not a person has an understanding of the intentions of others (i.e. “ I know that X does not know that Y wants to cheat upon him, and that Y knows that X cannot know what Y really intends to do”). 

It is as yet unknown whether an individual's understanding of another person's mental states about cooperative or deceptive intentions of a third party, resulting from false or true interpretations of the third party's actions and behavior, are processed in discrete brain regions of the ToM network. In this study, we therefore sought to examine whether a subject's evaluation of cooperative and deceptive interactions between two or three story characters elicits differential activation patterns within the ToM neural network. 

Accordingly, healthy participants were shown cartoon stories depicting scenarios of cooperation, deception or both; the participants' task was to attribute intentions and beliefs to the protagonists. The stories described either a) situations where one person wants another to cooperate to the advantage of both, b) situations where one person deceives another person, and c) situations where two persons cooperate to deceive a third person. Since the outcome of the scenarios was visible to the participants, the experimental design was suitable to examine the test subject's ability to represent a “true” or “false” belief held by one of the story characters. Moreover, the deception condition overtly signalled unfairness, whereas the cooperation condition clearly depicted reciprocity and fairness. By means of fMRI we investigated whether these concepts draw on different brain regions, i.e. whether the representation of a character's erroneous belief in the (unfair) deception condition recruits different brain regions compared to the mental representation of a character's correct inference of intentions in the (reciprocal) cooperation condition.. In addition, the combined cooperation/deception stories were introduced to determine brain regions commonly activated by the formation of a cognitive representation of both a cooperative and deceitful intention. In an additional baseline condition, we showed the same cartoons in jumbled order, the task of the participants was to answer questions regarding physical properties of the stimuli. 

Since involvement of temporoparietal junction and precuneus in intention and belief attribution has repeatedly been demonstrated, we expected these regions to be activated across all scenarios. In contrast, we hypothesised that the representation of a scenario depicting a character's concealed deceitful intention would recruit additional brain activation  . As a potential candidate for these more complex scenarios we predicted that the medial prefrontal cortex would be more strongly activated due to its involvement in disambiguating information, including discrepancies between one's own expectation and others' (covert) intentions  . Moreover, we expected that limbic and orbitofrontal structures such as the insula would differentially be activated by the deceitful scenario, which was associated with a high level of unfairness. We also assumed that increasing complexity of the social interaction in scenarios describing both cooperation and deception and an interaction of three characters would lead to more widespread brain activation due to the higher processing load involved. 


## Results 
  
### Imaging 
  
We analyzed results by directly contrasting all three types of stories, cooperation (COOP), deception (DEC) and cooperation/deception (COOPDEC) with each other, using a height threshold of p<0.02 and an extent threshold of k = 15. The contrasts were calculated for the ROIs derived from the preceding exploratory whole-brain analysis that compared activation during the ToM tasks with activation during the non-ToM tasks. These ROIs encompassed superior, medial and inferior frontal regions, and ACC, insula, as well as parietal and temporal regions including the TPJ and precuneus. In several of these ROIs, mentalizing about stories with a deception element yielded differential activation from mentalizing about stories with a cooperation element. Other regions were commonly activated by both types of stories, with spatially distinct peaks of activation (see   and  ,  ). 
   Brain activation in frontal, temporoparietal and temporal regions.  
Activation patterns are rendered on the brain surface in the contrasts of stories describing deception (DEC), cooperation (COOP) and both (COOPDEC). n = 13, extent threshold k = 15; height threshold p<0.02. 
     Brain activation in medial frontal, cingulate and parietal regions.  
Brain activation patterns are shown for the contrasts of stories describing deception (DEC), cooperation (COOP) and both (COOPDEC). n = 13, extent threshold k = 15; height threshold p<0.02. 
     Contrasts of the ToM task conditions cooperation (COOP), deception (DEC), and cooperation/deception (COOPDEC) (n = 13; height threshold p<0.02, extent threshold k = 15).        
As expected, stories containing both cooperation and deception elements recruited the largest regions, in comparison to the other conditions. Specifically, brain activation patterns of the stories containing both elements (COOPDEC) tended to show higher BOLD responses in the majority of ToM-activated regions, i.e. in bilateral TPJ, right anterior temporal cortex, left inferior and superior frontal cortex compared to COOP and DEC, respectively. These results suggest that the processing load for the more complex situation depicted in the COOPDEC scenarios might be higher than for the more straightforward one-to one interactions. 

Compared to DEC>COOP, the contrast COOPDEC>COOP showed larger activation in bilateral temporoparietal regions, while both contrasts yielded similar activation in inferior and superior frontal gyrus. Compared to COOP>DEC, the contrast COOPDEC>DEC shows larger activation in inferior frontal gyrus and righthemispheric parietal and temporal regions. 

#### Frontal activation 
  
The results from direct contrasts between stories containing elements of deception or cooperation or both showed differential activation patterns. Participants showed higher medial (lefthemispheric BA 9 and 10) and left inferior frontal (BA 47) activation when mentalizing about stories containing an element of deception compared to cooperation. On the other hand, mentalizing about cooperation alone, but not about the combined cooperation/deception stories, led to higher activation in superior frontal gyrus (lefthemispheric BA 9 and 10) when compared to deception alone. 

Moreover, within stories containing an element of deception, superior and medial prefrontal activation (left hemisperic BA 9) was higher in DEC compared to COOPDEC, while inferior frontal gyrus activation (lefthemispheric BA 47) was higher in COOPDEC than in DEC. 

On the other hand, within stories containing the element of cooperation there was higher activation in left superior frontal gyrus (BA 9) in COOP than in COOPDEC, while the opposite applied in bilateral inferior frontal gyrus (BA 47) and left medial frontal gyrus (BA 32), where COOPDEC stories led to higher activation than COOP stories. A higher activation of COOP in left superior frontal gyrus (BA 10) was also found compared to DEC. 

In general, these results suggest that stories containing a deception element activated predominantly left inferior and medial frontal gyrus. In spatially distinct regions of left superior frontal gyrus, higher activation was found in tasks containing only the cooperation element or the deception element, respectively (see   and  ,  ). 


#### Limbic activation 
  
In left posterior cingulate gyrus (BA 31), both types of stories containing a deception element led to higher activation than stories dealing with cooperation alone, while both types of stories containing a cooperation element led to higher activation in right posterior cingulate gyrus (BA 31) compared to the deception stories. 

Further differentiation between stories was found in right ACC (BA 33) and bilateral posterior cingulate gyrus (BA 23), where the activation was higher for DEC than for COOPDEC, and in left posterior cingulate (BA 30), where activation was higher for COOP than for COOPDEC (see  ,  ). 


#### Temporoparietal junction activation 
  
Both types of stories containing a deception element led to higher activation in left middle temporal gyrus (BA 39) than cooperation alone, while they activate right middle temporal gyrus (BA 39) less than cooperation alone. 

Furthermore, stories containing a cooperation element led to higher activation than DEC in several regions of the TPJ: in left superior and middle temporal gyrus (BA 12, 22, 39) and in right middle temporal gyrus, however, there are no TPJ regions where stories containing a cooperation element commonly show less activation than deception stories (see  ,  ). 


#### Other temporal regions 
  
Right middle temporal gyrus (BA 39) exhibits higher activation regarding stories containing a deception element than mere cooperation stories. Within stories containing deception, some regions in right middle temporal gyrus (BA 21, 37) are activated stronger by COOPDEC than by DEC, while a more superior situated region in left middle temporal gyrus appear to be activated stronger by DEC than COOPDEC (BA 22). 

There are no temporal regions that commonly exhibit higher activation in stories containing a cooperation element compared to deception. However, some temporal regions show differential activation when comparing COOP and COOPDEC, such as left superior temporal gyrus (BA 41), which is activated stronger by COOP than by COOPDEC, while regions in right superior (BA 21, 22) and middle temporal gyrus (BA 37) are activated stronger by COOPDEC than COOP. In general, stories containing a deception element apparently lead to higher temporal activation than those without. In particular righthemispheric middle temporal regions are predominantly involved in deception processing and/or even more in the combination of deception and cooperation (see  ,  ). 


#### Parietal regions 
  
Both types of stories containing a deception element yield higher activation in left precuneus (BA 7) than stories with only a cooperation element, however, when comparing deception type stories with each other, this same region is activated higher in DEC than in COOPDEC stories, and also activation in an adjacent precuneus region (BA 31 left) is higher in COOP compared to COOPDEC. No parietal region shows higher activation in COOPDEC compared to DEC and COOP, respectively. 

It appears that lefthemispheric precuneus BA 7 is activated predominantly when deception has to be processed, while BA 31 seems rather to be involved in processing cooperation. 



### Mean signal intensity 
  
An ANOVA comparing mean signal intensity in left medial (BA 9/10) and inferior frontal (BA 47) gyrus and in left temporoparietal junction (BA 22) in all three ToM task conditions revealed main effects of condition (F(2) = 7.917 p<0.001, region (F(2) = 4.830 p<0.01 and a significant condition*region interaction (F(4) = 9.910 p<0.001). Paired t-tests comparing activation in the same region for different conditions showed significantly higher activation in medial prefrontal cortex during DEC compared to COOP and COOPDEC (t(12) = 2.537 p<0.01 and t(12) = 2.290 p<0.01, respectively); in inferior frontal cortex during DEC and COOPDEC compared to COOP (t(12) = 3.041 p<0.01 and t(12) = 4.005 p<0.001), and in temporoparietal junction in COOPDEC compared to DEC (t(12) = 2.079 p<0.01) and COOP (t(12) = 4.173 p<0.001). T-tests comparing activation in the same condition for different regions showed significantly higher activation in medial PFC than in TPJ for DEC (t(12) = 3.179 p<0.01), and higher activation in TPJ than in inferior frontal gyrus for COOP and COOPDEC (t(12) =  3.726 p<0.01 and t(12) = 2.757 p<0.01) (see  ). 
   Activation in frontal and temporal regions during the different ToM conditions.  
The graph shows the mean signal intensity (+/− s.e.m.) (in arbitrary units) in these regions in the conditions DEC (black), COOP (white) and COOPDEC (grey), respectively. The ANOVA with the factors condition and region showed main effects of condition (F(2) = 7.917 p<0.001, region (F(2) = 4.830 p<0.01 and a significant condition*region interaction (F(4) = 9.910 p<0.001 with significantly higher activation in medial prefrontal cortex during DEC compared to COOP and COOPDEC (t(12) = 2.537 p<0.01 and t(12) = 2.290 p<0.01, respectively); in inferior frontal cortex during DEC and COOPDEC compared to COOP (t(12) = 3.041 p<0.01 and t(12) = 4.005 p<0.001), and in temporoparietal junction in COOPDEC compared to DEC (t(12) = 2.079 p<0.01) and COOP (t(12) = 4.173 p<0.001). Activation during DEC was significantly higher in medial PFC than in TPJ (t(12) = 3.179 p<0.01), and during COOP and COOPDEC significantly higher in TPJ than in inferior frontal gyrus (t(12) =  3.726 p<0.01 and t(12) = 2.757 p<0.01). 
  

### Behavioral measures 
  
Participants performed at ceiling level in the paper-and-pencil ToM story comprehension task that followed the fMRI session. The mean score was 23.0 for answering the ToM questionnaire alone (standard error 0.00) and 59.0 for the ToM questionnaire combined with the sequencing task (standard error 0.00). 



## Discussion 
  
In a functional magnetic resonance imaging paradigm using cartoons showing social interactions (including the outcome of the interaction) between two or three story characters, respectively, we sought to determine whether brain areas of the ToM network would be differentially involved depending on the nature and complexity of the observed interaction. The overall activation pattern observed in our ToM task showing activated regions in temporoparietal junction, precuneus, temporal cortex, cingulate areas, and prefrontal cortex corresponds largely to the findings of previous studies and the general notion of the theory-of-mind network  – . Since story comprehension of cooperative and deceitful scenarios was flawless in all participants, as indicated by the behavioral data, the observed activations most likely reflect adequate belief reasoning in all three task types. When considering the results from contrasting the three task conditions, it can be assumed that an area that is primarily involved in processing deception will most likely show up in the contrast DEC>COOP, but not its opposite, and potentially also in the contrasts DEC>COOPDEC or COOPDEC>DEC. An area primarily involved in processing cooperation should show up in the contrast COOP>DEC, but not its opposite, and potentially also in COOP>COOPDEC or COOPDEC>COOP. 

### Temporoparietal junction, precuneus and posterior cingulate regions are involved in the comprehension of cooperation and deception 
  
Mentalizing about scenarios describing both cooperation and deception (COOPDEC) always showed higher activated areas in the temporoparietal junction when compared to the DEC or COOP conditions alone. Moreover, the opposite contrasts of COOP>DEC and DEC>COOP exhibited activation in TPJ. COOP and COOPDEC tend to activate bilateral TPJ stronger than DEC, with COOPDEC moreover showing higher activation than COOP in these regions. In general, these results correspond to studies reporting temporoparietal activation in ToM tasks requiring belief reasoning  ,  . However, in contrast to lateralized effects found in recent imaging studies on belief reasoning, with right TPJ selectively activated in false belief   and belief attribution during moral judgments  , and the findings from lesion studies implicating left TPJ in belief reasoning  ,  , our results showed bilateral TPJ activation in both cooperation and deception conditions. A possible reason for the disparity of the observed activation pattern compared with previous studies could lie in differences in task requirements. Our stories were designed to force subjects to reason about (cooperative and deceitful)   intentions   of the story characters, whereas the study by Sommer et al. (2007) used stories where the   knowledge   of a story character had to be inferred. Hence, the higher processing demands placed on the ToM network by our task may well have recruited more bilaterally distributed TPJ activation than a standard task requiring comprehension of a false belief about the location of an object.. 

Accordingly, our findings expand upon previous findings on the role of the temporoparietal junction in ToM, suggesting that processing deception, cooperation or both activates bilateral TPJ. 

Precuneus activation was also observed in all contrasts of cooperation, deception, and cooperation/deception compared with the other conditions. These findings correspond to the study by Sommer et al.  , who also found precuneus activation in both false and true belief reasoning about object location. An fMRI study by Ochsner et al.   found left precuneus to be one of the regions activated by attributing emotions to other people and the self, together with posterior cingulate and prefrontal cortex. According to Vogeley & Fink  , the medial parietal cortex-together with medial prefrontal cortex-has a role in taking the first-person perspective and differentiating between actions controlled by the self versus other persons. However, in a PET study by Ruby and Decety  , there was more bilateral precuneus activation when taking a third person perspective than first person perspective. In an fMRI study that compared thinking about physical causality (physical event and its consequences) versus intentional causality (a subject's intentions and its consequences), the precuneus/posterior cingulate cortex was found to subserve reasoning about intentional causality  , a function that usually develops before false belief understanding. In accordance with the literature, our results therefore suggest that in ToM tasks, the precuneus performs a rather broad function, relating to perspective taking as well as attribution and processing of emotions and intentions, that is required for belief reasoning including comprehension of cooperation and intentional deception. 

Another region commonly activated to varying degrees in all contrasts across conditions is the posterior cingulate gyrus /posterior cingulate (BA 23, 30, 31). Posterior cingulate activation has previously been found in theory of mind research when reading stories about social interaction  ,  , in particular reading about a protagonist's thoughts  , and also specifically in tasks focussing on empathy  –here together with anterior cingulate, paracingulate gyrus and amygdala. These results hint at a role for posterior cingulate apparently related to social/emotional processing aspects of ToM, which in our study were present in both forms of belief reasoning. 


### Processing deception additionally recruits prefrontal cortex, insula and anterior cingulate 
  
Mentalizing about a situation involving intentional deception on the part of the acting character and not recognizing the deceitful intent on the part of the passive character additionally activates left orbitofrontal lateral, inferior, and medial frontal cortex, as seen in the contrasts of DEC vs COOP and COOPDEC, respectively, and in the contrast COOPDEC vs DEC. These results indicate that these prefrontal regions might have a central role in processing a mismatch between intentions and expectations of the protagonists, and also in processing emotional aspects of unfairness  . 

Regions in left lateral superior frontal gyrus, however, showed up in all contrasts, suggesting that adjacent, but spatially distinct areas in this region are involved in processing of cooperation and deception, respectively. 

Involvement of different frontal regions in ToM tasks has been observed in previous PET and fMRI imaging studies  ,  ,  ,  ,  . These studies, however, did not specify variations of cooperative or deceitful intentions shown in their tasks, nor did they explicitly request to evaluate expectations and intentions of the protagonists in a social setting. These studies revealed either left  ,   or right   activation of medial frontal and inferior frontal cortex during ToM tasks performance, or right orbitofrontal activation during recognition of mental states  , as well as specific medial frontal activation  . 

One recent neuroimaging study considering belief processing in ToM associated right lateral rostral prefrontal cortex, but not medial prefrontal cortex, with reasoning about a character's false belief  . The authors used a standard false belief task that described hiding and dislocation of objects, which required subjects to predict a behavior without intention attribution–as already pointed out, this constitutes an important difference to our task that may account for differential results. 

Two further studies found activation of medial prefrontal cortex in subjects playing games that involved trust and reciprocity, particularly when cooperative intentions had to be evaluated  ,  . At first sight these findings might seem contradictory to our results of deception-specific medial frontal activation. However, evaluating cooperative intentions also requires checking for a match or mismatch between one's own expectations and the other's intentions-which might include deception. Therefore such a task may be more similar to our deception task than to our cooperation task, where cooperation was evident and needed no additional evaluation in terms of the truthfulness of the cooperative intent. 

Moreover, our results are consistent with lesion studies showing that damage to the medial frontal lobe impaired detection of deception in a ToM task   and caused deficits in “affective” theory of mind, including evaluation of another person's emotional situation  . It is conceivable that these divergent findings on medial and orbitofrontal involvement in ToM reasoning result from different task paradigms that concentrate either on cognitive or affective aspects of the ToM task. In contrast to classic second-order false belief tasks, which require only a cognitive understanding of the difference between one person's knowledge and that of another, our ToM task required both cognitive and affective ToM in true and false belief conditions. Therefore, the higher activation of medial and orbitofrontal prefrontal regions in tasks requiring both the processing of a malicious intent of one character and the ignorance of that intent by another character might well be related to the stronger emotional valence and perception of unfairness in the deception scenario compared to cooperation. 

Interestingly, as shown by Abe et al., orbitofrontal medial PFC has also been found activated when subjects themselves were deceiving another person,  . In combination with our findings, these results indicate a general involvement of this region in deception processing, regardless of whether one's own actions or actions of others are concerned. These findings blend in well with the general role suggested for the anterior rostral medial prefrontal cortex (arMFC)–a region which corresponds largely to the area activated in our deception task-by Amodio & Frith  . Their review suggests that the arMFC is involved particularly in thinking about mental states and intentions–of self and others. 

Orbitofrontal/ventromedial PFC (BA 10/11) and dorsolateral PFC (BA 9/10/46) have also been found to participate in moral judgements  – . Before a moral judgment can be made, the inappropriate and harmful intention of an actor has to be detected and linked to empathetic engagement with the deceived person. In our study, participants did not have to judge the moral implications of the scheming person's behavior, because the outcome of each scenario was evident. Thus, subjects were merely requested to describe the deceiver's intention and the victim's ignorance. It is therefore conceivable that the activation during moral judgment in previous studies results from a more complex process in which a malicious intention has to be detected. Inferior frontal gyrus (BA 47) in ventrolateral orbitofrontal cortex has also been found activated in response to moral and social transgressions  , suggesting that the activation in left BA 47 during deception processing observed in our study may well relate to the moral implications of the depicted events. 

However, orbitofrontal cortex activation has to date rarely been found to be involved in theory of mind  . It has been suggested that orbitofrontal cortex belongs to a system responding to aversive reactions of others and is therefore also activated in intentional or unintentional violations of social norms  . These notions of orbitofrontal cortex involvement in evaluation of moral behavior and violation of social norms loosely correspond to our finding of involvement of orbitofrontal cortex in mentalizing about people who take advantage of the false beliefs of others to transgress social norms. 

Bilateral anterior cingulate regions also showed higher activation in conditions containing a deception element, in particular in the contrast DEC>COOP. These results correspond to those by Sommer et al.  , who found ACC activation in the contrast false vs. true belief. In their comparison of neuronal correlates of ToM and empathy, Völlm et al.   found empathy associated with enhanced activations of paracingulate, anterior and posterior cingulate; thus it might be conceivable that higher activation of anterior cingulate regions during processing of false belief situations relates to empathizing with the deceived character. The left insula region (BA 13) also exhibited higher activation in deception compared to the other conditions. In accordance with the results by Sanfey et al.  , this activation could relate to the perception of unfairness in the deception scenarios. 


### Conclusion 
  
Our results suggest that bilateral TPJ, precuneus, and posterior cingulate are regions involved in belief reasoning and evaluation of both cooperative and deceptive intentions of others embedded in a social interaction, at least if the outcome of the social interaction is directly observable. In contrast, orbitofrontal and medial prefrontal cortex, and anterior cingulate regions seem to be predominantly active during processing of a character's ignorance of a malicious intent against him, and attribution of deceptive intentions to a third party. To the best of our knowledge, this study is the first to further dissect the cognitive architecture of processing cooperation versus intentional deception. Our findings provide evidence for the hypothesis that different processes of ToM, namely the comprehension of cooperation and deception, are associated with different activation patterns of the neural network involved in social cognition. 



## Methods 
  
### Participants 
  
13 healthy participants (mean age 26.46 years, SD 5.3 years, range 22–38 years; 4 male participants, mean age 26.25 years, SD 4.78; 9 female participants, mean age 26.55 years, SD 5.79) without a history of neurological or psychiatric disorder or first-degree relatives with such illnesses took part in this study after giving written informed consent. The protocol was approved by the local ethics committee of the Ruhr-University Bochum. Prior to the experiment, participants received a handout informing them about the MRI procedure and the instructions for the ToM task. 


### Theory of Mind Task 
  
The theory of mind (ToM) task consisted of six different cartoon stories with four pictures each  , showing scenarios of: a) cooperation of two persons depicting reciprocality, b) deception, where one person deceives another person associated with overt unfairness, and c) cooperation of two persons to the disadvantage of a third person,-i.e. two cartoon stories of each type (Examples see  ). In order to compare activation elicited by ToM demands with non-ToM activation, we introduced a control (non-ToM) condition, where the pictures of the stories were presented in jumbled order. 
   Examples of the ToM cartoon stories presented to the subjects.  
Panels show (A) cooperation, (B) deception, and (C) cooperation/deception. (D) shows an example of a jumbled cartoon story presented in the non-ToM condition. 
  
For the purpose of acquiring fMRI data during performance of the task, the cartoon stories were projected onto a screen during the MR scanning session and presented to the participant via a 45° angled mirror fixed on the head coil. The mirror was adjusted to enable each participant to view the screen without having to move the head. Prior to scanning, a test image was displayed on the screen to ensure that the images were in focus and that the participant could comfortably see the pictures and read the questions. All four pictures of a given story were shown simultaneously on the screen, arranged in two rows in left to right order. In each condition (cooperation, deception, cooperation/deception and non-ToM control), at first the cartoon story was presented alone for 15 sec, then two questions were successively superimposed upon the screen (between the first and the second row of pictures) for 12 seconds each. The task of the participant was to regard the story attentively during the first phase and to think about the answer to each question as long as the question was displayed on the screen. 

In the ToM conditions, the questions referred to intentions and beliefs of the protagonists. While one question always referred to the intention of the acting character(s) (e.g. “What does the boy with the red pullover have in mind?”), which could be positive (cooperation) or negative (deception) for the other; the second question pertained to the belief of the reacting character (e.g. “What does the boy in the blue pullover expect from the boy in the red pullover?”), which could be false or true. False beliefs included the incorrect assumption that the other person wanted a positive social interaction (to cooperate, to play, to give a present) or had a problem and needed help. True beliefs correctly assumed a desire for a cooperative social interaction. In the non-ToM control condition, the questions referred to properties of objects displayed on the scene (e.g., “Is the background blue or yellow?”). 

The cartoon stories for the ToM and non-ToM condition were presented alternatingly in a blocked design with a total of 12 phases (6 ToM phases and 6 non-ToM control phases) of 39 sec duration each, always beginning with a non-ToM phase, with conditions of cooperation, deception and cooperation/deception presented in randomized order. Each experimental scanning session had a duration of approx. 7 min 48 secs. 


### Behavioural measures 
  
After the scanning procedure, the participants completed a paper and pencil version of the ToM task. In the first part of this task, the four pictures of each story were presented in a jumbled order and participants had to put them into the correct sequence. For each cartoon story sequenced correctly, subjects received 6 points (max. score 36 points). In addition, 23 open questions pertaining to the mental states of the cartoon characters were given, i.e. the 12 questions from the scanning session plus additional questions. Here each correct answer scored 1 point (max. total 23 points). The maximum total score for sequencing and questionnaire was 59 points (for details, see  ). 


### fMRI Data Acquisition 
  
Data were acquired using a whole body 1.5 T scanner (Magnetom Symphony, Siemens, Germany) equipped with a high power gradient system (30 mT/m/s; SR 125 T/m/s), using a standard imaging head coil. Blood-oxygen level dependent (BOLD) images were obtained with a single-shot SpinEcho-EPI sequence (TR 3000 ms, TE 60 ms, matrix 64×64, field of view 224 mm, slice thickness 3.0 mm, 0.3 mm gap between slices, voxel size 3.5×3.5×3.0 mm). To reduce noise and obtain an adequate signal-to-noise ratio we restrained the subjects' heads in order to prevent head motion, chose a voxel size of 3.5×3.5×3 mm and used a block length of 13 scans ( =  39 seconds) as well as a spatial smoothing algorithm of 6 mm FWHM in the single subject preprocessing. We acquired 30 transaxial slices parallel to the anterior commissure–posterior commissure (AC-PC) line. The area covered by the fMRI scans encompassed the complete cortex area extending from the superior pole of the cortex to the inferior pole of the temporal cortex. Additionally, anatomical images of each subject were acquired using an isotropic T1-3dGE (MPRAGE) sequence (TR 1800 ms, TE 3.87 ms, matrix 256×256, field of view 256 mm, slice thickness 1 mm, no gap, voxel size 1×1×1 mm) with 160 sagittally oriented slices covering the whole brain. 


### fMRI Data Analysis 
  
For preprocessing and statistical analysis of the fMRI data, we used the Statistical Parametric Mapping (SPM) Software, Version 5 (Wellcome Department of Cognitive Neurology, London, UK) implemented in Matlab (Mathworks, Sherbon, MA). The first 5 images of each fMRI session (total 157 images), during which the BOLD signal reaches steady state, were discarded from further analysis. Single subject preprocessing consisted of the following steps: realignment for motion correction, normalization to standard stereotaxic coordinates (MNI coordinates), smoothing at 6 mm  voxels, and first-level single subject data analysis. The acceptable limit of head motion was 2 mm for translational movements and 0.5° for rotational movements. 

To assess the differences between the individual ToM conditions (i.e. cooperation versus deception, deception versus cooperation/deception and cooperation versus cooperation/deception), we performed second-level paired   t  -test analyses by using first-level contrasts obtained for cooperation, deception and cooperation/deception minus the global non-ToM condition. To do this, in a first-level single subject analysis, contrast images were calculated for activation in the ToM conditions relative to the non ToM condition for each participant. The analysis encompassed the complete presentation phases of the cartoons, i.e. both processing of the story and answering the questions. The individual contrast images were then entered into an exploratory second-level random-effects analysis (one-sample   t  -test) of the activation patterns for all subjects, with a liberal threshold of p<0.02 (uncorrected) and with a minimum cluster size of k = 15 voxels-in order to find the areas involved in mentally answering questions requiring theory of mind in general. 

We restricted our further analysis to ToM-relevant areas found significantly activated in this first exploratory analysis comparing all ToM conditions to all non-ToM conditions. These hypothesis-driven regions of interest (ROIs) were identified by extracting activated clusters using the MARSBAR tool  . These clusters encompassed significantly activated regions in left TPJ, BA 21,22 (peak voxel at −58 −40 16), left precuneus, BA 7/31 (peak voxel at −6 −54 36), right Insula, BA 13 (peak voxel at 38 −22 24), left anterior cingulate, BA 33 (peak voxel at −2 6 20), right middle temporal gyrus, BA 21/37/39 (peak voxel at 60 −64 6 and 62 −6 16), bilateral inferior frontal gyrus BA 47 (peak voxels at −46 30 −10 and 40 20 −20), left medial frontal gyrus BA 9/10 (peak voxel −2 62 22) and BA 32 (peak voxel −12 16 50) and left superior frontal gyrus, BA 9/10 (peak voxel at −16 53 34). Using the MARSBAR procedure, box-shaped ROIs were refined based on these clusters by applying the end coordinates in the x,y,z dimensions of the activated areas as corner points of the boxes. To compare the different ToM conditions (cooperation, deception, cooperation-deception) with each other, contrasts within the described ROIs were calculated in a first-level single-subject analysis for each of the conditions separately, in each case compared to the overall non-ToM condition, resulting in three basic comparisons per subject. The resulting contrast images were then entered into second-level random-effects group analyses, i.e. into paired   t  -tests, by means of which we calculated direct contrasts between the activation patterns in all three conditions, resulting in six contrasts (DEC vs. COOP; DEC vs. COOPDEC; COOP vx DEC, COOP vs. COOPDEC, COOPDEC vs. DEC, and COOPDEC vs. COOP). Functional imaging results are reported as   t  -scores with a threshold of p<0.02 (uncorrected) and a minimum cluster size of 15 contiguous voxels. In view of the height threshold chosen, a minimum cluster size of 15 voxels was selected in order to further protect against including areas of spurious activation in our analysis. Maxima of significant activation were transformed into Talairach space  , anatomical labelling was performed using the Talairach Demon database  . 

Mean signal intensities (in arbitrary units) were calculated for all conditions using the MARSBAR toolbox for SPM for several regions of interest that showed activation differences between the task conditions. The resulting mean values for the activated regions were entered in an ANOVA (SPSS 11.5) comparison of the different conditions and regions. 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-28'>
<h2>28. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/24324679/' target='_blank'>24324679</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Perception of Social Cues of Danger in Autism Spectrum Disorders</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2013</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0081206</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3852523/' target='_blank'>3852523</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This fMRI study examines perception of social cues (fearful facial expressions with gaze direction) — a social-related task involving perception/understanding of others. It includes a healthy control group of adults (mean age 23.7, within 17–65) with whole-brain voxel-wise analyses reported (subject- and group-level GLMs, mixed-effects FLAME, permutation testing, FWE-corrected maps). Although an ASD group is also studied, results for healthy controls are reported separately. Both whole-brain and ROI analyses are presented, so it does not meet any exclusion criteria. Therefore it meets all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Intuitive grasping of the meaning of subtle social cues is particularly affected in autism spectrum disorders (ASD). Despite their relevance in social communication, the effect of averted gaze in fearful faces in conveying a signal of environmental threat has not been investigated using real face stimuli in adults with ASD. Here, using functional MRI, we show that briefly presented fearful faces with averted gaze, previously shown to be a strong communicative signal of environmental danger, produce different patterns of brain activation than fearful faces with direct gaze in a group of 26 normally intelligent adults with ASD compared with 26 matched controls. While implicit cue of threat produces brain activation in attention, emotion processing and mental state attribution networks in controls, this effect is absent in individuals with ASD. Instead, individuals with ASD show activation in the subcortical face-processing system in response to direct eye contact. An effect of differences in looking behavior was excluded in a separate eye tracking experiment. Our data suggest that individuals with ASD are more sensitive to direct eye contact than to social signals of danger conveyed by averted fearful gaze. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (28234 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Autism spectrum disorder (ASD) is a neurodevelopmental condition affecting more than 1% of children  ,  , characterized by deficits in social interaction and communication as well as by the presence of restricted interests and repetitive behaviors  . Absence or impairment of social instinct has been proposed to lie at the core of ASD  . 

Social observation is an efficient way to learn about potential harmful situations in the environment  ,  , and evolutionary-old fear mechanisms are automatically engaged when typical individuals observe others showing signs of fear-related distress. Fearful expression and gaze direction are directly linked with biological self-relevance ( ). In typical individuals, averted gaze in a fearful face is detected faster  , rated as more intense than the same fearful expression with a direct gaze  , and leads to automatic/reflexive gaze shifts  . Studies have shown that individuals with ASD show atypical brain activation in response to fearful facial expressions  ) and to gaze  – . However, despite their relevance in social communication, fear and gaze direction interactions have not been investigated using real faces in adults with ASD. 
   Face and gaze interactions depend on the degree of biological relevance conveyed.  
(1) For neutral faces, humans are more sensitive to direct gaze than averted gaze  , as direct gaze reflects interest from a social partner and the beginning of a social exchange. (2) A face looking at us with a fearful expression is more arousing than a face with a neutral expression, due to the strong emotion it conveys  . (3) For fearful facial expressions, averted gaze is the most biologically self-relevant condition, with the social partner using non-verbal communicative cues to alert us to potential environmental danger  . 
  
Gaze perception produces activation of the intraparietal sulcus, the superior temporal sulcus (STS) and regions of the dorsal and ventral fronto-parietal attention networks  – . Saliency is captured by several areas: the amygdala ensures automatic attention to threatening stimuli  , allowing biologically self-relevant stimuli to be processed even when outside the current focus of attention (reviewed in  ); the pulvinar nucleus of the thalamus, through its reciprocal connections with the amygdala   and the superior colliculus (SC)  ,   contributes to the selection of salient stimuli  ,  ; finally, the SC, associated with covert and overt shifts of attention  , along with the frontal eye fields is involved in saccadic eye movement generation. The interaction of emotion and gaze direction hence involves various social attention processes including reorientation of attention, emotion processing as well as attribution of thoughts and intentions  . 

Using a paradigm with briefly presented fearful faces with averted or direct gaze for which we previously showed that it leads to modulation of attention and emotion networks  – , we aimed to investigate the neural response to fearful averted as opposed to fearful direct gaze in young adults with ASD. This paradigm relies entirely on social observation and although no social interaction is involved, the grasping of the meaning of these stimuli is particularly relevant for ongoing social interactions and communication. While previous studies in ASD have mostly used emoticons or avatars, this fMRI study investigates brain modulation in response to social cues of potential environmental threat using real face stimuli. We hypothesized that individuals with ASD would fail to grasp the meaning of this social prompt and would not show activation in brain regions associated with social attention compared to typical control participants. 


## Materials and Methods 
  
### Participants 
  
The protocol was approved by the Lausanne University Hospital Ethical Committee and all procedures followed the Declaration of Helsinki. After complete description of the study was given to the participants, written informed consent was obtained. Twenty-six high-functioning individuals with ASD were enrolled in the study, from three centers (Lausanne, Brest and Gothenburg). For comparison purposes, 26 typical control individuals (CON) with no history of psychiatric or neurological disorders were recruited in Lausanne. Four participants with ASD and 4 CON had to be excluded due to excessive movement (>3 mm) during data acquisition. Thus 22 participants with ASD (19 males, 27.6 years±7.7 (mean±SD)) and 22 CON participants (19 males, 23.7 years±5.9) were included in the final data analysis. Participants in the ASD group were diagnosed according to DSM-IV-TR criteria by experienced clinicians  . The Autism Diagnostic Observation Schedule (ADOS) and the Autism Diagnostic Interview-Revised (ADI-R)  ,   were conducted for 14 ASD participants and the Diagnosis of Social and Communication Disorder-10 (DISCO-10)   was used for the participants from Gothenburg. All participants met criteria for autism spectrum disorder according to the current DSM 5 criteria  . In addition, autism traits were assessed in all participants but one using the Autism Quotient (AQ) self-report questionnaire  . The ASD group scored significantly higher than the CON group (ASD: 28.1±7.0; CON: 13.0±4.1;   t  (41) = 8.6,   p  <0.001). Performance intelligence quotient (PIQ) was assessed using the Wechsler Non-verbal Scale or the Wechsler Abbreviated Scale of Intelligence  ,   and all participants had a PIQ in the normal range (ASD: 114±15; CON 112±8). ASD and CON-groups did not differ in terms of age, intelligence quotient or gender. All participants had normal or corrected to normal vision. None of the participants of the current study were enrolled in the previously published study  . 


### Stimuli and paradigm 
  
The paradigm used in the current experiment has been previously described in  . The stimuli were taken from the NimStim Set of Facial Expressions database  . Eight greyscale fearful faces (4 females) were selected and their gaze direction was altered by changing the position of the iris so that the faces were looking downwards toward the left or right, without altering their head direction (for an example of the stimuli used, see   in  . A central fixation cross (FIXATION) was presented for 1200 ms followed by a face stimulus briefly presented for 300 ms in the center of the screen. This ensured that the eye region of the face stimuli appeared where the fixation cross was previously located and that the participants would attend to the eye-region  . Faces were presented in 24-second alternating blocks: 8 blocks of stimuli with direct (DIRECT) gaze and 8 blocks with averted (AVERTED) gaze (to the right in half of the blocks, to the left in the other half). Participants were instructed to observe the images attentively, and to look at the fixation cross, while trying to feel what the faces they were observing expressed. 


### MRI data acquisition 
  
Imaging data were acquired on a 3T scanner (Siemens Tim Trio, Erlangen, Germany) using a 12-channel matrix coil at the Centre d′Imagerie BioMédicale at the Centre Hospitalier Universitaire Vaudois in Lausanne. Slices were automatically positioned using the online AutoAlign Head LS (Landmark Survey) from Siemens. T1-weighted high-resolution (1.0×1.0×1.0 mm ) structural images were obtained at the beginning of the session with a multi-echo magnetization-prepared rapid acquisition gradient echo (ME-MPRAGE) sequence (176 slices, FOV = 256, matrix size 256×256, echo time (TE1) = 1.64 ms, (TE2) = 3.5 ms, (TE3) = 5.36 ms (TE4) = 7.22 ms; repetition time (TR) = 2530 ms; flip angle = 7°). Whole brain T2*-weighted gradient echo-planar images (EPI) were collected during the presentation of the paradigm. This functional acquisition (45 or 47 AC-PC slices, FOV = 216, matrix size = 64×64, TE = 30 ms, TR = 3 s, slice thickness 3 mm, flip angle 90°) lasted 384 s. 


### fMRI data preprocessing and analysis 
  
Whole brain voxel-wise analyses were conducted using FEAT version 5.98 part of FSL (FMRIB Software Library). For each subject first-level general linear model (GLM) analyses were conducted for the contrast averted vs. direct fearful gaze. Motion-correction was conducted using MCFLIRT and the motion parameters were added as nuisance parameters to the model. FSL's motion outlier detection program was used to identify residual outlier timepoints, which were included as additional confound variables in the GLM. Spatial smoothing using a Gaussian kernel of 8 mm, grand mean intensity normalization and highpass temporal filtering with sigma = 50.0 s were applied. Brain extraction of high-resolution anatomical images was carried out using Christian Gaser's VBM8 toolbox for SPM8   and fed into FEAT. Subject-level analyses for the contrast AVERTED>DIRECT and DIRECT>AVERTED were performed using FILM. Non-linear Registration to the MNI template was carried out using the tool FNIRT. Group-level analyses were conducted using mixed effects with FLAME 1 and 2, allowing inference about the population from which the individuals were drawn. FSL's randomise was used to perform a permutation-based nonparametric statistical between-group (CON vs. ASD) analysis (n permutation = 10,000) using threshold-free cluster enhancement (TFCE). P values were family-wise error (FWE) corrected (  p  <0.05). Local maxima where identified using   t   value maps as FWE-corrected clusters appeared large. A threshold of   t  >3.2 was chosen to control cluster size. Thus, only clusters which survived   p  <0.05 and   t  >3.2 and contained at least 20 contiguous voxels are reported. All coordinates refer to MNI standard space. For visualization, statistical corrected   p   value maps (  p  <0.05) are displayed on the pial cortical surface of the FreeSurfer brain (fsaverage) template (htttp://surfer.nmr.mgh.harvard.edu). In an additional analysis, the contrast AVERTED>FIXATION and DIRECT>FIXATION were compared within and between groups to control for potential differences in activation of face processing areas for the two different gaze conditions. 


### ROI analyses 
  
Regions of interest (ROIs) were selected to analyze activation of the subcortical route, known to be involved in the detection of biologically relevant stimuli, and consisting of the thalamus, the amygdala and the SC. To avoid circularity, ROIs were defined by independent anatomical constraints. The thalamus and the amygdala were identified using the respective label within the 25% probability Harvard-Oxford subcortical atlas. The SC was selected following anatomical landmarks  . Standard space anatomical ROIs were mapped back to subject space. Subsequently, for each ROI, mean percentage BOLD signal change within that ROI was extracted from the contrast of parameter estimate at the subject-level using FSL's Featquery. For each ROI Mann-Whitney U-test were conducted to assess differences between groups. 


### Eye-tracking 
  
To control for potential between-group differences in looking behavior, we conducted an eye-tracking study on a separate day after the fMRI experiment in a subset of the participants. Nineteen ASD and 14 CON participated in this experiment, but 3 ASD had to be excluded due to insufficient data (unsuccessful calibration or poor tracking quality). Data analysis was therefore conducted on 16 ASD and 14 CON. 


### Data collection and analysis 
  
Eye-tracking data was collected using a T120 eye-tracking system running Tobii Studio (TOBII Technology, Sweden). Participants sat comfortably 60–65 cm away from a 17-inch flat screen in a dimly lit room. Corneal reflection was measured for both eyes with infrared light sources and cameras, integrated in the monitor. A 9-point calibration was run prior to the experiment and data were recorded at 60 Hz. The same stimuli as those used in the fMRI were presented for the same amount of time as in the fMRI experiment (300 ms), preceded by a fixation cross (1200 ms). Areas of interest (AOI) were drawn for the eye region, the face and the computer screen. The eye region consisted of one rectangle covering both eyes and the bridge of the nose between the eyes. One large oval was used as AOI for the face. The total time spent looking at those areas was measured using Tobii Studio v.3.0.2. Eye fixations were determined using the criterion of eye position remaining within a 35-pixel area for a time greater than 80 ms. Analysis was conducted on absolute time spent looking at the eye region and at the face as well as on the ratio of time spent on eye region to time spent on the computer screen and time spent on face to time spent on computer screen. For each AOI total fixation duration differences in averted vs. direct gaze conditions were investigated within group using non-parametric Wilcoxon signed-rank tests. Between-group differences (CON vs. ASD) were assessed using two-tailed non-parametric Mann-Whitney U-tests. 



## Results 
  
### Eye-tracking results 
  
No differences were found for the time spent on the   eyes   between gaze conditions or groups (CON: fear direct: 211 ms±23 (mean±SEM) and fear averted: 213 ms±24, ASD: fear direct: 190 ms±20 and fear averted: 195 ms±20, all   p  >0.05,   ns  .) and for the   ratio of time spent on the eyes   to time spent on the computer screen (CON: fear direct: 77.4%±0.8 (mean ± SEM) and fear averted: 78.0%±0.9, ASD: fear direct: 69.0%±0.7 and fear averted: 70.7%±0.7, all   p  >0.05,   ns  .). There were also no significant differences for the   face   region (CON: fear direct: 272 ms±2 and fear averted: 274 ms±2, ASD: fear direct: 261 ms±6 and fear averted: 270 ms±4, all   p  >0.05,   ns  .) and for the   ratio of time spent on the face   to time spent on the computer screen (CON: fear direct: 100.0%±0 and fear averted: 100.0%±0, ASD: fear direct: 95.6%±2.4 and fear averted: 98.9%±0.8, all   p  >0.05,   ns  .). This was expected given the chosen paradigm, designed to have participants look in the eye region (fixation cross presented where eye region of face would later appear), and the very short presentation time (300 ms). 


### fMRI results 
  
#### Within-group whole brain analysis - AVERTED>FIXATION and DIRECT>FIXATION 
  
As expected based on the eye-tracking data, both ASD and CON showed increased activation in striate and extrastriate areas for direct and for averted gaze when compared to fixation. In particular, ASD and CON exhibited fusiform face area (FFA) activation in both conditions, indicating that participants in both groups were looking at the faces. 


#### Within-group whole brain analysis - AVERTED>DIRECT 
  
Within-group analysis showed that for AVERTED>DIRECT gaze, CON exhibited increased activation in several brain regions including the frontal eye fields, the intraparietal sulcus, the superior temporal gyrus, the FFA, the insula and the supramarginal gyrus (see  ) whereas ASD failed to demonstrate increased activation in any area for this contrast, even at a very liberal threshold (  p  <0.05, uncorrected). 
   Within-group contrasts in CON.        

#### Within-group whole brain analysis - DIRECT>AVERTED 
  
For DIRECT>AVERTED gaze, CON did not show increased activation even at a very liberal threshold (  p  <0.05, uncorrected). ASD participants did not show increased activation for direct gaze at   p  <0.05. However, at a more liberal threshold (  p  <0.01, uncorrected), ASD showed increased activation for direct fearful gaze compared to avert in areas of the subcortical route, including SC and thalamus (but not the amygdala), and in fronto-insular cortex, anterior cingulate, posterior cingulate/precuneus, and cerebellum. See  . 
   Within-group contrasts in ASD.        

#### Between-group whole brain analysis - AVERTED>DIRECT 
  
For the contrast AVERTED>DIRECT, CON showed increased activation compared to ASD in areas associated with gaze processing and attention including the intraparietal sulcus, superior parietal lobule, frontal eye fields, STS, superior temporal gyrus, temporo-parietal junction and supramarginal gyrus. CON also exhibited increased emotion processing in brain areas involved in emotion processing, including the anterior insula, anterior cingulate and posterior cingulate/precuneus cortex. In addition, increased activation was found for CON compared to ASD in the striate and extrastriate cortex, FFA, inferior occipital gyrus, inferior frontal gyrus, thalamus, hippocampus and cerebellum (  p  <0.05,   t  >3.2, 20 contiguous voxels). See  ,  . 
   Cortical activation for averted gaze.  
Statistical maps of differences in fMRI activation for CON>ASD for the contrast averted>direct gaze (depicted in red to yellow). Group differences reflect increased activation for averted gaze in CON and lack of activation in ASD. Statistical maps are displayed on the lateral, medial and ventral views of both hemispheres, at   p   <0.05. The light grey mask covers subcortical regions in which activity cannot be expressed in surface rendering. 
     Between-group contrasts: CON>ASD for [AVERTED>DIRECT].        


###  A priori   ROI analysis 
  
For all subcortical ROIs, values were numerically greater for CON for the contrast AVERTED>DIRECT, indicating activation in controls for averted gaze. In contrast, ROI values for ASD for the contrast AVERTED>DIRECT were always negative, indicating that ASD showed more activation for the direct gaze condition. Significant between-group differences were observed for the SC (  p   = 0.01) and the right thalamus (  p   = 0.04), and showed a strong trend towards significance in the left amygdala (  p   = 0.056). See  . 
   Region of interest analysis.  
Percent BOLD signal change (± SEM), for averted vs. direct gaze in selected subcortical ROIs. The thalamus (THAL) (  p   = 0.01), and superior colliculus (SC) (  p   = 0.04) were significantly different between ASD and CON while a strong trend was found for the amygdala (AMY) (  p   = 0.056). 
  


## Discussion 
  
Previous studies in autism have mostly investigated gaze and facial expression separately, leaving aside their interactive effects. Here, by combining fearful expression with different gaze directions, we demonstrate that the observation of social cues implicitly indicating the presence of a danger does not result in activation of brain areas involved in gaze perception, attention, emotion processing and mental state attribution in adults with ASD. 

In our study, ASD participants failed to show typical activation in the dorsal and ventral fronto-parietal attention networks for averted vs. direct gaze. The absence of activation of these top-down and bottom-up attention networks suggests the lack of intuitive grasping of the biological relevance of the gaze cue and the absence of spontaneous reorientation. While studies using emoticons and studies using neutral faces have previously shown reflexive orienting in response to eye gaze cues in ASD  ,  , the present study is to our knowledge the first to address the perception of the meaning of an emotional and social cue using real faces with emotional expressions in adults with ASD. 

In ASD, gaze following behavior is developmentally delayed, and joint attention deficits belong to the earliest markers of this disorder  – . Deficits in joint attention, i.e. deficits in the ability to non-verbally coordinate attention between individuals in order to share information regarding the environment, remain present in adults with ASD. Individuals with ASD do not spontaneously react to joint attention cues in videos with avatars, still emoticons with a neutral expression, or during live interactive video  – ,  . The capacity to attribute mental states to others, also known as theory of mind (ToM), has been suggested to arise from joint attention   and individuals with ASD show deficits in ToM, as demonstrated by their decreased performance in the “reading the mind in the eyes” task  , as well as by their lack of spontaneous mental state attribution to others   or to animated shapes  . In this study, the ASD group showed significantly less activation in areas associated with the attribution of thoughts, actions and intentions to others. Notably, we observed absence of modulation in posterior STS in response to gaze cues, a finding previously reported in ASD  ,  . The STS is involved in biological motion and gaze perception   and abnormal STS activation has been repeatedly described in autism (for review see  ). 

Unlike typical individuals, ASD failed to show increased activation in the anterior insula for averted fearful gaze. The anterior insula, structurally connected with the posterior STS through the superior longitudinal fasciculus, is sensitive to the social significance of eye gaze  . The insular cortex has been associated with multiple functions, ranging from performance monitoring   and attention to sensory and sensorimotor processing  , and the activation in the ventral part of the anterior insula observed in controls is likely related to socio-emotional processing  ,  , that is absent in ASD. The anterior cingulate cortex (ACC), involved in appraisal and regulation of negative emotion   was also significantly less activated in ASD. 

Increased activation of the FFA for averted vs. direct gaze was observed in controls but not in ASD participants (although both groups showed FFA activation in both avert and direct conditions compared with fixation). The importance of the eye region in driving FFA activation has been shown in previous studies  ,  . In the eye-tracking experiment, both groups spent the same amount of time looking at the eye region in both conditions, strongly suggesting that different fixation times on the eye region are not the cause of the observed difference between groups in the FFA for averted vs. direct gaze. Instead, a more likely explanation is that participants with ASD, not grasping the increased emotional meaning of the averted gaze stimulus in the fearful face (a phenomenon previously reported in typical individuals   and linked with both attentional and emotional processes  ), fail to modulate FFA activation in response to this biologically-relevant cue. 

The detection of threat-related facial expressions and the ability to quickly read gaze direction play a central role for adaptive responses. Based on the literature, we propose a conceptual scheme emphasizing that the combination of facial expression and gaze direction are directly linked with biological self-relevance (See  ). In neutral expressions (1), direct gaze leads to more activation than averted gaze, as direct gaze represents a desire to engage in a social interaction. Direct gaze associated with a fearful emotion (2), leads to more activation than neutral direct gaze (reviewed in  . Even more activation is observed for briefly presented fearful faces with averted gaze (3). Averted gaze in a fearful face is biologically self-relevant, and leads to shorter reaction times and increased amygdala activation in typical individuals  ,  ,  ,  ,  . 

 summarizes the findings for the processing of gaze in neutral and fearful faces in ASD. For   neutral   facial expression, individuals with ASD as well as controls show increased activation in response to direct neutral gaze as opposed to averted neutral gaze  ,  . Recent data show that this process is supported by the subcortical route, as amygdala activation for neutral direct gaze has been documented in a cortically blind patient  . The influence of direct gaze on behavior is referred to as “eye contact effect” reflecting the fact that perceived eye contact in others modulates cognitive processes (reviewed in  ) and drives activation of areas associated with social processing, including the FFA, STS, amygdala and medial prefrontal cortex. In a study investigating the perception of socially relevant facial expressions either self- or other-directed (as indicated by gaze direction), ventromedial prefrontal cortex and medial temporal lobe/amygdala were shown to play an important role  . In ASD atypical eye contact effect has been observed, reflecting altered processing of direct gaze  . Increased subcortical activation in response to direct gaze in fearful faces in ASD is in line with reports of atypical modulation of arousal in response to direct gaze in children with ASD reported by Kylliainen et al, who measured greater skin conductance in response to direct than averted gaze  , increasing as a function of the degree of eye openness  . 
   Atypical reactivity to social stimuli in ASD.  
Individuals with ASD show increased response to direct as opposed to averted gaze ((1) - Kylliainen 2006) but show atypical eye contact. While deficits in fearful face processing have been described in ASD, no study to our knowledge has specifically investigated fearful vs. neutral faces and it is unclear if individuals with ASD would show more activation in response to direct fearful gaze as opposed to direct neutral gaze. Finally, unlike controls, individuals with ASD do not show more activation for fearful averted gaze. 
  
Studies investigating modulation by   emotion   in direct gaze have shown diminished modulation of the face-processing network in ASD  ,  , and a study conducted in adolescents with ASD reported that brain activations do not differ between averted and direct gaze in negative (anger and fear combined) facial emotions  . However, the results of this latter study do not allow to specifically draw conclusions about the interaction of gaze direction with a fearful facial expression as these two emotions were not analyzed separately. In addition, individuals with Asperger Syndrome do not have faster reaction times for fearful averted gaze, while controls show enhancement of joint attention by emotion  . 

To our knowledge, even though numerous studies have investigated the effect of fear vs. scrambled stimuli or the effect of various intensities of fear, no study has specifically compared fearful with neutral facial expressions (with direct gaze). Finally, in the current study, we show that individuals with ASD do not show increased activation for averted gaze in a fearful face. Instead, whole brain within-group and ROI analysis show increased activation of the subcortical face detection route in ASD for direct fearful gaze. This route, consisting of the SC, the thalamus and amygdala,  ,  – , is activated in typical individuals by direct eye contact in neutral faces  , to a greater extent by direct gaze in a fearful face  ,   and to an even greater extent by an averted gaze in a briefly presented fearful face  – . As shown by Senju and Johnson, the subcortical route may not appropriately modulate cortical and subcortical social brain networks in individuals with ASD  , and the lack of top-down modulation together with decreased processing of mental and emotional states may therefore have lead to increased eye contact effect  ,  . 

Future studies should investigate the role of gaze direction in other emotional expressions and neutral faces. 


## Conclusions 
  
Using short stimulus presentation times, reflecting quick joint attention bids akin to how they occur in real life, we observed significant deficits in the activation of the distributed network of social attention in high-functioning individuals with ASD. Although both ASD and control participants looked similarly at the eye-region of the stimuli, networks involved in attention, gaze perception, emotion attribution and understanding of intentions were not engaged in individuals with ASD when processing social cues of danger. Instead participants with ASD showed hyper-activation of the subcortical route for direct gaze. This suggests that for individuals with ASD, eye contact with a fearful expression is more arousing than a fearful averted gaze signaling the potential presence of an environmental danger. These findings suggest that in early behavioral therapies, emphasis should be placed on association between eye-gaze cues and emotions, in order to specifically train the integration of these cues, thereby allowing young children with ASD to gain access to their social meaning. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-29'>
<h2>29. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/30430680/' target='_blank'>30430680</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Sex differences in own and other body perception</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Hum Brain Mapp</p>
<p><strong>Publication Year:</strong> 2018</p>
<p><strong>DOI:</strong> 10.1002/hbm.24388</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6587810/' target='_blank'>6587810</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Study reports task-based fMRI in healthy adult participants (N=30, ages ~26) performing a body-perception task that probes self- and other-related processing (ratings of “To what degree is this picture you?”), which falls under the social-related constructs (Perception and Understanding of Self and Others). Results are reported from whole-brain analyses (FEAT/FLAME, cluster-corrected maps reported; whole-brain contrasts and parametric analyses described). At least one group of healthy participants is reported separately and no ROI-only restriction applies. Therefore all inclusion criteria are met and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Own body perception, and differentiating and comparing one's body to another person's body, are common cognitive functions that have relevance for self‐identity and social interactions. In several psychiatric conditions, including anorexia nervosa, body dysmorphic disorder, gender dysphoria, and autism spectrum disorder, self and own body perception, as well as aspects of social communication are disturbed. Despite most of these conditions having skewed prevalence sex ratios, little is known about whether the neural basis of own body perception differs between the sexes. We addressed this question by investigating brain activation using functional magnetic resonance imaging during a Body Perception task in 15 male and 15 female healthy participants. Participants viewed their own body, bodies of same‐sex, or opposite‐sex other people, and rated the degree that they appeared like themselves. We found that men and women did not differ in the pattern of brain activation during own body perception compared to a scrambled control image. However, when viewing images of other bodies of same‐sex or opposite‐sex, men showed significantly stronger activations in attention‐related and reward‐related brain regions, whereas women engaged stronger activations in striatal, medial‐prefrontal, and insular cortices, when viewing the own body compared to other images of the opposite sex. It is possible that other body images, particularly of the opposite sex, may be of greater salience for men, whereas images of own bodies may be more salient for women. These observations provide tentative neurobiological correlates to why women may be more vulnerable than men to conditions involving own body perception. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (46863 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## INTRODUCTION 
  
The neurobiology of identity and self‐concept is currently a hot topic among neuroscientists, and emerging data suggest that it is mediated by specific cerebral networks. One fundamental facet of identity is gender. While certainly influenced by cultural and other environmental factors, gender identity is, nevertheless, foremost shaped by the perception of one's own body and its sex characteristics. Yet, we know very little about how our brain processes identification of self in the context of the sex of one's body. How does our brain distinguish own body from other bodies? Are there specific neural networks for processing recognition of the sex of the body? Are there sex differences in how cerebral networks process recognition of the physical sex in relation to self? 

Self‐other distinction, crucial for human social interaction, relies mainly on the visual perception of the own and another person's body (Longo, Azañón, & Haggard,  ). This process can be viewed as a composition of three components: (1) those involving sensory perception of own body, (2) the specific perception of body ownership, and (3) the integration of own body into the concept of self. Neural regions, within more extended networks, specialized in visual body perception include the fusiform body area (FBA) and extrastriate body area (EBA), which are specialized in human body and body parts perception (Downing & Peelen,  ; Downing, Jiang, Shuman, & Kanwisher,  ; Peelen & Downing,  ; Schwarzlose, Baker, & Kanwisher,  ). The EBA and FBA, especially on the right side, were found to be involved in   own   body representation (Peelen & Downing,  ) and to show stronger responses after viewing pictures of one's own body compared to that of a same‐sex other (Vocks et al.,  ). These brain regions thus provide important self‐other information at a perceptual level of representation. Perception of body ownership primarily requires intact function of the temporo‐parietal junction (Limanowski & Blankenburg,  ). Higher order social cognition (e.g., mentalizing), self‐other distinction, and (own) body representation requires recruitment of cortical midline structures: the medial prefrontal cortex (mPFC), anterior and posterior cingulate cortex, and precuneus (Northoff & Bermpohl,  ). 

More specifically, the ventral and rostral medial prefrontal cortices (mPFC) have been shown to be involved in self‐relative to other‐evaluations and in affective processing of self‐relevant information. (Amodio & Frith,  ; Denny, Kober, Wager, & Ochsner,  ; Murray, Schaer, & Debbané,  ; van der Meer, Costafreda, Aleman, & David,  ). In contrast, the dorsal mPFC was suggested to be involved in the evaluation and decision‐making process of whether a certain stimulus is applicable to the self or to another person, and was associated with judgments about dissimilar others (D'Argembeau,  ; D'Argembeau et al.,  ; Denny et al.,  ; Mitchell, Macrae, & Banaji,  ; Murray et al.,  ; van der Meer et al.,  ). The posterior cingulate and precuneus areas have been associated with autobiographical and semantic memory retrieval about physical aspects of own body, may be responsible for integration of self‐relevant emotional information, and have been found to be important for self‐other differentiation (Northoff & Bermpohl,  ; Ruby & Decety,  ; van der Cruijsen, Peters, & Crone,  ; van der Meer et al.,  ). Of particular interest are findings in the precuneus cortex because this region is tightly connected with networks processing visual and pheromonal stimuli, and sexual arousal (Berglund, Lindström, & Savic,  ; Cavanna & Trimble,  ; Zhang & Li,  ). In concert with the cortical midline structures, activation in the (anterior) insula has consistently been associated with own body awareness and ownership, integration of internal affective bodily states, and with self and familiar face processing (Craig,  ; Kircher et al.,  ; Mega, Cummings, Salloway, & Malloy,  ; Tsakiris,  ; Tsakiris, Hesse, Boy, Haggard, & Fink,  ). 

Distortions of one's body image, including those that might arise during body perception, and impairments in social cognition are core symptoms of several psychiatric conditions, such as anorexia nervosa, body dysmorphic disorder, autism spectrum disorders, and in a subset of individuals with schizophrenia (American Psychiatric Association,  ; Beilharz, Castle, Grace, & Rossell,  ; Farrell, Lee, & Shafran,  ; Gardner & Brown,  ; Krumm, Ferraro, & Ingvalson,  ; Madsen, Bohon, & Feusner,  ; Priebe & Röhricht,  ; Röhricht & Priebe,  ; Ropar, Greenfield, Smith, Carey, & Newport,  ; Smeets, Smit, Panhuysen, & Ingleby,  ). Notably, several of these conditions show skewed sex ratios. Whereas, for example, autism spectrum disorders are more common in males than females, with a sex ratio of about 3:1 (Loomes, Hull, & Mandy,  ), eating disorders are much more prevalent in females (Hudson, Hiripi, Pope, & Kessler,  ; Keski‐Rahkonen & Mustelin,  ). Body dysmorphic disorder, on the other hand, has almost equal prevalence in males and females (Buhlmann et al.,  ; Koran, Abujaoude, Large, & Serpe,  ; Rief, Buhlmann, Wilhelm, Borkenhagen, & Brähler,  ). A direct link between gender and own body perception also represents the hallmark of gender dysphoria, a condition gaining increasing public attention. Gender dysphoria, termed “Gender Incongruence” in the latest ICD11 criteria of the World Health Organization (  https://icd.who.int/dev11/f/en#/http%3a%2f%2fid.who.int%2ficd%2fentity%2f411470068  ), is characterized by a perceived incongruence between a person's gender identity and his/her sex assigned at birth (DSM‐5, American Psychiatric Association,  ). This is possibly due to a disturbed own body perception with respect to gender identity (Burke, Manzouri, Dhejne, et al.,  ; Burke, Manzouri, & Savic,  ; Feusner, Dervisic, et al.,  ; Feusner, Lidström, et al.,  ; Manzouri, Kosidou, & Savic,  ). Gender dysphoria has traditionally been regarded to have a male (sex assigned at birth) predominance, although this has been questioned more recently (Steensma, Cohen‐Kettenis, & Zucker,  ; Zucker,  ). 

Whether and how own body perception differs between men and women is not known, although it has been hypothesized that women may be more sensitive to information about the own body image than men (Mitchison et al.,  ; Powell & Hendricks,  ). One of the few studies describing sex differences in brain activations upon viewing distorted images of one's own body (appearing with different degrees of thinness or fatness) found that women showed activations in the amygdala and prefrontal areas, suggesting more complex cognitive emotional processing, whereas men had activations in the primary and secondary visual streams, similar to object and spatial visual processing (Kurosaki, Shirao, Yamashita, Okamoto, & Yamawaki,  ). Shirao et al. ( ), investigating sex differences in brain activations during perception of negative body image related words, found amygdala activations in women, but hippocampal and prefrontal brain activations in men, suggesting a more cognitive rather than emotional processing of body image stimuli in men. 

Despite vivid discussions about the representation of one's own body image in the brain (Guterstam & Ehrsson,  ; Schauder, Mash, Bryant, & Cascio,  ; S Vocks et al.,  ; Wiebking et al.,  ), surprisingly little is known about the neural representation of sex or gender, thus how our brain processes perception of the sex of others' bodies in relation to self, and whether this process differs between men and women (Pavlova,  ). This issue is of special interest considering that the visual system is central for social communication, for example, for sexual attraction and partner selection. In line with this, sex differences in brain activations during body motion processing have been reported, with females showing increased activations in regions known to be involved in social cognition (Anderson et al.,  ; Pavlova, Sokolov, & Bidet‐Ildei,  ). In addition, perception of one's own in relation to another body's sex may contribute to self‐referential processes, for example, when comparing oneself to others of the same sex (“appearance competition”) (Jackson,  ). However, to the best of our knowledge, no study to date has investigated the neural correlates of gender identity, and sex differences in the perception of another person's body in the context of self. 

We therefore developed a body perception task paradigm (Feusner, Dervisic, et al.,  ; Feusner, Lidström, et al.,  ) in which male and female participants viewed photographs of their own body, same‐sex other bodies, opposite‐sex other bodies, and sets of bodies that were morphed in increments between own body and same‐sex and opposite‐sex other bodies. For each image, the participant rated the degree that the body appeared like them: “To what degree is this picture you?” Based on previous reports, we expected to find sex differences in brain activation during   own   body perception, such that women would show stronger activations in limbic brain regions (Kurosaki et al.,  ; Shirao et al.,  ). Furthermore, we expected that both men and women during own body perception and during the perception of bodies similar to their own (i.e., same‐sex other bodies) would recruit brain areas suggested to be involved in self‐referential processing and bodily self‐consciousness (Craig,  ; Ionta, Martuzzi, Salomon, & Blanke,  ; Northoff,  ; Northoff et al.,  ), such as the ventral mPFC and insula, in addition to regions involved in body perception in general (EBA and FBA). During perception of opposite‐sex bodies we predicted to find “other”‐related activations such as in the dorsal mPFC, precuneus, and TPJ (D'Argembeau et al.,  ; Eddy,  ; Van Overwalle,  ). Our paradigm allowed us to additionally test the novel question of whether brain activation patterns differ depending on the sex of the viewed body, independently of how that body was identified in relation to self, for instance, when the viewed body was of the opposite or same sex as the perceiver's but was in both events labeled as “not me.” 


## MATERIALS AND METHODS 
  
### Participants 
  
We enrolled 30 healthy participants (15 males, 15 females, mean age 26 ± 3.5 years) who performed the body perception task while we acquired functional magnetic resonance imaging (fMRI) data to measure brain activity. Participants were recruited via flyers and advertisements around the campus of The Karolinska Institute. Participants had no self‐reported neurological or psychiatric disorders and were not taking any psychotropic medications. The study was approved by the ethical committee of The Karolinska Institute (application number Dnr 2011/281–31/4) and each participant provided signed informed consent before entering the study. 


### Body perception task 
  
Participants were photographed from the front with a Nikon D90, 18–105 mm f/3.5–5.6 G ED VR camera, fixed on a tripod. Lightning, contrast, and luminance were identical during each photo session. Each participant wore a skin‐colored, skin‐tight, full body unitard, and was positioned against a wall in an identical manner. The purpose of using a full‐body unitard was to best approximate the view of one's own and other bodies in the nude while avoiding the discomfort of being photographed undressed. In addition, it eliminated any differences in skin tone that would have otherwise occurred from morphing images of participants' bodies to others' bodies. Hands, feet, and head in the photos were cropped, and the photos were then morphed with photos of five other male and five other female bodies acquired in an identical manner using FantaMorph Software, version 5.0 (Abrosoft  http://www.fantamorph.com/  ). Each participant's picture was morphed separately with pictures from five different female and five different male participant morph targets to degrees of 20%, 40%, 60%, 80%, and 100%, respectively (producing a total of 50 different morphed images). The “100%” images were simply unaltered photos of another person. We also included the unmorphed (0% morphed) picture of each participant (Figure  ). 
  
Examples of a scrambled image and a male's body images morphed, from left to right, to 20%, 40%, 60%, 80%, and 100% to the same (denoted by positive morph degrees) and the opposite (denoted by negative morph degrees) sex. Note that “100%” photographs were unaltered images of another person [Color figure can be viewed at   http://wileyonlinelibrary.com  ] 
  
The total number of morph conditions was thus 11: the unmorphed 0% and images morphed 20%, 40%, 60%, 80%, and 100% to the same sex and 20%, 40%, 60%, 80%, and 100% to the opposite sex. Images were also presented over two different presentation durations: short (0.5 s) and long (2 s) durations). We present results from trials of the long 2 s duration in the main text and results from trials of the short 0.5 s duration, as well as comparisons of the two presentation durations in the supplement. 

In each experiment, 15 repetitions were presented per morph percentage and for each of the two presentation durations, totaling 330 (15 × 11 × 2) experimental trials. Experimental trials were intermixed with 30 (15 for each of the short and long presentation durations) “scrambled” control images, created by phase scrambling an unmorphed body image using a Fourier phase randomization procedure (Näsänen,  ). Here, an image's phase spectrum is replaced with random values, keeping the amplitude spectrum of the image unaltered. Global low‐level properties (i.e., luminance, contrast, color distribution, and spatial frequency spectrum) of the original image are preserved while the shape information of the image is entirely degraded. Scrambled images were also shown at two different presentation durations, 2 s and 0.5 s, and there were a total of 30 scrambled image trials. 

Participants were instructed to respond as quickly as possible, rating the presented picture based on the degree to which it appeared like them, with the specific question “To what degree is this picture you?” Participants were instructed to press response button box keys 1 to 4, 1 corresponding to 0%–25% “me,” 2 to 25%–50% “me,” 3 to 50%–75% “me,” and 4 to 75%–100% “me.” Before starting the experiment, participants performed a practice session inside the scanner to ensure task comprehension. 

Using Presentation version 18.1 for stimulus delivery, trials appeared in randomized order across 3 runs of 9.5 min each, acquiring 280 volumes per run. There was a 1 min break between runs. Each run began with an instruction screen, followed by a fixation cross for 30 s. Each trial consisted of (a) an image presentation for either 0.5 s or 2 s, followed by (b) the appearance of a response screen for 1 s with button press options, followed finally by (c) a fixation cross for a jittered inter‐trial interval of 1–11 s. We used optseq2 (  http://surfer   .  http://nmr.mgh.harvard.edu  /optseq/), a genetic algorithm, to create jittered presentation timing with the highest efficiency. The presentation of images was balanced and randomized with respect to degree of morph and presentation time. 


### Body localizer task 
  
As an additional control condition and to localize those areas in the brain responsible for the specific processing of human bodies, participants performed the   body localizer task  . Participants viewed 16 alternating blocks (24 s duration) of images of either others' male or female clothed bodies (8 blocks) or chairs (8 blocks). A 10 s fixation screen was interspersed between every set of 4 blocks. To keep participants actively engaged in the task they were asked to press a button any time the exact same image (of either a chair or a body) would be presented twice in a row. 


### MR data acquisition 
  
Magnetic resonance imaging data was acquired on a 3 Tesla MRI scanner (Discovery 3 T GE‐MR750, General Electric, Milwaukee, WI). Functional MRI of both the body perception and body localizer tasks was performed with a gradient echo pulse sequence using a voxel size of 3.03 × 3.03 × 3.5 mm (TE = 30 ms, TR = 2000 ms, FoV = 23 cm, 41 bottom up interleaved axial slices, 3 mm thickness, 75° flip angle) and a 32‐channel head coil. 3D T1‐weighted Spoiled Gradient Echo pulse sequence (SPGR) images were acquired with 1 mm  isotropic voxel size (TE = 3.1 ms, TR = 7.9 ms, TI = 450 ms, FoV = 23 cm, 176 axial slices, 12° flip angle) using an 8‐channel coil. 


### Behavioral data analysis 
  
Sample characteristics and behavioral data of the fMRI task were analyzed using SPSS Statistics 21 (SPSS Inc., Chicago, IL). 

We calculated a   Self‐Perception Index   (Feusner, Lidström, et al.,  ) by multiplying the value of a participant's “self” rating (from 1 to 4) with the degree of morph. This degree of morph was 0 for the unmorphed image and was positive when images were morphed to the same‐sex other body (20%, 40%, 60%, 80%, 100%) and negative when images were morphed to the opposite‐sex other body (−20%, −40%, −60%, −80%, −100%). These weighted values were averaged for each participant and then divided by the number of rated images. Thus, greater positive values would indicate higher average “me” ratings for images morphed to a high degree to the same sex and greater negative values would indicate higher average “me” ratings for images morphed to a high degree to the opposite sex. Values closer to zero, on the other hand, would indicate higher average “me” ratings for images that were only slightly morphed from their own image. 

Furthermore, male and female participants were compared with respect to their ratings of “self” when viewing their own bodies compared to bodies morphed to either the same‐ and opposite‐sex (80% and 100%, and −80% and −100% morph degrees, respectively) to evaluate possible sex differences in self‐perception. 


### MR data analysis 
  
Data analysis was performed using FEAT (fMRI Expert Analysis Tool) version 5.0.8, part of FSL (FMRIB Software Library  http://www.fmrib.ox.ac.uk/fsl  ) (Jenkinson, Beckmann, Behrens, Woolrich, & Smith,  ). BOLD sequences were motion‐corrected (using the FMRIB linear image registration tool, MCFLIRT) and spatially smoothed (using FEAT) with a smoothing kernel of 5 mm. Portions of subject runs with notable movement greater than a maximum displacement of 1.5 mm were truncated if they occurred at the beginning or end of the run to minimize the effect of movement. An average of 59 TRs per run was truncated from 7 different runs of 6 subjects (3 female and 3 male controls) on account of movement. Functional images were registered to the participant's T1‐weighted image (using the FMRIB nonlinear image registration tool, FNIRT) after brain extraction using BET (implemented in FSL) with a fractional intensity threshold of 0.3. Images were then registered to the MNI‐152 brain for group analysis (using FNIRT). Higher‐level analysis was carried out first using Fixed Effects modeling to combine the three acquired runs per participant followed by a second higher‐level analysis using FLAME 1 (FMRIB's Local Analysis of Mixed Effects) for cross‐subject comparisons (Beckmann, Jenkinson, & Smith,  ; Woolrich,  ; Woolrich, Behrens, Beckmann, Jenkinson, & Smith,  ). We thresholded   z  ‐statistic group map images using a cluster‐forming threshold of   Z   > 2.3 and a corrected cluster significance threshold of   p   = .05. Cluster   p  ‐values were determined using a spatial smoothness estimated in FSL. In addition, to further explore the extent of sex differences in (own) body perception observed, contrasts directly comparing activations of men and women were explored at a lower threshold of   Z   > 2.0,   p   < .05, corrected. 

Our first set of questions was whether there are any sex differences in the perception of (1) one's own body, and (2) other bodies of the same or opposite sex, derived from images morphed 80% and 100% to same and opposite sex, respectively. Male and female participants were thus compared for the following contrasts: for (1) [own body (morphed 0%) – scrambled image]; for (2) [same‐sex other body (morphed 80–100%) – scrambled image], and [opposite‐sex other body (morphed 80%–100%) – scrambled image]. 

Our second set of questions was whether there are any sex‐differences in the processing of other bodies in contrast to one's own body, and if this would be affected by whether the other body is of same or opposite sex. We compared male and female participants, therefore, using the following contrasts: [same‐sex other body (morphed 80%–100%) – own body (morphed 0%)] and [opposite‐sex other body (morphed 80%–100%) – own body (morphed 0%)]. 

Finally, we sought to understand the neural correlates of cognitive self‐perception, utilizing participants' own behavioral measures of similarity to self as a parametric measure when viewing images morphed to either the same or opposite‐sex. Participants' responses to the question “To what degree is this picture you?” when viewing   any morphed   image (images morphed from 20% to 100%, excluding the unmorphed image of self) were parametrically modeled on a scale from 1 to 4 (see description of   Body Perception Task   above) and demeaned. Images morphed to the same‐sex and those morphed to the opposite‐sex were treated separately. This resulted in two continuous variables (for the same vs. opposite sex morphs, respectively) centered at 0, with higher values representing greater identification with “me.” In this way, neural processes involved in self‐perception could be separated from differences in perceiving same‐sex and opposite‐sex bodies of others. 



## RESULTS 
  
Sample characteristics and self‐perception indices are presented in Table  . Male and female participants did not differ in mean age or mean scores for handedness, and all participants identified as heterosexual. Self‐perception indices were positive for both groups, indicating, as reported earlier (Feusner, Dervisic, et al.,  ), self‐identification for images morphed to the same sex. Results from trials of the long 2 s duration are presented below, and the short 0.5 s duration results can be found in the supplement. Males' and females' ratings of self‐perception did not differ significantly at any morph degree (Figure  ). 
  
Sample characteristics and self‐perception indices 
      
Average morph ratings for men and women for each degree of morph. Ratings ranged from 1 (0%–25% “me”) to 4 (75%–100% “me”). Positive values indicate percentage morphed to the same‐sex, whereas negative values indicate percentage morphed to the opposite‐sex. Error bars indicate standard errors of the mean. There were no significant differences between groups at any morph degree [Color figure can be viewed at   http://wileyonlinelibrary.com  ] 
  
Despite the groups being of equivalent age, we reprocessed the analyses for all contrasts of the Body Perception Task, as presented below, using age as a covariate of no interest. The results were very similar as when age was not accounted for, and therefore are presented in the supplement (see Supporting Information Tables   and  , please compare to Tables   and  ). 
  
Brain (de)activation for the contrast own body perception (0% morph condition) > scrambled image (control condition) in men and women 
      
Sex‐differences in brain activation 
    
### Body localizer task 
  
As has been shown in previous studies, the   body localizer task   resulted in significant (  Z   > 2.3,   p   < .05, corrected) bilateral activation in areas specialized for body perception, in both males and females. These areas included bilateral lateral occipital cortices (EBA), temporal occipital fusiform gyri (FBA), precuneus, left angular gyrus, bilateral precentral gyri, and the right amygdala in males (see Supporting Information Table  ). When comparing males and females, males showed significantly (  Z   > 2.3,   p   < .05, corrected) greater activation in the bilateral motor cortex and superior frontal gyri (Table  ). 


### Own body perception 
  
On account of an error, one male participant did not see images of his own body but rather another participant's body during the scan. This participant was therefore excluded in all analyses involving   own body  . 

Contrasting perception of one's   own body   (0% morph) with the   scrambled   image baseline revealed significant (  Z   > 2.3,   p   < .05, corrected) activation in both men (N = 14) and women (N = 15) in the bilateral lateral occipital cortex, including the EBA, dorsal medial PFC, bilateral frontal operculum/anterior insula, caudate nucleus, and thalamus. There were no significant differences between groups (Supporting Information Figure   and Table  ). Both males and females showed right dominant deactivation in the precuneus, posterior cingulate, TPJ (bilateral, but right‐dominant middle temporal gyri, angular gyri, supramarginal gyri), right temporal pole, and fusiform gyri (Table   and Supporting Information Table  ). 


### Same‐sex other body perception 
  
Contrasting perception of   other bodies of the same sex   (80–100% morph) with the   scrambled   image baseline revealed significant (  Z   > 2.3,   p   < .05, corrected) activation in both (N = 15) men and (N = 15) women in the bilateral inferior lateral occipital cortices (EBA), fusiform cortices (FBA), bilateral caudate nucleus, thalamus, bilateral anterior insula, ventrolateral PFC, and dorsal mPFC, anterior cingulate cortices, and bilateral cerebellar hemispheres (Supporting Information Figure  ). In both groups, there was deactivation of the bilateral TPJ (middle temporal gyri, angular gyri, supramarginal, gyri) (Supporting Information Table  ). When comparing males and females, males showed significantly (  Z   > 2.3,   p   < .05, corrected) greater activation in the left superior lateral occipital cortex. Using a slightly more lenient threshold of   Z   > 2.0,   p   < .05, corrected, revealed additional, stronger activation in the precuneus cortex of males. The latter effect, however, was due to greater   de  activation in this area in females during perception of same‐sex other bodies (Table   and Supporting Information Table  ). 

Contrasting perception of other bodies of the   same sex   (80%–100% morph) with one's   own body   (0% morph) revealed significant (  Z   > 2.3,   p   < .05, corrected) activation only in males in the bilateral temporal occipital and fusiform cortex (EBA, FBA), left precentral gyrus, and left ventrolateral PFC (Figure  ). Women showed no significant differences in activation between perception of the own body and perception of other females' body. Although there were no significant differences between females and males at the   Z   > 2.3 threshold, lowering the threshold to   Z   > 2.0 revealed that men had significantly greater activation in the bilateral FBA and bilateral lateral occipital cortex (EBA) (Table  , Figure  ). 
  
Brain activation in men (blue‐light blue color) and women (red‐yellow color) when viewing images of (a) a same sex other body and (b) an opposite sex other body, contrasted to images of the own body, respectively, and (c) when viewing images of the own body contrasted to images of an opposite sex other body; MNI coordinates of the slices shown: (a)   x   = 30,   y   = −48,   z   = −14; (b)   x   = 4,   y   = −54,   z   = −12; (c)   x   = 4,   y   = 24,   z   = −4; R = right, L = left; color bars indicate   z   value of the presented contrast 
    
Sex differences in activation, with men (M) showing greater activation than women (F) when viewing images of (a) a same sex other body and (b) an opposite sex other body, contrasted to images of the own body, respectively; MNI coordinates of the slices shown: (a)   x   = −42,   y   = −66,   z   = −2; (b)   x   = 6,   y   = −74,   z   = 10; R = right, L = left; color bars indicate   z   value of the presented contrast 
  

### Opposite‐sex other body perception 
  
Contrasting perception of other bodies of the   opposite sex   (80%–100% morph) with the   scrambled   control images revealed significant (  Z   > 2.3,   p   < .05, corrected) activation in both men and women in the bilateral lateral occipital cortex including the EBA and FBA, and the right dorsolateral PFC. Both groups showed significant deactivation in the angular and supramarginal gyri. Women, in addition, showed deactivations in the precuneus and left frontal pole. Direct comparison of men and women revealed significantly greater activation in men in the bilateral EBA and FBA, precuneus, left middle temporal gyrus, right‐TPJ (angular, superior temporal, and supramarginal gyri), and left frontal pole (Supporting Information Figure   and Table  ). Using a slightly more lenient threshold (  Z   > 2.0,   p   < .05, corrected), men showed additional stronger activations compared to women in the bilateral caudate nucleus and left inferior frontal gyrus (Table  ). 

Contrasting perception of other bodies of the   opposite sex   (80%–100% morph) with one's   own body   (0% morph) revealed no significant (  Z   > 2.3,   p   < 0.05, corrected) activations in women, whereas in men there was significant activation in the (pre)cuneus cortex, bilateral TPJ (supramarginal, superior temporal, angular gyri), and right middle temporal gyrus (both anterior and posterior parts) (Figure  ). The direct group comparison revealed significantly stronger activations in men than in women in the bilateral precuneus, supra‐ and intracalcarine cortices, and lingual gyri (Figure  ). With a threshold of   Z   = 2.0,   p   < 0.05, corrected, men showed additional greater activations than women in the bilateral caudate nucleus and left accumbens, frontal pole, right‐TPJ (supramarginal, middle temporal, superior temporal, angular gyri), and the bilateral anterior insular cortices (Table  ). 

By contrast, women showed pronounced deactivation (i.e., greater activation to their   own   bodies compared to opposite sex bodies) in the bilateral anterior insula, right anterior cingulate cortex, left cerebellum, left postcentral gyrus, left precuneus, and bilateral (though right‐dominant) TPJ (Figure  c). Deactivations (activation to their   own   bodies more than to opposite sex bodies) in males were detected in the bilateral anterior cingulate gyri, right ventrolateral PFC, right‐anterior insula, and right‐superior parietal lobule (Figure  c). Thus, greater activations in response to own body compared with opposite sex bodies were observed in both men and women, but more pronounced in women. This indicates that the sex difference pattern in regions such as the anterior insula and right TPJ was driven by greater activation to own bodies than opposite sex other bodies in the women, rather than greater activation for opposite sex other bodies in men. 


### Response‐dependent perception of images morphed to same‐sex and opposite‐sex other bodies 
  
When viewing images morphed to the   same sex   (20%–100%), participants' ratings of greater self‐similarity (greater “me” rating) was significantly (  Z   > 2.3,   p   < 0.05, corrected) associated with activation in the left postcentral gyrus in both males and females. Participants' ratings of greater self‐similarity (greater “me” rating), when viewing images morphed to the   opposite sex   (20%–100%), was significantly (  Z   > 2.3,   p   < .05, corrected) associated with activation in the bilateral insula, anterior cingulate, and paracingulate in both males and females. 

By contrast, participants' rating of less self‐similarity (greater “not me” rating) of images morphed to the   same sex   (20%–100%) was significantly (  Z   > 2.3,   p   < .05, corrected) associated with activation in the precuneus and bilateral middle frontal gyri only in females. There were no significant associations for “not me” ratings in males. Participants' ratings of less self‐similarity (greater “not me” rating) when viewing opposite‐sex other bodies were significantly (  Z   > 2.3,   p   < .05, corrected) associated with activation in the bilateral TPJ and precuneus in both men and women. Men in addition showed significantly (  Z   > 2.3,   p   < .05, corrected) associated greater activations in the vmPFC and bilateral anterior temporal gyri. When males and females were directly compared regarding associations to greater “not me” ratings, males had significantly (  Z   > 2.3,   p   < .05, corrected) stronger associations in the bilateral amygdalae, precuneus, and posterior cingulate (Table  ). 

As noted above, brain regions that were associated with participants' ratings of self‐similarity (whether greater “me” or “not me” rating) differed when participants were viewing either the opposite or same‐sex—suggesting that the activation could be perceptually driven. To further investigate this possibility, we directly contrasted viewing of opposite versus same sex images in a combined group of males and females when parameterized to greater “not me” rating. Here, greater   “not me”   ratings when viewing bodies of the   same sex   versus the opposite sex were significantly (  Z   > 2.3,   p   < .05, corrected) associated with activation in the bilateral insula, bilateral vlPFC, right dlPFC, anterior cingulate cortices, left thalamus, and left cerebellum. By contrast, greater   “not me”   ratings when viewing bodies of the   opposite sex   versus the same sex were significantly (  Z   > 2.3,   p   < .05, corrected) associated with activation in the bilateral lateral occipital cortex (EBA), precuneus/posterior cingulate cortex, vmPFC, and left‐FBA, providing further evidence that the pattern of activation could be perceptually driven (Table   and Figure  ). 
  
Brain activation for parametrically modeled greater “not me” rating while viewing images morphed to the same versus opposite sex 
      
Across male and female participants, parametrically‐modeled “not me” ratings when viewing images of same sex and opposite sex other bodies of different morph degrees; red color = activation for the contrast “opposite sex – same sex bodies rated as ‘not me’”; green color = activation for the contrast “same sex – opposite sex bodies rated as ‘not me’”; MNI coordinates of the slices shown:   x   = 6,   y   = −66,   z   = 6; R = right, L = left; color bars indicate   z   value of the presented contrast 
  


## DISCUSSION 
  
The current study investigated whether cerebral processing of the perception of one's own body and of other bodies in the context of self differs between men and women. Perception of own, unmorphed bodies showed no sex differences, and involved activation of a set of brain regions previously described to be associated with perceptual recognition of self as well as during perceptual decisions about object identity (Ploran et al.,  ). This included body perception regions (EBA, FBA), and areas involved in self‐referential processing, such as the medial PFC, anterior insula, and thalamus (Amodio & Frith,  ; D'Argembeau,  ; D'Argembeau et al.,  ; Denny et al.,  ; Mitchell et al.,  ; Murray et al.,  ; van der Meer et al.,  ). Furthermore, activation of bilateral caudate nuclei was observed, congruent with previous reports about its involvement in processing of body and limb posture (Villablanca,  ). Finally, there was deactivation of the precuneus, right temporal pole, and both TPJ‐regions known to be involved in self‐other distinction, mentalizing, and perspective taking (Eddy,  ; Payne & Tsakiris,  ; van der Cruijsen et al.,  ). We also found activation in the cerebellum during own body perception, which is in line with a study describing its inclusion in a neuronal network underlying illusory own‐body perceptions (Schutter, Kammers, Enter, & Van Honk,  ). 

In sum, own body perception in the context of self involves cerebral processes related to one's own body schema, identification of self, as well as the specific distinction and comparison of self from and with others. Importantly, these processes do not seem to differ between men and women. 

Interestingly, and to the best of our knowledge not described earlier, during perception of   other bodies of the same   sex (contrasted to the   scrambled image  ), men and women engaged very similar brain areas as when viewing their own body, including the EBA, FBA, bilateral caudate, thalamus, bilateral anterior cingulate cortices, bilateral anterior insula, ventrolateral PFC, and dorsal mPFC. This was true also for the deactivation pattern (TPJ, temporal pole), with the only exception that it was more right‐lateralized in women than in men (Eddy,  ). 

One possible explanation for this similarity is that self‐referential information may be experienced and generalized to others who look similar to us (Platek, Krill, & Kemp,  ; Tsakiris,  ). It was also suggested that coactivation of the reward system and the dorsal anterior cingulate cortices during evaluation of self compared to others might contribute to the integration of social comparisons into evaluation of self (Lindner et al.,  ). Interestingly, an fMRI study (Lübke et al.,  ) that used body   odors   rather than visual body stimuli found very similar brain regions involved during perception of others' (males and females) body odors—the fusiform cortex, the anterior and posterior cingulate cortices, and the anterior insular cortex. 

As opposed to the “own, unmorphed body” condition, viewing another body of the same sex revealed a sex difference, with men having a more pronounced activation than women in the left lateral occipital cortex, which could be an indication of heightened attention towards same‐sex others. There was also a sex difference in the precuneus cortex, due to greater   de  activation of this region in female participants, implying that women might have less of self and same sex other differentiation compared to men (see further discussion). 

Notably, these sex differences in   same‐sex other   body perception became even more apparent when   contrasted to the own body   (0% morphed, rather than scrambled image). Whereas in female participants there was no significant difference in brain activation during own body and same‐sex other body perception, (there was a stronger   de  activation of the EBA), in male participants there was an increased activation of the FBA, left precentral gyrus and left ventrolateral PFC–when viewing another same sex body compared to the own body. A recent study showed that these latter brain areas were involved in decoding familiarity (of faces, bodies, and gait) (Hahn & O'Toole,  ). It may thus be possible that men show increased engagement, together with higher attentional load, in cognitive decision processes on differentiating between self and same‐sex others. This potentially could be evoking intrasexual competition (Buunk & Massar,  ) and/or could help to discern what is related and similar as opposed to different from self. Moreover, the sex differences in neural activations during perception of bodies similar to one's own may indicate that women more easily adopt other female bodies as “self” than men. This is also supported by the observed cerebellar activations during own and same‐sex other perception specifically in females, which have been reported to be involved in illusory own body perception (Schutter et al.,  ). Thus, our findings may be interpreted as that women may more easily be able to put themselves in other females' shoes, which require Theory of Mind (ToM), the ability to explain and predict other people's mental states, and cognitive empathy. Indeed, several previous studies have suggested sex differences in mind reading abilities as well as empathy (Adenzato et al.,  ; Frank, Baron‐Cohen, & Ganzel,  ; Krach et al.,  ; Schulte‐Rüther, Markowitsch, Shah, Fink, & Piefke,  ; Singer & Lamm,  ). 

A third major observation in this study related to perception of bodies of the opposite sex. When compared to the   scrambled image  , both men and women activated general as well as body perception‐specific attention circuits (EBA, FBA, right‐dorsolateral PFC). However, and notably, sex differences were most pronounced when contrasting viewing bodies of an opposite sex other to the   own body   (unmorphed image). The two groups differed distinctly in that men activated, whereas women   de  activated the precuneus and right TPJ. In addition, during viewing an opposite sex other body and when rating an image of their body that appeared female (morphed to the opposite sex) as “not me,” men showed activation in the visual cortex, caudate nucleus, precuneus, and bilateral amygdala, regions reported to be involved in other rather than self‐orientation (Bischoff et al.,  ; Eddy,  ), sexual arousal (Ponseti et al.,  ), and emotional salience (Gerber et al.,  ; Phan et al.,  ). 

Together, these data hint that the other body in relation to self might have a greater salience in men (van Hooff, Crawford, & van Vugt,  ), whereas for women images of the own body are more salient. The observed sex differences may have implications when trying to understand conditions involving own body perceptions such as anorexia nervosa, gender dysphoria, or autism spectrum disorders, which all show a sex skewed prevalence. Females previously were found to be more sensitive to information about their own body than males (Mitchison et al.,  ; Powell & Hendricks,  ), and therefore perhaps have a less distinct or a more vulnerable own body schema, rendering them more prone to internalized distorted perceptions of their own bodies. Females may also easier adopt other females' bodies as “self” and, conversely, do not accept the image of one's body as “self.” Worth mentioning is that all the participants were heterosexual, thus the discussion only pertains to heterosexual cis‐gender persons. 

In addition to investigating whether men and women engage different cerebral networks during perception of own and other bodies in the context of self, we also approached this at a different level: when distinguishing self from others, does the brain show differences depending on whether it is viewing the same or the opposite sex? To investigate this, we directly contrasted rating “not me” of same sex versus rating “not me” of opposite sex bodies. Here, greater   “not me”   ratings when viewing   same sex   bodies compared with opposite sex bodies was significantly associated with activation in regions involved in (illusory) own body perception and comparative processes (Kedia, Mussweiler, & Linden,  ). Yet, the same   “not me”   ratings but when viewing   opposite sex   bodies compared with same sex others did engage (body) perceptual and evaluative regions (Kedia et al.,  ). This suggests that the activations were dominated by perceptual—the type of visual body stimuli—rather than cognitive processes, since the latter was same in both cases: rating “not me.” 

Interestingly, and in support of this notion, a neuroimaging study using body odor stimuli from either the sisters or same‐sex best friends of a group of 12 women, showed that, independently of conscious recognition, olfactory‐based kin recognition activated self‐referential brain regions when smelling body odors of their sisters as compared to their female friends (Lundström, Boyle, Zatorre, & Jones‐Gotman,  ). In that study, kin recognition, via the mechanism of so‐called “automatic self‐referent phenotype matching” (Mateo & Johnston,  ), recruited self‐referential networks without any cognitive or conscious identification process involved. Together with the current study, these observations suggest that sensory body perception (visual or olfactory) seems to overrule cognitive perception (i.e., labeling a given body as “me” or “not me”), which was previously shown for other stimuli of high social and ecological importance, such as body odors, emotional faces, and infant crying and laughing sounds (Lundström, Boyle, Zatorre, & Jones‐Gotman,  ; Morris, Öhman, & Dolan,  ; Seifritz et al.,  ). Whether this overruling of sensory over cognitive perception also applies to other stimuli remains to be further investigated. 

Our findings should be viewed in light of its limitations. First, we did not assess participants' impression of the body stimuli afterward outside the scanner in terms of how attractive the opposite‐sex, or same‐sex body stimuli were perceived. It is possible that the male participants considered the opposite sex stimuli as more attractive than did the female participants, which might partially explain our findings of stronger attention and reward‐related brain activation in men for this condition. In addition, this information would have helped to establish more direct links between the activation patterns and cognitive/evaluative processes other than the subjective degree that the body was similar to theirs, about which we could only make post hoc inferences. We also did not obtain any ratings from independent raters of how similar the morph‐to stimuli bodies were to the participants' bodies and did not measure participants' body weight or body mass index. It may have theoretically been possible, by chance, that the female morph‐to bodies used were better comparable, in terms of, for example, height, weight, shape, or muscularity, to those of the female participants than how the male morph‐to bodies compared to the male participants' bodies. This might have affected the sex differences we observed in the same‐sex other versus own body condition. However, this is mitigated partially by the fact that based on the investigators' subjective impression, none of our participants had extremely different body composition than the morph‐to stimuli bodies; for example, none appeared obese or extremely underweight. Finally, though only (self‐reported) healthy participants were included, we did not perform a structured assessment of any prior or current eating disorder (or other psychiatric disorders). Therefore, we cannot rule out that there may have been (if the participants were unaware or did not report accurately) any disturbances in body image or possible concerns about the own body, that might have resulted in own‐body stimuli being much more emotionally salient and that might have been more common in one of the groups. 

In conclusion, we provide first evidence that the neural representation of own body does not differ appreciably between the sexes. In contrast, perception of other bodies, in particular of the opposite sex, could be a particularly salient social signal to men, whereas for women the own body likely has higher relevance. 


## CONFLICT OF INTERESTS 
  
The authors have no conflict of interest. 


## Supporting information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-30'>
<h2>30. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/19384602/' target='_blank'>19384602</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Audiovisual Non-Verbal Dynamic Faces Elicit Converging fMRI and ERP Responses</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Brain Topogr</p>
<p><strong>Publication Year:</strong> 2009</p>
<p><strong>DOI:</strong> 10.1007/s10548-009-0093-6</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/2707948/' target='_blank'>2707948</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study reports fMRI data collected from a group of healthy adult participants (10 right-handed males, ages 24–37) performing a social-related task: perception/integration of non-verbal vocalizations with facial movements (social communication/perception of others). Group-level voxelwise whole-volume analyses (voxel-by-voxel parametric t tests with multiple comparisons correction using AlphaSim) are reported alongside ROI analyses, so findings are not limited to ROI-only results. Results for the healthy participant group are reported separately. Although slice coverage was limited (targeting lateral temporal cortex), analyses were voxelwise rather than ROI-only. Therefore the study meets the review’s inclusion criteria for fMRI studies of social-related processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
In an everyday social interaction we automatically integrate another’s facial movements and vocalizations, be they linguistic or otherwise. This requires audiovisual integration of a continual barrage of sensory input—a phenomenon previously well-studied with human audiovisual speech, but not with non-verbal vocalizations. Using both fMRI and ERPs, we assessed neural activity to viewing and listening to an animated female face producing non-verbal, human vocalizations (i.e. coughing, sneezing) under audio-only (AUD), visual-only (VIS) and audiovisual (AV) stimulus conditions, alternating with Rest (R). Underadditive effects occurred in regions dominant for sensory processing, which showed AV activation greater than the dominant modality alone. Right posterior temporal and parietal regions showed an AV maximum in which AV activation was greater than either modality alone, but not greater than the sum of the unisensory conditions. Other frontal and parietal regions showed Common-activation in which AV activation was the same as one or both unisensory conditions. ERP data showed an early superadditive effect (AV > AUD + VIS, no rest), mid-range underadditive effects for auditory N140 and face-sensitive N170, and late AV maximum and common-activation effects. Based on convergence between fMRI and ERP data, we propose a mechanism where a multisensory stimulus may be signaled or facilitated as early as 60 ms and facilitated in sensory-specific regions by increasing processing speed (at N170) and efficiency (decreasing amplitude in auditory and face-sensitive cortical activation and ERPs). Finally, higher-order processes are also altered, but in a more complex fashion. 

## Electronic supplementary material 
  
The online version of this article (doi:10.1007/s10548-009-0093-6) contains supplementary material, which is available to authorized users. 

 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (41009 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Everyday social interactions involve the integration of auditory and visual information from speech and non-verbal social cues. These latter cues are often underemphasized in humans, as most attention tends to focus on the spoken word (Campbell et al.  ; Capek et al.  ; Frith and Frith  ; Kawashima et al.  ; Macaluso et al.  ; MacSweeney et al.  ). Humans generate many non-verbal vocalizations that are accompanied by readily identifiable stereotypical facial gestures (Howell  ). Non-verbal vocalizations likely engage higher-order processing, and can be overlooked, misused, or misinterpreted by those with social cognition disorders (Golarai et al.  ; Luyster et al.  ; Sarfati et al.  ; Troisi et al.  ). Non-verbal vocalizations can be communicative as one may purposely vocalize or exaggerate non-verbal cues to send a message, such as burp to signal the deliciousness of a meal, or one may purposely suppress a sign or yawn to conceal dissatisfaction or boredom. Social and other advantages may thus come from the ability to interpret information about the mental, emotional, or homeostatic state of individuals as conveyed through multisensory non-verbal cues. This is supported by studies that show greater activation to human non-verbal stimuli versus other non-human categories in multiple regions including STS, frontal parietal regions, and insula (Fecteau et al.  ; Lewis et al.  ). 

In a normal context, the accurate interpretation of socially related non-verbal information requires appropriate integration of multisensory input, usually visual and auditory information, which can change based on incoming information quality. In a noisy situation like a crowded bar, one observes lip and face movements more than in a quiet setting, as the visual information can effectively amplify the audio by up to 11 dB (MacLeod and Summerfield  ). Behavioral studies of both speech and non-speech stimuli indicate that multiple (congruent) stimulus modalities lead to improved processing, with both shorter reaction times and increased accuracy compared to either modality alone (Grant and Walden  ; Miller  ; Sumby and Pollack  ). 

These behavioral advantages for multisensory stimuli manifest as differences in timing, amount and type of brain activity compared to unisensory stimuli. However, studies have revealed conflicting results including both facilitation, in the form of faster and   decreased   brain responses (for fMRI Martuzzi et al.  ; Wright et al.  ; for ERPs Besle et al.  ; van Wassenhove et al.  ), and enhancement, or   increased   activation, for multisensory versus unisensory stimuli (Hubbard et al.  ; Kayser et al.  ). The reasons for these differences in multisensory effects are not understood, although some studies suggest that they may be related to factors such as congruency (Puce et al.  ; Saint-Amour et al.  ), whether one modality predicts the other (Ghazanfar et al.  ; Stekelenburg and Vroomen  ), or neuronal population properties (Laurienti et al.  ; Stevenson et al.  ). Even more complex results have been seen for higher-order regions, with effects (in speech-related studies) seen in posterior superior temporal sulcus (pSTS), inferior parietal lobule (IPL), and inferior frontal cortex (IFC) (Calvert et al.  ; Kawashima et al.  ). In the current study we were particularly interested in multisensory effects in pSTS due to its postulated role in social related processes (Redcay  ), and links to different visual, auditory, and motor processes (Beauchamp et al.  ). 

To investigate multisensory effects related to human non-verbal vocalizations and accompanying facial movements, we studied neural responses elicited to an animated synthetic female face producing various non-verbal vocalizations (i.e. coughing, yawning), using both functional magnetic resonance imaging (fMRI) and event-related potentials (ERPs). We presented stimuli under three conditions. In the audiovisual (AV) condition participants saw the animated face and heard congruent human vocalizations. In the visual (VIS) condition, only the animated face was seen, whereas in the auditory (AUD) condition only the vocalizations were heard. Randomized blocked presentations of AV, VIS and AUD conditions were alternated with rest (R). Two participant groups (  n   = 10 for fMRI,   n   = 13 for ERPs) responded to infrequent unisensory targets (animated face blinking, or uttering “mmm” without a visual change to the face). Our hypothesis predicted that sensory-specific regions specialized for a given unisensory condition, would show facilitated processing (faster times to peak and reduced amplitudes) in the presence of a multisensory stimulus. Specifically, for the fMRI experiment, we predicted a reduced BOLD signal for the AV versus either unimodal condition in sensory regions. For the ERP experiment, we predicted reduced amplitudes and faster latencies for early ERP components. In addition, we predicted that higher-order regions, especially right pSTS, would show greater AV activation (versus unisensory conditions) due to specialization in multisensory and/or social processes. 


## Materials and Methods 
  
### Participants 
  
For the fMRI study 10 right-handed healthy males participated (ages: 24–37 years, mean 28 years). For the ERP study, there were 13 right-handed participants (18 originally collected, 5 excluded, for the 13 included participants: 7 males, ages: 19–43 years, mean 29 years). All participants had either normal or corrected-to-normal vision and gave informed consent in a study approved by the Institutional Review Board for the Protection of Human Participants at West Virginia University. 


### Stimuli and Task 
  
Participants viewed 4 × 4 degree videos of a synthetic female face producing facial movements and vocalizations. Stimuli were seven non-speech vocalizations with accompanying face movements consisting of a cough, sneeze, burp, yawn, laugh, sigh and whistle. Two infrequently presented unisensory target stimuli, a blink (visual) and an uttered ‘mmm’ (auditory), made participants focus on visual and auditory sensory input equally. In the Audiovisual condition, there was a 33 ms (or 1 video frame) delay between the peak movement (i.e. fully opened mouth) and sound. Animations were based on filmed real life movements associated with the seven non-verbal vocalizations of three different actors. 

Stimulus type was pseudorandomly ordered within 20 s stimulus blocks consisting of 10 trials each of combined Audiovisual stimulation (AV), Auditory stimulation only (AUD), and Visual stimulation only (VIS) (Fig.  ). In the AV participants saw the face making the facial movements and heard the associated non-speech vocalizations. In VIS, participants observed the face making movements without hearing the vocalizations. In AUD, participants viewed a neutral colored plain background (RGB = 140, 132, 127) and heard the vocalizations. The absence of the face for the AUD condition prevented an ‘incongruent’ stimulus (face still but vocalization present), but made an event-related design difficult due to onset effects. Visual motion duration and sound duration was 600 and 567 ms respectively, for all non-target stimulus types. Participants maintained their gaze on an ever-present green fixation cross and pressed a single response button when either of one of the two specified unisensory targets were seen or heard. Behavioral responses were monitored to ensure attentional alertness. Minor variations in timing occurred for the fMRI versus ERP paradigms.   
Example of a stimulus still frame depicted at the middle of an animation.   a   In the AV condition, the face is present and the non-verbal vocalization accompanies the visual stimulus. Here a yawn is depicted and the open mouth and narrowing eyes can be clearly seen.   b   In the VIS condition only the moving face is present.   c   In the AUD condition only the vocalizations are heard. For all conditions a green fixation cross was located in same position on the screen throughout scans (between the eyes when the face present in the AV and VIS conditions) 
  


### Data Acquisition 
  
#### Functional MRI Study 
  
Data were acquired on a 3 Tesla GE Horizon LX MRI scanner and quadrature birdcage headcoil. We used a 14 slice split-sagittal acquisition (Puce et al.  ), where 7 sagittal slices (3 mm thickness + 1 mm gap) were taken in each hemisphere to maximally visualize the cortex of the STS and STG (see Supplementary Fig.  ). A series of 125 gradient echo echoplanar volumes were acquired over each of the three, 4 min 10 s stimulation periods (after before and after rest period removal, total = 375 volumes) using the following parameters: TE = 35, TR = 2000, α = 70°, NEX = 1, BW = 125, FOV = 24 mm, matrix = 128 × 128 (in-plane resolution of 1.875 mm), slice thickness = 3 mm, gap = 1 mm. In the Talaraich   x   plane, sagittal slice coverage was from   x   = −34 to −67, and   x   = 34 to 67. 

A T1-weighted whole brain volume which was acquired as a high-resolution spoiled gradient-recalled acquisition in a steady state (SPGR) (voxel size = 1.2 × 0.9375 × 0.9375 mm; FOV = 240; matrix = 256 × 256; 124 slices). 


#### EEG/ERP Study 
  
Participants were seated comfortably in an armchair in a dimly lit room with a white noise generator. A continuous 128-channel recording of 124 channels of scalp EEG (QuikCap, Compumedics Neuroscan, El Paso, TX, USA) and 4 channels of horizontal and vertical electrooculograph (EOG) was taken using Neuroscan 4.3 software (Compumedics, Neuroscan, El Paso, TX, USA). Data were sampled at 250 Hz/channel and bandpass filtered from 0.1 to 100 Hz and amplified with a gain of 5,000. A reference consisted of two electrodes placed either side of the nose or on the cheek close to the nose. The midline frontal ground electrode was sited on the electrode cap itself. Electrode impedances were kept below 10 kΩ. 



### Data Analysis 
  
#### Functional MRI 
  
Data reconstruction was implemented via Analysis of Functional Neural Images (AFNI), version 2.31 software (Cox  ). Data processing steps included offline image reconstruction in conjunction with smoothing in Fourier space via a Fermi window (full width at half maximum = 1 voxel), correction for differences in slice-timing, and 6-parameter rigid-body motion correction. The motion estimates over the course of the scan for translation (inferior–superior, right–left, and anterior–posterior) and rotation (yaw, pitch, roll) parameter estimates were used as covariates in further analyses. 

Each image time series was spatially registered to the volume closest in time to the high-resolution structural scan both within-plane and then in all three planes using an iterative linear least squares method, to reduce the effects of head motion. AUD, VIS, and AV blocks were analyzed with a least-squares general linear model (GLM) fit that modeled each activation block and head motion parameters. Each regressor consisted of an ideal hemodynamic response function for the specified block type, obtained by convolving the event time file (across 3 concatenated imaging runs) with a γ-variate function. The beta-weights resulting from the GLM analysis were converted to percent signal change using the mean overall baseline and spatially smoothed using a 4 mm Gaussian filter. These percentage signal change maps were transformed into standardized Talaraich space. 

A voxel-by-voxel parametric two-tailed   t   test was used on the percent signal change maps for a group comparison of each condition (versus rest) separately, plus AV versus AUD + VIS.   P  -value correction for multiple comparisons was based on a combination of threshold cutoff and cluster extent using 3dmerge (AFNI). Minimal cluster size was calculated using Monte Carlo simulation program AlphaSim (AFNI). For a masked AFNI image, AlphaSim ran 1,000 iterations, with a radius connectivity of 4.1 (since slice thickness + gap was 4 mm) and image defined Gaussian filters with FWHM determined with 3dFWHM. The minimal cluster size to avoid false cluster detection was 57 voxels for   P   < 0.05, 16 voxels for   P   < 0.01, 11 voxels for   P   < 0.005, 6 voxels for   P   < 0.001. Alpha maps were overlaid on inflated PALS atlas cortical model brains (Van Essen  ; Van Essen et al.  ). 

Regions of interest (ROIs) were based on significant activation from the analyses above. The average time course of the MR BOLD response in select ROIs was generated using the AFNI 3dDeconvolve program with the iresp option. The average time courses for each condition (AUD, VIS, AV, ApV) were averaged within each ROI and normalized across datasets. For a given hemisphere, we took voxels showing significant activation from that hemisphere plus its mirror opposite correlate (using 3dLRflip in AFNI), such that each ROI had equivalent right and left hemisphere volumes. 


#### Event-Related Potentials 
  
ERP analysis was performed using Neuroscan 4.3 Software (Neurosoft, Inc., Sterling, VA, USA). EEG data were first segmented into 1500 ms epochs with 100 ms pre-stimulus baseline based on the event markers which identified each trial type. The EEG data of the target trials were not included in subsequent analyses (similar to the fMRI study). Epochs containing artifact registering greater than ±100 μV, due primarily to eye blinks, or electromyographic activity due to face or head motion, were excluded from subsequent analyses. We excluded data from five of the eighteen participants (three participants had technically suboptimal studies due to excessive eye blinks/muscle activity in their EEG data, and two participants were deemed to be overly familiar with the stimuli and showed low alertness levels during the study), leaving thirteen participants in the final ERP analyses. 

The zero time point was the start of the audio, visual or simultaneous audiovisual stimulus. Individual epochs were normalized relative to a 100 ms prestimulus baseline, and linear trend was calculated and removed across the entire epoch, based on the prestimulus baseline. Stimulus types for each condition (AUD, VIS, AV) were averaged across all 6 runs. Each participant’s averaged ERP data were then digitally smoothed with a zero phase-shift low pass filter (cut-off 30 Hz, 6 dB/octave). 

Group averages were constructed and the averaged ERPs were scrutinized to identify ERP peaks and troughs. P100, N170, P250, and P500 ERP components were identified in the group average waveforms. Area under the curve (AUC) ranges were also selected for certain broader peaks. Latency ranges (windows) were selected for each grand average ERP peak or trough, and an automated peak picking routine was then run on the averaged ERP data of each individual subject. Area under the curve (AUC) measures were also taken for selected ERP components. Each subject’s ERP waveforms and ERP peak amplitude and latency measures and AUCs were exported as sets of ASCII files. 

Topographic voltage maps were created from the grand average ERP data at peak and trough timepoints to examine the regional distribution of ERP activity. Data from multiple sensors showing similar ERP behavior were then averaged as noted in the results section, with location of sensor markers determined by averaging Polhemus digitizer locations. 

Data at eye channels were also displayed in order to determine whether ERP signals may have been influenced by systematic, but subtle, eye movements. The signal excursion for the artifact free data in the eye channels was small (on the order of μV) and therefore did not appear to be due to actual eye movements which typically generate signals on the order of mV. In addition, the lower horizontal EOG channels did not show an equal and opposite negativity, suggesting that the positivity in the upper vertical EOG channel, located on the forehead, was likely due to frontal brain activity and not to eye related activity per se. 


#### Statistical Analysis of ERP Data 
  
Student’s   t   tests, one-way (Condition) and two-way (Condition by Hemisphere) ANOVAs of peak amplitudes, latencies, and AUC for particular ERP components were analyzed using SPSS V15. In order to objectively determine the timepoints for AUC measures, we calculated timepoint by timepoint values for the   t   test difference for AV versus AUD plus VIS. Thus, we set as time regions for AUC, periods of sustained (20 ms, 5 timepoints) significant differences (  t   > 1.67 for   n   = 60 epochs) between the multisensory and sum of the unisensory conditions. We used similar calculations to measure the time elapsed, after which no significant peaks occurred, an effective Return to Baseline (RTB). To determine the RTB we first calculated the   t   value versus zero for each point on the waveform. The RTB was defined as the end of the last significant peak of sustained (20 ms, 5 timepoints) significance. 




## Results 
  
### fMRI Data 
  
Ten participants completed the non-verbal unisensory target detection task in a 3T MRI scanner. A split sagittal slice acquisition optimized sampling of temporal cortex, but excluded medial regions as well as more medial aspects of frontal parietal cortex, fusiform and early visual cortex. 

All three conditions produced robust activation in sensory and higher-order cognitive regions. AUD and AV conditions produced additional and extensive activation of mid- to anterior STS and mid-insula (Fig.  a, c), whereas VIS and AV conditions produced activation of lateral occipital and posterior middle temporal gyrus (LO/pMTG) and lateral fusiform gyrus (Fig.  b, c). Brain regions showed multisensory relationships that fell into four main categories (Fig.  ):   
Group fMRI activation maps for each stimulus condition, AUD (  a  ) VIS (  b  ) and AV (  c  ) versus REST.   Warm colors   represent net positive BOLD signal,   cool colors   represent net negative BOLD signal.   d   Difference maps for VIS versus AUD. Regions more active in the VIS condition are represented by   warm colors   (  P   < 0.01 corrected).   e   Common activation maps (  black  ) for AV, VIS and AUD (  P   < 0.001 corrected). Overlaid regions show mathematical superadditivity (  solid white lines  ) and underadditivity (  dashed white lines   P   < 0.05 corrected) 
    
Group fMRI data ROI analyses: underadditive BOLD responses. Histograms depict relative fMRI percent signal change for all three conditions in   underadditive   ROIs (  a  –  c  )   AV maximum   (  d  –  e  ) and   common-activation   ROIs (  f  ).   Asterisks   indicate pairwise   t   test significance: *   P   < 0.05, **   P   < 0.01, ***   P   < 0.001 
    
 superadditive  , defined as audiovisual greater than the sum of auditory alone and visual alone i.e. AV > ApV; 
  
 underadditive  , defined as audiovisual less than the sum of auditory and visual alone, and audiovisual less than the dominant sensory modality e.g. AV < ApV and AV < AUD or VIS; 
  
 AV maximum  , defined as audiovisual greater than either unisensory condition along (AV > VIS and AV > AUD, and VIS > 0, AUD > 0). 
  
 Common activation  , defined as AV activation equal to one or both conditions (AV = AUD and/or VIS. Note that for both AV maximum and Common activation, audiovisual would be less than the sum of the unisensory conditions (AV < ApV). 
  

Two regions showed mathematical   superadditivity,   the right insula/frontal operculum and left angular gyrus. However, this resulted from negative activation versus baseline in one or in all three conditions, and neither region showed significant positive activation for the AV condition (solid white outlines, Fig.  d). 

Several regions showed significant or near-significant   underadditive   effects including MTG, LO/pMTG, and lateral fusiform gyri, with the AV condition showing decreased activation compared with either unisensory condition or the sum of the unisensory conditions, ApV (Table  A). The AUD-preferred region, left mid-MTG, showed a trend (  P   < 0.1) of AV < AUD. Similarly, for the VIS-preferred regions, LO and fusiform gyrus, there was a significant difference and trend, respectively, of AV < VIS. LO and fusiform also showed a right-hemisphere bias (Table  A).   
Summary of significant and trend effects resulting from 2-way ANOVA comparisons for (A) fMRI and (B) ERPs 
  
The middle columns show the results of AV versus ApV, while the right columns show the effects for AV versus VIS and AV versus AUD. B has an additional set of columns for ERP latency effects.   Asterisks   indicate   P  -value of   F   statistic: *   P   < 0.05, **   P   < 0.01, ***   P   < 0.001, ****   P   < 0.00001. All effects were tested, but non-significant interactions are listed as n.s. or are omitted. In several cases, noteworthy   t   tests are listed 
  

 AV maximum   and Common activation   effects were seen in frontal, parietal and temporal regions (Black overlay at   P   < 0.001, Fig.  d). The pSTS, TPJ, IFG, and DLPFC all showed strong condition effects for AV < ApV (Table  B). Portions of these regions were also revealed in a voxelwise   t   test of AV versus ApV (dashed white lines in Fig.  d). The pSTS showed a significant hemisphere effect (right > left), with the VIS condition showing the strongest lateralization (  t   = 4.98,   P   < 0.005).   AV maximum   activation was seen in several of these regions, including right posterior pSTG (  P   < 0.01 versus VIS,   P   < 0.001 versus AUD), and TPJ (  P   < 0.01, versus VIS,   P   < 0.05 versus AUD). IFG and DLPFC showed   common activation,   with the AUD condition showing the least activation in DLPFC. 

The STS and IFG regions, in addition to showing at least a trend towards hemisphere effects for amplitude of activation (Table  A), also showed a greater number of active voxels in the right versus left hemisphere (Right STS: 134 versus Left STS: 0; Right IFG: 1871 mm  versus Left IFG: 157 mm ), thus showing right hemisphere dominance in both magnitude and extent of activation. 

A separate group of 13 participants participated in the ERP version of the experiment. Since the neutral, eyes forward face was present as a baseline for the duration of VIS and AV blocks (except during movements), the zero time point for ERP measurements is at the onset of the facial movement and/or simultaneous vocalization (for AUD, onset of vocalization). In general, ERP waveforms revealed modality-specific early components with characteristic topographies and morphologies, in addition to a late positivity (Fig.  ). Stimuli containing auditory stimulation (AUD and AV conditions) showed the typical auditory N140 with an amplitude maximum at midline central electrodes. Stimuli containing visual stimulation (VIS and AV conditions) showed the typical face-specific N170 at bilateral temporo-occipital electrodes, showing delayed latencies typical of dynamic visual stimuli. In addition to showing both typical auditory and face-related components, the AV condition also elicited a unique early positivity in left parieto-occipital electrodes. All three conditions showed a diffuse late positivity which lasted up to 1500 ms, and varied in amplitude between conditions. A   t   test of AV versus ApV was used to search for regions of potential multisensory effects. Again, effects were grouped into the four categories of   superadditive  ,   underadditive, AV maximum   and   common-activated  .   
Group average topographic ERP maps as a function of condition and time. Topographic maps are depicted at post-stimulus time points of 80, 140, 270 ms, and then every 100 ms for all three stimulus conditions (  top three rows  ). The   bottom row   shows difference maps for the AV condition minus the sum of the unisensory conditions (ApV).   Red-yellow   shows positive ERP activity,   blue-aqua   show negative ERP activity. Topographic maps showing timepoints analyzed in subsequent figures are labeled 
  

#### Superadditivity at 60–148 ms 
  
At this relatively early post-stimulus time range, the AV condition elicited an early positivity in bilateral temporo-occipital electrodes that was not seen in either unisensory condition (Figs.  ,  a). We performed a timepoint-by-timepoint   t   test analysis to determine the time range showing significant differences between AV and AUD plus VIS (i.e. AV versus ApV), and performed an AUC analysis for this time range (60–148 ms). A two-way ANOVA revealed superadditivity, with main effects of Hemisphere [  F  (2,24) = 16.67,   P   < 0.01].   
Superadditivity in group ERP averaged data at bilateral temporo-occipital electrodes (from 60 to 148 ms). Histograms for area under the curve (AUC) analysis for time range 60–148 ms. Topographic map shows 12 sampled electrodes (  white dots  ). Waveform for 6 averaged right temporal occipital electrodes shows unique peak for AV (  black circle  ).   Asterisks   indicate pairwise   t   test significance 
  


#### Trend Towards Underadditivity for N140 
  
AUD and AV, but not VIS, conditions elicited a central negativity at 144.7 ms, typical for auditory stimuli (Fig.  a). Peak amplitude analysis revealed a trend for AUD > AV (Table  B), but found no significant super- or underadditivity.   
Underadditivity in group averaged ERP data in relatively early post-stimulus timeranges. Histograms for peak amplitude for   a   N140 and both peak amplitude and latency for   b   N170. Averaged ERP waveforms for sampled electrode sites (  white dots   on topographic maps), appear at the right of the histograms.   Asterisks   indicate pairwise   t   test significance.   P  -values listed for non-significant trends 
  


#### Underadditivity for N170 
  
All three conditions produced a negativity at an average 276.7 ms, with preference for conditions including visual stimuli (Fig.  b). The waveform was characteristic of the N170 which is elicited by dynamic faces, peaking at temporo-occipital electrodes, with a right hemisphere bias (Fig.  c, white dots). As the stimulus was dynamic, the N170 was considerably delayed relative to the 170 ms typical for the presentation of static face stimuli (see Puce et al.  ). Face movement began at 0 ms and was generally identifiable as a particular “vocalization” by 33 ms. Although the AV and VIS N170 s were larger, the AUD condition also elicited a negativity that had a similar timecourse at these electrodes (274.8 ms). The N170 was underadditive, such that AV < ApV, and showed condition and hemisphere main effects (Table  B). Peak analysis revealed reduced amplitude and decreased latency for the AV versus VIS condition, as well as a right hemisphere bias for amplitude (Table  B). 


#### AV Maximum and Common Activation for Late Positivities 
  
All three conditions elicited widely distributed late positivities (Fig.  ). A strict AV versus ApV   t   test revealed an underadditivity at bilateral temporo-parietal electrodes at 230–304 ms (timepoint-by-timepoint   t   test, Fig.  a). Even though the peaks were broad, we used a semi-automated peak analysis with verification of peaks in individual subjects data. We wanted to examine the data for latency differences, and more strictly apply multisensory criteria (at the time of the AV and AUD peaks, the VIS peak has yet to appear). The temporo-parietal peak occurred at 240 and 244 ms respectively for the AUD and AV conditions, but was delayed at 328 ms for the VIS condition. This peak was considered a   common activation,   as analysis, using the homologous peaks for all three conditions, did not show any significant amplitude differences between conditions (Table  B).   
Later ERPs histograms and waveforms. Charts showing peak amplitude and latency analysis for Common activation   a   12 temporo-parietal electrodes (6 in each hemisphere) in the post-stimulus timerange, 230–304 ms and AV maximum,   b   8 frontal-temporal electrodes in the timerange 460–616 ms. Rightmost panel in each row shows ERP waveforms for each condition along with AV-ApV topographic maps (sampled electrodes are   white dots  ).   Asterisks   indicate pairwise   t   test significance. Very late timeranges show common activation in occipital and frontal electrode sites (  c  –  e  ) 
  

An underadditivity was seen at right fronto-temporal electrodes at 460–616 ms (timepoint-by-timepoint   t   test, Fig.  b). Latency of this broad peak was also greatest for the VIS condition (492 ms) and was similar across the AUD and AV conditions (384 and 400 ms, respectively). Analysis of homologous peaks revealed a Condition effect, with the AUD condition showing the smallest amplitude (Table  B). This peak was considered an   AV maximum  , as the AV condition was significantly greater than either unisensory condition in the right hemiscalp, and a similar trend was seen in the mirror opposite electrodes (Fig.  b). 

 Common activation   was seen at several other electrode sites, include occipital and frontal electrodes. Occipital electrodes showed equivalent sustained activation for all three conditions in the 700–800 ms range (Fig.  c). In contrast, for frontal electrodes, F5 and FPZ, late sustained activation was only seen for AV and VIS conditions and not the AUD condition (rectangles, Fig.  d, e). Note at F5 the   AV maximum   peaks at the 250 ms and 450 ms ranges (circle, Fig.  d). 



### Results Summary 
  
The ERP data showed a unique early positivity for the AV condition starting at 60 ms. In sum, however, there was convergence of ERP and fMRI data. Both the N140 (generated in the superior temporal plane) (Giard et al.  ; Godey et al.  ; Ponton et al.  ), and the auditory STS showed non-significant trends towards underadditivity. For VIS related processing, AV activation was significantly reduced (smaller amplitude ERPs and BOLD responses) compared to the preferred unisensory stimuli (VIS). Finally, multiple “higher-order” cortical regions, as well as late time ranges typically associated with more higher-order processes showed significant or near significant trends of AV maximum activation (AV greater than either condition alone). Other regions/timeranges showed common activation in which AV and one or both conditions showed similar degrees of activation. Several of these regions and timeranges showed a right hemisphere bias. 



## Discussion 
  
Using an animated synthetic face and associated real human non-verbal vocalizations we elicited reliable fMRI activation to unisensory and multisensory stimulation in an imaging study designed to optimally image the STS/STG in its entirety, while still including face-sensitive and auditory regions in lateral sensory cortex. In a second group of subjects we elicited reproducible and consistent ERPs to the relatively long durations of the facial motion and associated vocalizations. Subjects were asked to detect unisensory target stimuli (a blink and an “mmm” sound) so that we could study audiovisual integration without a bias to a particular sensory modality. We discuss our results, summarized in Fig.  , in the context of other audiovisual non-biological and speech integration studies, and in more general terms of social cognition.   
Summary of main fMRI and ERP findings in terms of time of occurrence relative to stimulus onset and type of multisensory phenomenon 
  

### Multisensory Effects in Sensory-Related Processes 
  
Multisensory effects were seen in early regions (fMRI data) and ERP components which supported our hypotheses predicting facilitation effects. Interestingly, we also observed a unique early AV ERP component. This AV positivity peaking around 60–80 ms is similar to that seen in recent audiovisual integration studies (Giard and Peronnet  ; Shams et al.  ). Somewhat surprisingly, these studies, which used   non-biological   stimuli, showed early AV integration effects whose laterality was opposite to ours. Giard and Perronet ( ) proposed that their early ERP response may stem from the recruitment of specific multisensory cells in or near striate cortex, where bisensory cells have been seen observed in animals (Fishman and Michael  ; Morrell  ). Due to our slice selection in our fMRI study, we could not confirm whether multisensory effects occurred in early visual cortex, however, such early effects in humans have been seen in other studies (Martuzzi et al.  ). 

Aside from the unique AV ERP signal, AUD and VIS-related sensory-related regions and ERP signals showed multisensory effects characteristic of facilitation, as predicted by our hypothesis. Significant effects were seen in VIS-related regions (LO) and ERP components (N170), and trends in the same direction were seen in fMRI activated AUD-related regions and ERP components (mid-MTG and N140). The strongest case of fMRI and ERP convergence was at mid-level visual processes, characterized by a right hemisphere bias and decrease in both amplitude (fMRI and ERP) and speed (ERP) of AV versus VIS. 

The auditory trend towards facilitation was consistent with the role of the centrally located N140 in multisensory integration (Besle et al.  ; Puce et al.  ; van Wassenhove et al.  ). A study by Puce et al. ( ) showed the largest N140s were elicited when a dynamic human face (relative to house and primate face stimuli) was paired with incongruous sounds, suggesting that the context provided by a conspecific (human) face influences associated auditory processing. Additionally, when congruous sounds were presented, the N140 was largest to both human and primate faces when paired with species-appropriate vocalizations relative to a house stimulus whose front door opened with a creaking door sound (Puce et al.  ). However, unlike previous ERP studies using speech stimuli (Besle et al.  ; van Wassenhove et al.  ), our results here did not reach significance, perhaps due to differences in timing of facial movements relative to vocalizations. In our paradigm, face movement and audio were simultaneous, although there was a natural delay in the movement peaking for our non-verbal stimuli (e.g. fully open mouth, upturned eyes in the sigh in Fig.  ), which is opposite to speech stimuli. Ghazanfar et al. (Ghazanfar et al.  ) also have shown that timing plays a critical role in multisensory effects in an experiment in which monkeys were presented conspecific coos and grunts along with images of primate faces, however, in this experiment static faces of primates were utilized. Multisensory neurons in the auditory core and belt regions showed more enhancement when the face versus audio delay was less than 100 ms, and facilitation when the delay was greater than 200 ms. The variance of these studies based on timing underscores the importance of subtle audio versus visual onset time differences in multisensory processing. 

Reduced activation in the AV condition could be due to various causes, including less energy demands brought about by facilitated processing. Alternatively, the relative decrease in amplitude in the multisensory relative to the unisensory conditions may be due a smaller population of neurons with exclusively multisensory versus unisensory preferences (Beauchamp  ; Laurienti et al.  ). Alternatively, the distribution of resources available to process these stimuli might be limited over multiple sensory cortical regions. We favor the increased efficiency explanation in the light of the behavioral facilitation effects observed in many studies (Bolognini et al.  ; Gondan et al.  ; Grant and Walden  ; Miller  ; Sumby and Pollack  ), although all three explanations are plausible and cannot be differentiated in the current dataset. Multisensory optimization may also take the form of synchronization of the phase of oscillatory stimuli (such as gamma band activity) (Engel et al.  ; Schroeder et al.  ; Senkowski et al.  ), which can produce important behavioral sequelae (Schroeder et al.  ). Future studies quantifying ERP amplitudes and latencies, oscillatory activity and behavior in a combined manner might better clarify the underlying nature of these processes. 

#### Higher-Order Underadditive Effects 
  
We saw significant activation by all three conditions in putative higher-order cognitive processes (based on latencies (ERP data) and origins (fMRI data); Doeller et al.  ; van Herten et al.  ; Vuilleumier and Pourtois  ). Here a clear case for convergence is more difficult to make since later ERPs are typically diffusely distributed, making source localization challenging, as they can potentially come from multiple sources (Siedenberg et al.  ; Soltani and Knight  ). However in our study, later ERPs, and activation in higher-order brain regions as revealed by fMRI showed spatially distributed responses and a combination of   AV maximum   and   Common activation   responses. From the fMRI side, this network of frontal, temporal and parietal regions has been implicated in other studies as playing an important role in multisensory perception (for review see Ghazanfar and Schroeder  ), as well as for understanding speech and socially related stimuli (Calvert et al.  ; Moll and de Oliveira-Souza  ). For the ERPs, there were multiple distributed late peaks that showed an AV response with properties from both unisensory conditions (AV elicited larger amplitudes like the VIS condition and faster latencies like the AUD condition). 

It is much more difficult to attribute higher-order activation as being specifically related to multisensory processing, as these regions did not show superadditivity, perhaps due to ceiling effects from these robust stimuli (Stevenson et al.  ). In addition, higher order processes can be non-specific and can be very sensitive to other factors such as attention. The target stimuli were always unisensory, and therefore there were two possible unisensory targets in the AV blocks. It is possible that in the AV and VIS conditions responding to the corresponding unisensory target stimulus may have resulted in potentially greater stimulus-driven attentional effects. Having said that, the STS, IFG, and TPJ have shown potential multisensory behavior in other studies where the task requirements did not involve such contingencies (Calvert et al.  ; Kawashima et al.  ). Additionally, the blocked-event design in this study could conceivably have produced some refractoriness effects in the data, and in other studies (Calvert et al.  ; Kawashima et al.  ), albeit unlikely. Ideally, an event-related design would circumvent these kinds of issues. 

Notably, all three conditions in our study activated right pSTS, a region previously shown to be important in social-related multisensory processing (Redcay  ). Right pSTS along with right TPJ, were the only regions in which there was maximum activation in the AV condition. Further evidence of pSTS importance in both multisensory and social processing come from prior research on a possible pSTS homologue in monkeys, the Anterior Superior Temporal Polysensory Area (STPa), which responds to visual biological motion, faces, and head and body view and direction (Jellema et al.  ; Oram and Perrett  ), and projects to higher order cognitive and emotional processing regions such as the amygdala and prefrontal regions (Oram and Perrett  ). 

In addition, we saw right-hemisphere dominated effects in STS and frontal regions, which is typically not seen in most speech related studies (Campbell et al.  ; Capek et al.  ; Hubbard et al.  ; Kawashima et al.  ; Macaluso et al.  ; MacSweeney et al.  ; Skipper et al.  ). However, left lateralized activation has been less strongly observed in multisensory studies of simple speech, syllables, and emotional prosody (Kreifelts et al.  ; Olson et al.  ; Wright et al.  ). It is possible that higher-order regions in both hemispheres have multisensory properties and are recruited based on verbal versus non-verbal relevance. 



### Summary 
  
Both imaging modalities produced datasets that were very complex, yet there was a surprising degree of convergence between the ERP and fMRI data (Fig.  ). Underadditivity dominated the multisensory effects in earlier regions as supported by the significant (VIS areas) and trend towards (AUD) smaller and faster responses for AV versus unisensory stimuli. These data, along with previous behavioral studies, suggest that early or mid-sensory regions may be optimized to process multisensory stimuli, if information from multiple modalities is available (Foxe and Schroeder  ). Multiple “higher-order” cortical regions, as well as late ERP activity typically associated with more higher-order processes showed underadditive effects driven by common activation for all conditions of non-verbal human stimuli, with a dominance of the AV condition in temporal regions. In particular the unique right pSTS effects confirm the important role of pSTS in social cognition, and again show the tendency toward right lateralization for social-related stimuli. 



## Electronic supplementary material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-31'>
<h2>31. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31680152/' target='_blank'>31680152</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> The neural basis of shared preference learning</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Soc Cogn Affect Neurosci</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1093/scan/nsz076</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6970152/' target='_blank'>6970152</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social processing (learning about others’ preference similarity and impression formation), conducted in healthy adult participants (N=25, mean age 25.1, within 17–65). The task is explicitly social (tracking other agents’ preferences relative to the self). Results report whole-brain, cluster-corrected analyses (conjunctions and contrasts with whole-brain significance thresholds); findings are not limited to ROI analyses. Thus all inclusion criteria are met and no exclusion criteria apply.</p>
<p><strong>Fulltext Confidence:</strong> 0.96</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
During our daily lives, we often learn about the similarity of the traits and preferences of others to our own and use that information during our social interactions. However, it is unclear how the brain represents similarity between the self and others. One possible mechanism is to track similarity to oneself regardless of the identity of the other (Similarity account); an alternative is to track each other person in terms of consistency of their choice similarity with respect to the choices they have made before (consistency account). Our study combined functional Magnetic Resonance Imaging (fMRI) and computational modelling of reinforcement learning (RL) to investigate the neural processes that underlie learning about preference similarity. Participants chose which of two pieces of artwork they preferred and saw the choices of one agent who usually shared their preference and another agent who usually did not. We modelled neural activation with RL models based on the similarity and consistency accounts. Our results showed that activity in brain areas linked to reward and social cognition followed the consistency account. Our findings suggest that impressions of other people can be calculated in a person-specific manner, which assumes that each individual behaves consistently with their past choices. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (39403 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
The ability to rapidly form and update our impressions about other people is a vital skill in navigating our complex social world. During our daily lives, we frequently learn about the traits and preferences of other people and use that information to inform our social interactions. However, the neural mechanisms that govern our learning of the relationship between our preferences and those of others are currently unclear. The current study investigated these mechanisms by combining fMRI and computational modelling. 

Researchers investigating impression formation have sought to determine which brain areas respond when we learn about other people and when our expectations of others are violated. Most have done this by providing participants with some information about a novel person and then presenting either consistent information that confirms the previous impression or inconsistent one, which requires participants to update their impressions. These studies have shown increased activity in regions like the precuneus/posterior cingulate cortex (PCC), the temporal-parietal junction (TPJ) and the dorsomedial prefrontal cortex (dmPFC) when receiving inconsistent   vs   consistent information about another person’s moral behaviour ( ;  ;  ), competence ( ;  ), traits ( ;  ;  ) and political beliefs ( ). These regions are key nodes in the ‘mentalising’ network, which is activated when thinking about the beliefs, preferences and intentions of others ( ;  ;  ;  ). 

The increased activation to inconsistent information seen in the mentalising network is reminiscent of the prediction error (PE) signal seen in reinforcement learning (RL) models. These signals compute the expectation of a future outcome (or reward) as being a function of the current expectation plus the product of the learning rate and the PE, i.e. the difference between the last expected and actual outcome ( ;  ). RL models have been shown to be biologically plausible both at the neurochemical level, where the pattern of midbrain dopamine neuron response matches that of reward PEs ( ), and at the level of whole brain anatomy ( ). This biological plausibility along with the findings outlined above have led researchers to suggest that regions in the mentalising network may be involved in calculating social PEs ( ;  ;  ). 

Several studies have investigated this possibility directly, using computational modelling to parametrically track PE from trial to trial and have found evidence of social PE tracking in the dmPFC, the anterior cingulate cortex (ACC), the TJP, the superior temporal sulcus (STS), the medial temporal gyrus (MTG), ventrolateral PFC (vlPFC) and the precuneus ( ;  ;  ;  ). A recent study by   examined the related phenomenon of self-other mergence, in which knowledge about another person’s performance reciprocally influences judgements of one’s own performance. They found a division between PEs for self-performance, represented in the anterior cingulate cortex, and PEs for other performance, represented in the dmPFC. Interestingly, individual variance in the strength of dmPFC activation also predicted how far participants’ self PEs were affected by the performance of the others. Such findings have led some researchers (e.g.  ;  ) to argue that predictive processing plays a key role in social cognition. 

To date, most studies examining social PEs have considered cases where participants learn about other individuals, but do not examine the relationship between those individuals and the self (although see   for an interesting exception). A distinct literature has examined the role of self-similarity in impression formation ( ;  ) and shown that self-similarity can lead to liking and affiliation. Numerous studies have shown that those we perceive as similar to us in terms of traits ( ), attitudes ( ) and preferences ( ) tend to be evaluated more favourably than those perceived as different. There is evidence for a ventral–dorsal gradient in the mPFC when processing the similarity of others with similar others being processed in the ventromedial prefrontal cortex (vmPFC) and dissimilar others in the dmPFC ( ;  ). 

The current study aims to test how the brain tracks and learns about other people from the self-similarity of their choices. In particular, we distinguish two possible ways in which the brain could track others: the similarity approach and the consistency approach. The similarity approach assumes that, on each trial, we consider ‘is this person like me on this trial?’ and assign high PEs to any trial where an agent makes a different choice to me. The consistency approach assumes that we model each person we encounter as an individual with a level of overall similarity to me. On each trial, we then consider ‘is this person’s choice consistent with their overall similarity to me?’ and assign high PEs to any trial where the agent behaves in a way that is inconsistent with that agent’s track record. 

To do this, we adapted RL models to investigate how the brain tracks the choices of two different agents in terms of how similar they are to the participant’s own choices. It is important to note that we are not claiming that the tracking of similarity is necessarily linked to reward-based reinforcement in a direct manner. Rather, we use RL models because they can track the accumulation of information and evidence over time. This allows us to look at how the brain represents confirming and disconfirming information about other’s similarity to ourselves. For a related approach applied to the learning of others’ traits, see  . 

Our task created a context in which participants chose which painting they prefer (an arbitrary aesthetic choice) and then learn the preferences of two agents for the same paintings (see  ). Using fMRI and computational modelling, we can identify which brain areas track agents’ preferences relative to self-preferences in a trial-by-trial manner. In each trial, our participants saw two paintings and indicated which they preferred. They then saw the preferences of two agents, a similar agent (ASim) who chose the same painting 75% of the time and a different agent (ADiff) who chose the same painting 25% of the time. Using RL models, we are able to calculate the prior probability of the agents’ choice and the PE of their actual choice separately for each trial and each agent, allowing us to localise brain regions where BOLD signal tracks the model parameters. 
  
Outline of experimental trial structure and number of trials per condition. A trial phases and timings. Each trial has four phases (self, similar, different, feedback). On every screen, three icons at the top represent the participant (blue outline in the centre) and the two agents (two photos), with one icon enlarged in a green square to show who is the ‘active player’ in this phase. In the self-phase, participants chose which of two pictures they prefer. In the ASim phase and ADiff phase, the two agents ASim and ADiff chose pictures and the participant sees the outcome. The order of these two phases was counterbalanced. Finally, in the Feedback phase, the participant sees a reminder of his/her own choice.   B. Detail of one phase  . This shows an expanded view of the two different screens within the ASim phase; the same structure was used for the Self phase and ADiff phase. Participant’s first see a ‘decision screen’ with the two pictures used on this trial. During the decision screen participants either chose their own preferred painting (Self phase) or waited to see the choice of the agent (similar and different phases). Then they see an ‘outcome screen’ which shows either the painting they chose (Self phase) or the painting the agent chose (ASim and ADiff phases). The durations of each screen are given at the bottom of the figure, and multiple times separated by a dash represent the jittering in order to effective temporal sampling resolution much finer than one TR  . C. Number of trials of each type.   This table shows the breakdown of the four possible combinations of choices made by the two agents, ASim and ADiff. Each agent could agree with the participant’s choice (Ag) or disagree (Dis). The columns show the percentage of trials, number of trials by block and total number of trials which had a particular pattern of choices. 
  
We then used RL to create signed PE models of both the similarity and consistency approaches to tracking the agent’s choices (see  ). In the similarity model, agents are tracked only in relation to the participant’s own preferences, on a single dimension of ‘distance from me’. This means that the model will tend to have positive PEs for ASim and negative PEs for ADiff (see  ). In the RL model, each signed PE then contributes to an accumulated similarity (AS) parameter, which will tend to be high for ASim (who is often similar) and low for ADiff (who is often different). To make this model clear, we term the two parameters the ‘similarity PE’ (PE_Sim) and the AS. 
  
Two possible ways that the choices of the two agents, ASim and ADiff, may be tracked in the brain  . A. Similarity approach.   The yellow/green boxes in the top row show how trials are classified as Similar or Different according to whether the agent choose the same picture as the participant or not, and the same classification is used for both agents. Green indicates that a choice is given a positive value and yellow that it has a negative value. This is reflected in the sample sequence of 20 trials, where the ‘choice similarity’ tends to be high for ASim and low for ADiff. Based on the choice similarity, the Sim_PE and AS parameters are calculated as in equations   and  .   B. Consistency approach.   Trials are classified as Consistent or Inconsistent according to whether the agent conforms to type. Both agents show high choice consistency most of the time in the sample of 20 trials shown below. Based on the choice consistency the PE_Con and AC parameters are calculated as in equations   and  . 
  
The alternative is the consistency model, which assumes that participants track agents and choices in terms of whether the agent’s choice is consistent with their past level of preference similarity to the participant. Thus, we label each agent’s choices as ‘consistent’ or ‘inconsistent’ with that agent’s past behaviour: agreeing with the participant is   consistent   for ASim but   inconsistent   for ADiff. In this model, a trial will have negative consistency PE when ASim chooses a different picture to the participant, because this is unlike ASim’s typical preference. In the same way a trial will have negative PE when ADiff chooses the same picture as the participant (unlike ADiff’s typical preference) (see  ). These PEs feed into the accumulated consistency (AC) of each agent, which will be high when that agent conforms to type (i.e. high for both ASim and ADiff most of the time) but will fall if the agent makes atypical choices. To make this model clear, we term the two parameters the ‘consistency PE’ (PE_Con) and the AC. 

Importantly, these two models predict a different pattern of brain activity in our experimental design, as ASim and ADiff’s trial-by-trial preferences can have the same sign (both consistent, according to the consistency approach) or opposite sign (as they chose different images, according to the similarity approach, see  ). It is important to note that while our study can test how well each of these models fit activation in different brain areas, we are not claiming that they are mutually exclusive competing accounts. Indeed, it is entirely plausible that some brain areas track similarity of choices directly while others track the consistency of choices. Our design allows for us to investigate the neural signature of both models, in two separate GLMs, and thus identify which brain areas (if any) are involved in each of these two ways of processing similarity relationships. 


## Methods 
  
### Design 
  
In our study, participants tracked the choices of two agents on multiple trials, in relation to their own choices. On each trial, the participant and two agents, ASim and ADiff, indicated which of two paintings they preferred. ASim chose the same painting as the participant in 75% of all trials, while ADiff only chose the same painting in 25% of trials. 


### Participants 
  
Twenty-five participants (mean age ± SD: 25.1 ± 5.7, 11 male) took part in this study, which was approved by the University College London, Institute of Cognitive Neuroscience Research Department’s Ethics Committee. All participants gave their informed consent to participate and were paid for their participation. All participants were right handed and were screened for neurological disorders. Due to technical issues, pre- and post-ratings data were lost for seven participants. Therefore, our final sample size for the ratings analysis was   n   = 18. As we did not use this ratings data for model fitting, and data on all 25 participant’s choices during the task were collected, this issue did not impact on the fMRI analysis so the full sample   n   = 25 was used for fMRI analysis. 



## Procedure 
  
### Experimental task 
  
The main task in this study was an aesthetic choice task. Participants were told that in each trial, they would see a pair of paintings (see  ) and would have to choose which painting they preferred. They were informed that other participants had previously indicated which of the paintings they preferred and that they would see the choices of two previous participants during the study. Names and faces were assigned to these ‘previous participants’, but in fact they were computer agents whose choices were determined based on the participant’s own choices. Prior to entering the scanner, participants completed a training block of the task (see  ). After the training, participants learnt the names of the agents with whom they would do the experimental task. They also rated their faces for similarity, likeability and attractiveness, using a 10-point scale in order to provide us with a manipulation check as to how well the participants learnt the similarity of the agent to themselves. Other than being asked to rate their similarity to the agent, participants were not given any information to suggest the relationship between their choices and those of the agents were important to the task. 

Each trial was divided into four phases (see  ). The first three phases were each split into two screens, a   decision screen   and an   outcome screen   (see  ). In the self-phase, participants were shown a pair of paintings on the   decision   screen and had 2.75 s to choose which they preferred using the left and right buttons on a response box. They then saw an   outcome   screen displaying their preferred painting for a jittered interval (1–3 s). In the similar phase, participants first saw a 1-s   decision   screen, which displayed the pair of paintings along with an indicator that ASim was choosing. This was followed by an   outcome   screen, which displayed the agent’s preferred painting for a jittered interval (2.75–4.75 s). In the different phase, participants again saw a   decision   screen with an indicator that ADiff was choosing, followed by a jittered   outcome   screen displaying that agent’s preferred painting. The order of the similar and different phases was pseudorandomised across trials. Finally, each trial contained a   feedback   phase in which participants again saw their own choice for an interval of 2 s. 

Participants completed four sessions of 20 trials (see   for a breakdown of trial types by block); at the end of each block, they rated the similarity, likeability and attractiveness of each agent using a 10-point scale. Using fast event-related design, i.e. varying the intervals of the outcome screen in the three choice phases and using many trials, an effective temporal sampling resolution much finer than one TR for each of these periods was achieved. The lengths of the intervals were uniformly distributed for each period, ensuring that evoked haemodynamic responses time locked to the events were sampled evenly across the time period following each choice period. 


### Model-based fMRI analysis 
  
For full details of image acquisition and fMRI data analysis, please see  . To examine whether the relationship between the participant preferences and those of the agents was coded in terms of similarity or consistency, two general linear models (GLM) were created, which include different trial types and the parameters of the two RL models. Both GLMs modelled BOLD activation during   outcome   screen for ASim and ADiff separately. Regressors of no interest modelled activity during the   self-choice outcome   screen, the   feedback   phase, the ratings periods and trials where participants failed to make a choice and the residual effects of head motion. In addition, parametric modulators linked to the   outcome   screen regressors allowed us to model the values of our RL parameters on a trial-by-trial basis. Note that we also conducted a more traditional GLM without RL parameters, the details of which can be found in  . 

In the similarity GLM, we modelled the signed similarity PE (PE_Sim) and accumulated similarity (AS) between the agent choice and the participant choice for each agent (  n  ), using the following algorithms: where 

As we did not fit the model to any response, we set the learning rate (λ) with a fixed value of 0.5 and initial AS was set to 0. The learning rate of 0.5 was chosen a priori and fixed for all participants, to indicate the carry-on effect of previous trials to the current trials. This value was chosen because it is in the middle of the LR range (0–1) and indicates a decaying memory window of about four trials. We chose this conservative approach and did not explore learning rates further to avoid double dipping the data or   post hoc   analysis. AS was set at 0 as this represented no a priori expectation of a similarity relationship between the participant and the agents. In total, there were six regressors-of-interest in our similarity GLM: outcome screens, AS values, and PE_Sim values for both ASim and ADiff. 

In the consistency GLM, we modelled the signed consistency PE (PE_Con) and AC between the agent choice and the participant choice for the two agents (  n   = ASim or ADiff), using the following algorithm. where 

Again, the learning rate (λ) was set to 0.5 and initial AC was set to 0 (see   for examples of how AS and PE varied across 20 trials). In total, there were six regressors of interest in our consistency GLM: outcome screens; AC values and PE_Con values for both ASim and ADiff. 



## Results 
  
### Behavioural results 
  
To examine whether learning about the preferences of the agents changed participants’ feelings of affiliation towards them, we collected ratings of similarity, likeability and trustworthiness at the start of the study and after every 20 trials. This meant that each participant contributed five ratings of each of the three attributes across the study. These ratings were then z-scored within participant to remove baseline differences between participants, before the next analysis. Three separate 2 (agent: similar/different) × 5 (session number: pre/S1/S2/S3/S4) repeated measures ANOVAs were carried out on the z-scored ratings of similarity, liking and trust (see  ). Due to problems with data recording, the ratings from seven participants were incomplete and were excluded from the behavioural analysis leaving a remaining sample of 18 participants. 
  
Z-scored ratings of liking similarity and trustworthiness for the similar and different agents across rating sessions. 
  
The ANOVA on similarity ratings found a significant main effect of agent,   F  (1.17) = 23.52,   P   < 0.001, η  = 0.58. Overall participants rated ASim as being more similar (  M   = 0.33,   MSE   = 0.15) to them than ADiff (  M   = −0.68,   MSE   = 0.12). There was also a significant interaction between agent and session   F  (1.17) = 5.65,   P   = 0.001, η  = 0.25. To examine this interaction further, ratings for ADiff were subtracted from the ratings of ASim for each session to create a difference score. Pairwise comparisons (Bonferroni corrected) showed that the difference score for the pre-session (  M   = −0.16,   MSE   = 0.36) significantly differed from the scores after sessions S1 (  M   = 1.49,   MSE   = 0.35),   P   < 0.05, S3 (  M   = 1.26,   MSE   = 0.29),   P   < 0.05, and S4 (  M   = 1.43,   MSE   = 0.25),   P   < 0.01. No other pairwise comparisons were significant. 

The ANOVA on liking ratings found a significant main effect of agent,   F  (1.17) = 23.8,   P   < 0.001, η  = 0.58. Overall participants rated ASim as being more likeable (  M   = 0.55,   MSE   = 0.07) than ADiff (  M   = −0.2,   MSE   = 0.12). There was no significant effect of session and no interaction between session and agent. The ANOVA on trust ratings found a significant main effect of agent,   F  (1.17) = 7.67,   P   < 0.05, η  = 0.31. Overall participants rated ASim as being more trustworthy (  M   = 0.23,   MSE   = 0.11 than ADiff (  M   = −0.24,   MSE   = 0.01). There was no significant main effect of session and no interaction between session and agent. 


### fMRI results 
  
#### Main effect of agent preference similarity 
  
Two contrasts investigated the main effect of agent identity (ASim/ADiff) on BOLD response. The regressors, which contribute to these contrasts, were identical in the similarity GLM and the consistency GLM, so the results here are the same for both. The ADiff > ASim contrast revealed that observing the choice of ADiff compared to ASim led to a greater activation in the right inferior frontal sulcus (rIFS) and in a cluster centred on the right fusiform gyrus (rFG) (  and  ). No significant activations were found in the ASim > ADiff contrast. 
  
Peak voxel coordinates in MNI space,   z  -values and cluster sizes for analyses of the outcome screen showing significant effects after cluster correction for main effect of similarity. Same shading indicates local maxima in distinct anatomical regions within the same cluster, BA indicates Brodmann area and   k   indicates the cluster size threshold for whole brain significance of   P   < 0.05 
    
A. Brain areas showing significant cluster corrected results in the ADiff > ASim contrast for the Outcome screen. B. Brain areas tracking the PE_Sim parameter (similarity PE) for the outcome screen across both agents, cluster corrected. Parameter estimates in the lower panel are averaged across the whole cluster. Error bars represent SEM. Graph border colours indicate matching circled area. Red/yellow represents positive activations and blue/green represents negative activations. 
  

#### Parametric analysis of the similarity GLM 
  
To identify brain regions, which tracked accumulated similarity (AS) across both agents, we calculated a conjunction of the RL parameters for each of the agents, that is AS  ∩ AS . This did not reveal any significant clusters in either a positive or negative direction, suggesting that no brain areas directly tracked preference similarity between agents and participant. Similarly, there were no significant clusters that tracked the positive conjunction of similarity PE for both agents, that is, PE_Sim  ∩ PE_Sim . This means that no areas showed increased activation when both agents preferences were unexpectedly similar to that of the participant. However, the negative PE_Sim conjunction analysis revealed that unexpected dissimilarity between either agent choice and participant choice correlated with activation in a number of clusters within the occipital cortex including the bilateral lateral occipital cortex (LOC) and the lingual gurus (  and  ). 
  
Peak voxel coordinates in MNI space,   z  -values and cluster sizes for analyses of the outcome screen in the similarity GLM showing significant effects after cluster correction for conjunction analyses of the AS and PE parametric modulators. Same shading indicates local maxima in distinct anatomical regions within the same cluster, BA indicates Brodmann area and   k   indicates the cluster size threshold for whole brain significance of   P   < 0.05 
  


### Parametric analysis of the consistency GLM 
  
To identify brain regions tracking the consistency of agents’ choices across both agents, we first examined the conjunction of areas tracking AC, that is AC  ∩ AC . The positive conjunction showed a significant activation in a cluster-corrected region centred on the superior medial frontal gyrus (smFG) (  and  ). This region showed greater activation as evidence for the consistency of the agents’ choice similarity to the self-increased, and lower activation during inconsistence periods. No significant activations were found in the conjunction analysis testing for areas negatively correlated with AC. 
  
Peak voxel coordinates in MNI space,   z  -values and cluster sizes for analyses of the outcome screen in the consistency GLM showing significant effects after cluster correction for conjunction analyses of the AS and PE parametric modulators. Same shading indicates local maxima in distinct anatomical regions within the same cluster, BA indicates Brodmann area and   k   indicates the cluster size threshold for whole brain significance of   P   < 0.05 
    
Brain areas showing significant cluster corrected tracking of AC and PE_Con for the Outcome screen. A. Areas significantly tracking AC in the positive ASim ∩ ADiff conjunction. B. Areas significantly tracking PE_Con in the positive ASim ∩ ADiff conjunction. C. Areas significantly tracking PE_Con in the negative ASim ∩ ADiff conjunction. Parameter estimates averaged across whole cluster. Error bars represent SEM. Graph border colours indicate matching circled area. Red/yellow represents positive activations and blue/green represents negative activations. sMFG = superior medial frontal gyrus, rCN = right caudate nucleus, rAG = right AG, rSFS = right superior frontal sulcus. 
  
The conjunction analysis testing for areas tracking PE in consistency (PE_Con  ∩ PE_Con ) identified significant cluster-corrected activations bilaterally in a dorsal region of the caudate nucleus as well as in a more ventral midbrain region of the left hemisphere (  and  ). These areas showed increased BOLD response when the agents’ choices were unexpectedly consistent with their overall preference, and decreased activation when agents’ choices were unexpectedly inconsistent. Note that while the peak activation in the more dorsal left hemisphere cluster is in fact found in the neighbouring corpus callosum, both dorsal clusters showed considerable overlap with the caudate nucleus. The conjunction analysis testing for areas tracking PE_Con in a negative direction identified significant clusters in several right hemisphere regions, namely the angular gyrus (rAG), the superior frontal sulcus (rSFS), the rSTS, the rMTG and the precuneus (  and  ). These areas showed increased BOLD response when the agents’ choices were unexpectedly inconsistent with their overall preference, and reduced activity when the agents’ choices were highly predictable. 



## Discussion 
  
Our study examined the neural basis of learning about preference similarity between self and others and its role in promoting affiliation. We created a context where participants could express a preference for a painting and learn about the preferences of two agents for the same paintings. Our behavioural data show that similar preferences lead to higher ratings of liking, trustworthiness and similarity, indicating that participants tracked the agents’ preferences in relation to their own preferences. 

Our introduction outlined two possible, non-mutually exclusive, ways in which preference similarity might be tracked in the brain: either by a general mechanism, which tracks an agent’s choice in relation to one’s own, i.e. how similar or dissimilar they are from the self, or via a model of consistency, which tracks agent’s choices in terms of their consistency to that agent’s previous choice, i.e. how   consistently   similar or dissimilar they are from the self. To examine the evidence for each of these two mechanisms, we created two RL models, which tracked the agents’ choices based on similarity and consistency, respectively. Our results from the similarity model indicated that regions of the visual cortex negatively tracked similarity PE (PE_Sim). Results from the consistency model showed a number of brain areas tracking different variables associated with the consistency model; the dorsomedial pre-frontal cortex (dmPFC) tracking AC, and the caudate nucleus, AG and precuneus tracked consistency PE (PE_Con). The caudate is involved in value updating ( ;  ), while the AG and precuneus are associated with social cognition ( ;  ). Below, we elaborate on the results of the AC conjunction before moving on to discuss the findings on PE_Con and PE_Sim. 

### dmPFC tracks AC 
  
The AC parameter represents a trial-by-trial estimate of the probability that a person makes choices in line with his previous choices, this is, that the similar agent (ASim) should choose the same painting as the participant while the different agent (ADiff) should choose differently. The only area we found tracking AC was a cluster in the bilateral superior medial frontal gyrus (smFG) corresponding to the anterior region of the dmPFC. The dmPFC is known to be a key area for the processing of information about both self and other ( ;  ;  ). See   for a more detailed survey of previous results. 

The dmPFC’s involvement in coding prior knowledge of other people is supported by previous research suggesting that the dmPFC encodes reputational priors of one’s partners during economic games ( ;  ). Our results build on these findings by suggesting that dmPFC PEs track the   consistency   of the agent’s similarity to the self rather than simply tracking preference similarity. 


### Consistency PEs are tracked by regions involved in reward and social cognition 
  
PE_Con reflects the difference between the agent’s choice and the participant’s expectation of what choice the agent will make. For example, the model assigns a positive update signal when ADiff picked the painting not chosen by the participant, and a negative signal when ADiff picked the same painting (see  ). Areas that tracked PE_Con revealed two distinct patterns of activation. Clusters in the bilateral caudate nucleus ( ) showed increased activity when the agents chose consistently with their type. Meanwhile, clusters in regions associated with social cognition including the superior temporal sulcus (STS), the AG, precuneus and superior frontal sulcus (SFS;  ) showed increased activations when the agent’s choice was inconsistent with their type. Overall, this pattern shows that PE tracking in these regions is not a ‘generic’ signal of how similar a person is to me, but rather reflects how much each person’s choice conforms to their typical pattern of similarity to me. 

The caudate nucleus, along with other parts of the striatum, has been heavily implicated in the generation of PEs during RL of rewards for self ( ;  ;  ) and others ( ;  ;  ). Previous studies have shown that the caudate nucleus is also involved in signalling PEs when learning the characteristics of others.   found that the caudate nucleus activity tracked PEs regarding the trustworthiness of other during an economic game. Subsequent studies have found similar results for trustworthiness ( ;  ;  ), generosity ( ), reliability in advice giving ( ) and general behavioural traits ( ). Our findings add to this literature by showing that caudate nucleus activity also tracks PE when learning about the similarity of others’ preferences to one’s own. 

The regions showing greater activations when PE_Con was negative, i.e. when the agents’ choice was inconsistent with their typical choices, are key nodes of the mentalising network involved in processing information about self and others ( ;  ;  ;  ). These areas have been implicated in the formation of impressions about other peoples’ traits ( ;  ;  ;  ;  ), beliefs ( ) and abilities ( ;  ). Of particular note are two studies which directly modelled PEs for learning about the traits of other.   found that the precuneus and STS tracked PEs for other generosity during an economic game, while   found that only the precuneus showed greater tracking of PEs in a social verses non-social setting. The current study shows that these regions also track PEs regarding the similarity relationship between self and others, underlining the role of PEs in social learning ( ). 

It is also notable that while previous studies on social impression formation have tended to show bilateral activations of the mentalising network, in the current studies, activity was limited to the right hemisphere. This is consistent with previous research demonstrating right lateralisation for tasks involving self and other differentiation ( ;  ;  ;  ). 


### Similarity-related responses in regions involved in visual attention 
  
In addition to modelling the RL parameters, we also directly contrasted the outcome screen where participants see the choices of ASim with the outcome screen for ADiff. This contrast shows greater activation for ADiff in two clusters: one centred on the rIFS and the other on the rFG. The IFS has been implicated in attentional processing and in particular in the control of attentional shifts by both internal goals and by salient external stimuli ( ,  ;  ;  ;  ), while the FG is known to play a key role in the visual perception of faces ( ;  ;  ). Interestingly, a previous study found greater FG activation when participant observed faces of individuals judged to have different traits to themselves ( ). These findings were also consistent with our conjunction analysis of regions that showed a negative relationship to the value of PE_Sim. This analysis revealed that when an agent made an unexpectedly dissimilar choice to that of the participant, it led to increased activation across a series of visual areas including regions in the bilateral LOC and in the left FG. 

The activation of these areas suggests that participants may have found the choices of ADiff to be more attention-grabbing than those of ASim in a comparable way to studies that have demonstrated an attentional bias towards untrustworthy as opposed to trustworthy agents ( ;  ;  ). 


### Comparison with non-RL GLM 
  
In addition to running our main RL analysis, we also conducted a more traditional GLM, which divided our trails using a 2 × 2 design with confederate/agent identity (similar   vs   different) as one factor and choice decision (agree   vs   disagree) as the other factor, the interaction between them (i.e. similar agree and different disagree   vs   similar disagree and different agree) was equivalent to our consistency model. This allowed us to compare the results of our RL model to more traditional non-parametric approaches (see   for full details and results). When comparing the results of the RL models and the conventional GLM the activations for the choice main effects and the consistency (interaction effects) were largely similar with the disagree > agree contrast showing activations equivalent to the clusters shown for areas that negatively tracked similarity PEs, the consistent > inconsistent contrast showing activations for two of the three clusters we identified that positively tracked consistency PE and the results for the inconsistent > consistent contrast showing results largely consistent with areas negatively tracking consistency PE. 

Despite these similarities, our model has two advantages over the non-RL GLM. First, it is more sensitive to the temporal order of observations, as it takes history into account. For example, it treats differently two consecutive inconsistencies as the first one is more surprising than the second one, while the standard GLM treats them in the same way. This makes our approach more sensitive, more powerful (statistically) and more relevant to our research question. The second advantage is that we can estimate the hidden variables of AC/similarity which the standard GLM cannot. This allowed our model to identify the dMPFC area, which is involved in the tracking of AC. 


### Limitations 
  
One key limitation of the current study is that our task did not allow us to collect trial-by-trial behavioural data showing what participants had learnt about the agents. This is because we wanted participants to learn implicitly, rather than making explicit predictions of the agent’s choice on each trial. Because of this, we approximated a learning rate (0.5) and used it in our RL models to track changes in preference tracking according to the actual choices made by the agents. This raises the possibility that there may only be a weak fit between the learning rate used in our model and the actual learning rate of our participants. However, our main predictions related to the direction of the tracked PEs and accumulated preferences, and not with the specific magnitude of these variables, are less likely to be affected by our approximation. This is in line with a recent theoretical paper ( ) that demonstrated that model-based fMRI results are, under some conditions, insensitive to changes in individual learning rates. While it is possible that our approximation may lead to lower power at detecting brain responses to PEs, we feel that the main hypothesis concerning the direction of the effects (similarity approach   vs   consistency approach) is supported by our analysis. 



## Conclusions 
  
In this study, we combined computational modelling and fMRI to investigate the neural processes that underlie learning about the similarity of other people’s preferences to one’s own. We found that more regions of the brain encode information about the similarity of others’ choices in a consistency driven manner than encode that information purely based on each particular preference’s similarity to one’s own. This was particularly the case for the accumulated information about the other’s similarity with no areas showing sensitivity to purely accumulated similarity while a region of the dmPFC showed significant tracking of AC. 

These findings suggest that higher level neural representations of similarity to the self are coded in a person-specific manner, which reflects how consistent are that person’s preference related to the self, i.e. do we usually agree or disagree in our preferences. As such our study highlights the role of context-dependent predictive processing in the learning of preference similarity between self and others and, by extension, in the formation of social impressions more generally. Further research in this area could build on our results by examining whether the neural correlates of similarity learning are modulated by having pre-existing cues about how similar that person is to oneself. In addition, it is possible that this consistency approach also applies to learning about other domains including people’s traits, attitudes and competence. 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-32'>
<h2>32. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/23342130/' target='_blank'>23342130</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> It’s All in the Eyes: Subcortical and Cortical Activation during Grotesqueness Perception in Autism</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2013</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0054313</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3544832/' target='_blank'>3544832</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of face perception and grotesqueness (Thatcher Illusion), a social/emotional processing task relevant to ‘Perception and Understanding of Others.’ It includes a healthy adult control group (NT; n=18, mean age 25.8), reported separately from the ASD group. The paper reports whole-brain analyses (within-group and between-group whole-brain contrasts, cluster-corrected thresholds) as well as ROI analyses; thus it is not limited to ROIs. All inclusion criteria are satisfied and no exclusion criterion is met.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Atypical face processing plays a key role in social interaction difficulties encountered by individuals with autism. In the current fMRI study, the Thatcher illusion was used to investigate several aspects of face processing in 20 young adults with high-functioning autism spectrum disorder (ASD) and 20 matched neurotypical controls. “Thatcherized” stimuli were modified at either the eyes or the mouth and participants discriminated between pairs of faces while cued to attend to either of these features in upright and inverted orientation. Behavioral data confirmed sensitivity to the illusion and intact configural processing in ASD. Directing attention towards the eyes vs. the mouth in upright faces in ASD led to (1) improved discrimination accuracy; (2) increased activation in areas involved in social and emotional processing; (3) increased activation in subcortical face-processing areas. Our findings show that when explicitly cued to attend to the eyes, activation of cortical areas involved in face processing, including its social and emotional aspects, can be enhanced in autism. This suggests that impairments in face processing in autism may be caused by a deficit in social attention, and that giving specific cues to attend to the eye-region when performing behavioral therapies aimed at improving social skills may result in a better outcome. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (39377 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Autism spectrum disorders (ASD) are neurodevelopmental disorders affecting close to 1% of the population, that are characterized by three behaviorally defined symptoms: impaired social interaction, deficits in communication and restrictive and repetitive behavior  . Decreased attention to faces, difficulties in reading facial expressions and emotions, failure to orient towards the eye region of the face and difficulties in understanding eye gaze have been reported in numerous studies (e.g.  ,  ,  ). These aspects are determinant elements in diagnosis of ASD (e.g.  ,  ,  ). Typical face perception is based on configural processing, which refers to the sensitivity of the spacing between features of a face, such as eyes and mouth. Those relations, commonly referred to as second-order relations  , are automatically computed for typical upright faces. Inversion interferes with configural processing and inverted faces are processed using a feature-based strategy (e.g.  ,  ). 

In ASD, there has been a debate whether typical upright faces are processed configurally (e.g.  ,  ) or using a feature-based strategy  ,  . A recent review of behavioral studies in face processing in ASD has concluded that face identity processing is qualitatively similar between people with ASD and individuals with neurotypical development, but that people with ASD have specific deficits discriminating the eyes during face processing  . 

One of the behavioral paradigms thought of as providing support for configural processing of faces is the Thatcher Illusion (TI). In the TI the eyes and mouth are inverted relative to the rest of the face  . When thatcherized faces are presented upright, they appear weird and grotesque, whereas this effect vanishes when they are presented inverted. The relationship between the TI and configural processing has been the subject of investigation  ,  ,  ,  . Recent studies have confirmed that configural processing is present in typical upright faces, as well as in upright faces which have been thatcherized at only one feature  . In contrast, the role of configural processing in fully thatcherized faces is unclear  ,  . Furthermore, we have recently shown that the efficacy of the illusion relies on a network of areas involved in social and emotional processing and which are engaged in mentalizing, including the medial prefrontal (mPFC)/orbitofrontal cortex and the posterior cingulate/precuneus. Discrimination between a typical face and a thatcherized face led to increased activation in the face-processing network when the faces were presented inverted  . Studies investigating face processing in normal inverted faces have yielded discrepant results. The face inversion effect has been specifically associated with decreased activation for inverted faces in the fusiform face area (FFA)   but also with increased activation in the object responsive lateral occipital cortex  ,  . 

Our previous work in a neurotypical population demonstrated the pre-eminent role of the eyes in generating the TI  . When looking at faces, adults with neurotypical development have a natural tendency to attend more to the eye region  , and this is not the case in individuals with ASD  ,  ,  . There is evidence that people with ASD, rather than having non-specific difficulties in face processing, are specifically impaired with the processing of the eyes  ,  . To our knowledge, no fMRI study has so far addressed the contribution of the different features (eyes and mouth) to the TI in ASD. The current study employed thatcherized stimuli modified to tease apart the relative contribution of different facial features to the TI to further examine the neural substrate of face processing in individuals with ASD. Previous studies have shown that cueing to the eyes can improve performance in a configural face processing paradigm   and elicit typical brain activation in areas associated with face processing in individuals with ASD (e.g.  ,  ,  ). Given that the eyes have been demonstrated to play a primary role in driving the TI  , we hypothesized that cueing to the eyes would increase the sensitivity to the TI and therefore lead to heightened discrimination accuracy as well as to increased activation in cortical areas involved in social and emotional processing in participants with ASD. 

Individuals with ASD have a natural tendency to avoid looking at the eyes and experimental designs requiring them to look at the eye region have led to increased amygdala activation  ,  . Together with the superior colliculus and the thalamus, the amygdala belongs to the subcortical extrageniculostriate route involved in rapid face detection. Given the use of cues to attend to the eye region in the current TI paradigm, we hypothesized that participants with ASD would show increased activation in this subcortical route. 

In summary, three hypotheses were tested in this study: Directing visual attention towards the eyes in a TI discrimination task, leads to (1) better behavioral performance (2) increased activation in cortical areas involved in social and emotional processing and (3) increased activation in subcortical areas in individuals with ASD. 


## Materials and Methods 
  
### Participants 
  
Twenty neurotypical controls (NT) and 20 normally intelligent individuals with ASD were enrolled in the study. All participants had normal or corrected to normal vision. Two NT and 4 ASD had to be excluded due to excessive movement during data acquisition. Sixteen participants with ASD (3 females, 23.5 years ±6.8 (mean ± SD)) and 18 NT participants (2 females, 25.8 years ±5.3) were included in the data analysis. Performance intelligence quotient (PIQ) was assessed using the Wechsler Non-verbal Scale or the Wechsler Abbreviated Scale of Intelligence  ,   and all participants had a PIQ in the normal range. Scores on the first series of the Raven’s Progressive Matrices Advanced were also obtained  . Groups were matched for age, PIQ and Raven’s score. 

Participants with ASD were assessed by experienced clinicians on the Autism Diagnostic Observation Schedule (ADOS) and on the Autism Diagnostic Interview-Revised (ADI-R)  ,  . Seven had a diagnosis of Autism, 7 of Asperger’s syndrome and 2 were in the broad spectrum – Pervasive Developmental Disorder not otherwise specified (PDD-NOS). See   for participants’ characteristics. 
   Participant characteristics.        
The Lausanne University Hospital Ethical Committee approved the protocol and all procedures followed the Declaration of Helsinki. None of the participants were compromised in their capacity to assent/consent, and each of them, or their legal guardian for two minor participants, provided written informed consent after complete description of the study. The subjects in the photograph in   gave written informed consent, as outlined in the PLOS consent form, to publication of their photograph. 
   Example of the stimuli presented.  
Panel a: discrimination of stimuli thatcherized at the eye region. Panel b: discrimination of stimuli thatcherized at the mouth. Stimuli were presented in upright and inverted orientation for both conditions. Before each block, a cue indicated the location of thatcherization. Participants had to indicate with a button box whether the left or the right stimulus had been thatcherized. Note that those pictures do not represent the original identities used in the study. 
  

### Behavioral Assessment 
  
In addition to the ADOS and the ADI-R diagnostic tests, and in order to quantify the presence of autism traits, all participants completed the Autism Quotient (AQ) and Empathy Quotient (EQ) self-report questionnaires  ,  . Student   t  -tests were conducted to assess differences between groups. 


### Stimuli 
  
The stimuli used have been described in detail in previous studies  ,  . Sixteen identities were used. Thatcherized faces were paired with the non-thatcherized versions of the same faces, to create three types of stimulus pairs (face with thatcherized eyes vs. typical face, face with thatcherized mouth vs. typical face, and both features thatcherized vs. typical face) for each identity. It is important to note that the discriminability of the features used in this study (eyes and mouth) has been shown to be equal when the features were presented in isolation with no face contexts  . 


### Task Paradigm Used during fMRI (see  ) 
  
Visual stimuli, presented using the E-Prime software package (Psychological Software Tools, Pittsburgh, PA), were back-projected onto a screen positioned at the head of the scanner bore and viewed by the participants through an oblique mirror mounted on the head coil. The experiment was composed of two runs, each consisting of 16 blocks. Runs consisted of a single feature condition (eyes or mouth) alternating with the double feature condition. The sequence of the presentation of the two runs was counterbalanced across participants. A 3 second visual cue preceded each block and stated, “changes have been made to the eyes”, “changes have been made to the mouth” or “changes have been made to the eyes and mouth”. Each stimulus pair (modified face and its typical version) was presented for 1′350 ms during which participants responded. A fixation cross was then presented for 1′650 ms. Pairs of faces were presented in upright and inverted orientation, counterbalanced across blocks. Presentation of the target was counterbalanced between the left and the right side of the screen. Participants were told to press the button corresponding to the side of the location of the thatcherized stimulus. A button box was used to record participants’ responses to the stimuli. Behavioral data for two NT participants were lost due to a technical problem. 

The main aim of the current study was to investigate the relative contribution of the eyes and the mouth to the TI in ASD; the double feature (modification to eyes and mouth) was also included in the experimental paradigm but does not represent the contrast of interest for the current study. In addition, double feature condition contrasts have to be interpreted with caution, because the cues given to look at the eyes or the mouth were found to have long lasting effects. 


### fMRI Data Acquisition 
  
Anatomical and functional MR images of brain activity were collected in a 3T high-speed echoplanar-imaging device (Tim Trio, Siemens, Erlangen) using a 12-channel matrix coil. Participants lay on a padded scanner couch and wore foam earplugs. Foam padding stabilized the head. High-resolution (1.0×1.0×1.0 mm ) structural images were obtained at the beginning of the session with a multi-echo magnetization-prepared rapid acquisition gradient echo (ME-MPRAGE) sequence (176 slices, FOV = 256, 256×256 matrix, echo time (TE1) = 1.64 ms, (TE2) = 3.5 ms, (TE3) = 5.36 (TE4) = 7.22 ms; repetition time (TR) = 2530 ms; flip angle = 7°. The co-registered functional acquisition (45 AC-PC slices, FOV = 216, matrix = 64×64, TE = 30 ms, TR = 3,000 ms, 3 mm thick, 3.12 mm by 3.12 mm in-plane resolution, flip angle 90°) lasted 384 seconds. A separate face and object functional localizer run was also obtained in all participants. The localizer scan consisted of alternating blocks of upright faces and objects   during which participants had to perform a one-back task. 


### fMRI Data Analysis 
  
FSL (FMRIB Software Library) package and techniques were used in data preprocessing and analysis. Specifically, FSL Brain Extraction Tool (BET) was used to remove non-brain tissue   and fMRI data processing was performed using FEAT (FMRI Expert Analysis Tool) version 5.98.  ,  ,  . Each functional run was first motion-corrected with MCFLIRT   and spatially smoothed with full width at half maximum of 8 mm. First-level analysis was performed using FILM (FMRIB’s Improved Linear Model), which uses a nonparametric estimation of time series autocorrelation to pre-whiten each voxel’s time series  . High pass temporal filtering with sigma = 50.0 s was applied to remove low frequency artifacts. Registration to high-resolution structural images was carried out using FMRIB’s linear registration tool (FLIRT)   and registration to standard space was further refined using FMRIB’s nonlinear registration tool (FNIRT,   http://www.fmrib.ox.ac.uk/fsl/fnirt/index.html  ). To examine the TI effect, contrasts were conducted between upright faces (involving configural processing and grotesqueness perception) and inverted faces (involving featural processing) for each single feature condition. Mixed effects GLM analyses were carried out across participants using the two stages of FLAME (FMRIB’s Local Analysis of Mixed Effects)  ,  ,  , an analysis allowing inference about the population from which the subjects were drawn. Threshold significance in the whole brain analysis for the within group data was   p    <0.05, corrected for multiple comparisons using false discovery rate (FDR). Activation between groups was compared using a two sample unpaired   t  -test available in FSL. Statistical maps were thresholded using clusters determined by Z>2.3 and a corrected cluster significance threshold of   p =   0.05  . 


### ROI Analyses 
  
Regions of interest (ROIs) comprised cortical and subcortical areas involved in face and face inversion processing. The cortical ROIs comprised the fusiform face area (FFA), the lateral occipital cortex (LOC) and the pars opercularis of the inferior frontal gyrus (IFG) previously shown to be activated for discrimination of inverted thatcherized faces  . Subcortical ROIs consisted of the pulvinar nucleus of the thalamus (PUL) and the amygdala (AMY), both involved in rapid face detection. To avoid circularity, ROIs were defined by anatomical constraints or by independent functional constraints. The AMY and IFG were specified by labels corresponding to the 25% probability cortical and subcortical Harvard-Oxford atlases. The PUL was defined within the thalamic mask of the 25% probability Harvard-Oxford subcortical atlas, following anatomical landmarks  . Anatomical ROIs were then mapped back to each participant. An independent functional experiment with faces and objects was performed to define the functional ROIs for the FFA and LOC at the subject level. As there is strong evidence for right hemispheric dominance in face processing (e.g.  ,  ), cortical ROIs were restricted to the right hemisphere. Subsequently, for each ROI, the percentage BOLD signal change was extracted from the mean (for all subcortical ROIs) or from the peak (for all cortical ROIs) of the parameter estimate at the subject-level for the contrasts of interest using FSL’s Featquery. A one-sample   t  -test against zero was conducted in order to determine whether the percent signal change for the contrast across orientation (upright vs. inverted) was significantly different from zero, indicating that there was increased activation for one or the other Orientation. Effects of Feature (eyes vs. mouth), Group (ASD vs. NT) and Feature x Group interactions were assessed with ANOVAs. 



## Results 
  
### Behavioral Assessment Questionnaires 
  
ASD participants had an AQ score of 30.4±4.6 (mean ± SD) and an EQ score of 25.8±6.7. NT scored significantly lower on the AQ (  t  (32) = 9.58,   p  <0.001) and significantly higher on the EQ (  t  (32) = 4.78,   p  <0.001) with mean scores of 14.6±5.0 and 39.6±9.6 respectively. 


### Behavioral Performance during the Thatcher Illusion Discrimination Task ( ) 
  
To assess how efficient participants were at discriminating thatcherized stimuli, we analyzed error rates, indicating wrong choice or omission, as well as reaction times. Error rates were analyzed in an ANOVA repeated over Feature (eyes vs. mouth) and Orientation (upright vs. inverted) with Group as the between-subject factor. As predicted, there was a significant Orientation effect (  F(1,30) = 259.43, p  <0.001, partial eta-squared (  η  ) = 0.90) and no Orientation x Group interaction (  F  (1,30) = 0.26,   ns,   (  η  ) = 0.009). Follow-up t-tests confirmed that both groups showed the orientation effect for both features (all   p  <0.05), demonstrating the presence of the Thatcher Illusion (grotesqueness detected in upright orientation but not inverted) in both ASD and NT. The interaction between Feature, Orientation and Group was significant (  F  (1,30) = 7.40,   p   = 0.01,   η   = 0.20). Follow-up   t  -tests demonstrated that for NT error rates did not differ between eyes and mouth in upright orientation (eyes: (mean ± SEM) 5.0±1.3, mouth: 6.8±1.6,   ns  ), while in inverted orientation they made more errors when cued to the mouth (eyes: 37.8±5.0, mouth: 58.3±3.4,   p  <0.05). ASD on the other hand, made fewer errors when cued to the eyes compared to when cued to the mouth in upright orientation (eyes: 13.6±3.1, mouth: 23.2±3.2,   p  <0.05) but only a trend for better discrimination of eyes compared to mouth in inverted presentation (eyes: 58.2±4.2, mouth: 68.4±4.6,   p   = 0.06). Moreover, NT showed higher accuracy than ASD for all conditions (all   p  <0.05) apart for the condition in which discrimination was made based on the mouth in inverted thatcherized faces   (see   ).   Reaction times were analyzed in an ANOVA repeated over Feature (eyes vs. mouth) and Orientation of context (upright vs. inverted) with Group as the between-subject factor. A significant Orientation x Group effect (  F  (1,30) = 8.17,   p  <0.01, (  η  ) = 0.21) was found. Follow up   t  -tests showed that this was due to faster reaction times in ASD for the inverted condition (NT upright (mean ± SEM): 840 ms ±15, ASD upright: 844 ms ±16, NT inverted: 886 ms ±25; ASD inverted: 690 ms ±56,   p  <0.01). 
   Behavioral results for Thatcher discrimination.  
Percentage error rates (with standard errors) across the different conditions for the behavioral Thatcher experiment. UP stands for stimuli presented in upright orientation, INV for those presented in inverted orientation. For both groups and all feature conditions, participants made significantly more errors for the inverted than for the upright condition   (p  <0.0001), reflecting sensitivity to the TI in both ASD and NT. 
  

### Within-group Whole Brain Activation, for ASD and NT 
  
#### Attending to the eyes (see   and  s,  ) 
  
In ASD only, attending to the eyes in upright faces resulted in activation in the subcortical route, amygdala, thalamus pulvinar, and superior colliculus as well as in the hippocampus and the anterior cingulate. For both groups, attending to the eyes in upright faces lead to significant activation in emotion processing and mentalizing areas (mPFC, orbitofrontal cortex, posterior cingulate cortex/precuneus cortex, posterior insula;   see activation in yellow)  , whereas attending to inverted faces lead to significant activation in extrastriate visual areas associated with face and object processing (fusiform gyrus, inferior occipital gyrus, lateral occipital cortex  ; see activation in blue)  . NT in addition showed activation in the cerebellum, pallidum and in motor regions of the thalamus. 
   Cortical activation for within-group whole brain analysis.  
Statistical maps of differences in fMRI activation for each group for each condition. Statistical maps are displayed on the inflated cortical surface of the template FreeSurfer brain (fsaverage), at   p  <0.001 uncorrected, for visualization purposes, on the lateral, medial and ventral views of both hemispheres. Regions of greater activation for discrimination between upright thatcherized and normal faces are depicted in yellow to red; those for discrimination of inverted thatcherized faces from normal faces are depicted in cyan to blue. The grey mask covers subcortical regions in which activity cannot be expressed in surface rendering. The two left panels show activation for the condition where participants are attending to the eye-region to perform the task (top panel: NT; bottom panel: ASD). The two right panels show activation for the condition where participants are attending to the mouth-region to perform the task (top panel: NT; bottom panel: ASD). 
     Cortical and subcortical activation for within-group whole brain analysis.  
Statistical maps of increased activation for each group for the contrast upright vs. inverted, showing areas of subcortical activation, displayed on the FSL MNI template at a sagittal slice x = 49. The two left panels show activation for the condition where participants are attending to the eye-region to perform the task (top panel: NT; bottom panel: ASD). The two right panels show activation for the condition where participants are attending to the mouth-region to perform the task (top panel: NT; bottom panel: ASD). Data are thresholded with   p  <0.005, uncorrected, for visualization purposes. When cued to the eyes, both groups showed activation in medial prefrontal cortex and posterior cingulate/precuneus cortex. In addition, ASD showed activation in subcortical structures. When cued to the mouth ASD do not show activation in medial prefrontal cortex and posterior cingulate/precuneus cortex. 
     Within-group contrasts when participants are attending to the eyes and mouth, for upright and inverted conditions   p   <  0.05.      

#### Attending to the mouth (see   and  s,  ) 
  
Attending to the mouth in upright faces resulted in comparable patterns of activation for NT as observed when attending to the eyes   (see activation in yellow)   whereas ASD exhibited no activation in this condition. For inverted faces, patterns of activation for both groups were comparable to the activation observed when they were cued to the eyes   (see activation in blue)  . 



### Between-group Whole Brain Activation Analyses 
  
#### Attending to the eyes (see  ,  ) 
  
For upright faces, ASD showed increased activation compared to controls in the thalamus, the caudate, and at a more liberal threshold (  p  <0.01) in the superior colliculus. No area showed more activation in NT vs. ASD for upright faces. For inverted faces, NT exhibited more activation in several areas including the IFG, the anterior insula, anterior cingulate, pallidum, prefrontal cortex and cerebellum. ASD did not show increased activation in any area compared to NT when attending to the eyes in inverted faces. 
   Between-group statistical map for the upright vs. inverted eye-cued condition (Z>2.3, corrected cluster significance of   p   = 0.05).  
This map shows brain regions that are significantly different between groups. To see whether the difference is due to ASD>NT or NT>ASD, refer to  . 
     Between-group contrasts when participants are attending to the eyes.        

#### Attending to the mouth 
  
There were no significant differences between groups when participants were attending to the mouth, both for the upright and the inverted conditions. 

At a more liberal threshold (  p  <0.001), NT showed higher activation in a large set of brain areas for upright faces, including areas associated with emotion processing (amygdala, orbitofrontal cortex) and mentalizing (mPFC, posterior cingulate/precuneus, temporal pole). There were no areas for which ASD showed increased activation compared to NT when attending to the mouth in upright faces. For inverted faces, NT exhibited more activation than ASD in the anterior insula, visual cortex, IFG (pars opercularis) and cerebellum (Crus I, VI, VIIIa), while the ASD group showed increased activation in the inferior lateral occipital cortex. IFG (pars triangularis) and superior temporal gyrus were significantly different between groups, with NT showing increased activation for upright faces and ASD for inverted faces. 


#### A priori ROI analysis (See   and  ) 
  
For the cortical ROIs, the FFA, LOC and IFG, activation was significantly different from zero when comparing upright vs. inverted presentation in both groups and in both feature conditions, with increased activation observed for the inverted orientation (all   t  >5.33,   p  <0.001). For the FFA and LOC, ANOVAs revealed no main effect of Group, Feature, or Feature x Group interaction (all   F  <3.1) indicating that ASD showed similar activation than NT in face and object areas. In contrast, a significant Feature x Group interaction was found for the IFG (  F  (1.32) = 5.09,   p  <0.05) due to increased activation in NT, specifically when cued to the eyes (  p  <0.01) (See  ). 
   Region of interest analysis.  
Percent BOLD signal change with standard errors for the contrast upright>inverted in cortical areas, including the right FFA, LOC and IFG. Negative values show that inverted faces led to significantly more activation than upright faces in those brain areas. 
  
Results for the subcortical ROIs are shown in  . One sample   t  -tests against zero conducted to assess differences between orientation revealed a significant activation in ASD for AMY and PUL in both hemispheres, indicating that those areas showed increased activation for upright faces in the eye-cued condition (all   t  (15)>2.22,   p  <0.05). There was however no significant activation in the mouth-cued condition. For NT, no significant effect was found in either structure for either condition. 
   Region of interest analysis.  
Percent BOLD signal change with standard errors for the contrast upright>inverted in subcortical areas including the amygdala and the pulvinar for the right hemisphere (rh) and the left hemisphere (lh). Areas that were significantly different across Orientation (upright vs. inverted) are represented in solid color, and only the contours of those that failed to reach significance are shown. 
  



## Discussion 
  
Using a Thatcher Illusion paradigm, we demonstrated that when individuals with ASD were cued to attend to the eye-region (as opposed to the mouth) in upright faces, they showed increased face discrimination accuracy, enhanced activation in cortical areas involved in social and emotional processing and concurrent hyper-activation in subcortical areas. 

### Configural Processing and Importance of the Eyes, Evidence from Behavioral Data 
  
The TI is one of the experimental paradigms allowing assessment of configural face processing. Consistent with previous findings  ,  , the behavioral data revealed that individuals with ASD as well as NT are sensitive to the TI, as illustrated by significantly decreased performance for discriminating between a thacherized and a typical face when presented inverted as opposed to upright, and the absence of a Group x Orientation interaction. 

One of the behavioral marker for a loss of configural processing in faces is a reduced face inversion effect (FIE): the FIE is defined by the reduction in performance for inverted face recognition and identity matching relative to upright faces  ,  ,  ,  ,  . Initial studies have reported a reduced FIE in individuals with ASD (e.g.  ). However, further studies have reported normal FIE in this population (e.g.  ,  ,  ). Our data add to the body of literature suggesting that impairments in face processing in ASD are not due to a generalized configural processing deficit (reviewed in  ,  ). Individuals with ASD were however generally less accurate than NT in recognizing thatcherized stimuli, independent of feature and orientation, supporting the hypothesis of difficulties in face processing. The significant interaction of Feature x Orientation x Group found in the current study for error rates resulted from the fact that NT were particularly impaired at discriminating the two faces during the single feature mouth condition in inverted faces. The accuracy of the NT did not differ across single features in the upright condition, due to a performance close to ceiling, but differed for the inverted condition, with cueing to the mouth rendering the task more difficult (See  ). It has been shown that less salient facial regions such as the mouth are more affected by face inversion  . On the other hand, individuals with ASD showed better performance when cued to the eyes compared to the mouth in upright faces, and a trend for better discrimination when cued to the eyes compared to mouth in inverted faces. High error rates for the inverted condition were due to higher number of omissions for this orientation. Reaction times did no differ between groups for the upright orientation, however for inverted faces, ASD showed faster reaction times, but did not make fewer errors than NT, suggesting they guessed the answer when the discrimination became particularly difficult. 

In conclusion, our behavioral data confirm that individuals with ASD are sensitive to the TI, supporting the presence of configural processing. In addition, they show that directing visual attention towards the eyes, the most salient feature in typical face processing   and key in driving the TI, leads to better face discrimination ability in ASD. 

Experiments using the Thatcher Illusion have shown deficits in configural face processing along with preserved featural processing in individuals with prosopagnosia, a disorder characterized by severe impairments in recognizing familiar faces  ,  . However, while both individuals with ASD and individuals with prosopagnosia exhibit impairments in processing information from faces, the underlying causes are of very different nature. While prosopagnosia is essentially a disorder of face identification, linked with abnormal function of the FFA and/or occipital face area  ,  ,  , face-processing difficulties in ASD are on the other hand mainly associated with deficits in emotional processing, possibly linked to reduced motivation to attend to social stimuli  . 


### Enhancement of Social and Emotional Processing by Cueing to Eyes 
  
Activation maps showed that an extensive network of areas involved in social and emotional processing was activated by the discrimination of upright thatcherized faces in both groups. Discrimination of upright faces while attending to the eye-region is the condition for which ASD and NT groups showed the least functional difference. Notably, whole brain analysis showed a similar increase in mPFC and posterior cingulate/precuneus activation for upright grotesque face discrimination while attending to the eyes in both groups. These regions have been implicated in emotional processing, including attribution of emotion/mentalizing  ,  ,  ,  ,  ,  . The mPFC has a role in top down biasing towards treating information as socially relevant  . This underlines the fact that if the paradigm requires participants to attend to the eye-region in upright faces, brain activation in areas associated with social processing can be alike in ASD and NT groups. However, when participants were cued to mouths in upright faces, the NT group alone showed activation in the mPFC and the posterior cingulate cortex/precuneus cortex at a more liberal threshold (  p  <0.001). Most of our cognition occurs automatically and without awareness  . We speculate that activation in mPFC and posterior cingulate cortex/precuneus cortex could be due to a spontaneous orienting of NT to the eyes, when cued to the mouth, reflecting typical attention to the most salient region of the face, the eye region. Several studies have indeed demonstrated that NT point of regard naturally gravitates to the eyes  ,  . We suggest that the lack of activation in the aforementioned areas in ASD is due to the fact that ASD, in contrast to NT, strictly follow the cueing instructions and perform the discrimination without implicit emotional processing induced by gazing to the eye-region. Our current findings are however limited by the fact that we did not collect eye-tracking data during fMRI image acquisition, and future eye-tracking studies should help clarifying this point. Amygdala activation correlates with time spent looking in the eye region of the face  . Supporting the notion that NT spontaneously re-orient towards the eye region, increased amygdala activation was observed in the mouth-cued condition in NT. In line with this, a recent combined fMRI eye-tracking study reported increased amygdala activation when typicals as opposed to ASD first looked at the mouth reflecting increased re-orientation to the eye region in typicals  . Furthermore, previous research has shown that typically developing children cannot resist an uninformative gaze cue in attention paradigms, which is not the case in children with ASD  . 


### Face Processing Network 
  
Face processing involves a distributed network of cortical and subcortical areas, including the inferior occipital gyrus, the FFA, the superior temporal sulcus, the insula, the IFG, the amygdala, and pulvinar (e.g.  ,  ,  ,  ). There has been a long controversy about the involvement of the FFA in ASD. Initial studies that did not control for gaze patterns reported reduced activation in this region (e.g.  ,  ), but subsequently others have suggested that this reduced activation may originate in atypical eye-gaze patterns towards faces. These more recent studies indicate that FFA activation depends on orientation towards the eyes during stimulus presentation both in neurotypicals   and in individuals with ASD  ,  . 

In the current study, discrimination of thatcherized stimuli led to increased activation of an extended face-processing network in both ASD and NT for inverted faces. First, it is important to note that in inverted thatcherized faces, the eyes or mouth are in fact upright, given that thatcherization consisted in inverting those regions in upright faces. Additionally, this increased activation in inverted faces could also be due to a greater workload allocation in order to perform the task in this orientation, and possibly also due to the fact that thatcherized faces are less ecologically face-like in their upright than in their inverted orientation. Face inversion was also shown to lead to increased latency and amplitude of the N170, an electrophysiological response sensitive to faces  ,  ,  . It is important to note that no between-group differences were observed in the FFA, and that both ASD and NT showed increased activation for the discrimination of inverted thatcherized faces. 

The significantly decreased activation of the IFG when participants with ASD were cued to eyes, compared to the activation seen in NT, is in line with previous studies reporting decreased activation of the IFG during face processing in ASD. This finding is relevant for a mirror neuron system hypo-activation theory in ASD  ,  . Additional areas in which participants with ASD showed decreased activation compared to NT included the anterior insula and the cerebellum. The anterior insula is involved in the evaluation of task performance as well as in social and emotional processing; hypoactivation of this region in individuals with ASD is consistent with the findings from neuroimaging studies using social stimuli  . The role of the cerebellum in cognitive processing is still poorly understood. Here, differences in the cerebellum were systematically found between the ASD and NT groups for inverted face processing, in areas known to be functionally connected with motor and cognitive association areas  . The findings indicate that the role of cerebellum in face processing in individuals with ASD requires further investigation. 


### Subcortical System 
  
The superior colliculus, the pulvinar nucleus of the thalamus and the amygdala are key elements of the subcortical face-processing pathway  ,  . Specifically for the condition in which they were cued to eyes in upright faces, individuals with ASD showed increased activation compared to NT individuals in these subcortical areas. 

The development of eye contact seems to be disrupted in ASD, although apparently contradictory results have been reported, with some showing stronger neurophysiological response to direct gaze  ,  ,  ,  , while others showed no such effect  ,  . Previous research has suggested that a global face-configuration in newborns activates the subcortical system as a means to orient towards faces, a phenomenon known as CONSPEC  . CONSPEC may also be the mechanism underlying eye-contact detection  ,   that leads to the preference for the eye region seen in NT individuals during face processing, and seemingly absent in individuals with ASD. Expert face processing builds on the maturation of other circuits devoted to face processing, which require sufficient opportunity to process faces and depends on motivation and/or social orienting mechanisms. The subcortical system remains active in neurotypical adults during emotional face processing, allowing rapid orienting towards biologically-relevant stimuli  ,  ,  ,  ,  ,  . In the current study, we saw a greater engagement of the subcortical route for discrimination of grotesque faces in individuals with ASD when cued to look at the eye-region in upright faces. We suggest that this effect may be due to an emotional response induced by looking at the eye-region, possibly resulting from an immature or hypersensitive subcortical system. Increased activation of the subcortical route, a system normally engaged in emotional processing and location of threat in our environment  , may lead to a mistaken interpretation of threat during face perception that underpins active disengagement from faces, especially from the eye-region in individuals with ASD. 

Our data suggest abnormal involvement of the subcortical route during complex face discrimination in the ASD group. Further studies should address the neural substrates of eye-contact aversion in individuals with ASD, and test whether an alteration in face-detection systems can provide a theoretical account of a behavior that jeopardizes smooth social interactions. 


### Conclusions 
  
In conclusion, our data indicate that individuals with ASD are sensitive to the TI, supporting the presence of configural face processing. We observed large group similarities in the face-processing network in response to inverted thatcherized faces. Our results show that directing visual attention towards the eyes in upright faces leads to better behavioral performance and to increased activation in cortical areas involved in emotional and social processing. 

Our data also indicate a heightened activation of subcortical areas in ASD when their attention is directed towards the eyes. This observation suggests a mechanism by which over-activity in the subcortical system could lead to unpleasant arousal and active eye-avoidance in people with ASD. 

Given the ample evidence of difficulties in eye-discrimination in ASD, one key question has been whether a deficit in face-processing leads to a deficit in social attention, or whether it is the consequence of the latter  . Our findings indicate that face-processing, including its social and emotional aspects, may be enhanced in ASD when social attention is warranted by explicit cueing  . Our results may also have implications for behavioral therapies aimed at improving face processing. If social attentional processes underlie face-processing difficulties, then, to ensure improvement that generalizes to all aspects of face-processing, explicit cueing to the eyes should be a crucial component of the training. 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-33'>
<h2>33. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/23922755/' target='_blank'>23922755</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> The Effect of Criticism on Functional Brain Connectivity and Associations with Neuroticism</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2013</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0069606</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3724923/' target='_blank'>3724923</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study used fMRI during a social-evaluation manipulation (participants heard standardized critical remarks and could respond), which qualifies as a social-related task involving perception/understanding of others and self. Participants were healthy adults aged 18–27 (within 17–65). Analyses produced whole-brain seed-based functional connectivity maps entered into second-level random-effects models with FWE cluster correction; although seeds were used, results are whole-brain rather than ROI-only. Only healthy participants’ results are reported. Therefore all inclusion criteria are met and no exclusion criteria are triggered.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Neuroticism is a robust personality trait that constitutes a risk factor for psychopathology, especially anxiety disorders and depression. High neurotic individuals tend to be more self-critical and are overly sensitive to criticism by others. Hence, we used a novel resting-state paradigm to investigate the effect of criticism on functional brain connectivity and associations with neuroticism. Forty-eight participants completed the NEO Personality Inventory Revised (NEO-PI-R) to assess neuroticism. Next, we recorded resting state functional magnetic resonance imaging (rsfMRI) during two sessions. We manipulated the second session before scanning by presenting three standardized critical remarks through headphones, in which the subject was urged to please lie still in the scanner. A seed-based functional connectivity method and subsequent clustering were used to analyse the resting state data. Based on the reviewed literature related to criticism, we selected brain regions associated with self-reflective processing and stress-regulation as regions of interest. The findings showed enhanced functional connectivity between the clustered seed regions and brain areas involved in emotion processing and social cognition during the processing of criticism. Concurrently, functional connectivity was reduced between these clusters and brain structures related to the default mode network and higher-order cognitive control. Furthermore, individuals scoring higher on neuroticism showed altered functional connectivity between the clustered seed regions and brain areas involved in the appraisal, expression and regulation of negative emotions. These results may suggest that the criticized person is attempting to understand the beliefs, perceptions and feelings of the critic in order to facilitate flexible and adaptive social behavior. Furthermore, multiple aspects of emotion processing were found to be affected in individuals scoring higher on neuroticism during the processing of criticism, which may increase their sensitivity to negative social-evaluation. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (39111 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Most people like to hear that they are performing well, both in their personal as well as their professional life. Inevitably, people's behavior is sometimes negatively judged or criticized by others. Individual differences in stress reactivity play an important role in the way people deal with criticism and other forms of negative social-evaluation  . How people cope with stress is determined -among other factors- by their personality. A personality trait that has specifically been associated with stress sensitivity is neuroticism  – . Neuroticism is one of the Big Five dimensions of personality and represents a robust trait that has been replicated many times in various studies  . High neurotic individuals express heightened emotional reactivity, especially to negative events   and are more prone to develop psychiatric disorders, such as depression and anxiety disorders  . Moreover, these individuals tend to be more self-critical   and are overly sensitive to criticism by others  . 

To our knowledge, the interaction between criticism and neuroticism has not previously been studied using functional magnetic resonance imaging (fMRI). Studies investigating the effect of criticism on brain function are limited as well. However, it has been shown that listening to criticism activates brain areas involved in the cognitive control over negative emotions and self-referential processing  . Furthermore, differential processing of criticism has been related to several psychiatric disorders. For instance, Blair et al. (2008) found that patients diagnosed with generalized social phobia (GSP) showed increased activation in the medial prefrontal cortex and the amygdala, as well as enhanced functional connectivity between these two areas in response to negative comments referring to themselves in comparison to healthy controls  . In addition, Hooley et al. (2009) showed that even though patients were remitted from depression, their brain functioning was still altered in response to hearing critical comments made by their own mothers compared to healthy controls  . Moreover, previous research has shown that formerly depressive patients are more likely to relapse, when they perceive their significant family members as being critical of them (‘perceived criticism’). This has also been replicated in other patients samples, including anxiety disorders, schizophrenia and substance abuse disorders  . Individuals that score high on perceived criticism show increased limbic reactivity and decreased cognitive regulatory prefrontal activity during the processing of criticism  . 

One may conclude that criticism is a clinically relevant concept and that it is important to identify and map its underlying neurobiological mechanisms. A new challenge would be to investigate the concept of criticism in a setting, where comments are applicable to the individuals' current situation and his or her corresponding behaviour. However, related literature on psychosocial stress has taught us that it proved to be a challenge to create a task paradigm within (i) the neuroimaging environment that is (ii) able to reliably induce a stress response and (iii) has a naturalistic character  . A meta-analysis on changes in cortisol -an indicator of the stress response- showed that stress could be elicited by motivated performance tasks, which contain elements of social evaluation (e.g. an evaluative audience is present) and uncontrollability (e.g. false feedback)  . However, a limitation of motivated performance tasks is that components related to challenge and achievement play a prominent role, which overshadow the effect of negative social-evaluation  . Interpersonal stressor paradigms overcome this limitation but are still strictly virtual simulations of social situations; for example participants are deceived into believing that they are excluded from an online ball-tossing game  . 

To surpass abovementioned drawbacks, we recorded resting state fMRI (rsfMRI) during a newly constructed paradigm in which criticism on the participants' behaviour was applicable to the current situation. The elements (negative) social-evaluation and uncontrollability, shown to be important in eliciting a stress response  , were incorporated in the paradigm. We presented participants with three standardized critical remarks through headphones, in which the investigator urged the participant to please lie still in the scanner (independent of whether they were lying still or not). The requests were conferred with an increasingly agitated tone. Furthermore, participants were made aware before they went into the scanner that both the investigator and MRI laboratory technician were monitoring them during the experiment. rsfMRI provides an excellent tool to investigate undirected behaviour in participants; it has been shown that intrinsic activity can be modulated by exogenous factors   but is task independent in principle. 

The aim of the current study was twofold. First, we investigated which functional connectivity patterns underlie the processing of criticism, using seed-based functional connectivity and subsequent cluster analysis. Based on the reviewed literature related to criticism  ,  – , we selected regions of interest associated with self-reflective processing: frontal, temporal, parietal and cortical midline structures ( )   and stress regulation: the amygdala and hippocampus  . We hypothesized enhanced functional connectivity between selected seed regions and brain areas involved during the processing of emotions and social interaction. Second, we investigated whether neuroticism explained variance within functional connectivity patterns related to criticism. We hypothesized altered functional connectivity between selected seed regions and brain areas related to emotion regulation in individuals scoring higher on neuroticism  . The former as well as the latter hypothesis were confirmed. 
   Seed regions associated with self-reflective processing.        

## Materials and Methods 
  
### Participants 
  
Forty-eight healthy Dutch participants (32 women, mean age 20.78±SD 2.45; 16 men, mean age 20.63± SD 2.16, age range: 18–27) were recruited from the University of Groningen. Participants were screened for exclusion criteria using a self-report checklist, comprising the following criteria (1) a history of seizure or head injury, (2) a life time diagnosis of psychiatric and/or neurological disorders, (3) a life time diagnosis of psychiatric disorders in first degree relatives of the participant, (4) the use of medication that can influence test results, (5) visual or auditory problems that cannot be corrected, (6) MRI incompatible implants or tattoos, (7) claustrophobia, (8) suspected or confirmed pregnancy. 


### Ethics statement 
  
The Medical Ethical Committee of the University Medical Center Groningen approved the experimental protocol and written informed consent was obtained from all participants prior to participation. The study was conducted in accordance with the Declaration of Helsinki. 


### NEO (Neuroticism, Extraversion, Openness) Personality Inventory Revised 
  
The NEO-PI-R   is based on the Five-Factor Model (FFM) of personality   and consists of 240 items, which assess the following five domains: Neuroticism, Extraversion, Openness, Agreeableness, and Conscientiousness. The psychometric properties of the NEO-PI-R can be considered good. Cronbach's alpha ranges from 0.86 to 0.92 for the domain scales of the Dutch version of the NEO-PI-R  . 


### Stress manipulation 
  
rsfMRI data were recorded during two sessions, each lasting five minutes. Participants were instructed to close their eyes and to not fall asleep. The first session consisted of scanning a standard resting state (standard session). The second session was manipulated before scanning by presenting three standardized critical remarks through headphones (criticism session). The general request addressed to the participant was to please lie still in the scanner. Participants were able to respond after each remark. The first remark: “It is important that you lie still” (neutral tone) was presented at time zero. The second remark: “[harrumph] Could you please lie still now for a moment” (slightly agitated tone) was presented after the scan preparation. The third remark: “Lie still now please” (agitated tone) was presented after the second remark, depending on the length of the participants' reaction to the second remark. The scan was proceeded, after the corresponding reaction to the third remark. The remarks were recorded by the investigator (J.L., male voice). In this way, participants were criticized by the person, who led the experiment. Furthermore, participants were introduced to the MRI laboratory technician, before they went into the scanner. Participants were made aware that both the investigator and MRI laboratory technician were monitoring them during the experiment. After the scanning session, participants were debriefed and informed that the repeated requests to lie still were part of the experiment. The order of the sessions was kept constant; the criticism session always followed the standard session. 

To validate our stimuli, a pilot study was conducted to demonstrate that the tone of the three critical remarks was indeed perceived as increasingly agitated and that the receipt of the critical remarks was indeed experienced as negative, stressful and arousing. The results showed that the critical remarks were ranked as expected (remark 1 as least agitating and remark 3 as most agitating). Furthermore, positive affect significantly decreased (T  = 2.85, p<0.05) after the presentation of the critical remarks, while negative affect significantly increased (T  = −4.59, p<0.05) (see 1. Stimulus pilot in   for a full description of the pilot study). 


### Image acquisition 
  
A 3 Tesla Phillips Intera scanner (Phillips Medical Systems, Best, the Netherlands), equipped with an 8-channel SENSE head coil, was used to acquire the images. A high-resolution T1-weighted 3D structural image was obtained using fast-field echo (FFE) for anatomical reference (160 slices; TR: 25 ms; TE: 25 ms; FOV: 256×204; 256×204 matrix; voxel size: 1×1×1 mm). Functional images were acquired by T2*-weighted gradient echo planar imaging (EPI) sequences. The criticism session comprised 150 volumes in 40 axial-slices (TR: 2000 ms; TE: 25 ms; FOV: 210×210; 64×66 matrix; voxel size: 3.2×3.2×2.5 mm). The standard session comprised 200 volumes – only the first 150 volumes were used for analysis – in 43 axial-slices (TR: 2290 ms; TE: 28 ms; FOV: 220×220; 64×61 matrix; voxel size: 3.44×3.44×3 mm). Slices were acquired in an interleaved manner and oriented parallel to the AC-PC plane without gap. 


### Image analysis 
  
Image processing and statistical analyses were performed using SPM8 (  http://www.fil.ion.ucl.ac.uk  ), implemented in Matlab 7.8.0 (The Mathworks Inc.). The images were corrected for slice timing and realigned using rigid body transformations. After realignment, the mean image was coregistered to the anatomical T1 image. Subsequently, images were spatially normalized to common stereotactic space (MNI T1-template) and resampled to a voxel size of 2×2×2 mm. Lastly, smoothing was applied using a 6 mm kernel full-width at half maximum (FWHM). 

Next, a series of preprocessing steps specific to rsfMRI analysis were performed. First, regression of several nuisance variables was applied to remove sources of spurious variance, comprising six rigid body head motion parameters, the global signal, white matter signal and cerebrospinal fluid (CSF) signal. In order to obtain the last two signals, we performed segmentation to create two separate masks and extracted the first eigenvariate from the time series of the included voxels. In addition, the first temporal derivatives of abovementioned nuisance variables were removed. Second, temporal band-pass filtering was applied to detrend the signal and to retain frequencies between 0.008 – 0.08Hz  . 

Subsequently, a seed-based functional connectivity method was used to analyse the data with a General Linear Model (GLM)  . A total of thirteen seed regions were defined based on the following criteria: (i) nine seed regions associated with self-reflective processing were based on a meta-analysis of neuroimaging studies investigating self-reflection   (see  ) (ii) the bilateral amygdala and hippocampus were selected as seed regions based on a review on stress regulation in the central nervous system  . Next, a sphere (radius of 6 mm) was created with Marsbar   around the nine center coordinates, which were reported for the contrast (self > baseline) in the meta-analysis on self-reflection. The center coordinates reflect voxels with a maximum score in clusters of activation that are reported in a certain percentage of the studies, included in the meta-analysis  . The seed regions consisted of 123 voxels and had a volume of 984 mm . With regard to the amygdala and hippocampus, seed regions were constructed using the WFU Pickatlas. Accordingly, the first eigenvariate was extracted from the time series of the voxels in the thirteen specified seed regions per subject for the two sessions. This resulted in twenty-six eigenvariate time courses for every subject, thirteen for the standard session and thirteen for the criticism session. The eigenvariate time courses were added as a regressor at first level per subject for the two sessions separately and the betas were subtracted from each other (criticism > standard). The resulting contrast images were entered in a second level random effect analysis. 

For every seed region, a design was built on second level that consisted of two factors: subject and gender. Gender was entered as a factor of no interest in the model because a gender difference was found in neuroticism scores (see the Results section, Neuroticism scores). Hence, neuroticism scores were centered separately for women and men and were entered as a regressor of interest in the model. Differences between the two sessions as well as interactions with neuroticism (positive as well as negative correlations) were investigated. Results were corrected on FWE cluster level (cluster extent, k>20) with an initial threshold of p<0.001 uncorrected. 


### Cluster analysis 
  
In order to facilitate interpretation of the results, abovementioned connectivity maps, i.e (criticism > standard) for each of the thirteen seed regions, were clustered into a number of networks. First, the connectivity maps were averaged across subjects and concatenated. This resulted in a two dimensional matrix (D), where rows represented the seed regions and columns the voxels. Second, the number of clusters present in the data was estimated by creating Cattell's screeplot   and a maximum profile log-likelihood   based on the eigenvalues of the covariance matrix of D. Both methods revealed a four-component solution (see 2. Clustering analysis, Figure S1 in  ). Third, fuzzy c-means (FCM) clustering was applied to matrix D to group the selected seed regions based on their functional connectivity pattern in four clusters  ,  . The same four-component solution (see 2. Clustering analysis, Figure S2a in  ) and cluster partition (see 2. Clustering analysis, Figure S2b in  ) were found, when the cluster analysis was performed on the connectivity maps resulting from the contrast (criticism > standard × neuroticism). 



## Results 
  
### Neuroticism scores 
  
The mean neuroticism score across the whole sample was 138.75± SD 20.53 and was consistent with the mean reference value mentioned in the NEO-manual   for the neuroticism domain within a student sample (research-context, mean 138.4± SD 21.5). Furthermore, a gender difference was found for neuroticism (F  = 8.55, p<0.05). On average, women had higher scores on neuroticism than men (women: mean 144.44± SD 17.72; men: mean 127.38± SD 21.57) (NEO manual, students, research-context, women: mean 143.6± SD 21.0; men: mean 132.8± SD 20.6). 


### Cluster analysis 
  
The eigenvalues revealed a four-component solution (see 2. Clustering analysis, Figure S1 in  ) and therefore, FCM clustering was applied to find four clusters. The first cluster consisted of functional connectivity patterns associated with two seed regions positioned in the prefrontal cortex; the superior frontal gyrus (BA9) and left superior frontal gyrus (prefrontal cluster). The second cluster comprised functional connectivity patterns related to three seed regions located in the fronto-temporal cortex; the left inferior frontal gyrus (orbital part), left insula and left temporal pole (fronto-temporal cluster). The third cluster consisted of functional connectivity patterns associated with two seed regions sited in the occipito-parietal cortex; the posterior cingulate gyrus/precuneus and cuneus (occipito-parietal cluster). The fourth cluster comprised functional connectivity patterns related to four subcortical seed regions: left and right amygdala and hippocampus (amygdala/hippocampal cluster). The seed regions anterior cingulate gyrus and superior frontal gyrus (BA10) loaded on both the first cluster as well as the second cluster (see   and  ). 
   Four clusters were found using fuzzy c-means clustering for the contrast (criticism > standard): (A) prefrontal cluster (red bars), (B) fronto-temporal cluster (yellow bars), (C) occipito-parietal cluster (green bars) and (D) amygdala/hippocampal cluster (light blue bars).  
The seed regions anterior cingulate cortex and SFG(BA10) are depicted in dark blue. On the x-axis, the different seed regions can be found in alphabetical order. On the y-axis, membership degrees are continuously expressed as proximities to a cluster centroid, containing values between 0 and 1. ACC, anterior cingulate cortex; L_Amy, left amygdala; R_Amy, right amygdala; Cun, cuneus; L_Hip, left hippocampus; R_Hip, right hippocampus; L_IFG, left inferior frontal gyrus; L_Ins, left insula; L_SFG, left superior frontal gyrus; L_TP, left temporal pole; PCC/Prec, posterior cingulate cortex/precuneus; SFG(BA10), superior frontal gyrus (BA10); SFG(BA9), superior frontal gyrus (BA9). 
     Visualization of correlations between the seed regions based on their functional connectivity pattern.  
Gephi (0.8.1 – beta) was used to draw the graph. The following colors indicate the cluster to which a specific seed region belongs based on the fuzzy c-means clustering approach: the prefrontal cluster (red), the fronto-temporal cluster (yellow), the occipito-parietal cluster (green) and the amygdala/hippocampal cluster (light blue). The seed regions anterior cingulate cortex and SFG(BA10) are depicted in dark blue. The edges between the nodes have a mixed color. The thickness of the edges represents the strength of the correlation between the seed regions based on their functional connectivity pattern. ACC, anterior cingulate cortex; L_Amy, left amygdala; R_Amy, right amygdala; Cun, cuneus; L_Hip, left hippocampus; R_Hip, right hippocampus; L_IFG, left inferior frontal gyrus; L_Ins, left insula; L_SFG, left superior frontal gyrus; L_TP, left temporal pole; PCC/Prec, posterior cingulate cortex/precuneus; SFG(BA10), superior frontal gyrus (BA10); SFG(BA9), superior frontal gyrus (BA9). 
  

### Brain networks related to criticism 
  
The criticism and standard session were contrasted for each of thirteen seed regions (see   and  ). First, brain regions were identified that were functionally connected to the prefrontal cluster. When contrasting the criticism session and standard session, this cluster revealed enhanced functional connectivity with the precuneus, superior parietal gyrus, calcarine sulcus, lingual gyrus, fusiform gyrus, superior occipital gyrus and middle cingulate gyrus. The reverse contrast (standard > criticism) revealed increased functional connectivity between the prefrontal cluster and the superior medial frontal gyrus, superior frontal gyrus, anterior cingulate gyrus, middle cingulate gyrus, supplementary motor area, middle frontal gyrus, insula, inferior frontal gyrus, precentral gyrus, middle temporal gyrus, inferior temporal gyrus, inferior parietal gyrus, angular gyrus and supramarginal gyrus. 
   Functional connectivity patterns related to the thirteen seed regions overlayed on a MNI template for the different contrasts: (A) criticism > standard, (B) standard > criticism, (C) criticism > standard, positive correlation with neuroticism and (D) criticism > standard, negative correlation with neuroticism.  
Brain regions, showing enhanced functional connectivity to our thirteen seed regions, are depicted in red for seed regions that belong to the prefrontal cluster, in yellow for seed regions that belong to the fronto-temporal cluster, in green for seed regions that belong to the occipito-parietal cluster and in light blue for seed regions that belong to the amygdala/hippocampal cluster. Connectivity results for the seed regions anterior cingulate cortex and SFG(BA10) are depicted in dark blue. Results were corrected on FWE cluster level (k>20) with an initial threshold of p<0.001 uncorrected. 
     Functional connectivity results related to criticism and associations with neuroticism.        
Second, the functional connectivity pattern was determined for the fronto-temporal cluster. For criticism compared to standard, this cluster showed stronger functional connectivity with the precuneus, lingual gyrus and calcarine sulcus. When standard was contrasted with criticism, enhanced functional coupling was found between the fronto-temporal cluster and the superior medial frontal gyrus, anterior cingulate gyrus, middle cingulate gyrus, supplementary motor area, middle frontal gyrus, insula and inferior frontal gyrus. 

Third, brain areas were identified that were functionally connected to the occipito-parietal cluster. When criticism was contrasted with standard, the occipito-parietal cluster showed stronger functional connections with the medial orbital frontal gyrus. For standard compared to criticism, no significant results were found. 

Finally, the functional connectivity pattern was identified for the amygdala/hippocampal cluster. The contrast (criticism > standard) showed enhanced functional coupling between this cluster and the superior medial frontal gyrus. The reverse contrast (standard > criticism) revealed increased functional connectivity between the amygdala/hippocampal cluster and the hippocampus, lingual gyrus and calcarine sulcus. 


### The effect of neuroticism on criticism-related brain networks 
  
Interactions between criticism-related functional connectivity and neuroticism were investigated by calculating positive as well as negative correlations with neuroticism for the contrast (criticism > standard) per seed region (see   and  ). 

First, we identified the functional connectivity pattern for the prefrontal cluster that was modulated by neuroticism. Neuroticism correlated positively with functional connectivity between this cluster and the middle frontal gyrus, supplementary motor area, inferior frontal gyrus, precentral gyrus, insula and rolandic operculum. Furthermore, neuroticism was negatively related to functional connectivity between the prefrontal cluster and the posterior cingulate gyrus, angular gyrus, superior temporal gyrus, middle temporal gyrus and superior temporal pole. 

Second, the functional connectivity pattern was identified for the fronto-temporal cluster on which neuroticism had a modulatory effect. Neuroticism showed a positive correlation with functional connectivity between this cluster and the middle frontal gyrus, inferior parietal gyrus, angular gyrus, inferior frontal gyrus, precentral gyrus and rolandic operculum. No significant functional connectivity results were found, when a negative correlation was calculated with neuroticism. 

Third, brain areas were determined for which their functional connection with the occipito-parietal cluster was modulated by neuroticism. Neuroticism was positively associated with functional connectivity between this cluster and the cuneus, calcarine sulcus, lingual gyrus and inferior frontal gyrus. Furthermore, neuroticism correlated negatively with functional connectivity between the occipito-parietal cluster and the middle cingulate gyrus, insula, rolandic operculum and postcentral gyrus. Lastly, we identified the functional connectivity pattern for the amygdala/hippocampal cluster on which neuroticism had a modulatory effect. Neuroticism revealed a positive correlation with functional connectivity between this cluster and the lingual gyrus, calcarine sulcus, superior occipital gyrus and cuneus. Furthermore, neuroticism was negatively related to functional connectivity between the amygdala/hippocampal cluster and the superior medial frontal gyrus, superior frontal gyrus, middle frontal gyrus and middle cingulate gyrus. 



## Discussion 
  
In the current study, we developed a novel resting-state paradigm to investigate the effect of criticism on functional brain connectivity and associations with neuroticism. The cluster analysis revealed four clusters based on selected seed regions related to self-reflective processing and stress-regulation. During the processing of criticism, these clusters showed enhanced functional connectivity with brain areas involved in emotion processing and social cognition, while they showed reduced connectivity with brain regions related to the default mode network and higher-order cognitive control. Furthermore, the findings revealed that neuroticism modulated functional connectivity between aforementioned clusters and brain areas associated with the appraisal, expression and regulation of negative emotions. 

### Brain networks related to criticism 
  
First, decoupling was found between the prefrontal and fronto-temporal cluster and brain areas related to the default mode network during the processing of criticism. The default state of the brain is supported by a distributed network of anterior and posterior cortical midline structures, the lateral parietal cortex and hippocampal formation  . Activity in this network has been observed during passive experimental control conditions and is involved in self-relevant internal cognitive processes  . Our finding may suggest that individuals were more externally oriented during the criticism session than during the standard session. Furthermore, the prefrontal and fronto-temporal cluster displayed reduced functional connectivity with several prefrontal brain regions as well. This finding is in line with previous research showing that even mild acute uncontrollable stressors are able to disrupt prefrontal functioning  ,  . However, the effects of stress on the brain are not always disadvantageous. Emotional stress can bias processing in favor of a salient stimulus that is relevant to the individuals' current situation  ,  . In the present paradigm, the salient stimulus took the form of criticism that was expressed onto the subjects' behavior in the scanner. Accordingly, we found enhanced functional coupling between the clustered seed regions and brain areas involved in emotion processing and social cognition during the processing of criticism. Our results fit with the integrative model of emotion understanding proposed by Spunt and Lieberman (2012)  . The authors suggested that first, the mirror neuron system is recruited during the identification of behavior and subsequently, the mentalizing system is recruited in order to make a causal attribution to the observed behavior  – . 

In line with the first part of Spunt and Lieberman's model (2012), we found enhanced functional coupling between the fronto-temporal cluster (specifically the inferior frontal gyrus, IFG) and a number of parietal regions, specifically the precuneus  . Previous research has shown that the IFG possesses mirror neuron properties  ,   and that it is involved in the identification of emotional prosody by utilizing motor representations with regard to the production of a given intonation  – . Such sensorimotor patterns may facilitate the identification of other people's feelings by simulating their mental state  ,  . This step precedes the mental process of mentalizing in which emotions are attributed to social causes  . One of the connections through which both systems are integrated is the connection between the IFG and precuneus (the latter structure is an integral part of the mentalizing system)  . This finding is in line with our results, except that Spunt et al. (2012) found the right IFG to be connected to the precuneus instead of the left  . However, this distinction might be explained by a difference in task paradigm. In the paradigm of Spunt and Lieberman (2012), participants were instructed to infer an individuals' emotional state from motor behavior in contrast to linguistic input  . In accord, a recent meta-analysis on the diversity of the inferior frontal gyrus revealed that movement control could be attributed to the right hemisphere, while functions related to empathy, language and working memory could be attributed to the left hemisphere  . 

Alternatively, a connection between the left IFG and precuneus has been implicated in the recollection of personal episodes from the past (autobiographical memory)  . There is evidence linking autobiographical memory to social cognition by showing a common neural substrate for both mental processes, including the inferior frontal gyrus and precuneus/posterior cingulate gyrus  . This functional overlap might promote the construction of predictions regarding other people's feelings and behavior by drawing upon personal past experiences  . 

With regard to the second part of Spunt and Lieberman's model (2012), we found enhanced functional connectivity between the prefrontal cluster and several parietal regions (including the precuneus and superior parietal gyrus) and the parietal cluster and medial orbital frontal cortex (OFC)  . These regions have been implicated in mentalizing and represent the cognitive and affective components of Theory of Mind (ToM), respectively  ,  – . The dorsal medial prefrontal cortex (dmPFC, overlapping with the prefrontal cluster) is involved in inferring what other people   think  , while the ventral medial prefrontal cortex (vmPFC, overlapping with the medial OFC) is implicated in making inferences about what other people   feel  . Both components are indirectly connected to the precuneus/posterior cingulate gyrus in the higher association cortex, which is engaged in self-referential processing  ,  . Furthermore, a connection has been found between the dmPFC and precuneus during the assessment of social relationships and their implications   and autobiographical memory  ,  . Moreover, the orbital frontal cortex has been associated with decoding mental states by extracting social information from the environment, such as an individuals' tone of voice  . 

Finally, we found that the left amygdala coactivated with the dmPFC during the processing of criticism. This finding is consistent with the postulated framework of Etkin et al. (2011), in which a positive connection between abovementioned brain regions is attributed to the appraisal and expression of negative emotions  . Furthermore, various studies have shown the dmPFC and amygdala to be part of a network underlying emotion regulation  ,  . 


### The effect of neuroticism on criticism-related brain networks 
  
Enhanced functional coupling was found between the prefrontal and fronto-temporal cluster and the lateral prefrontal cortex (LPFC) in individuals scoring higher on neuroticism during the processing of criticism. This region -among others- is involved in the cognitive control over negative emotions  , specifically during cognitive reappraisal  ,  ,  . Reappraisal can be defined as a strategy in which individuals explicitly regulate their emotions by reinterpreting the meaning of an affective stimulus to reduce its emotional impact  . Individual differences in the capacity to employ cognitive control in response to emotionally distressing experiences have been related to variation in adaptive functioning. The impact that these experiences ultimately have on well-being are determined by regulatory success  . Generally, high neurotic individuals cope poorly with daily hassles and frequently experience mood spillovers  ,  . Furthermore, fMRI studies systematically showed that high neurotic individuals are more sensitive to a wide range of negative emotional stimuli, e.g. sad, angry and fearful faces; negative and arousing scenes; negative words; and aversive anticipatory cues  – . In addition, high neurotic individuals are more self-critical   and are overly sensitive to criticism by others  . These findings and ours may indicate that individuals scoring higher on neuroticism need greater regulatory efforts in order to gain cognitive control over their emotions. However, caution is needed since other functional roles of the LPFC cannot be ruled out  . 

Furthermore, we found decreased functional connectivity between the prefrontal cluster and several default mode brain regions in individuals scoring higher on neuroticism during the processing of criticism. As described before, the default mode network has been related to processes such as self-related processing, mental simulation, introspection, future planning and emotion regulation  ,  . This finding indicates that although frontal connections are strengthened in high neurotic individuals during the processing of criticism, multiple other long range connections -important for regulating negative emotions- are weakened. It seems that the aforementioned frontal circuit may play a compensatory role by increasing its functional connectivity. Previous research has shown that patients with anxiety disorders also demonstrate decreased default mode functioning in comparison to healthy controls, when they are not given explicit instructions on how to regulate their emotions  . In addition, decreased functional coupling was found between the amygdala/hippocampal cluster and a number of frontal regions, including the dmPFC and dorsal lateral prefrontal cortex (dlPFC) in individuals scoring higher on neuroticism during the processing of criticism. As previously mentioned, a connection between these brain areas is involved in the appraisal and expression of negative emotions  . It seems that multiple aspects of emotion processing are affected in high neurotic individuals during the processing of criticism, which may increase their sensitivity to negative social-evaluation. 


### Limitations 
  
Several limiting factors can be mentioned with regard to the current study. First, a seed-based functional connectivity method was used to quantify connections within the brain. Since this is a correlation based method, we cannot distinguish between direct or indirect pathways between brain regions or assess causal directions between them. Second, a difference in acquisition parameters existed between the two resting-state sessions. The influence of such a difference on functional connectivity has been investigated by van Dijk et al. (2010). In their study, temporal (TR 2.5 versus 5) as well as spatial (voxel size 2 mm  versus 3 mm ) resolution were varied between runs. The authors concluded that these factors have a minimal effect on functional connectivity measures  . Notably, the differences in TR and voxel size were much smaller in the current study (TR 2 versus 2.29 and voxel size 3.2×3.2×2.5 versus 3.44×3.44×3). Therefore, we deem it unlikely that differences in acquisition parameters biased our results substantially. Specifically, the functional connectivity findings related to neuroticism cannot be explained by differential acquisition parameters, since all participants were scanned using the same protocol. Third, a test-retest effect (i.e. time on task) could not be examined in the current study. An option would have been to present neutral comments between the two runs to half of the subjects, however this would have doubled the sample size. Alternatively, counter balancing task order is often applied to disentangle task effects from effects related to test-retest. Note that this was not option because the temporal dynamics of the manipulation are unknown. Investigating the whole-brain functional connectivity dynamics as a consequence of the manipulation would be particularly interesting and should improve the sensitivity of the analysis even further. Future research may benefit from studying such time-varying aspects in functional connectivity, for instance, to elucidate how long changes in brain networks related to negative affect persist and whether this pattern is different for high and low neurotic individuals. However, we need to emphasize that having a fixed task order puts constraints on the interpretation of our results. In principle, the findings could be explained by factors such as habituation effects. Nonetheless, differences were found between the two runs that correlated with neuroticism. It is improbable that high neurotic individuals would have reacted in a similar manner to neutral comments, since it is a robust finding in neuroticism research that these individuals express heightened emotional reactivity to negative events  –  or react differently to prolonged scan duration. Fourth, no objective stress measures were assessed during the experiment (e.g. heart rate, respiration and cortisol) in order to perform a manipulation check and verify that receiving criticism is indeed experienced as a stressful and arousing event. Nevertheless, the current paradigm has never been used before and now that it has shown significant effects, it can be investigated more extensively with accompanying measures. 



## Conclusion 
  
In the current study, we used a novel resting-state paradigm to investigate the effect of criticism on functional brain connectivity and associations with neuroticism. The findings showed that brain regions involved in emotion processing and social cognition were recruited during the processing of criticism, while default mode activity and higher-order cognitive control functions were attenuated. These results may suggest that the criticized person is attempting to understand the beliefs, perceptions, emotions and goals of the critic in order to facilitate flexible and adaptive social behavior. Furthermore, individuals scoring higher on neuroticism showed alterations in functional connectivity between brain areas involved in the appraisal, expression and regulation of negative emotions. These results underscore the general emotional liability that characterizes high neurotic individuals and provide insights into the underlying neurobiological mechanisms that predispose such individuals to the development of mood disorders. 


## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-34'>
<h2>34. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22003388/' target='_blank'>22003388</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Predicting Decisions in Human Social Interactions Using Real-Time fMRI and Pattern Classification</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2011</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0025304</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3189203/' target='_blank'>3189203</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study uses fMRI while participants performed a social task (ultimatum game), recruiting healthy adult participants (ten males, age 23–28). The paper reports whole-brain analyses (offline whole-brain SVM classification and reporting of discriminating volumes across brain regions) in addition to ROI-based real-time analyses. No participant groups with psychiatric or neurological disorders are the sole focus. Thus all inclusion criteria are met (social-related fMRI task, healthy adult sample, and whole-brain results reported); no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Negotiation and trade typically require a mutual interaction while simultaneously resting in uncertainty which decision the partner ultimately will make at the end of the process. Assessing already during the negotiation in which direction one's counterpart tends would provide a tremendous advantage. Recently, neuroimaging techniques combined with multivariate pattern classification of the acquired data have made it possible to discriminate subjective states of mind on the basis of their neuronal activation signature. However, to enable an online-assessment of the participant's mind state both approaches need to be extended to a real-time technique. By combining real-time functional magnetic resonance imaging (fMRI) and online pattern classification techniques, we show that it is possible to predict human behavior during social interaction   before   the interacting partner communicates a specific decision. Average accuracy reached approximately 70% when we predicted online the decisions of volunteers playing the ultimatum game, a well-known paradigm in economic game theory. Our results demonstrate the successful online analysis of complex emotional and cognitive states using real-time fMRI, which will enable a major breakthrough for social fMRI by providing information about mental states of partners already during the mutual interaction. Interestingly, an additional whole brain classification across subjects confirmed the online results: anterior insula, ventral striatum, and lateral orbitofrontal cortex, known to act in emotional self-regulation and reward processing for adjustment of behavior, appeared to be strong determinants of later overt behavior in the ultimatum game. Using whole brain classification we were also able to discriminate between brain processes related to subjective emotional and motivational states and brain processes related to the evaluation of objective financial incentives. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (44181 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Neuroscientific studies of the brain mechanisms of social decision-making offer new insight which helps to incorporate human behavior into economic models. In the framework of neuroeconomics, cognitive and neural constraints of the complex processes of social decision-making are explored  – . Experimental paradigms from game theory are well suited to the investigation of neural correlates of decision-making, because profound empirical insight into human behavior is provided  ,  . 

Using a real-time noninvasive technique based on fMRI, we investigated the neural correlates of social decision-making and tried to already infer the decisions made by participants involved in social interaction from brain activation during scanning. We employed a well-established economic game called the ultimatum game (UG), in which two players split a given amount of money. One player acts as the proposer, retaining one share of the money and offering the remaining share to the other player (the responder). The responder can either accept or reject the proposer's offer. If the offer is accepted, the money is split as proposed. If the offer is rejected, neither player receives anything. According to the notion of profit maximization, the proposer is expected to offer the smallest possible sum of money and the responder to accept this offer, because even the smallest profit is preferable to no monetary reward  . Contrary to this assumption, it has been repeatedly shown that the results of negotiation in this game do not conform to the expected game-theoretic equilibrium outcomes. Instead, low (unfair) offers of 10–20% of the total sum of money are rejected in more than 50% of cases  ,  , suggesting that emotions, attitudes, and expectations influence players' decisions. 

Social interaction as in the ultimatum game may lead to conflicts between players' goals and internal attitudes and social norms, which elicit emotions. These conflicts require considerable cognitive effort to be resolved  ,  ,  . Consequently, previous fMRI studies on decision-making report the involvement of cortical and subcortical brain regions related to cognitive control, such as prefrontal cortex, anterior cingulate cortex, and regions connected to emotional response such as amygdala and insular cortex (for a review see  ). Decision-making processes in social interaction scenarios have already been examined using functional magnetic resonance imaging (fMRI)  ,  ,  ,  . For example, Sanfey et al. reported activation of anterior cingulate cortex, anterior insula, and dorsolateral prefrontal cortex when presenting unfair offers vs. fair offers in a single-shot version of the UG  . In the single-shot UG, the responder plays just one trial against a single proposer, whereas in the repeated UG, a responder interacts repeatedly with the same proposer. Generally, the behavior in the repeated version of the game is influenced by strategic reasoning and the interaction of the players is more competitive than in the single shot version  . 

However, the statistical analysis used in these studies relies on the comparison of mean blood oxygen level dependent (BOLD) signals calculated from many trials, leaving the question open whether these effects are strong enough to be reliably detected in   single   decisions   before   the decision is revealed by the subject, and without prior knowledge of the actual offer in the trial  . Multivariate classification is well suited to such a “brain-reading” task. Brain states have been decoded from the temporal and spatial patterns in fMRI data  – . The application of pattern classification to fMRI data was done in the fields of fear perception  , visual perception  , goal-related intentions  , or lie detection  . However, in conventional fMRI decoding, these methods are applied offline in the post-experimental analyses. We aimed to predict the decisions before volunteers communicated them and therefore combined the multivariate classification of brain states with real-time fMRI (rtfMRI). This technique allows for online analysis of BOLD activity, for example in the framework of brain computer interfaces  – . To date, real-time multivariate analysis of fMRI data has been conducted in very few studies  – . La Conte et al. and Sitaram et al. combined whole-brain classification and rtfMRI to implement neurofeedback experiments. Posse et al. combined a classifier with neuroanatomically constrained boosting to analyze rtfMRI data recorded during visual stimulation, finger tapping, auditory attention, and mental calculation. In none of these studies were the online data used to continuously retrain the classifiers during the experiment to improve classification performance. 

Here our goal was to discriminate complex brain states occurring in social interactions on the basis of the BOLD signal in a small number of distinct brain regions in real time. Including only few relevant brain areas allowed us to adapt the model parameters of a Relevance Vector Machine (RVM) classifier   during the ongoing experiment to improve online classification performance. In a second offline analysis step, we trained a multivariate pattern classifier on the whole brain across subjects and tested the transfer of the brain activation over subjects. This latter step allowed us to   a posteriori   evaluate if the pre-selected brain areas used in the online approach were adequate. We were also able to investigate hypotheses about the role of brain processes related to subjective emotional and motivational states during decision-making and to distinguish them from brain processes related to the evaluation of an objective financial incentive. 


## Materials and Methods 
  
### Subjects and paradigm 
  
Ten healthy male subjects (23–28 years, mean: 24.7±1.6 years) with normal or corrected to normal vision were examined after providing written informed consent. The experiments were approved by the local ethics committee of the Medical Faculty of the University of Magdeburg. One subject was excluded from the study after reporting doubts about whether he was playing with human partners. Data from two subjects served for the initial training of the classifier that was subsequently used to examine seven subjects. To avoid cross-gender effects, only male volunteers participated in the study  . 

At the beginning of a session, participants met two male individuals, who were introduced to them as the proposers in the UG. Participants were told that the actual proposer would be chosen randomly from these two individuals for each single trial and that proposers do not interact with each other during the experiment. This procedure was chosen because personal contact between responder and proposer is considered to be an essential prerequisite to establishing a social bond between players  ,  ,  . During scanning, the actual offers were made by a computer in a predefined order. This ensured a controllable set of offers. 

Brain activity was measured and analyzed using rtfMRI and real-time pattern classification while each volunteer completed 60 trials of 22 s length each. In each trial the amount to be split was shown for 2 s. Subsequently, the offer was shown to the volunteer for 12s. The BOLD signal of the first 10 s after showing the offer was used to predict the upcoming decision. During the following response phase of 4 s length, participants pressed one of the two buttons to convey their decision. Finally, the payoff in the current trial was presented for 4 s and the next trial started immediately (see   for the trial design). The amount of money to share was 3 euros in every trial and five types of offers were presented at the following rates (percentage of 3 euros share for proposer: responder): 6×50∶50, 8×65∶35, 12×70∶30, 21×80∶20, 13×90∶10. These offers were presented in a random order. As usual in economic bargaining games, reimbursement for the volunteers was determined solely by their earnings in the ultimatum game. During the experiment no cumulative earnings were presented. After the experiment, every participant completed a questionnaire to assess whether he had any doubts about having played with a human partner at any time during the experiment. Also the questionnaire assessed the emotional states during the experiment and the perceived decision behavior concerning timing and fairness. 
   Single trial design in the ultimatum game with cumulative event times.  
 (a)   Each trial started by displaying the amount to be split (3 euros) for 2 s.   (b)   Subsequently, the offer was shown to the volunteer, who then had 12 s to make up his mind. This time was required for BOLD activity to build up and to subsequently use it to predict the upcoming decision. The classification result was indicated to the experimenter 1–2 s   before   the response screen   (c)   was shown to the participant. During the response phase (4 s), participants pressed one of the buttons to convey their decision. After the response, the payoff (split sum as proposed when the offer was accepted or no money for both players when offer was rejected) in the current trial was presented for 4 s   (d)  . The outcome of a rejected offer is shown. 
  
Stimuli were backprojected with an LCD beamer onto a transparent screen. Subjects had to press buttons with their left or right index finger to convey their decisions on the given offers. The mapping between buttons and responses (for either accepting or rejecting) was switched randomly for each trial and displayed at the beginning of each response phase. This prevented the classifiers from using brain activity related to preparation of motor responses  ,  . 


### Imaging protocol and real-time prediction 
  
The blood oxygen level dependent (BOLD) response was measured in a 3 Tesla whole-body MRI scanner equipped with Avanto gradient system (Siemens Medical Systems, Erlangen, Germany). The imaging protocol consisted of a gradient echo EPI sequence for BOLD imaging with repetition time (TR) of 2 s, time to echo (TE) of 29 ms, and a flip angle of 90°. Thirty-one slices with axial slice orientation covering the whole brain were acquired. The matrix size was 64×64 and spatial resolution was 3.4×3.4×4 mm . 

The vendor's EPI BOLD sequence (system version VA25A) and the corresponding image reconstruction programs were modified to export each EPI volume immediately after acquisition and internal motion correction to the host computer of the MR scanner (see   for a scheme of the hardware and the dataflow). All further preprocessing steps, statistical data analysis and classification were performed on an external computer (“External PC” in  , Pentium IV, 3.0 GHz, 2 GB Random Access Memory, Windows XP) which received the preprocessed EPI volumes via a 100 MBit/s network connection. 
   Schema of information flow in the experimental setup.  
The components highlighted in gray depict the vendor-specific measurement system (Siemens Trio with SYNGO Version VA25A). Initially, the original MR data are fourier-transformed and motion-corrected by the vendor image processing unit (Image PC). The reconstructed data are then transferred to the host computer (External PC). There the data are processed using custom software (rtExplorer). This software performs pre-processing, statistics, online classification, and documentation of the classification results. The participants' responses are processed in the stimulus PC and transferred to the external PC for evaluation of the classification and for retraining the classifier during the ongoing session. 
  
The locations of the regions of interest (ROIs) used in the online procedures were pre-specified on the basis of functional MRI data from preliminary experiments including two participants (120 trials) using the same experimental paradigm. The results of a whole-brain offline trained Support Vector Machine (SVM) classifier indicated signal changes predictive of the volunteers' decisions in anterior insula, lateral prefrontal cortex, and occipital cortex (see also  ). The informative brain areas revealed in the pilot study were in concordance with those reported in the literature on social interaction where in particular anterior insula and lateral prefrontal cortex were found to be involved in decision making in the ultimatum game  ,  . Therefore, we selected prefrontal cortex, anterior insula and visual cortex as ROIs for the online classification.   lists the MNI coordinates of the centre points and volumes of these ROIs (also shown in  ). 
   The regions of interest (ROIs) used for online classification projected onto anatomical data of one participant.  
Three distinct brain regions were used for classifying the volunteers' decisions: anterior insula (AI), lateral prefrontal cortex (LPFC) and occipital cortex (OC). See   for MNI coordinates and volumes of the ROIs. 
     Regions of interest used in the real-time classification.        
These preliminary data sets were also used to obtain an initial solution for the model parameters of the real-time classifier used in the online experiment. This allowed us to start prediction without first acquiring an exhaustive set of individual data. Importantly, using only a small set of ROIs reduced the feature space sufficiently allowing us to continuously adapt the classifier in real time by retraining with newly arriving individual data. 

In the online experiments, custom rtfMRI analysis software was used to process the incoming image data as soon as they were acquired  . During online processing, data sets were normalized to 3×3×3 mm  MNI space (Montreal Neurological Institute  ) and detrended to remove linear signal drifts. The BOLD signal of homologous left and right brain areas were pooled. Then the mean BOLD signal in the ROIs during the baseline period (1  and 2  scan immediately following the offer) were compared to the mean BOLD signal during the active period (3  to 5  scan) by calculating one t-value per ROI. Note that we only used data acquired during ten seconds immediately following the presentation of the offer to predict the subject's intended decision in single trials. Thus all data for prediction was acquired before the mapping for the manual decision was revealed. Specifically, we calculated t-values comparing the BOLD response in the first four seconds (scans 1&2) and seconds 6–10 (scans 3&4&5) which were fed into the real-time classification. Because the BOLD response requires approximately five seconds to develop  ,   we can use the data acquired in the first four seconds after the offer was presented as a baseline. The BOLD response to the offer can be expected to be fully developed 6–10 seconds after the offer and the difference between BOLD following the offer and baseline is the trial specific effect of the offer. 

The three t-values per trial served as input for the online classifier, a nonlinear Relevance Vector Machine Classifier   (Software available at   www.miketipping.com/index.php?page=rvm  ), was used to decide on each trial   i   whether an offer would be accepted or rejected. The training set   X   of the classification problem is defined as: 

We refer to   y   as decision vector. Its elements   y   take a value of 1 for an accepted offer and 0 for a rejected offer. 

During the experiment, the initial training set (  X  ) was continuously expanded by including the t-values and decision from the   n  -1th trial into the training data (  X  ) of the   n  th trial: 

The classifier was continuously retrained in each trial using the expanded training set. As such, the system adapted the model parameters based on subject-specific activation states in real time and included these in the forecast of volunteers' future decisions to improve classification accuracy. 

The RVM applied in online prediction makes use of Bayesian inference to obtain sparse solutions for classification. By computing a posterior distribution, it provides probabilistic classification and has the same functional form as the well-known Support Vector Machines:  

Here   w   depicts a weight vector and   is a kernel function that can be used to express a non-linear relationship between   x   and   y  . The goal is to compute the posterior probability of class membership   given the input   x   and target class   y  . This is solved by computing the weight posterior  , where α denotes a hyperparameter. More details are described in  . 


### Offline estimation of the guessing level of the real-time classifier 
  
To test the reliability of the online prediction, we determined individual empirical guessing levels to ensure that the online discrimination rates were not obtained by pure guessing but exploit information inherent to the data. The theoretical guessing level of a two-class experiment (e.g. accept or reject an offer) is 50% (perfect coin toss). However, other factors, such as the relative frequencies of the two classes in the training set, may influence the classifiers' strategy and bias the guessing level to much higher values than expected  . 

We estimated individual empirical guessing levels by permuting the decision vectors in each subject's data set. Permutation destroys the coherence between the observed BOLD data and volunteers' decisions but retains other information such as class size ratio. The classifier was then retrained, and all trials were classified according to the new training set. These steps were repeated 500 times to estimate the mean guessing level and the 95% confidence interval. Empirical guessing levels were calculated as the geometric mean of the guessing levels for the classes accept and reject  . Only if the correct prediction rate of the classifiers in the actual experiment exceeded the 95% confidence interval of the empirical guessing level estimates did we assume that the classifier learned from the inherent structure of the data  . 


### Offline whole brain classification 
  
Additional offline classification was performed to assess classification performance achievable using BOLD data from the whole brain and to further investigate the neural correlates of the decision process. Preprocessing included motion-correction, spatial smoothing with a 9 mm Gaussian kernel, and linear detrending. Furthermore, low-frequency signal fluctuations were removed using a high-pass filter with a cut-off frequency of 0.01 Hz, and BOLD volumes were normalized to 3×3×3 mm  MNI space. Non-brain voxels were excluded by applying a MNI brain template. Before combining the BOLD-data over subjects we first z-scored every subject's data individually. This normalization was done voxel-wise and as a result the BOLD-time series of each voxel had a mean of 0 and a standard deviation of 1. The volumes of the 2 , 3 , and 4  scan after the presentation of the offer were averaged for every subject. This resulted in 420 average functional brain volumes serving as single samples for whole brain classification. Our learning algorithm thus provides a cross-subject model based on single trial data. We then used this to classify the single trial data of the single subject excluded from the classifier training. 

The 2 , 3 , and 4  volumes after offer presentation were chosen because the participants reported in the post-scanning questionnaire that they made their internal decisions quickly (i.e. always in less than 5 seconds) after an offer was revealed and always before the accept/reject screen was shown. We thereby also avoided including information about the actual motor response, because in the interval included the participants did not know the mapping of the two buttons for accepting or rejecting the offer. 

We used feature selection, a very common approach in pattern classification, to reduce the number of features (voxels) in the input space. This was done on a training set by correlating signal changes with the volunteers' two different decisions. Voxels with correlation values between −0.15 to 0.15 were excluded. Since we wanted to analyze which voxels the trained classifier judged as informative we chose this relatively liberal value to somewhat reduce the number of voxels used for classification without being overly restrictive. Approximately 10  voxels were retained for subsequent classification using this criterion. 

For offline classification, we used a publicly available implementation of a SVM  . We used a linear classifier because it allows direct analysis of informative features learned during training  . Generalization performance was tested in a leave-one-average-volume-out cross-validation (LOOCV) which also included feature selection. In LOOCV, one trial is excluded from feature selection and training. The trained classifier is then used to predict the class label of the excluded trial. These steps are repeated for all trials, and the result (the percentage of correct classified decisions) represents a measure of the generalization power of the classifier. The correct prediction rate is finally calculated as: 


### Guessing level of the whole brain classification and discriminating volume 
  
Theoretical and empirical guessing levels were determined analogous to the approach in real-time prediction, in a permutation test with 500 repetitions. 

We extracted the spatial patterns used by the classifier to discriminate between different brain states from the weight vector   w   (Eq. 3). Therefore,   w   was transformed from feature space into the original voxel space and scaled to the length of one. The absolute weight value of each voxel reflects its importance for the discrimination of brain states. To obtain a probability distribution of the weight for each voxel, we permuted the class labels 1000 times. This provides a probability distribution under the null hypothesis of no relationship between class labels and the intrinsic structure of the data  . Based on these distributions, we computed the p-values for each voxel to determine which voxels were significantly predictive for the class label. The threshold for the reported discriminating volumes was set to p<0.05 (uncorrected). 



## Results 
  
### Behavioral analysis and real-time prediction 
  
The percentages of acceptance for the five types of offers are depicted in  . The acceptance/rejection ratios are in accordance with previous studies employing the repeated UG  – . A dramatic drop in the acceptance rate for offers around 20% or less of the amount to be split indicates that these offers were judged as unfair by our participants. 
   Overall percentage of acceptance rates of the offers in the ultimatum game.  
Values are calculated as rate of accepted offers over seven volunteers. Labels on the x-axis show the split rate: (proposer: responder). 
  
As depicted in  , the average online prediction accuracy reached 69.7%±2.4%. The average empirical guessing level derived from permutation tests was 52.3%±2.8% (average 2.5% and 97.5% quantiles were 47.2% and 55.3%, respectively). The real-time prediction accuracy was significantly above guessing level (p<0.0038, binomial distribution). The significant prediction results show that the classifier captured information about rejection or acceptance of an offer which was available in brain activity before the participant revealed his decision. With our approach, we were able to predict the participants' decisions 1–2 s before their response ( ). The online processing algorithm (pre-processing, real-time classification) was executed in less than 0.5 s (time required for retraining of the classifier was 0.4 s on average). 
   Real-time prediction accuracy of the RVM classifier in the ultimatum game.  
The arrows mark the empirical guessing levels. 
  
To assess the gain in correct predictions achieved by continuously retraining the classifier, we simulated the online procedure both with and without retraining. The overall prediction accuracy increased by 10.7% when novel data were used to retrain the classifier showing a clear benefit of retraining with individual data ( ). 
   Improvement of online prediction due to continuous retraining.  
The number of additional correct predictions using individual data acquired during the experiment in a sliding window of six trials are shown. Each window includes 42 single predictions (6 trials times 7 subjects). 
  
In addition to binary classification accuracy, RVM classification provides a continuous posterior probability estimate for each classified decision. The mean probability estimates for the five types of offers are depicted in  . Acceptance of an offer is indicated by a probability exceeding 0.5. 
   Mean posterior probabilities for accepting an offer assigned by the RVM to single offers in the UG.  
Means and standard deviations plotted were calculated over the seven volunteers tested in online analysis. The labels on the x-axis depict the split rate: (proposer: responder). 
  
The analysis of the activation of the signal variation immediately following an offer showed a clear difference between frontal and posterior ROIs. Higher BOLD signal in AI and LPFC predicted rejection, whereas a higher BOLD signal in OC predicted acceptance of an offer ( ). This finding suggests different functional roles during the evaluation of the offer for frontal and posterior sensory areas. 
   Mean fMRI signal differences in the ROIs used in the online UG to predict acceptance vs. rejection for the five types of offers.  
Differences were calculated between 1  to 2  and 3  to 5  scan after the offer and averaged over the seven participants. Bold signal in AI (slope linear fit 0.062, p<0.05) and LPFC (slope linear fit 0.11, p<0.05). In contrast, signal decreases in OC when the likelihood of acceptance decreases (slope linear fit −0.16, p<0.05). 
  

### Offline whole brain classification 
  
In an additional offline analysis, we pooled the single trial fMRI data from all but one subject (leave on subject out) to train classifiers and test generalization among subjects. This improved the correct classification rate greatly to an average of 81.2%. The average guessing level of the offline classification determined in permutation tests was 51.1%±2.3% SD (average 2.5% and 97.5% quantiles were 47.3% and 55.1%, respectively). Again, the correct classification rate clearly exceeds the 95% confidence interval for guessing. This results clearly shows that there is information about rejection or acceptance of a decision in the BOLD data that is similar among participants. Moreover, this analysis allowed us to derive brain areas informative about a participant's decision from a larger set of subjects and to validate the choice of the ROIs in the online experiment.   lists the discriminating volumes extracted from the trained linear SVM (see also  ). Importantly, the brain areas revealed by this analysis include the predefined ROIs used for real-time classification. Both, bilateral LPFC and OC were revealed as informative by the classifier. The only discrepancy was that bilateral AI was used in the online experiment but the offline classifier revealed only right AI as an informative ROI. In addition, offline classification found informative differences consistent over subjects in medial frontal gyrus (MFG), ventromedial prefrontal cortex (vmPFC), ventral striatum (VS), CRUS I in cerebellum, right orbitofrontal cortex (OFC), and posterior superior temporal sulcus (pSTS). 
   Volumes discriminative for decisions in the offline classification.        
The decision process we investigated so far includes at least two sub-processes: one related to the evaluation of the offer (e.g. low or high earning) and another related to the choice of the response (reject or accept an offer). We analyzed our data according to choices in the previous offline analysis. However, since choice and offer value are correlated over the full scale of offers it is possible that BOLD activity related to evaluation of offer value is more predictive about the subjects' UG responses than choice related BOLD activity, at least on the full scale of offers. To investigate this hypothesis each trial received two labels: one for the offer (low or high) and one for the choice (accepted or rejected) and we trained two classifiers with trials of the same dataset sorted in the two different ways (choice or value). The datasets used for classifier training have to be balanced with respect to each of the four possible label combinations (low/accept, high/accept, low/reject, and high/reject) to avoid unwanted classifier bias. In order to maximize the number of trials available in the four label combinations we distinguish high from low offers around the categorical decision border between 80∶20 and 70∶30 split rates where acceptance rate sharply drops. We labeled 50∶50, 65∶35, and 70∶30 trials as high offers and 80∶20 and 90∶10 trials as low offers. The combination reject/high offer contained the lowest number of samples (n = 19), restricting the number of trials used in the other three combinations in the training of the classifier. In order to avoid selection bias, we evaluated classifier performance on 200 balanced subsets of 76 samples each of which included the 19 rejected/high offers and 19 samples randomly drawn from each of the other three label combinations. The average LOOCV classification accuracy revealed that it was possible to discriminate high from low offers on the basis of the single trial BOLD activity (65.9% correct ±6.2% SD) with some success. On the contrary, discrimination according to choice (accept/reject) was around chance level (56.4% correct ±5.9% SD). This result indicates that brain processes related to the evaluation of offer value rather than the choice related activation allows the prediction of the subject's response on the wide range of offer values used in the offline prediction. 

Although no systematic brain activation difference related to choice (reject/accept) may exist over a wide range of offer values, this does not rule out, that a strong link between choice and brain activity exists that may manifest in a predictable and restricted regions along the offer scale where a large change in choices (accept/reject) is found. In the following analysis we aim to demonstrate such an isomorphism between brain activity and behavior for choice related activity. The reasoning behind this analysis follows previous work from us and other groups  ,   and is outlined below. We assume that brain activation related to choice should easily discriminate between two adjacent offers if these differ greatly in their acceptance rate and little if they differ little in their acceptance rate. Behaviorally, trials with split rates 50∶50, 65∶35, and 70∶30 trials were mostly accepted and trials with 80∶20 and 90∶10 trials were mostly rejected. Discrimination between trials with different offers within the same category (accepted or rejected) should be low because choice related brain activity should be very similar in trials from the same category. Importantly, choice related brain activity should reproduce the categorical border between acceptance and rejection of offers observed between 70∶30 and 80∶20 split ratios. Consequently, a classifier trained to discriminate between trials either of these two split ratios should produce particularly high discrimination rates because these offers cross the category border between acceptance and rejection. In addition, classifiers trained on adjacent pairs of offers from within a category should be less discriminable. 

We tested this prediction by training an SVM in an LOOCV to discriminate between adjacent offers. Therefore, we repeatedly (200 times) selected 42 examples from each split rate. The number of trials used per repetition was limited by the class with the lowest number of examples, in this case the number of trials in the 50∶50 split rate. In concordance with our hypothesis we found the highest discrimination rate between trials from 70∶30 and 80∶20 splits (71.4%±5.53% SD). The single trial discrimination rate was at guessing level for the comparisons among trials between split rates 80∶20 vs. 90∶10 (53.4%±5.3% SD), and 65∶35 vs. 70∶30 (54.6%±4.7% SD), and moderate for the discrimination between split rates 50∶50 vs. 65∶35 (65.9%±5.2% SD). It is important to note that this pattern of results cannot be explained by value differences between offers. The 70∶20 offer differs by 10% (or 0.3 Eurocent) from the 80∶20 offer, the same amount the 80∶20 differs from the 90∶10 and even less than the 65∶35 differs from the 70∶30, and the 50∶50 from the 60∶35 offer ( ). This result indicates that there exists informative brain activity that reflects choice rather than evaluation of the offer value. The discriminative brain areas found at the choice category border 70∶30 vs. 80∶20 are listed in   together with those areas discriminative for offers 50∶50 vs. 65∶35 (see also  ). 
   Discriminating volumes found in the offline classification of offers.        


## Discussion 
  
### Real-time analysis of decision processes 
  
In this study, we show that it is possible to predict the behavior of social agents acting as responders in the UG in real time using BOLD measurements of brain activity to detect complex emotional and cognitive states. Offline analyses confirmed the ROIs selected for online prediction on two pilot subjects and the rejection rates. More detailed analyses of the information about split rate and decision outcome available in the BOLD-data strongly supports the notion that brain activity related to expected subjective value of an offer rather than choice predict the subjects behavior over a large range of offer values. the mere decision process. Importantly, we find that information about choice in the BOLD activity predicts the behaviorally observed categorical change from offer acceptance to rejection. 


### BOLD modulation related to emotional and regulatory processes predicts imminent behavior in the UG 
  
We found that AI and LPFC are both predictive of the rejection of an offer on a trial-by-trial basis, in the online as well as in the offline analysis. Both brain areas are involved in emotion regulation and adjustment during social interaction  ,  –  as well as in the evaluation of negative emotions such as disgust  ,  . Increasing activation in AI and LPFC may reflect the experienced level of unfairness which in turn leads to the rejection of the offer in a given trial. In accordance with this interpretation, AI was found to be informative about split level when comparing 70∶30 splits to 80∶20 splits ( ) but not when comparing 50∶50 splits to 65∶35 splits. Moreover, this finding is in concordance with Sanfey et al.  , who also found that higher BOLD activation in AI indicated the rejection of an offer. A competing hypothesis is that activation in AI is not directly connected to the evaluation of negative emotional content but rather refers to attentional processes as reaction to salient environmental stimuli. As part of the ventral attention system the AI is thought to support the reorientation of the attention focus to external stimuli  . In this context it was suggested that activation of the ventral attention system may be connected to switching “internally directed” activities to behaviorally salient external stimuli, also in social cognition  . 

As opposed to AI and LPFC, activation in early visual cortex decreased with unfavorable split rates. It has been shown that attention strongly influences the responses of cortical neurons  ,  . Different levels of attention elicited by offers with different split rates, i.e. a fair offer may induce stronger attention because it reflects fair behavior and higher monetary outcome, may result in different activation in early visual cortex. However, one could also argue that the behavioral relevance is comparable for high and low offers in the UG and thus should lead to comparable attentional effects. The role of attention-related activation in encoding of decision behavior in the presented social context is not fully explored and may be subject to further investigation. 

In sum, the results from the online experiment suggest that activation in brain areas reflecting the subject's emotional and motivational state and self-regulatory processes can be used to discriminate accepted from rejected offers. 


### Reward-related brain areas predictive of altruistic punishment and financial incentive 
  
When playing against a computer that is creating offers in a random order, it makes no sense to reject an offer from an economic perspective. Thus, the participants' best strategy to optimize monetary gain would have been to accept any offer. However, responders in our study rejected unfair offers (20% of 3 euros and less) significantly more often than fair offers. This is the behavior expected in the repeated version of the UG ( ) with two humans playing, and corroborates the participants' reports that they thought they were playing with a human. In such a social setting of reciprocal cooperation, altruistic punishment, sacrificing potential monetary gain, can serve to optimize gains in the long run. 

Thus, in the ultimatum game the acceptance of an offer is correlated with the expectation of a financial incentive but, in addition, hedonic states following costly punishment of an unfair offer may also contribute to adjustment of behavior  ,  . We hypothesized that processing of the financial incentive and altruistic punishment is likely to involve different brain circuits although the same behavioral result, the acceptance or rejection of an offer, is observed  ,  . We probed this hypothesis by comparing the discrimination power of brain activity according to financial incentive vs. discrimination power tracking a categorical change from acceptance to rejection signifying altruistic punishment. We found that BOLD activation in VS signified the categorical border and discriminated between offers with a 70∶30 split rate vs. 80∶20 split rate but not between 50∶50 and 65∶35 offers (  and  ). The first pair differs with respect to the number of accepted offers, whereas the number of accepted offers is approximately equal and the difference in financial incentive is even higher in the second pair. This implies that, in our social setting, activation in VS, an important component of the reward network, is linked to hedonic states following punishment of unfair offers rather than financial incentive. OFC, another informative brain area of the reward circuit, provides similar information. Interestingly, OFC has previously been linked to the evaluation of threatening and/or punishing stimuli that may lead to the adjustment of behavior  ,  . In contrast, ventral medial prefrontal cortices discriminate accepted from rejected offers when all split rates are included ( ) but they do not discriminate 70∶30 from 80∶20 split rate trials ( ) where the categorical transition between accepted and rejected offers occurred. This suggests that, in contrast to VS and OFC, activation in ventral medial prefrontal cortices is related to the evaluation of monetary gain rather than hedonic states following punishment of unfair offers. This is in agreement with results from previous studies linking ventral medial prefrontal cortices to evaluation of primary as well as secondary rewards like monetary gain  . Thus, the result of the offline analysis adds further support to the conclusions that activation in brain areas reflecting the subject's emotional and motivational state and the self-regulatory processes thereof can be used to discriminate accepted from rejected offers in the social UG. 


### Cross subject ROI based probabilistic classification 
  
Unlike other offline “mind reading” approaches (compare e.g.  ,  ), we used a cross-subject approach in the online analysis. Nevertheless, the high prediction rate of 69.7% in the cross-subject procedure confirms the good generalization of the classifier between subjects. This indicates the identification of neural mechanisms that are common between our volunteers. The advantage of this approach is that it allows training of the RVM classifier prior to measurement, simplifying the setup by providing an initial solution of the classification problem without acquisition of additional training trials. Our approach made it possible to predict the subject's choice from the first experimental trial on, although this was with reduced accuracy. Importantly, continuous retraining during the course of the experiment increased classification performance by approximately 11% on average. 

Moreover, RVM provides posterior probabilities for single trial class membership, which can be useful in classification-based neurofeedback (compare  ,  ). Subject-specific offline classification resulted in 81.2% average accuracy and was, as expected, superior to cross-subject online prediction performance. This increase might be partly due to including subject-specific anatomical information but also to the high dimensional feature space we used in offline training. Thus, we would expect improvements in online classification using a more elaborate training scheme that combines non-subject-specific ROI-based classifiers with subject-specific whole-brain classifiers. During an experiment, the classification result would be calculated as a weighted average of the two classification approaches with weights adjusted by the quantity of information available for online classifier retraining. Fast implementations of procedures for preprocessing and training of whole-brain fMRI data are necessary for this approach. 


### Implications of single trial online prediction of social decision-making 
  
Whether a responder in the UG finally decides to reject or accept a specific offer depends on a multitude of internal factors. Among these factors are emotions such as the feeling of being treated fairly as well as rational considerations of reward maximization. The extraction of this information about the way a social agent is tending with a decision in real time   before   the decision was actually revealed can have extensive consequences for negotiations and other social interactions. However, the framework presented here for online decision prediction can also be used to study the link between neuronal and behavioral aspects of human decision-making In future studies, this framework could be used to investigate how decision-making processes are influenced by additional information about the emotional or cognitive state of a communication partner in an “augmented communication” scenario which feeds back information about current hidden brain states of the partner. Our approach could significantly extend previous work on effects of overt social cues in social interaction  ,  , or emotional facial expressions of social agents in bargaining games  . 


### Conclusion 
  
In sum, our results show that, in single trials, it is possible to reliably predict acceptance or rejection of an offer from BOLD measurements of brain activity before the subject reveals the decision with an overt response. However, more detailed analyses indicated that prediction of the decision was based on brain processes related to the perception and evaluation of the offer rather than processes related to the decision itself. Importantly, AI, VS, and LOFC, brain areas related to emotional self-regulation and reward processing for adjustment of behavior, appeared to be strong determinants of overt behavior in the ultimatum game. The decisions derived from the activation in these brain areas paralleled the behaviorally observed categorical transition from high likelihood of acceptance to high likelihood of rejection of an offer when the split rate fell below 70∶30. The framework presented here can be used in future studies to augment information available in social interaction with information about current brain states that remain hidden in traditional approaches. 



## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-35'>
<h2>35. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/19620621/' target='_blank'>19620621</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> The Selectivity and Functional Connectivity of the Anterior Temporal Lobes</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Cereb Cortex</p>
<p><strong>Publication Year:</strong> 2009</p>
<p><strong>DOI:</strong> 10.1093/cercor/bhp149</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/2837089/' target='_blank'>2837089</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study in healthy adult participants (N=12, ages 20–32) that explicitly examines person-related (social) conceptual processing vs. non-social categories (buildings, hammers). The task engages social cognition (learning facts about people) and the paper reports whole-brain voxelwise analyses with multiple-comparison correction (conjunction analyses and cluster-size correction across the brain), not only ROI results (although ROI analyses are also presented). Participants are healthy and within the 17–65 age range. No exclusion criteria are met. Therefore the study fits the meta-analysis objective of fMRI studies of social-related processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
One influential account asserts that the anterior temporal lobe (ATL) is a domain-general hub for semantic memory. Other evidence indicates it is part of a domain-specific social cognition system. Arbitrating these accounts using functional magnetic resonance imaging has previously been difficult because of magnetic susceptibility artifacts in the region. The present study used parameters optimized for imaging the ATL, and had subjects encode facts about unfamiliar people, buildings, and hammers. Using both conjunction and region of interest analyses, person-selective responses were observed in both the left and right ATL. Neither building-selective, hammer-selective nor domain-general responses were observed in the ATLs, although they were observed in other brain regions. These findings were supported by “resting-state” functional connectivity analyses using independent datasets from the same subjects. Person-selective ATL clusters were functionally connected with the brain's wider social cognition network. Rather than serving as a domain-general semantic hub, the ATLs work in unison with the social cognition system to support learning facts about others. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (53824 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
It is now generally accepted that the representation of knowledge in the human brain depends on broadly distributed neural circuits that are differentiated by conceptual categories and their associated perceptual, motor, and affective properties ( ;  ;  ). At least 2 important questions remain unresolved, however. The first is whether a property-based model of the conceptual system is sufficient to support all conceptual phenomena (see   for a discussion of these issues). The second pertains to the systemic architecture linking these property regions. 

Recently, semantic hub models have grown in influence by offering answers to both of these questions ( ;  ). With regard to the first, these models assert that property circuits are necessary, but not sufficient to support conceptual knowledge; that in addition to property regions one must posit the presence of an amodal, domain-general representational hub. With regard to the second question, these models assert that the anterior temporal lobe is the domain-general hub through which property regions are connected. 

The anterior temporal lobes are regarded as the likely location of the semantic hub, largely on the basis of evidence from semantic dementia patients. Semantic dementia, a variant of frontotemporal dementia, is a progressive degenerative disorder characterized by damage to the anterior temporal lobes in its earliest stages, followed by widespread deterioration in more posterior temporal and frontal cortices ( ). Semantic dementia patients typically exhibit impaired performance on a variety of semantic memory tests across multiple categories of knowledge, whereas other cognitive abilities remain relatively intact ( ;  ;  ). Recent studies have shown that deficits in semantic dementia are more highly correlated with pathology along the lateral surface of the anterior temporal lobes, as compared with more medial temporal cortex ( ;  ;  ). 

Upon closer review, however, the neuropsychological evidence for an anterior temporal hub is not so clear as it might first appear. First, the pathology in semantic dementia is not restricted to the anterior temporal lobes. The pathology often extends up into frontal cortex (Hodges and Patterson 2007; Brambati et al. 2009). In addition, voxel-based morphometry demonstrates that semantic memory impairments in semantic dementia patients are as strongly correlated with pathology in the posterior fusiform as to pathology in the anterior temporal lobe ( ). Second, resection of the temporal lobes to treat intractable epilepsy does not lead to the catastrophic, domain-general semantic memory deficits one might predict if this region is the seat of conceptual knowledge ( ). Proponents of an anterior temporal hub argue that this simply reflects the fact that the surgery removes abnormal tissue that no longer serves its normal function due to pathology-related reorganization. Although this is undoubtedly true ( ), it is not, however, as if the surgery or damage to this region is without cognitive consequences. Anterior temporal resection, or damage due to conditions such as herpes encephalitis, is often associated with significant episodic memory deficits, as well as notable domain-specific semantic impairments typically including recognizing and naming famous and familiar people ( ;  ;  ;  ;  ;  ,  ;  ; Tsukiura et al. 2003). These findings suggest that the anterior temporal lobes support person-specific knowledge, with the left hemisphere being relatively more important for person naming. 

Given its prominent role in semantic hub models, one would expect a veritable mountain of neuroimaging evidence that the anterior temporal lobes are involved in conceptual processing. Significantly, the majority of imaging studies, whether using positron emission tomography (PET) or functional magnetic resonance imaging (fMRI), have not observed anterior temporal lobe activation during conceptual processing. Instead most find posterior temporal or frontal cortex activations (see  ;  ). To the extent that anterior temporal activation is observed during conceptual processing, it is usually in the context of social conceptual processing tasks ( , forthcoming; for review see  ) along with the medial prefrontal cortex (PFC), the posterior superior temporal sulcus (pSTS), the amygdala, and the precuneus; regions that are widely regarded as the brain's social cognition network ( ). For example, the anterior temporal lobe is frequently activated by theory of mind tasks ( ), as well as to famous and familiar faces (Sergent and Signoret 1992;  ;  ;  ;  ;  ;  ;  ;  ). The findings of   are of particular interest to the present study as they used a verbal fact recall task and observed that activity in the left anterior temporal lobe reflects recall of associations between names and faces, whereas right anterior temporal activity reflects recall of faces and person-related semantic information. 

Aside from the processing of social concepts, functional neuroimaging evidence for anterior temporal lobe involvement in conceptual processing has been inconsistent. Although this would seem to be a major challenge to the model, proponents of anterior temporal hub accounts cite 2 reasons for this dearth of evidence. First is the claim that fMRI is blind to the anterior temporal lobes ( ,  ). Relative to other brain regions, image quality in the anterior temporal lobes is degraded due to distortions of the magnetic field caused by air–tissue interfaces. Hub proponents have often addressed this problem by using PET imaging, which does not suffer from the same signal deficits, but with spatial resolution that is 2 to 3 times lower than that of most fMRI studies. Indeed, some PET studies have provided support for anterior temporal hub accounts by demonstrating anterior temporal activations during conceptual processing ( ;  ,  ;  ;  ;  ;  ). Additionally, a parallel literature has developed showing activation of the ATLs during sentence-level processing using both reading and auditory–verbal stimuli ( ;  ,  ;  ;  ;  ;  ,  ;  ). These studies often report that the ATL is activated for syntactically correct versus incorrect sentences that control for semantic content, thus indicating a potential role for the ATLs in the representation of syntax. 

A second argument put forth for why imaging studies of conceptual processing often do not find anterior temporal activation is that they employ tasks that require subjects to process concepts at a level that is too general to engage the region, or because they compare categories at different levels of specificity. By this account, the aforementioned person-knowledge effects in the anterior temporal lobes do not reflect social information processing per se, but rather the comparison of specific classification (e.g., famous faces) with more general classification (e.g., nonfamous faces, animals, tools) ( ;  ). 

Hub accounts claim that the anterior temporal lobes are the seat of human conceptual knowledge, storing amodal conceptual representations, irrespective of category. On the other hand, a different account asserts that the anterior temporal lobes are domain-specific and involved in the representation of person knowledge. Based on the issues and controversies described so far, directly testing these 2 accounts requires: 1) an fMRI study with adequate signal quality in the anterior temporal lobes; 2) processing of multiple object categories, at least one of which is people; 3) each processed at the same level of specificity; 4) with the same type of information across categories; and 5) a nonconceptual control condition. 

To meet these requirements, we used fMRI scan parameters optimized for imaging the anterior temporal lobes to study subjects while they learned facts about 4 different unfamiliar and unique people, places, and hammers, or performed a nonconceptual control task, in this case a Riser Letter Detection task. In the scanner, subjects were presented only written sentences describing the age, location, and occupation/usage of the people, places, and hammers, ensuring that all categories were processed at the same level of specificity and with the same types of information (e.g., see  ). If the anterior temporal lobes serve as a hub for domain-general conceptual processing, then we should expect to find anterior temporal lobe regions that respond equally to all 3 categories over and above the nonconceptual Riser Letter Detection Task control condition. If on the other hand the anterior temporal lobes are part of a domain-specific social information processing network, then we should expect to find anterior temporal regions that exhibit reliably greater activation for person information as compared with either building or hammer information. Additionally, if the social information processing account of the anterior temporal lobes is correct, then we should also expect that any person-selective regions in the anterior temporal lobes will exhibit reliable functional connectivity with the previously well-described social-processing circuit distributed throughout the brain. To test this last prediction, subjects also underwent a low-level Vigilance Task scan before performing the Fact Encoding Task scans. During this scan, subjects simply pressed a button whenever they saw a fixation mark change color, which occurred approximately once a minute. With this independent data set we were able to evaluate the entrained “resting-state” functional connectivity of the anterior temporal lobes. 
  
Examples of stimuli 
    

## Materials and Methods 
  
### Participants 
  
Twelve right-handed, native English-speaking volunteers were paid for their participation (7 females; age range, 20–32 years). All subjects completed health questionnaires and none reported a history of head injury or other neurological problems. In accordance with the National Institutes of Health Institutional Review Board protocols, all subjects read and signed informed consent documents. 


### Experimental Design 
  
Subjects performed 3 tasks while undergoing fMRI. During the first functional scanning run, subjects performed a simple Vigilance Task. In the subsequent 3 scanning runs, participants performed alternating blocks of the Fact-Learning Task and the Riser Detection Task. 

#### Person-Building-Hammer Fact-Learning Task 
  
Subjects were instructed to remember facts described by short sentences presented in black font against a white background. Each sentence described a fact about 4 unique but novel persons, buildings, or hammers, each labeled with a different proper name (see   for example stimuli). For each unique exemplar, subjects learned an age, location, and usage/occupation fact (e.g., “the gilbert building is forty-five years old”; “the gilbert building is located in baton rouge”; “the gilbert building is used for community meetings”). Our decision to have subjects learn the same attributes about the 3 different categories’ exemplars was motivated by our desire to have subjects process the 3 categories at the same level of specificity and using similar types of information. We believe this is important because hub proponents have claimed that greater item specificity leads to greater anterior temporal lobe activation ( ;  ). In addition, the stimulus sentences were balanced across categories for average number of words and letters per sentence. 

During the task instruction period prior to entering the scanner, subjects were presented with photographs of each unique entity and given its name but no other information. At the conclusion of the instruction period, subjects were again shown the photographs and asked to recall each exemplar's name. Subjects who were unable to recall the correct name upon seeing its photograph were given extra time to study the photo and learn the corresponding name. 

In the scanner, subjects only saw sentences; no pictures were presented. In each 18-s Fact-Learning Task block, subjects read sentences describing the 3 facts for a particular exemplar, each presented for 6-seconds. The presentation orders of sentences describing the individual exemplars were varied within and between categories, and presentation orders of the age, location, and usage/occupation facts were randomized within each block. Subjects were shown the 3 facts about an exemplar once during each run and 3 times over the course of the experiment. 

After being removed from the scanner, subjects were asked to first recall the critical information for each fact learned while in the scanner. They were presented with the same sentences they read in the scanner, but with the critical fact replaced with a blank space (e.g., “the gilbert building is located in _________”). After completing the recall trials, subjects were given a forced-choice recognition test for all facts. 


#### Entrained “Resting-State”/Vigilance Task 
  
To evaluate functional connectivity, we chose to use a simple vigilance task because it provides images of the brain's functional connectivity in a more constrained context than the typical “resting-state” scan, whereas keeping the subjects’ information processing load to a minimum. In the vigilance task subjects fixated a cross in the center of a grey background and pressed a button anytime the fixation mark changed colors (mean interchange duration = 60 s, range 30–90 s). These data provided an independent data set for exploring the functional connectivity of brain regions activated in the subsequent Fact-Learning Task scanning runs. 


#### Riser Detection Task 
  
Riser Detection letter strings were constructed by scrambling the letters used in the Fact-Learning Task, and contained the same number of spaces as the text strings in the Fact-Learning Task. By doing so, we controlled for the amounts of visual stimulation and visual scanning between the 2 tasks. There were 13 Riser Detection blocks in each scanning run. In each 18-s Riser Detection Task block subjects saw 3 letter strings, presented individually for 6 s in black font against a white background. The subjects’ task was to count the number of “riser letters” in nonword letter strings and press a button on a response box held in the right hand if the total was an odd number. Subjects were instructed that the letters b, d, f, h, k, l, and t are riser letters because they each have some portion that rises up above the tops of most other lower-case letters. This task is a modified version of the “feature detection task” used by  . 



### Imaging Details 
  
Stimuli were back-projected onto a screen at the head of the scanner and viewed by subjects via a mirror mounted on the head coil. Stimulus presentation and response collection both during scanning and the recall and recognition tests were controlled using Eprime (  www.pstnet.com  ). 

During the Vigilance Task scanning run, 140 echoplanar MR volumes depicting blood oxygenation level dependant (BOLD) contrast were collected with a 3T General Electric scanner. In each echoplanar image (EPI) volume 42 contiguous 3-mm thick slices were collected in the axial plane, ensuring whole-brain coverage (echo time [TE] = 27 ms, repetition time [TR] = 3500 ms, flip angle = 90°, voxel size = 2.3 mm × 2.3 mm × 3 mm). The 3 Fact-Learning Task runs used the same volume parameters, although 143 volumes were collected per run. High-resolution structural images were collected as the first and last scans in each session (TE = 6 ms, TR = 25 ms, flip angle = 15°, voxel size = 0.9 mm × 0.9 mm × 1.2 mm). A General Electric 8-channel send-receive head coil was used for all functional and structural scanning runs, with a SENSE factor of 2 used to minimize EPI distortions in anterior temporal regions while also reducing gradient coil heating over the course of the scan session. As demonstrated by measurements of temporal signal-to-noise (the ratio of the average signal intensity to the signal standard deviation), signal quality in the anterior temporal lobes was very good (see  ). 
  
Temporal signal-to-noise ratio (TSNR) maps showing EPI image quality over the anterior temporal lobes. The color gradient indicates the TSNR of the smoothed EPI time course data overlaid on the AFNI Talairach N27 atlas brain. TSNR was calculated by dividing the mean signal intensity at a voxel by the standard deviation of its signal time course. The color map is thresholded at a TSNR of 40, with all areas in red indicating a TSNR of at least 200. Simulations indicate that a TSNR of 40 (indicated in the map by light blue) is the minimum to reliably detect effects between conditions in fMRI data (Murphy et al. 2007). Note that virtually all of the anterior temporal lobes far exceed this threshold, with many anterior temporal regions exceeding a TSNR of 200. 
  
Prior to statistical analyses, image preprocessing was conducted using the AFNI software package ( ). The first MP–RAGE anatomical scan was coregistered to the second MP–RAGE, and the 2 were then averaged to produce a single high-quality anatomical image of the subject's brain. Next, each subject's EPI volumes were coregistered to the 130th volume of the final EPI scanning run, and smoothed in the axial plane with an isotropic 6-mm full width half max Gaussian kernel. Following application of slice time correction, and removal of the first 3 volumes from each run, EPI signal intensity measurements at each time point were normalized to reflect the percent signal change from the voxel's signal time course mean. 


### fMRI Statistical Analyses 
  
Multiple regression was used to analyze the Fact-Learning Task data. The regression model included one regressor for each of the 3 fact categories (people, buildings, and hammers) with the Riser Detection Task periods composing the signal baseline. The 3 task regressors were constructed by convolving a box-car function with a width of 18-s beginning at the onset of a condition's blocks with a gamma-variate function to adjust the predictor variable for the delay and shape of the BOLD response. In addition, regressors of no interest were included to account for each run's signal mean, linear, quadratic, and cubic signal trends, as well as 6 motion parameters (3 translations and 3 rotations). 

Subjects’ beta maps for each condition were then transformed to Talairach space, and resampled to a 2-mm isotropic resolution. Finally, a repeated measures random effects ANOVA was used on the aggregated group data to evaluate differences between conditions at the population-level. 

We used the conjunction analysis methods described by   to identify regions where the activity patterns across conditions conformed to domain-specific and domain-general response patterns. A domain-specific response was defined as a cluster of activity where a particular condition exhibited reliably greater activity than each of the other Fact-Learning Task conditions. For example, to qualify as a person-selective region, each voxel in a cluster of activity had to satisfy 2 separate statistical tests: person > building AND person > hammer. Because this conjunction assumes a particular directionality, each of the individual tests were thresholded at   P   < 0.05 one-tailed within the 3 regions of interest (ROIs) described below, and at   P   < 0.005 one-tailed outside the ROIs. As described by  , the conservative estimate of the probability of a conjunction is the   P  -value associated with the minimum statistic among the conjoined tests, which in this case is   P   < 0.05 one-tailed in the ROIs and   P   < 0.005 one-tailed outside the ROIs. To implement corrections for multiple comparisons at the   P   < 0.05 level, we used Monte Carlo simulations implemented in AFNI's AlphaSim to identify the required cluster-size threshold, given the voxel-wise probability and the volume in the statistical map (see below) separately for each of the tests in a conjunction. Because the clusters of activity for each test in a conjunction were corrected for multiple comparisons, and should thus be regarded as reliable, so too can the intersections between the clusters. Nevertheless, because it is possible that small areas of intersection between clusters from different statistical tests could be induced by spatial smoothing and resampling, we applied a small cluster-size threshold of at least 10 voxels (defined in the original scanning resolution) on all areas of conjunction. 

In contrast to the domain-specific clusters, domain-general clusters were defined as regions where responses for all 3 categories were reliably greater than the Riser Detection Task, but where activity did not differ between categories in the Fact-Learning Task. To this end, we used conjunction analyses similar to those used to identify domain-specific clusters. First we identified regions where each of the categories in the Fact-Learning Task responded reliably above the Riser Detection Task with a   P  -value of 0.05 one-tailed in the ROIs and   P  -value of 0.005 one-tailed outside the ROIs, again with each test corrected separately for multiple comparisons at the   P   < 0.05 level using cluster-size correction (see below). Importantly, the conjunction probability for domain-general clusters was equal to the conjunction probability of the domain-specific clusters. Finally, to remove regions showing a bias toward a particular category, a mask was applied to the data to remove all regions exhibiting a difference with   P   < 0.25 between any 2 categories in the Fact-Learning Task. Again, as with the domain-specific regions, a cluster-size threshold of at least 10 voxels was applied to all areas of conjunction to ameliorate concerns that smoothing or resampling induced the observed domain-general clusters. 

There were 3 region of interest volumes used in the cluster-size threshold calculations: the anterior temporal lobes, the posterior middle temporal gyrus, and the parahippocampal gyrus. The anterior temporal lobes were defined as all areas in the temporal lobes anterior to the limen insula ( ; located at approximately   y   = 3 in the left hemisphere and   y   = 5 in the right hemisphere of the AFNI Talairach N27 atlas brain). This ROI included only temporal cortex, and did not include any portion of the amygdala. Within the volume of this region, defined bilaterally, a cluster-size threshold for individual tests among the conditions was determined to be at least 1056 mm  (132 resampled voxels sharing at least one edge). The posterior middle temporal gyrus between   y   = −40 and   y   = −69 was selected as a ROI given its association with tool processing (for review see  ). Within this region, the cluster-size threshold was determined to be at least 1216 mm  (152 voxels sharing at least one edge). The parahippocampal gyrus was also selected as a ROI given its association with location representation ( ;  ). Within this region, the cluster-size threshold was determined to be at least 992 mm  (124 voxels sharing at least one edge). Finally, outside these 3 ROIs, clusters of activity had to exceed a size threshold defined by the volume of the brain minus the volumes of the 3 ROIs, rendering a cluster-size threshold of at least 848 mm  (106 voxels sharing at least one edge). (The cluster size threshold for the regions outside the ROIs is smaller than the cluster size threshold within the ROIs because the   P  -value threshold outside the 3 ROIs is more stringent by an order of magnitude;   P   < 0.05 vs.   P   < 0.005.) 

Functional connectivity analyses were implemented on the subjects’ Vigilance Task scanning run, with seed voxels determined by the highest average   t  -values across the statistical contrasts used in the group conjunction analyses. The connectivity analyses proceeded in the following manner. First, at the subject-level, multiple regression was used to model the run's signal mean, linear, quadratic, and cubic signal trends, as well as 6 motion parameter regressors. In addition, the average signal time course from the subject's ventricles was included to further account for global signal changes. The residual time course for each voxel was then used in the subsequent analyses. Time course residuals for the anterior temporal lobe seed voxels were then used as predictors in separate regression analyses, to produce a map of the correlations between each voxel in the brain and a given seed voxel. These   r  -values were then converted to   Z  -values using Fisher's   r  -to-  Z   transformation. Next, the subjects’   Z  -maps were included in a random effects, one-sample t-test to identify voxels whose means differed from zero with   P   < 0.0005. Finally, these statistical maps were corrected for multiple comparisons at the   P   < 0.05 level by applying a cluster-size threshold of at least 296 mm  (37 voxels sharing at least one edge). The resulting maps show brain regions where activity across subjects was reliably correlated with a seed-voxel's time course while subjects performed the Vigilance Task scanning run, a dataset that was independent of the Fact Encoding Task scanning runs. 



## Results 
  
### Behavioral Results 
  
Responses to color change events in the Vigilance Task were quick and accurate (RT: M = 614 ms, SD = 159 ms; detection accuracy: M = 70%, SD = 22%). In contrast, subjects found it difficult to provide responses on the Riser Detection Task within the allotted time for each trial (RT: M = 4768 ms, SD = 130 ms; detection accuracy: M = 26%, SD = 13%, responses occurring earlier than 2 standard deviations from the response mean were filtered out, as were responses occurring later than the 6-second trial duration). The riser detection accuracy scores reflect the fact that subjects had to perform the task under significant time constraints, rather than indicating that they were performing the task poorly. The letter strings presented to subjects were rather long because they were constructed by scrambling the fact-learning sentences, and as a result it was difficult for subjects to provide responses before the stimuli disappeared from the screen. 

After scanning, subjects demonstrated good recall of the information presented during the Fact-Learning Task (Person fact recall: M = 72%, SD = 17%; Building: M = 63%, SD = 17%; Hammer: M = 65%, SD = 21%). Although subjects recalled more person facts than building facts,   t  (11) = 4.31,   P   < 0.005, person and hammer fact recall were equivalent,   t  (11) = 1.13,   P   = 0.28, as was recall of building and hammer facts,   t  (11) = 0.38,   P   = 0.71. As with recall, recognition performance was good for all categories (Person fact recognition: M = 87%, SD = 17%; Building: M = 77%, SD = 17%; Hammer: M = 74%, SD = 24%). Although subjects recognized more person facts than hammer facts,   t  (11) = 2.55,   P   < 0.05, person and building fact recognition were not reliably different, t(11) = 1.88,   P   = 0.09, nor were recognition of building and hammer facts,   t  (11) = 0.49,   P   = 0.63. 


### The Anterior Temporal Lobes are Engaged while Acquiring Person Knowledge 
  
Two lateral anterior temporal regions exhibited person-selective responses (  A  ,  ). The 2 clusters, located bilaterally in homologous locations in the temporal pole and superior temporal gyri, responded more during person-fact encoding than during building-fact or hammer-fact encoding. Aside from these 2 regions, there were no other category-selective responses in the anterior temporal lobes. To demonstrate the robustness of the person-selective effects to a different voxel selection strategy ( ), and to assess whether statistical mapping was even necessary to observe person-selective responses in this region, we used an anatomical region of interest approach to examine the average response across all voxels in the anterior temporal lobe ROIs for each of the 3 conditions. As can be seen in   B  , person-fact encoding produced greater activation than either building- or hammer-fact encoding across the entirety of the left and right anterior temporal lobes, but no differences were observed between buildings and hammers (left anterior temporal: person > building,   t  (11) = 1.95, one-tailed   P   = 0.04; person > hammer,   t  (11) = 2.27, one-tailed   P   = 0.02; building versus hammer,   t  (11) = 0.65, 2-tailed   P   = 0.53; right anterior temporal: person > building,   t  (11) = 2.10, one-tailed   P   = 0.03; person > hammer,   t  (11) = 2.75, one-tailed   P   = 0.01; building versus hammer,   t  (11) = 1.14, 2-tailed   P   = 0.29). 
  
Anterior temporal lobe activations 
      
Person-selective responses in the anterior temporal lobes. (  A  ) person-selective clusters in the anterior temporal lobes identified using conjunction analyses. The rendered surfaces show the person-selective clusters in the left and right hemispheres where person > building AND person > hammer with   P   < 0.05 and cluster-size corrected for the volume of the anterior temporal lobes. (  B  ) Activity in the anterior temporal lobe ROIs. The rendered surfaces show the extent of the anterior temporal ROIs in the left and right hemispheres. The bar graphs demonstrate the average percent signal change across subjects in the left and right anterior temporal ROIs relative to the nonconceptual (riser detection) control task. In both ROIs, the responses to person-fact encoding were reliably greater than the responses to building- or hammer-fact encoding. Responses during building- and hammer-fact encoding were not different from each other. Error bars on bar charts in both panels indicate ±1 standard error of the subject means. 
  
No domain-general responses were observed anywhere in the anterior temporal lobes. In other words, there were no regions in the anterior temporal lobes where activity was equivalent for person, building, and hammer fact learning and where these 3 conditions produced reliably greater activation than the Riser Detection Task, our nonsemantic control condition. 


### Fact Encoding Effects Outside the Anterior Temporal Lobes 
  
Although the current experiment's focus is the function of the anterior temporal lobes, domain-specific and domain-general responses were observed in other brain regions ( ). 
  
Domain-specific and domain-general responses outside the anterior temporal lobes indentified using conjunction analyses. Domain-general responses (shown in gold) were observed in various regions outside the anterior temporal lobes, including the left inferior and superior frontal gyri, the left middle temporal gyrus, and the hippocampus. A hammer-selective cluster (shown in blue) was observed in the left middle temporal gyrus (L pMTG) immediately posterior to a domain-general cluster. More medially, building-selective clusters (shown in green) were observed in left and right middle occipital gyri. Person-selective clusters (shown in red) were observed along the midline in the medial PFC and the precuneus, among other regions. All clusters are corrected for multiple comparisons. 
  
#### Domain-Specific Encoding Effects 
  
Outside the anterior temporal lobes, person-selective encoding effects were observed in regions commonly implicated in social processing, including the medial PFC, precuneus and posterior cingulate, and the right pSTS. In addition, the superior parietal lobule was also activated bilaterally, as was the left insula (see  ). Contrary to our prediction, place-selective effects were not observed in the parahippocampal gyrus. Instead, large areas of place-selective activity were observed bilaterally in the lingual, cuneus, and middle occipital gyri, as well as the right cerebellum. Finally, as predicted, hammer-selective activity was observed in the left posterior middle temporal gyrus. 
  
Domain-specific and domain-general activations outside the anterior temporal lobes 
    

#### Domain-General Encoding Effects 
  
Although domain-general encoding effects were not observed in the anterior temporal lobes, other brain regions did exhibit these effects (see  ). For example, a large area of domain-general activation was observed to stretch from the left inferior frontal gyrus into the middle frontal gyrus. Additionally, domain-general activation was observed in the left hippocampus, the left middle temporal gyrus, left angular gyrus, and the right cerebellum. 



### Functional Connectivity: Anterior Temporal Person-Selective Regions are Part of the Wider Social Cognitive Network 
  
Further support for the person-selective nature of the anterior temporal lobes comes from functional connectivity analyses using independent data sets. We used the Vigilance Task scanning runs to examine the functional connectivity with the peak activations in the left and right anterior temporal person-selective clusters identified in the Fact-Learning Task. The left anterior temporal person-selective cluster was functionally connected with brain regions frequently implicated in social cognition, including the medial PFC, the pSTS, the amygdala, and the precuneus/posterior cingulate bilaterally, and in the left lateral portion of the fusiform gyrus ( ). In addition to the other social-processing regions, activity in the left anterior temporal person-selective cluster was tightly coupled with activity in the corresponding region in the right anterior temporal lobe. Finally, activity in the left anterior temporal person-selective region was correlated with activity in regions known to support more general information processing, including the left inferior frontal gyrus and the left hippocampus (see   Supplemental Table 1   for a complete list of regions functionally connected with the left anterior temporal seed voxel). As with the left hemisphere, activity in the right anterior temporal person-selective cluster was correlated with activity in regions previously implicated in social processing, including the medial PFC bilaterally, the amygdala bilaterally, the left posterior cingulate/precuneus, the left fusiform gyrus, and the left anterior temporal lobe ( ). In addition, this region was functionally connected with a host of more general information processing areas, including the left inferior frontal gyrus, the left perirhinal cortex, and the superior frontal gyrus bilaterally (see   Supplemental Table 2   for complete list). 
  
The person-selective clusters in the anterior temporal lobes are functionally connected with the wider social cognition network. Color overlays indicate clusters of functional connectivity with the anterior temporal seed voxels measured in the independent Vigilance Task scanning run. The left and right anterior temporal seed voxels were identified as those voxels in each hemisphere with the highest average   t  -value for the person > building and person > hammer   t  -maps in the Fact-Learning Task scanning runs. The depicted functional connectivity   t  -maps were obtained as follows. First, for each subject a Pearson correlation map was constructed showing correlation between each voxel and an anterior temporal seed voxel. Second, these   r  -maps were converted to   Z   score maps. Finally, these   Z  -maps were included in a random effects, one-sample   t  -test to identify voxels whose means differed from zero with   P   < 0.0005 and cluster-size corrected for multiple comparisons across the whole brain at   P   < 0.05. 
  


## Discussion 
  
### Person-Selectivity in the Anterior Temporal Lobes 
  
In the present study the anterior temporal lobes exhibited strong category-selectivity while subjects learned facts about people, relative to building- and hammer facts. The person-selective responses in the conjunction analyses were observed in nearly identical anterolateral regions of the superior temporal gyri and temporal poles in the 2 hemispheres. Domain-general effects were not observed in the anterior temporal lobes, although they were found in other brain regions, including the hippocampus and left inferior frontal gyrus. The absence of domain-general anterior temporal effects in our data cannot be due to poor signal quality because we observed statistically reliable clusters of activity in the lateral anterior temporal cortex, the anterior temporal region with the highest temporal signal-to-noise ratios in the present data ( ), and the area predicted to be the domain-general semantic hub based on pathology in semantic dementia ( ;  ;  ). 

Eschewing cluster mapping altogether, we evaluated separately for each hemisphere the average response of the entire temporal lobes anterior to the limen insula. Even when using this gross anatomical-ROI approach, the anterior temporal lobes responded selectively when encoding information about people. In both hemispheres, the response profile was highly person-specific, with little difference in the responses to buildings and hammers. 

The conjunction analysis was an extremely conservative measure requiring significantly greater activity for the person-fact learning than building-fact learning and greater activity for the person-fact learning than hammer-fact learning. Additionally, each of these tests independently had to reach significance after correction for multiple comparisons. The fact that we replicated the person-fact selectivity in the ROI analysis, which aggregated activity across the entire anterior temporal lobe, demonstrates the robustness of this effect. Including all the voxels in the anterior temporal lobe did not wash out the statistically reliable categorical effects observed in the conjunction analysis. 

The findings of the cluster-mapping and anatomical-ROI analyses were further strengthened by the functional connectivity profiles of the anterior temporal lobes, with the present study being the first to describe the functional connectivity of this region. The anterior temporal person-selective clusters, identified in the Fact-Learning Task scans, were found to be functionally connected with virtually the entire social cognition network, as measured during the independent Vigilance-Task scan. The functional connectivity findings reported here agree with tracer studies in the macaque, where strong anatomical connectivity is observed between the temporal pole and the amygdala, superior temporal gyrus, area TE (potential monkey homologue of human fusiform gyrus), and the medial frontal cortex ( ;  ). 

Given the results of the conjunction analyses, the anterior temporal ROI analyses, and the functional connectivity analyses on independent data, we can be confident that the person-selectivity observed in the anterior temporal lobes was not a product of the particular statistical-mapping procedure, or the particular task, or the particular stimuli presented to subjects, or even the particular seed voxel within the anterior temporal lobe. Rather the results appear to reflect this region's underlying function and connectivity within a network supporting social cognition. 


### Social Conceptual Processing in the Anterior Temporal Lobes 
  
Recently,   reported activation of the anterior superior temporal gyrus when subjects made meaning-relatedness judgments for social concepts. In the present study, the person-specific effects in the anterior temporal lobe stretched from the middle temporal gyrus up into the superior temporal gyrus. Given the differences in the paradigms and stimuli, it is remarkable how much agreement exists between our findings, and those reported by  . 

Zahn and colleagues observed a reliable difference between social and animal concepts in the superior temporal gyrus, with much weaker effects of each condition versus fixation in the middle temporal gyrus. They speculate that there may exist an inferior–superior gradient for multisensory versus abstract person-specific knowledge, with the former located in middle temporal gyrus, and the latter located in the superior temporal gyrus. Although this is one explanation for these findings, it is not the only explanation. Alternatively, it could be that the anterior temporal lobes are relatively more responsive to animate than inanimate entities, with the superior temporal gyrus being particularly responsive for human-animate attributes (such as the social abstract concepts used by Zahn et al.). By this account, we observed more inferior middle temporal activity, in addition to the superior temporal activity, because we compared animate to inanimate entities (e.g., people vs. buildings and hammers). This account also finds support in the both our ROI analyses using the entirety of the anterior temporal lobes, and in the functional connectivity findings, which showed correlated spontaneous fluctuations between our anterior temporal lobe person-selective regions and the wider social/animacy network. 

Yet another possibility is that in Zahn and colleagues’ data the signal quality might be poorer in middle temporal gyrus than in superior temporal gyrus. Zahn and colleagues only observed middle temporal activity in statistical comparisons that presumably have much higher contrast-to-noise ratios, namely the social and animal concepts versus a simple fixation baseline. Note, however, that this contrast does not control for many nonconceptual differences between the task performed by subjects (e.g., reading words and making meaning-relatedness judgments) and the fixation baseline condition. By this account, we may have observed more inferior effects, in addition to the superior temporal effects, because of better signal quality over this region (e.g., see   and refer to Imaging Details section). 

Although we are not certain which of the above-described explanations account for the differences between our findings and those reported by Zahn and colleagues, we strongly believe that the overall findings of the 2 studies exhibit significant agreement and are mutually supportive. 


### Person-Selectivity in the Anterior Temporal Lobes Does Not Simply Reflect Encoding Effort 
  
Given that subjects generally remembered more person facts than building or hammer facts, one might argue that the person selectivity in the anterior temporal lobes simply reflects encoding effort. There are at least 5 arguments against this account. First, not all brain regions responded selectively for person-fact encoding. Indeed, as just described, many regions responded selectively to other categories. This suggests that there was not a general encoding effort effect for the person facts. Second, regions such as the left inferior frontal gyrus and the hippocampus that would be expected to show a task difficulty or encoding effort effect do not exhibit selectivity for person-fact encoding, but rather responded in a domain-general fashion (e.g., responded equally to all categories). Third, given that we have much more experience learning new information about people, relative to buildings and hammers, it seems unlikely that one would find more activation for learning person facts relative to the other categories if the activity in this region is driven by encoding effort. Fourth, better person fact recall (vs. building fact recall) or recognition (vs. hammer fact recognition) does not guarantee differences between conditions at encoding. The recall and recognition differences could be entirely mediated by storage or retrieval processes. Finally, and perhaps most convincingly, using independent, non-task-related data we observed functional connectivity between the person-selective clusters in the anterior temporal lobes and the wider social cognition network, a finding that strongly supports our interpretation that the activation observed in this area reflects its role in social cognition, not encoding effort. 


### Domain-Specificity Outside the Anterior Temporal Lobes 
  
Outside the anterior temporal lobes, we observed other domain-specific effects. Encoding hammer facts selectively engaged a posterior region of the left middle temporal gyrus. This finding was predicted a priori, given that the region is consistently activated during conceptual processing of tool categories and tool-related verbs using both pictorial and linguistic stimuli (e.g.,  ;  ; for recent reviews see  ;  ;  ). Large place-selective responses occurred bilaterally in the cuneus and up into middle occipital gyrus. This region, near the transverse occipital sulcus, has been previously implicated in scene perception, navigation, and the representation of large-scale features (such as buildings) in the visual environment ( ;  ;  ). Finally, in addition to the anterior temporal lobes, learning facts about people elicited category-selective responses in other social cognition regions. Person-selective responses were observed in the medial PFC, a region that supports mentalizing about others’ mental states ( ;  ); the right pSTS, a region commonly implicated in the perception and conceptualization of biological motion ( ,  ); and the precuneus, a region implicated in social perspective-taking and representation of the self ( ). 


### Domain-General Responses 
  
We found no evidence for a domain-general hub in the anterior temporal lobes. This does not mean however that hub theories in general are incorrect. Rather, it only means that if a domain-general representational hub exists in the brain, it is not in the anterior temporal lobes. In fact, we did find domain-general areas. One region was a large area in left frontal cortex stretching from the inferior frontal gyrus up to the middle frontal gyrus. Based on findings from earlier research, this region serves as a control-center for conceptual processing, guiding retrieval and postretrieval selection of property information stored in posterior cortex, irrespective of category ( ;  ;  ). Similarly, domain-general responses were observed in the hippocampus, a region long known to support the acquisition of new knowledge ( ). It is unlikely that either of these regions serve as representational hubs in the sense previously attributed to the anterior temporal lobes. For example, although damage to the left inferior frontal gyrus results in word-finding deficits, it does not disrupt conceptual knowledge per se ( ;  ;  ). Similarly, although damage to the hippocampus greatly affects new learning, it does not result in conceptual deficits for previously acquired knowledge ( ). 

We also observed domain-general responses in the left middle temporal gyrus (immediately anterior to the domain-specific “hammer” cluster), the left angular gyrus, and the right cerebellum, all regions shown previously to be engaged when subjects learn new facts and associations ( ;  ). Of these regions, the left middle temporal gyrus may be of particular interest in future studies, as it is often implicated in domain-general conceptual processing ( ;  ). 


### Conceptual Processing during the Fact-Learning Task 
  
Semantic memory/conceptual processing involves retrieving information about objects and words that is not immediately available in a stimulus itself. This is perhaps most easily recognized in the case of conceptual processing for words, where the word itself is merely an arbitrary symbol, and so understanding its meaning necessarily requires attributions and inferences about the word's referent. A bedrock principle in cognitive psychology is that reading words automatically activates word meaning (e.g., consider the ubiquity of Stroop effects). Thus, reading the sentence stimuli in our task engaged our subjects’ conceptual systems. Given this, we simply needed to ensure that they actually read the sentence stimuli. To accomplish this we told subjects to remember the information they learned because their memory would be tested at the end of the study. 

Our task allowed us to directly compare 3 familiar categories for which subjects had a great deal of previously acquired conceptual knowledge, while being reasonably certain that subjects processed the categories at the same level of specificity and with the same amount of knowledge about the specific exemplars presented in the scanner. Although the specific exemplars were unfamiliar, subjects’ comprehension of the sentence stimuli meant that the task engaged retrieval of pre-existing category-knowledge. Good evidence for this comes from the neuroanatomical distribution of the activations we observed. Consider the person-fact learning condition. Learning facts about specific peoples’ occupations, ages, and places of birth activated regions previously demonstrated to represent biological motion (posterior STS;  ,  ), mentalizing about other's mental states (medial PFC;  ;  ), and social perspective-taking and representation of the self (precuneus;  ). The facts learned by subjects about a particular person did not contain references to that person's physical motions, their mental states, or social interactions, and thus these activations are neural signatures of conceptual inferences about the exemplars. Similarly, the hammer facts never described the hammers in motion, yet we can deduce that subjects were engaged in conceptual inference about the hammer exemplars because we observed activation in a region of the middle temporal gyrus known to represent nonbiological (tool) motion ( ). These activations further strengthen our confidence that the fact-learning task was successful at engendering conceptual processing, and warrants our claims about the anterior temporal lobe's role in conceptual processing. 

Because all 3 conditions required fact learning, comparisons among the categories should cancel-out domain-general conceptual processes, leaving only domain-specific conceptual processes. Now, in light of this, consider the claims of the domain-general semantic hub account, which asserts that the anterior temporal lobes are the domain-general hub of the human conceptual system irrespective of the task context through which conceptual information is accessed. In fact, hub models explicitly claim that the anterior temporal semantic hub is engaged in any and all varieties of conceptual processing tasks (e.g., see  ). If this is correct, then we should have observed greater anterior temporal lobe activation for all categories compared to the nonsemantic control task, and equivalent activations for all categories in our task. We did not. This leaves us with only 2 options. The first option is that the anterior temporal lobes are domain-specific for person knowledge during sentence comprehension, but the same tissue is domain-general in other task contexts (perhaps after consolidation from the hippocampus to the neocortex), and also exhibiting strong functional connectivity with the wider social cognition network. The second option is that the anterior temporal lobes are domain-specific for person knowledge regardless of the conceptual processing context, and also strongly functionally connected to the wider social cognition circuit. Option one assumes a remarkable switch in domain selectivity from one task context to another, and we can think of no evidence for such a switch either in the anterior temporal lobe or indeed anywhere else in the brain. Option 2 is also a more parsimonious account. 



## Conclusion 
  
Rather than serving as a domain-general conceptual hub, the anterior temporal lobes appear to support person knowledge. Using both typical statistical-mapping approaches, as well as gross anatomical-ROI analyses, we observed person-selectivity in both the left and right anterior temporal lobes. Further, in independent data sets these regions were functionally connected with the social cognition network. Future studies should seek to better understand the information content within the anterior temporal lobes. In this regard, it is important to note that there exists both neuropsychological and neuroimaging evidence that this regions plays a critical role in the representation of unique entities ( ;  ;  ;  ). The present study compared responses among different categories of unique entities, rather than between unique and nonunique entities. As such, it will be important for future studies to clarify the relationship between the unique entity findings, and the results reported here. 

More generally, the findings reported here help to clarify the architecture of the human conceptual system. As demonstrated in many earlier studies, conceptual knowledge is supported by a widely distributed network of property regions that represent in part the content of conceptual representations, as well as auxiliary regions such as the hippocampus and left inferior frontal gyrus that support memory acquisition and retrieval processes generally. The precise architecture of this system, namely the nodes through which regions are functionally connected, remains an important and controversial question. In the present study, no evidence was obtained in support of the claim that the anterior temporal lobe is a domain-general representational hub. Rather, the findings strongly suggest that the anterior temporal lobe is a component in a network supporting an important class of knowledge: social concepts ( ). Describing how the components of this and other conceptual processing networks connect and communicate is a major challenge for all neural theories of the human conceptual system. Developing a better understanding of both the functional and structural connectivity among these regions, and how these connections develop over the lifespan and change with experience, remains a critical and unfinished task. 


## Supplementary Material 
  
 Supplementary material   can be found at:   http://www.cercor.oxfordjournals.org/  


## Funding 
  
. 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-36'>
<h2>36. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/26644594/' target='_blank'>26644594</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> The shaping of social perception by stimulus and knowledge cues to human animacy</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Philos Trans R Soc Lond B Biol Sci</p>
<p><strong>Publication Year:</strong> 2016</p>
<p><strong>DOI:</strong> 10.1098/rstb.2015.0075</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4685521/' target='_blank'>4685521</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study used task-based fMRI in healthy adult participants (final N=23, mean age 26.4) performing a social perception task (observing agents interacting; manipulations probe perception/understanding of others, person perception, action observation and mentalizing). Neuroimaging analyses were conducted and reported at the whole-brain level (voxel-wise threshold, cluster reporting; not ROI-only). Participants were healthy young adults (within 17–65) and results for this group are reported separately. No exclusion criteria are met (not clinical-only; whole-brain results presented). Therefore the study meets all inclusion criteria for fMRI studies of social-related processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Although robots are becoming an ever-growing presence in society, we do not hold the same expectations for robots as we do for humans, nor do we treat them the same. As such, the ability to recognize cues to human animacy is fundamental for guiding social interactions. We review literature that demonstrates cortical networks associated with person perception, action observation and mentalizing are sensitive to human animacy information. In addition, we show that most prior research has explored stimulus properties of artificial agents (humanness of appearance or motion), with less investigation into knowledge cues (whether an agent is believed to have human or artificial origins). Therefore, currently little is known about the relationship between stimulus and knowledge cues to human animacy in terms of cognitive and brain mechanisms. Using fMRI, an elaborate belief manipulation, and human and robot avatars, we found that knowledge cues to human animacy modulate engagement of person perception and mentalizing networks, while stimulus cues to human animacy had less impact on social brain networks. These findings demonstrate that self–other similarities are not only grounded in physical features but are also shaped by prior knowledge. More broadly, as artificial agents fulfil increasingly social roles, a challenge for roboticists will be to manage the impact of pre-conceived beliefs while optimizing human-like design. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (49446 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Detection and recognition of other agents is a necessary ability across species. It is an integral pre-requisite for social interaction: one must accurately identify others in order to appropriately interact with them. For instance, one would not expect a robot to offer the same opportunities for social interaction as a human. Considering the predicted rise of artificial agents in society performing tasks alongside humans in hospitals, care homes and schools [ ], it will become increasingly important to distinguish between animate agents (e.g. humans) and inanimate agents (e.g. robots). Robots can act in the world by moving and achieving goals, but they are not sentient or intentional. Indeed, a key factor for classifying other agents is the perception of animacy—the presence of life in others. The distinct way that robots and humans look and move as well as what we know about their origins offer important cues to animacy [ ]. As such, a key question for social cognition and social neuroscience research pertains to understanding the cognitive and neurobiological mechanisms that enable us to recognize animacy in other agents [ ]. 

### The neuroscience of social perception and cognition 
  
The neuroscience of social cognition is concerned with how the brain manages social interactions with others [ ]. Several distinct brain circuits have been identified that process elements of our social worlds, three of which are of particular relevance to the current study ( ). Person perception research has shown how sensory systems are sensitive to the presence of conspecifics in the environment [ ]. For instance, patches of cortex in the ventral visual stream including fusiform and occipitotemporal gyri respond preferentially to images of social stimuli (faces and bodies) compared to non-social stimuli (houses and cars) [ , ]. Accumulating evidence suggests the ventral visual stream contributes to understanding identity through processing physical appearance, such as facial features, body shape and posture [ , ].
   
Social brain circuits. mPFC, medial prefrontal cortex; TP, temporal poles; Prec., precuneus; IFG, inferior frontal gyrus; IPL, inferior parietal lobule; TPJ, temporoparietal junction; pSTS, posterior superior temporal sulcus; FG, fusiform gyrus; OT, occipitotemporal cortex. The mirror neuron system and pSTS form the key nodes of the action observation network. 
  

Another form of social perception involves observing others moving through the environment and interacting with objects. Brain regions responding to the observation of others in action include posterior temporal gyri, inferior parietal lobule and inferior frontal gyrus [ – ]. The frontal and parietal responses are consistent with research into the mirror neuron system discovered in monkeys, which shows similar responses to performed and observed actions [ ]. One dominant theory argues that this frontoparietal network enables action understanding through simulation by mapping observed actions onto the observer's own motor system [ ]. 

Simply coding the physical characteristics of other agents and their movements would not, however, be sufficient to understand the meaning of their actions. It is also necessary to make inferences about information one cannot see, such as others' beliefs, desires, attitudes and traits [ ]. A third strand of social cognition research—mentalizing—aims to delineate the cognitive and brain systems integral to representing such mental states of others [ ]. Brain circuits spanning the medial prefrontal cortex (mPFC), temporoparietal junction (TPJ), temporal poles and precuneus are consistently engaged when inferring and evaluating mental states and are collectively known as the theory of mind network [ , ]. The ability to draw inferences about underlying intentions helps us to predict what another individual may do next and helps to regulate social interactions [ , ]. Together, the studies highlighted in this section have identified discrete brain circuits that subserve aspects of social perception and interaction. It is less clear, however, how social information is organized beyond a social–non-social distinction. 


### The ‘like-me’ hypothesis 
  
One dominant model in social cognition states that understanding the similarity between self and other is a basic principle of social cognition and that humans have developed to seek out self–other equivalence [ , ]. This account, known as the ‘like-me’ hypothesis, further proposes that actions performed by oneself and another are represented in common cognitive codes [ ]. At the core of the ‘like-me’ hypothesis is the proposal that cognitive and brain mechanisms have been shaped to show sensitivity to information that is physically or cognitively similar to one's own makeup. This view is consistent with the biological imperative to detect similar others as a foundation for successful navigation of the world [ ]. 

One approach to test predictions that follow from the ‘like-me’ hypothesis has been to vary cues to human animacy. In such studies, the idea is that the more human-like an agent is perceived, in terms of physical appearance and intentionality, the more it is considered to be ‘like me’. These studies have fallen into two main camps based on the type of cues to human animacy under investigation. One camp has manipulated stimulus features, such as what an agent looks like or how it moves. The second camp has manipulated knowledge cues to animacy, such as whether an observer believes an agent to be human or not. Both cue types are of clear relevance to the study of social perception. Humans move in a particular way, for instance using a minimum jerk trajectory, and have a particular form (i.e. head above a torso with limbs). Such distinctive physical features can be diagnostic of a human presence. Likewise, knowledge cues also matter for interpreting human animacy. If you know the gorilla across the street is actually a man in a costume, your perception of the social environment would be markedly different from if you were not aware of this fact. In the following, we review behavioural and brain-imaging studies that have manipulated stimulus cues and knowledge cues to human animacy. Instead of an exhaustive review of all studies exploring animacy detection, our focus is on brain systems that index the distinction between human and non-human agents. 


### Stimulus cues to human animacy 
  
The majority of research into cues influencing animacy perception has focused on stimulus cues to human animacy, such as what an agent looks like and how it moves. These can be considered ‘bottom-up’ cues that are determined by the visual appearance of the form and motion of an agent. Many studies have investigated responses along the ventral visual stream to depictions of human compared to non-human stimuli, such as other animals or inanimate objects [ , ]. Less research in the domain of person perception has varied cues to human animacy by comparing human to less human or robotic agents [ , ]. Gobbini   et al  . [ ] showed similar engagement of core face perception areas—fusiform face area (FFA), occipital face area (OFA) and posterior superior temporal sulcus—when observing human and artificial, robotic faces. In addition, core face and body processing regions also respond to cartoon and schematic depictions of faces and bodies [ , ]. Thus, the ventral visual stream appears to be indifferent to animacy cues that are based on physical form and responds to real faces and bodies as well as face- and body-like forms. 

In the domain of action perception, where agents are moving in the world and sometimes interacting with objects, results are mixed. The superior temporal sulcus has been shown to respond to biological motion, even in the absence of a clear human form [ , ]. Many studies have also compared the observation of actions performed by humans and robots. A common result is more engagement of sensorimotor brain regions collectively termed the action observation network (AON) and facilitated behavioural responses when the agent is more human than not [ , ]. For example, observing human form and motion increased motor priming in an imitation task [ , ]. In addition, right premotor cortex is engaged more during the observation of reaching actions performed by a human hand compared to a robotic claw [ ]. These results are consistent with a self-similarity bias and more AON engagement when an observed agent is more human. 

On further inspection of the action perception literature, however, several studies show indifference in the AON to degrees of stimulus-driven humanness or even a preference for non-human stimuli. For instance, Gazzola   et al  . [ ] failed to find any difference in brain responses when participants viewed actions performed by a human or robotic hand. Likewise, Ramsey & Hamilton [ ] found that the left anterior intraparietal sulcus, a core AON node, responded in a similar manner when participants observed a geometric shape or a human hand perform goal-directed actions. Moreover, some studies show an even greater response in the AON when perceiving non-human compared to human visual cues [ , ]. In two experiments, Cross and co-workers show greater engagement when watching rigid robotic movement compared to natural free-flowing dance moves that are more consistent with a human's motor repertoire [ ]. This robust AON engagement was seen when participants observed a human actor dancing and when observing a robot toy animated to move in a similar manner. Therefore, the AON was shown to be more sensitive to rigid, non-human-like movement irrespective of animacy cues based on physical form. Finally, Saygin & Stadler [ ] found that middle temporal gyrus and intraparietal sulcus are more sensitive to an android (a robot dressed as a human) than a clearly presented human or robot actor. Thus, the role of the AON in response to varying stimulus cues to human animacy remains somewhat unclear. 

Stimulus cues can also drive mental state reasoning and engagement of the person knowledge or theory of mind network. Heider & Simmel [ ] showed that when people observe simple shapes moving around as if they are interacting, they ascribe human-like mental states to these shapes. Using the same stimuli, Castelli   et al  . [ ] demonstrated that these stimuli also engage brain regions associated with mental state reasoning and social cognition (see also [ ]). Social context can also lead to mental state reasoning if stimuli are arranged in a manner that makes a moving object look like a social agent (such as an ice skater) rather than an inanimate object (like a spinning top [ ]). Finally, the same movie footage of social interactions engages person knowledge networks more if real video footage is viewed rather than modified versions that have been made to appear ‘cartoonish’ [ ]. Together, this work suggests that stimulus cues alone can provide an input to human-like mental state and animacy judgements. 


### Knowledge cues to human animacy 
  
Knowledge cues to animacy are based on beliefs about an agent's animate origins and can be task instructed or task independent [ ]. These can be considered ‘top-down’ cues that are driven by prior information about the stimulus, rather than by the visible form and motion cues. The impact of knowledge cues can be seen most clearly when visually identical stimuli are encountered across different conditions, which vary knowledge about the agent's humanness. Thus, any differences in cognitive or brain function are cued by information that is independent to the stimulus. 

A growing body of behavioural evidence supports the notion that beliefs about humanness influence social perception and interaction [ – ]. For example, Liepelt & Brass [ ] used an automatic imitation task and found that participants showed stronger evidence of motor priming when movements were thought to be made by a human rather than a wooden hand. Using simplified moving dot stimuli, Stanley   et al  . [ , ] showed increased behavioural interference together with reports of stimuli appearing more human-like when participants believed the stimuli originated from real human movement compared to computer-generated movement. Finally, using a manipulation where participants were required to coordinate their actions with a physically present humanoid robot, Stenzel   et al  . [ ] found that participants were more likely to represent the robot's action if they believed that the robot's behaviour was based on a biologically inspired neural network than when it was based on a computer program. 

Neuroimaging research has also varied knowledge cues to human animacy. Seminal fMRI studies of theory of mind used the same stimuli for both ‘human’ and ‘computer’ conditions, and varied participant instructions. The instruction ‘you are playing with a human’ gave rise to robust activation in the person knowledge network [ , ]. That is, the identical stimulus increasingly activated social brain regions when participants believed it originated in another person, not a computer. 


### Combined stimulus and knowledge cues to human animacy 
  
Few studies have directly compared stimulus and knowledge cues to human animacy. Press   et al  . [ ] showed that stimulus cues to animacy override knowledge cues when imitating hand actions. By contrast, Stanley   et al  . [ ] showed that knowledge of how a moving dot was made (human versus computer-generated) dominated perception of animacy compared to its motion properties. Klapper   et al  . [ ] showed that both types of cue influence imitation of hand actions. Moreover, fMRI results from the study by Klapper and co-workers showed that right TPJ was engaged more during an automatic imitation task when both stimulus   and   knowledge cues to human animacy were present than when only one or neither cue to human animacy was present [ ]. This result supports the view that right TPJ may be particularly sensitive to controlling interactions with human agents [ , ]. 

A neuroimaging study by Stanley   et al  . [ ] manipulated both types of cue by investigating passive observation of point-light animations. Point-light stimuli typically consist of a sequence of moving dots, representing several joints on an actor's body, which give the appearance of human biological motion [ ]. This study found that knowledge of human animacy engaged mPFC more than knowledge that the stimuli were computer-generated. By contrast, human-like movement did not engage social brain circuits more than less-human movement. While emerging evidence suggests instances when both stimulus and knowledge cues influence social perception and cognition, the conditions and parameters that lead to these biases remain largely unknown. 


### Summary and the current study 
  
Evidence suggests widespread cortical engagement of distinct social brain circuits for detecting and recognizing aspects of human animacy during social interactions. Stimulus and knowledge cues to human animacy engage person perception, action observation and mental state reasoning networks. The picture to date remains far from clear, but there appears to be some kernel of truth to the suggestion that a mechanism of self-similarity or ‘like me’ may operate across these studies. Many questions remain unanswered, however. A growing number of studies show indifferent or opposite brain or behavioural responses to those consistent with a theory based on self-bias. Moreover, few neuroimaging studies have directly compared stimulus and knowledge cues to human animacy in the same experiment to tease apart their relative contributions to detection and recognition of other humans. Indeed, only one other study to date has investigated action perception in this manner and this study did not present visible human features, such as faces or body parts, but instead used point-light displays of simple actions [ ]. Hence, it remains unclear how perception of action is influenced by cues to human animacy, particularly when physical form cues are visible. 

The current study, therefore, directly compares stimulus and knowledge cues to human animacy during the observation of agents interacting with objects. Face and body cues are manipulated as well as beliefs about the origins of such actions. By doing so, we are able to investigate which cues to animacy dominate perception of action as well as how these cues engage social brain circuits. To support the ‘like-me’ hypothesis, we would expect greater engagement of brain regions implicated in action observation [ , ], mentalizing [ , , ] and person perception [ , ] when stimulus or knowledge cues to human animacy (or both) are present. However, as a number of recent studies suggest [ , – ], we might also find that parts of the social brain are not solely tuned to preferentially respond to cues that are ‘like me’. Thus, the current study will provide novel insights into aspects of the social brain that are more or less responsive to features of an agent that are ‘like me’ through careful manipulation of stimulus and knowledge cues to human animacy. 



## Material and methods 
  
### Participants 
  
Twenty-nine physically and neurologically healthy young adults were recruited from the fMRI Database of the Max Planck Institute for Human Cognitive and Brain Sciences (Leipzig, Germany). All were monetarily compensated for their involvement and provided written informed consent in line with procedures set forth by the local ethics board. Six participants were excluded from the final analyses due to not believing the cover story (see   Behavioural Procedure and Task  ). The final sample included 23 participants (14 women, nine men;   M   = 26.41 years, s.d. = 3.02 years) who believed the cover story. All participants were native German speakers and right handed as measured by the Edinburgh Handedness Inventory [ ]. 


### Stimuli 
  
Stimuli were created using P  three-dimensional animation software (SmithMicro Software Inc, Santa Cruz, CA, USA) and featured 10 object-directed actions ( ). Each video lasted 5 s. To create the stimuli, a human actor was first filmed performing each action, and these videos served as a model for creating the Poser videos. Each action was mapped onto two different avatars: a human male and a custom-designed robot ( ). Each action was ‘filmed’ from the waist upwards and from three different angles: centre, off centre and from the side (see right panel of   a  ). These procedures yielded 60 videos in total (10 different actions × 2 different agents × 3 different viewing angles).
   
Details of experimental materials and design. (  a  )(i) Eight of the 10 actions featured in the stimuli set (the remaining two, ‘toss ball’ and ‘hammer nail’ are seen in (  a  )(ii) and in (  b  )). (  a  )(ii) The three viewing angles each action was ‘filmed’ from, to create a larger, richer stimulus set. (  b  ) The 2 × 2 factorial design that enabled investigation of bottom-up features (whether the agent looked like a human or robot; rows of design) as well as top-down features (whether participants were told the videos were created using human motion capture or computer animation; columns of design). 
  


### Belief manipulation 
  
In order to manipulate knowledge cues to human animacy, participants were told the current study was commissioned by a major German film studio for the purpose of examining how the human brain processes two cutting-edge animation techniques: human motion capture and computer-generated keyframe animation. Before taking part in the experiment, participants watched a 10-min custom-made and professionally produced ‘documentary’ that explained human motion capture and computer keyframe animation techniques in detail (see also [ ]). Specifically, participants learned that human motion capture involves recording real human movement via sensors that are attached to the body, whereas computer-generated keyframe animation involves a computer algorithm that fills in intermediate frames of a movement between predefined start and end positions. To further induce believability, the Poser stimuli used in the actual experiment were briefly seen in several parts of the cover story documentary to reinforce the idea that both kinds of animation could lead to the types of stimuli observed in the present study. In reality, however, all stimuli used in the real experiment were made with computer keyframe animation (the technique used by P  software), which closely approximates real biological motion. After watching the documentary, participants were asked whether they had understood how both techniques were used to animate avatars, and whether they had any questions about the techniques before the experiment started. 


### Behavioural procedure and task 
  
Participants' task in the scanner was to carefully observe 240 video stimuli during one functional run (each of 60 videos was repeated four times in total during the experiment). The videos were blocked into groups of five (with each group of five videos featuring either the human or the robot avatar), and participants observed a total of 48 blocks of five videos containing equal numbers of each agent form/belief pairing. Before each block of five videos was played, a cueing screen appeared for 2 s that specified that the following videos were made either with motion capture or computer keyframe animation (  b  ). The order of instruction screens and the individual actions that made up each series of five videos was pseudo-randomly assigned. 

After each video, one of two questions appeared which participants were required to answer: either (i) how much did you   like   the video you just saw? or (ii) how   smooth   did you find the movement in the previous video? These questions were chosen for several reasons. First, we wanted to determine how stimulus and knowledge cues to human animacy influence perception of the stimuli at a behavioural level. Second, two questions were chosen so that participants could not anticipate the exact question they would be asked, which required them to maintain attention to the stimuli. Participants made their ratings on a 1–8 scale via a fibre-optic scanner compatible button box. Following scanning, participants completed a debriefing survey where they were explicitly asked whether they noticed anything of note about the stimuli, as well as what they believed the true goal of the study was. The six participants (of the original sample of 29 participants) who raised suspicions the stimuli seemed to be the same and only the instructions changed were excluded from the final sample. Upon completing this survey, all participants were told the true nature of the study and compensated for their time. 


### MRI acquisition 
  
Functional neuroimaging was acquired using a Bruker 3 Tesla Medspec 20/100 whole-body MR scanning system, equipped with a standard birdcage head coil. Functional images were acquired continuously with a single-shot gradient echo-planar imaging sequence with the following parameters: echo time (TE) = 30 ms, flip angle = 90°, repetition time (TR) = 2000 ms, acquisition bandwidth 100 kHz. Twenty-four axial slices allowing for full-brain coverage were acquired in ascending order (pixel matrix = 64 × 64; FOV = 24 cm, resulting in an in-plane resolution of 3.75 × 3.75 mm , slice thickness = 4 mm, interslice gap = 1 mm). Slices were oriented parallel to the bicommissural plane (AC-PC line). The first two volumes of each functional run were discarded to allow for longitudinal magnetization to approach equilibrium. An additional 813–830 volumes of axial images were collected. Geometric distortions were characterized by a B0 field map scan (consisting of a gradient echo readout (32 echoes, inter-echo time 0.64 ms) with a standard two-dimensional phase encoding). The B0 field was obtained by a linear fit to the unwarped phases of all odd echoes. Following the functional run and field map scan, 24 two-dimensional anatomical images (256 × 256 pixel matrix, T1-weighted MDEFT sequence) were obtained for normalization purposes. In addition, for each participant, a sagittal T1-weighted high-resolution anatomical scan was recorded in a separate session. The anatomical images were used to align the functional data slices with a three-dimensional stereotaxic coordinate reference system. 


### Behavioural data analysis 
  
Behavioural responses to the smoothness and liking questions asked during the imaging task were combined to form a single dependent variable and were analysed with a 2 (Agent Form: human, robot) × 2 (Belief Manipulation: human motion capture, computer-generated animation) repeated measures ANOVA. 


### Imaging data analysis 
  
Data were realigned and unwarped in SPM8 (Wellcome Department of Imaging Neuroscience, London, UK) and normalized to the Montreal Neurological Institute (MNI) template with a resolution of 3 × 3 × 3 mm. Slice timing correction was performed after realignment. Functional data were normalized to individual participants' T1 anatomical scans with a resolution of 3 mm . All images were then spatially smoothed (8 mm). A design matrix was fitted for each participant, with each type of video (Human with Motion Capture instruction, Human with Computer Animation instruction, Robot with Motion Capture instruction and Robot with Computer Animation instruction), the belief manipulation instruction screen and the question/response period modelled as a boxcar function convolved with the standard haemodynamic response function. The imaging analyses were designed to achieve the following three primary objectives: 

#### Main effect of stimulus cues 
  
First, we evaluated the main effect of visual cues to the socialness of an observed agent. To achieve this, we compared observation of actions performed by the human avatar to the robot avatar (human > robot), as well as the inverse (robot > human). 


#### Main effect of knowledge cues 
  
We next assessed the main effect of our belief manipulation. We evaluated brain regions more engaged when videos were believed to have a human origin (motion capture > computer animation), or when videos were believed to be computer-generated (computer animation > motion capture). 


#### Interaction between stimulus and knowledge cues 
  
The third set of contrasts examined the interactions between agent form and belief cues. The aim of these interaction analyses was to determine the extent to which brain regions associated with the action observation, mentalizing or person perception networks are sensitive to specific pairings of stimulus-driven and knowledge-based cues to human animacy. The first interaction contrast interrogated brain regions more engaged when viewing congruent agent/belief pairings more than incongruent pairings. An example of a congruent pairing would be a human agent paired with motion capture belief or a robotic agent paired with computer-generated belief, whereas incongruent pairings would feature a human agent paired with computer animation belief or the robotic agent paired with motion capture belief. The inverse interaction examined brain regions more engaged when viewing the incongruent agent/belief pairings compared to the congruent pairings. 

All neuroimaging analyses were evaluated at the whole-brain level with a voxel-wise threshold of   p   < 0.005 uncorrected and   k   = 10 voxels [ ].   lists all regions that meet this threshold. To most clearly illustrate all fMRI findings,   t  -images are visualized on a participant-averaged high-resolution anatomical scan. Parameter estimates (beta values) were extracted and plotted for visualization purposes only for the two interaction analyses. Anatomical localization of all activations was assigned based on consultation of the Anatomy Toolbox in SPM [ , ].
   
Main effects and interaction from whole-brain analyses. MNI coordinates of peaks of relative activation within regions responding to the main effects of agent, collapsed across instruction (a: observing a human compared to a robot perform an action; and b: observing a robot compared to a human perform an action), the main effects of belief manipulation, collapsed across agent (c: observing actions said to be made by human motion capture compared to computer-generated animation; and d: observing actions said to be made by computer-generated animation compared to human motion capture) and the interactions between agent form and belief manipulation (e: observation of congruent agent/belief pairings; and f: observation of incongruent agent/belief pairings). Results were calculated at a voxel-level threshold of   p   < 0.005,   k   = 10 voxels. Up to three local maxima are listed when a cluster has multiple peaks more than 8 mm apart. Entries in bold denote activations significant at the false discovery rate cluster-corrected level of   p   < 0.05. HF, human form; RF, robot form; MCB, motion capture belief; CGB, computer-generated belief. 
  




## Results 
  
### Behavioural data 
  
During scanning, participants rated each video on how smooth they found the movement or how much they enjoyed watching it. Due to an error in the MATLAB code, it was not possible to separate ratings of liking and smoothness for the main experiment. However, a follow-up behavioural study was performed with 30 naive participants who performed the identical task with the same stimuli. These data showed that across all 120 stimuli/instruction pairings, ratings of liking and smoothness correlated at   r   = 0.53,   p   < 0.001. As prior work suggests that both questions tap into the same psychological construct (i.e. we tend to like movements more that are smooth [ ], and participants' ratings of movement smoothness and liking strongly correlate in other experimental settings [ ]), we considered it valuable to examine behavioural responses as a single combined variable. A repeated measures ANOVA revealed that participants rated movements they thought to be generated by human motion capture as significantly smoother and more pleasing to watch than videos they believed to be generated by computer animation,   F   = 21.28,   p   < 0.001 ( ). No main effect of agent (  p   = 0.39) emerged, nor was any interaction between belief and agent manifest in the data (  p   = 0.79). These data suggest that beliefs influence our dependent measure more than an agent's form.
   
Behavioural data from fMRI task. Plots illustrate mean ratings reported by participants to questions interrogating how smooth participants found the movements or how much they enjoyed watching them. A main effect of belief was manifest, such that participants found those action videos they believed to originate from human motion capture techniques to be smoother and more enjoyable to watch than videos they believed to originate from computer-generated animation. No other main effects or interactions were observed. 
  


### Functional imaging data 
  
#### Main effects of stimulus cues 
  
The first imaging analyses investigated the extent to which visual cues to human animacy influence action perception. No suprathreshold clusters emerged from the human > robot form contrast. The inverse contrast (robot > human form) revealed engagement of bilateral ventral temporal and occipital cortices, which survived correction for multiple comparisons (  p   < 0.005,   FWE  -corrected), as well as   engagement of portions   of the left superior temporal gyrus and hippocampus (  b   and   a  ). Similar to findings reported by Cross   et al  . [ ], this result suggests greater high- and low-level visual engagement when observing a robotic agent execute actions.
   
Main effects of agent form (stimulus) and belief manipulation (knowledge). Panel (  a  ) illustrates brain regions more engaged when participants watched actions performed by a robotic avatar compared to a human avatar. Panel (  b  ) shows brain regions more engaged when participants watched videos they believed to originate from human motion capture compared to computer animation. Full details of these findings are presented in  . STG, superior temporal gyrus; FG, fusiform gyrus; IOG, inferior occipital gyrus; SPL, superior parietal lobule. 
  


#### Main effect of knowledge cues 
  
The next set of contrasts evaluated the impact of belief or knowledge cues to human animacy on action perception. The first contrast (human motion capture > computer keyframe animation belief) revealed activity within the right inferior occipital and fusiform gyri. While these brain regions did not survive correction for multiple comparisons, it is nonetheless of interest to note that the cluster located within the right inferior occipital gyrus closely corresponds to functional localizations of the OFA (less than 6 mm away [ ]). Moreover, the peak of the cluster in fusiform gyrus is 14 mm away from an average peak location of this region when functionally localized, as reported by Spiridon   et al  . [ ]. It should be noted, however, that the fusiform cluster identified in the present study is more anterior to most reports of the FFA. Clusters also emerged in the left precuneus, as well as the left superior parietal lobule also emerged from this contrast (  c   and   b  ). The response in the precuneus corresponds closely to responses typically found with a theory of mind localizer task based on comparing beliefs to physical stories [ ]. The inverse contrast (computer keyframe animation > human motion capture) did not reveal any suprathreshold activations. 


#### Interaction between stimulus and knowledge cues 
  
The next set of analyses investigated the extent to which brain regions associated with social perception are influenced by the interaction of stimulus and knowledge cues to human animacy. The first interaction examined congruent pairings of agent and belief compared to incongruent pairings ((human form + motion capture belief) and (robot form + computer animation belief) > (human form + computer animation belief) and (robot form + motion capture belief)). Three uncorrected clusters emerged along the midline cingulate cortex, including middle and posterior cingulate cortices (  e   and electronic supplementary material, figure A). The parameter estimate plots reveal evidence for crossover interactions for the two middle cingulate activations, while the interaction within posterior cingulate cortex appears to be driven most by a stronger response to the human agent being paired with motion capture instructions compared to computer animation instructions. 

The inverse interaction evaluated brain regions more engaged when observing incongruent compared to congruent form and belief pairings ((human form + computer animation belief) and (robot form + motion capture belief) > (human form + motion capture belief) and (robot form + computer animation belief)). This contrast revealed two uncorrected clusters: one in the right inferior frontal gyrus, and a second in the cerebellum (  f   and electronic supplementary material, figure B). For this interaction, it is of note that the interaction present within these two brain regions is driven by different stimuli (see parameter estimates in electronic supplementary material, figure B). Specifically, robotic agents paired with motion capture instructions seem to drive the cerebellar region most strongly, while the human agents paired with computer animation instructions drive the inferior frontal gyrus region most. 




## Discussion 
  
Prior research has revealed that many different cues to human animacy engage brain networks associated with social cognition, while less is known about the relationship between these cues. In the present study, we used video stimuli featuring kinematically identical actions performed by a human or robotic agent and an elaborate belief manipulation to test the extent to which stimulus and knowledge cues to human animacy influence perception. Behaviourally, participants reported actions believed to originate from human motion capture to be smoother and more enjoyable to watch than those believed to have computer animation origins, while differences in agent form did not affect ratings. The neuroimaging findings echoed this pattern, with knowledge cues to human animacy showing subtle influence (at a liberal threshold) on brain circuits implicated in social cognition. 

We failed to find evidence that visual cues to human animacy more strongly engage the action observation, person perception or theory of mind networks than visual cues to a robotic agent, as might have been predicted. In contrast, we found a robust, cluster-corrected area of activation spanning ventral temporal and occipital cortices when participants observed actions performed by a robotic compared to human-like agent. These findings raise questions about the role played by stimulus cues to human animacy, while also highlighting the influence of knowledge cues on social perception when perceiving identical agents and actions. Together, they provide new insights into the supporting neural architecture and behavioural consequences of social perception. 

### Belief about humanness influences perception, as shown by brain and behavioural responses 
  
While some prior studies have failed to find evidence that belief about the human origins of a stimulus can impact perception [ ], a growing body of evidence supports the notion that beliefs about humanness influence the way we perceive and imitate other agents [ – , ]. Our results are consistent with these findings as participants were more likely to report actions supposedly originating from real human movements as smoother and more pleasing to watch (questions that tap into how natural or human-like an agent or action appears [ ]). Our findings also fail to demonstrate that differences in agent form influence these ratings, which further suggests that knowledge cues can dominate stimulus cues in explicit evaluation of social features of an observed action [ ]. A challenge for future behavioural research will be to systematically investigate how knowledge cues to animacy impact different facets of social cognition. To date, for example, perceptual and imitative processes have been studied separately, and the relationship between these key aspects of social cognition and knowledge cues to human animacy remains unexplored. 

At the neural level, our findings provide some evidence that actions paired with a human- compared to computer-generated belief lead to greater engagement of brain regions associated with person perception and theory of mind. Specifically, portions of the right inferior occipital gyrus and fusiform gyrus responded more to the same stimuli when they were paired with human motion capture instructions. Both regions are located in close proximity to patches of cortex that are face selective including the OFA [ ] and fusiform face [ ] and body areas [ ]. It is of note that these two brain regions associated with processing the human face were modulated in this instance by social knowledge, and not differences in stimulus-driven features. 

Also important is the emergence of a cluster within the right precuneus from this same contrast. The precuneus is consistently implicated in theory-of-mind tasks and is believed to play a role in explicit belief processing [ , ]. If these results were to be replicated by future studies, they would suggest that parts of the social brain network involved in perceiving others' physical features and reasoning about others' minds are engaged when viewing agents whose actions are believed to have human origins. Revisiting the study by Stanley   et al  . [ ], these researchers varied the motion parameters of point-light actions (ranging from veridical displays of the original action to completely scrambled versions of each action), and, as in the current study, they also varied instructions (human- or computer-generated). For the main effect of instructions (human > computer), and similar to the present study, Stanley and co-workers reported greater engagement of brain regions associated with mentalizing. Consistent with Stanley and co-workers' interpretation of this finding [ ], we propose that based on believing that an agent is more human in nature, greater demands are placed on extracting relevant cues to support and evaluate this belief, changing the observer's perception of the social scene. In other words, it seems plausible that visual inputs are matched against a human template more in the human- than computer-belief condition. This process engages theory of mind and person perception in combination. This interpretation, however, remains speculative at this stage and will require further research to test it thoroughly. 


### Revisiting stimulus cues to human animacy and the action observation network's role in social perception 
  
In contrast to a number of previous studies [ , , , ], we failed to find behavioural or brain-based evidence that stimulus cues to human animacy enhance action perception relative to non-human stimulus cues. Instead, we contribute further support, which survives correction for multiple comparisons, to a growing body of evidence that suggests that non-human stimulus cues can lead to the same or even an enhanced engagement of high- and low-level visual areas and the AON [ , – ]. Specifically, we add to the evidence that social brain circuits including the AON are frequently indifferent to stimulus cues to human animacy. 

Although visually salient differences between the human and robot avatar are apparent, the AON did not respond to this difference in the present study. An exploratory analysis of each stimulus form compared independently to an implicit baseline revealed that observing the human or robot agent in isolation resulted in widespread, robust engagement of bilateral AON, fusiform and occipitotemporal brain regions. The results of these simple contrasts help to rule out the possibility that the lack of findings in the human > robot contrast are due to a peculiarity of the human stimuli not engaging such brain networks on their own. The present findings could possibly be due to the fact that both agents executed the identical goal-directed actions (cf. [ , ]) or because the robot and human forms shared some features (i.e. a head atop a torso with two arms). Even though the human and robot forms were generated with the same CGI package, one potential reason the AON might have failed to discriminate between the agents might be because the human form was slightly less human than a video of a real person would be. Another possibility for why we found greater engagement of brain regions associated with person perception when observing a robot compared to a human could be that these brain regions are engaged to assimilate the robotic agent with a more familiar and predictable human template. A similar idea was discussed by Cross   et al  . [ ] in light of finding more robust AON engagement when observing robotic compared to human-like actions. Recent work [ ] lends tentative support to the idea that greater engagement of occipitotemporal brain regions when observing unfamiliar visual stimuli (such as the robotic actions in [ ] and the robotic agents in the current study) might indeed be due to differences in predictability, as outlined by a predictive coding model of action perception [ ]. 

Regardless of the reason for the absence of a difference in AON engagement observed between human and non-human stimulus cues in our study, the current findings suggest that the importance of a human-like form to social perception may have been overstated. Other factors such as top-down beliefs [ , ] and bottom-up kinematic information [ ] also shape social cognition when perceiving and interacting with others [ , ]. Our data help to redress the balance of how much weight the AON assigns to self–other similarities on a form-based, visual level. Future research investigating perception of human animacy may explore which social brain mechanisms are specifically tuned to respond to the extent to which a stimulus is perceived as being ‘like me’, and what other complementary mechanisms might be at play [ , ]. Returning to the ‘like-me’ account of social cognition, the current findings contribute to this view by demonstrating that social brain circuits may be tuned to detect human animacy based on knowledge cues that signal an agent to be ‘like me’. 

While we fail to find behavioural or imaging evidence demonstrating that visual cues to humanness influence social perception, it should be noted that exploratory further analysis of the human > robot form contrast (evaluated at   p   < 0.01,   k   = 10 voxels) revealed activity within the right temporoparietal junction, centred on coordinates   x   = 51,   y   = −37,   z   = 27. While this finding provides weak evidence that brain structures implicated in social cognition [ ] might indeed be more engaged when observing human compared to robotic agents, we are reluctant to interpret this finding further due to the lack of statistical strength. The clearer message to emerge from the main effects of the present study is that top-down belief cues to human animacy shape social perception to a stronger degree than bottom-up visual form cues to human animacy, with stimuli paired with human beliefs associated with engagement of brain regions implicated in person perception and theory of mind. 


### Interactions between stimulus and knowledge cues to human animacy 
  
The design of the present study enabled us to address how stimulus and knowledge cues to human animacy interact during action perception. Findings from the contrast comparing congruent with incongruent pairings of stimulus and knowledge cues failed to show modulation of the action observation, person perception or mentalizing networks. Instead, we report engagement of three uncorrected clusters spanning the middle and posterior cingulate cortex. However, as this finding was not predicted, we are reluctant to interpret it further. The result from the incongruent pairings interaction revealed an uncorrected cluster within the right inferior frontal gyrus located in a similar coordinate space to recent meta-analyses of the AON [ , ]. One simple interpretation of this finding, consistent with a rich literature on executive control, is that viewing incongruent pairings of agent form and humanness belief requires greater attentional control than when pairings are congruent [ ]. Alternatively, it is possible that increased engagement of this sensorimotor brain region when viewing incongruent stimulus and knowledge pairings relates to increased demands on motor simulation mechanisms to reconcile human and artificial features of an observed agent. In order to evaluate this necessarily speculative interpretation, further research is required to replicate and more fully delineate how stimulus and knowledge cues to human animacy interact. If we take a step back and attempt to construct a broader view of how the current study's findings fit in to the wider literature on the biological substrates of social perception and social cognition, given that some findings do support the ‘like-me’ hypothesis [ – ], while others do not [ – ], and the fact that not all reported results survive correction for multiple comparisons, replication of these findings will be important for future progress towards understanding how we perceive animacy in other agents. 


### Multiple routes to socialness and considerations for social artificial agent design 
  
The theoretical implications of the current study and research reviewed in this paper extend beyond the laboratory and serve to inform disciplines in addition to social cognition and neuroscience, including robotics. Over the past decade, individuals working to develop socially interactive artificial agents, including robots and avatars, are taking an increased interest in social cognition and social neuroscience research that examines the impact of ‘like-me’-ness on how we perceive and interact with such agents [ – ]. An ongoing goal for robotics designers has been to maximize the similarity of artificial agents to humans, in terms of appearance and movement (while perhaps attempting to circumnavigate the uncanny valley), in an attempt to make particular artificial agents as ‘like me’ as possible [ ]. However, findings from the current study and considerations raised by related work suggest that how an agent is perceived as being ‘like me’ can take many forms and is not only dictated by how convincingly a robot looks or moves like a human. Pre-conceived beliefs about robots will impact their reception in the workplace, schools, care homes and other social settings, and will undeniably shape how effective human–robot interactions will be. Thus, human knowledge about and attitudes towards robots will need to be optimized as much as a robot's physical form and motion parameters. As such, roboticists and computer animators stand to benefit from further dialogue and collaboration with researchers investigating mechanisms of social perception and their consequences for social interaction. 



## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-37'>
<h2>37. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/28273888/' target='_blank'>28273888</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> The experience of social exclusion in women with a history of suicidal acts: a neuroimaging study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Sci Rep</p>
<p><strong>Publication Year:</strong> 2017</p>
<p><strong>DOI:</strong> 10.1038/s41598-017-00211-x</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5428048/' target='_blank'>5428048</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study using the Cyberball social exclusion paradigm (a social-related task). It includes a healthy control group (HC) and reports within-group whole-brain analyses for HC (e.g., main effect of condition in anterior insula; voxelwise FWE-corrected results) as well as whole-brain group × condition ANOVA and post-hoc whole-brain tests. Thus it meets: (1) task is social processing, (2) includes healthy adults with results reported separately, and (3) reports whole-brain analyses (not only ROIs). Note: sample comprises only females and includes psychiatric groups, but that does not violate inclusion criteria because HC results are reported separately. Therefore the study should be INCLUDED.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Suicidal behaviors result from a complex interaction between social stressors and individual vulnerability. However, little is known of the specific neural network supporting the sensitivity to social stressors in patients at risk of suicidal acts. Using functional Magnetic Resonance Imaging, we investigated brain processing of social rejection in suicide attempters. Thirty-six euthymic women with a history of depression and suicidal behavior were compared to 41 euthymic women with a history of depression but no suicidal attempt, and 28 healthy controls. The Cyberball Game was used as a validated social exclusion paradigm. Relative to healthy controls, both patient groups reported higher levels of social distress related to the task, without significant differences according to suicidal status. Compared to patients without any history of suicide attempt and healthy controls, suicide attempters showed decreased contrast in the left insula and supramarginal gyrus during the exclusion vs. inclusion condition, after controlling for number of depressive episodes, medication, mood disorder type or social phobia. Our study highlights impaired brain response to social exclusion in euthymic female suicide attempters in regions previously implicated in pain tolerance and social cognition. These findings suggest sustained brain dysfunctions related to social perception in suicide attempters. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (24764 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Humans have a fundamental need for social belonging that, when thwarted, has consequences on mental well-being . Low social integration has been reported as a potential risk factor for suicide , raising the question of the need to focus on an “outside- in” view to capture the dynamic influence between biological and environmental factors on suicidal behavior . The majority of suicide victims had experienced at least one or more adverse life events within the last few months before their death . Interpersonal conflicts, relationship breakdown and job loss or difficulties are among the most prevalent events, all social stressors confronting the individual with some form of social exclusion and a threat toward their social status. However, while these events are rather common in general, only the most vulnerable individuals are at increased risk of committing suicide when facing such stressors, suggesting that the way these individuals process social perception and interactions is key to understanding their fatal act. It has been suggested that all these psychosocial stressors trigger a high level of psychological pain, a frequent theme in suicide notes , which, in turn, increases the risk of suicidal ideas and act . Finally, interpersonal difficulties and social exclusion facilitates risky decision-making , a putative endophenotype of suicide . For example, excluded individuals are more prone to eat non-nutritive foods and to avoid less tasty but nutritive foods that should be preferred for survival . The study of social cognitions - including social rejection and associated psychological pain - and their neural basis is therefore crucial for understanding the suicidal vulnerability, which will shed light on potential therapeutic targets. 

The vulnerability to suicidal behaviour has been associated with the dysfunction of several brain regions and cognitive processes. Notably, suicide attempters showed increased activation of the lateral orbitofrontal cortex following exposure to angry faces , suggesting an over-evaluation of emotional negative cues; increased activity in the middle prefrontal cortex and anterior cingulate cortex when recalling the psychological pain experienced during the suicidal episode ; and reduced activation of the ventral prefrontal cortex during risky choices  and the anticipation of rewards , both associated with risky decision-making. A study in depressed patients suggests that psychological pain is associated with increased perfusion in the dorsolateral prefrontal cortex and in inferior frontal gyrus, but also in occipital cortex and in inferior temporal gyrus . Altogether, it is hypothesised that the development of unbearable psychological pain following perception of social threat or rejection may lead to choose options (i.e. suicidal act) with short-term reward (i.e. relief from pain) in spite of the risks (i.e. death) in vulnerable individuals, partially relying on prefrontal cortex. Moreover, several neuroimaging studies in suicide attempters suggest that brain alterations associated with the suicidal vulnerability extend beyond the prefrontal cortex, notably the temporal and parietal cortices , known to be involved in processing social cognitions . However, to date, no study has specifically investigated response to social rejection in vulnerable individuals i.e. those with a history of suicidal acts. 

In the present study, we used a validated paradigm of social exclusion, the Cyberball Game . During this task, the participant plays a virtual ball-tossing game with two supposedly real other participants. However, he/she is not informed that he/she will progressively be excluded from the game by the two other participants who will continue to play together. A recent meta-analysis reported that three main areas were reliably recruited during the exclusion phase of the Cyberball task: the anterior insula, the anterior cingulate cortex, and the inferior orbitofrontal cortex . Intriguingly, these results therefore show a relative overlap with the brain regions previously associated with the vulnerability to suicidal acts . In order to focus on the vulnerability to suicidal acts, we compared patients with vs. without a history of suicidal acts to control for the effect of comorbid disorders (mood disorders here). Moreover, patients were euthymic at time of scanner to exclude the effect of acute depressive state and a large sample of participants was recruited to allow sufficient statistical power. 


## Results 
  
### Sociodemographic and clinical data 
  
There were no between-group differences for sociodemographic variables (Table  ).   
Between-group comparisons for sociodemographic and clinical variables. 
  
 Footnotes  : HC = Healthy Controls; PC: Patient Controls; SA: Suicide Attempters; KW: Kruskal Wallis test; MW: Mann Whitney test; NART: National Adult Reading Test; HDRS: Hamilton Depression Rating Scale; YMRS: Young Mania Rating Scale; BDI: Beck Depression Inventory; BIS: Baratt Impulsiveness Scale; STAI: Spielberger State-Trait Anxiety Inventory; STAXI: Spielberger State-Trait Anger Inventory; CTQ: Childhood Trauma Questionnaire; NTS: Need Threat Scale; RRRS: Risk and Rescue Rating Scale; SIS: Suicide Intent Scale; OCD: Obsessive Compulsive Disorder; PTSD: Post Traumatic Stress Disorder; GAD: Generalized Anxiety Disorder; NA = Not Applicable. 
  

As expected, HC had lower levels of subclinical depressive symptoms (BDI score only), anxiety-state and -trait, and anger-state and –trait than both patient groups. They also experienced less often childhood trauma (excepted sexual abuse). 

SA had a median number of suicide attempt of 2 (min-max: 1–10), and a median age at first suicide attempt of 22 (11–43) years old. SA had higher numbers of past depressive episodes than PC (3.5 (1–13) vs. 2 (1–50) respectively, p < 10–2). Number of past depressive episodes was therefore used as covariate in the subsequent neuroimaging analyses in comparisons between patient groups (i.e. PC vs. SA). While medication was equally distributed across groups, we nevertheless controlled for this variables in analyses. 

Following the Cyberball game, PC and SA had higher mean scores of social distress than HC, with no difference between SA and PC (63.5 (41–96), 65 (40–96) vs. 54 (31–87) respectively, p = 0.01). 


### Functional MRI 
  
#### Within-group analyses 
  
ANOVA analysis revealed a main effect of condition in left anterior insula/inferior frontal gyrus (Brodmann Area [BA] 13 extending to BA45, peak voxel: −43 18 7, 11 voxels, F = 14.9; Z = 5.2; voxel p-FWE = 0.002) in HC (Fig.  ), but not in PC and SA. Post hoc analyses in HC showed greater activation for both explicit social exclusion (ESE) and implicit social exclusion (ISE) vs. inclusion (INC) in anterior insula. This region has previously been associated with this contrast in healthy subjects in a recent meta-analysis .   
Main effect of conditions in healthy controls (voxel p-FWE corrected < 0.05, k ≥ 10) Brodmann Areas 13/45. 
  


#### Between-group analyses 
  
ANOVA analyses revealed a group by condition interaction only for ESE vs. INC for two clusters located in left supramarginal gyrus (BA40 extending to BA13; peak voxel: −39 −36 18; 23 voxels; F = 25.2; Z = 6.28; voxel p-FEW <10 ) and posterior insula (BA13; peak voxel: −39 −16 13; 10 voxels; F = 18.10; Z = 5.3; voxel p-FWE = 0.001) (Fig.  ). Post-hoc analyses showed decreased activation in these regions in SA relative to both PC (after covarying for number of past depressive episodes and medication) and HC (without covariates). These results were unchanged when mood disorder type or social phobia were used as covariates.   
Comparison of brain activation between the three groups for the explicit exclusion (ESE) vs. inclusion (INC) conditions contrast. Significant group x condition differences in supramarginal gyrus at −39 −36 18 (red) and insula −39 −16 13 (blue) (voxel p-FWE corrected < 0.05, k ≥ 10). 
  

For explanatory purposes, Fig.   presents extracted beta-values for the two contrasts in the three groups. Graphs show different patterns of responses in the two clusters. In left BA40, SA showed a larger deactivation during exclusion (whether implicit or explicit), while in left posterior insula, there was a diminished deactivation during exclusion in SA.   
Betas values of brain activation (arbitrary units) during contrasts of interest ES vs. INC and ISE vs. INC in the three groups in (  a  ) left supramarginal gyrus (−39 −36 18) and (  b  ) left posterior insula (−39 −16 13). Footnotes: SA: Suicide attempters; PC: Psychiatric controls; HC: Healthy controls; ESE: explicit social exclusion; ISE: implicit social exclusion; INC: inclusion. 
  

There were no significant correlations between brain activations for ESE vs. INC at the two clusters and clinical measures of level of childhood maltreatment, anxiety, anger, impulsivity and social distress measures. There were no significant correlations between decreased cerebral activations for ESE vs. INC and number of previous suicide attempts as well as intent and lethality of the most recent and most severe suicide attempts. 




## Discussion 
  
This first study exploring the neural basis of the experience of social exclusion in SA showed two main results. Using the self-administered scale (NTS), both patient groups, although euthymic, experienced more distress than HC during the Cyberball Game, with no difference between patient groups. However, functional neuroimaging was able to discriminate patients with vs. without a history of suicidal behavior. Indeed, during the exclusion phase of the Cyberball Game, patients with a history of suicidal acts showed a different activation in left posterior insula and supramarginal gyrus (two interconnected regions ) compared with both psychiatric and healthy controls. First, comparing the three groups we found a reduced activity of the posterior insula in SA vs. both groups of controls during exclusion. More precisely, the posterior insula showed a reduced deactivation in SA during ESE vs. INC. While not significant, this seems to be also the case during ISE vs. INC suggesting a general alteration in brain processing of exclusion. Previous studies have reported structural, metabolic abnormalities and modified connectivity of the insula in suicidal vulnerability . The posterior part of insula has been involved in interoceptive information  and pain . In borderline personality disorder patients, enhanced physical pain tolerance has been associated with decreased activation of insula during pain processing in comparison to controls . Thus reduced activity of the posterior insula in our sample may be a correlate of higher tolerance to pain via repeated exposure—and attendant habituation—to painful and provocative experiences in subjects vulnerable for suicide, as suggested by the interpersonal theory of suicide . Indeed, insula is part of the network underlying the acquired capability for suicide , which would facilitate lethal suicidal act when occurring simultaneously with thwarted belongingness (i.e., loneliness and lack of reciprocity) and perceived burdensomeness (i.e., feeling like a liability on others). Interestingly, in a prospective 2-year observational PET study, Oquendo   et al.   showed that greater 5HT  receptor binding potential in insula predicted more lethal attempts in depressed subjects . 

Second, we also found a different activity in the supramaginal gyrus in SA vs. both groups of controls during exclusion, with larger deactivation during ESE vs. INC. Reduced volumes of bilateral inferior parietal lobe have previously been reported in SA . Additionally, using magnetization transfer imaging, Chen   et al.   reported impaired macromolecular structural integrity in left inferior parietal lobe in SA relative to non-attempters and HC . Inferior parietal lobe is known to be involved in social cognition , but also in first/third person perspective-taking . Interestingly, in our study, this region did not show the same pattern of activation during ESE and ISE condition (vs. INC) in HC: left supramarginal gyrus was activated during ESE (when participants are excluded by the others) but deactivated during ISE (when particpants are told they will not participate for technical reasons) in HC. In SA, it was deactivated in both conditions suggesting that SA have difficulties taking into account the context in exclusion conditions. 

Third, we have not found significant differences of activation in orbitofrontal cortex in SA as hypothesized. It may suggest that increased lateral orbitofrontal activation in SA when viewing angry faces  may reflect a hypersensitivity to reprobation or conflict more than to social rejection   per se  . Overall, current and previous findings support a significant and sustained sensitivity to social stressors in individuals at-risk of suicide. 

Our study has several limitations. First, most of our patients were taking medications during this study. This may have influenced final findings. However, the distribution of different classes of drugs was similar between the two patient groups, which have been taken into account in analyses between patients. Moreover, patients presented with various comorbidities. In the present study, we chose not to exclude medicated patients (except patients with benzodiazepines) or patients with several comorbidities in order to maintain a reasonable level of representativeness. Importantly, when controlling for medication, mood disorder type or social phobia, our main results remained unchanged. Second, the naturalistic validity of the game is questionable as is the sensitivity of the questionnaire to measure distress at the end of the scanning session. Alternative investigations will have to be conducted. However, even if Cyberball game is not reflecting what individuals experience in their daily social interactions, Eisenberger   et al.   have shown strong relationships between neural activity during this experimental task and real-world feelings of rejection. Moreover, individuals who are the most sensitive to experimental social rejection in the scanner are also the most sensitive to these types of experiences in their everyday lives. Third, only female participants were recruited here, enabling to exclude a gender effect and give sufficient statistical power. A similar study deserves to be conducted in men because behavioural and biological differences have been reported during Cyberball game according to gender as well as evidence for gender paradox in suicidal process. Fourth, Cyberball non-randomized block design may involve a risk of failure of non-sphericity in the low frequency range by using parametric instead non-parametric thresholding. But we decided to perform parametric analyses as always done in previous studies using this paradigm. 

The main strengths of our study are the large sample size and assessment of euthymic patients to capture traits of suicidal vulnerability. The Cyberball game had never been used in subjects having a history of suicide attempt. Studies exploring influence of social stressors in vulnerable subjects are very relevant in suicidal process. Our results suggest a role for the left posterior insula and parietal regions in sensitivity to social exclusion as part of the suicidal vulnerability in women, and raise the question of the role of social perception and physical pain in the suicidal process. 


## Materials and Methods 
  
### Participants 
  
Three groups of euthymic female participants were recruited: (1) suicide attempters (SA)—individuals with a past history of both major depressive episode and suicidal behaviour; (2) patient controls (PC)—individuals with a past history of major depressive episode but no personal history of suicidal acts; (3) healthy controls (HC)—individuals with no past history of any major DSM-IV axis I diagnosis. 

Healthy controls were recruited through advertisement and among a list of volunteers from the Montpellier Academic hospital database. Patients were recruited among outpatients of the Department of Emergency Psychiatry & Post Acute Care from the Montpellier Academic hospital. Participants were first screened for inclusion criteria and then in person by a psychiatrist. All participants were Caucasian right-handed (as assessed by the Edinburgh scale ) females. Only females were included in this study to avoid any gender effects that may blur the results, insure a sufficient statistical power, and because most previous studies using the Cyberball game were conducted with females. 

Suicidal behaviour was defined as any act carried out with some intent to die. Diagnoses were made according to DSM-IV criteria using the Mini-International Neuropsychiatric Interview, version 5.0.0. All participants had to be euthymic at the time of scanning, as indicated by a Hamilton Depression Rating Scale score < 7 and a Young Mania Rating Scale score < 7. Other exclusion criteria were a lifetime history of severe head trauma, CNS disorder, schizophrenia, and a history of alcohol or drug abuse or dependence within the past 12 months. 

Local Ethics Committee (CPP Sud Mediterranée IV, CHU Montpellier) approved the study protocol. All experimental methods were carried out in accordance with the ethical guidelines determined by the National Ministry of Health, Labour and Welfare and the Declaration of Helsinki. All participants provided written informed consent before entering the study. Subjects received 100€ for their participation in the study. 

In total, 120 participants were examined. Two HC were unable to remain in the scanner because of anxiety. For technical reasons, data from two PC were not available. Moreover, we excluded from analyses patients taking benzodiazepines. In sum, data from 36 SA, 41 PC, and 28 HC were analyzed. 


### Clinical assessment 
  
We administered the French version of the National Adult Reading Test (NART)  to provide an estimate of verbal IQ; the Beck Depression Inventory (BDI) for a subjective measure of depressive state; the Spielberger Anxiety Scale (STAI)—state  for current level of anxiety; and the State-Trait Anger Expression Inventory (STAXI)-state  for current level of anger. The lethality and the intent of the last and the most severe (according reported medical consequences) suicidal acts were assessed with the Risk Rescue Rating Scale (RRRS) and the Suicide Intent Scale (SIS) . 

We also assessed various personality traits including impulsivity with the Barratt Impulsiveness Scale (BIS-10) , trait anger with the STAXI-trait , and trait anxiety with the STAI-trait . Finally, we measured a history of childhood maltreatment with the Childhood Trauma Questionnaire (CTQ) . 


### Cyberball Game 
  
Functional Magnetic Resonance Imaging (fMRI) scans were acquired while participants played the Cyberball game, a virtual ball-tossing game . The Cyberball game is a validated paradigm to study social exclusion and has been widely used in fMRI studies. Participants were instructed that they would play with two other players, also in fMRI scanners. In reality, participants were playing with a preset computer program and were given a cover story to ensure that they believed the other players were real. The Cyberball game comprises three successive conditions. In the first condition (Implicit Social Exclusion, ISE), the participant watched the other “players” play the Cyberball game. Participants were told that, because of technical difficulties, the link to the other two scanners could not yet be made and thus, at first, they would only watch but not play with the other two players. This cover story was intended to allow participants to view a scene visually identical to the exclusion condition (Explicit Social Exclusion, ESE) without participants experiencing exclusion by the other participants. In the second condition (inclusion, INC), participants played with the other two players and received the ball as many times as virtual players. In the final condition (ESE), participants were progressively excluded with the two other players not throwing the ball to the participant anymore. Each run consisted of 60 throws by condition, i.e. 180 throws in total for the whole session. The computer players waiting 0.5–3.0 seconds before making a throw to heighten the sense that the participant was actually playing with other individuals. ESE included 8 throws to the participant during an initial transition phase toward total exclusion. 

Following completion of the Cyberball task, participants completed the Need-Threat Scale (NTS)  to measure social distress associated with being excluded during the game. The NTS assesses 12 subjectively experienced consequences of being excluded during the game, including ratings of self-esteem (“I felt liked”), belongingness (“I felt rejected”), meaningfulness (“I felt invisible”), and control (“I felt powerful”), on a scale ranging from 1 = “not at all” to 5 = “very much”. Items were reverse-coded when appropriate and averaged to create a composite score. 


### Image Acquisition 
  
Imaging acquisition was done in the Neuroradiology Department - I2FH (Academic Hospital of Montpellier) - using a 1.5T whole-body MRI system (MAGNETON AVANTO, Siemens, Erlangen, Germany) equipped with a standard 12-channel receive-only head coil. Sixty volumes of BOLD echo planar images (EPI) were obtained during the Cyberball Game. Gradient-Echo EPI images characteristics were as follows: TR = 2 sec, TE = 40 ms, FOV = 220 mm, 25 axial slices (5 mm slice thickness), slice gap = 0.5 mm, voxel size = 3.43 × 3.43 × 5 mm, flip angle 90°. The slices were covering a region extending from the vertex to lower parts of the cerebellum. 

A 3D magnetization-prepared, rapid acquisition gradient echo (MP-RAGE) sequence was also obtained for each participant with the following parameters: TR = 2100 ms, TE = 4.1 ms, IR = 1100 ms, 15° flip angle, PAT = 2, aligned with the corpus callosum, voxel-size 0.98 × 0.98 × 1 mm, 160 transversal slices. 


### fMRI Data Analysis 
  
Data were analyzed using SPM12 (Wellcome Department of Imaging Neuroscience, London, UK) implemented in Matlab R2015 (Mathworks, Inc., Natick, MA) using a block-designed model. The 5 first volumes of each fMRI run were discarded due to the time of launch of the Cyberball task synchronized with fMRI acquisition. The following 55 volumes were retained for functional analysis for each condition (ISE, INC and ESE). In total 165 volumes were analyzed. EG-EPI data were re-oriented to the anterior commissure, slice-time corrected, realigned to the first volume, co-registered, normalized to T1 template (provided by Montreal Neurological Institute MNI), and smoothed with an 8-mm FWHM Gaussian filter. 

Contrast images were estimated for ESE vs. INC, ISE vs. INC and ESE vs. ISE conditions for every participant using a first-level general linear model. Realignment parameters have been added in the regressor to remove specific activation of head movement of the subject and 128 seconds high-pass filter was used to remove non-physiological slow signal shifts. To check the validity of our experiment, we first conducted a one-way ANOVA at the whole brain level for the main effect of condition in HC. Significance threshold was set at voxel level p < 0.05, family-wise error (FWE) corrected for multiple comparisons with k ≥ 10 voxels. Then, we conducted a twoway mixedmodel ANOVA, at the whole-brain level for the interaction between Group and Condition. Significance threshold was set at voxelwise FWE-corrected p < 0.05, with k ≥ 10 voxels. Post hoc tests were performed using two sample T-tests with an inclusive mask of regions showing a significant group by condition interaction in the ANOVA (voxel p-uncorrected p < 0.001, k ≥ 10 voxels). The website   http://sprout022.sprout.yale.edu/mni2tal/mni2tal.html   and xjView toolbox were used for anatomical localization. Coordinates are reported in Talairach space. Beta values were then extracted to measure correlations with social distress scores and clinical variables. 


### Statistical Analyses 
  
Clinical and behavioral analyses were carried out with SPSS Statistics 23 (SPSS, Inc., Chicago). Clinical and behavioural quantitative data were compared between the three groups with Kruskal-Wallis tests and between pairs of groups with Mann-Whitney U tests. Associations between qualitative variables and groups were calculated with chi-square tests. All correlation analyses of brain activation with clinical measures were conducted using Spearman test. The alpha level was set   a priori   at 0.05. 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-38'>
<h2>38. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31157395/' target='_blank'>31157395</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Investigation of functional brain network reconfiguration during vocal emotional processing using graph-theoretical analysis</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Soc Cogn Affect Neurosci</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1093/scan/nsz025</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6545541/' target='_blank'>6545541</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study used functional MRI during a task where participants listened to and processed vocal emotional (prosody) stimuli — a form of social communication/perception of others’ emotions, matching the review’s social-related constructs. Participants were healthy adults (N=36, ages 20–35). Analyses were whole-brain: FC computed across the Power-264 atlas with graph-theoretical measures (nodal, global, and interregional whole-brain results), not limited to ROIs. No exclusion criteria are met (not solely ROI analyses; healthy group reported separately). Therefore it meets all inclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Vocal expression is essential for conveying the emotion during social interaction. Although vocal emotion has been explored in previous studies, little is known about how perception of different vocal emotional expressions modulates the functional brain network topology. In this study, we aimed to investigate the functional brain networks under different attributes of vocal emotion by graph-theoretical network analysis. Functional magnetic resonance imaging (fMRI) experiments were performed on 36 healthy participants. We utilized the Power-264 functional brain atlas to calculate the interregional functional connectivity (FC) from fMRI data under resting state and vocal stimuli at different arousal and valence levels. The orthogonal minimal spanning trees method was used for topological filtering. The paired-sample   t  -test with Bonferroni correction across all regions and arousal–valence levels were used for statistical comparisons. Our results show that brain network exhibits significantly altered network attributes at FC, nodal and global levels, especially under high-arousal or negative-valence vocal emotional stimuli. The alterations within/between well-known large-scale functional networks were also investigated. Through the present study, we have gained more insights into how comprehending emotional speech modulates brain networks. These findings may shed light on how the human brain processes emotional speech and how it distinguishes different emotional conditions. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (37745 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Emotion is one of the crucial cognitive factors that affect our daily life and social interaction. Various facial and vocal expressions convey the emotion during social interaction. Thus, comprehending these emotional expressions and their underlying neural mechanism is essential to modern society and to build new communication technologies. Several prior neuroimaging studies have aimed to elucidate the neural mechanism foremotional processing; however, most of them have studied emotion based on facial expressions and visual stimuli ( ;  ). Of late, several neuroimaging studies have focused on vocal emotion. Functional magnetic resonance imaging (fMRI) studies have shown that emotional prosody (especially emotions such as anger) consistently activates amygdala as well as numerous brain regions in the lateral temporal lobe and frontal lobe ( ;  ;  ;  ). Additionally, electrophysiological [electroencephalography (EEG) and magnetoencephalography (MEG)] studies using event-related potentials have strived to delineate the neural dynamics related to the effects of vocal emotions. For example,   suggested that valence information is decoded during early processing, while arousal effects occur at a later stage of processing. 

In addition to changes in regional brain activity, emotional perception may also alter the interregional functional connectivity (FC) as well as the brain network topology. At the connectivity level, studies have employed FC analysis and investigated reorganized FC induced by emotional processing ( ;  ;  ;  ;  ). At the network level, the recent advancement in computational approaches, especially graph-theoretical analysis, has provided the means to characterize the brain network topology ( ). Several studies have used graph-theoretical analysis to investigate the alteration of brain networks when interpreting facial emotional expressions that have shown significant changes of global efficiency and clustering coefficient (CC) compared with the resting state ( ;  ). Compared with regional functional activation, connectivity-based and network-based studies may help us gain more insights into the neural mechanism of emotion and learn how emotion may modulate the cognition states. Currently, a growing body of evidence supports the affective workspace hypothesis, suggesting that either positive or negative affective state is not necessarily associated with activating a specific set of regions ( ;  ). Alternatively, it can emerge as ‘brain state’ at the population level. Therefore, to strengthen the validity of this hypothesis, it is essential to understand how emotion-related cortical regions interact during processing of emotional information. 

Several studies have explored the alteration of network topology due to facial emotional expressions, but not much is known about the effects of vocal emotional stimuli on brain networks at connectivity and network topological levels. Therefore, to explore the vocal emotion and its underlying neural mechanism, this study has the following three objectives. First, we sought to examine the feasibility of graph-theoretical analysis on fMRI data with vocal emotional stimuli. Second, we sought to explore whether vocal emotional stimuli induce any alteration of brain networks—at both network topological and connectivity levels. We also investigated the differences within/between well-known large-scale functional networks. Third, we sought to investigate whether there is any difference in network topology between the resting state and the ones induced by vocal emotional stimuli. 


## Materials and methods 
  
### Participants 
  
A total of 36 healthy volunteers (27 male and 9 female) participated in our study. Furthermore, to reduce the risk of possible confounding factors, the participants were recruited based on several criteria: being free of any brain disease or major brain injury, age ranging between 20 and 35 years and a college or higher-level education to understand the vocal emotion stimuli pronounced in English. Furthermore, we only recruited right-handed subjects to exclude any potential variability due to handedness. The Institutional Review Board at National Health Research Institutes approved this study, and all volunteers provided informed consent. 


### Experimental stimuli 
  
The vocal emotion stimuli were generated from part of the USC IEMOCAP database ( ). The audio data from IEMOCAP database consist of recordings of scripted or spontaneous speech during dyadic interaction between a pair of voice actors. Naive raters rated each recording with attributes including valence, arousal and dominance with the continuous rank from 1 to 5. For our study, we used the scripted dialogs by a chosen male voice actor whose recordings yielded the highest variability in the speech attributes among all voice actors. From 639 segments spoken by the selected voice actor, we selected 251 voice segments as the stimuli for our experiments. 

We categorized the stimuli into two types of emotional attributes, namely, arousal and valence, and designed three conditions for each feature. Each experiment comprised six 5 min vocal emotion stimuli and a 1 min break between any two stimuli. For the arousal attribute, the conditions were categorized into low (value ≤ 2.5), medium (2.5 < value < 3.5) and high (3.5 ≤ value) levels. For the valence attribute, the conditions were negative (value ≤ 2.5), neutral (2.5 < value < 3.5) and positive (3.5 ≤ value) levels. For each condition, the speech segments with the given attribute and level were shuffled to remove any contextual information and were then concatenated to form a 5 min continuous vocal emotional stimulus. The participants were asked to pay attention to the speech-based stimuli without being informed of the purpose or the details of the experiment. 


### Image acquisition 
  
MR experiments were performed on a 3T MRI scanner (Prisma, Siemens, Erlangen, Germany) at National Taiwan University. Each scanning session included T1-weighted imaging (T1WI), resting-state fMRI (rs-fMRI) and task-evoked fMRI (t-fMRI) of all vocal emotional stimuli. The T1WI protocol was employed using a magnetization-prepared rapid gradient-echo sequence with repetition time (TR) of 2000 ms, echo time (TE) of 2.3 ms, inversion time (TI) of 900 ms, flip angle (α) of 8°, voxel size of 1 × 1 × 1 mm , matrix size of 256 × 256 and 192 slices. Each fMRI scan with blood oxygen level-dependent (BOLD) contrast was acquired using gradient-echo echo-planar imaging sequence with TR/TE of 3000/32 ms, α of 90°, voxel size of 2.5 × 2.5 × 3 mm , matrix size of 96 × 96, 40 slices and 100 repetitions. 


### Data pre-processing 
  
Before network analyses, all rs-fMRI and t-fMRI data sets were pre-processed using DPARSF toolbox ( ). The pre-processing procedures included the removal of the first 10 volumes, slice-timing correction, co-registration to T1WI, covariate regression of head motion, white matter signals and cerebrospinal fluid signals, nonlinear spatial normalization using T1WI, linear detrending and band-pass filtering (0.01–0.1 Hz). To estimate the FC over the whole brain, brain regions were parcellated using the Power-264 functional atlas ( ), which comprises 264 putative functional regions-of-interest (ROIs) associated to 13 large-scale functional networks and a group of unlabeled regions ( ). We also provide the region definitions used in Automated Anatomical Labeling (AAL) atlas ( ) and reported the corresponding anatomical locations of functional ROIs using the definitions by the AAL atlas. The averaged time series of each putative functional ROI defined in Power-264 functional atlas was derived by averaging the pre-processed rs-fMRI signals within the ROI. The pairwise between ROI FC was derived by quantifying the temporal dependency between two extracted averaged time series. We computed two types of FC measures—Pearson’s correlation (PC) and covariance (COV). It should be noted that the negative FCs were excluded in the following analysis, i.e. only positive FCs were used. Subsequently, we employed the orthogonal minimal spanning trees (OMSTs) method on constructed FC matrices to filter out spurious connections ( ;  ). Briefly, the OMSTs iteratively extract the minimal spanning trees from a given graph, and the filtered graph is the aggregate of OMSTs that maximizes the global efficiency subtracted by the wiring cost of the brain network. Compared with the conventional sparsity thresholding method based on either a given FC value or a network sparsity, the OMSTs method is parameter-free and more reproducible in group-wise or even individual-level brain network ( ;  ). 
  
Abbreviations of the large-scale functional networks defined in Power-264 functional atlas 
  

### Graph-theoretical analysis 
  
After applying OMSTs, the graph-theoretical analysis was employed to derive both nodal and global graph-theoretical network measures from the filtered FC matrices. The nodal network measures used in this study are degree centrality (DC), CC ( ), local efficiency (E ) ( ) and PageRank centrality (PR) ( ). In addition to investigating the network attributes at nodal scale, we also examined the network attributes at the global scale—the whole brain—using a set of global graph-theoretical network measures. The global network measures in our study includes characteristic path length ( ), global efficiency ( ), mean local efficiency ( ), mean clustering coefficient ( ), transitivity ( ) ( ), modularity ( ) and assortativity coefficient ( ) ( ), in addition to the network wiring cost ( ). We provided the detailed definitions of network measures in the  . One can also refer to a previous review article for more details ( ). We also performed an analysis of complementarity among different network measures and provided the discussion in the  . 


### Statistical analysis 
  
In this study, we sought to explore the topological reconfiguration of t-fMRI networks with vocal emotional stimuli and rs-fMRI networks. By categorizing these vocal emotional stimuli into multiple arousal and valence levels, we further investigated the relationship within and between these levels, as well as their differences with the resting-state condition. The comparisons were performed at nodal network, global network and FC levels. As for each well-known large-scale functional network, we calculated the averaged nodal measures across its member ROIs, the averaged intra-network FC and inter-network FC connecting to other functional networks. Except the above analyses, we also performed the analysis of common connections across all subjects for each specific arousal, valence or resting-state condition and discussed in the  . All statistical analyses of the FC and graph-theoretical network measures were performed using the paired-sample   t  -test. All significant levels were subsequently adjusted for multiple comparisons jointly across 264 ROIs and 6 pairs of conditions (either resting-state and 3 arousal levels or resting-state and 3 valence levels) using Bonferroni correction. 



## Results 
  
### Investigation on nodal network measures 
  
 shows the statistical comparisons of the nodal network measures among different t-fMRI and resting-state conditions. Note that we denoted the type of FC in superscripts for a given network metric in the following sections. For example,   denotes the DC calculated using PC as definition of FC. For t-fMRI with arousal stimuli, significantly reduced   of low-arousal condition was found in an ROI (in STG.R) within the auditory network by comparing with resting-state condition. However, no significant differences among those arousal and resting-state conditions were found by using all nodal network measures derived from COV. For t-fMRI with valence stimuli, significant differences of nodal network measures were only found between neutral- and negative-valence conditions. Compared to neutral-valence condition, our results show decreased   in one ROI (located between MOG.L and IOG.L) within the visual network,   in one ROI (between DCG and SMA.L) within the hand sensory/somatomotor network and   in three ROIs (one in IOG.R, one between ITG.R and IOG.R and one between CUN.R an PCUN.R) in visual network of negative-valence condition. 
  
The statistical comparisons of nodal network measures among different task-evoked, (a) arousal stimuli and (b) valence stimuli and resting-state conditions. All   P  -values were corrected for multiple comparison across the arousal–valence levels by Bonferroni correction (  P   < 0.01;   P   < 0.001). For each ROI, both of the corresponding network in Power-264 atlas and the corresponding regions in Automated Anatomical Labeling atlas were shown. Please see   for abbreviations of AAL region 
    
The statistical comparisons of global network measures among different task-evoked, (a) arousal stimuli and (b) valence stimuli and resting-state conditions. All   P  -values were corrected for multiple comparison across the arousal–valence levels by Bonferroni correction (  P   < 0.01;   P   < 0.001) 
  

### Investigation on global network measures 
  
 shows the statistical comparisons of the global network measures among different t-fMRI and resting-state conditions. For t-fMRI with arousal stimuli, the high-arousal condition showed increased  ,  ,   and   compared to mid-arousal condition. The decreased   was also found in high-arousal condition compared to mid-arousal condition. Compared to low-arousal condition, increased   was found in high-arousal condition. However, no significant between-condition difference of global network measures was found by utilizing  as definition of FC. For t-fMRI with valence stimuli, significant between-group differences of global network measures were found mainly in negative-valence condition compared to other valence or resting-state conditions. For utilizing COV as FC definition, the altered global network measures includes increased   and decreased   (compared to all other conditions), decreased  ,   and   (compared to resting-state and neutral-valence conditions). For utilizing PC as FC definition, decreased  ,  ,   and increased   (compared to neutral-valence condition) were found. No significant between-condition difference of  ,   nor   was found among all comparisons. 


### Investigation on interregional FC 
  
In addition to network metrics—either nodal or global—we also performed the between-condition comparisons of interregional FC (PC based and COV based). For arousal stimuli, significant between-condition differences were found by using PC-based FC, while no significant between-condition differences were found by using COV-based FC. Compared with resting-state condition, significantly reduced PC-based FC were found in either low- or high-arousal condition for Aud, SM.M, SM.H, DA, VA and Vis networks, as shown in  . For valence stimuli, significant between-condition differences were found by using both PC-based and COV-based FC. By comparing the resting-state and positive-valence conditions, the significantly different connection with PC-based FC was found between DA and DMN. Most of the significant between-condition differences were found to associated with reduced FC in negative-valence condition, including Vis-FP (resting-state > negative-valence; neutral-valence > negative-valence), Vis-DMN (resting-state > negative-valence), SM.H-Vis (neutral-valence > negative-valence), SM.M-CO (neutral-valence > negative-valence) and DA-Vis (neutral-valence > negative-valence). Two significantly different connections with increased FC in negative-valence condition were found in intra-DMN (resting-state < negative-valence) and SM.H-CO (positive-valence < negative-valence). For COV-based FC, a significantly different connection was found between DMN and Vis (negative-valence < neutral valence;  ). 
  
Significant changes of FC associated with arousal stimuli and resting state. Blue and red lines signify decrease and increase of connectivity in the latter condition compared with the former condition, respectively. For having a better visualization, the ROIs are reordered and colored according to their correspondence to the large-scale functional networks. Please see   for the abbreviations of the functional networks. Note that we excluded CB in the illustration. All FCs are corrected for multiple comparisons across arousal levels using Bonferroni correction. 
    
Significant changes of FC associated with valence stimuli and resting state. Blue and red lines signify decrease and increase of connectivity in the latter condition compared with the former condition, respectively. For having a better visualization, the ROIs are reordered and colored according to their correspondence to the large-scale functional networks. Please see   for the abbreviations of the functional networks. Note that we excluded CB in the illustration. All FCs are corrected for multiple comparisons across valence levels using Bonferroni correction. 
  

### Investigation on large-scale functional networks 
  
 shows the statistical comparisons of averaged nodal network measures within well-known large-scale functional networks among different conditions. No significant difference was found in the arousal condition. In contrast, significant differences of averaged nodal network measures were found to be mostly associated with negative-valence condition. Compared with the neutral-valence condition, decreased averaged nodal network measures were found in negative-valence condition, including   and   in SM.H,   in DMN and  ,   and   in Vis for both FC definitions. Additionally, increased   in MR and decreased   in Vis were found in negative-valence condition by comparing with the neutral-valence and resting-state conditions, respectively.   shows the inter-network and intra-network comparisons of FCs. The alterations of FCs were only found in t-fMRI with valence stimuli, and most of them were associated with the negative-valence condition. A total of five inter-network alternations of PC-based FC were found, including VA-Sub (resting-state < positive-valence), CO-DA (positive-valence < negative-valence), Sub-FP (positive-valence < negative-valence), Aud-SM.M (neutral-valence > negative-valence) and Vis-DA (neutral-valence > negative-valence). In contrast, the only intra-network alteration was found in Vis (neutral-valence > negative-valence) by using COV-based FC. 
  
The statistical comparisons of averaged nodal network measures within large-scale functional networks among different task-evoked and resting-state conditions. All   P  -values were corrected for multiple comparison across the arousal–valence levels by Bonferroni correction (  P   < 0.01;   P   < 0.001). 
    
Significant changes of averaged intra-network or inter-network FCs with respect to the 12 large-scale functional networks (without CB and unlabeled) associated with the valence stimuli and resting state. Both PC- and COV-based FCs were investigated. Blue and red lines signify decrease and increase of connectivity in the latter condition compared with the former condition, respectively. For having a better visualization, the ROIs are reordered and colored according to their correspondence to the large-scale functional networks. Please see   for the abbreviations of the functional networks. All FCs are corrected for multiple comparisons across valence levels using Bonferroni correction. 
  


## Discussion 
  
Our study demonstrates that perception of emotional speech could modulate brain network topology in several cortical regions associated with emotion processing. We also found the altered global network topology among different task-based and resting-state conditions. Beyond regional level, we further investigated the alterations of network metrics and FCs within/between large-scale functional networks and reported our findings. To our knowledge, this is the first study that investigates the effects of vocal emotional stimuli on brain network topology using graph-theoretical analysis of fMRI data. These findings may shed light on how the human brain processes emotional speech and how it distinguishes different emotions. In the following sections, the results from our analysis and their interpretations are elaborated. Also, the limitations of the experimental design and data interpretation are discussed. 

### Task-related alterations in nodal network measures 
  
Results for valence stimuli revealed a tendency that the network topology was significantly altered under the negative-valence condition compared with that of neutral valence or resting state, suggesting that the negative-valence stimuli may modulate or reorganize the brain network. In addition, we should note that alterations of averaged network measures in the large-scale functional networks are highly consistent with that by investigating individual ROIs, further supporting our findings. One interesting finding from the experiments with valence stimuli was that the reductions of functional segregation (  and  ) were observed in the visual network. These alterations were observed in several individual ROIs in visual network and from investigating the averaged measures in visual network. A meta-analytic review by   has reported that a group of visual sub-regions would be activated under visual emotional stimuli. Furthermore, we hypothesized that these visual sub-regions could be stimulated by not only visual stimuli but also other modalities. A similar hypothesis has been introduced in an fMRI study by   in which activation in CUN was observed under attended anger prosody compared with neutral or unattended anger prosody. Therefore, we speculated that the alteration of network topology may be resulted from the complex cross-modal interactions during emotional processing. One possible explanation about cross-modal interactions in our case is the visual mental imagery triggered by the speech stimuli. A previous fMRI study showed that the mental imagery evokes greater emotional response than verbal representation ( ). Another fMRI study by   also revealed that the visual imagery is crucial for sentence comprehension. Essentially, the theory of multimodal mental imagery has been supported by a growing body of evidence. For instance, an fMRI study by   showed that using silent visual speech stimulus (facial videos during speech overlaid with written pronunciation) could activate primary auditory cortex. Other than visual mental imagery, a few studies have also reported different kinds of cross-modal interactions during emotional processing.  ,   have reported that visual attention could be modulated by anger prosody. Another EEG study by   also showed that the cross-modal prediction of emotion exists in the multimodal processing of audiovisual emotion. Based on these previous studies, we could suggest that a similar cross-modal interaction mechanism to alter the network topology might also be revealed in visual sub-regions. However, a more sophisticated experimental design in further study would be needed to verify our speculation. 

We also observed significantly reduced nodal functional segregation (  and  ) in the sensorimotor network by comparing negative-valence and neutral-valence conditions. These alterations were found in one ROI in the hand sensorimotor network and by investigating the averaged network measure of the mouth sensorimotor network. Consistently, previous studies have also reported the association of sensorimotor network with speech, language and emotional processing ( ;  ;  ). A study using transcranial magnetic stimulation suggested the role of supplementary motor area in movement control triggered by emotional stimuli ( ). An fMRI study showed that the vocal emotion was associated with the BOLD responses in emotion, attention and sensorimotor circuits, in addition to the inter-subject synchronization within somatosensory and supplementary motor cortices ( ). Intense emotion can trigger corresponding physiological and bodily response through sensorimotor and visceral nervous systems ( ;  ;  ). Therefore, it is reasonable to speculate that the alterations in sensorimotor network were likely due to the increased demand for physiological and bodily emotion response. 


### Task-related alterations in global network measures 
  
Our results showed that vocal emotional stimuli altered not only nodal network measures but also global network measures. For arousal stimuli, significant increases of functional integration (increased   and decreased  ) and segregation (increased  ,  , and  ) were found in high-arousal condition compared with low- and mid-arousal conditions. For valence stimuli, significantly reduced functional integration and segregation were found in negative-valence condition compared with all the other conditions (neutral valence, positive valence and resting state). We hypothesized that the brain network for processing emotional speech with high-arousal condition might intrinsically exhibit distinct level of functional integration and segregation as compared with other conditions or resting state. In this case, the brain network under high-arousal condition may show higher degree of integration and segregation, while the task-negative resting-state network is being suppressed. However, the brain network under low- or mid-arousal condition may be presented as a mixed pattern of task-positive and resting-state networks. Having different combinations of task-positive and resting-state networks may contribute to our speculation about the altered global network topology between high-arousal and the other two arousal levels. 

Similarly, the brain network to process the negative-valence vocal emotion stimuli may be characterized by reduction in network integration and segregation. Our results generally showed reduced network integration and segregation in negative-valence conditions compared with the resting state. Previous studies have attempted to understand the underlying mechanism and investigate the relationship between task-specific and resting-state networks further.   compared the global network measures of a task-general and meta-analytic coactivation network to a group-averaged resting-state network and reported reduced clustering, reduced modularity and increased efficiency. Recently,   used binarized PC matrix for studying the change of brain network topology under seven different kinds of functional tasks, which showed significant increases in global efficiency in all functional tasks compared with resting state. Another specific study by   investigated the network topology during the semantic matching task and resting state using binarized correlation matrices. Their results showed reduced global efficiency, reduced normalized global efficiency, increased E  and increased nodal centrality.   used alphabet recognition tasks and discovered reduced normalized CC compared with that of resting state. Although the experimental designs and targeted network measures of these previous studies do not converge in details, a general tendency that we could summarize from these studies is that most task-related networks would exhibit increased efficiency—in contrast to our findings. This controversy may arise from experimental designs, pre-processing of graph theoretical analysis, computation of network measures and statistical comparison approaches. A further study is needed to clarify these effects of data processing. 


### Task-related alterations in FC 
  
Our results also showed altered interregional FC in several connections. For arousal stimuli, reduced FC was mostly found in those connections associated with the auditory network, mostly involving superior temporal gyrus (STG). This finding may suggest that the reduced FC centered to these regions could be a result of configuration switching between resting-state and task-positive networks. Several sub-regions within STG, e.g. primary auditory cortex and Wernicke’s area, are known to be responsible for processing auditory and language information. Functionally, STG is responsible for language processing, which may also contribute to the altered FC under task-related conditions ( ;  ). In our current results, the altered FC related to STG may reflect that the patterns of network topology are different between vocal emotion modulation and resting state. However, our results cannot fully explain the association between STG and vocal emotional processing. Other than STG, we also observed that the   and   in TPOmid.R under high-arousal condition were significantly lower than those under mid-arousal condition. Interestingly, previous studies have suggested the temporal pole was associated with the social and emotional processing, including face recognition and theory of mind ( ;  ). Although the association between the temporal pole and vocal emotional processing is not clear yet, we could speculate that the arousal levels of vocal emotion stimuli may alter the network topology and result in altered nodal network characteristics in temporal pole. For valence stimuli, significantly reduced COV-based interregional FC and mean intra-network FC was found in several connections within the visual network by comparing negative-valence to neutral-valence conditions—consistent with our findings in the nodal network topology, further supporting our hypothesis of cross-modal mental imagery altering the network topology in visual-associated regions. We should note that the alterations of averaged network measures in the well-known large-scale functional networks and mean inter-network/intra-network FCs were highly consistent with those observed by investigating individual ROIs, especially in the visual and sensorimotor networks. The observations among large-scale functional networks further solidified our findings in FCs, nodal and global network metrics. 


### Investigation on complementarity of network measures 
  
Since we incorporated a series of nodal and global network metrics that may be used to quantify similar network topological characteristics in theory, it was of great interest to explore the complementarity between these network metrics. How they complement each other to form a more concrete delineation of the overall brain network topology would be beneficial for our current study. Thus, we also analyzed the similarity between different nodal network metrics using correlation analysis and also compared these between-metric similarities from two different pre-processing procedures, i.e. OMSTs and sparsity thresholding (see   for details). Our results generally showed that the network metrics used to characterize the same topological attribute could be highly correlated even if they have different theoretical definitions. For example, E  was calculated based on the shortest path length and CC was based on triangles; however, these two metrics were highly correlated in our case. Although these metrics were highly correlated, E  revealed more between-condition differences than other metrics that also measured the functional segregation in this study. We could summarize that, in our study, the network metrics for characterizing the same topological attribute could still provide complementary information, e.g. sensitivity to differentiate subtle alterations between conditions, even if they were highly similar in their quantities. It would be beneficial if all metrics were calculated and included in providing more insights into the complex brain network architectures. 


### A comparison between PC- and COV-based FC 
  
We also investigated the influence of two kinds of FCs—PC and COV—on brain network topology. Interestingly, it was revealed that the analyses using these two FCs could provide non-redundant information for depicting the brain networks under different task-related and resting-state conditions. For nodal network measures, PC and COV reflected the influences of arousal and valence stimuli on brain network topology, respectively. For global network measures, the influences of both arousal and valence stimuli were only revealed by COV. For FC, PC revealed most of the alterations induced by arousal stimuli, whereas COV revealed most of the alterations induced by valence stimuli. By definition, assuming two independent variables X and Y, PC(X,Y) is equivalent to COV(X,Y) divided by the products of the variances of those two variables ( ). In other words, the calculation of COV considers both the signal amplitudes and variations, while PC is a dimensionless measure that decouples the effect of the signal variations. Therefore, PC and COV could reflect different aspects of functional dependency in principle and then result in non-redundant observations. 

Here, we give two scenarios where the observations of PC and COV may not converge. In some cases where the alteration of signal variances is irrelevant to the stimulation, COV may show a lower significance level than PC due to the inclusion of signal variances. In other cases where the alteration of signal variances is highly relevant to the stimulation, COV may show a higher significance level than PC. Considering the nature of definitions, we speculate that the network modulation under arousal stimuli is less relevant to the alteration of signal variations, while network modulation under valence stimuli is mostly contributed by the alteration of the amplitude of signal fluctuations. To date, choosing optimal FC measures for graph-theoretical analysis remains challenging. Our study demonstrates that the use of multiple FC measures may be a better approach to address the complex network and could provide complementary perspectives on the task-related reconfiguration of a network. 


### Limitations 
  
In this investigative study, we have shown that the different levels of emotional speech stimuli may alter or modulate the brain networks on either a nodal or global scale. Although we suggest that brain network analysis could have the potential to resolve the vocal-emotion-induced topological changes, several limitations must be carefully discussed. The first limitation may come from the cultural difference between the volunteers who rated the emotional scales in the IEMOCAP data set and the participants involved in this study. The cultural difference arising from native languages and environmental factors may play a major role in comprehending the emotional speech, which might be the major confounding factor in this exploratory study. The second limitation is the design of vocal emotional stimuli, in which we tried to mimic the real-world scenarios. However, this experimental design might be too complicated to rule out some other mental confounding factors. Considering both limitations, one should use the speech database with the same native language as that of the participants involved in the experiments to investigate better the effects of vocal emotional stimuli on brain network topology. Furthermore, the scenarios of the functional stimuli should be divided into several simplified sections so one could investigate each phenomenon separately. Additionally, it is also worth noting that the method used in this study assumes a static topology under a given type of stimuli. However, it is highly likely that such an assumption does not hold—for brains are dynamic systems. Notably, several studies have also investigated how functional networks change and evolve with time using dynamic FC ( ;  ).   also performed whole-brain dynamic connectivity analysis for studying the effects of emotional speech on dynamic changes of brain networks. It is highly likely that considering the dynamic nature of the brain network would provide a more valid analysis and allow for studying dynamic changes in brain states. However, some careful analysis design is required to apply high-level network analysis to a dynamic network. Furthermore, the emotional stimuli used in our study were attributed to a simple two-dimensional model (i.e. arousal and valence). However, it is also possible to extract emotion-related features directly from the stimuli ( ). In fact, it has been shown that emotion recognition using EEG signals can be facilitated by incorporating features extracted from the stimuli ( ;  ;  ). Therefore, we postulated that by incorporating sound features extracted from the speech stimuli, we could achieve a more comprehensive analysis of various aspects of emotions during the speech. 



## Conclusions 
  
In this study, we investigated the modulation of brain networks under emotional speech perception using high-level graph-theoretical network measures. With the use of OMSTs approach and Power-264 functional atlas, we discovered that brain network exhibits significantly altered network attributes at global, nodal and connectivity levels, especially under emotional speech with high arousal or negative valence. We also investigated the alterations of network metrics and FCs within/between large-scale functional networks and found that most of alterations were associated with negative valence. To the best of our knowledge, this is the first study employing a graph-theoretical analysis of emotional speech perception. Although this is predominantly an investigative study, we have gained crucial insights into how comprehending emotional speech modulates brain networks. Additionally, this study provides directions for high-level network analysis on emotional speech comprehension or possibly other types of brain functions. 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-39'>
<h2>39. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22768085/' target='_blank'>22768085</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Neural Network Development in Late Adolescents during Observation of Risk-Taking Action</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2012</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0039527</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3387168/' target='_blank'>3387168</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study reports a functional MRI experiment where healthy late-adolescent participants (N=25; age range 18y1m–22y8m) viewed and judged risk-taking versus safe hand actions—an action observation task tapping social cognition/perception and understanding of others. Participants are healthy undergraduates (no psychiatric/neurological disorders). Whole-brain voxelwise analyses were conducted (SPM8; risk-taking vs. safe contrasts; whole-brain thresholding reported), not ROI-only. Results for the healthy participant group are reported separately. Therefore it satisfies: (1) a social-related fMRI task (action observation/social cognition), (2) healthy sample within the 17–65 age criterion, and (3) whole-brain analyses. No exclusion criteria are met (no ROI-only analyses; no clinical-only reporting).</p>
<p><strong>Fulltext Confidence:</strong> 0.93</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Emotional maturity and social awareness are important for adolescents, particularly college students beginning to face the challenges and risks of the adult world. However, there has been relatively little research into personality maturation and psychological development during late adolescence and the neural changes underlying this development. We investigated the correlation between psychological properties (neuroticism, extraversion, anxiety, and depression) and age among late adolescents (  n   = 25, from 18 years and 1 month to 22 years and 8 months). The results revealed that late adolescents became less neurotic, less anxious, less depressive and more extraverted as they aged. Participants then observed video clips depicting hand movements with and without a risk of harm (risk-taking or safe actions) during functional magnetic resonance imaging (fMRI). The results revealed that risk-taking actions elicited significantly stronger activation in the bilateral inferior parietal lobule, temporal visual regions (superior/middle temporal areas), and parieto-occipital visual areas (cuneus, middle occipital gyri, precuneus). We found positive correlations of age and extraversion with neural activation in the insula, middle temporal gyrus, lingual gyrus, and precuneus. We also found a negative correlation of age and anxiety with activation in the angular gyrus, precentral gyrus, and red nucleus/substantia nigra. Moreover, we found that insula activation mediated the relationship between age and extraversion. Overall, our results indicate that late adolescents become less anxious and more extraverted with age, a process involving functional neural changes in brain networks related to social cognition and emotional processing. The possible neural mechanisms of psychological and social maturation during late adolescence are discussed. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (48242 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
 Late adolescence   is a unique and important period for human development. Erikson (1994) examined the concept of   identity   in relation to late adolescence  ,  . Although Erikson considered identity formation to be a life-long process, he emphasized late adolescence as a key stage in his developmental theory, constituting a particular critical development period when a sense of personal and social identity becomes integrated through ‘identity crisis’. Newman and Newman (2007, 2009) redefined Erikson’s criteria regarding developmental stages, dividing adolescence into early and late adolescence, such that late adolescence (18–24) is distinguished from adolescence (12–18)  ,  . Erikson theorized that identity develops when young people are given a psycho-social ‘moratorium’, referring to an opportunity in which they can experiment with different social roles before making permanent commitments to an occupation, to intimate relationships, to social groups and communities, and to a philosophy of life. This ‘moratorium’ period   closely corresponds to ‘college age’; attending college provides students with consciousness-raising experiences to learn about themselves and others through exposure to diverse perspectives, opinions, and ways of living  ,  ,  . Examining psychological changes in college-age late adolescents is valuable in elucidating the ongoing process of human identity integration or maturity  ,  ,  . 

Understanding the late adolescence period is also of particular importance because dynamic psychological changes, such as human identity integration or maturity, continue throughout this period, as social and affective instabilities are overcome. Contrary to a long-held assumption that the brain is largely mature by the end of childhood, recent neuroimaging studies have provided increasing evidence that adolescence involves profound brain growth and change  ,  . For example, increases in white matter volume have been reported throughout childhood and adolescence, particularly in the prefrontal and parietal cortices (e.g.,  ,  ,  ,  ,  ,  ,  . In addition, grey matter volume has been reported to increase in the prefrontal and parietal cortices during the preadolescent stage, followed by a steady decline during late adolescence  ,  . These findings indicate that brain development in adolescence is not linear, and that the brain volume of a typical early adolescent is measurably different to that of a typical late adolescent. In addition, these findings suggest that brain regions involved in planning, decision-making, cognitive reasoning, or controlling impulses and emotions undergo refinement through adolescence at least into a person’s twenties (i.e., late adolescence). 

In addition to the morphometric studies discussed above, behavioral techniques have been used to examine brain development during late and post adolescence. For example, a behavioral study using a mentalizing task requiring theory of mind and executive function reported that social abilities like ‘theory of mind’ continue to improve from adolescence to adulthood  , further suggesting that developmental changes continue throughout the late adolescent phase. Another study using a gambling task reported that the rate of risky choices did not significantly change between early (12–15 y.o.) and mid (15–18 y.o.) adolescence, but was significantly reduced in adulthood (25–35 y.o.)  . These findings indicate that a profound ‘shift’ in cognitive or emotional regulation ability during late adolescence may occur in the transition from adolescence to adulthood. Functional neuroimaging studies of mental-state attribution have reported decreases in frontal cortex activity between adolescence and adulthood  , providing further evidence that a developmental shift occurs during late adolescence, i.e., from adolescence to adulthood. A similar discrepancy between adolescence and adulthood has been observed in the neural correlates of emotional processing. For example, in processing fearful facial expressions, adolescents were found to exhibit a strong reliance on the emotional network in the brain, while adults tended to rely more on an attentional network  . In addition, adults, compared with adolescents, exhibited decreased activity in the hippocampus during the encoding of negative images  . In accord with the studies discussed earlier, this evidence indicates that late adolescence is important as a transitional period from adolescence to adulthood, involving the maturation of emotional regulation and cognitive processing in social situations. 

Several studies have reported the usefulness of a five-factor model that describes five distinct personality traits for parsing personality constructs in late adolescents  ,  ,  . Of the five factors, neuroticism and extraversion are of particular interest, as they are believed to be crucial for the development of healthy social interactions and to exert an over-arching influence on affect and mood. Extraversion is characterized by an increased tendency to be optimistic, and to experience positive emotions and enhanced sociability. Conversely, neuroticism is defined as an increased tendency to worry and to experience psychological distress, accompanied by negative affect and over-sensitivity to negative cues. Functional neuroimaging studies have demonstrated that task-evoked brain activity varies with neuroticism and extraversion scores in the prefrontal cortex and cingulate cortex  ,  ,  ,  ,  . Thus, these two personality traits are strongly associated with emotional experience and may modulate emotion-evoked brain activity  . 

Development of personality traits occurs not only in adulthood, but also in childhood and adolescence  . Neuroticism and extraversion are consistently included in personality models, including 3-factor and 5-factor models  ,  ,  . In addition, the two dimensions seem to be most related to age, educational level, and positive/negative life events from late adolescence to young adulthood  ,  ,  . A longitudinal study of college students reported that an increase in positive life events with age was associated with extraversion, while an increase in negative events was associated with neuroticism  . Another longitudinal study showed that extraversion in high school students predicted their experience of more positive life events over 4 years later in their college- or work-life, while their neuroticism predicted the experience of more negative life events  . These studies highlight the importance of understanding extraversion and neuroticism during late adolescence. 

Moreover, a meta-analysis of 92 longitudinal studies revealed that the largest changes in personality traits occurred between ages 18 and 30, and, specifically, that late adolescents typically become more socially dominant (a facet of extraversion) and less neurotic  . The study indicates that late adolescence is a critical period for the development of personality traits, showing that extraversion and neuroticism are influential for late adolescents in adapting to society as they mature. 

Recently, extraversion and neuroticism were also shown to impact on structural features of the prefrontal cortex in adult and elderly populations  ,  , suggesting that extraversion and neuroticism are related to structural brain development in the earlier stages of life. Low extraversion and high neuroticism are also associated with depression, anxiety  , and phobia  , which are all related to psychological and psychiatric problems frequently occurring in late adolescence  ,  . Neuroticism also predisposes individuals to develop chronic functional pain/pain disorders   and mood disorders  ,  , which are also common problems among late adolescents  ,  . The way in which adolescents become extraverted and less neurotic with regard to the challenging external environment during the late adolescent period is a developmental issue that has not been adequately addressed. Moreover, the neural correlates of this process are currently unclear. 

In a review study examining social and emotional development during late adolescence, depressive and anxiety symptoms were found to be predictive of changes in psychosocial functioning  . For example, rejection sensitivity (the tendency to anxiously expect, readily perceive, and intensely react to rejection) appears to be particularly salient in late adolescence as anxiety or angry expectation  , and was linked to a relative increase in adolescent depressive and anxiety symptoms  . Similarly, social anxiety was predictive of physical/psychological ‘dating aggression’ among late adolescents  . Moreover, healthy adolescents between 12 and 21 years old, who engaged in more extracurricular activities (i.e., participation in organized sports teams, clubs, etc.) and experienced higher quality family relationships, presented with significantly less depressive symptoms  . Since late adolescents face increasingly complex social situations, symptoms of depression and anxiety may be particularly damaging for the development of social competence. 

In the current study, we used functional magnetic resonance imaging (fMRI) to measure neural responses elicited by the observation of actions associated with a certain risk. Moreover, we investigated the influence of developmental differences of psychological properties among late adolescents. We administered psychological questionnaires to measure anxiety, depression, neuroticism, and extraversion, all of which play a crucial developmental role in the establishment of identity during late adolescence. During fMRI scanning, participants viewed hand movements associated with a risk of harm (risk-taking actions) or no risk of harm (safe actions). This task was designed to represent common situations involving potential risks in an everyday environment, providing an index of how late adolescents are likely to cope with potential risks in their social lives in the future. Late adolescence is a challenging period characterized by pervasive social role changes across many domains  ,  . Salient tasks of late adolescence include goals relating to friendship, academic success, and social conduct, giving way to occupational and romantic goals as late adolescents move into young adulthood  . The large number of changes faced in late adolescence make it an unstable time, but also reflects the explorations that take place during the late adolescent years. Many of the changes made by late adolescents are for the purpose of some new period of exploration, in love, work, or education. In accord with this notion, it is possible that a late adolescent’s level of tolerance of risk-taking actions may become entrenched as they are frequently confronted with challenging social situations during late adolescence. Here, we postulated that action observation of risk-taking would be a developmental indicator of motivation to overcome a broad range of difficulties in the world. Although teenagers are generally regarded as engaging in more ‘risky behavior’, such as binge drinking, cigarette smoking, having casual sex partners, violence and other criminal behavior etc  ,  ,  , it should be noted that in this study we do not use the term ‘risk-taking’ to refer to a tendency to such a ‘risky behavior’. Rather, we use ‘risk-taking’ to refer to a more positive concept, whereby adolescents confront and manage the difficulties facing them. 

Although this is an exploratory analysis, we hypothesized that late adolescents will become less anxious, less neurotic, less depressive, and more extraverted as they age, measured by the correlation between age and questionnaire scores, and that neural responses to the observation of risk-taking actions will be modified as adolescents become tolerant of risks in the external environment. Furthermore, we hypothesized that the developmental aspects of their tolerance to the external environment (measured as the correlation between questionnaire scores and age) will be mediated by changes of neural circuitry. These changes may involve the limbic or paralimbic systems (e.g., insula) or brainstem, which are central to the processing of affective information. In addition, the changes may also affect the prefrontal areas, which are important for emotional regulation. Activity in the anterior insula has been found to be associated with empathic maturity during the observation of emotional expressions among children  . This finding supports the notion that the insula is relevant to social functioning in everyday life. 


## Materials and Methods 
  
### Participants 
  
Twenty-five participants in their late adolescence took part in this experiment (12 females and 13 males, from 18 years and 1 month to 22 years and 8 months,   M   ±   SD   years: 20.60±1.09). All participants were undergraduate students and had normal or corrected-to-normal vision. All participants were right-handed (lateralization quotient for the right side of more than 90%) as assessed by the Edinburgh Handedness Inventory  . Written informed consent was given before participation in the study, which was specifically approved by the Institutional Ethical Review Board of the National Center of Neurology and Psychiatry, Japan. All participants were screened to rule out head trauma, the use of medication, history of neurological or psychiatric disorders, and other serious medical conditions. 


### Image Acquisition 
  
Images were acquired using a 1.5 T Magnetom Vision plus MRI scanner (Siemens, Erlangen, Germany). We acquired a unique high-resolution structural image (T1-weigthed anatomical images; 3D MP-RAGE sequence, repetition time; TR  = 11.4 ms, echo time; TE  = 4.4 ms, flip angle  = 15°, 256×256 matrix, slice thickness 1.25 mm) with 144 sagittal slices after the functional runs. Each functional run involved the acquisition functional echo-planar imaging (EPI) volumes (gradient-echo, TR  = 3,000 ms, TE  = 40 ms, field of view; FOV  = 192 mm, flip angle  = 90°, 64×64 matrix, slice thickness 3.5 mm), each with 36 interleaved slices approximately parallel to the anterior commissure-posterior commissure line. Stimuli were displayed on a screen positioned at the rear of the scanner, which the participant could comfortably see through a mirror mounted on the standard head coil. 


### Psychological Measures 
  
Prior to the fMRI session, participants completed the Maudsley Personality Inventory (MPI)  ,  , Spielberger State-Trait Anxiety Inventory (STAI)  ,  , and the Self-rating Depression Scale (SDS)  ,  . The MPI consists of 80 items, each assessing a constellation of traits, also providing a measure of personality along the neuroticism and extraversion scales. The STAI-trait is a self-report instrument of the longstanding quality of trait anxiety. The STAI-trait consists of 20 items, and high total scores indicate more trait anxiety. The SDS was developed as a self-administered measure of depression severity, with higher scores indicating more severe depression. The 20 items of the scale address each of the four most commonly found characteristics of depression: pervasive effects, physiological equivalence, other disturbances, and psychomotor activities. 


### Action Observation Stimuli and Procedure 
  
The action observation experiment involved two types of video clips, ‘risk-taking’ (video of a person’s hand performing an action with clear potential for causing harm to oneself) and ‘safe’ (showing a person’s hand performing an action with no clear danger) ( ). The stimuli are described in detail in  . It should be noted that the video clips were not created to convey the meaning of problematic behaviors among adolescents, such as using drugs or alcohol, driving drunk, smoking, unprotected sex, or other offensive or criminal activities. Rather, the video clips presented participants with situations involving common risks that most people are exposed to in everyday life. Each functional run began and ended with the presentation of a white fixation dot for 9 s. Between these two fixation periods, video clips from the two conditions were presented in alternating 21 s blocks. Each block consisted of a 21 s video clip, and each baseline consisted of a 9 s fixation period. Each block contained videos depicting three different risk-taking actions, or three different safe actions. Half of the blocks showed people performing actions from the right of the screen, and half from the left. Participants completed 10 blocks of each condition during a single scan. The order of presentation of the stimuli was determined according to an optimized random sequence for each block. The brightness of the screen, the intensity of contrast (luminance contrast and texture contrast), the velocity of hand actions, and the representation of objects were equalized for all task/control video clips. The total duration of the risk-taking video clip equaled the duration of the safe video clip (the length of each video clip was 7.0 s). Three functional runs, lasting 10 minutes each, were collected for each participant. The hand movements of participants were monitored by direct visual inspection and video-monitoring from the back of the fMRI tunnel. No visible movements were noted during the presentation of the experimental stimuli. 
   Examples of movies (risk-taking and safe).       Experimental conditions and Visual Analog Scale (VAS) score (100-0) for each condition.        

### Behavioral Measures 
  
After the scanning procedure, each participant was shown the video clips again, and asked to answer specific questions related to them. To test subjective evaluations of the degree of risk, participants were asked to rate their subjective experience of the video clips using a visual analog scale (VAS) (1) from feelings of risk to safety (i.e. to what extent did you feel alarmed while watching the video clip?) and (2) from feelings of anxiety to comfort (i.e. how anxious did you feel while watching the video clip?). 


### fMRI Data Analysis 
  
Image processing was carried out using statistical parametric mapping software (SPM8, the Wellcome Trust Centre for Neuroimaging, London, UK). The functional time series was motion corrected, slice timing corrected and smoothed with a Gaussian kernel of 8 mm full-width at half-maximum. The corresponding high-resolution structural image (the T1 image as the source image) was registered to the first EPI image as the reference image. The co-registered structural image was then transformed into standard anatomical space using the Montreal Neurological Institute structural template (MNI 152). These parameters were used to normalize all functional images. Following preprocessing, ‘Risk-taking’ and ‘Safe’ condition, and motion parameters (six realignment parameters) were entered as regressors. A high-pass filter (hpf) of 128 sec was also applied as regressors. The risk-taking and safe blocks were convolved with a hemodynamic response function without derivatives, and modeled as 21 s boxcar regressors. The 9 s fixation periods were modeled as implicit baseline blocks. Next, a first fixed level of analysis was computed subject-wise using the general linear model. The following T-contrasts were estimated: risk-taking, safe, risk-taking vs. safe, and safe vs. risk-taking. 


### Neural Response to Observation of Risk-taking versus Safe Actions 
  
To test our hypothesis that activation in areas related to action observation would be significantly enhanced when actions involved risk-taking, we compared activation in each condition using linear contrasts (risk-taking versus safe and safe versus risk-taking). The resulting set of voxel values for each contrast constituted a statistical parametric map of the   t   statistic SPM(  t  ). Anatomical localization was performed in MNI coordinates. Talairach coordinates (Talairach Daemon,   www.talairach.org/daemon.html  ) were used for anatomical localization to be compared with Brodmann areas  . Significant activations were defined using a lenient height-threshold of   p  <0.001, uncorrected, and an extent threshold of   k   = 10 (voxels), to reduce the risk of false negatives. Our use of cluster size thresholding combined with uncorrected   p   values was intended to adequately control for the prevalence of false positives  . This threshold suffices to eliminate speculation that effects observed in the primary parametric analysis are an artifact due to non-specific reductions in BOLD signal. 


### Neural Activity Associated with Age and Psychological Measures 
  
This analysis aimed to reveal the brain regions in which activity mediates the age-related change of psychological properties that are essential in individual maturity during late adolescence. In a second-level random-effect analysis, participant’s imaging data were regressed with psychological scores (neuroticism, extraversion, anxiety and depression) and age with a multiple regression analysis. The correlation map of neural responses to risk-taking action (the main SPM(  t  ) contrast of risk-taking vs. safe actions) with age and the correlation map of the same neural response with each of the psychological scores were calculated separately. A conjunction analysis was then performed to show overlapping areas of the two correlational maps: an age-related activation map and a personality-related map. 

Parameter estimates were extracted from the regions surviving the conjunction analyses that tested for statistical mediation using the INDIRECT macro for SPSS (  http://www.afhayes.com/  )  ,  ,  ,  . According to Baron and Kenny (1986), four steps are required to establish that neural activity in a particular region mediates the relation between age and psychological properties: (1) showing that age is associated with psychological properties; (2) showing that age is associated with neural activity in the region; (3) showing that neural activity in the region predicts psychological properties when controlling for age; and (4) showing that the relation between age and psychological properties is reduced when controlling for neural activity in the region. For a sample of 20–80 participants, statisticians recommend the use of bootstrapping methods for testing the statistical significance of mediation (rather than the Sobel test, which is appropriate for larger samples;  ,  . The current study used the bootstrapping approach outlined by Shrout and Bolger (2002), which provides a mean estimate of the indirect effect (i.e., the path through the mediator) and the associated 95% confidence interval. A confidence interval that does not contain zero indicates statistically significant mediation (  p  <0.05). Cook’s distance metric was used to test whether data from a few individuals unduly influenced the strength of the bivariate relationships. A value (age, psychological property, and neural activity) greater than 1 for a data point represents a statistical outlier  . No point had a Cook’s distance greater than 0.5, indicating that none of the correlations were dependent on statistical outliers. 



## Results 
  
### Behavioral Measures 
  
 shows descriptive features of psychological measurements (neuroticism, extraversion, anxiety-trait, and depression scores) and the correlation coefficients between these scores and age. The scores of neuroticism, anxiety, and depression were negatively correlated with age (  r   = −0.49, −0.56, and −0.54, respectively), and extraversion scores were positively correlated with age (  r   = 0.44), suggesting that the late adolescents became less neurotic, less anxious, less depressive, and more extraverted with age. These scores were used for the multiple regression analysis of neural responses, regressed with age and psychological variables. 
   Psychological assessment scores and correlation coefficients with age for each score.        
 shows the scores of subjective ratings using the visual analog scale for each video clip. To test the efficiency of the categorization of the stimuli in terms of risks, the scores of 1) participants’ subjective levels of risk-taking and 2) the extent to which they felt anxious when observing the stimuli were compared between the two within-participant categories (risk-taking and safe actions in video clips). The results indicated that participants experienced significantly stronger feelings of risk-taking and anxiety during the observation of risk-taking compared with safe actions (  F   = 151.16,   p  <0.001, and   F   = 93.73,   p  <0.001, respectively, using repeated-measures ANOVA). To validate the video clip task used in this study, we calculated the correlation coefficients of the subjective ratings of the feeling (“risky” and “anxious”) induced by the actions in the video clips with psychological assessments (correlation coefficients   r   are provided in the  ). The VAS scores of feeling “risky” about Risk-taking actions were positively correlated with anxiety (  r   = 0.41), and negatively correlated with extraversion (  r   = −0.42). VAS scores for feeling “anxiety” about Risk-taking actions were positively correlated with neuroticism and anxiety (  r   = 0.44 and 0.44, respectively), and negatively correlated with extraversion (  r   = −0.40). In contrast, VAS ratings for safe actions were not correlated with any psychological assessment. These results indicate that the video task in this study (the observation of risk-taking action) provides a suitable measure of the psychological factors of interest in this study, and can be used to examine important developmental processes in the late adolescence period. 
   Correlation coefficients between psychological assessments and subjective ratings (“risky” and “anxiety”) about the actions in video clips.        

### Neural Response to Risk-taking versus Safe Actions 
  
We compared the neural activation elicited by observing risk-taking versus safe actions across the whole brain ( ,  ). The results revealed that risk-taking actions elicited significantly stronger activation, mainly in the bilateral middle frontal gyrus (BA9/10), superior frontal gyrus/frontal pole (BA8/10), supramarginal gyrus (BA39/40), inferior parietal lobule (BA40), superior temporal gyri (BA22/39), middle occipital gyri (BA18/19), and cuneus (including the calcarine sulcus) (BA17/18/19) compared with safe actions. Additional areas of significant activation were also found in the left middle temporal gyrus (BA21/22), medial frontal gyri (supplementary motor area) (BA6), superior parietal gyrus/lobule (BA7), precentral gyrus (BA6), posterior cingulate (BA23), fusiform gyrus (BA37), lingual gyrus (BA17), insula (BA13), and declive. In the right hemisphere, we observed significant activation in the precuneus (BA7) and postcentral gyrus (BA2). No regions exhibited greater activation while viewing safe actions compared with risk-taking actions associated with risk. 
   Brain images of neural activity in response to the observation of the object-related hand movement task for risk-taking actions vs. safe actions.  
Statistical threshold for illustrating the clusters was   p  <0.001 uncorrected. The bar on the right shows the range of   t   scores for statistical parametric mapping. Calc. S, calcarine sulcus; FG, fusiform gyrus; FP, frontal pole; MFG, middle frontal gyrus; MTG, middle temporal gyrus; Occ, occipital cortex; SMA, supplementary motor area; SMG, supramarginal gyrus; SPG, superior parietal gyrus. 
  

### Neural Responses Mediating Relationship between Age and Psychological Properties 
  
Finally, we performed a conjunction analysis to reveal common brain activity that correlated both with age and psychological scores (neuroticism, extraversion, anxiety, and depression) ( ). A positive correlation between age and neural response to observation of risk-taking action [  r  ,   p  <.001] and a positive correlation with extraversion [  r  ,   p  <.001] were found to overlap in the insula [BA13,   r   = 0.70,   r   = 0.76], middle temporal gyrus [BA22,   r   = 0.68,   r   = 0.70, ], and precuneus [BA19,   r   = 0.67,   r   = 0.67]. A positive correlation with age [  r  ,   p  <.001] and a negative correlation with anxiety [  r  ,   p  <.001] were found to overlap in the angular gyrus/supramarginal gyrus [BA39,   r   = 0.68,   r   = −0.79, ], precentral gyrus [BA6,   r   = 0.67,   r   = −0.73, ], and red nucleus/substantia nigra [  r   = 0.66,   r   = −0.79]. Parameter estimates were extracted from the regions surviving the conjunction analysis. The parameter estimates were used in a series of analyses testing for statistical mediation. 
   Brain regions mediating association between psychological measurement and age.        
As shown in  , insula activation (BA13) mediated the relation between age and extraversion. This insula activation was positively associated with age and extraversion (age:   β   = 0.44; extraversion controlling for age:   β   = 0.41). The relationship between age and extraversion (  β   = 0.28) was reduced when controlling for activity in the insula (  β   = 0.22). Bootstrapping revealed that the insula significantly mediated the relation between age and extraversion (mean indirect effect  = 5.35, 95% confidence interval ranging from 0.37 to 11.78). The results indicate that, as late adolescents’ age, their neural responses to the observation of risk-taking actions increase in the insula and middle temporal, lingual, and precuneus areas. These changes were related to developmental changes of the participants’ psychological properties, such as increased extraversion. In particular, the insula significantly mediated the relation between age and extraversion. Also, age-related increases of neural activation in the angular gyrus, precentral gyrus, and red nucleus (and substantia nigra) were found to contribute to decreasing anxiety with age. 
   (A) Scatterplots of associations between insula activity (BA13, peak in MNI space: −40 −10 20) and age for the peak of the clusters surviving conjunction analysis with an independent regression of extraversion.  
Left panel: association between age and insula activity (  r   = 0.60,   p  <0.01). Right panel: association between extraversion and insula activity (  r   = 0.61,   p  <0.01). (B) Brain regions that mediated the relationship between age and extraversion. Parameter estimates (risk-taking > safe contrast) extracted at the region identified by conjunction analyses were independently regressed by age and psychological properties. Mediation tests were based on methods described by Shrout and Bolger (2002) and Baron and Kenny (1986). (a) Regression slope of age predicting neural activity; (b) regression slope of neural activity predicting extraversion, controlling for age; (c) regression slope of age predicting extraversion; (c’) regression slope of age predicting extraversion, controlling for neural activity. Bootstrapping was used to estimate indirect effects (Shrout & Bolger, 2002; see also Preacher & Hayes, 2004). A confidence interval that does not overlap with zero indicates statistically significant mediation. *Indicates significant difference from zero,   p  <0.05. Coordinates are given in MNI space. 
  


## Discussion 
  
The primary question motivating the present study was whether late adolescents become more extraverted, less neurotic, and less anxious as they age, and whether such changes might reflect increased tolerance to the challenges of the adult world. In addition, we also sought to test how brain function reflects developmental changes occurring in late adolescent psychology. 

The results revealed several major findings. First, we observed significant correlations between age and scores on psychological parameters that have been hypothesized to play central roles in the development of the late adolescent mind: younger people tended to become more extraverted and less neurotic, less anxious and less depressive with age during late adolescence, even within the small age range in our sample. Levels of neuroticism have been previously reported to decline with age until around age 80  . However, extroversion has also been found to decline with age  . Reports of the correlation of age with depression and anxiety are, however, inconsistent. While some studies have reported no age-related difference on the SDS and STAI among students aged 18–28  , another study reported correlations of anxiety and depression with age in a population with a mean age of 33.0 years  . To date, there has been no study reporting detailed changes of these psychological properties within a small age range in late adolescence. The robust association of age with neuroticism, extraversion, anxiety, and depression in our study indicates that the late adolescent mind undergoes dramatic changes within a short period of time. These changes appear to be unique and distinct from psychological changes that occur across the longer lifespan. Future studies with larger samples will be necessary for elucidating the nature of these dramatic changes in late adolescence. 

Analysis of the “risk vs. safe” contrast revealed neural activation in areas broadly associated with action recognition. These results indicate that observing risk-taking compared with safe actions in our task elicited neural activation in; 1) occipital visual areas including the calcarine sulcus and fusiform gyrus, which are related to lower-level processing of visual information and sending output information to the action recognition network; 2) the bilateral superior and inferior parietal regions, which have been implicated in action recognition and representation  ; 3) the posterior middle temporal gyrus, which is located in the middle of the ventral pathway and serves as a central node in the association of actions and meanings  ; 4) the supramarginal gyrus or inferior parietal area, widely considered to be homologous to the monkey parietal mirror neuron system, which is critical for encoding and recognition of gestures such as object–related postures and movements  ; 5) the posterior cingulate area associated with human awareness, self-reflection  , and memory retrieval  ,   etc. and 6) the frontal pole (superior frontal gyrus), which has been implicated in retrospective monitoring of observed actions that affect one’s future actions  ,  . Therefore the results suggest that the risk content of the observed action in the video clips enhanced the broad spectrum of visually-guided action recognition processing; the network of visual input and its processing appear to encode the meaning of the observed action and even the reflective or retrospective monitoring of the action’s outcomes. As a result, the risk-related content of the action enhanced a broad network associated with action recognition. This finding indicates that risk-taking situations may increase cognitive load in the entire action recognition system, commanding more attention to the actions shown in the video clips. One possible explanation for the result is that risky actions are relatively unusual and involve novelty, which may cause more brain activation. In the present study, however, it is unlikely that factors related to novelty exerted a substantial effect on brain activation, because the situations depicted in the video clips were not unusual. Rather, the videos depicted common situations that often occur in everyday life. In addition, the degree of novelty of the experimental stimuli was controlled using control video clips. Although we did not observe strong activation in affect-related brain areas, another explanation is that the present results reflect some affective impact on brain activation related to risk-taking context. For example, activation in the mirror neuron system while observing action can be enhanced by motivational and affective aspects of the observed action, (e.g.,  ). Thus the action recognition system may be modulated by the affective context of the risk-taking actions of observed actions. 

Alternatively, processing risky actions may require more cognitive resources, involving the estimation and monitoring of possible outcomes of observed actions (see  . This notion is in accord with our current finding that the frontopolar region was more engaged while observing risk-taking compared with safe actions. In addition, a previous study reported that the superior part of the frontal polar area exhibited stronger activation when participants thought about the future compared with when they thought about the past  . Moreover, human lesion studies have indicated that the frontal polar area may be involved in generating insights into one’s future  ,  ,  . On the basis of the current findings, taken together with previous evidence, we hypothesize that risk-taking actions require more cognitive resources to process, involving the estimation of action outcomes resulting in stronger activation in the frontopolar cortex. 

The posterior cingulate cortex (PCC) was also activated by risk-taking vs. safe actions. This region may be another center for risk-related brain activity, which has been suggested by previous animal studies. For example, it has been reported that PCC activation in monkeys is sensitive to risk in decision making tasks  . In addition, the PCC is reported to exhibit activation when monkeys make risky choices, and to become more active with greater perceived risk  . These reports are consistent with the present finding that the observation of risk-taking actions (compared to safe ones) activated the PCC. The PCC is reciprocally connected to parietal areas (action recognition network) and receives feedback input from the prefrontal cortex (see the review in  ), which is involved in estimating the possible outcomes of action. Activation in this area may have exhibited risk-related sensitivity, together with the other regions listed above. 

The main finding in the current study was that neural activation during the observation of risk-taking (compared with safe) actions was correlated with age and some psychological measures, especially, extraversion and anxiety. These results indicate that these psychological properties have important developmental components during late adolescence, and that these developmental changes are represented by brain activation related to the observation of risk-taking actions in the insula and the parietal-temporal-occipital association area (middle temporal gyrus, lingual gyrus, and precuneus). Furthermore, we found that the insula significantly ‘mediated’ the relationship between age and extraversion. 

The insula is a multifunctional cortical region involved in emotional processing  ,  ,  ,  ,  ,  , speech-motor function  ,  ,  ,  ,  ,  , aversive experience  , both physical (i.e. visceral and somatic pain) and emotional (i.e. affect and mood) experience  ,  ,  , conscious awareness (interoceptive awareness)  , and emotional awareness  . The insula also plays a critical role in the processing of risk-taking during decision-making  , suggesting that insula activity may also be modified by the risk-taking context of the observed action in our study. 

The present finding of a correlation between insula activity and extraversion is consistent with the results of a previous positron emission tomography (PET) study   showing that the blood flow of the insula cortex was correlated with extraversion. Introversion (low extraversion) is associated with anxiety through increased limbic activation (in the insular cortex and amygdala), and is affected by genetic factors  . A morphometric study also revealed that extraversion correlated positively with gray matter volume of the insula  . Importantly, a previous fMRI study   revealed that extraversion correlates with neural responses to   positive   word stimuli in the bilateral insula. It is possible that, although the insula response to observing risk-taking actions may reflect an elevated alertness to the risk of harm in the environment, the participants did not experience substantial negative affect, as would be the case if they suffered from severe neuroticism or anxiety/depression. Rather, participants may have been receptive to the new challenges evoked by the task, which could result in the relationship between insula activity and a personality trait relating to a more positive aspect of affect, i.e., extraversion. Although insula activity reflects the processing of arousal or novelty  ,  , this may be accompanied by positive affect to some extent. 

While insula activity is related to extraversion, the insula has also been found to exhibit developmental changes  ,  . A neuroimaging study revealed increased activation in the insula with age in response to a risk-taking task  . Studies of individuals with clinical or developmental disorders consistently show insular morphometric changes, such as gyrification   and reduction of the insular volume in Williams syndrome  , which further suggests developmental changes in the insula. The current finding of an age-related increase in insula activation may also support the notion that the level of affective (particularly positively-valenced) engagement in risk-taking action increases with age in late adolescence. Overall, the current results, which show a link between age and insula activity as well as a link between insula activity and extraversion, suggest that insula activity may ‘mediate’ the development of extraversion. 

Our results also revealed that activity in the posteromedial parietal cortex (including the precuneus) correlated positively with extraversion. Gamma et al., (2000) report a similar positive correlation between extraversion and rCBF in the precuneus, consistent with the current findings  . Extraversion is related to the active seeking of social or interpersonal engagement, and the precuneus is also related to processing social information and estimating interpersonal relationships. For example, the precuneus is activated during ‘forgivability’ judgments in social scenarios   and in the attribution of emotions to the self and others  . Moreover, a number of studies have identified that the precuneus is modulated by agency and intentions in action/movement recognition  ,  , and moral judgments  . The precuneus, in parallel with its social functions, shows age-related changes of brain activity during theory of mind tasks  ,  . The correlation between extraversion and activity in the precuneus, with its age-related changes, suggests that increased precuneus activation may mediate the process of late adolescents becoming increasingly extraverted and exhibiting improved social functioning with age. 

In the current study, as late adolescents aged, activity in the angular gyrus and precentral gyrus increased, and was negatively correlated with anxiety. In a previous fMRI study  , participants were told that an electrodermal stimulation could occur at any time (“threat”) or that no stimulation would occurs (“safe”). The results revealed stronger activity in the “safe” condition than in the “threat” condition in the angular gyrus and precentral gyrus. Thus, these regions may reflect enhanced perceptions of safety, consistent with the current finding of a negative correlation between the activity in these two regions and the level of anxiety. Simmons et al.   also reported reduced activity in the posterior superior temporal cortex adjacent to the angular gyrus in anxiety-prone participants compared with control participants during the observation of aversive images. Moreover, the more repetitively the emotional facial pictures were presented the stronger the neural activity was in the angular/posterior superior temporal gyrus and precentral gyrus, such that the activation in these areas correlated with participants becoming habituated to the emotional stimuli and becoming less anxious  . The precentral gyrus has dense connections with the angular gyrus  , and the angular gyrus and precentral gyrus have been reported to exhibit coactivation during a range of cognitive tasks, including lexical  ,   and calculation tasks  . These findings suggest the existence of a network involving these two areas. Moreover, both the angular gyrus and precentral gyrus are included in the default-mode network (DMN), a prominent large-scale brain network that exhibits strong activity during the resting state and deactivation during cognitively demanding tasks  ,  . We propose that maturation of a network including the angular gyrus and precentral gyrus may play an important role in stabilizing affective states during late adolescence. 

Several limitations of the current study should be considered. First, the sample size was relatively small for studying personality-related factors. This may have reduced the statistical power of our analysis, potentially influencing the results. Additional studies with larger sample sizes and more detailed longitudinal behavioral and cognitive testing focusing on the developmental aspects of personality are required to verify these novel findings. Second, our mediation analysis design, consisting of three variables, may have omitted many other variables that influence both insula response and extraversion in the same direction, potentially resulting in a positive bias in the results. For example, it has been reported that empathic ability is correlated with insula activity  . In addition, some evidence suggests that empathic individuals are more likely to be extraverted  . Moreover, an independent variable can have multiple mediators, which would have been omitted in this design. These potential confounds are likely to affect mediators and dependent variables in the same way. Future studies should take into account other potential mediators. Third, the conjunction analysis shown in Supplementary   may contain false positives, meaning that the results should be corrected for multiple comparisons (e.g. Bonferroni correction). Applying the Bonferroni correction would increase the likelihood of false negatives, however. Since the current study is an exploratory examination, it may be appropriate to consider the statistical significances of conjunction analyses as preliminary values at this point. Additional studies using the Bonferroni correction will be needed to more rigorously test our hypothesis. Fourth, we found a negative correlation of age and anxiety with activation in the red nucleus/substantia nigra, but no significant effect of the main contrast (risk-taking vs. safe; in Supplementary  ). The substantia nigra contains dopamine-containing neurons  ,  . Moreover, the sequence planning and timing-related motor functions in the substantia nigra indicate dopaminergic gating of motor sequences  ,  . Future studies will be required to investigate this issue in more detail. Fifth, as shown in  , multiple correlation analyses were computed between psychological measurements. This may have led to significant effects due to chance in each correlation analysis, such as correlation coefficients between the subjective ratings of the two kinds of video and the four psychological measurements. Adopting a more conservative corrected alpha level, however, would increase the likelihood of false negative results. In the current study, we adopted a thresholding method (  p  <0.001, uncorrected, with 10 contiguous voxels) that was initially proposed more than a decade ago   and has been used in many fMRI studies. A number of alternative methods of correction for multiple comparisons currently exist (e.g.,  ,  ), and the thresholding method in our study is not the only one available. It is important to note that the present correlational analysis constitutes an exploratory finding. Future studies will be required to test whether the current data can be replicated. 

Overall, our findings indicate that late adolescents become less neurotic, less anxious, less depressive, and more extraverted as they age. These changes are associated with activity in brain regions related to social cognition and emotional processing. 


## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-40'>
<h2>40. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/29088456/' target='_blank'>29088456</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Dissociation of Brain Activation in Autism and Schizotypal Personality Disorder During Social Judgments</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Schizophr Bull</p>
<p><strong>Publication Year:</strong> 2017</p>
<p><strong>DOI:</strong> 10.1093/schbul/sbx083</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5737648/' target='_blank'>5737648</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study reports functional MRI collected while participants performed an explicit social judgement task (approachability from faces), which fits the social-related processing constructs (perception/understanding of others). It includes a healthy control group of adults (controls reported and analyzed separately) alongside clinical groups. Analyses include whole-brain group × condition contrasts with family-wise error correction and voxel-based (whole-brain) inference in addition to small-volume correction for the amygdala, so results are not limited to ROI-only analyses. Therefore all inclusion criteria are met and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
## Background 
  
There are overlaps between autism and schizophrenia but these are particularly pronounced, especially in social domains, for higher functioning individuals with autism spectrum disorders (ASD) or schizotypal personality disorder (SPD). It is not known whether these overlapping social deficits result from shared or distinct brain mechanisms. We therefore compared social cognition in ASD and SPD using functional magnetic resonance imaging (fMRI). 


## Methods 
  
Twenty-one individuals with SPD, 28 with ASD and 33 controls were compared with respect to clinical symptoms using the Positive and Negative Syndrome Scale; social cognition, using a social judgment task and Ekman 60 faces task; and brain activation using an fMRI task of social judgment. 


## Results 
  
The ASD and SPD groups showed few differences in symptoms or social cognition. However, fMRI showed that, compared to ASD, the SPD group showed significantly greater activation during social compared to gender judgments in the amygdala and 3 clusters: right posterior cerebellum, extending into fusiform and inferior temporal gyri; left posterior cerebellum; and left intraparietal sulcus extending through medial portions of the temporal gyri into the fusiform gyrus (all   P   < .05 family-wise error corrected). Control activations lay between the ASD and SPD groups. 


## Conclusions 
  
Although social cognitive deficits in ASD and SPD appear superficially similar they are the result of different brain mechanisms. These findings have implications for therapeutic interventions targeted at social dysfunction in these conditions. 

 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (30140 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
The term autism was initially coined by Bleuler in 1911 to describe a characteristic symptom of people with schizophrenia, specifically “detachment from reality, together with the relative and absolute predominance of the inner life.”  It was first used to describe a specific disorder by Kanner in 1943, when he presented a case series of children affected by “autistic disturbance of affective contact.”  Although initially thought to be a distinct condition, autism soon came to be regarded as a form of early onset schizophrenia  and this continued until a series of studies differentiated the disorders on phenomenology, course and family history. 

With the advent of the autism spectrum concept, it is now recognized that there exist forms of both disorders which do not show such marked impairments. Although autism spectrum disorders (ASD) and “schizophrenia spectrum disorders,” such as schizotypal personality disorder (SPD), would be expected to differ on the level of mild psychotic symptoms and on restricted repetitive behaviors,  there are significant overlaps between the conditions: both occur in nonintellectually disabled people and are associated with social difficulties, idiosyncratic language and unusual behavior, as well as showing common associated psychopathology.  Both conditions are also associated with deficits in social cognition.  Finally, the age of onset of SPD is unclear, while ASD may not become obvious until after early childhood, when social demands exceed ability.  Thus the distinction between ASD and SPD can be difficult ; indeed it has been proposed that the disorders should not be classified separately. 

Clinical and neuropsychological similarities therefore exist between ASD and SPD, but it is unclear whether these share a common pathophysiological mechanism, as direct comparisons have not been conducted. It has been suggested that, although ASD and schizophrenia show similar social deficits, the mechanisms through which these develop differ, with schizophrenia associated with hyper-mentalizing (ie, over-ascription of mental states to others) and ASD associated with hypo-mentalizing.  To the authors’ knowledge, 3 functional magnetic resonance imaging (fMRI) studies have directly compared ASD and schizophrenia using social cognition tasks ; these are broadly supportive of the hypo-/hyper-mentalizing theory, particularly the most recent studies.  However, it is also not clear whether these findings apply to higher functioning groups with ASD and SPD, in which fewer symptomatic differences are apparent. 

We therefore compared social cognitive deficits in people with ASD and SPD and tested whether they are associated with different underlying brain activity using fMRI. We employed a social judgment task (assessing approachability from faces) on which we have previously shown impaired performance in ASD  and schizophrenia.  Making a judgment of approachability requires individuals to assess affective information from facial cues and to interpret this in relation to the threat or otherwise represented.  Using fMRI, we have also shown this task to activate social brain regions in typically developing individuals, including the medial and inferior prefrontal cortex, amygdala and cerebellum.  We hypothesized that individuals with ASD and those with SPD would show impaired social judgment compared to controls, but that, consistent with the literature on autism and schizophrenia, those with SPD would show increased activation of these brain regions while making social judgments whereas the opposite pattern would be seen in ASD. 


## Methods 
  
### Participants 
  
Individuals with ASD were recruited from clinical and support services in Southeast Scotland. All had a DSM-IV diagnosis of either autism or Asperger Syndrome and met ASD cut-offs on the Autism Diagnostic Observational Schedule (ADOS-G). 

Participants with SPD were recruited from nonpsychotic people who had previously participated in the Edinburgh High Risk Study of schizophrenia (EHRS)  and from clinical services in Southeast Scotland. All met DSM-IV criteria for SPD using the Structured Clinical Interview for DSM-IV Axis II Disorders (SCID-II). 

Some individuals met criteria for both ASD (determined by DSM-IV and the ADOS) and SPD (determined by the SCID-II). These were analyzed as a separate group, referred to as “comorbid” (CM). 

Controls were recruited from participant and investigator acquaintances and the Scottish Mental Health Network research register. Individuals with a history of, or first degree relative with, ASD, SPD or a psychotic illness were excluded. 

General exclusion criteria were IQ < 70, substance dependence or history of schizophreniform disorder, schizophrenia or bipolar affective disorder. 

The study was approved by the NHS Lothian Research Ethics Committee. Written informed consent was obtained from all participants. 


### Assessments 
  
In addition to the ADOS-G and the SCID-II, participants were assessed using the Positive and Negative Syndrome Scale (PANSS)  and the Wechsler Abbreviated Intelligence Scale.  For those on antipsychotic medication, doses were converted to chlorpromazine equivalents. 

Social cognition was assessed outside the MRI scanner using the Ekman 60 facial emotion recognition test  and a social judgments task.  In the Ekman 60 each face was presented for up to 5 seconds and participants selected the emotion displayed from a randomly ordered list consisting of fear, anger, disgust, sadness, happiness and surprise. Ten presentations of each emotion were shown in a random order. Performance was measured by totaling correctly identified emotion labels. 

For the social judgment task, participants were shown 6 sets of 32 faces for up to 5 seconds each. In each set they allocated the faces into one of the following binary characteristics: approachable-unapproachable, distinctive-not distinctive, young-old, trustworthy-untrustworthy, intelligent-not intelligent, and attractive-unattractive. The stimuli for the social judgment task were the same as a previous study and ratings for each were scored as “correct” when they agreed with predefined ratings for each stimulus. 


### fMRI Image Acquisition 
  
Details of image acquisition and preprocessing are given in the supplementary material. 


### fMRI Approachability Task 
  
The approachability component of the social judgment task was adapted for the scanner as previously described.  Face stimuli were presented in blocks of approachability judgments (“social” condition) and gender judgments (“gender” condition). Stimuli differed from those employed for the behavioral task. Two runs were presented, each lasting 240 seconds. Three blocks of each condition were shown; each lasted for 25 seconds, separated by a central fixation cross (“Baseline” condition). Each block began with a 1 second visual reminder of the task for the block (“Approachable?” or “Gender?”), followed by 6 faces, in a pseudorandom order, each presented for 3.5 seconds with a 0.5-second gap between stimuli. Underneath the faces, participants were shown their bivalent choice (“Approachable:Not approachable” or “Male:Female”) and indicated their selection by pressing a button in the hand corresponding to their choice. The stimuli were counterbalanced for stimulus order, judgment order, and hand used to indicate choice. 


### Data Analysis 
  
Differences between demographic characteristics were determined using parametric or nonparametric tests. The PANSS, Ekman 60, and social judgment scores were not normally distributed and so were analyzed using Kruskal-Wallis tests. When significant results were identified in the Kruskal-Wallis tests, follow-up Mann Whitney   U   tests were conducted. To assess the potential confounding effect of IQ, partial correlations between IQ and performance were conducted across all participants with group as a covariate. 

Statistical analysis of fMRI data were conducted using the general linear model in SPM8. Data for individual participants were modeled with 3 conditions (social judgment, gender judgment and baseline). Parameters representing participant movement were entered as covariates of no interest. Contrast images were generated for each participant for 2 contrasts: social vs baseline and gender vs baseline. In the second level analysis, a 2 × 4 flexible factorial design matrix was constructed with the 2 contrasts (social vs baseline and gender vs baseline) as within subjects factors, and 4 groups (ASD, SPD, CM, and control) as between-subjects factors, in addition to subject constants. Contrasts were constructed to test the main effect of condition (social or gender) across all 4 groups; the effect of condition within each group; and the group × condition interaction. Note that the group × interaction contrast essentially allows comparison of the social and gender conditions, with the gender condition acting as a “high level” baseline to remove the effects of any differential face processing not related to affective content. 

Between group analyses were conducted using an initial height threshold of   P   = .005 uncorrected. Cluster results were only considered significant at   P   < .05 after family wise error (FWE) correction for multiple comparisons across the whole brain. A small volume correction (SVC) was applied to the amygdala bilaterally. 

When clusters showed a significant group × condition interaction, eigenvariates were extracted and the difference value calculated by subtracting the value for the gender vs baseline contrast from the social vs baseline contrast. These difference values were regressed against PANSS scores to explore the relationship between brain activation and symptomatology. To assess the effect of potential confounding factors, difference values were regressed against IQ, chlorpromazine equivalents and task performance. Regression analyses were conducted within IBM SPSS Statistics 19.0. Finally, to examine whether results related to differences in activation during the social or nonsocial condition, or both, eigenvariates for the social vs baseline and gender vs baseline conditions were compared between groups. 



## Results 
  
### Participants 
  
Characteristics of the participants are given in  . 
  
Participant Characteristics 
    
No significant differences were seen with respect to gender, handedness, age or education (all   P   > .22). IQ scores differed significantly (  F   = 4.12,   P   = .009) with the control group having significantly higher IQ than the SPD and the CM group (all   P   < .05). The ASD, SPD and CM groups did not differ significantly on IQ (all   P   > .08). Ten participants were taking antipsychotic medication in chlorpromazine equivalent doses ranging from 25 mg to 400 mg per day. The median chlorpromazine equivalent doses for those taking antipsychotics in each group were: ASD = 50 mg, SPD = 100 mg, CM = 150 mg. The SPD and the CM groups were more likely to be taking antipsychotic medication than the ASD or control groups (  P   = .008). 


### Clinical Features 
  
Summary scores for PANSS positive and negative symptom scales are shown in  . 
  
Median Positive and Negative Syndrome Scale (PANSS) positive and negative symptom scores. Error bars represent 95% CIs. 
  
Kruskal-Wallis tests showed significant differences between the groups for positive and negative symptoms (χ  = 49.3,   P   < .001 and χ  = 41.7,   P   < .001, respectively). Follow-up Mann-Whitney tests showed that the ASD group scored less than the SPD and CM groups on positive symptoms (  Z   = −3.34,   P   = .01;   Z   = −3.7,   P   < .001, respectively). With respect to negative symptoms, there was no difference between the ASD and SPD group (  Z   = −.82,   P   = .41); however, the CM group scored significantly more than the SPD group (  Z   = −2.0,   P   = .04) and showed a trend towards a significantly higher score than the ASD group (  Z   = −1.7,   P   = .09). 


### Social Cognition 
  
The results for the out of scanner social cognition tasks are summarized in supplementary table s1. 

In the Ekman 60, there were no significant differences between the ASD, SPD, and CM groups on any measure. The ASD group identified significantly fewer angry faces correctly than the controls (  P   = .002), while the ASD, SPD, and CM groups all identified significantly fewer fearful faces correctly than the controls (all   P   < .05). A significant positive relationship was seen across the groups between IQ and anger recognition (  P   < .001) suggesting differences in this measure may relate to IQ differences between the groups; no such relationship was seen for fear. 

In the Social Judgments Task, the ASD, SPD, and CM groups did not differ significantly from each other on any of the measures. The ASD and SPD groups both scored significantly less than the controls on judgments of approachability, attractiveness, distinctiveness and intelligence (all   P   < .05). The CM group scored significantly less than controls on judgments of age and distinctiveness (  P   < .02 for both). IQ correlated positively with scores on age and distinctiveness (  P   = .01 and   P   = .03, respectively), suggesting differences in these measures may relate to IQ differences between the groups. 


### Functional Magnetic Resonance Imaging 
  
Two individuals from the ASD group, 1 from the SPD group and 1 from the CM group did not participate in the imaging component due to fear of the scanner environment. Two individuals (1 control, 1 ASD) were excluded due to technical issues such that meaningful data were not recorded. Finally, one individual with ASD was excluded due to imaging artifacts. Supplementary table s2 contains the details of those included in the scanning study. 

#### Task Performance and Within Group Analyses. 
  
Details of in-scanner performance in the task and the within group analyses are in the supplementary material (supplementary tables s3–s6 and figures s1–s5). Within the whole study group combined, greater activations were found in the social compared to the gender condition in many regions previously associated with social brain function: inferior frontal gyri, medial prefrontal cortex, left anterior temporal lobe, left superior temporal sulcus, occipital gyri, and the cerebellum. No regions showed greater activation in the gender vs the social condition. 


#### ASD, SPD, CM vs Controls. 
  
There were no significant group × condition interactions in the ASD, SPD or CM vs control comparisons. However, in the ASD vs control comparison, 2 trends towards significant group × condition interactions were observed, with the ASD group showing less increase in activation than the controls during the social condition compared to the gender condition in the posterior cerebellum bilaterally (cluster peaks (30 −58 −44),   P   = .05; and (−45 −55 −41),   P   = .07; table s7 and figure s6 in supplementary material). 


#### ASD vs SPD. 
  
A significant group × condition interaction was seen for the ASD vs SPD comparison. The SPD group showed significantly greater activation compared to the ASD group when making social compared to gender judgments in a voxel in the amygdala and in 3 clusters: the right posterior cerebellum, extending into the fusiform and inferior temporal gyri; the left posterior cerebellum; and the left intraparietal sulcus extending through the medial portions of the temporal gyri into the fusiform gyrus. For each of these regions the controls lay between the ASD and the SPD groups (  and  ; table s8 and figure s7 in the supplementary material). 
  
Clusters projected onto a rendered brain demonstrating regions of greater increase in activation in schizotypal personality disorder (SPD) compared to the autism spectrum disorder (ASD) group using the social > gender contrast in: (A) left temporo-parietal cluster (−24 −52 31); (B) left cerebellum (−15 −40 −38); (C) right cerebellum (33 −64 −44). All clusters were significant at an initial height threshold of   P   < .005 uncorrected with a cluster significance of   P   < .05 family wise error (FWE) corrected. Graphs underneath show difference values of extracted eigenvariates for each cluster. 
    
Location of peak voxel (  P   = .03 family wise error [FWE] corrected) of increased amygdala activation (−18 10 14) and graph of difference values of extracted eigenvariates for social > gender contrast in schizotypal personality disorder (SPD) vs autism spectrum disorder (ASD). 
  
Due to recent concerns expressed about the possibility of false positives due to the use of cluster-based statistics in resting state fMRI,  we also examined data for this comparison using voxel-based inference with a height threshold of   P   < .05 FWE corrected, which has not been found to show the same concerns.  In this case, in addition to the significant voxel in the amygdala, we identified significant voxels in the right cerebellum at the same location as in our main analysis (  Z   = 4.54,   P   = .03) and in the right inferior frontal gyrus (MNI = 51 35 25,   Z   = 4.5,   P   = .03). 


#### ASD vs CM. 
  
A significant group × condition interaction was observed in the ASD vs CM contrast. During the social condition compared to the gender condition the CM group showed significantly greater increases in activation than the ASD group in left pre- and post-central gyri and right cerebellum (supplementary table s9). 


#### SPD vs CM. 
  
There were no significant group × condition interactions for the SPD vs control contrast. 


#### Analysis of Confounding Factors. 
  
No significant relationships were seen between fMRI activations and IQ, antipsychotic use or within-scanner task performance suggesting that results are not confounded by these factors. To further explore the effects of antipsychotic medication on the fMRI results, the ASD vs SPD analysis was repeated after omitting those taking antipsychotic medication. In this analysis, greater activation was seen in the SPD then in the ASD group in the cerebellum bilaterally and in a new cluster in the ventromedial prefrontal cortex (tables s10–s11 and figure s8 in supplementary material). 


#### Exploratory Symptom Analysis. 
  
A significant group × symptom interaction (  P   = .04) was seen for positive symptoms when regressed against the extracted value from the left amygdala (−18 −10 −14). The ASD group showed a significant negative relationship between positive symptom score and activation change during the social compared to the gender condition (  r   = −50,   P   = .01) which was similar to the relationship in the CM group but different from the positive relationship in the SPD group (supplementary figure s9a). A significant group × symptom interaction (  P   = .01) was also seen for negative symptoms and the extracted value from the frontal cluster identified in the ASD < CM contrast (−18 −19 49). For this cluster the CM group showed a significant positive relationship with negative symptoms (  r   = .76,   P   = .02) while the SPD group showed a trend towards a significant negative relationship (  r   = −.43,   P   = .06; supplementary figure s9b). 


#### Analysis of Gender vs Baseline Condition. 
  
Analyses of the extracted gender vs baseline eigenvariates showed significantly increased activation in the ASD group in the left amygdala (−18 −10 −14) compared to the SPD and control groups (  P   = .003 and .01, respectively) and the left postcentral gyrus cluster (−18 −19 49) compared to the CM and control groups (  P   = .02 and   P   = .004, respectively). There were no instances of the SPD or CM groups showing greater activation than the other groups in the gender vs baseline analysis. 




## Discussion 
  
To our knowledge this is the first study directly comparing ASD and SPD using fMRI. The clinical groups all showed similar patterns of impairment compared to controls in negative symptoms and the social cognition tests, but clear differences were seen between the ASD and SPD groups using fMRI during the social judgment task. Differences between the ASD and SPD groups were also seen in the relationship between amygdala activation and positive symptoms. Our findings demonstrate that apparently similar clinical and neuropsychological features may be associated with quite distinct underlying brain mechanisms. 

Although this is the first fMRI study comparing ASD and SPD, our findings are consistent with the 3 previous imaging studies which compared ASD and schizophrenia. Pinkham et al  reported greater activation in right amygdala and left ventrolateral prefrontal cortex in non-paranoid individuals with schizophrenia compared to people with ASD during a trustworthiness judgment. In addition, a meta-analysis combining various mentalizing tasks showed greater activation in people with schizophrenia compared to those with ASD, albeit in different brain regions than we identified.  Pinkham et al also reported qualitatively different factors underlying paranoia in ASD and schizophrenia,  consistent with the opposing correlations between amygdala activation and positive symptoms that we report. This is also in keeping with a study showing that psychosis in autism was associated with different structural brain changes than psychosis alone. 

Recently, Ciaramidaro et al  identified opposing patterns of brain activation in ASD and schizophrenia during intentionality assessment. Specifically, using stimuli which didn’t require the assessment of intention they identified hyperactivation in schizophrenia compared to controls in VMPFC and left posterior superior temporal sulcus. In contrast, using stimuli requiring an assessment of intention they found hypoactivation in the right posterior superior temporal sulcus in ASD. Similarly, Eack et al also identified increased ventromedial prefrontal and temporo-parietal junction activity in patients with schizophrenia compared to those with ASD during a visual perspective taking task.  These findings are comparable to ours in that we also found opposing patterns of activation between groups in left temporoparietal regions and in the VMPFC, although the latter was only apparent in unmedicated individuals. However, Ciaramidaro et al’s findings also differ from ours in that they identified hyperactivation to a non-intentional stimulus in the schizophrenia group, whereas our findings are limited to explicit social judgments (ie, hyperactivation in the SPD group was not seen in the gender vs baseline analysis). This disparity between studies could relate to task differences, or to the difference between schizophrenia and SPD. It is possible that in people with SPD, this hyperactivation is limited to explicit social judgments, as opposed to also being inappropriately present during nonsocial judgments in schizophrenia.  This may represent the mechanism by which individuals with SPD are spared some of the more severe symptomatology associated with schizophrenia. 

We found hyperactivation in SPD compared to ASD in 2 regions we previously found to be activated in controls using the same task: the amygdala and the cerebellum. The amygdala has a range of functions in socio-emotional processing which include the detection of threat,  so the increase in activation may represent an exaggeration of this response in SPD; with a relatively reduced response to such stimuli in the ASD group. However, we have previously found that the amygdala is activated by both affective and non-affective judgments, suggesting that the hyperactivation observed here may relate to a broader role of the amygdala in inferring the traits of others.  Consistent with this, a recent meta-analysis found that activations in posterior cerebellum, which overlap strongly with those identified here, are also associated with tasks requiring participants to draw inferences about traits of others. 

We also identified increased activation in participants with SPD compared to those with ASD in the fusiform gyrus, a region strongly associated with face processing.  On the left side we also identified a cluster in the intraparietal sulcus extending through the temporal gyri, including the superior temporal sulcus. The intraparietal sulcus and the superior temporal sulcus are known to be involved in assessing the intent of others,  although more usually in the context of biological motion perception. Interestingly, increased activity in these regions has been reported in people with schizophrenia compared to controls when making judgments of a nonsocial, but not a social, nature  and was also identified as hyperactive in schizophrenia compared to ASD by both Ciaramidaro et al  and Eack et al. 

Although we did not identify clear group differences between either the ASD or SPD groups and the controls, results in the controls tended to lie between the 2 clinical groups, as did the findings for the CM group (  and  ). Given this, and the above, we suggest that our findings are consistent with the hypo- and hyper-mentalizing theory of ASD and schizophrenia.  Further evidence for distinct patterns of pathophysiology comes from our finding that increased activation in the left amygdala is associated with increased positive symptoms in SPD, whereas the reverse is true in ASD. These opposite patterns of correlation are consistent with the hypo- and hyper-mentalizing theory of the autism and schizophrenia spectrums with the SPD group developing psychotic symptoms due to over-activation of amygdala, whereas the ASD group develops such symptoms due to under-activation of this region. It should be noted however that we made no attempt to correct for multiple comparisons for these exploratory analyses and therefore further research is required to confirm the differential symptom-function relationships which we report. At present, however, our results are in keeping with the idea that the schizophrenia and autism spectrums represent diametrical disorders of brain development, at least in regard to social cognition.  Future studies investigating brain activation during other aspects of brain function known to be impaired in both conditions are required to determine if similar patterns are seen for other cognitive domains. 

Irrespective of the exact nature of the underlying process, the differences we report carry important implications for clinical practice and classification. In particular it is important to note that clinical phenotypes can appear similar but arise from very different mechanisms and may therefore require quite different treatment approaches. This raises the prospect of developing treatments targeted at mentalizing styles, as opposed to clinical symptoms, an idea in keeping with the RDoC proposals.  These findings also highlight the importance of considering SPD as a differential diagnosis for ASD and vice versa; it is therefore important that diagnostic services where these conditions may be met, especially those working with adults, contain access to skilled professional assessment of both sets of disorders. 

We also identified people who met criteria for both ASD and SPD. This is consistent with previous work which reported that 23% of people with ASD met criteria for SPD.  These “comorbid” individuals were more symptomatic than those with either condition alone, highlighting the importance of their identification. Interestingly, the fMRI findings for the CM group showed differences compared to the ASD group suggesting that they do not simply suffer from severe ASD. In contrast, there were no significant differences between the CM and SPD groups, which may indicate that they have a form of SPD. However, the numbers in this group are small making it difficult to draw firm conclusions. It is also possible that the definition of the CM group is reflective of the diagnostic tools that we employed and that more detailed clinical investigation could allocate members of this group more confidently into either one category or the other. 

A number of limitations of the current study merit mention. The sample size is relatively small, especially the CM group, and a larger population may have identified more subtle differences. IQ differences were apparent between the groups, although the lack of correlation between IQ and the fMRI results suggests that this did not confound the results. In addition, ASD diagnoses were based upon DSM-IV criteria, and confirmed using the ADOS; we would ideally also have included a standardized developmental history but this was not practicable in this adult sample. In terms of the image analysis, the choice of threshold for our fMRI may be considered to be quite lenient raising the risk of type I error; however, we note that some differences between the groups were still apparent using the more stringent  voxel based inference. Finally, it is likely that the gender judgment condition, although intended to remove non-affective face processing related activations, also contained an element of implicit social judgments, which may have reduced the differences between our groups when compared to the explicit judgment of approachability. The addition of a gender judgment using neutral stimuli with no affective content would perhaps have revealed greater differences between the groups. 

Notwithstanding these limitations, we report marked overlaps between ASD and SPD in negative symptoms and social cognitive difficulties, but significant differences on examination of social brain activity using fMRI, consistent with the idea that these superficially similar conditions are associated with distinct underlying mechanisms. 


## Supplementary Material 
  
Supplementary data are available at   Schizophrenia Bulletin   online. 


## Funding 
  
This work was supported by a fellowship awarded to A.C.S. from the Wellcome Trust (WT802131MF) and by a research grant from Medical Research Scotland (206FRG). Further support came from the Shirley Foundation and the Dr Mortimer and Theresa Sackler Foundation. 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-41'>
<h2>41. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/28939856/' target='_blank'>28939856</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Altered brain activity and the effect of personality traits in excessive smartphone use during facial emotion processing</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Sci Rep</p>
<p><strong>Publication Year:</strong> 2017</p>
<p><strong>DOI:</strong> 10.1038/s41598-017-08824-y</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5610339/' target='_blank'>5610339</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Meets all inclusion criteria: 1) Task is social-related (facial emotion discrimination—perception and understanding of others/social communication). 2) Healthy adult participants reported separately: both groups (excessive smartphone users screened to exclude current psychiatric diagnoses, and normal controls) are adults aged 19–35. 3) Whole-brain analyses are reported (group differences with FWE-corrected, cluster-level results reported across the whole brain), not only ROI analyses (ROIs are secondary). No exclusion criteria are violated. Therefore study is appropriate for inclusion in the review of fMRI studies of social-related processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Excessive smartphone use is a phenomenon related to maladaptive smartphone use, leading to negative consequences. This study set out with the aim of assessing the effects of excessive smartphone use on behavioral and neural responses during facial emotional processing. We examined 25 excessive smartphone users and 27 normal control users using functional MRI during facial emotion processing and investigated Behavioral Inhibition System/Behavioral Activation System (BIS/BAS). The excessive smartphone use group (SP) showed neural deactivation in the dorsolateral prefrontal cortex (DLPFC) and dorsal anterior cingulate cortex (dACC) during the presentation of an angry face and emotional transition compared to that of the normal control group (NC). Additionally, the SP revealed neural deactivation of the superior temporal sulcus and temporo-parietal junction related to social interaction during emotional transition compared to the NC. We found that BAS-Reward Responsiveness level was correlated with behavioral responses during repeated happy faces related to emotional reward in SP compared to NC. It can thus be suggested that excessive smartphone use is likely to fail on cognitive control during emotional processing, and this impairment might be influenced on emotional processing related to social interaction. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (38877 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Over the past decade, smartphones have become a necessity for people’s daily lives with the development of technology. Despite many positive aspects, excessive mobile phone use often leads to potentially harmful or disturbing behaviors such as uncontrolled use leading to a negative impact on various aspects of daily life , and thus, problematic mobile phone use has raised sufficient concerns for being considered a potential public health issue . People who are addicted to smartphone use are unable to maintain concentration on a task or in interpersonal relationships due to the need to constantly check mobile phone notifications . Additionally, the tendency to be emotionally vulnerable  and have low levels of self-esteem  is known to be associated with increased smartphone addiction. In the study using neuroimaging, college students with mobile phone dependence showed altered gray matter volume and white matter integrity . In the previous study using exploratory factor analysis, smartphone addiction symptoms were identified that disregarding of harmful consequences, preoccupation, inability to control craving, productivity loss, and feeling anxious and lost . Particularly, lonely and depressed people preference interacting with other people by texting or social networking applications  and these pattern leads to negative outcomes related to their Internet use . Also, previous study using Internet questionnaire identified that lonely participants preferred making voice calls and anxious participants preferred texting . Therefore, it would be suggested that individual’s emotion influence on excessive smartphone use associated with social interaction. 

Although excessive smartphone use did not define clinical criteria for disorder, excessive smartphone use shares similar sub-dimension with addiction criteria of DSM 5 . In particular, the negative aspects of excessive smartphone use share the same effects as Internet addiction including Internet gaming addiction on interpersonal interaction . In previous studies, Internet addiction and pathological Internet use have been shown to lead to negative outcomes including uncontrolled Internet use, tolerance, withdrawal, social isolation and poor academic or professional achievement . However, the study of smartphone addiction as a potential psychiatric disorder is in its infancy, and the evidence supporting problematic smartphone use as an addictive behavior is still insufficient . 

Problematic smartphone use have related to individual’s social interaction. In previous studies, people using SNS more in terms of time spent usage were found to be less involved in the real life community , and individuals who did not feel comfortable with their peers in real life tend to use social networking service (SNS) more in order to compensate . In some studies, the negative consequences of using SNS use considered as criteria for substance dependence, and these might be considered as valid criteria for behavioral addiction . Addiction influence on the brain’s neuronal circuits necessary for not only reward and motivation, but also social behaviors, and thus allows addicted individuals to make poor choices despite awareness of the negative outcomes . Internet addiction criteria of DSM 5 have included social isolation, and previous studies related to Internet addiction, Internet gaming addiction, and smartphone addiction have considered important role of social interaction or interpersonal relationship on addiction . It is necessary to take account of individual’s personality traits in order to understand characteristic of social interaction in smartphone addiction. In particular, personality traits related to emotional processing are key to understanding social interaction. 

It is known that the behavioral inhibition (BIS) and behavioral activation (BAS) systems are closely related not only to temperament and personality traits but also to a wide range of affective experiences . The BAS are associated with positive emotional and extroversion, whereas BIS are closely related to negative emotional and emotional instability . Furthermore, BAS and BIS are explained on the basis of the independent and distinctive structures in the nervous system and behavioral patterns . According to Gray’s theory, the BIS/BAS systems are theoretical biopsychological systems related to personality traits involving sensitivity toward stimuli associated with negative and positive reinforcement and regulation of motivational behavior . In particular, it is reported that BIS is sensitive to punishment and non-reward cues in terminating behavioral output, and BAS is not only sensitive to reward cues and activating goal directed behavior , but also likely to promote the experience of positive feelings such as exaltation and happiness . Additionally, BAS are considered to be personality factors associated with Internet addiction  and smartphone dependency . In previous studies, BAS activity is associated with substances use such as alcohol . It has been reported that BIS and BAS were associated with the neural activity in the lateral prefrontal cortex  and dorsal anterior cingulate cortex (dACC)  related to cognitive control. Therefore, it can be supposed that individual personality traits in excessive smartphone use have an influence on behavioral and neural response for social reward cue. 

In this study, we have designed a task to explore altered brain activity in excessive smartphone use during cognitive control of an emotional face. In previous studies, a facial emotion discrimination task has been generally used to study social interaction . The perception of changes due to facial movements plays a more central role in social communication . In previous studies, an increased level of general anxiety, including social anxiety, is related to excessive smartphone use , and socially anxious individuals revealed attentional biases toward threatening stimuli, especially angry faces . In previous neuroimaging studies, the dorsolateral prefrontal cortex (DLPFC) and dACC have been shown to be engaged in cognitive control and emotional regulation . Previous studies using animal models of affective learning and imaging studies of either cognitive control or emotional responding in both healthy and psychiatric populations have implicated regions of the prefrontal cortex (PFC) and anterior cingulate cortex (ACC) . The DLPFC may be more involved in maintaining a representation of the context, such as goals, rules and sequence of events, necessary to perform a task accurately . Additionally, the ACC has been shown to be activated by the manipulation of interference and cognitive loading in a previous study related to working memory . Activation of this region is thought to be related to detecting cognitive conflict and signaling the need for greater allocation of attention for the purpose of resolving conflict . 

In this study, we will focus on identifying altered brain activity involved in social interaction in those with excessive smartphone use. Although the relationship between excessive smartphone use and social interaction has been reported , no evidence has been found proving altered neural activity of social emotion in excessive smartphone use. Therefore, we investigated the differences in the behavioral and neural responses between the excessive smartphone use group (SP) and the normal control group (NC) in the cognitive control of facial expressions in order to find neurobiological evidence of excessive smartphone use affecting social interaction. Additionally, this study tends to investigate the influence of personality trait related reward system on the emotional processing due to social context in excessive smartphone use. We examined the correlations between BAS reward response and the behavioral and neural responses related to facial emotion processing in the SP compared with NC. 

This study investigated the effect of excessive smartphone use on neural activity during facial emotion discrimination through the following hypothesis. First, we hypothesized that the SP would show a cognitive deficit during the emotional transition of faces requiring fast emotional regulation. Second, we expected that there is altered neural activity in the SP compared to that in the NC in the prefrontal and cingulate cortex related to emotional regulation and cognitive control. Lastly, we hypothesized that BAS-Reward Responsiveness (BAS-RR) is correlated with the responses of happy faces related to the emotional reward in the SP. 


## Results 
  
### Demographics and clinical data 
  
Table   summarizes the demographic and clinical characteristics of the two groups. The two groups did not differ in age, K-WAIS, and the main usage of smartphones, whereas the time of smartphone use per week,   t  (50) = 4.67,   p   < 0.001, the time of major smartphone use per week,   t  (50) = 3.47,   p   < 0.005, and Smartphone Addiction Proneness Scale (SAPS) scores,   t  (50) = 4.55,   p   < 0.001 were significantly different. The SP showed higher score on the BIS,   t  (50) = 3.6,   p   < 0.001 and BAS,   t  (50) = 5.38,   p   < 0.001, and particularly the SP revealed higher score on the BAS-RR,   t  (50) = 2.32,   p   < 0.005 and BAS-Fun Seeking (BAS-FS),   t  (50) = 5.08,   p   < 0.001 compared to NC. Additionally, there was a significant difference in the education duration,   t  (51) = 2.16,   p   < 0.05, but the difference was around a year. According to gender distribution, there was no significant difference across groups.   
Demographic characteristics of the PSU and NC. 
  
Abbreviations: SP, Excessive smartphone use group; NC, Normal control group; SAPS, Smartphone Addiction Proneness Scale; BIS, Behavioral inhibition system; BAS, Behavioral activation system. 

*  p   < 0.05, **  p   < 0.005, ***  p   < 0.001. 
  


### Behavioral performance 
  
As shown in Table   and Fig.  , we conducted a repeated-measures ANOVA on the error rate with emotional valence of face (happy and angry), emotional status (repetition vs. transition), and group (SP and NC). For error rate, there was a 3-way interaction between the emotional valence, emotional status, and groups,   F  (1,50) = 11.52,   η   = 0.91,   p   < 0.001. The ANOVA revealed significant interaction between the emotional valence and emotional status of the face,   F  (1,50) = 14.19,   η   = 0.96,   p   < 0.001.   
Behavioral responses. 
  
Abbreviations: SP, Excessive smartphone use group; NC, Normal control group; HH, Happy face followed by happy face; AH, Angry face followed by happy face; AA, Angry face followed by angry face; HA, Happy face followed by angry face. 
    
Behavioral responses of each group. In the SP, the error rate for AH was higher than that for the HH, and the error rate for the AA was higher than that for the HA (  a  ); however, there were no significant differences between conditions in the NC (  b  ). The SP showed a higher error rate than the NC in the AH. The SP exhibited slower responses in the AH than in the HH, and they also showed slower responses in the AA than the HA (  c  ). The NC showed delayed responses in the AH trials compared to that in the HH trials, however, there were no significant differences between the AA and the HA in the NC (  d  ). 
  

In the SP, the error rate for the AH was higher than that for the HH,   t  (24) = 4.67,   p   < 0.001, and the error rate for the AA was higher than that for the HA,   t  (24) = 2.50,   p   < 0.05; however, there were no significant differences between conditions in the NC. In the group comparison, the SP showed a higher error rate than the NC in AH,   t  (50) = 2.04,   p   < 0.005. 

For the reaction time, there were main effects for the emotional valence of the face,   F  (1,50) = 20.05,   η   = 0.99,   p   < 0.001, and emotional status,   F  (1,50) = 33.32,   η   = 1.00,   p   < 0.001. There were a 3-way interaction among the two conditions and the groups,   F  (1,50) = 13.03,   η   = 0.94,   p   < 0.005. There was a significant interaction in the reaction time between the emotional valence of the face and the groups,   F  (1,50) = 5.14,   η   = 0.60,   p   < 0.05. There was a significant interaction between the emotional valence and emotional transition of the face,   F  (1,50) = 81.46,   η   = 1.00,   p   < 0.001. 

The SP exhibited slower responses in the AH than in the HH,   t  (24) = 8.45,   p   < 0.001, and they also showed slower responses in the AA than the HA,   t  (24) = 2.77,   p   < 0.05. The NC showed delayed responses in the AH trials compared to that in the HH trials,   t  (26) = 5.96,   p   < 0.001, however, there were no significant differences between the AA and HA in the NC. 

Regarding to correlation between the behavior response and effect of personality trait, BAS-RR score revealed a significant negative correlation with the error rate during the HH,   r   = −0.42,   p   < 0.05, in SP, however there was no significant correlation in NC (Fig.  ). The results were converted to equally probable z-scores, comparing Fisher’s z-transformed correlation values across groups (z = 1.65,   p   = 0.049).   
Correlations among neural activity of the ROIs, the error rate, and the BAS-RR scores. In the SP, the activation of the right DLPFC did not showed correlation with behavioral error (  a  ), and the dACC exhibited negative correlation with the error rate under HH,   r   = −0.53,   p   < 0.05 in SP (  b  ). In the SP compared to NC, the error rate revealed a significant negative correlation with BAS-RR score during the HH,   r   = −0.42,   p   < 0.05 (  c  ). 
  


### Functional MRI results 
  
#### Group differences in emotional valence 
  
The results from the emotional valence of the face condition analysis are presented in Table  . In the happy face condition, the SP showed less activity in the left precentral gyrus (PG), left lingual gyrus (LG), right inferior temporal gyrus, left middle frontal gyrus (MFG), and left middle temporal gyrus than the NC. In the angry face condition, the SP exhibited less activity in the bilateral precentral gyri, left LG, bilateral middle temporal gyri, right superior parietal gyrus (SPG), left middle occipital gyrus, right dACC, left DLPFC, right supplementary motor area (SMA), right cuneus, right thalamus, left cerebellum, left superior occipital gyrus (SOG), and left MFG than the NC. However, the SP did not exhibit significantly more activity than the NC in either the happy or angry face condition.   
Group differences of brain regions showing significant activation in each emotional valence. 
  
Clusters with peak-level and FWE-corrected p < 0.001 and more than 100 voxels are reported. 

Abbreviations: L., Left; R., Right; B., Bilateral; ACC, Anterior cingulate cortex; DLPFC, Dorsolateral prefrontal cortex; SMA, Supplementary motor area; FWE, family wise error. 
  


#### Group differences in emotional status 
  
The results from the analysis of the emotional status are presented in Table  . The SP showed less activity in the right inferior temporal gyrus, left LG, and left PG than the NC with emotional repetition. The SP exhibited less activity in the bilateral precentral gyri, left LG, left STS, left SPG, left DLPFC, right interior temporal gyrus, left SMA, left inferior frontal gyrus, left supramarginal gyrus, left dorsal ACC, right TPJ, left inferior parietal gyrus, left SOG, right cuneus, and right superior frontal gyrus (SFG) with emotional transition. However, the SP did not exhibit significantly more activity than the NC with either emotional repetition or transition.   
Group differences of brain regions showing significant activation in emotional status. 
  
Clusters with peak-level and FWE-corrected p < 0.001 and more than 100 voxels are reported. 

Abbreviations: L., Left; R., Right; B., Bilateral; STS, Superior temporal sulcus; ACC, Anterior cingulate cortex; DLPFC, Dorsolateral prefrontal cortex; SMA, Supplementary motor area; TPJ, Tempro-parietal junction; FWE, family wise error. 
  


#### Regional differences between conditions within groups 
  
The results from the analysis of the reginal differences between conditions for each group are presented in Table  . The SP showed stronger activation in the right SFG, right LG, left middle occipital gyrus, right dorsal ACC, right MFG, right thalamus, right postcentral gyrus, right superior temporal gyrus, and left inferior parietal gyrus during AH than during HH. Additionally, they revealed more activation of the right SFG, right DLPFC, left SPG, right inferior parietal gyrus, and right angular gyrus during AA than during HA. There were no significant differences in activity dependent on the condition in the SP. In contrast, the NC showed stronger activation in the left SPG, left SMA, left LG, and right SOG during AH than during HH. There were no significant differences dependent on other conditions in the NC.   
Brain regions of each group showing significant activation in conditions. 
  
Clusters with peak-level and FWE-corrected p < 0.05 and more than 100 voxels are reported. 

Abbreviations: L., Left; R., Right; B., Bilateral; ACC, Anterior cingulate cortex; DLPFC, Dorsolateral prefrontal cortex; SMA, Supplementary motor area; FWE, family wise error; *Region of Interest. 
  


#### ROIs analysis 
  
In the region of interest (ROI) analysis for exploring the activation differences of the DLPFC (Fig.  ), the main effect of the emotional status of the face was significant,   F  (1,50) = 4.75,   η   = 0.57,   p   < 0.05, and the activation of DLPFC during emotional repetition was higher than that during emotional transition. The interaction between the emotional status and group was significant,   F  (1,50) = 8.90,   η   = 0.83,   p   < 0.005. Also, the interaction between the emotional valence of the face and the emotional status was significant,   F  (1,50) = 48.35,   η   = 1.00,   p   < 0.001.   
Neural activity in the DLPFC and dACC of each group. The right DLPFC extracted from the contrast between HH and AH in SP (  a  ), and the right DLPFC in the SP showed stronger activity with emotional repetition than emotional transition, while the difference was not significant in the NC. Additionally, the NC showed greater activity in AH than in HH, while the difference was not significant in the SP (  b  ). The right dACC extracted from the contrast between AA and HA in SP (  c  ). In the right dACC, the SP showed greater activity in the happy than the angry faces, but the NC did not show a significant difference. Additionally, the SP revealed deactivation of the dACC in the HH, AA, and HA trials compared to observed in the NC (  d  ). 
  

In the multiple comparison, the right DLPFC in the SP showed stronger activity with emotional repetition than emotional transition,   t  (24) = 3.22,   p   < 0.05, while the difference was not significant in the NC. In the AH, the NC showed greater activity in the right DLPFC than in HH,   t  (26) = 3.90,   p   < 0.005, but the SP did not show a significant difference in activity between the AH and HH. 

In terms of the activity in the right dACC (Fig.  ), the main effects of emotional valence of the face,   F  (1,50) = 8.37,   η   = 0.81,   p   < 0.005, and emotional status,   F  (1,50) = 16.58,   η   = 0.98,   p   < 0.001, were significant. The activation of dACC during happy face trials was higher than that during angry face trials, and the activation of dACC during emotional transition was higher than that during emotional repetition. The 3-way interaction among the emotional valence, emotional status, and the groups was significant,   F  (1,50) = 6.43,   η   = 0.70,   p   < 0.05. The interaction between the emotional valence of the face and the group was significant,   F  (1,50) = 6.15,   η   = 0.11,   p   < 0.05. Additionally, the interaction between the emotional valence and emotional status of the face was significant,   F  (1,50) = 23.51,   η   = 1.00,   p   < 0.001. In the right dACC, the SP showed greater activity in the happy than the angry faces,   t  (24) = 3.23,   p   < 0.001, but the NC did not show a significant difference. 

In the SP, multiple comparisons revealed that the activation of the right dACC exhibited negative correlation with the error rate under HH,   r   = −0.53,   p   < 0.05 (Fig.  ), however, right DLPFC did not show a significant correlation between the BAS score and regional activations. 




## Discussion 
  
The aim of this study was to identify the behavioral differences between the SP and NC, and the altered brain activation of the prefrontal and cingulate cortex associated with cognitive control in SP compared to that of NC during facial emotion processing. Additionally, we identified the correlations between the BAS-RR activity, behavioral, and neural response during facial emotion processing related to emotional reward. We hypothesized that, based on the vulnerability of the excessive smartphone user in social interaction, SP would reveal deficit of cognitive control in behavioral and neural responses during facial emotional processing. In addition, we predicted that reward sensitivity in the SP would influence on cognitive processing of social reward cue. 

In this study, the SP showed higher error rate induced by failure of cognitive control during presentations of angry face in the previous trial, whereas the NC did not show such a difference. These results indicated that the SP suffered difficulty on cognitive control caused by emotional evaluation when they are exposed to negative emotional expression. In particular, the SP showed a higher error rate under the emotional transition preceded by a negative emotional face, compared to the NC. These behavioral findings would indicate that the previous exposure to a negative emotion influenced the cognitive control on the current emotional transition trial in the SP. 

In the neural response, the SP showed decreased activation in the dACC and DLPFC related to cognitive control of facial emotion compared to NC under angry face and emotional transition. These results associated with previous studies which reported dysfunction of frontolimbic region related to cognitive control in Internet gaming disorder . The previous studies have reported that cognitive reappraisal of negative emotion activates the dACC and PFC systems that support the selection and application of reappraisal strategies and modulate activity in appraisal systems suitable for the goal of reappraisal . In the results of meta-analysis, it has been reported that emotional interference during cognitive conflict induced neural activities in the DLPFC and dACC . Therefore, decreased activity of both the dACC and DLPFC in the SP suggests that the cognitive control of negative emotion and emotional transition has been altered compared to that in the NC. Consistent with neural activities, the SP reported higher error in emotional transition after angry face comparted to NC. Therefore, excessive smartphone user has a harmful effect on cognitive control during emotional face processing, and this impairment might be influenced on emotional processing related to social interaction. Additionally, the SP revealed neural deactivation of the STS and TPJ compared to the NC. According to a previous study related to facial information, the activation of the STS is associated with processing and reacting to the emotional state of another person . Additionally, it has been known that the right TPJ is selectively recruited for the attribution of mental states when receiving socially relevant stimuli  and is more responsive to mentalizing than physical judgments . Therefore, this evidence suggests that activation of the STS and TPJ during emotional transition reflects the social cognitive effort to make a rapid emotional judgment, and the SP showed a lower neural response towards emotional information involved in social context than the NC. 

In the ROIs comparison, we found that NC showed higher activation of DLPFC during presentations of angry face in previous trial than during presentations of happy face in the previous trial, while the SP did not show significant difference of neural activation between the previous emotional valences under current happy face. Cognitive reappraisal has been known to enhance the signal in the DLPFC regions in cognitive regulation of negative emotion . In a previous study on emotional distracters, normal control participants were able to recruit the DLPFC; however, depressed individuals showed an exaggerated amygdala response to such distracters and a failure to recruit the DLPFC . In this study, the activation of DLPFC during emotional repetition was higher than that during emotional transition. The effect of repeated emotion revealed only in the angry face, not in the happy face. In particular, SP showed strong activation in DLPFC during repeated angry face compared to non-repeated angry face. In the previous study related to emotional processing, the repeated negative stimuli induced significant activation in the DLPFC, and functional connectivity between the DLPFC and other regions . The activation of DLPFC can be regarded as a cognitive effort in other to process repeated angry faces. In previous studies, the right lateral prefrontal regions have been shown to be activated under interference conditions , and the activation of right DLPFC region negatively correlated with sensitivity of interference . Despite the higher DLPFC activation, the SP showed more behavioral errors during the repeated angry face than non-repeated angry face. Therefore, it would imply that the neural activity related emotional regulation fails to control the behavioral performance in excessive smartphone user. 

The SP also showed less activation of the dACC, which is related to conflict monitoring, during presentations of angry faces than the NC and compared to happy faces within the SP. The dACC has been known to be associated with detecting cognitive conflict  and signaling the need for greater allocation of attention for the purpose of resolving conflict . In the previous study related to altered brain structure of mobile phone dependence (MPD), MPD individuals had decreased gray matter volume relative to controls, and they showed decreased white matter integrity of bilateral hippocampal cingulum bundle fibers . Therefore, it can be inferred that the SP have a deficit in cognitive monitoring during the presence of negative emotional faces compared to NC and, as this result, the SP revealed higher error rate under angry face followed by happy face compared to NC. Additionally, the SP showed a higher error with less neural activity in the dACC related to cognitive monitoring during repeated happy face, while there was no significant correlation between error rate and activity in the DLPFC related to cognitive conflict resolution. In other words, it imply that the SP showed individual differences according to cognitive monitoring during repeated happy face related to emotional reward. 

In this study, correlations between the BAS-RR level, behavioral and neural response of facial emotion were shown to depend on the group. In the correlation results, high BAS-RR individuals in the SP exhibited low error rate during repeated happy face. In particular, the correlation between the BAS-RR and error rate in repeated happy face showed a significant difference between the SP and NC. These results indicate that sensitivity of reward more influence behavioral performance during repeated positive facial expression in the SP compared to NC. Therefore, it can be supposed that high BAS-RR individuals in the SP are sensitive to emotional reward such as happy face, and they might use social network service in order to gain positive responses. This is related to a previous finding that people who have a negative social identity tend to use SNSs more in order to compensate for this . 

Finally, a number of important limitations need to be considered. First, the participants did not evaluate the emotional valence and arousal of each face in this study. Second, the main usages of smartphone were heterogeneous among the participants. A future study with more focus on problematic social network service use through smartphones is therefore suggested. Third, the gender differences in excessive smartphone use group were not considered. In subsequent study, it is necessary to identify differences in facial emotional discrimination according to gender differences in the SP using the same gender distribution. Additionally, we suggest that the functional connectivity of fronto-cingulate regions in SP are investigated in social cognitive contexts in future studies. 

In summary, we showed that the SP exhibited different behavioral responses and functional alterations compared to the NC during emotional processing of faces. The SP revealed a cognitive deficit during the emotional transition preceded by a negative emotional face, compared to NC. In the neural activity, the SP showed a neural deactivation of prefrontal and cingulate cortex related to conflict detection and cognitive control compared to that of the NC during exposure to angry faces and emotional transition. The behavioral performance in the SP correlated with the activity of dACC related to cognitive monitoring during repeated happy face associated with emotional reward. Lastly, we found BAS-RR level was correlated with behavioral responses during repeated happy faces related to emotional reward in SP compared to NC. These findings may help us to understand altered neural responses associated with cognitive control during facial emotional processing, and could provide important implications for the effect of personality traits related to emotional reward in excessive smartphone use. 


## Methods 
  
### Participants 
  
This study was conducted for adult men and women aged 19–35 through online recruiting. A total of 728 adults participated in the online survey on smartphone usage. Twenty-six adults with SP (14 male and 12 female) and 30 NC (18 male and 12 female) were recruited for the fMRI study, and all participants underwent the Mini-International Neuropsychiatric Interview by a clinician to screen out participants with a current psychiatric diagnosis. One participant was excluded because of depressive disorder, and the data from three participants were excluded because of severe head motion during the analysis; thus, the data from twenty-five adults with problematic smartphone use (13 male and 12 female, 27.76 ± 5.97 years) and twenty-seven NC (18 male and 9 female, 28.93 ± 6.39 years) were considered in this study (Table  ). Exclusion criteria included past or current major medical disorders (e.g., diabetes mellitus), neurological disorders (e.g., seizure disorders, head injury) or psychiatric disorders (e.g., major depressive disorder, anxiety disorders). All participants had normal or corrected-to-normal vision and were right-handed assessed by the Edinburgh handedness inventory . The purpose and procedure of this study were explained to the participants. Each participant provided written informed consent, and this study was approved by the Institutional Review Board of Seoul St. Mary’s Hospital. All experiments were performed in accordance with relevant guidelines and regulations. 


### Questionnaires 
  
#### SAPS 
  
Excessive smartphone use was estimated using SAPS developed by the Korean National Information Society Agency in 2011 and the reliability test of the scale yielded a Cronbach’s alpha of 0.814 . The SAPS is a self-report scale and includes fifteen items, and the responses are scored on a four-point Likert scale (1: Not at all to 4: Always). The SAPS has four subscales: disturbance of adaptive functions, virtual life orientation, withdrawal, and tolerance, and participants were classified as SP if their total score exceeded 44, or if their subscales scores exceeded 15, 13, and 13 for disturbance of adaptive function, withdrawal, and tolerance, respectively. 


#### BIS/BAS 
  
BIS and BAS are general motivation systems that underlie behavior and affect . The BIS responds to cues associated with punishment; the BAS responds to those associated with reward. The BIS and BAS questionnaire scales assess BIS (7 items) and three subdomains of BAS-D (4 items), BAS-FS(4 items), and BAS-RR (5 items) . Responses used a 4-point scale (1: strongly disagree, 4: strongly agree). Items on the BIS scale assess sensitivity to the mechanism controlling aversive motivation. Items in the BAS-RR subscale assess positive responses to anticipated rewards. Items in the BAS-D subscale assess persistent pursuit of desired appetitive goals. Items in the BAS-FS subscale assess desire for new rewards and willingness to spontaneously approach potentially rewarding events . 



### Facial emotion discrimination task 
  
Participants performed a facial emotion discrimination task using Korean emotional faces, which were selected from the Korean Facial Expressions of Emotion . To maintain the participants’ attention, the stimulus material for each trial consisted of a positive or negative emotional face on the left or right side and a fixation cross at the center of the gray background. Half of the participants were asked to press a button with their left or right index finger in response to a positive or negative feeling produced by the picture, respectively, regardless of the picture’s location. The other half of the participants were assigned to respond in the opposite manner as a counterbalance. The trials consisted of four different stimuli according to emotional valence (happy vs. angry) and emotional status (repetition vs. transition) of face. The task sequence was separated into two sessions and was composed of a rapid event-related design in which the duration of each trial was 1,500 ms and the inter-trial intervals were varied from 500 to 4,500 ms. Each session started with a 12-s dummy scan with six practice trials and included 160 events consisting of 40 repeated happy face trials, 40 non-repeated happy face trials, 40 repeated angry face trials, and 40 non-repeated angry face trials, and thus took a total duration of 7 min 32 s. 


### Image acquisition 
  
Functional and structural MRI data were acquired using a 3T MRI system (Siemens, MAGNETOM Verio, Erlangen, Germany) equipped with a 16-channel head coil. Participants’ heads were cushioned with attached earmuffs. The functional images were obtained using a T2*-weighted gradient echo-planar imaging sequence (31 slices of 3.5-mm thickness and no gaps, repetition time [TR] = 2,000 ms, echo time [TE] = 30 ms, flip angle = 90°, image matrix = 124 × 124, field of view = 220 mm) with an in-plane resolution of 1.719 mm × 1.719 mm. Structural images with a resolution of 0.859 mm × 0.859 mm × 1.2 mm were acquired using a 3D T1-weighted gradient echo sequence (170 slices, TR = 9.692 ms, TE = 4.59 ms, image matrix = 224 × 224). 


### Data analysis 
  
#### Behavioral data 
  
The behavioral data were analyzed according to the emotional valence of the face, the stimuli exposure, and the group. The three variables of interest were the emotional valence of the face (happy vs. angry), emotional status (repetition vs. transition), and group (SP vs. NC). The task performances, measured by accuracy and reaction time, were analyzed by a repeated measures analysis of variance (ANOVA) to assess the main effects of the three factors and their interactions using IBM SPSS Statistics for Windows, Version 20.0 (IBM SPSS Inc., Armonk, NY). Subsequent paired t-tests for post hoc analyses were performed to test the significance between the different conditions and groups. 


#### Image data 
  
Image preprocessing and statistical analysis were performed with Statistical Parametric Mapping software (SPM8; Wellcome Department of Cognitive Neurology, London, UK). After discarding the first six images from the dummy scan at each session, the remaining 220 images were used for further preprocessing. Differences in the slice acquisition time of the interleaved sequence were corrected, and realignment was performed to correct the artifact created by head motion. The corrected images were coregistered on the T1-weighted image of the same participant. The T1-weighted images were normalized to the standard T1 template, and the resulting transformation matrices were applied to the coregistered functional images. Functional data were smoothed with a Gaussian kernel of 8-mm full-width at half-maximum. 

Preprocessed data were analyzed using a general linear model. Experimental trials were modeled separately using a canonical hemodynamic response function for individual data. Multiple linear regression, as implemented in SPM8 using a least-squares approach, was used to obtain the parameter estimates . These estimates were then analyzed by testing specific contrasts using the participant as a random factor. According to the emotional valence and emotional status of the face, all trials were classified as HH, AH, AA, and HA trials. Images of the parameter estimates for each condition were created in the primary analysis, during which individual realignment parameters were entered as regressors to control for movement-related variance. 

For the secondary analysis, the parameters for the four conditions, which were estimated in the primary analysis, and group condition were entered into the flexible factorial model, in which contrast maps were compared for group differences. The results were measured with group differences in relation to the emotional valence (happy and angry) and emotional status (repetition vs. transition) of the face. Significant results were determined by family-wise error (FEW) corrected p values of less than 0.001 and more than 100 voxels preferentially. 

Post hoc tests for interactions and correlation analysis were performed on the a priori regions of interest (ROIs), which were defined as significant clusters within fronto-cingulate regions including the dACC [6, 10, 38] and DLPFC [48, 16, 32] related to cognitive control for emotional faces in group. The % BOLD signal changes in the ROIs were extracted in each condition using MarsBaR version 0.41 (  http://marsbar.sourceforge.net  ), and the differences for the ROIs were analyzed using repeated measures ANOVA. The correlations between ROIs and behavioral error rate were calculated using Pearson correlation analyses in each condition and groups, and the p-values were adjusted by Benjamin–Hochberg FDR for multiple comparisons. Also, the statistical difference in regional correlation results between groups was computed after application of Fisher’s r-to-z transform. 



 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-42'>
<h2>42. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31877452/' target='_blank'>31877452</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Brain imaging correlates of self- and other-reflection in schizophrenia</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Neuroimage Clin</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1016/j.nicl.2019.102134</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6931228/' target='_blank'>6931228</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study used fMRI during a social-related task (self- and other-reflection vs. facts), which falls under Perception and Understanding of Self and Others. It reports data from a healthy control group (n=33; adults matched 18–65) with results for controls presented separately alongside a patient group. Analyses were whole-brain (FEAT/FSL mixed-effects GLM with cluster-level correction, Z=2.3, p<0.05), not ROI-only. Therefore it meets all inclusion criteria (social-related fMRI task, healthy adult participants with separate results, whole-brain analyses). No exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>   Highlights  
  
Self- and other-reflection in schizophrenia were studied with fMRI. 
  
Patients failed to activate the right temporo-parietal junction in other-reflection. 
  
They also hyperactivated lateral prefrontal cortex for self and other-reflection. 
  
These findings might be linked to altered self/other processing in schizophrenia. 
  
  
## Background 
  
An alteration in self/other differentiation has been proposed as a basis for several symptoms in schizophrenia, including delusions of reference and social functioning deficits. Dysfunction of the right temporo-parietal junction (TPJ), a region linked with social cognition, has been proposed as the basis of this alteration. However, imaging studies of self- and other-processing in schizophrenia have shown, so far, inconsistent results. 


## Methods 
  
Patients with schizophrenia and healthy controls underwent fMRI scanning while performing a task with three conditions: self-reflection, other-reflection and semantic processing. 


## Results 
  
Both groups activated similar brain regions for self- and other-reflection compared to semantic processing, including the medial prefrontal cortex, the precuneus and the TPJ. Compared to healthy subjects, patients hyperactivated the left lateral frontal cortex during self- and other-reflection. In other-reflection, compared to self-reflection, patients failed to increase right TPJ activity. 


## Conclusions 
  
Altered activity in the right TPJ supports a disturbance in self/other differentiation in schizophrenia, which could be linked with psychotic symptoms and affect social functioning in patients. Hyperactivity of the lateral frontal cortex for self- and other-reflection suggests the presence of greater cognitive demand to perform the task in the patient group. 

 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (35546 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
A disturbance in the process of distinguishing the self from others is proposed as a relevant factor contributing to the symptom profile in schizophrenia: poor self/other distinction may lead to incorrect attribution of one's own thoughts or intentions to others, resulting in paranoia and ideas of reference, or to a disruption of the sense of agency of behavior leading to delusions of control ( ). Self/other differentiation has been proposed to involve both motor processes underpinning imitation and cognitive processes linked to mentalizing and reasoning about the other's beliefs and emotions ( ), and its failure (self/other blending) might impair perspective taking, among other processes ( ). As a result, it can also affect social interaction in terms of increasing social anhedonia and social withdrawal ( ;  ;  ). Social functioning deficits are common in schizophrenia and can result in the misinterpretation of others’ intentions and difficulties in daily social interactions ( ). These deficits are closely linked to worse functional outcomes ( ). Therefore, a better understanding of the alterations in processing self- and other-related information will be an important contribution to the improvement of therapeutic interventions and patients’ quality of life. 

Brain activity related to self-reflection is typically assessed with tasks that require the participant to decide whether a particular trait adjective or descriptive statement applies to themselves. For other-reflection, the same kind of decision is applied to another personally or publicly known person. Both conditions are associated with activation in a network of regions which include the medial prefrontal cortex (mPFC), the temporo-parietal junction (TPJ), and the posterior cingulate cortex (PCC) ( ), very similar to the regions associated with social cognition, theory of mind, autobiographical memory or future planning, which are often referred to as the default-mode network (DMN,  ). The involvement of DMN regions in such a broad range of cognitive functions has led to the hypothesis that one of the core functions of the network is to process self-relevant or social information ( ;  ). Patients with schizophrenia have shown altered brain activity in DMN regions during self-reflection, including the PCC ( ;  ), the mPFC ( ), and the temporal cortex ( ). Other-reflection has been associated with altered activation of the PCC ( ), the temporal cortex ( ), and the mPFC and cuneus ( ), but also in regions not traditionally linked to other-reflection like the insula ( ) and the fusiform and lingual gyri ( ). These findings suggest that there is altered DMN function during self- and other-reflection in schizophrenia, although the lack of consistency among the results makes it difficult to characterize the nature of the alteration precisely. 

Although self- and other-reflection tend to activate a similar set of brain regions, studies have also shown differences between the two conditions in the mPFC (with ventral mPFC more linked to self-reflection and dorsal mPFC to other-reflection) and the TPJ, among other areas ( ). The TPJ (especially in the right hemisphere) has been proposed as a key brain structure for self/other differentiation, with its disruption generating deficits in self and other representations in several psychiatric disorders ( ). Literature on the function of the right TPJ has highlighted its involvement in tasks that require processing information about others’ intentions and mental states, like theory of mind or moral judgments tasks ( ), which is consistent with such a role. Alteration of TPJ function by means of non-invasive brain stimulation affects third-person perspective taking ( ), which has signaled this region also as a potential target for intervention ( ). It is important to note, though, that the TPJ is a functionally defined region that can be subdivided in different portions ( ): the most posterior and dorsal parts of the TPJ (i.e. angular gyrus) seem to be more linked with social information processing and tend to co-activate with other regions involved in self-reflection and theory of mind, while anterior parts are associated with externally cued attention ( ). There also seems to be a hemispheric asymmetry in the TPJ, since social cognition has been especially linked to the right TPJ while the left has been attributed a more general role in meta-representation (for a review, see  ). However, this remains an open issue since the left TPJ is sometimes also activated in social processing tasks ( ). 

Alterations in self/other differentiation in schizophrenia may be observed in the comparison between self- and other-reflection. For example,  , using a task where participants heard their own pre-recorded voice alternated with someone else's voice, found that the ‘self’ and ‘non-self’ cortical maps were more overlapped in patients with schizophrenia than controls, affecting the medial frontal cortex and PCC/precuneus, the right middle temporal cortex and the right inferior parietal cortex (adjacent to the TPJ). This was interpreted as impairment for self/other differentiation in the patient group.   found an alteration in the dorsomedial prefrontal cortex in patients, who showed similar levels of activity in this region for self and other-processing, while the controls significantly increased its activity for self-reflection compared to other-reflection. However, other studies have reported no differences between patients and controls ( ;  ;  ;  ), or found differences outside the typical self/other-reflection areas (e.g., the precentral gyrus in  ). 

The studies reviewed above reveal that, although self/other processing and differentiation are proposed as a basis for several symptoms in schizophrenia, consistent deficits in the neural correlates of these cognitive processes are yet to be characterized. This heterogeneity in previous studies might be a result of the combination of different factors: first, most of the studies on self/other reflection in schizophrenia have used tasks where trait adjectives or sentences are presented to the participants, who have to decide whether these traits apply to themselves or to another person. However, the control conditions against which self- and other-reflection are contrasted vary from affect labeling (i.e. judging whether the adjective is positive or negative) ( ;  ;  ), semantic knowledge (i.e. answering Yes or No to sentences about general facts) ( ;  ) or perceptual tasks ( ;  ). Contrasting self- or other-reflection against conditions that might impose different cognitive demands (e.g. semantic knowledge is likely to be more demanding than perceptual tasks) may result in differences in the self and other activation maps. Secondly, the degree of familiarity with the individual chosen for other-reflection also ranges from close relatives and friends ( ;  ;  ;  ) to public figures ( ;  ), which could also affect activation patterns (e.g. reflecting upon close relatives may rely more in autobiographical memory, while reflecting upon public figures may involve more semantic memory, and involve different brain regions, see  ). Finally, significant differences in patient status and small sample sizes might also explain the lack of consistency among results. 

The present study aims to further examine self- and other-processing in schizophrenia, with an emphasis on self/other differentiation (i.e. the direct comparison between self- and other-reflection). We will use a self/other-reflection task based on previous studies ( ;  ) that we have already used successfully in healthy subjects ( ), where we observed significant differences between self- and other-reflection in DMN regions with the specific involvement of the right posterior TPJ (angular gyrus) in other, but not self-reflection. Considering the variability in the tasks used in the previous literature, we have selected this task to best isolate the components of interest for our study. We consider that the present work will allow us to broaden the knowledge on the neural basis of self/other differentiation in schizophrenia. Although there is no consistent pattern of findings in the existing schizophrenia literature, we expect that alterations will arise in relevant DMN areas involved in self/other differentiation, namely the mPFC, the PCC and the TPJ. 


## Methods 
  
### Subjects 
  
Thirty-two patients with a DSM-IV-TR diagnosis of schizophrenia recruited from three psychiatric hospitals (Benito Menni CASM, Sagrat Cor de Martorell and Hospital Sant Rafael) in Barcelona participated in the study. They all underwent diagnostic evaluation by trained raters using the Spanish version of the Structured Clinical Interview for DSM Disorders (SCID). Psychotic symptoms were also scored using the Positive and Negative Syndrome Scale (PANSS,  ) and the The Clinical Global Impressions Scale (CGI,  ). Patients were excluded if they (a) were younger than 18 or older than 65 years, (b) had a history of brain trauma or neurological disease, and (c) had shown alcohol/substance abuse within 12 months prior to participation. With respect to the last criterion, all participants were questioned about alcohol and drug use during the previous year by a psychiatrist. As well as excluding patients who showed evidence of substance abuse/dependence, we also excluded those who reported habitual use of cannabis. All patients were right-handed and all were taking antipsychotic medication. 

The control sample consisted of 33 right-handed healthy individuals recruited from non-medical staff working in the hospital, their relatives and acquaintances, plus independent sources in the community. They were selected to be similar to the patients in age, sex and IQ (premorbid IQ in the patients). This last was estimated using the Word Accentuation Test (Test de acentuación de palabras (TAP)  ;  ), which requires pronunciation of Spanish words whose accents have been removed. This test is conceptually similar to the UK National Adult Reading Test (NART) ( ) and the US Wide Range of Achievement Test used in the USA ( ). Scores can be converted into full scale IQ estimates ( ). The control sample met the same exclusion criteria as the patients. They were also questioned and excluded if they reported a history of mental illness and/or treatment with psychotropic medication and the SCID was also used to exclude current psychiatric disorders. 

All participants gave written informed consent prior to participation. All the study procedures had been previously approved by the Research Ethics Committee FIDMAG Sisters Hospitallers (Comité de Ética de la Investigación de FIDMAG Hermanas Hospitalarias) and complied with its ethical standards on human experimentation and with the Helsinki Declaration of 1975, as revised in 2008. Healthy controls received a gift-card as a compensation for their participation in the study. 


### Self-other task 
  
The task used in the present study was adapted from the one described in   and has already been used in healthy subjects by our group ( ) to investigate the processing of information related to the self and another known person, compared to general semantic knowledge. To best isolate the components of interest for our study, this task uses (1) a semantic control condition (matched in perceptual and motor requirements and in statement complexity with the conditions of interest) to separate self- and other-reflection from processing of externally-oriented information, and (2) an ‘other’ condition aimed to compare reflection upon oneself to reflection on other individuals within the participant's environment, for which we selected an ‘other’ personally known by the participant (so responses might be based on previous interactions and not so much on semantic knowledge, and so exposure to this ‘other’ might be more uniform across participants than with public figures), but not a very close ‘other’ to avoid strong emotional investment. 

Before scanning, participants were given detailed task instructions and were asked to choose an acquaintance to think about inside the scanner for the other-reflection condition. The chosen individual had to be familiar to the participant, but not too close in order to avoid eliciting strong feelings towards them (valid examples were classmates or co-workers), similar to the original implementation of the task ( ). The final choice of acquaintance was made in consultation with one of the researchers to ensure the degree of closeness was similar for all participants. 

During the task, participants viewed a series of statements which were either about themselves (Self), about an acquaintance (Other) or about general knowledge (Facts), which were similar in length and complexity in the three conditions. Participants had to respond whether they considered the sentence to be true or false with a button press. In the Self condition, sentences referring to personal qualities, attributes or attitudes were presented (e.g. “In general, I like order”, “I am a tense or very nervous person”). Similarly, in the Other condition sentences referred to the personality traits and behavior of the chosen acquaintance. Examples of sentences included in the Other condition are “OTHER often makes decisions without thinking” or “OTHER usually has very good ideas”, where OTHER was substituted by the chosen person's name. In the Facts condition, sentences referred to general knowledge, such as “A decade is a period of ten years” or “Insects only have four legs”. As in the original version, half of the sentences in the Self and Other conditions had a positive valence and the rest had a negative quality, while in the Facts condition half of the sentences were true and the other half were false. Different from the original, the Self and Other conditions only included statements referring to personality, behavior and attitudes, but not physical appearance (these were a minority in  ). All statements were written in Spanish, and all participants were fluent Spanish speakers. 

The task consisted of 54 trials (18 per condition) arranged in a block design. Each block started with an instruction screen indicating the condition that corresponded to that block (“Sentences about Me”, “Sentences about Other”, “Sentences about Facts”), which lasted 3s. After a 1s delay, three trials were presented, each lasting 9s, where the sentence appeared in the center of the screen and the options “Yes” and “No” appeared at the bottom-right and bottom-left corners, respectively, to act as a reminder of the required response (“Yes” with the right index finger, and “No” with the left index finger). Trials were separated by a 1s blank screen. After the three trials, the next block started, for a total of 6 blocks per condition. Every 3 blocks there was a resting period of 16s in which only a crosshair was presented as fixation point. Block order was pseudorandomized, with each of the three conditions occurring once between resting periods. Total task duration was 12 min and 12 s. This design deviates from the task design used by   in that the trials were longer, resulting in fewer trials overall, but with a similar amount of time spent in each condition. This change was made to ensure participants had time to read and reflect on each statement before responding. As demonstrated in  , this version of the task is able to elicit activation of relevant DMN brain regions in self and other-reflection. 


### Image acquisition 
  
Images were acquired with a 3T Philips Achieva scanner (Philips Medical Systems, Best, the Netherlands). Functional data were acquired using a T2*-weighted echo-planar imaging (EPI) sequence with 364 volumes and the following acquisition parameters: TR = 2000 ms, TE = 30 ms, Flip angle = 78 , in-plane resolution= 3 × 3 mm, FOV = 240 mm, slice thickness = 3 mm, inter-slice gap = 1mm. Slices (32 per volume) were acquired with an interleaved order parallel to the AC-PC plane. Before the functional sequence, a high-resolution anatomical 3D volume was acquired using a TFE (Turbo Field Echo) sequence for anatomical reference and inspection (TR = 8.15ms; TE = 3.73ms; Flip angle = 8 ; voxel size = 0.9375 × 0.9375 mm; slice thickness = 1mm; slice number = 160; FOV = 240 mm). 


### Image preprocessing and analysis 
  
Preprocessing and analysis was carried out with the FEAT module included in the FSL (FMRIB Software Library) software, version 5.0 ( ). The first 20 s (10 volumes) of the sequence, corresponding to signal stabilization, were discarded. Preprocessing included motion correction (using the MCFLIRT algorithm) and co-registration and normalization to a common stereotactic space (Montreal Neurological Institute template). Before group analyses, normalized images were spatially filtered with a Gaussian filter (FWHM = 5 mm). To minimize unwanted movement-related effects, individuals with an estimated maximum absolute movement >3.0 mm or an average absolute movement >0.3 mm were excluded from the study. 

Statistical analysis was performed by means of a General Linear Model (GLM) approach. At the first level, three regressors of interest were defined in the GLM corresponding to the three task conditions (Self, Other, Facts) in a block-design fashion. Instruction screens were modeled by an additional nuisance regressor. Fixation periods were not modeled and thus acted as an implicit baseline. GLMs were fitted to generate activation maps for each of the three conditions of interest compared to baseline and for the comparisons between conditions (Self vs. Facts, Other vs. Facts, Other vs. Self). Second level analyses and group comparisons between patients and controls were performed within the FEAT module, with mixed-effects GLMs ( ). All statistical tests were carried out at the cluster level with a corrected   p   value of 0.05 using Gaussian random field methods. The default threshold of   z   = 2.3 was used to define the initial set of clusters. 



## Results 
  
Demographic and clinical characteristics of the final samples included in the analyses are detailed in  . As can be seen, the patients and the controls did not differ significantly in terms of age, sex and estimated premorbid IQ. Nine patients and 6 controls were excluded from the analyses due to excessive head movement. All patients were on antipsychotic treatment (21 on atypical neuroleptics and 2 on both typical and atypical) and were admitted to inpatient (14 patients) or outpatient (9 patients) units.   
Demographic and clinical sample characteristics. 
  Table 1     

### Self vs. facts mean group results 
  
Brain activity associated to self-reflection was identified by the Self > Facts contrast, where both patients and controls showed similar regions of activation in the medial prefrontal cortex, the PCC and precuneus, the left angular gyrus and TPJ area, the middle temporal cortex (bilateral), and parts of the visual cortex (calcarine cortex and lingual gyrus, see   and Supplementary Table S1 for details).   
Mean activation in Self > Facts control group (A) and in the patient group (B). Images are displayed in neurological convention (right is right). Color bar depicts   z   values. 
  Fig 1   


### Self vs. facts group comparison 
  
Group comparison in the Self vs. Facts contrast showed a cluster of differences in the left DLFPC/middle frontal gyrus (MNI coordinates   x   = -52,   y   = 14,   z   = 36;   Z   = 3.94; cluster size = 527 voxels;   p   = 0.008). As seen in  , the patients hyperactivated this region in self-reflection. Moreover, controls increased activity in the DLPFC in Facts with respect to Self, but this increase was not observed in the patients, who displayed similar (heightened) levels of activation in both conditions.   
Group differences between healthy subjects and schizophrenic patients in the Self vs. Facts contrast. Plot shows the mean parameter estimates (average of all beta weights in the cluster) for the left DLFPC in the Self and Facts conditions (respective to baseline) for each group in the cluster of group differences. Error bars represent standard error of the mean. Images are displayed in neurological convention (right is right). Color bar depicts   z   values. 
  Fig 2   


### Other vs. facts mean group results 
  
Other-reflection (Other > Facts contrast) yielded a very similar pattern of activation to that of Self-reflection, involving mostly the same regions plus the right angular gyrus in the control group. In patients, other-reflection also activated the left insula and putamen (see   and Supplementary Table S2 for details).   
Mean activation in Other > Facts in the control group (A) and in the patient group (B). Images are displayed in neurological convention (right is right). Color bar depicts   z   values. 
  Fig 3   


### Other vs. facts group comparison 
  
This group comparison showed three clusters of differences between patients and controls: one in the precuneus (MNI coordinates   x   = 22,   y   = -46,   z   = 18;   Z   = 3.94; cluster size = 502 voxels;   p   = 0.02), one in the left DLPFC (MNI coordinates   x   = -42,   y   = 50,   z   = 14;   Z   = 4.06; cluster size = 594 voxels;   p   = 0.008), and one in the left precentral gyrus (MNI coordinates   x   = -54,   y   = 8,   z   = 34;   Z   = 4.21; cluster size = 552 voxels;   p   = 0.01). We observed that patients deactivated the precuneus during the Other condition while controls did not (although both groups deactivated this region in the Facts condition, as shown in  ). In the DLPFC and precentral gyrus, we observed increased activation in the patient group in Other-processing (while activation in the Facts condition was similar in both groups). Interestingly, these last two clusters were located very close to the area of differences found in the Self vs. Facts contrast and displayed a similar pattern of alteration in the patient group.   
Group differences between healthy subjects and schizophrenic patients in the Other vs. Facts contrast. Plots show the mean parameter estimates (beta weights) for the precuneus (upper row), the DLPFC (middle row) and the precentral gyrus (lower row) in the Other and Facts conditions (respect to baseline) for each group. Error bars represent standard error of the mean. Images are displayed in neurological convention (right is right). Color bars depict   z   values. 
  Fig 4   


### Self vs. other mean group results 
  
No region showed increased activity in Self trials when compared to the Other condition (Self> Other contrast), neither in the patients nor in the controls. On the other hand, several brain areas were more active in the Other than in the Self condition: healthy subjects showed activation in the precuneus and PCC, mPFC extending into the right hemisphere, angular gyrus, temporal pole and amygdalae, and right superior frontal cortex (Supplementary Table S3,  ). Patients with schizophrenia, however, only showed activation in the PCC and the left temporal pole (Supplementary Table S3,  ).   
Mean activation in Other > Self in the control group (A) and in the patient group (B). (C) Group differences between healthy subjects and schizophrenic patients in the Other vs. Self contrast. Plot shows the mean parameter estimates (beta weights) for the cluster in the right angular gyrus in the Self and Other conditions (respect to baseline) for each group. Patients fail to activate the right angular gyrus in the Other condition. Error bars represent standard error of the mean. Images are displayed in neurological convention (right is right). Color bars depict   z   values. 
  Fig 5   


### Self vs. other group comparison 
  
This group comparison showed a cluster of differences in the right angular gyrus (MNI coordinates   x   = 48,   y   = -64,   z   = 30;   Z   = 4.54; cluster size = 547 voxels;   p   = 0.007), which was activated for other-reflection in the control group, but not in the patients ( ). 



## Discussion 
  
This study aimed to examine the brain correlates of self/other differentiation in schizophrenia by comparing brain activation during self- and other-reflection. We report, for the first time, a significant alteration in right TPJ activity in patients with schizophrenia in other-reflection. In healthy controls, self- and other-reflection activated a similar set of brain regions when compared with a semantic control condition, although direct comparison of self and other revealed that some of them were relatively more active in other-reflection. However, the right TPJ was not activated for self, but only for other-reflection, which is consistent with the role attributed to this area in self/other differentiation and social cognition ( ;  ). In contrast, patients with schizophrenia did not activate right TPJ for either self- or other-reflection. TPJ hypoactivation in schizophrenia has been previously described with social cognition tasks ( ;  ;  ;  ; but see also  ), which shows meta-analytic evidence of both aberrant hypo and hyperactivation of the TPJ in mentalizing tasks). The present finding supports the hypothesis that TPJ dysfunction may underlie a disturbance in self/other differentiation processes in schizophrenia ( ). 

Self/other differentiation is believed to initially involve motor mechanisms underpinning imitation and recognition of action goals, as well as interpretation of facial emotions and non-verbal communication; followed by mentalizing processes that include inferring the mental state of the other or reasoning about their beliefs and emotions ( ). Successfully decoupling the self and other may aid higher level perspective taking. In contrast, when these processes are impaired, self/other blending can occur and the person may have reduced ability in perspective taking, or may not be able to suppress imitation and this could lead to confusion, personal distress and depersonalization ( ). The right TPJ is associated with decoupling mechanisms, referring to the ability to dissociate an agent's mental state from one's own beliefs and to differentiate between belief and reality ( ). This could conceivably provide a basis for patients with schizophrenia being impaired in identifying the origin of beliefs, intentions, or actions, and so having difficulties testing them against reality, resulting not only in difficulties in social interaction but also in delusional explanations of others’ behavior (e.g. ideas/delusions of reference or persecution, grandiosity). 

It should be noted that the TPJ is not a unitary region, and at least two subdivisions have been found using resting-state functional connectivity: a more anterior part that shows connectivity with attentional regions (ventral PFC and anterior insula) and a more posterior subdivision connected with DMN regions (mPFC, PCC/precuneus) ( ). In the present study, group differences were found in the angular gyrus, which belongs to the posterior subdivision of the TPJ, and is usually described as belonging to the DMN ( ). Interestingly, though, there was a laterality effect: the left angular gyrus was activated both by self- and other-reflection (although BOLD signal was higher in the second), but the right was only active during other-reflection. This adds specificity to our results, since the right TPJ has been more strongly linked to self/other differentiation and social cognition in the previous literature than the left ( ). Consistently, there were no group differences in the left TPJ. 

The findings concerning the TPJ are also relevant because this region has been proposed as a target for therapeutic intervention. Several drugs may affect its function, for instance, drugs that alter norepinephrine ( ), selective serotonin reuptake inhibitors ( ) and intranasal oxytocin ( ). In addition, the TPJ is a promising target for neuromodulation techniques such as repetitive transcranial magnetic stimulation (rTMS) and transcranial direct current stimulation (tDCS) ( ). 

In the present study, we also observed hyperactivation of the left lateral frontal cortex (including the DLPFC and the precentral gyrus) during self- and other-reflection. Detailed examination of the activation pattern in this area revealed that hyperactivation was specific to self/other processing, while activation levels were similar between groups in the semantic condition. Given the attentional role that the lateral frontal cortex has been assigned ( ), and its involvement in semantic memory ( ), activation of this region would arguably be expected during semantic processing (i.e. Facts condition), but not in self- and other-reflection. Moreover, we observed that the patients deactivated a cluster in the precuneus for both semantic and other processing, while controls only did so for semantic processing. Deactivation of the precuneus is characteristic of tasks that place cognitive demands on the subject, such as classical attention or working memory tasks ( ), even in schizophrenic patients ( ). In the patients in our study, self- and other-reflection seem to have imposed greater cognitive demands than in controls, leading to hyperactivity of the lateral prefrontal cortex and deactivation of the precuneus in conditions that should not require these changes (more akin to cognitive, attention-demanding tasks). An alternative, or perhaps complementary interpretation of this finding, would be that healthy participants treat self- and other-related information differently from semantic knowledge, as evidenced by the obvious differences in patterns of brain activity between these conditions. In schizophrenia, however, the ability to distinguish between these two kinds of information may be disturbed, leading to difficulties in the management of social information. 

This activation pattern is also interesting because DMN regions involved in self/other-reflection tend to decrease their activation when attention is externally focused, which in turn involves an increase in activity of attentional or executive networks, where the lateral prefrontal cortex is a relevant node (Fox et al., 2005). Thus, adequate balance between these intrinsic networks seems necessary for adaptive cognitive functioning, and a failure in its regulation might be linked to psychiatric symptoms. Alterations in the DMN are well-established in schizophrenia ( ;  ;  ;  ;  ). Some authors have proposed that there is a stable difference in the DMN structure and its connections with the salience network and the central executive network ( ;  ). Given that healthy subjects showed activation differences between task conditions in the lateral prefrontal cortex, the precuneus and the right angular gyrus, and these changes were not found in patients, our results could also be linked to a failure in network balance between the DMN and the executive network in schizophrenia. These results may suggest that the process of functional specialization of the DMN may be altered in schizophrenia. 

The present results add evidence to the range of alterations in self/other-reflection reported in schizophrenia. However, our findings converge only partially with previous results. In the Other vs. Facts contrast, we found altered activation of a region close to the PCC as also found by   and  , but other findings have not been replicated. Our task was based on the design used by  ; however, we did not include sentences about physical attributes in the Self or the Other conditions. A second reason for differences might be the degree of familiarity with the individual chosen as ‘other’ in the Other condition ( ). In our study, participants were instructed to choose a known person but not someone with a close relationship with them, so that the ‘other’ was personally known and had a history of past interactions with the participant, but not as close as in other studies where the ‘other’ was required to be a close friend or family member. Other studies have used a public ‘other’; however, this may impose significant variation in the amount of exposure to such individuals. Although we tried to control the level of closeness between the participant and the ‘other’, it is important to keep in mind that there is some degree of variability that could not be controlled. It might also be important to bear in mind that relationships and attachments might be different in schizophrenia patients than in controls. It is also of course possible that discrepancies between studies could be explained in terms of prevalence of positive and negative symptoms in the schizophrenia samples, stage of the disorder, or medication use. 

### Conclusions 
  
The present study is the first to reveal diminished activation of the right TPJ, a brain region with a relevant proposed role for self/other differentiation and social cognition, in patients with schizophrenia during other-reflection. Additionally, it found evidence that schizophrenic patients rely more on cognitive control areas (i.e. left lateral prefrontal cortex) for self- and other-reflection, suggesting that this type of cognitive process might place greater cognitive demands in patients with this disorder. Taken together, the results support a failure in self- and other-related information processing in schizophrenia and provide evidence for disturbances in self/other differentiation, which might lead to altered judgments of others’ behavior and personality. An alteration in the right TPJ activity is a potential neural mechanism for this disturbance. This latter finding may be relevant for future studies, particularly those aiming to examine psychosocial treatments and neuromodulation techniques in schizophrenia. 



## Financial support 
  
This work was supported by   (2017 SGR 01271 to EP-C and 2017 SGR 1265 to PF-C from AGAUR). Also by grants from  : Juan de la Cierva-formación contract (FJCI-2015-25278 to PF-C) and from   (FFI2016-77647-C2-2-P to PS-P). And by the  , co-funded by  /  “Investing in your future”: Miguel Servet Research contract (CPII16/00018 to EP-C), Rio Hortega contract (CM15/00024 to MM-S), and Research Project Grants (PI14/01151 to RS, PI14/01148 to EP-C, PI18/00810 to EP-C, PI18/00877 to RS and PI18/00880 to PM). 


## CRediT authorship contribution statement 
  
 Paola Fuentes-Claramonte:   Investigation, Data curation, Formal analysis, Writing - original draft, Writing - review & editing, Visualization.   Marta Martin-Subero:   Investigation, Data curation, Formal analysis, Writing - original draft, Writing - review & editing, Visualization.   Pilar Salgado-Pineda:   Conceptualization, Methodology, Investigation, Data curation.   Aniol Santo-Angles:   Investigation.   Isabel Argila-Plaza:   Investigation.   Josep Salavert:   Investigation.   Antoni Arévalo:   Investigation.   Clara Bosque:   Investigation.   Carmen Sarri:   Investigation.   Amalia Guerrero-Pedraza:   Investigation.   Antoni Capdevila:   Investigation, Resources.   Salvador Sarró:   Resources, Project administration, Funding acquisition, Supervision.   Peter J. McKenna:   Conceptualization, Funding acquisition, Writing - review & editing.   Edith Pomarol-Clotet:   Conceptualization, Funding acquisition, Writing - review & editing, Supervision.   Raymond Salvador:   Conceptualization, Methodology, Software, Writing - original draft, Writing - review & editing, Funding acquisition. 


## Declaration of Competing Interest 
  
None 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-43'>
<h2>43. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31798816/' target='_blank'>31798816</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Intact neural representations of affective meaning of touch but lack of embodied resonance in autism: a multi-voxel pattern analysis study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Mol Autism</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1186/s13229-019-0294-0</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6881998/' target='_blank'>6881998</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This fMRI study examines social-related processing (observation of social touch) in adult participants and includes a healthy neurotypical (NT) group (n=21) with results reported separately. Participants are adult men (within 17–65). The study used functional MRI during a social task (observing social vs. non-social touch) and reports whole-brain univariate analyses (SPM with MNI peak coordinates referenced in Supplementary Tables/Figures) as well as ROI-based MVPA; inclusion allows studies reporting both whole-brain and ROI results. Therefore all inclusion criteria are met and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
## Background 
  
Humans can easily grasp the affective meaning of touch when observing social interactions. Several neural systems support this ability, including the theory of mind (ToM) network and the somatosensory system linked to embodied resonance, but it is unclear how these systems are affected in autism spectrum disorder (ASD). Individuals with ASD exhibit impairments in the use of nonverbal communication such as social and reciprocal touch. Despite the importance of touch in social communication and the reported touch aversion in ASD, surprisingly little is known about the neural systems underlying impairments in touch communication in ASD. 


## Methods 
  
The present study applies a dynamic and socially meaningful stimulus set combined with functional magnetic resonance imaging (fMRI) to pinpoint atypicalities in the neural circuitry underlying socio-affective touch observation in adults with ASD. Twenty-one adults with ASD and 21 matched neurotypical adults evaluated the valence and arousal of 75 video fragments displaying touch interactions. Subsequently, they underwent fMRI while watching the same videos. Using multi-voxel pattern analysis (MVPA) and multiple regression analysis, we examined which brain regions represent the socio-affective meaning of observed touch. To further understand the brain-behavior relationship, we correlated the strength of affective representations in the somatosensory cortex with individuals’ attitude towards social touch in general and with a quantitative index of autism traits as measured by the Social Responsiveness Scale. 


## Results 
  
Results revealed that the affective meaning of touch was well represented in the temporoparietal junction, a core mentalizing area, in both groups. Conversely, only the neurotypical group represented affective touch in the somatosensory cortex, a region involved in self-experienced touch. Lastly, irrespective of the group, individuals with a more positive attitude towards receiving, witnessing, and providing social touch and with a higher score on social responsivity showed more differentiated representations of the affective meaning of touch in these somatosensory areas. 


## Conclusions 
  
Together, our findings imply that male adults with ASD show intact cognitive understanding (i.e., “knowing”) of observed socio-affective touch interactions, but lack of spontaneous embodied resonance (i.e., “feeling”). 

 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (51063 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Background 
  
Interpersonal touch, such as a hug or a slap, is a potent non-verbal communicative tool for expressing one’s emotions and intentions [ ,  ]; thus, an appropriate understanding of the meaning of touch is crucial for social functioning. Humans can extract a vast amount of information, including other’s affective states, when merely watching a touch interaction [ ,  ]. Identifying other’s emotions from these social cues involves a sophisticated neural circuitry, including the extended visual system, the limbic system [ ], and regions implicated in social cognition [ ]. 

Pertaining to social cognition, two complementary theoretical frameworks—along with their associated neural modules—have targeted the processing of emotional body language. The first aligns with the more cognitively oriented   theory of mind account   (ToM; both the modular-theory and theory-theory) and postulates that humans are able to infer other’s mental states (i.e., emotions, intentions, and beliefs) by means of meta-perspective reasoning [ – ]. The modular account postulates that ToM is achieved by an innate neural mechanism selectively involved in mental state inference [ ]. The theory-theory account postulates that children are born with “naive” internal theories about the social world that are constantly revised in response to accumulated experiences, resulting in conceptual advances in mental state inference [ ]. In both accounts, the ToM system has been depicted as a relatively effortful, controlled, and cognitively demanding form of social cognition [ ], implicating the bilateral temporoparietal junction (TPJ) [ ,  ]. The second theoretical framework originates from the   embodied simulation/resonance   literature, aligns with the mirror neuron mechanism theory, and posits that individuals implicitly infer other people’s emotional states from social cues by automatically re-enacting pre-acquired sensory experiences [ ,  ]. 

While this second line of research initially focused on the observation of fairly simple motor activities, implicating the premotor cortex and inferior parietal areas [ ,  ], more recent studies have started investigating the observation of simple touch [ ,  ,  ] and more complex interpersonal touch [ ]. Concerning touch observation, accumulating evidence suggests that activated brain regions go beyond the visual cortex and include somatosensory regions involved in the processing of self-experienced touch [ ,  – ]. This direct mapping of other’s bodily experiences to the self may aid in simulating and empathizing with others’ emotions (e.g., the pain we feel when we observe another person being injected with a needle). Accordingly, the level of activation in the somatosensory system during touch observation has been associated with interindividual differences in empathy [ – ]. 

Although many studies have affirmed the presence of interindividual differences in social cognition, the behavioral and neural mechanisms of social touch perception have not been thoroughly investigated in neuropathological populations. Among the most relevant in this context is autism spectrum disorder (ASD), a hereditary neurodevelopmental disorder that is characterized by impairments in social interaction and communication and the presence of restricted, repetitive, and stereotyped patterns of behavior [ ]. ASD is often accompanied by an aversion to social touch [ ,  ]. Using a limited range of touch stimuli, previous studies have shown that individuals with ASD frequently struggle with both receiving and offering touch [ – ], display reduced empathic resonance to painful touch observation [ ], and show diminished neural activity in social brain regions in response to pleasant, gentle touch [ ]. 

While difficulty in interpreting other people’s emotions from non-verbal social cues such as facial [ ,  ] and bodily expressions [ ,  ] is one of the diagnostic criteria of ASD, the empirical evidence in experimental studies is mixed [ ,  ]. At a theoretical level, the socio-communicative impairments of individuals with ASD have often been attributed to impaired ToM abilities [ ,  ], as well as to deficits in spontaneous embodied resonance [ – ]. 

Initial studies showed impaired or delayed development of ToM abilities in ASD, as evidenced by deficits in perspective taking, false belief processing, and emotion recognition [ ]. Likewise, at a neural level, individuals with ASD showed attenuated brain activity in the TPJ during various socio-cognitive tasks targeting ToM [ – ]. On the other hand, it has been gradually recognized that many individuals with ASD, especially those with intact intellectual and verbal ability, are able to pass these ToM tasks by means of compensatory sensory strategies and rule-based reasoning [ ] despite substantial impairments in spontaneous social communication and interaction in daily life. Moreover, more recent neuroimaging studies revealed that individuals with ASD do show similar brain activation as neurotypical controls during a false belief task and during facial emotional expression recognition [ ,  ]. This is where the embodied simulation/resonance account comes into play. According to this account, social impairments in ASD may result from a disability to simulate observed actions and internal states of others via personal sensory and emotional representations [ ]. This account is supported by reduced brain activation in the mirror neuron system (MNS) of individuals with ASD during a variety of tasks requiring simulation [ ,  ,  ,  ]. Yet, also this “broken mirror theory” of ASD has been criticized based on conflicting evidence showing intact MNS during motor observation in ASD [ ]. Thus far, embodied resonance and MNS have mainly been tested in relation to motor mimicry with rudimentary action observation paradigms. Testing this system in relation to a more higher-level socio-affective domain, such as social touch observation, may help clarify whether an individual with ASD spontaneously re-enacts previously acquired sensory experiences to understand other people’s emotional states. 

The current study aims at understanding socio-affective touch processing in adults with ASD, both at the behavioral and neural level, using a dynamic stimulus set consisting of videos showing social touch interactions encountered in everyday life. We particularly aim at unraveling whether neural representations of socio-affective touch observation are represented in a cognitive rule-based manner or based on embodied somatosensory resonance. We also investigate to what extent individual differences in socio-affective representations in brain regions relate to the presence of autism symptoms and touch aversion. 


## Methods 
  
### Participants 
  
Forty-two men participated in the study, including 21 male adults with a multidisciplinary ASD diagnosis and 21 age-, gender-, and IQ-matched neurotypical (NT) adults (Table  ). Participants with ASD had been diagnosed following DSM-IV or DSM-5 criteria, depending on the year of diagnosis. All were diagnosed by the Expertise Center for Autism at the University Hospitals Leuven. The diagnostic trajectory involves 8 h of patient-contact and assessment, distributed across several sessions, administered by a multidisciplinary team comprising of a psychiatrist, psychologist, social worker, and (optionally) a speech therapist. Assessment encompasses an extensive developmental anamnesis with the patient and his parents, a semi-structured psychiatric interview [ ] and/or scoring of the Adult Asperger Assessment inventory [ ], an in-depth personality inventory, and an extensive psychological and neuropsychological testing. None of the participants with ASD had comorbid neurological, psychiatric, or genetic conditions, such as epilepsy, traumatic brain injury, or attention-deficit/hyperactivity disorder. On the other hand, healthy adults with no prior diagnosis of ASD were recruited as NT participants through online advertising. None of the NT participants, nor first-degree relatives, had a history of neurological, psychiatric, or medical conditions known to affect brain structure or function. None of the participants in either group took psychotropic medication, and all had normal or corrected-to-normal vision. The ASD participants show above average intelligence and adequate social adaptive functioning (e.g., 11 out of 21 have a regular job and 7 others are students in higher education). There is a partial overlap (5 out of 21 NT participants) between the current NT sample and the data reported in [ ]. These five participants were the only ones from the earlier study for whom we had IQ scores and who are male. The sample size was based on previous studies that examined atypical neural representations in clinical populations by means of similar neuroimaging approaches [ ,  ]. Moreover, the reliability of behavioral and neural data was thoroughly examined (see below for methods and results), further justifying the adequacy of our sample size.
   
Demographics and IQ scores for ASD and NT control groups and descriptive statistics 
  
 IQ   intelligence quotient assessed with the Wechsler Adult Intelligence Scale (WAIS-IV-NL [ ], population average   M   = 100 and SD = 15),   M   mean,   SD   standard deviation.   T   values are from the two-sample   t   test 
  


### Questionnaires 
  
Participants filled out two questionnaires. The   Social Touch Questionnaire   (STQ) assesses individual attitudes towards receiving, offering, and witnessing social touch [ ]. The STQ comprises 20 items (e.g., “I generally like it when people express their affection towards me in a physical way”), and participants were asked to respond to each statement on a 5-point scale (1 = strongly disagree, 2 = disagree, 3 = undecided, 4 = agree, 5 = strongly agree). A higher total score indicates a stronger preference for reciprocal touch. Reliability and validity of the STQ are adequate, with a Cronbach’s alpha inter-rater reliability of .89, and moderate to strong correlations (Rs = .42–.74) with 4 out of 5 sub-categories of the Touch Experiences and Attitudes Questionnaire [ ]. 

The   Social Responsiveness Scale for Adults   (SRS-A) is a normed self-report questionnaire measuring a wide range of behaviors characteristic of ASD [ ]. The SRS-A comprises 64 items covering subscales for social communication and interaction and for restricted and repetitive patterns of behavior and interests. The SRS-A consists of three subscales measuring social deficits and one measuring restricted and repetitive behavior. A higher total score indicates a higher presence of quantitative autism traits. The reliability and validity of the SRS-A are excellent, with Cronbach’s alpha inter-rater reliability being .80 and strong correlations (Rs = .70) with the Autism Diagnostic Interview-Revised [ ]. 


### Stimuli 
  
We used a recently created and well-validated set of 75 greyscale video clips (3 s each) displaying positive (e.g., hugging and holding hands) and negative (e.g., slapping) interpersonal touch interactions as well as neutral object manipulations (e.g., carrying a box). Representative still images of some videos are shown in Fig.  , and example video clips are available at   https://osf.io/8j74m/  . The 39 scenes for interpersonal or “social touch” and the 36 scenes for object manipulation or “non-social touch” were closely matched according to the type of physical interactions. For example, the movements involved in hugging another person vs. holding a large box were matched. Various physical parameters from the video sequences were quantified, including pixel-wise intensity, pixel-wise motion energy, and total motion energy [ ]. In the current study, the resulting parameters were defined as nuisance covariates in the multiple regression model. A detailed description of the stimuli can be found in our previous study [ ]. Psychophysics Toolbox Version 3.0.12 (PTB-3) [ ] in MATLAB (R2015a, The MathWorks, Natick, MA) was used for stimulus presentation in all experiments.
   
Types of stimuli. The figure shows still frames of exemplary stimuli, showing different types of touch events. Positive, negative, and neutral stimuli are in the first, the second, and the third rows respectively 
  


### Behavioral rating of valence and arousal 
  
First, participants took part in a behavioral experiment where they viewed all the video clips and reported their subjective feelings of pleasantness (“How pleasant is the touch?” 1—extremely unpleasant, 5—neutral, 9—extremely pleasant) and arousal (“How arousing is the touch?” 1—extremely calm to 9—extremely exciting) in relation to the 75 touch scenes. Each of the 75 stimuli was presented once per session, with a short break in between the two sessions. More details about this experiment can be found in experiment 2 of the previous study [ ]. 


### MRI acquisition 
  
All participants underwent an MRI scanning session consisting of two functional MRI experiments (1 localizer run and 7 main runs) and an anatomical scan. MRI images were acquired on a 3T Philips scanner with a 32-channel coil at the University Hospitals Leuven. Functional imaging was performed with a gapless, echo planar imaging sequence (repetition time (TR) = 2000 ms, echo time (TE) = 30 ms, flip angle (FA) = 90°, field of view (FOV) = 216 × 216 mm, in-plane matrix = 80 × 80, voxel size = 2.7 × 2.7 × 3 mm, 37 slices), with the acquisition of 239 volumes for each run of the main experiment (1673 volumes in total) and 298 volumes for the localizer run. 

Structural MR images were collected using a T1-weighted sagittal high-resolution magnetization-prepared rapid gradient echo (MPRAGE) sequence [TR = 9.6 ms, TE = 4.6 ms, FA = 8°, FOV = 250 × 250 mm, in-plane matrix = 256 × 256, voxel size = 0.98 × 0.98 × 1.2 mm, 182 axial slices]. 


### Main fMRI experiment: observing touch 
  
In the scanner, participants watched the same videos shown during the behavioral experiment while performing an orthogonal attention task (i.e., detecting the color of the shirt of the agent who initiates the touch). The main experiment consisted of 7 runs of 7.8 min each. Note that while structural MRI or resting-state fMRI measures typically involve less than 10 min of scanning time per participant, our multi-voxel pattern analysis (MVPA) study adopts a neuroimaging paradigm that takes about 1 h of continuous scanning time (7 runs) per participant. In each run, the 75 videos were displayed in an optimally designed pseudo-random order in an event-related design. Accordingly, the same touch scenes (e.g., the three slapping scenes) were never displayed consecutively. Every run consisted of 3 blocks, each of which contained a baseline condition displaying a fixation cross (6 s) and 25 trials consisting of video presentation (3 s) and the inter-stimulus interval (ISI, 3 s). All the videos were projected on a screen behind the scanner, and participants viewed them through a mirror mounted on the head coil. 


### Localizer fMRI experiment: receiving touch 
  
This experiment was used to localize the (affective) touch-related cortical areas as ROIs within the somatosensory cortex. Note that the current study aimed at investigating the neural representation of observed touch and that the actual touch stimulation only served to confine a touch-related cortical area involving both positive and negative touch. Participants received pleasant (i.e., brush-strokes with a velocity of 5 cm/s) and unpleasant (i.e., rubber band snapping) touch stimulations on the ventral surface of the right and left forearms while lying in the scanner. Pertaining to the pleasant touch, it has been shown that stimulation velocities between 1 and 10 cm/s specifically target unmyelinated C-Tactile afferents, thereby eliciting pleasant touch sensations [ ,  ]. The total duration of the localizer run was approximately 10 min. The experiment comprised four randomized blocks (pleasant touch-left arm, pleasant-right, unpleasant-left, and unpleasant-right), and each block consisted of a rest trial (10 s) and eight touch trials (five repetitions of stimulation for 10 s, followed by 6 s of ISI in each trial). A trained experimenter stood next to the scanner and delivered stimulation by following the audio instruction (“start” to start the stimulation, “stop” to end the stimulation). More information can be found in our previous study in NT adults [ ]. 


### Statistical analysis 
  
Statistical inferences were made with one of the following tests depending on the results of the Shapiro-Wilk normality test (with   α   < 0.05): a parametric (e.g., two-tailed one-sample   t   test, two-sample   t   test, and Pearson correlation) vs. non-parametric test (e.g., Wilcoxon signed-rank test, Mann-Whitney   U   test, and Spearman correlation). For the group-based multiple regression analyses, we used a non-parametric permutation test (details are described below). To quantify the group differences, we report Cohen’s   d   effect sizes whenever the null hypothesis is rejected after a   t   test [ ]. According to Cohen’s recommendations, an effect size ranging from 0.2 to 0.3 is considered small, values around 0.5 are medium, and values of 0.8 or above are considered large effects. We performed all statistical analyses within the MATLAB (2015a) software environment. 


### Behavioral data 
  
The ratings of valence and arousal obtained through the two repetitions were averaged for each participant and stimulus. The ratings of the videos with positive, negative, and non-social touch scenes were analyzed separately to assess whether participants perceived positive touch scenes as relatively more pleasantly, negative touch scenes as unpleasantly, and non-social touch scenes as neutrally. We also compared the arousal ratings of social touch scenes with those of non-social touch scenes. For each of the video categories, we compared the ratings of the ASD vs. NT group in terms of perceived valence and arousal. Lastly, we quantified within- and between-subjects reliability to examine how consistent the ratings were within and between participants in each group (see Additional file  : within- and between-subjects reliability tests). 

In order to use the behavioral data as an independent variable to predict the neural data, we generated an overall affect score integrating the valence and arousal ratings. This was done by calculating the two-dimensional Euclidean distance of valence and arousal ratings for each pair of videos with the Pythagorean theorem, which was first done for each individual and then averaged across individuals. This operation resulted in an affective dissimilarity (distance) matrix. Note that there was a high within- and between-subject consistency of the behavioral valence and arousal ratings (see Additional file  : intra- and inter-subject consistency of valence and arousal ratings and Additional file  : Figure S1), justifying the use of a group average affective dissimilarity matrix. 


### Functional MRI data analysis 
  
#### Preprocessing, first- and second-level analysis 
  
Imaging data was processed using the Statistical Parametric Mapping software (SPM 12). The standard preprocessing, first- and second-level analyses were implemented. Analysis pipelines are described in detail in Additional file   (MRI data preprocessing and first- and second-level analysis). 

During the preprocessing phase, we also assessed the head movement of each participant and compared the two groups by using an Artifact Detection and Repair toolbox that calculates a composite measure of scan-to-scan movement. Runs whose maximum frame-wise displacement was greater than the voxel size (3 mm) were discarded (ASD = one run each from two participants; NT = one run from one participant). We found no group difference in the maximum (ASD = 1.38 mm, NT = 1.36,   t  (40) = 0.04,   p   = 0.97) and mean frame-wise head motion displacement (ASD = 0.13 mm, NT = 0.13,   t  (40) = 0.04,   p   = 0.96). 


#### Regions of interest 
  
We included the same regions of interest (ROIs) as in our previous study [ ]: Brodmann area (BA) 3, BA1, BA2, parietal operculum (PO), insula, middle cingulate cortex (MCC), middle temporal gyrus (MTG), superior temporal gyrus (STG), TPJ, precuneus, BA17, BA18, BA19, BA37, V5, and BA4. All these ROIs are known to be involved in the processing of visually presented social touch scenes in NT adults: vicarious touch processing in the somatosensory network (BA3, BA1, BA2, and PO [ ]), the pain network (insula and MCC [ ]), the social-cognitive network (MTG, STG, TPJ, and precuneus [ ]), and the visual network (BA17, BA18, BA19, BA37, and V5 [ ]). The motor cortex (BA4) was also included as motor responses, associated with active button presses, were required during the task in the scanner. 

We defined subject-specific ROIs by applying an identical procedure as employed in our previous study [ ], including selecting the activated voxels within the anatomical mask for each ROI and trimming the overlapping voxels among the nearby ROIs. When the number of selected voxels was less than 10 per ROI, a more liberal threshold of   p   < 0.01 instead of   p   < 0.001 was used. Nevertheless, 9 out of 42 participants showed no activation in the insula and 11 out of 42 participants showed no activation in MCC. Accordingly, these two ROIs were not included in the present study. This lack of consistent activation was not surprising, given the low-reliability estimates and limited explanatory power of these same ROIs in our previous study [ ]. The low-reliability estimates in these regions found in the previous study do not mean that the current study has low reliability. Instead, it means behavioral data may not be explainable with the neural signals in these regions due to low signal-to-noise ratio in these regions. BA4 was defined based on the anatomical mask only. We did not find any group differences in the size of the ROIs (all   p   > 0.06). Mean ROI sizes and the   p   values for individual ROIs are reported in Additional file   (mean ROI sizes). With the CARET software [ ], the ROIs are shown on the PALS atlas [ ] in Fig.  .
   
Visualization of ROIs. The figure illustrates the functionally defined ROIs (except anatomically defined BA4) for one example subject, mapped on inflated cortices using the CARET software with PALS atlas. Note that mapping the volume-based data to surface can introduce artefacts 
  


#### Neural representational dissimilarity matrices 
  
For each ROI and each participant, we created neural representational dissimilarity matrices (RDM) capturing the difference in multi-voxel neural response patterns between pairs of videos. For example, if an ROI shows selectivity for the affective valence of the touch scenes, the neural patterns of two differing social touch scenes (e.g., hugging a person vs. slapping a person) will be largely dissimilar. On the other hand, if an ROI does not show this selectivity, the neural patterns will be largely similar across both types of affective interactions. 

The “general touch RDM” involved the neural responses for both the social and non-social touch videos and consisted of the pair-wise correlation coefficients of the 75 neural patterns. The “social touch RDM” exclusively involved the neural responses for the social touch videos and consisted of the pair-wise correlation coefficients of the 39 neural patterns. We created these two RDMs per ROI and per participant and tested their reliability by applying an identical procedure as employed in our previous study [ ]. The summarized procedure of making RDMs and performing a reliability test can be found in Additional file   (neural representational dissimilarity matrices (RDMs) and reliability test for neural data). Note that based on the results of the reliability test, we excluded PO from further analysis as the between-subject variability was too high to conduct group analyses. In total, 42 (21 participants × 2 groups) general touch RDMs with 75 × 75 elements and 42 social touch RDMs with 39 × 39 elements were created per ROI. For the group analysis, we calculated the average of 21 individual RDMs to create each group’s general touch RDM and social touch RDM for each ROI. The RDMs of each ROI were used as dependent variables in each regression model in subsequent analyses. 


#### Multiple regression analysis 
  
To investigate which ROIs in which individuals host specific information on the displayed touch scenes, we carried out a series of multiple regression analyses to determine the independent contributions (as represented by the beta coefficients) of each variable of interest to the prediction of the neural data. Prior to this, we vectorized each matrix, took only the upper-diagonal elements, and normalized the vector with a   Z  -score transformation. 

In the regression model predicting each group’s general touch RDM, the regressor variables consisted of a binary model of social vs. non-social touch, the motor response made during the task, various physical parameters from the video sequences (pixel-wise intensity, pixel-wise motion energy, and total motion energy), and the type of touch action. 

In the regression model predicting each group’s social touch RDM, we replaced the binary model of social vs. non-social touch by each group’s average affective evaluation of social touch (i.e., the affective dissimilarity matrix, see above). We used each group’s average affective dissimilarity matrix in each group’s regression model. 

Statistical inferences for each group’s result were based upon a permutation test (1000 iterations), using the same procedure as described in [ ]. We randomly shuffled the indices of the vector of neural data and computed the beta coefficients of each independent variable in a multiple regression model applied to the permuted data. We counted the number of times a beta coefficient obtained through this operation was greater than or equal to the observed value in the nonpermuted data. The result of dividing this number by 1000 became the empirical   p   value after being corrected for multiple comparisons with the false discovery rate (FDR). 

In order to directly compare the two groups taking into account inter-subject variability, we performed multiple regression on the neural matrices of individual participants in each group and applied either a two-sample   t   test or a Mann-Whitney   U   test to compare the two groups. Against the background of the ToM and embodied simulation accounts (see the “ ” section), we specifically questioned the group difference in the quality of these representations in the core ToM area (TPJ) and the somatosensory cortex (BA3, BA1, and BA2), respectively. 




## Results 
  
### Affective responses to social and non-social touch videos 
  
Overall, both groups perceived the affective meaning of the touch videos as expected. More specifically, positive touch videos were rated as pleasant (NT, median = 7.4 (the median absolute deviation (MAD) = 0.4); ASD, median = 6.8 (0.6)), negative touch as unpleasant (NT, median = 2.9 (0.3); ASD, median = 3 (0.5)), and non-social touch as neutral (NT, median = 4.8 (0.2); ASD, median = 4.8 (0.2)). Concerning arousal ratings, both groups perceived social touch as exciting (NT, median = 5.7 (0.9); ASD, median = 6.2 (0.8)) and non-social touch as calm (NT, median = 2.4 (0.9); ASD, median = 2.5 (0.6)). Figure   shows data points of all individual participants for valence (a) and arousal (b) ratings. In addition, within- and between-subjects reliability tests revealed that participants were consistent in their ratings between the two sessions and were consistent with each other within each group. Additional summary statistics and statistical inference can be found in Additional file   (Affective responses to social and non-social touch videos, Intra- and inter-subject consistency of valence and arousal ratings, and Additional file  : Figure S1).
   
Affective responses to social (positive and negative) and non-social touch stimuli. The boxplots show each group’s valence (  a  ) and arousal ratings (  b  ) across conditions. The black lines inside each box indicate group medians, and the bottom and top border edges indicate the 25th and 75th percentiles. Data points from individual participants are marked as black circles. The red asterisks indicate statistical significance at *  p   < 0.05 and ***  p   < 0.001 
  

Regarding the difference between groups, a Mann-Whitney   U   test revealed no group difference in valence ratings of negative (  z   = − 0.21,   p   = 0.83) and non-social touch videos (  z   = 0.42,   p   = 0.68). On the contrary, we observed a significant difference with medium effect size in the rated valence of the positive videos between the two groups (  z   = 1.99,   p   = 0.046, effect size   d   = 0.65), indicating that participants with ASD perceived positive social touch, such as a hug, as relatively less pleasant. Although outlying data points were observed in the valence ratings (Fig.  a), the Mann-Whitney   U   test can robustly handle this as it is based upon medians rather than means. Neither group differed in their arousal ratings of social (z = − 0.97,   p   = 0.33) and non-social touch videos (z = − 0.40,   p   = 0.69). 


### Social touch preference and its association with quantitative autism traits 
  
Individuals with ASD showed a less positive appreciation towards giving, receiving, and witnessing social touch in daily life (STQ:   M   = 56.8, SD  = 13.2), as compared to the NT group (  M   = 69.2, SD = 9.6;   t  (40) = 3.21,   p   = 0.003,   d   = 1.07). As expected, individuals with ASD show a higher number of autism traits, as compared to NT individuals (SRS-A:   M   = 63.8, SD  = 11.6;   M   = 51.9, SD  = 8.9;   t  (40) = − 3.72,   p   < 0.001,   d   = 1.15). This group difference was significant on each of the social deficit subscales: social awareness (  M   = 60.9, SD  = 11.6;   M   = 50.2, SD  = 10.1;   t  (40) = − 3.18,   p   = 0.003,   d   = 0.98), social communication (  M   = 61.4, SD  = 11.2;   M   = 51.4, SD  = 8.2;   t  (40) = − 3.33,   p   = 0.002,   d   = 1.03), and social motivation (ASD   M  = 60.5, ASD_SD  = 11.6; NT   M   = 51.4, SD  = 8.8;   t  (40) = − 2.88,   p   = 0.006,   d   = 0.89). Overall, we found large to very large group differences in social touch preference and quantitative autism traits. 

The correlational analysis revealed a negative linear association between individual differences in social touch preference and the number of autism traits experienced by an individual (all participants   r   = − 0.62,   p   < 0.001; NT group   r   = − 0.55,   p   = 0.009; ASD group   r   = − 0.48,   p   = 0.03, Fig.  ). Similar associations were present for each of the social deficit subscales (Additional file  : Table S1). Together, our results confirm that individuals with ASD present social impairments and exhibit a higher degree of social touch avoidance. Furthermore, the participants avoiding social touch seem to exhibit stronger social impairment characterized by atypical social awareness, communication, and motivation, implying a tight link between social touch aversion and autism symptom severity.
   
Social touch preference and its association with quantitative autism traits. The green, pink, and black trend lines indicate the association in the ASD group (  r   = − 0.62,   p   < 0.001), the NT group (  r   = − 0.55,   p   = 0.009), and across all participants (  r   = − 0.48,   p   = 0.03), respectively 
  


### Univariate neural responses to observed and felt touch 
  
Two-sample   t   tests revealed no significant group difference in neural responses for the contrast of social vs. non-social touch videos and vice versa (  p   < 0.05). Mean group effects of social vs. non-social touch contrasts are shown in Additional file   (Neural responses to observed and felt touch, Additional file  : Figure S2 and Table S2 for detailed information such as MNI coordinates of peak activity). Similarly, no significant group difference in neural responses for felt touch was found (not at   p   < 0.05 and not at   p   < 0.02) (Additional file  : Neural responses to observed and felt touch, Additional file  : Figure S3 and Table S3). 


### Neural representations underlying observed social vs. non-social touch processing 
  
In line with earlier research by others [ ] and ourselves [ ], we expected that on top of this univariate selectivity for social vs. non-social touch, observed in both groups, there would also be high multi-voxel selectivity for the distinction between social and nonsocial touch videos. The multiple regression analysis confirmed that almost every implicated ROI represents the distinction between social and non-social touch scenes (11 of 13   p   values < 0.001 for both groups), even after controlling for the effects of all the other regressor variables (e.g., low-level visual features and motor response). Figure  a displays the main results, and more details can be found in Additional file   (Neural representations underlying observed social vs. non-social touch processing). Importantly, no significant group differences in neural selectivity for this distinction were found in the core ToM area (TPJ (  t  (40) = − 0.67,   p   = 0.50)) and the somatosensory areas (BA3   z   = 0.93,   p   = 0.35; BA1   z   = − 0.05,   p   = 0.96; BA2   z   = − 0.31,   p   = 0.76), indicating well-preserved neural selectivity in the ASD group for the social vs. non-social aspects shown in touch actions of others.
   
Neural representations of the social versus nonsocial distinction and of affective meanings in touch scenes. Radar charts were used to plot the results (a pink line for the NT and a green line for the ASD group). Each of the 13 ROIs, ordered according to the implied brain network as indicated by the color of the surrounding circles, forms an individual axis. The node (anchor) on the spoke (axis) represents the beta coefficient of each ROI.   a   The beta coefficient from the multiple regression model in which the neural patterns of each of the ROIs were predicted based on the social vs. non-social factor.   b   The beta coefficient from the multiple regression model predicting the neural patterns based on perceived overall affect. The asterisks indicate the statistical significance (beta higher than zero) determined by the permutation tests at *  p   < 0.05, **  p   < 0.01, and ***  p   < 0.001 in the NT (pink) and ASD group (green). In   a  , we additionally plotted the correlation coefficient representing the noise ceiling of the neural data, derived from the reliability test (a red dashed line for the NT group and a blue dashed line for the ASD group) 
  

Note that these and all the following multi-voxel analyses require a reproducible signal, and between-group comparisons are easier to interpret if the reliability is comparable between the two groups. To assess whether there may be group differences in the reliability of the neural data in the TPJ and the somatosensory cortex, we calculated values of the leave-one subject-out correlations within each group (correlating the neural data of one subject with the group averaged neural data after excluding this subject). Our results demonstrated that there was no group difference in the reliability of neural patterns in the four ROIs that are central to the tested hypotheses (BA3   t  (40) = − 1.75,   p   = 0.09; BA1   t  (40) = 0.40,   p   = 0.69; BA2   t  (40) = − 0.24,   p   = 0.81; TPJ   t  (40) = 1.40,   p   = 0.17). 

In sum, our results suggest that the brains of individuals with and without ASD can equally distinguish whether another person’s touch actions comprise social interactions or not, and this rudimental social processing is implemented across multiple brain areas including visual, somatosensory, and social regions. 


### Neural representations underlying dimensions of overall affect in social touch observation 
  
By combining the valence and arousal dimensions, we obtained a measure of overall affect conveyed in the social touch scenes. We investigated how this affective meaning of social touch is implemented in the brain when participants watch the interpersonal touch actions of others. In the NT group, statistically significant representations of overall affect were observed in V5 (  β   = 0.09,   p   = 0.04), MTG (  β   = 0.20,   p   < 0.001), STG (  β   = 0.08,   p   = 0.04), TPJ (  β   = 0.20,   p   < 0.001), the motor cortex (  β   = 0.11,   p   = 0.01), and the somatosensory cortex (BA3   β   = 0.13,   p   = 0.002; BA1   β   = 0.13,   p   = 0.004; BA2   β   = 0.14,   p   < 0.001) (see the pink line in Fig.  b and Additional file  : Table S4). In the ASD group, however, significant representations of overall affect were found in V5 (  β   = 0.10,   p   = 0.05), MTG (  β   = 0.10,   p   = 0.03), and TPJ (  β   = 0.18,   p   < 0.001), but not in the somatosensory cortex (BA3   β   = 0.08,   p   = 0.08; BA1   β   = 0.02,   p   = 0.32; BA2   β   = 0.03,   p   = 0.32), STG (  β   = 0.07,   p   = 0.12), and the motor cortex (  β   = 0.08,   p   = 0.09) (the green line in Fig.  b and Additional file  : Table S4). 

Comparing both groups in terms of the strength of neural selectivity for the fine-grained socio-affective information in the core ToM area and the somatosensory cortex, we found no significant difference between the two groups in TPJ (  t  (40) = 1.04,   p   = 0.30), but significantly weaker representations in BA1 (  t  (40) = 3.06,   p   = 0.004,   d   = 0.94) and BA2 (  t  (40) = 2.45,   p   = 0.02,   d   = 0.76) in the ASD group. Effect sizes indicate a large to very large group difference in the quality of affective representations in BA1 and BA2. No significant group difference was found in BA3 (  t  (40) = 0.90,   p   = 0.37). Similar results were observed when age or mean frame-wise head motion displacement was included as a covariate in an analysis of covariance model. The present results indicate that both groups are able to represent subtle socio-affective nuances of observed social touch interactions. However, whereas individuals with ASD only represent this information in high-level visual areas (V5, MTG) and cognitively oriented ToM areas (i.e., TPJ), NT individuals additionally represent this information in a more embodied somatosensory format (BA3, BA1, and BA2). The neural representations of other factors, such as motor response and low-level visual features, were additionally examined. No group difference was found either in visual or in motor processing (Additional file  : Figure S4). 


### Neural correlates of individual differences in touch avoidance and autistic traits 
  
In our previous study in NT adults, we demonstrated that individual differences in the strength of neural representations of socio-affective touch in the somatosensory cortex were associated with individual differences in the attitude towards social touch in daily life [ ]. Here, we extend these findings and connect the neuroscientific findings with core pervasive autistic traits. Note that the results described below were observed only when the two groups were merged and analyzed together. 


### Social touch preference 
  
When correlating the scores on the Social Touch Questionnaire (STQ) with the beta coefficients indexing the quality of the overall affect representations in somatosensory cortex, the results indicate that a more positive attitude towards social touch is significantly associated with higher quality of overall affect representations in BA1 (rS = 0.43,   p   = 0.008) and BA2 (rS = 0.32,   p   = 0.04). Individual differences in affect representations in BA3 (rS = 0.08,   p   = 0.64) were not linked to the individual attitude towards social touch. Similar results were observed when age and mean frame-wise head motion displacement were assigned as a covariate in a rank partial correlation model. Our results suggest that the functional organization and vicarious emotional sensitivity of the somatosensory cortex (i.e., BA1 and BA2) of individuals with a positive attitude towards receiving, witnessing, and providing social touch may differ from the one of individuals who show social touch aversion. 


### Social impairments 
  
Likewise, the correlations between SRS-A scores and the strength of overall affect representations in somatosensory cortex revealed that individual differences in social responsiveness were significantly associated with the distinctness and specificity of overall affect representations in BA1 (rS = − 0.38,   p   = 0.02) and BA2 (rS = − 0.45,   p   = 0.003). Individual differences in affect representations in BA3 (rS = − 0.12,   p   = 0.46) were not linked to individual differences in self-reported autistic traits. Again, similar results were observed when age and mean frame-wise head motion displacement were assigned as a covariate variable in a rank partial correlation model. 

Together, our results imply that the presence and the quality of affective representations of visually observed touch interactions in mid-to-high level somatosensory cortex (i.e., BA1 and BA2) show an association with quantitative autism features and personal attitudes towards social touch. In particular, individuals who show higher social impairments tend to show a higher degree of social touch aversion, and both these characteristics are associated with less robust socio-affective representations in the mirror-somatosensory system during the observation of social touch. 



## Discussion 
  
Our study investigates the neural basis of socio-affective touch observation in adults with ASD compared to well-matched NT adults. In particular, we sought to clarify to what extent social impairments and touch aversion in ASD may be linked to aberrant cognitive representations of the affective aspects of touch (due to impaired ToM abilities) or to an inability to re-enact pre-acquired somatosensory experiences (due to deficits in embodied somatosensory resonance). Using fMRI-based MVPA methods and a well-defined set of stimuli, we were able to pinpoint the atypicality of ASD in processing complex touch scenes containing multidimensional information (visual, somatosensory, and socio-affective). Our study provides novel evidence that adults with ASD specifically lack a differentiated somatosensory resonance when observing complex social touch interaction of others, despite a high degree of commonalities with NT adults in other aspects of neural information processing. 

Adults with ASD rated the socio-affective touch scenes fairly similarly as NT adults, and both groups showed a high intra- and inter-subject consistency in their ratings. The only difference was in the perception of the positive touch scenes, such as a hug, which the adults with ASD rated less pleasantly as compared to NT adults. While the effects are subtle, the results of this computer-based behavioral experiment are consistent with those of the questionnaire, which also revealed a significantly lower preference for receiving and observing social touch in daily life in adults with ASD. Similar to Voos et al. [ ], we also found an association between individual differences in social touch preference and the number of self-reported autism traits, while using different measurement instruments. 

At the neural level, we found surprisingly high similarities between the two groups. Using both univariate and multivariate analysis approaches, intact neural selectivity for the social vs. non-social distinction of touch scenes was observed, in multiple brain regions including the ToM area and the somatosensory cortex. Although previous studies have shown that individuals with ASD may process social stimuli in an atypical manner [ ,  ], the neural patterns associated with social vs. non-social touch scenes may still be distinctive as long as both conditions are perceived sufficiently differently from each other. This was indeed the case, also in the ASD sample, as illustrated by the ratings of valence and arousal in Fig.  . Accordingly, the current findings indicate that social impairments in ASD are not simply due to an inability to distinguish between social and non-social information. 

Likewise, similar (univariate) neural activation in response to actual touch stimulation was observed in both groups in the current study. This observation contrasts with previous findings showing diminished neural response to affective touch events, especially to gentle brushstrokes, in individuals with ASD or in individuals scoring high on autistic traits [ ,  ,  ]. Possibly, this discrepancy may be due to the administration of both positive and negative touch stimulation in our study, unlike the aforementioned studies which only delivered positive touch. 

Strikingly, neural commonality with the NT group was even evident with regard to more delicate and fine-grained socio-affective processing. Individuals with ASD did represent subtle and differentiated information on the overall affect of socio-affective touch interactions in the TPJ, the most classical “social cognition ToM module”, suggesting intact social cognitive reasoning. Functional abnormalities, such as reduced neural activation, in this region have been attributed to the impairments in social cognitive reasoning in various disorders, such as schizophrenia, [ ] bipolar disorder [ ], and ASD [ – ]. In the current study, however, we did not find any evidence that individuals with ASD exhibit functional abnormalities in the TPJ. On the contrary, the presence of intact fine-grained affective touch representations in this region suggests that individuals with ASD are capable of mentalizing the affective meaning of observed social touch interactions. For decades, impaired ToM ability has been put forward as the primary cause of socio-communicative impairments in ASD [ ,  ,  ]. However, several recent studies have shown that intellectually and verbally gifted individuals with ASD, like the ones in our sample, successfully pass ToM tasks, possibly by using compensatory strategies [ – ]. 

Despite the typical ToM involvement in our ASD sample and despite the numerous behavioral and neural commonalities among both groups, we did observe significant and very specific differences in the more automatic and spontaneous processing of socio-affective touch interactions. Unlike NT adults, the ASD group did not show affective touch representations in mid-to-high level somatosensory areas (i.e., BA1 and BA2), indicating a lack of embodied resonance in relation to others’ bodily experiences. Our findings thereby extend studies demonstrating reduced empathic resonance to a painful touch experience of others as reflected in weaker mu suppression in ASD [ ]. A lack of embodiment of others’ emotional state—not only painful sensations but also joyful ones—as revealed in the current study, further supports the argument that social difficulties in ASD may involve a lack of embodied simulation [ ]. 

Lastly, building upon our previous study in NT adults [ ], the current study provides evidence that individuals with stronger social touch avoidance or with more autistic traits experience diminished embodied somatosensory resonance with others. These findings extend recent studies that demonstrated an association between the level of activation in the somatosensory system during the observation of touch and inter-individual differences in empathy [ – ]. 

### Limitations 
  
The current study instigates new questions that will require further research. In particular, while our ASD sample showed a clear dissociation between intact socio-affective representations in TPJ vs. severely affected and absent representations in mid-to-high level somatosensory areas (with large group differences), it should be noted that the current study only included a selective subsample of male adults with ASD showing average to above-average intelligence and no language deficits. Although the homogeneity of this sample allowed controlling for confounding factors such as age, IQ, and gender, future studies may benefit from the inclusion of children, women, and more severely affected individuals, including individuals with low IQ, who may not mobilize compensatory cognitive strategies. Indeed, it remains an open question whether also these individuals would show intact rule-based ToM representations. Likewise, as the present study used a relatively effortless task, it remains to be seen whether intact ToM processing would still be in place when a task requires more higher-level cognitive exertion (e.g., understanding the meaning of touch based on the social norm and culture) [ ]. 



## Conclusions 
  
The current study provides strong support for the impaired embodied simulation account of ASD [ – ]. Accordingly, the less positive attitude towards reciprocal touch in ASD may be a consequence of the deficient automatic emotional resonance and the resulting increase in cognitive processing load during such interactions. Gallese and Sinigaglia [ ] nicely illustrated the different formats of representations, and its impact, with the analogy of a route description: “Just as a map and a series of sentences might represent the same route with a different format, so might mental representations have partly overlapping contents while differing from one another in their format (e.g., bodily instead of propositional)” (p. 517). Crucially, while the same information can be represented in different formats, its utility is constrained by the format. Evidently, representing in a bodily format an emotion, such as disgust or pain, or a sensation, such as being touched, is different from representing them in a propositional format [ ]. According to our findings and to the extent that TPJ may be a more cognitive and rule-based ToM module, individuals with ASD may not have access to the bodily format of the affective touch representations, but they have access to the propositional format. As a result, the depth of understanding and experiencing the state of others (and themselves) may differ between the two groups (i.e., “knowing” vs. “knowing and feeling”), which is also related to alexithymia in ASD [ ]. The current findings may also motivate to reconsider how cognitive behavioral therapies designed to enhance mentalizing capacities of individuals with ASD can be complemented by more physical and bodily intervention strategies (e.g., mirror imitation therapy [ ,  ];) that directly target the deficient emotional resonance in clinical practice. 


## Supplementary information 
  




 ## Availability of data and materials

Data that support the findings of this study are available through the Open Science Framework (https://osf.io/6ktwc/) for scientific use. https://osf.io/6ktwc/ </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-44'>
<h2>44. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/27531389/' target='_blank'>27531389</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Emotional prosody processing in autism spectrum disorder</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Soc Cogn Affect Neurosci</p>
<p><strong>Publication Year:</strong> 2016</p>
<p><strong>DOI:</strong> 10.1093/scan/nsw118</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5390729/' target='_blank'>5390729</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study reports an fMRI experiment in adults (controls: mean age ~32, range 20–46) performing an emotional prosody task, which is a social-communication/perception task relevant to ‘Perception and Understanding of Others’. Healthy control results are reported separately and whole-brain mixed-effects analyses were performed (FSL/FLAME) with cluster FWE correction; ROI analyses were also performed but whole-brain results are available. Participants fall within the 17–65 age range. Therefore the paper meets all inclusion criteria (social-related fMRI task, healthy adult group reported separately, whole-brain analyses). No exclusion criteria are met.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Individuals with Autism Spectrum Disorder (ASD) are characterized by severe deficits in social communication, whereby the nature of their impairments in emotional prosody processing have yet to be specified. Here, we investigated emotional prosody processing in individuals with ASD and controls with novel, lifelike behavioral and neuroimaging paradigms. Compared to controls, individuals with ASD showed reduced emotional prosody recognition accuracy on a behavioral task. On the neural level, individuals with ASD displayed reduced activity of the STS, insula and amygdala for complex   vs   basic emotions compared to controls. Moreover, the coupling between the STS and amygdala for complex   vs   basic emotions was reduced in the ASD group. Finally, groups differed with respect to the relationship between brain activity and behavioral performance. Brain activity during emotional prosody processing was more strongly related to prosody recognition accuracy in ASD participants. In contrast, the coupling between STS and anterior cingulate cortex (ACC) activity predicted behavioral task performance more strongly in the control group. These results provide evidence for aberrant emotional prosody processing of individuals with ASD. They suggest that the differences in the relationship between the neural and behavioral level of individuals with ASD may account for their observed deficits in social communication. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (42481 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Noticing a person’s negative undertone to a seemingly neutral comment is crucial for choosing an adequate response. Emotional prosody, i.e. tone of voice, conveys important information about the speaker’s communicative intention and is processed mainly implicitly (i.e. in the absence of explicit verbal cues) ( ). In contrast to basic emotions (e.g. happy, angry) that involve universal, highly stereotypical physiological reactions ( ;  ;  ), understanding complex emotions (e.g. gratitude or jealousy) requires successful decoding and integration of contextual, social information ( ). 

How do humans extract emotional meaning from prosody? Across various tasks, emotional prosody processing has been shown to involve activity of the right superior temporal sulcus (STS) and the bilateral inferior frontal gyrus (IFG) ( ;  ). A current prosody processing model proposes that the right STS is involved in extracting acoustic information, which is subsequently evaluated within the bilateral IFG ( ;  ). IFG, amygdala and the ventral striatum are also involved in processing the emotional salience of auditory stimuli ( ). It is, however, an open question how the interplay between these regions differentiates intact from impaired emotional prosody processing. 

Autism Spectrum Disorder (ASD) has been associated with both impairments in emotional prosody production and processing ( ;  ;  ). However, empirical research investigating prosody processing in autism produced mixed results. Some studies reported aberrant prosody processing of basic and complex emotions in individuals with ASD compared to controls ( ;  ;  ;  ;  ;  ), whereas other studies did not find such group differences ( ;  ;  ). These inconsistencies likely reflect substantial differences in methodology between studies ( ). Studies investigating emotional prosody processing with abstract, non-word stimuli ( ), a limited number of mostly basic emotions ( ;  ), including one or two speakers and two answer options ( ), may lack the sensitivity to detect subtle impairments in prosody processing of high-functioning individuals with ASD. 

Furthermore, neural processing of emotional prosody in ASD has remained an under-researched topic with inconclusive results. There is the notion that individuals with ASD show increased and more widely spread neural activity during prosody processing compared to controls ( ;  ;  ). With respect to the visual domain, research has shown that emotion recognition impairments of individuals with ASD are linked to dysfunctional activity of the social perception system including the amygdala, the posterior STS and the fusiform gyrus ( ;  ;  ;  ;  ). 

The primary aim of this study was to corroborate previous reports of aberrant emotional prosody processing in individuals with ASD. Our results may also help to identify how the interplay of brain regions involved in prosody processing relates to prosody recognition performance and thus to intact   vs   impaired prosody processing. These insights help to further specify models of emotional prosody-processing. Given the striking social deficits of individuals with ASD in naturalistic settings ( ;  ), we investigated emotional prosody processing with naturalistic behavioral and neuroimaging tasks. Our study overcomes important drawbacks of previous studies: most previous studies included a very limited number of mostly basic emotions, few speakers and abstract stimuli, which may lack sensitivity to detect impairments in prosody processing of high functioning individuals with autism. 

We developed behavioral and fMRI tasks, which comprise a variety of complex emotions, speakers, as well as implicit and explicit task conditions. To approximate the communication challenges individuals face in real life, audio stimuli consisted of semantically neutral, short sentences spoken with either emotional or neutral prosody. In accordance with previous studies ( ), we assessed implicit emotional prosody processing with a gender discrimination task, asking participants to determine the speaker’s gender rather than the emotion conveyed in the spoken sentences, while in the scanner. In the explicit emotional prosody tasks, participants were asked to label the emotion conveyed in the speaker’s tone of voice. We expected individuals with ASD to score lower than controls on the explicit behavioral prosody recognition task and their emotion recognition deficit to be reflected in aberrant activity and effective connectivity of core prosody processing regions, such as the STS, IFG and amygdala. 


## Materials and methods 
  
### Procedure 
  
The study consisted of a behavioral and an fMRI experiment (average time interval between the sessions was 18 days (SD = 15 days)). Participants were invited to participate in both, if they met MRI inclusion criteria. The behavioral session took place in testing rooms at Freie Universität Berlin, Germany. Participants completed the behavioral prosody task online through the project’s website under the supervision of trained experimenters. The fMRI experiment was scheduled at the DINE (Dahlem Institute for Neuroimaging of Emotion, Freie Universität Berlin, Germany;   http://www.loe.fuberlin.de/dine/index.html  ). All participants received payment for participation and gave written informed consent in accordance with the requirements of the German Society for Psychology ethics committee (DGPs). 


### Participants 
  
#### Behavioral experiment 
  
Twenty-seven adults with ASD (18 male, mean age = 33, age range: 19–47) and 22 control participants (16 male, mean age = 32, age range: 20–46) with no reported history of psychiatric or neurological disorders were matched according to gender, age and verbal IQ as measured with a vocabulary test [Mehrfachwahl–Wortschatz Test (MWT);  ;  ]. All participants were right handed and had normal or corrected-to-normal vision. ASD participants were recruited through the autism outpatient clinic for adults of the Charité—University Medicine Berlin, Germany or were referred to us by specialized clinicians. ASD participants were diagnosed according to the DSM-IV criteria for Asperger syndrome and autism without intellectual disabilities ( ). Diagnoses were confirmed by at least one of the two gold-standard diagnostic instruments: the Autism Diagnostic Observation Schedule (ADOS) ( ) and the Autism Diagnostic Interview—Revised (ADI-R; ( ), if parental informants were available (  n   = 15)). For 12 participants, the diagnostic methods included both ADOS and ADI-R. Additionally, the diagnosis of Asperger syndrome was confirmed with the Asperger Syndrome and High-Functioning Autism Diagnostic Interview (ASDI) ( ).
   
Demographical and symptom characteristics 
    


#### FMRI experiment 
  
Seven of the 27 ASD participants met exclusion criteria for participation in the fMRI experiment (claustrophobia:   N   = 2; no normal or corrected to normal vision   N   = 1, no current health insurance:   N   = 1; psychotropic medication:   N   = 3). Two of the 22 controls chose not to participate in the fMRI experiment (one male and one female), and one female only participated in the fMRI experiment. The fMRI sample thus comprised 20 ASD and 21 control participants matched for age, gender and IQ ( ). All participants were right-handed. 



### Tasks and materials 
  
#### Behavioral prosody task 
  
The newly developed task comprised 25 semantically neutral sentences (e.g. ‘They were all invited to the meeting’) spoken by a total of 16 professional actors [6 male, varying age (20–50 years)]. All sentences (mean length = 5.1 seconds, SD = 0.9) were spoken with emotional prosody. In sum, the task covered four basic (angry, sad, happy, surprised) and 21 complex emotions (interested, frustrated, curious, passionate, contemptuous, furious, confident, proud, desperate, relieved, offended, concerned, troubled, expectant, confused, hurt, bored, in love, enthusiastic, lyrical and shocked). After listening to the audio excerpt, participants were asked to select the correct emotion label out of four different options and drag and drop it into the target panel (see   for an example). Distractor labels consisted of (i) two emotions of the same valence, with one resembling the correct option more closely with respect to emotional arousal than the other one and (ii) one emotion of opposite valence (e.g. target emotion: angry, same valence distractors: desperate and embarrassed, opposite valence distractor: enthusiastic). Participants read introduction slides before completing the task (approximate total task duration: 15 min). Throughout the entire task, participants used the mouse to navigate through introduction screens and solve the 25 task items. There was no time limit to solve each item, but participants were instructed to perform as fast and as accurately as possible. No trial and thus no target emotion was repeated. Also no feedback was provided about whether the items had been solved correctly or not. Items were presented in randomized order across participants. The prosody task was designed and programmed as a web-based application in cooperation with a digital agency (gosub communications GmbH,   www.gosub.de  ). Please refer to the supplemental section for detailed information about the chosen emotions, stimuli and task validation procedure.
   
Behavioral emotional prosody task. (A) Example item. Participants heard semantically neutral sentences that contained emotional prosody and were subsequently asked to label the emotional prosody from four different options. (B) Mean accuracy scores and reaction times for correctly solved items in Controls and ASD participants. Dark and light grey bars illustrate mean task performance of controls and ASD participants, respectively. * Significant difference between controls and ASD groups (  P   < 0.05). ASD: Autism Spectrum Disorders. 
  


#### FMRI prosody task 
  
In the block-design fMRI task, participants were presented with semantically neutral sentences (mean length: 2.9 s, SD = 0.01) spoken with emotional or neutral prosody by 10 different actors (5 male). The task was presented using Presentation (Version 14.1, Neurobehavioral Systems Inc., Albany, CA) in two runs of 10 min 34 s each. Participants had to either indicate the speaker’s gender (implicit condition) or the correct emotion label from two options (explicit condition) ( ). To make a choice, they had to press a button with either index or middle finger of their right hand. The position of the correct option and distractor on the screen (left or right) were counterbalanced (see example blocks for each condition in  ). Each fMRI task block (30s) started with a cue screen (2 s), which indicated the condition (‘gender’ for implicit blocks; ‘emotion’ for explicit blocks). The cue was followed by four audio trials (4 s each), interleaved with four answer screens (3 s each). Note that we simplified the explicit emotion recognition condition by reducing the number of target emotions (6 basic and 6 complex emotions) and answering options relative to the behavioral prosody task (4 basic and 21 complex emotions). Based on the ratings obtained by ( ), the six basic emotions (happy, surprised, fearful, sad, disgusted and angry) were matched for valence (Wilcoxon signed-ranks:   P   = 0.75) and arousal (Wilcoxon signed-ranks:   P   = 0.92) with six complex emotions (jealous, grateful, contemptuous, shocked, concerned, disappointed). In all explicit task blocks (neutral, basic and complex emotions) participants were asked to select the correct emotion label from two options. We limited the number of options to two (from the previous 4 in the behavioral task) to reduce task demands and thus possible load-related between group differences in Blood Oxygen Level Dependent (BOLD) signal change. One of the options was the correct emotion label. The other option, the distractor, was randomly chosen from five different emotion labels (4 of the same valence, differing in how much they resembled the valence and arousal of the correct label, and 1 emotion label of opposite valence). Eight blocks contained audios with neutral prosody (4 in the implicit and 4 in the explicit task condition, 32 audio stimuli in total) and 24 blocks contained audios with emotional prosody (12 in the implicit and 12 in the explicit condition, 96 audio stimuli in total). To increase design efficiency, task block should contain similar emotions, which would elicit similar neural responses. Given that several studies report different activation patterns for stimuli of positive   vs   negative valence ( ), we presented positive and negative emotions in separate blocks.
   
fMRI emotional prosody task. (A) The task comprised blocks of semantically neutral sentences spoken with (basic or complex) emotional prosody or with neutral prosody. Participants either indicated the speaker’s gender (implicit condition) or the correct emotion label from two options (explicit condition). (B) Brain regions showing significantly greater activation during emotional compared to neutral prosody processing (a) in controls and in ASD participants, (b) in both groups. (C) (a) Brain regions showing significantly greater activation during complex compared to basic emotional prosody processing in controls compared to individuals with ASD. Parameter estimates extracted from the amygdala and STS are illustrated in bar graphs (blue color: basic emotions, grey color: complex emotions). Error bars indicate standard error of mean. All clusters are significant at   P   < 0.05 and   z   = 2.3 family wise error (FWE) cluster corrected for multiple comparisons. (b) Effective connectivity between the right STS (seed region in yellow) and left Amygdala in controls (red) is greater (yellow) than in individuals with ASD. The psychophysiological interaction (PPI) is the interaction between the physiological regressor (PHYS: is the extracted time course from the STS seed region) and the psychological regressor (PSY: complex   vs   basic emotional prosody). All clusters are significant at   P   < 0.05 and   z   = 2.3 family wise error (FWE) cluster corrected for multiple comparisons. Abbreviations: Autism Spectrum Disorders (ASD); Blood Oxygen Level Dependent signal (BOLD signal); Inferior Frontal Gyrus (IFG); Superior Temporal Sulcus (STS) a.u. = arbitrary units. 
    
Example blocks for the explicit emotion recognition condition in the fMRI task 
  

Out of the 12 blocks per condition, 4 blocks contained positive emotions (2 blocks basic and 2 blocks complex positive emotions) and 8 blocks contained negative emotions (4 blocks basic and 4 blocks complex negative emotions). Blocks of audios were counterbalanced with respect to the type of emotion and speaker’s gender across runs and conditions. There was no overlap between sentences used in the behavioral and fMRI task. The average duration of audio stimuli in the fMRI task was 2.9 s (SD = 0.75 s, range: 2–4 s). Mean duration of basic and complex emotional prosody audios did not differ [t(94) = 0.14;   P   = 0.84]. 



### FMRI data acquisition 
  
MRI data were acquired on a 3 Tesla scanner (Tim Trio; Siemens, Erlangen, Germany) using a 12-channel head coil. Functional data were acquired using an echo-planar T2*-weighted gradient echo pulse sequence (TR = 2000 ms, TE = 30 ms, flip angle = 70, 64 × 64 matrix, field of view = 192 mm, voxel size = 3 × 3 × 3 mm ). A total of 37 axial slices (3 mm thick, no gap) were sampled for whole-brain coverage. Functional imaging data were acquired in two separate 310-volume runs of 10 min 34 s each. Both runs were preceded by two dummy volumes to allow for T1 equilibration. For each participant, a high-resolution T1-weighted anatomical whole brain scan was acquired in the same scanning session, which was later used for registration of the fMRI data (256 × 256 matrix, voxel size = 1 × 1 × 1 mm ). 


### FMRI data analysis 
  
FMRIB’s Software Library (FSL, version 4.1.8; Oxford Centre of fMRI of the Brain,   www.fmrib.ox.ac.uk/fsl   ( ) was used for fMRI data analysis on the High-Performance Computing system at Freie Universität Berlin (  http://www.zedat.fu-berlin.de/HPC  ). 

#### Preprocessing 
  
fMRI data were preprocessed and analyzed using FEAT (FMRI Expert Analysis Tool) within the FSL toolbox. After brain extraction, slice timing, and motion correction, volumes were spatially smoothed using an 8-mm full width at half maximum (FWHM) Gaussian kernel. Low frequency artifacts were subsequently removed with a high-pass temporal filter (Gaussian-weighted straight line fitting, sigma = 100 s). Functional data were first registered to individuals’ T1-weighted structural image and then registered to standard space using the FMRIB's Linear Image Registration Tool (FLIRT) ( ). 


#### fMRI single-subject analysis 
  
We modeled the time series individually for each participant and run including ten epoch regressors [representing the factor levels for the three factors emotion   complexity   (complex and basic prosody),   valence   (positive, negative and neutral prosody) and   condition   (implicit and explicit condition)], as well as one regressor for all button presses that occurred during the experiment. Additionally, we included six regressors modeling head movement parameters. There were no differences between groups in the total amount of motion between functional volumes [mean relative displacement:   t   (39) = 1.21,   P   = 0.236; see   in the supplemental section]. The regressors of interest were then convolved with a Gamma hemodynamic response function (HRF). Contrast images were computed for each condition, run, and participant. They were spatially normalized, transformed into standard space and then submitted to a second-order within-subject fixed-effects analysis across the two runs. 


#### FMRI group analysis 
  
All reported group analyses were higher-level mixed-effects analyses using the FMRIB Local Analysis of Mixed Effects tool provided by FSL (FLAME, stage 1 & 2). The models included age and IQ as regressors of no interest. Additionally, we added a gender regressor. Given the growing literature on gender differences in ASD, we explored if any group effects were additionally modulated by gender. We report clusters of maximally activated voxels that survived family wise error (FWE) cluster correction for multiple comparisons at a statistical threshold of   P   < 0.05 and a   z  -value > 2.3. Given our   a   priori   hypothesis regarding group differences in amygdala activity, we performed separate region of interest (ROI) analyses using an anatomically defined ROI of the bilateral amygdala. These analyses were also corrected for multiple comparisons at a statistical threshold of   P   < 0.05 and a   z  -value > 2.3. 


#### Common emotional prosody network 
  
To investigate which regions are involved in emotional prosody processing across groups, we computed a conjunction map of the overlap between activation in the control and ASD group for the contrast emotional   vs   neutral prosody ( ). We additionally report changes in neural activity for emotional vs. neutral prosody separately for each group in  . Subsequently, we performed whole brain analyses to investigate   group   differences (controls   vs   ASD) in emotional prosody processing and whether the emotional prosody network was distinctly modulated by   condition   (implicit   vs   explicit) and   emotion complexity   (complex   vs   basic) in controls   vs   ASD participants. For the sake of completeness, we report significant clusters of activation for these contrasts for each group separately in  .
   
Emotional prosody recognition performance 
    


####  Psychophysiological   i   nteraction  
  
To investigate group differences in effective connectivity of brain regions during prosody processing, we conducted a psychophysiological interaction (PPI) analysis following the guidelines by O’Reilly   et al.   (2012). The PPI analysis reveals how the coupling between a seed region and any other voxel in the brain changes with task condition ( ;  ;  ). Specifically, we sought to identify group differences in the coupling of brain regions when processing emotional   vs   neutral prosody and complex   vs   basic emotional prosody. 

The PPI represents the interaction between task condition (e.g. emotional   vs   neutral prosody) and the correlation of activity in two or more brain regions. External effects, such as the main effect of condition (e.g. brain activity for emotional   vs   neutral prosody), are regressed out in the PPI approach. We selected the right STS as the seed region for the PPI based on a previous study ( ) that identified the right STS as the input region of the prosody processing network. The seed ROI was defined by drawing a 10 mm sphere around the peak-activated voxel of the STS cluster (MNI coordinates: 52, −18, −10) in the conjunction map. The conjunction represents the overlap of activation for emotional   vs   neutral prosody across groups, and is therefore not biased by group differences. On the single-subject level, the PPI model included four main regressors and additional nuisance regressors as described in the preprocessing section. The physiological regressor was the demeaned time course from the seed ROI (right STS). The psychological regressor contrasted the experimental conditions (e.g. emotional   vs   neutral prosody). A third regressor represented the added effect of both task conditions (e.g. emotional and neutral prosody). Finally, the PPI regressor was the vector product of the physiological and psychological regressors. On the group level, we investigated differences in effective connectivity between controls and individuals with ASD. 


#### Brain behavior relationship 
  
To investigate whether brain activity during prosody processing correlated with prosody recognition accuracy, we added accuracy scores from the independent behavioral prosody task as a covariate into the fMRI group analysis. We investigated whether activity for emotional   vs   neutral prosody and complex   vs   basic emotional prosody were modulated by prosody recognition accuracy. 

Furthermore, we investigated whether the coupling between brain regions during emotional prosody processing predicted prosody recognition accuracy on the independent behavioral task. For this analysis, we added performance on the behavioral prosody recognition task as a covariate into the PPI group analyses. 




## Results 
  
### Behavioral results: emotional prosody recognition 
  
Performance measures for both tasks comprised accuracy scores (percentages of correct answers) and reaction times (time to choose the correct emotion label) for correctly solved items. 

#### Behavioral prosody task 
  
To avoid the repetition of basic emotion in the task, the majority of items conveyed complex emotions (21 out of 25 task items). Due to the different numbers of included basic and complex emotions, we refrained from analyzing group differences in basic emotion recognition and from comparing basic and complex emotion recognition in the behavioral task. Independent sample   t  -tests revealed that controls were more accurate and faster than individuals with ASD [accuracy:   t   (41) = 2.72,   P   = 0.006; RT:   t   (47) = −2.23,   P   = 0.03 (homogeneity of variance is not met); see  ]. In the ASD group, accuracy scores correlated negatively with autism symptomatology, as measured by the ADOS [  r   (22) = −0.448,   P   = 0.028] and the ASDI [  r   (22) = −0.478,   P   = 0.018], indicating that more severely affected individuals scored lower on the task (see   in the supplemental section). Furthermore, task accuracy was positively correlated with verbal IQ in the control group [  r   (20) = 0.497,   P   = 0.019] but not in the ASD group [  r   (25) = −0.100,   P   = 0.619]. The difference between the correlations is significant (Fisher’s   Z   = 2.10;   P   < 0.05). 


#### FMRI task 
  
The number of blocks containing basic and complex emotions in the fMRI prosody task was equal, and thus we compared emotion recognition behavior of complex   vs   basic emotions by adding the within-subject factor emotion complexity to the analysis  .   Repeated measures ANOVAs with the within subject factor complexity (complex   vs   basic emotions) and the between subject factor group (Controls   vs   ASD) were performed for accuracy rates and RT separately. Over all participants, basic emotions were recognized faster and more accurately than complex emotions [accuracy:   F  (1, 39) = 47.9,   P   < 0.01, η = 0.551; RT:   F  (1, 39) = 55.93,   P   < 0.01, η = 0.589]. The groups showed comparable emotion recognition performance for basic and complex emotions [accuracy:   F  (1, 39) = 0.43,   P   = 0.516; RT:   F  (1, 39) = 0.18,   P   = 0.667]. Furthermore, there was no significant group by complexity interaction for accuracy rates [  F  (1, 39) = 0.61,   P   = 0.441] and RT [  F  (1, 39) = 2.05,   P   = 0.161; see also  ]. In the implicit task condition, participants had to correctly label the gender of the speaker. Participants accuracy overall conditions was greater than 95%. There was no between group difference in either accuracy (Controls: 95%, SD = 6; ASD group: 96%, SD = 6) or reaction times (Controls: 0.9 s, SD = 0.2; ASD group: 0.9 s, SD = 0.2).
   
Significant activations in the contrasts of interest in Controls and in individuals with ASD 
    



### FMRI results 
  
#### Emotional prosody processing network 
  
Contrasting emotional with neutral prosody revealed a previously described fronto-temporal network including the STS and IFG in both groups (  and  ) whereby ASD and controls showed overlapping neural activity in the right temporal pole, STS and IFG (  and  ). There were no between group differences in overall emotional prosody processing.
   
Significant activations in the contrasts of interest over all participants and between group differences 
    


#### Effects of condition and emotion complexity on emotional prosody processing 
  
With regards to emotion complexity, we did not find regions that showed stronger activity for complex   vs   basic emotions in either group. We did, however, find a significant group by complexity interaction. Compared with the ASD group, controls showed a significantly greater increase in activity of bilateral fronto-temporal regions including the STS, insular cortex, superior temporal gyrus (STG) and right amygdala for complex   vs   basic emotions (  and  ). The ASD group recruited temporal regions, such as the STS, more when processing basic emotions. We found a significant main effect of condition (basic   vs   complex) in the ASD group only ( ). Interestingly, we also found significant gender differences in the ASD group. Female ASD participants showed more activity of right temporal regions such as the STG and STS for complex   vs   basic emotions compared to males ( ). 

In both groups, explicit   vs   implicit emotional prosody processing yielded increased activity of prosody processing regions such as the STS ( ). Implicit   vs   explicit prosody processing recruited cortical midline regions, such as the PCC and the frontal pole in both groups ( ). There was also a significant condition by group interaction. Controls showed increased activity of occipital and prefrontal regions compared to the ASD group ( ). 


#### Effective connectivity between brain regions during emotional prosody processing 
  
The PPI analysis did not reveal between group differences in processing emotional   vs   neutral prosody. We did, however, find between-group differences in effective connectivity for complex   vs   basic emotional prosody. STS and amygdala (peak voxel: −20, −6, −22) (  and  ). 


#### Relationship between neural processing of emotional prosody and behavioral performance 
  
We found group differences in the relationship between brain activity for emotional vs. neutral stimuli and prosody recognition performance on the behavioral task. Brain activity in a wide network of frontal and temporal regions, including the STG and the superior frontal gyrus, correlated more strongly with prosody recognition performance in individuals with ASD compared to controls ( ). There were no significant correlations between brain activity for complex vs. basic emotions and behavioral task performance in either group.
   
Brain behavior relationship. (A) Stronger correlation between brain activity during emotional   vs   neutral prosody processing and accuracy on the behavioral prosody recognition task in ASD participants compared to controls. Correlation plot illustrates the relationship between parameter estimates extracted from the MCC and task accuracy in controls (red) and in individuals with ASD (blue). (B) Stronger correlation between rSTS—ACC effective connectivity and accuracy on the behavioral prosody recognition task in controls compared to individuals with ASD. Correlation plot illustrates the relationship between effective connectivity and accuracy in controls (red) and in individuals with ASD (blue). All clusters are significant at   P   < 0.05 and   z   = 2.3 family wise error (FWE) cluster corrected for multiple comparisons. Abbreviations: Autism Spectrum Disorders (ASD); Middle Cingulate Cortex (MCC); Anterior Cingulate Cortex (ACC); right Superior Temporal Sulcus (rSTS). 
    
Relationship between neural processing of emotional prosody and behavioral performance in ASD   vs   Controls 
    

When investigating the relationship between effective connectivity and behavioral task performance, we found the opposite group difference. Higher coupling between the right STS and anterior cingulate cortex (ACC, MNI coordinates: 0, 48, −4) for emotional   vs   neutral prosody predicted prosody recognition accuracy in controls compared to individuals with ASD ( ). Furthermore, we found similar group differences when investigating the relationship between effective connectivity for complex   vs   basic emotional prosody and behavioral performance. The coupling between right STS, fusiform cortex (FC) and precentral gyrus (PG) was stronger correlated with task accuracy in controls than in the ASD group ( ).
   
Relationship between effective connectivity between brain regions and behavioral performance in Controls   vs   ASD 
    




## Discussion 
  
The aim of the current study was to investigate differences in emotional prosody processing between individuals with ASD and healthy controls in behavior and brain function. In the behavioral experiment, we found that the ASD group was slower and less accurate in recognizing emotional prosody than controls. Symptom severity was negatively correlated with accurate recognition of emotional prosody. More impaired individuals scored lower on the task. The fMRI experiment, replicated the well-established emotional prosody network, including the STS and IFG, overall participants. Complex   vs   basic emotional prosody elicited less activity of core prosody processing regions, such as the STS and amygdala, in individuals with ASD compared to controls. Also, the STS and amygdala were less functionally connected in individuals with ASD. Importantly, the relationship between behavioral performance and neural processing of emotional prosody differed between groups. In the ASD group, brain activity in a wider spread network of cortical regions was more strongly related to behavioral task accuracy. In controls, on the other hand, the magnitude of effective connectivity between STS and ACC during emotional prosody processing more strongly predicted behavioral accuracy. 

Processing emotional prosody robustly activated the well-replicated prosody network both in the control and ASD group ( ;  ). Furthermore, both groups showed overlapping clusters of activation in the right IFG and STS for emotional   vs   neutral prosody. The right STS and right IFG have been more strongly implicated in emotional prosody processing than their contralateral homologues ( ;  ). There were no between-group differences in overall prosody processing. We did, however, find group differences in processing complex   vs   basic emotions and implicit   vs   explicit prosody processing. 

Individuals with ASD displayed reduced activity in bilateral temporal regions, such as the superior temporal gyrus, temporal pole and right STS for complex vs. basic emotions. These regions have been extensively implicated in auditory processing ( ), in particular in processing emotional prosody ( ). This interaction effect in temporal regions, such as the STS, is due to the fact that individuals with ASD engage these regions more when processing basic   v   s   complex emotions. Previous research has shown that the STS does not distinguish between social and nonsocial information in individuals with ASD ( ). In this study, both basic and complex emotions represent social stimuli. Basic emotions, however, are less socially motivated; accurately recognizing basic emotions relies more on decoding physiological states than interpersonal relations ( ). Greater activity in the STS when processing basic emotions could mean that they are more salient. This may also explain greater processing accuracy of basic emotions in ASD. 

Furthermore, ASD participants exhibited reduced activity of the bilateral insula and right amygdala, regions associated with emotion processing ( ). Groups further differed in the magnitude of effective connectivity between the right STS and left amygdala for complex   vs   basic emotions. Typically developing controls exhibited a stronger coupling between STS and amygdala than individuals with ASD. Our results are in line with previous studies, which showed reduced functional connectivity of STS and amygdala in ASD in both the visual and auditory modality ( ;  ). Both, the amygdala and STS, have been implicated in social perception across modalities ( ), which precedes and supports later developing mentalizing abilities ( ;  ). 

The social perception deficits of individuals with ASD concern both visual and auditory modalities and persist from early childhood ( ;  ,  ) throughout adulthood ( ). In the visual domain, the amygdala and the posterior STS extending into the temporoparietal junction (TPJ) have been tightly linked to aberrant social perception of individuals with ASD ( ;  ;  ;  ), in particular to their deficits in inferring others’ intentions ( ;  ;  ;  ). In contrast, very little is known about auditory social information processing of individuals with ASD. Our findings indicate that the amygdala and STS underlie the social information processing deficits of individuals with ASD also in the auditory modality. 

In contrast to previous studies ( ;  ), we did not find increased activity of core mentalizing regions such as the ACC in controls for complex   vs   basic emotional prosody. The lack of a modulation by emotion complexity in typically developing controls suggests basic and complex emotions might be comparably salient and thus elicit similar activity of prosody processing regions. 

An exploratory analysis of gender differences for emotional prosody processing revealed that females with ASD exhibit greater STS activity when processing complex   v   s   basic emotions compared to males. These differences in neural processing could be linked to previously observed gender differences in autism symptomatology ( ). However, we did not find gender differences on the behavioral level. Given the limited sample size of individuals with ASD, larger-scale studies are needed to explore gender differences in emotional prosody processing in greater detail. 

In line with previous studies ( ;  ;  ;  ), we found a modulation of the emotion prosody network by task condition (implicit   vs   explicit). Explicit evaluation of emotional prosody produced increased activity of the STS and IFG, regions assigned to the core prosody network in both groups. In accordance with previous studies, our results thus provide evidence of greater involvement of the core prosody regions (STS and IFG) in directing attention to emotional prosody (explicit condition)   vs   away from it (implicit condition) ( ;  ;  ;  ). Implicit compared to explicit emotional prosody processing yielded activity of cortical midline regions, such as PCC, in both groups. Thus, in accordance with the literature, our study suggests that implicit and explicit prosody processing are mediated by distinct neural networks ( ;  ). Furthermore, controls showed greater activity in the angular gyrus, and prefrontal regions such as the ACC, for implicit   vs   explicit prosody processing than individuals with ASD. The angular gyrus has been implicated in processing semantic information, fact retrieval, shifting attention to relevant tasks and is believed to represent a cross-modal hub, which integrates these multiple cognitive processes across sensory modalities ( ). Increased activity of this region in the control group relative to the ASD group might thus indicate a higher degree of cross modal integration of relevant information during implicit processing of emotional prosody in controls   v   s   individuals with ASD. 

We found significant group differences in emotional prosody recognition on the behavioral task. Individuals with ASD showed lower performance on the newly developed prosody recognition task compared to controls. Accuracy rates were negatively correlated with symptom severity in individuals with ASD, with more impaired individuals scoring lower. Along with basic emotional expressions, the newly developed task covers a wide range of complex emotions portrayed by a large number of male and female speakers. The higher degree of complexity and ecological validity of the task most likely increased its sensitivity to the subtle impairments of our sample of high-functioning ASD participants. Our results are in line with studies showing emotion recognition difficulties from voices of individuals with ASD ( ;  ;  ). Given that the recognition of complex emotions may involve mental state processing ( ;  ;  ), the impaired recognition of complex emotions in individuals with ASD likely reflects their core deficit in understanding others’ mental states ( ). In the simpler fMRI version of the task, which comprised a more limited number of speakers and emotions (six basic and six complex emotions) with only two answer options, we did not find behavioral between-group differences. Similarly, some studies that also used a more limited number of speakers, emotions or answer options report no differences in emotional prosody recognition between individuals with ASD and controls ( ;  ;  ). Our study thus stresses the importance of using more naturalistic tasks than previously done to sensitively assess the subtle social cognitive impairments of high-functioning individuals with ASD. 

Finally, we took the first step towards establishing a neurocognitive model of prosody processing in ASD by investigating the relationship between neural processing of emotional prosody and prosody recognition performance on an independent task. 

We found significant group differences in the relationship between behavioral and neural prosody processing. In typically developing individuals the coupling between STS and ACC during emotional prosody processing was a stronger predictor of task accuracy than in individuals with ASD. While the STS is involved in assessing the social salience of nonverbal stimuli ( ;  ), the ACC is more strongly implicated in the explicit evaluation of emotions ( ;  ). A higher connectivity between the two regions may facilitate emotion detection in the auditory modality and thus increase emotion recognition accuracy. Moreover, increased connectivity between the STS, FC and PG while processing complex   v   s   basic emotions, was also more strongly related to prosody recognition in controls compared to individuals with ASD. The relationship between task-based functional connectivity of emotion processing regions and emotion recognition accuracy has been very little explored. A recent study that investigated the relationship between resting state functional connectivity and emotion recognition found that the intrinsic connectivity between STS and prefrontal regions was more predictive of emotion recognition in typically developing individuals than in individuals with ASD ( )). Reduced connectivity of the STS and prefrontal regions during emotion processing could account for the emotion recognition deficits of individuals with ASD. In contrast, higher activity of a wide-spread network of cortical regions including the STG and PCC was more strongly related to performance accuracy in the ASD than in the control group. ASD participants, however, were overall less accurate on the task. This indicates that the neural processes supporting accurate emotional prosody recognition in typically developing individuals differ from those in individuals with ASD. 

Control participants’ verbal IQ was positively correlated with emotional prosody recognition performance on the behavioral task. This was not the case for ASD participants, suggesting that their deficits in emotional prosody processing may be independent of verbal IQ. The IQ measure used in this study, however, provides a partial picture of an individual’s verbal competence. Future studies should exhaustively explore the potential relationship between language and emotional prosody processing by including a more general IQ test with more fine-grained assessments of verbal and pragmatic language skills. Another limitation to the current study is the lack of an implicit behavioral prosody processing task. Future studies should explore the relationship between implicit and explicit prosody processing with comparable performance based tasks. 

In sum, our study provides new insights into typical and atypical prosody processing that most likely have important implications for typical and impaired social communication in real life. We found significant differences between typically developing individuals and individuals with ASD on the behavioral and neural level as well regarding the relationship between behavioral and neural processing of emotional prosody. 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-45'>
<h2>45. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/32599550/' target='_blank'>32599550</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Sharpened self-other distinction in attention deficit hyperactivity disorder</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Neuroimage Clin</p>
<p><strong>Publication Year:</strong> 2020</p>
<p><strong>DOI:</strong> 10.1016/j.nicl.2020.102317</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/7327378/' target='_blank'>7327378</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This fMRI study used a social-related task (self-touch vs other-touch) that probes perception/processing of self and others (social touch). It includes a healthy control group of neurotypical adults (n=30, mean age ~23.7) with results reported separately. The paper reports whole-brain analyses (FWE-corrected whole-brain comparisons for other‑touch and group contrasts) in addition to ROI analyses, so it is not ROI-only. Participants fall within the 17–65 age range. Although the study also reports data from an ADHD group, healthy participant results are presented independently. Therefore all inclusion criteria are met and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.93</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>   Highlights  
  
Distinction of self and non-self is crucial for establishment of a bodily self. 
  
People with ADHD showed sharper neural distinction of self- and other-touch. 
  
Detection thresholds of weak tactile stimuli did not differ between groups. 
  
People with ADHD were less susceptible to the rubber hand illusion. 
  
People with ADHD might have a clearer self-other-boundary. 
  
  
## Introduction 
  
Differentiation between self-produced tactile stimuli and touch by others is necessary for social interactions and for a coherent concept of “self”. In attention-deficit-hyperactivity-disorder (ADHD), tactile hypersensitivity and social cognition problems are part of the symptomatology, but pathophysiological mechanisms are largely unknown. Differentiation of self- and non-self- generated sensations might be key to understand and develop novel strategies for managing hypersensitivity. Here, we compared the neural signatures of affective self- and other-touch between adults with ADHD and neurotypical controls (NC). 


## Methods 
  
Twenty-eight adult ADHD participants and 30 age- and gender-matched NC performed a self-other-touch-task during functional magnetic resonance imaging: they stroked their own arm, an object, or were stroked by the experimenter. In addition, tactile detection thresholds and rubber hand illusion (RHI) were measured. 


## Results 
  
ADHD participants had more autistic traits than NC and reported to engage less in interpersonal touch. They also reported to be more sensitive to tactile stimuli. Compared to NC, ADHD participants showed enhanced responses to both the self- and other-touch conditions: stronger deactivation during self-touch in the anterior and posterior insula, and increased activation during other-touch in primary somatosensory cortex. ADHD participants had intact tactile detection thresholds, but were less susceptible to the RHI. 


## Conclusions 
  
Unaltered detection thresholds suggest that peripheral processing is intact, and that hypersensitivity might be driven by central mechanisms. This has clinical implications for managing somatosensory hypersensitivity in ADHD. The more pronounced differentiation between self- and other-touch might indicate a clearer self-other-distinction. This is of interest regarding body ownership perception in both NC and ADHD, and possibly other psychiatric conditions with altered self-experiences, like schizophrenia. A sharper boundary of the own body might relate to deficits in social cognition and tactile hypersensitivity. 

 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (29693 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Attention-deficit/hyperactivity disorder (ADHD) is characterized by inattention, impulsivity and hyperactivity. ADHD is typically diagnosed during childhood but often persists into adulthood. ADHD can negatively affect life outcomes in multiple areas, e.g. in social interaction, education and occupation ( ). 

ADHD is associated with a higher prevalence of depression, anxiety, substance use disorder and autism spectrum disorder (ASD) ( ). In ASD, sensory abnormalities like hyper- and hyposensitivity have been described ( ). Much less is known about sensory processing in ADHD. The few available studies in children point to a sensory processing dysfunction ( ,  ,  ), which seems comparable to that of children with ASD ( ). In children with ADHD, about 50% have increased somatosensory reactivity in multiple sensory domains, compared to 20% in typically developing children ( ). In adults with ADHD, auditory hypersensitivity is related to inattention severity ( ) and increased pain sensitivity ( ). Atypical sensory processing is not related to the amount of autism traits, but to self-reported ADHD symptoms ( ), indicating that sensory dysfunction should be considered as a key symptom domain in ADHD. Even in the general population, ADHD traits relate to altered self-reported sensory sensitivity ( ). Altogether, this suggests that sensory hypersensitivity plays an important role for attention deficits in ADHD. 

Most studies on hypersensitivity in ADHD involve children and rely on self-report or parent-report; few studies have tested hypersensitivity experimentally. Such studies suggest differences in tactile adaptation ( ) and in physiological measures of recovery from a sensory challenge ( ). While one study found higher tactile detection thresholds – possibly related to inattention – ( ), another found no difference between children with ADHD and typically developing controls ( ). Abnormal tactile processing in ADHD might relate to cortical mechanisms involved in adaptation ( ). Indeed, neural responses to somatosensory stimuli appear to be altered in ADHD: children with ADHD show larger somatosensory evoked cortical responses ( ), and adults with ADHD show differences in cortical synchronization patterns in response to somatosensory stimuli ( ). 

Sensory processing problems relate to sleep and behavior problems in ADHD ( ,  ). Furthermore, tactile hypersensitivity can have far reaching consequences for affected people, from leisure activities ( ) to food preferences ( ,  ). Considering the importance of social touch during development ( ), hypersensitivity to touch by others might relate to social problems in ADHD, as has been suggested for ASD (Carissa J ( ). However, somatosensory processing, especially social touch, has hardly been studied in the ADHD population, and particularly not in adults. Symptomatology, comorbidities and subtypes might differ between adults and children ( ,  ,  ). Therefore, we studied the processing of social touch stimuli in young adults with ADHD. 

Adult ADHD participants and matched controls performed the self-other-touch-task previously established in neurotypical people ( ). Participants stroked their own arm (self-touch condition) or were stroked by the experimenter (other-touch condition). We used functional magnetic resonance imaging (fMRI) and psychophysics to measure behavioral and neurophysiological processing of self-touch and other-touch. Based on previously reported hypersensitivity problems, we hypothesized that the psychophysical test of ADHD participants would show lower detection thresholds for weak tactile stimuli. 

With regard to fMRI, we hypothesized that ADHD participants would be more sensitive to non-self-generated sensations, accompanied by a sharper self-other-distinction. Our region of interest here was the insula, given studies showing that posterior insula activates in response to slow stroking social touch ( ,  ) and plays a role in body ownership ( ), while anterior insula has been implicated in integrating interoceptive signals ( ), in the awareness of the own body ( ,  ,  ) and in tracking mismatches between predicted and actually perceived sensations ( ). 

A clearer self-other-distinction might in turn sharpen the experienced bodily self ( ,  ,  ). A way to test the stability of one’s own body are body ownership illusions, like the rubber hand illusion (RHI) ( ). Since we hypothesized that ADHD participants exhibit a clearer self-other-distinction, we expected them to be less susceptible to the RHI. 


## Methods and materials 
  
The study consisted of two parts: the first part was a functional magnetic resonance imaging (fMRI) session and the second part included detection thresholds and rubber hand illusion (RHI). 

### Participants 
  
Exclusion criteria for the neurotypical controls (NC) were any psychiatric disorder, alcohol or substance abuse, chronic pain, or any other major health concern as assessed during a structured telephone interview. 

Clinically stable ADHD participants were recruited at their biannual routine checkup visit at the adult Psychiatric Clinic, at the Linköping University Hospital, Sweden. Exclusion criteria for the ADHD group were any severe acute psychiatric disorders (such as, but not exclusively, psychosis, bipolar disorder, severe obsessive–compulsive disorder), ASD, substance use disorder within the past year, chronic pain or any other major health concern. In total, 53 adults with ADHD expressed interest in the study. Of these, five could not be reached, four declined participation after detailed study description, six were excluded for reasons related to MR scanning (metal in the body, claustrophobia), one due to ASD diagnosis, and one’s age was outside our target age range. Furthermore, seven participants did not show up for their appointment and one did not finish the fMRI task. The 24 persons not included had mean age 28.3 ± 5.0 years, 12 females ( ).   
Recruitment process and drop-out of ADHD participants. 
  

Some individuals with ADHD who could not participate in the first part due to MRI contraindications were able to participate in the second part, resulting in two partially overlapping samples. 

Functional imaging data were thus obtained from 28 adults with ADHD (25.7 ± 4.7 years old, 15 females). 30 neurotypical adults were recruited as age- and gender-matched controls (23.7 ± 3.6 years old, 16 females). After fMRI, the participants filled out the Social Touch Questionnaire ( ), the Autism Quotient ( ), and the Empathy Quotient ( ). 

The majority (23 of 28 [82%]) took stimulant medication, two had medication with atomoxetin, and two had no medication for ADHD. ADHD volunteers were asked to refrain from taking stimulant medication for 48 h prior to participation. Four individuals with ADHD were on medication with antidepressants (SSRI), which they continued during the experiment. 

All fMRI participants were contacted and asked to participate in the study’s second part. Threshold detection data was collected for 14 ADHD participants (26.7 ± 5 years old, 5 female) and 15 NC (24.9 ± 3 years old, 7 female), rubber hand illusion (RHI) data were obtained for 10 ADHD participants (24.1 ± 4.5 years, 6 female) and 15 NC. These samples contained two newly recruited ADHD participants and eight newly recruited NC ( ). These ADHD participants also took stimulant medication, from which they refrained for 48 h prior to the experiment. During phone contact for the second appointment, participants answered a questionnaire about their tactile sensitivity, based on the Sensory Perception Quotient ( ) and the Sensory Profile ( ,  ).   
Neurotypical controls and ADHD participant characteristics, AQ: autism quotient, EQ: empathy quotient, STQ: social touch questionnaire, m: mean, sd: standard deviation. 
  

The Linköping Regional Ethics Review Board approved the study (Dnr 2016/360-31, 2019-02318), and written informed consent was obtained after complete study description. 


### Self-other-touch task 
  
Participants performed the self-other-touch task as described before ( ). In short, the task consists of three conditions: 1) self-touch, during which participants stroked their own left forearm with the right hand; 2) object-touch, where participants stroked a pillow with the right hand; 3) other-touch, where participants were stroked on the left forearm by the experimenter. Participants were instructed to perform slow, light stroking. Our main interest was the difference between self-touch and other-touch. The object-touch was a control for movement during self-touch. 


### fMRI 
  
During fMRI, participants performed the touch task lying comfortably in a 3.0 Tesla Siemens scanner (Prisma, Siemens, Erlangen, Germany) with their left arm placed on their belly and the right arm propped up by pillows, to reduce the movement during self-touch. 

The participants watched a computer screen through goggles, where they could read the task instruction and the cues for the upcoming trial. The cues were presented for three seconds (in Swedish): “Active, please stroke your arm”; “Active, please stroke the object”; “Passive, your arm will be stroked by the experimenter”. When the text turned green, the participant was stimulated or had to perform the stimulation while the text was on the screen, i.e. during a period of twelve seconds. The experimenter was standing next to the scanner bore and received auditory cues on when to perform the stroking action via headphones. In order to provide a comparable tactile stimulation during the self- and the other-touch condition, as our previous study evaluated using hand tracking, the experimenter watched the self-stroking motion that the participant was doing and mimicked it as closely as possible ( ). Each condition occurred 10 times with 12 s rest between each stroking block, resulting in a total length of 13 min. 

A 12 channel head coil was used to acquire 801 T2-weighted echo-planar images (  EPI  ) containing 48 multiband slices (TR = 1030 ms, TE = 30 ms, slice thickness 3 mm, matrix size 64*64, field of view 488*488 mm , in-plane voxel resolution 3 mm , flip angle = 63°). Functional MRI data were analyzed using statistical parametric mapping (SPM12, Wellcome Department of Imaging Neuroscience, London, UK;   http://www.fil.ion.ucl.ac.uk/spm  ) in Matlab R2018b (The MathWorks, Natick, MA, USA). The following steps were performed: motion correction, co-registration of the mean   EPI   and the anatomical image, spatial normalization to the MNI T1 template, and segmentation of the T1 image using the unified segmentation approach ( ). Finally, all images were spatially smoothed with an isotropic Gaussian kernel of 6 mm full width at half maximum. 

For statistical analysis of the blood oxygen level dependent (BOLD) response, the general linear model approach was used as implemented in SPM12. Because of our short TR, the FAST-option ( ) was used, which increases autocorrelation modelling performance ( ). Using a block-design, the conditions self, other, and object were convolved with the hemodynamic response function. Additional regressors of no interest were the cue phase, which included the motor preparation, and the period of one second after the active conditions, when subjects stopped their movement and put their right arm back into a resting position. To account for movement associated variance, realignment parameters were included as regressors-of-no-interest. Because our paradigm might be prone to movement artifacts, we also included the first temporal derivative of motion parameters in x,y,z-directions plus an additional regressor censoring scans with more than 1 mm scan-to-scan movement ( ). In addition, we compared movement parameters between groups and found no significant difference (F(51,6) = 0.882, p = 0.52). Individual contrast images were taken to group-level analysis, where an ANOVA was used to compare conditions between groups. Family-wise-error correction at the voxel level was used to correct for multiple comparisons at the whole-brain level and for small volume correction based on our   a priori   regions of interest (ROI): the anterior and posterior insula, as the insula is implicated in the processing of affective touch ( ), and the awareness of feelings from the body and body ownership ( ,  ). 


### Detection thresholds 
  
Following our previous protocol ( ), detection thresholds were measured during the three touch conditions and during baseline (no stimulation) using von Frey monofilaments (Bioseb, USA/Canada). The four conditions were randomized. Subjects sat comfortably, with eyes closed, resting their left, exposed arm on an armrest or a table in front of them. They were instructed to report when they felt the stimulation with the filament on the left forearm. During self-touch and other-touch this stimulation occurred in addition to the stroking on the same arm. The filaments were presented in an ascending-descending order (0.08–78.5 mN). The perceptual threshold was defined as the smallest filament that was detected in at least five out of 10 trials. Groups were compared using a repeated measures ANOVA in SPSS (IBM Corp.). 


### Rubber hand illusion 
  
To induce a rubber hand illusion (RHI), participants were seated comfortably in front of a desk with the RHI set up. They placed their right arm below a small table and viewed the rubber hand next to their own arm through a window in the table. The rubber hand and the participant’s hand were stroked simultaneously while the participant was watching the rubber hand. Three synchronous and 3 asynchronous (temporal and local mismatch) stroking trials were performed in a randomized order. After 1.5 min, the participant was asked to report, how much they felt that the rubber hand could be their own hand, by giving a number between 0 (not at all) and 10 (very much). Proprioceptive drift data was not collected because our set-up was too prone for using visual cues to guide the answer. Furthermore, proprioceptive drift may not reflect body ownership ( ). Groups were compared using t-tests in SPSS (IBM Corp.). 



## Results 
  
### Participant characteristics 
  
ADHD participants ( ) displayed reduced social abilities: they had more autistic traits (T = 4.2, p < 0.001) and lower empathy scores (T = 2.6, p = 0.012). They also differed in touch-behavior: ADHD participants reported to enjoy interpersonal touch less (T = 2.8, p = 0.006) and displayed more tactile hypersensitivities (T = 3.6, p = 0.001). 

In NC, the amount of autistic traits was negatively correlated to empathy scores (: r = -0.64, p < 0.001) and positively correlated to tactile hypersensitivities (r = 0.51, p = 0.02). We found no such associations in the ADHD group (AQ-EQ: r = -0.15, p = 0.48; AQ-sensitivity: r = -0.13, p = 0.61). 


### BOLD signal related to self- and other-touch 
  
We were interested in group differences in BOLD signal in response to self-touch and other-touch. There was no main group effect. Both groups showed a higher activation for other-touch than for self-touch in superior and middle temporal gyrus, amygdala, anterior cingulate gyrus, claustrum, prefrontal and cerebellar regions ( ,  ). The whole-brain comparison of the other-touch condition revealed that ADHD participants showed a stronger activation in the right primary somatosensory cortex ( A), while there was no difference for the whole-brain group comparison during self-touch.   
Other-touch and self-touch in neurotypical controls (NC) and attention deficit hyperactivity disorder (ADHD) participants compared to baseline.   A)   Other-touch in NC,   B)   self-touch in NC,   C)   other-touch in ADHD,   D)   self-touch in ADHD. Positive BOLD signal in red-yellow, negative BOLD signal in blue-green, p < 0.05, FWE-corrected at the whole brain level, other-touch at [44 64], self-touch at [41 64]. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.) 
    
Attention deficit hyperactivity disorder (ADHD) participants showed stronger activation of primary somatosensory cortex during other-touch compared to neurotypical controls (NC) and stronger deactivation of bilateral insula during self-touch.   A)   Activation during other-touch, whole brain analysis: ADHD > NC, [24–40 60], p < 0.05, FWE-corrected, t = 5.54;   B)   Group*Condition interaction, ROI analysis: p < 0.05 FWE-corrected for anterior insula left [-38 14–14] F = 4.22.3, p = 0.001; right [38 10–16] F = 21.18, P = 0.002, posterior left [–36–20 10] F = 21.74, p = 0.002; right [36 8–16] F = 16.35, p = 0.013);   C)   Deactivation during self-touch, ROI-analysis: ADHD > NC [-36 11–7], p < 0.005, FWE-corrected for ROIs (anterior insula left [-36 14–14] t = 4.37; right [38 10–16] t = 4.53, posterior left [-36–20 8] t = 4.05; right [44 0–8] t = 3.74); B&C thresholded at p < 0.001, cluster size = 10 for illustration purposes. 
  

With respect to our ROIs, anterior and posterior insula, we found a group*condition interaction ( B). To understand this interaction better, we performed a   post-hoc   test comparing groups separately for self-touch and for other-touch. The interaction was mainly driven by the self-touch condition, during which ADHD participants showed a stronger deactivation than NC ( C). There was no group difference in the insula ROIs during other-touch. 


### Detection threshold 
  
To see if the ADHD group was more sensitive to tactile stimuli, we compared stimulus detection thresholds between groups for a tactile stimulus that occurred either alone or simultaneously with our three touch conditions. In NC we found a difference between the four conditions (baseline, self-touch, other-touch, object-touch) using a Kruskal–Wallis (χ2(3) = 29.8, P < 0.001,  ). A   post hoc   Wilcoxon signed-rank test showed that detection thresholds during self-touch were significantly higher than during baseline and object-touch, (baseline: Z =  − 3.4, P < 0.001; object: Z =  − 3.4, P < 0.001), but not higher than during other-touch (Z =  − 0.25, P = 0.8). ADHD participants did not differ from NC in detection thresholds (repeated measures ANOVA: between subjects effect: F(1,24) = 0.5, p = 0.49) and there was no interaction between group and condition (F(1.85,44.36) = 0.92, p = 0.4).   
Attention deficit hyperactivity disorder (ADHD) participants did not differ from neurotypical controls (NC) with regard to their detection thresholds. Green: NC, blue: ADHD, plot indicates mean (bold line), median (dashed line), 95% confidence interval (inner box), one standard deviation (outer box) and individual data points. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.) 
  


### Rubber hand illusion 
  
NC reported to experience the illusion during synchronous stroking (mean rating = 7.6 ± 1.8), but not during asynchronous stroking, which is considered a control condition (mean rating = 2.7 ± 1.9). ADHD participants were less susceptible to the RHI during synchronous stroking (mean rating ADHD = 5.1 ± 1.5, T = 3.58, p = 0.002). There was no difference between groups during asynchronous stroking (mean rating ADHD = 3.4 ± 3, T = 0.7, p = 0.48). 



## Discussion 
  
This is, to our knowledge, the first study to investigate responses to social touch in adults with ADHD. We found a clearer difference between processing of self-touch and social (other) touch in ADHD and that the ADHD group was less susceptible to the RHI illusion. Both these findings might indicate a clearer self-body-boundary. Detection thresholds did not differ between groups. This finding suggests intact peripheral detection of tactile stimuli in ADHD, while central processing might be altered. 

The suggestion of a sharper self-other-distinction in ADHD is based on two observations: a stronger deactivation in the insula during self-touch and a stronger activation in the primary somatosensory cortex during other-touch. The stronger deactivation during self-touch might be related to stronger predictions about the sensory consequences of own actions resulting in an increased attenuation of self-generated stimuli ( ). Typically, the brain seems to attenuate the sensations arising from one’s own actions, as they are behaviorally irrelevant. This is thought to work through an efference copy of the outgoing motor command, which predicts its sensory consequences ( ). This mechanism is important in detecting surprise, i.e. unpredicted sensations – which might indicate a threat (e.g. an injury) or a reward (e.g. a positive social interaction). The anterior insula has been implicated in this mechanism through ascending input from thalamus and bidirectional functional connectivity with the primary somatosensory cortex. Furthermore, anterior insula might compare actual sensations with predicted sensations, identify mismatches and direct attention/awareness ( ,  ). In line with this, anterior insula activates when detecting surprising tactile events ( ). In the present study, we examined the opposite effect: a highly predictable tactile sensation during self-touch. Deactivation of anterior insula in both groups might indicate that there is no mismatch between predicted and perceived tactile sensation. In ADHD, we observed increased insular deactivation only during this highly predictable event. Considering a possible sensory overload in ADHD, this could an overcompensation: a stronger suppression of stimuli that a person with ADHD is hypersensitive to – if they are predictable, like in the case of self-touch. Future studies should investigate developmental trajectories of sensory attenuation in ADHD ( ,  ). 

An alternative interpretation could be that people with ADHD show stronger attenuation of self-produced stimuli because they experience a clearer bodily self with sharper boundaries, as has been suggested for people with ASD ( ) – which could in turn lead to clearer efference-copy based predictions. 

Our finding, of a heightened activation in the primary somatosensory cortex in response to other-touch, might relate to somatosensory hypersensitivity and alterations in social interaction behavior. This hypersensitivity to touch is in line with previous reports of sensory over-reactivity in ADHD ( ,  ,  ), and strengthens the assumption that altered sensory processing – although not a core symptom according to diagnostic criteria – should be regarded as an important domain in ADHD. 

If touch by others is experienced as more intense by people with ADHD, they might not enjoy social touch as much and engage in it less, as indicated by results of the self-report questionnaire in our study. Considering the importance of social-touch during development ( ), tactile hypersensitivity could impact important social learning situations in early life. This might in turn lead to less social skills, and could be one of the mechanisms for the higher autistic traits and lower empathy scores observed in this ADHD sample and elsewhere ( ,  ). Interestingly, although we found more autistic traits in participants with ADHD compared to NC, there were no associations between these traits in the ADHD group and atypical sensory processing. This replicates earlier findings ( ), indicating sensory dysregulation as a key feature of ADHD in adults that should be addressed as part of the clinical assessment. 

Our results in ADHD are similar to previous findings in ASD, demonstrating a lower susceptibility to the RHI and other body illusions ( ,  ). It is possible that a sharper distinction between self-generated and other-generated sensations might increase the perceived boundaries of the bodily self, thereby making its perception more stable and preventing body illusions. A possible alternative could be that ADHD participants did not experience the illusion because of attention deficits during the procedure. 

A sharpened boundary of the bodily self could increase somatosensory sensitivity, if it becomes harder to integrate and adapt to sensations that are not self-generated. This may explain why people with ADHD may be preoccupied with behaviorally irrelevant somatosensory stimuli – like the tag of a shirt. If such a stimulus is constantly present and cannot be habituated to, it might be hard to focus on other tasks. 

In contrast to our hypothesis, ADHD participants showed intact detection threshold for tactile stimuli for all conditions. This suggest that altered central processing of somatosensory stimuli might explain the reported hypersensitivity, i.e. individuals with ADHD do not actually perceive more/weaker stimuli but rather have difficulties attenuating percepts of irrelevant stimuli. Deficits in sensorimotor gating, i.e. the suppression of response to redundant stimuli, have been reported previously, e.g. for auditory stimuli ( ), however the picture in ADHD is complicated, since other studies reported enhanced habituation ( ). We found stronger activity of primary somatosensory cortex in response to other-touch, however dysfunctional gating/habituation might already occur at an earlier processing step, e.g. in the spinal cord or the thalamus, which is considered to play a crucial role in sensory gating ( ,  ) – or the insula as we discussed above. 

These findings have implications for clinical management of the reported hypersensitivity. A relationship between attention deficits and problems in attenuating irrelevant stimuli has been described in self-reports ( ) and on measurements of evoked potentials in adults with ADHD ( ). Sensorimotor integration training is already part of the clinical approaches to manage hypersensitivity symptoms, especially in children ( ), but there are few studies on behavioral training and biofeedback, with contradictory results ( ). Typical outcomes in evaluation of the efficacy of such training focuses mostly on motor skills, hyperactivity and externalizing behavior. Our results suggest an additional focus on the ability to habituate to irrelevant sensations, which might positively affect core symptoms (attention and hyperactivity). A base for novel approaches in sensorimotor integration therapy can be found in the Bayesian brain hypothesis ( ,  ). Within this framework, hypersensitivity might be due to heightened prediction errors, which would interfere with the attenuation of irrelevant stimuli and could lead to deficits in attention control. Based on this, a possible training could be to improve somatosensory predictions. Novel developments in brain-machine interface could also offer promising approaches, like functional electrical stimulation, which could support the learning of habituation and attention control or improve sensorimotor prediction loops ( ). 

### Limitations 
  
Participants included in the ADHD group of this study were young, adults, stable on stimulant medication, with no significant medical or psychiatric comorbidities. The high prevalence of comorbidity of adult ADHD with substance use disorder and/or ASD ( ) may limit generalizability of our findings to adults with these conditions and warrants further studies involving ADHD subjects with relevant comorbid disorders. Furthermore, we only examined people with ADHD who had not taken stimulant medication for two days. We do not know how medication may alter tactile processing and it would be interesting to compare medicated and unmedicated states in a future study. 


### Conclusion 
  
We demonstrated a larger difference between self-generated and other-generated touch in the adult ADHD population. While this increased differentiation is present at the cortical level, we did not find differences at a detection threshold task, suggesting intact basic somatosensory thresholds. We furthermore show a less flexible bodily self-percept in ADHD using RHI, which might be related to the sharper self-other-distinction. Future studies need to investigate how an increased differentiation between self-generated and other-generated stimuli impacts attention, bodily self-boundaries and social cognition – and how it changes with regard to age and medication status. 



## Funding 
  
This work was supported by grants from the   (2015-02684) to HO, and from Swedish Läkaresällskapet, Sweden (SLS-878101) and Lions Forskningsfond, Sweden (liu-2019-01191) to RB. 


## Disclosure 
  
AJC has served as consultant and received speakers’ fees from Indivior, Camurus and Lundbeck, all outside the scope of this work. MH has received personal fees from BrainsWay Technologies, Indivior, and Aelis Farma, and other income from Pfizer and Adial Pharmaceuticals, outside the scope of the submitted work. RB, MFK and HO have nothing to disclose. 


## CRediT authorship contribution statement 
  
 Rebecca Boehme:   Conceptualization, Data curation, Formal analysis, Funding acquisition, Investigation, Methodology, Project administration, Software, Supervision, Visualization, Writing - original draft, Writing - review & editing.   Morgan Frost Karlsson:   Data curation, Formal analysis, Investigation, Project administration, Writing - review & editing.   Markus Heilig:   Conceptualization, Resources, Supervision, Validation, Writing - review & editing.   Håkan Olausson:   Conceptualization, Funding acquisition, Methodology, Resources, Supervision, Validation, Writing - review & editing.   Andrea Johansson Capusan:   Conceptualization, Formal analysis, Investigation, Project administration, Supervision, Validation, Visualization, Writing - review & editing. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-46'>
<h2>46. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22889284/' target='_blank'>22889284</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Impaired social brain network for processing dynamic facial expressions in autism spectrum disorders</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> BMC Neurosci</p>
<p><strong>Publication Year:</strong> 2012</p>
<p><strong>DOI:</strong> 10.1186/1471-2202-13-99</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3459703/' target='_blank'>3459703</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study is an fMRI investigation of social processing (perception of dynamic vs. static facial expressions—‘Perception and Understanding of Others’). It includes a healthy control group (n=13; mean age 24.3) reported separately alongside an ASD group, satisfying the requirement of at least one healthy adult sample within the 17–65 range. Analyses include whole-brain random-effects SPM results with correction for multiple comparisons (as well as ROI/SVC where specified), so it is not ROI-only. The design and reported outcomes directly address social-related neural processing in healthy adults, meeting all inclusion criteria and violating none of the exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
## Background 
  
Impairment of social interaction via facial expressions represents a core clinical feature of autism spectrum disorders (ASD). However, the neural correlates of this dysfunction remain unidentified. Because this dysfunction is manifested in real-life situations, we hypothesized that the observation of dynamic, compared with static, facial expressions would reveal abnormal brain functioning in individuals with ASD. 

We presented dynamic and static facial expressions of fear and happiness to individuals with high-functioning ASD and to age- and sex-matched typically developing controls and recorded their brain activities using functional magnetic resonance imaging (fMRI). 


## Result 
  
Regional analysis revealed reduced activation of several brain regions in the ASD group compared with controls in response to dynamic versus static facial expressions, including the middle temporal gyrus (MTG), fusiform gyrus, amygdala, medial prefrontal cortex, and inferior frontal gyrus (IFG). Dynamic causal modeling analyses revealed that bi-directional effective connectivity involving the primary visual cortex–MTG–IFG circuit was enhanced in response to dynamic as compared with static facial expressions in the control group. Group comparisons revealed that all these modulatory effects were weaker in the ASD group than in the control group. 


## Conclusions 
  
These results suggest that weak activity and connectivity of the social brain network underlie the impairment in social interaction involving dynamic facial expressions in individuals with ASD. 

 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (56370 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Background 
  
Individuals with autism spectrum disorders (ASD) are characterized primarily by qualitative impairments in social interaction [ ]. One of the most evident features of their social impairment involves deficient communication via emotional facial expressions [ ]. For example, several previous behavioral studies reported that individuals with ASD exhibited less attention [ ], attenuated emotional behaviors [ ], and reduced and/or inappropriate facial reactions [ ] in response to the facial expressions of other individuals compared with typically developing individuals. 

Several neuroimaging studies using functional magnetic resonance imaging (fMRI) and positron emission tomography tested the neural substrates of impaired facial-expression processing in ASD and reported inconsistent findings. Almost all these studies used photos of emotional facial expressions as stimuli and found that individuals with ASD showed abnormal activities in several brain regions, including the posterior superior temporal sulcus (STS) or its adjacent regions such as the middle temporal gyrus (MTG) [ - ], the posterior fusiform gyrus (FG) [ , - ], amygdala (AMY) [ - , ], medial prefrontal cortex (MPFC) at around the medial superior frontal gyrus [ , ]  ,   and the inferior frontal gyrus (IFG) [ , , ]. Most of these studies reported hypo activation of these regions [ - , - ] (however, see [ ]). Substantial neuroimaging and neuropsychological evidence in typically developing individuals has suggested that these brain regions are related to social activities, such as the visual analysis of dynamic aspects of faces involving the STS/MTG [ ], the visual analysis of invariant aspects of faces and/or subjective perception of faces involving the FG [ ], emotional processing involving the AMY [ ], attribution of mental states involving the MPFC [ ], and motor mimicry involving the IFG [ ]. Based on these data, these regions have been called “social brain” regions [ - ]. Hence, the findings in individuals with ASD appear to account for their impaired processing of emotional facial expressions. However, it must be noted that different studies have reported abnormalities in different parts of the social brain, and thus the results appear to be far from consistent. Furthermore, whether the neural substrates of impaired expression processing in ASD can be traced to reduced activity in any specific brain region and/or to reduced connectivity among the regions, which has been suggested in other lines of ASD research (cf. [ ]), remains unknown. 

Dynamic facial expressions are more natural and powerful cues in real-life social interaction than are static expressions. From an evolutionary perspective [ - ], human minds are programmed to efficiently process dynamic facial expressions of conspecifics compared with their static expressions, which are artificial signals or products of technology. The importance of the dynamic properties of facial expressions is illustrated by behavioral studies of typically developing individuals. Researchers who observed facial expressions in real situations described rich, dynamic information in emotional facial expressions [ , ]. Several experimental studies have indicated that dynamic facial expressions, as compared with static expressions, induced more evident psychological activities, such as perception (e.g., [ ]), emotional reactions (e.g., [ ]), and facial mimicry (e.g., [ ]). Advantages of using dynamic compared to static facial expressions to induce behavioral reactions have even been shown in newborn infants [ ]. Consistent with these behavioral data, several neuroimaging studies with typically developing participants have shown that the social brain regions were more active when viewing dynamic as compared to static facial expressions [ - ]. These regions included the STS/MTG [ - ], FG [ - ], AMY [ , , ], MPFC [ , ], and IFG [ , , ]. 

Nevertheless, few studies have investigated brain activities in response to dynamic facial expressions in individuals with ASD. Impaired social interaction via emotional expression has consistently been shown in individuals with ASD in real situations [ - ], and dynamic, not static, facial expressions would be plausible mediums for such impairments  .   Consistent with this idea, several behavioral studies have demonstrated that impairments in the ability of individuals with ASD to process emotional expressions were more evident in response to dynamic than to static facial expressions (e.g., [ ]). Therefore, it is reasonable to assume that neuroimaging studies using dynamic facial expressions would more clearly identify abnormal brain activities in these participants. Pelphrey et al. [ ] tested this issue by presenting dynamic and static facial expressions depicting anger, fear, and neutral emotions to a group of individuals with ASD and to typically developing controls. The researchers found that the observation of dynamic facial expressions elicited less activation in the ASD group as compared with the control group in several social brain regions including the STS/MTG, FG, AMY, and MPFC. These data suggest that this reduced brain activation in response to dynamic facial expressions reflects the neural basis of impaired facial expression processing in individuals with ASD. However, this study did not reveal clear IFG activity in either the ASD or the control group. This issue could be critical because the IFG has recently received considerable interest in the neuroscientific literature on ASD. Indeed, it has been suggested that the IFG contains specific neuronal populations, known as “mirror neurons,” that discharge both when observing and when executing specific actions (for reviews, see [ , ]). In the context of behavioral data indicating abnormal mimicking in ASD (e.g., [ ]), some researchers have proposed that IFG dysfunction may constitute a fundamental deficit in ASD [ - ]. We reasoned that we could clarify this issue by using dynamic facial expression stimuli that were shown to effectively activate the IFG in typically developing individuals [ ]. We hypothesized that the observation of dynamic, compared with static, facial expressions would clearly reveal hypo activation of social brain regions (i.e., STS/MTG, FG, AMY, MPFC, and IFG) in individuals with ASD. 

Furthermore, the functional network patterns of the social brain regions for processing dynamic facial expressions in both typically developing individuals and those with ASD remain unknown. A previous study tested the effective connectivity in typically developing control and ASD groups using dynamic facial expressions as stimuli and found differential patterns of effective connectivity between groups [ ]. However, because that study focused on the effects of tasks, the functional network underpinning the processing of dynamic facial expressions   per se   remains to be tested. Among the components of the social brain, converging data from anatomical and theoretical studies suggest that the STS/MTG and IFG constitute the circuit. Several anatomical studies, including histological examinations in humans [ , ] and non-human primates [ , ], as well as diffusion tensor imaging in humans [ - ] and non-human primates [ ], indicated that the STS/MTG and IFG are directly connected. Some researchers have proposed that this circuit serves an important function in social interaction as the mirror neuron system (MNS) in typically developing individuals and is impaired in individuals with ASD [ , , ]. However, this idea remains to be empirically tested. Based on these data, we hypothesized that observation of dynamic versus static facial expressions would enhance the functional couplings of the neural networks including the STS/MTG and IFG of typically developing individuals and that reductions would be found in the same functional neural networks of individuals with ASD. 

In the present fMRI study, we examined the brain activities of a group of high-functioning individuals with ASD and age- and sex-matched typically developing controls while they viewed dynamic and static facial expressions. The stimuli used to depict dynamic facial expressions were shown to activate the social brain regions, including the IFG, in typically developing participants [ ]. The stimuli were also found to sufficiently represent natural changes in facial expressions [ ] and to effectively induce subjective emotion [ ] and facial mimicry [ ] in typically developing individuals. We prepared facial expressions with both negative (fearful) and positive (happy) emotional valences. The participants were asked to discriminate the sex of the presented faces to ensure that they were attending to the stimuli and to prevent their explicit processing of the emotional expressions. By comparing the brain activities under dynamic versus static facial expression conditions, we identified the regions involved in the processing of dynamic facial expressions. Furthermore, to investigate effective connectivity, we conducted dynamic causal modeling (DCM). 


## Results 
  
### Behavioral performance 
  
The correct response percentage of the sex-discrimination task was comparable across groups: dynamic fear (control:   M   = 98.4,   SD   = 1.1; ASD:   M   = 92.4,   SD   = 5.3), dynamic happiness (control:   M   = 98.7,   SD   = 1.0; ASD:   M   = 93.4,   SD   = 5.3), static fear (control:   M   = 98.7,   SD   = 1.0; ASD:   M   = 93.9,   SD   = 4.3) and static happiness (control:   M   = 97.4,   SD   = 1.3; ASD:   M   = 93.8,   SD   = 3.8). A three-way repeated-measures analysis of variance (ANOVA) using group, presentation condition, and emotion as factors on the correct response percentage showed no significant main effects or interactions. 

Correct response reaction times (RTs) were also comparable across groups: dynamic fear (control:   M   = 231.3,   SD   = 25.5; ASD:   M   = 242.0,   SD   = 52.7), dynamic happiness (control:   M   = 237.8,   SD   = 28.6; ASD:   M   = 205.7,   SD   = 53.0), static fear (control:   M   = 183.0,   SD   = 21.0; ASD:   M   = 186.4,   SD   = 45.5) and static happiness (control:   M   = 182.0,   SD   = 22.1; ASD:   M   = 201.3,   SD   = 41.2). An ANOVA with the same design as described above on the correct RTs showed only a significant main effect of presentation condition, indicating longer RTs in response to dynamic than to static presentations (  F  (1,23) = 13.96,   p   < .005). 

In summary, behavioral performance data revealed no significant effects related to group. 


### Regional brain activity 
  
We tested regional brain activity using the three-way repeated-measures ANOVA model with group, presentation condition, and emotion as factors (Additional file  : Figure S1). Initially, the simple main effect of presentation condition, contrasting dynamic and static presentations, was tested for each group (Table  ; Figure  ). For the control group, broad ranges of bilateral posterior regions, which included activation of the MTG and FG, were detected as areas of significant activation. Significant activation was also observed in the bilateral AMY, bilateral MPFC, and right IFG. For the ASD group, bilateral activation of the posterior regions was found to be significant, although its size was smaller than that of the control group. No other areas showed significant activation, including such social brain regions as the AMY, MPFC, and IFG. 
  
Brain regions showing significant activation for dynamic versus static facial expressions 
  
The coordinates of the foci of activation in Montreal Neurological Institute space, the T-values, and the cluster sizes for the control and autism spectrum disorders (ASD) groups are shown in the left and right parts, respectively.The extent threshold of p < .05, corrected for multiple comparisons, with the height threshold of p < .01 (uncorrected) were used. 
    
 Statistical parametric maps showing significant brain activation for dynamic versus static facial expressions.   The control (CON) and autism spectrum disorders (ASD) groups are shown in the left and right panels, respectively. The areas of activation are rendered on spatially normalized brains (upper) and overlaid on the normalized anatomical MRI of one of the participants at the coronal section showing amygdala activation (lower). The cross hairs in the lower panels are centered on the activation focus of the left amygdala in the control group (  x   -26,   y   -6,   z   -16;   t   = 4.65; cluster size = 5368 mm ). An extent threshold of   p   < .05, corrected for multiple comparisons, with a height threshold of   p   < .01 (uncorrected) were used. L = Left hemisphere; R = Right hemisphere. 
  
Then, a planned contrast of the interaction between group and presentation condition was conducted, testing for reduced activation in the ASD as compared with the control group under dynamic versus static conditions (Table  ; Figure  ). The bilateral posterior regions, including the activation foci in the MTG in the right hemisphere and the FG in both hemispheres, were significantly activated. Significant activation was also found in the left AMY, bilateral MPFC, and right IFG. No significant activation was observed in any other region. 
  
Brain regions showing significant interactions between group and presentation condition 
  
The coordinates of the foci of activation in Montreal Neurological Institute space, their   T  -values, and the cluster sizes are shown. 

The extent threshold of   p   < .05, corrected for multiple comparisons, with the height threshold of   p   < .01 (uncorrected) were used. 
    
 Brain activation for the significant interaction between group and presentation condition.   Weaker activation was found in the autism spectrum disorders (ASD) group than in the control (CON) group for dynamic (DY) versus static (ST) expressions.   A  . Statistical parametric maps rendered on spatially normalized brains. A height threshold of   p   < .01 (uncorrected) was used without extent threshold restriction for display purposes. L = Left hemisphere; R = Right hemisphere.   B  . Statistical parametric maps of representative brain regions overlaid on the normalized anatomical MRI of one of the participants in this study. From left to right, the activation of the middle temporal gyrus (MTG;   x   52,   y   -62,   z   0;   t   = 5.08), fusiform gyrus (FG;   x   40,   y   -58,   z   -14;   t   = 3.00), amygdala (AMY;   x   -28,   y   -4,   z   -18;   t   = 2.89), medial prefrontal cortex (MPFC;   x   8,   y   66,   z   20;   t   = 3.87), and inferior frontal gyrus (IFG;   x   48,   y   26,   z   8;   t   = 3.06) is shown. The statistical thresholds are the same as above.   C  . Mean parameter estimates (±   SE  ) of brain regions corresponding to the above overlaid MRIs. The data were extracted at the sites of peaks. FE = Fear; HA = Happiness. 
  
We also conducted exploratory analyses for other interactions related to the group factor in the whole brain, but found no significant results. 


### DCM 
  
DCM analyses were conducted to test the MNS network for each group. Bi-directional (forward and backward) intrinsic connections were constructed between the primary visual cortex (V1) and MTG and between the MTG and IFG (Figure  a). The modulatory effect of dynamic presentation was modeled to modulate each of these bi-directional connections. Based on the locations of the modulatory effects, we constructed the following four models (Figure  b): (1) the null model, with no modulatory effect; (2) the MNS-entrance modulation model, with modulatory effects on the V1–MTG connections; (3) the MNS-core modulation model, with modulatory effects on the MTG–IFG connections; and (4) the full model, with modulatory effects on both the V1–MTG and MTG–IFG connections. The exceedance probability of the Bayesian model selection (BMS) indicated that the full model was the most likely for both groups (Table  ). 
  
 Models and results of dynamic causal modeling (DCM) regarding the mirror neuron system (MNS).    A  . Analyzed brain regions rendered on the spatially normalized brain. V1 = Primary visual cortex; MTG = Middle temporal gyrus; IFG = Inferior frontal gyrus.   B  . Analyzed models. Thin arrows indicate intrinsic connections between brain regions. Bold arrows indicate the modulatory effects of dynamic presentation.   C  . Mean coupling parameters (±   SE  ) for the control (CON) and autism spectrum disorders (ASD) groups. Statistical comparisons showed that all parameters were significantly weaker in the ASD than in the control group (  t  -test,   p   < .05). 
    
Summary of the results of Bayesian model selection (BMS) and Bayesian model averaging (BMA) 
  
To test group differences in coupling parameters, Bayesian model averaging (BMA) analysis was conducted (Table  ), and the resultant posterior means of modulatory effect parameters (Figure  c) were analyzed. First, to test for differences from zero, one-sample   t  -tests were conducted for each group. The results showed that the facilitative modulatory effects of dynamic presentation were significant among members of the control group for all bi-directional connections between the V1 and MTG and the MTG and IFG (  t  (12) > 3.76;   p   < .005). Significant facilitative modulatory effects of dynamic presentation were found for the connection from the V1 to the MTG (  t  (11) = 2.73;   p   < .05) but not for any other connections (  t  (11) < 1.20;   p   > .1) in the ASD group. To test for differences between groups, two-sample   t  -tests were conducted. The results showed reduced modulatory effects under the dynamic condition with respect to all connections in the ASD group as compared with the control group (  t  (23) > 1.91;   p   < .05). 



## Discussion 
  
### Regional brain activity 
  
Our results regarding regional brain activity in the control group showed that observation of dynamic facial expressions was associated with greater activation than observation of static facial expressions in distributed brain regions including the MTG, FG, AMY, MPFC, and IFG. The activation of these regions is consistent with the findings of previous studies (e.g., [ ]). All of these brain regions have been proposed to constitute the social brain network (e.g., [ ]); our results confirm that the presentations of dynamic versus static facial expressions are appropriate for activating the social brain networks of typically developing individuals. 

More importantly, the group comparison results showed that these social brain regions were less activated in response to dynamic than to static facial expressions in the ASD compared with the control group. Because the participants in the ASD group had no symptoms other than social impairment and repetitive traits, these results can be attributed to the core deficits of ASD. The reduced activation of the social brain regions in individuals with ASD in response to dynamic facial expressions is consistent with the findings of a previous study [ ]. Because group differences in IFG activities were not reported in the previous study, the current study is the first to provide evidence that functional abnormality in this region is related to the impaired processing of dynamic facial expressions in ASD. We consider the possibility that some methodological differences may account for the disparity in the results. For example, the stimuli depicting dynamic facial expressions in the present study reflected more rapid changes than did those used in the study conducted by Pelphrey et al. [ ]. A previous behavioral study reported that the speed at which dynamic facial expressions changed influenced the recognition of natural facial expressions and suggests that the speed used in the present study was preferable for natural dynamic facial expressions [ ]. Because several anatomical studies have reported single-cell and/or population level structural abnormalities in the social brain regions (i.e., STS/MTG [ - ], FG [ , ], AMY [ , ], MPFC [ , ], and IFG [ , , ]) it is plausible that these regions reflect characteristics of abnormal brain functioning in ASD. Because dynamic facial expressions are realistic mediums for social interaction, our results suggest that the weak activation in these social brain regions is related to the real-life impairments in communication via facial expressions experienced by individuals with ASD. 

Previous neuroimaging studies of typically developing participants (e.g., [ - ]; for reviews, see [ , ]) have shown that the STS/MTG is involved in visual analyses of the dynamic or changeable aspects of faces. Previous neuroimaging studies also showed that observation of dynamic point-light displays of human actions activated the STS/MTG in typically developing individuals but not in those with ASD [ , ]. Consistent with these neuroscientific data, several behavioral studies have reported that individuals with ASD showed impaired perception of dynamic human actions [ - ]. In their review of behavioral and neuroscientific studies, Dakin and Frith [ ] proposed that individuals with ASD experience impairment in the perception of human actions and that this impairment appears to be related to dysfunction in the STS/MTG. Together with these data, our results suggest that reduced STS/MTG activation is involved in impaired visual analyses of the dynamic aspects of emotional facial expressions experienced by those with ASD. 

In contrast, the FG has been shown to relate to the visual analyses of invariant aspects of faces and/or the subjective perception of faces in typically developing participants (e.g., [ , ]; for a review, see [ ]). Several previous neuroimaging studies in individuals with ASD have also reported reduced FG activation in processes involved in basic visual discrimination of faces versus non-faces [ - ]. Together with these data, our results suggest that the dynamic presentations of facial expressions enhance the visual analyses or perception of faces in typically developing individuals but not in individuals with ASD. 

The AMY has been shown to be involved in emotional processing of typically developing participants while they view dynamic facial expressions [ ]. A previous neuroimaging study reported consistent changes in the AMY activities of typically developing controls but not of those with ASD as a function of the intensity of the emotional facial expressions depicted in photos, suggesting abnormal emotional processing in the AMY of individuals with ASD [ ]. Several lesion studies in animals have also indicated that damage to the AMY induced abnormal emotional reactions to the emotional expressions of other individuals (e.g., [ ]), which have been likened to the socioemotional impairments in ASD [ ]. Consistent with these neuroscientific data, a previous behavioral study reported that individuals with ASD did not show higher autonomic and behavioral responses to distressed than to neutral dynamic expressions, although typically developing controls did show such responses [ ]. Combined with these data, our results suggest that reduced AMY activation is involved in the impaired emotional reactions to dynamic facial expressions shown by individuals with ASD. 

The MPFC has been shown to be activated when participants attributed mental states to others (i.e., mentalizing or theory of mind; e.g., [ ]; for a review, see [ ]). The ability to mentalize has been proposed as a the specific characteristic that has emerged over the course of human evolution [ ] and as constituting a crucial social deficit in ASD [ ]. The reduced MPFC activation in mentalizing tasks among individuals with ASD compared with typically developing individuals has also been shown in previous neuroimaging studies [ , , ]. Our results showing that this region was active in response to dynamic facial expressions among those in the control group suggest that typically developing individuals automatically try to read others’ mental states in real-life social interaction. Furthermore, our results showing group differences in the activities in this region suggest that such automatic mentalizing is relatively less pronounced in those with ASD. 

Several previous neuroimaging studies involving typically developing participants have reported greater IFG activation not only when participants passively observed dynamic versus static facial actions [ , , , , ], but also when participants imitated the dynamic facial expressions that they were viewing than compared with when they passively viewed these stimuli [ , ]. This finding is consistent with theories proposing that the IFG contains mirror neurons [ , ], which are activated in response to both the observation and the execution of facial expressions. Previous neuroimaging [ ] and magnetoencephalographic [ ] studies have consistently indicated that the imitation of facial actions while viewing static facial stimuli induced less activation in the IFG in the ASD than in the control group. Together with these data, our results suggest that the reduced IFG activation in individuals with ASD in response to dynamic facial expressions is related to deficits in automatic facial mimicry in ASD. 

It is interesting to note that visual inspection of IFG activities (Figure  ) indicates that the ASD group participants showed clear IFG activation against the resting condition, although the differences between dynamic and static conditions were smaller than those in the control group. Consistent with these data, previous behavioral studies reported that individuals with ASD did not lack facial reactions to the emotional facial expressions of other individuals but instead reacted to the facial expressions differently from the ways in which typically developing individuals reacted [ , - ]. Collectively, our results suggest that the activation patterns of the mirror neurons in the IFG in individuals with ASD may be altered, perhaps producing abnormal facial mimicry during social interaction involving facial expressions. 


### Effective connectivity 
  
Our results regarding the DCM in the control group showed that observation of dynamic compared with static facial expressions enhanced effective connectivity of the MNS network connecting the V1, MTG, and IFG. These results provide a mechanistic account of the enhanced activities manifested by sets of brain regions in response to dynamic facial expressions by construing them as a positively connected circuit. For example, the STS/MTG is more active in response to dynamic than to static faces because the inputs from the V1 through the feed forward connection and the inputs from the IFG through the feedback connection are enhanced. The result also provides suggestions for information flow in the neural processing of dynamic facial expressions: When we observe dynamic facial expressions, the visual information processed through the V1 and STS/MTG is transmitted to the motor processing area in the IFG; then, the motor representation in the IFG modulates visual decoding in the STS/MTG, which then modulates basic visual processing in the V1. These systematic views are consistent with previous theoretical proposals that these brain regions constitute the functional network of the MNS and/or social brain network (e.g., [ ]). To our knowledge, this is the first evidence that dynamic facial expressions enhance not only regional brain activities but also effective connectivity among these regions. 

More interestingly, our results revealed weaker modulatory effects of dynamic facial expressions on the MNS connections in the ASD group than in the control group. As in the case of the control group, our results provide a mechanistic account of the relatively weak activities of the social brain regions for processing dynamic facial expressions in individuals with ASD: In these individuals, positive connectivity among the regions is weak. For example, STS/MTG activation induced by dynamic versus static facial expressions is reduced because feed forward inputs from the V1 and feedback inputs from the IFG are weaker than those in typically developing individuals. The effect of weak neural connectivity in ASD has been theoretically proposed in several previous studies (e.g., [ ]). Previous empirical studies have also reported that individuals with ASD showed reduced functional connectivity while engaging in social tasks, such as expression recognition [ , ], face perception [ , ], mentalizing [ ], and other non-social cognitive tasks [ - ]. Our results extend the literature by providing the first evidence that effective connectivity modulation of the social brain network for processing of dynamic facial expressions is reduced in ASD. 

Our results showed reduced modulatory effects in both the core (MTG–IFG) and the entrance (V1–MTG) connections of the MNS in the ASD group. These results provide insights into the loci of abnormalities in the social brain networks of those with ASD. As mentioned above, several previous studies have found abnormal activities in the social brain regions of individuals with ASD (e.g., [ ]). These data suggest the existence of problems in the core parts of the social brain network in ASD. However, some other studies have reported abnormal activities in the early visual cortices in individuals with ASD (e.g., [ ]; for a review, see [ ]), suggesting that problems begin before the social brain is involved. Our results allow reconciliation of these lines of research by indicating functional problems at both the entrance and the core of the social brain network among those with ASD. 

Our results provide unique explanations and predictions of the behaviors of typically developing individuals and of those with ASD. For example, a previous behavioral study among typically developing individuals showed that intentional facial mimicking facilitated the recognition of dynamic facial expressions [ ]. Our results explain this finding by indicating that one’s own facial motor commands related to IFG activation facilitate the visual analyses of others’ facial expressions that are related to MTG activation. Such an idea provides the basis for predicting that the facilitative effect of facial mimicry on expression recognition may be impaired in individuals with ASD. 


### Implications, limitations, and future directions 
  
Our results showing the group differences in the functioning of the social brain network in response to dynamic versus static facial expressions have practical implications for experimental studies on ASD. Several behavioral and neuroscientific studies have previously used static emotional facial expressions as stimuli to investigate abnormalities in the processing of emotional expressions in individuals with ASD and have produced inconsistent findings. Based on our results, we propose that the presentations of dynamic facial expressions are more appropriate than the presentations of static expressions for revealing abnormalities in social interaction among those with ASD. Consistent with this idea, some pioneering behavioral studies have found that dynamic presentations of facial stimuli revealed abnormal behavioral patterns characterizing the social interaction of individuals with ASD; these results have not been observed in studies using static presentations. For example, Uono et al. [ ] reported that experiments using dynamic facial expressions as stimuli revealed the facilitative effect of emotional expression on automatic gaze-triggered attentional shifts in typically developing individuals and the impairment in this regard among individuals with ASD, although such effects were not found in response to static presentations [ ]. We expect that further studies using dynamic facial expressions as stimuli will provide pronounced evidence of the cognitive mechanisms and neural substrates underlying the social impairments of ASD. 

Some limitations of this study should be acknowledged. First, the contrast between dynamic emotional and dynamic neutral expressions remains untested. Such a contrast would allow us to discriminate between the effects of facial motion and those of the emotional messages conveyed by dynamic facial expressions. This issue could be intriguing because inconsistent findings have been reported in studies with typically developing individuals regarding social brain activation patterns for dynamic emotional versus dynamic neutral faces (e.g., [ , , ]). Regarding this issue, Pelphrey et al. [ ] measured brain activation in response to dynamic neutral faces, which were derived from identity morphing, and static neutral faces in ASD and typically developing control groups. They found no significant interaction between group (ASD vs. control) and presentation condition (dynamic neutral vs. static neutral) in the activation of the AMY, FG, or STS/MTG. These results suggest that weaker activation of these regions induced by dynamic facial expressions in ASD might not be accounted for by facial motion   per se  . However, this question remains unresolved for the activities of other social brain regions (e.g., the IFG), and further investigation on dynamic neutral faces is an important matter for future research. 

Second, we tested only fearful and happy facial expressions. Hence, the effects of dynamic presentations of other emotions on individuals with ASD remain to be examined. Observation of dynamic facial expressions depicting other emotions may reveal abnormal activities in other brain regions among those with ASD. For example, some previous neuroimaging studies with typically developing participants have reported that the observation of dynamic and/or static disgusted facial expressions activated brain regions that were not activated in the present study, including the basal ganglia and insula (e.g., [ , ]; for a review, see [ ]). A previous neuroimaging study showed that the observation of photos depicting disgusted facial expression induced less activation in these brain regions in the ASD than in the control group [ ], although such a group difference was not evident in another study [ ]. We speculate that the observation of dynamic versus static facial expressions of disgust may provide clear evidence of abnormal activities of these brain regions in individuals with ASD. 

Third, our study did not record eye movements during participants’ observations of dynamic and static facial expressions, although a previous neuroimaging study suggested that an abnormal fixation pattern on faces reduced FG activation in individuals with ASD [ ]. This issue may be relevant because we presented stimuli for 1500 ms to depict dynamic aspects of facial expressions, which is long enough for the participants to make eye movements. To reduce the effect of eye movements, we instructed participants to fixate on a point between the eyes (the center of the screen). Some previous studies [ , ] using the same instruction reported that the FG of individuals with ASD showed normal activation in response to faces. Accordingly, our fMRI results (Figure  ) demonstrated that FG activities in response to static facial expressions were comparable across the ASD and control groups. These data may rule out the possibility that the abnormal fixation pattern on faces would account for the lower levels of brain activation in individuals with ASD. However, such speculation should be verified in future studies recording eye movements during the processing of dynamic facial expressions. 

Fourth, our functional coupling analyses were restricted to a part of the social brain network because DCM was designed to test specific hypotheses rather than to act as an exploratory technique [ , ]. Currently, knowledge about the anatomical and functional connections among all social brain regions remains lacking. It is plausible that the MNS is a sub-component in a more widespread network. For example, the AMY may directly modulate the activities of the MTG and IFG or may exert a bilinear modulatory effect on the connection between these regions. Further studies regarding anatomical and functional connectivity are necessary to elucidate the social brain network and related impairments in ASD. 



## Conclusions 
  
In summary, our results showed that activation of several brain regions (i.e., MTG, FG, AMY, MPFC, and IFG) in response to dynamic versus static expressions was weaker in the ASD than in the control group. The results also revealed that the modulatory effects of dynamic facial expressions on bi-directional effective connectivity in the V1–MTG–IFG circuit were weaker in the ASD than in the control group. These data suggest that weak activity and connectivity of the social brain network for processing dynamic facial expressions underlie the impairments demonstrated by individuals with ASD in real-life social interaction. 


## Methods 
  
### Participants 
  
The ASD group comprised 12 adults (1 female, 11 males; age,   M   = 27.5,   SD   = 7.6). Although an additional male candidate actually participated, his data were not analyzed due to large motion artifacts (>3 mm). The group consisted of eight males with Asperger’s disorder and four (1 female, 3 males) with pervasive developmental disorder not otherwise specified (PDD-NOS). As defined in the Diagnostic and Statistical Manual-Fourth Edition-Text Revision (DSM-IV-TR)[ ], PDD-NOS includes heterogeneous subtypes of ASD, ranging from so-called atypical autism to a subgroup with symptoms milder than Asperger’s disorder (i.e., satisfying fewer diagnostic criteria than required for a diagnosis of Asperger’s disorder). In this study, only high-functioning PDD-NOS participants with milder symptoms than those associated with Asperger’s disorder were included. Neurological and psychiatric problems other than those associated with ASD were ruled out. Participants were not taking medication. Therefore, all participants in the ASD group had only the core deficits of ASD (i.e., social impairments and repetitive traits). 

The diagnosis was made using DSM-IV-TR by a stringent procedure in which every item of the ASD diagnostic criteria was investigated in interviews with the participants and their parents (and professionals who helped them, if any) by two psychiatrists with expertise in developmental disorders. Only participants who met at least one of the four social impairment items (i.e., impairment in nonverbal communication including lack of joint attention, sharing interest, relationship with peers, and emotional and interpersonal mutuality) without satisfying any items of the criteria of autistic disorder, such as language delay, were included. Comprehensive interviews were administered in order to obtain information about the participants’ developmental histories for diagnostic purposes. 

For 10 individuals among the ASD group, the level of symptom severity was quantitatively assessed using the Japanese version of Childhood Autism Rating Scale (CARS) [ ] administered by a psychiatrist with expertise in developmental disorders. The CARS is one of the most widely used scales to evaluate the degree of ASD [ ]. The CARS scores in the ASD group (  M   = 21.1,   SD   = 1.7) were comparable to those in previous studies with individuals with Asperger’s disorder [ ] and individuals with Asperger’s disorder and Asperger type PDD-NOS [ ] (  t  -test,   p   > .1). These data support that the symptoms were severe enough in the ASD group. 

Full-scale intelligence quotients (IQs), measured by the Wechsler Adult Intelligence Scale-Revised (WAIS-R), of all participants in the ASD group fell within the normal range (full-scale IQ:   M   = 113.1,   SD   = 12.5; verbal IQ:   M   = 117.3,   SD   = 10.8; performance IQ:   M   = 106.3,   SD   = 14.9). 

The control group comprised 13 adults (1 female, 12 males; age,   M   = 24.3,   SD   = 3.4). They had no neurological or psychiatric problems. They were recruited through advertisements and were matched with the ASD group for age and sex. The full-scale IQs, measured by the WAIS-R, of all control participants also fell within the normal range (full-scale IQ:   M   = 126.3,   SD   = 6.1; verbal IQ:   M   = 128.1,   SD   = 7.2; performance IQ:   M   = 118.8,   SD   = 11.2). 

All participants had normal or corrected-to-normal visual acuity. All subjects were right handed, as assessed by the Edinburgh Handedness Inventory [ ]. Each participant provided informed consent to participate in the study, which was conducted in accordance with institutional ethical provisions and the Declaration of Helsinki. 


### Experimental design 
  
The experiment involved a three-way repeated-measures factorial design, with group (ASD, control) as a between-participant factor and presentation condition (dynamic, static) and emotion (fear, happiness) as within-participant factors. 


### Stimuli 
  
The stimuli were almost identical to those used in a previous fMRI study [ ]. The raw materials were grayscale photographs of faces of eight individuals (4 females, 4 males) chosen from a standard set [ ] depicting fearful, happy, and neutral expressions. Neutral expressions were adopted as the starting point of the emotional expressions. None of these faces was familiar to any of the participants. 

Dynamic expressions were created from photos via computer animation. First, 24 images that increased emotional expression by increments of 4% were created between the neutral (0%) and emotional (100%) expressions using computer-morphing software [ ] implemented on a computer operating with Linux. This software was used in several other studies (e.g., [ , ]). Next, to create a moving video clip, a total of 26 images (i.e., one neutral image, 24 intermediate images, and the image of the final emotion) were presented in succession. Each image was presented for 40 ms, and the first and last images were presented for 230 additional ms; thus, each clip lasted for 1500 ms. 

The final expressions under the dynamic expression condition were presented as static expressions for 1500 ms. 


### Presentation apparatus 
  
The events were controlled by Presentation version 10.0 (Neurobehavioral System) implemented on a Windows computer. The stimuli were projected from a liquid crystal projector (DLA-G150CL, Victor) onto a mirror that was positioned on a scanner in front of the participants. Under these visual conditions, the stimuli subtended a visual angle of about 15.0° vertical × 10.0° horizontal. 


### Procedure 
  
The scan session consisted of 12, 20-sec epochs interleaved with 12, 20-sec rest periods in which a blank screen was presented. Each epoch consisted of eight trials, and a total of 96 trials were performed in the scan. Each of the four stimulus conditions (dynamic fear, dynamic happiness, static fear, and static happiness) was presented in different epochs. The order of the epochs was pseudorandomized, and the order of trials within each epoch was randomized. 

In each trial, a single individual stimulus was presented for 1500 ms. There was an interval of 1000 ms before the next trial began, during which a fixation point (a picture with a small gray “+” of the same size as the stimulus) was presented on a white background at the center of the screen. The participants were instructed to direct their attention to the center of the screen until the face had disappeared and to specify the sex of the face presented by pressing one of two buttons with the forefinger after the face had disappeared. This task ensured participants’ attention to the stimulus and also prevented idiosyncratic explicit processing for the emotional expression.   Post hoc   debriefing confirmed that the participants were not aware that the purpose of the experiment was unrelated to sex discrimination. 


### MRI acquisition 
  
Image scanning was performed on a 3-T scanning system at the ATR Brain Activity Imaging Center (MAGNETOM Trio A, Tim System, Siemens) using a 12-channel array coil without acceleration mode. The functional images consisted of 40 consecutive slices parallel to the anterior–posterior commissure plane covering the whole brain. A T2*-weighted gradient-echo echo planar imaging sequence was used with the following parameters: repetition time (TR) = 2500 ms; echo time (TE) = 30 ms; flip angle (FA) = 90°; field of view (FOV) = 192 × 192 mm; matrix size = 64 × 64; voxel size = 3 × 3 × 4 mm. The order of slices was ascending. After the acquisition of functional images, a T1-weighted high-resolution anatomical image was also obtained using a magnetization-prepared rapid gradient-echo sequence (TR = 2250 ms; TE = 3.06 ms; FA = 9°; inversion time = 900 ms; FOV = 256 × 256 mm; matrix size = 256 × 256; voxel size = 1 × 1 × 1 mm). Elastic pads placed around each side of the participant’s head were used to stabilize head position during functional image acquisition. 


### Behavioral data analysis 
  
The percentage and RTs of correct responses were analyzed using three-way repeated-measures ANOVAs with group as a between-participant factor and presentation condition and emotion as within-participant factors. We had no specific predictions for the behavioral data, and hence conducted two-tailed tests. Results were considered statistically significant at   p   < .05. 


### Image analysis: Preprocessing 
  
Image preprocessing and regional brain activity analyses were performed using SPM5 (  http://www.fil.ion.ucl.ac.uk/spm  ) implemented in MATLAB version 7 (Mathworks). First, we performed slice-timing correction to correct for the different times needed to acquire slices in functional images. This process was also important to the robustness of the DCM. To correct for head movements, the functional images of each run were then realigned using the first scan as a reference. Data from all participants showed small motion corrections (<2 mm). Subsequently, the T1 anatomical image was co registered to the first scan of the functional images. Next, the co registered T1 anatomical image was normalized to a standard T1 template image as defined by the Montreal Neurological Institute (MNI), which involved linear and non-linear three-dimensional transformations [ , ]. The parameters from this normalization process were then applied to each of the functional images. Finally, these spatially normalized functional images were resample to a voxel size of 2 × 2 × 2 and smoothed with an isotopic Gaussian kernel (8 mm) to improve the signal-to-noise ratio and to compensate for the anatomical variability among participants. 


### Image analysis: Regional brain activity analysis 
  
We used random-effects analyses to identify significantly activated voxels at the population level [ ]. First, we performed a single-subject analysis [ , ]. The task-related blood-oxygen-level-dependent (BOLD) responses under each condition were modeled with a boxcar function and convoluted with a canonical hemodynamic response function. We used a high-pass filter composed of a discrete cosine basis function with a cut-off period of 128 sec to eliminate the artifactual low-frequency trend. Serial autocorrelation, assuming a first-order autoregressive model, was estimated from the pooled active voxels with a restricted maximum likelihood (ReML) procedure and was used to whiten the data and the design matrix [ ]. To reduce the motion-related artifacts, the six realignment parameters of the rigid-body transformation used in the realignment step in the preprocessing were added to the model. 

Planned contrast was then performed. The four contrast images of dynamic fear, dynamic happiness, static fear, and static happiness versus rest were entered into the flexible factorial model for each participant and each group, generating a three-way repeated-measures ANOVA to create a random-effect SPM{  T  }. The model included group, presentation condition, and emotion as factors of interest; participant was a factor of no interest (Additional file  : Figure S1). Based on preliminary analyses, the sex of participants, which showed no significant main effect or interaction in the results, was disregarded in the reported analyses. The non-sphericity correction used in the flexible factorial model corrected for possible differences in variance between the groups due to the unequal sizes of the samples. The same settings were used under the presentation and emotion conditions to correct for uneven variance between levels. The observations that were dependent on presentation and emotion conditions were also corrected. The ensuing covariance components were estimated using ReML and then used to adjust the statistics. This is exactly the same procedure used for serial correlations in single-subject fMRI models. We conducted preliminary analyses to test brain activation under each condition in each group against the resting condition using the same threshold criterion with reported results and found that none of the predicted social brain regions showed significant deactivation. Hence, we did not use any masking procedures. 

First, the simple main effect of dynamic versus static presentations was tested for each group. For these analyses, active regions were reported as statistically significant only if they survived the correction for multiple comparisons across the entire brain. Next, our prediction of the interaction between group and presentation condition was tested. For this analysis, about which we had specific predictions, we selected regions of interest (ROIs): the MTG, FG, AMY, MPFC, and IFG. The ROIs were defined as 8-mm-radius spheres centered on the activation foci in the above simple main effect analysis for the control group (cf. [ ]). Anatomical specification of the ROIs was conducted using the Talairach Daemon [ ] after the transformation of coordinates from the MNI to Talairach systems. All ROIs were confirmed to overlap with the activation foci in previous studies (e.g., [ ]). These ROIs were independently examined in an   a priori   manner (cf. [ , ]) by applying small-volume correction [ ]. Analyses for this interaction in other brain regions and for other interactions related to the factor of group were conducted in an   a posteriori   manner correcting for the volume of the entire brain. Significantly activated voxels were identified if they reached the extent threshold of   p   < .05 corrected for multiple comparisons, with a height threshold of   p   < .01 (uncorrected). In this setting, the minimum cluster size for the significant extent threshold with the small-volume correction was 58 voxels. 

To display the activation patterns across conditions, the parameter estimate under each experimental condition (the   beta   value in the SPM) at the peak voxel of the random-effect analysis was extracted and then averaged across participants. 


### Image analysis: DCM 
  
We used DCM [ ] to explore how the effective connectivity between brain regions was modulated by dynamic facial expressions. DCM enabled us to draw inferences about the influences that one neural system exerted over another and about how this was affected by the experimental context. Technically, DCM is described as an input–state–output model with multiple inputs and outputs, where inputs are represented by experimental factors determined by the experimental paradigm and outputs are the BOLD signals of all regions. The system dynamics of the interacting brain regions are described by changes in the neural state over time. The modeled neural dynamics are transformed into area-specific BOLD signals by a hemodynamic state model. DCM estimates neural and hemodynamic state parameters with a Bayesian inversion scheme [ ]. DCM allowed us to estimate three different types of interactions: (1) intrinsic connections, which represent fixed or baseline connectivity among neural states; (2) modulations of these connections by experimental manipulations; and (3) driving input, which embodies the influences of exogenous input on neural states. In this study, we focused on the modulatory effect of dynamic presentation on the cortical network for facial expression processing. 

DCM was performed using SPM8 (  http://www.fil.ion.ucl.ac.uk/spm  ) implemented in MATLAB version 7 (Mathworks). To construct driving and modulatory inputs in our DCM analysis, we remodeled single-subject analyses. The design matrix contained the following three experimental factor-specific regressors: visual input (i.e., all experimental conditions) as the driving input in the DCM; dynamic presentation as the modulatory input; and emotion (fear vs. happiness, which were coded as 1 and -1, respectively). Emotion regressors were included as effects of no interest. Other nuisance regressors (realignment parameters and constant terms), high-pass filters, and serial autocorrelations were at the same settings as for regional brain activity analyses. 

To define the cortico–cortical connectivity, we selected three brain regions: the V1 (  x   22,   y   -84,   z   -4), MTG (  x   52,   y   -62,   z   0), and IFG (  x   56,   y   28,   z   10) in the right hemisphere. These ROIs were selected based on our hypothesis described in the Background. The coordinates of the MTG and IFG were defined based on the results of the simple main effect of presentation condition (dynamic vs. static) in the control group. The coordinates of the V1 were derived from the strongest activation focus in the search region of the V1 in response to all stimulus presentations in the control group; this value was defined by the cytoarchitectonic map derived from data on human postmortem brains using the Anatomy Toolbox version 1.5 [ ]. The identical activation focus was found in the ASD group using the same procedure to define the V1. The ROIs were restricted to the right hemisphere because some ROIs showed significant activities only in the right hemisphere. ROI time series were extracted for each participant as the first eigenvariate of all voxels within a 3-mm radius around the selected coordinate. These time series were adjusted for the effect of interest and the nuisance effects, high-pass filtered, and corrected for serial correlation. 

Next, the hypothesized model was constructed for each participant. The visual input was modeled as the driving input into the V1. The bi-directional (forward and backward) intrinsic connections were constructed between the V1 and MTG and between the MTG and IFG. The modulatory effect of dynamic presentation was modeled to modulate each of these bi-directional connections. Based on the locations of the modulatory effects, we constructed following four models (Figure  b): the null model, MNS-entrance modulation model, MNS-core modulation model, and full model. 

To examine group differences in effective connectivity, we first tested the most appropriate model for each group using random-effect BMS [ ]. We used the exceedance probabilities as the evaluation measures based on the belief that a particular model was more likely than any other model given the group data (cf. [ , ]). We next analyzed parameter estimates of the averaged model resulting from BMA. We used the entire model space and computed weighted averages of each model parameter for which the weighting was given by the posterior probability for each model [ , ]. This approach is preferable in a group DCM study in which BMS may indicate a group difference in the model space. To expedite BMA calculation, the low-probability models were excluded from the summation using an Occam's window approach. In this study, Occam’s window was defined using a minimal posterior odds ratio of 1/20 [ ]. The modulatory effect parameters were tested with   a priori   interests (cf. [ ]) in terms with differences from zero and differences between groups using   t  -tests (one-tailed). The results were deemed statistically significant at   p   < .05. 



## Competing interests 
  
The authors declare that they have no competing interests. 


## Author contributions 
  
WS, MT, SU and TK designed research; WS, MT, SU and TK obtained the data; WS and TK analyzed the data; and WS, MT, SU and TK wrote the manuscript. All authors read and approved the final manuscript. 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-47'>
<h2>47. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/30085122/' target='_blank'>30085122</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Oxytocin Facilitates Approach Behavior to Positive Social Stimuli via Decreasing Anterior Insula Activity</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Int J Neuropsychopharmacol</p>
<p><strong>Publication Year:</strong> 2018</p>
<p><strong>DOI:</strong> 10.1093/ijnp/pyy068</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6165955/' target='_blank'>6165955</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study reports a functional MRI experiment in healthy adult participants (male students, mean age 21.4) performing an approach–avoidance task using social and nonsocial emotional scenes, which is a social-related task relevant to the review constructs. It clearly includes at least one healthy participant group (results reported separately). Although ROI analyses are emphasized, the Methods and Results state additional exploratory whole-brain analyses were conducted (threshold P<.05 corrected at peak level), satisfying the requirement that whole-brain results are reported. No exclusion criteria are met (not limited to clinical populations; not ROI-only). Therefore the study meets all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
## Background 
  
The neuropeptide oxytocin can extensively modulate human social behavior and affective processing, and its effects can be interpreted in terms of mediating approach-avoidance motivational processes. However, little is known about how oxytocin mediates approach-avoidance behavior and particularly the underlying neural mechanisms. 


## Methods 
  
In a randomized, double-blind, between-subject design, the present pharmaco-fMRI study used an approach-avoidance paradigm to investigate oxytocin’s effects on approach-avoidance behavior and associated neural mechanisms. 


## Results 
  
Results revealed that oxytocin generally decreased activity in the right striatum irrespective of response (approach/avoidance) and social context, suggesting an inhibitory effect on motivational representation during both appetitive approach and aversive avoidance. Importantly, while on the behavioral level oxytocin selectively enhanced accuracy when approaching social positive stimuli, on the neural level it decreased left ventral and right dorsal anterior insula activity in response to social vs nonsocial positive stimuli compared with the placebo treatment. The left ventral anterior insula activity was negatively correlated with the corresponding accuracy difference scores in the oxytocin but not in the placebo group. 


## Conclusion 
  
Given the role of the ventral anterior insula in emotional processing and the dorsal anterior insula in salience processing, the oxytocin-induced suppression of activity in these regions may indicate that oxytocin is acting to reduce interference from hyper-activity in core regions of the emotional and salience networks when approaching salient positive social stimuli and thereby to promote social interaction. Thus, oxytocin may be of potential therapeutic benefit for psychiatric disorders exhibiting avoidance of social stimuli. 

 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (26657 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'>  
## Significance Statement 
  
The hypothalamic neuropeptide oxytocin (OT) plays an important role in modulating human social behavior. These effects can be interpreted in terms of OT’s actions on basal approach-avoidance (AA) motivational processes, as proposed by the general AA hypothesis of OT (GAAO). However, few studies have evaluated the proposed OT effects on AA behavior and particularly the underlying neural mechanisms. Using neuroimaging combined with intranasal OT administration, the present study revealed that while OT selectively enhanced behavioral accuracy when approaching social positive stimuli, it decreased left ventral and right dorsal anterior insula (AI) activity in response to social vs nonsocial positive stimuli compared to the PLC treatment, with the left ventral AI activity being negatively correlated with the corresponding behavioral accuracy only in the OT group. These findings provide the first confirmatory evidence for the GAAO by demonstrating that OT facilitates human approach behavior to social positive stimuli via inhibiting AI activity. 

 
## Introduction 
  
Across species, the hypothalamic neuropeptide oxytocin (OT) regulates social behavior, particularly bonding and maternal care ( ;  ). During the last 2 decades, the number of studies examining oxytocinergic regulation of human behavior via intranasal administration of OT has steadily increased. While OT can facilitate appetitive approach behaviors, such as interpersonal trust and generosity ( ;  ), pair bonding and maternal behavior ( ;  ) and emotional empathy and face recognition ( ;  ), it can also promote aversive avoidance behavior by increasing envy and schadenfreude ( ), ethnocentrism (e.g., trust and empathy;  ;  ), group-serving dishonesty ( ), and noncooperation ( ;  ). 

To account for these complex and somewhat contradictory findings,   proposed in their general approach-avoidance (AA) hypothesis of OT (GAAO) that the broad effects of OT on human behavior are mediated by its actions on basal AA motivational processes. More specifically, within this extended overarching framework, OT’s complex behavioral effects are considered to be rooted in its modulation of the salience of personally relevant and emotionally evocative stimuli not necessarily restricted to social contexts ( ; cf.   for the social-approach/withdrawal hypothesis and   for the social salience hypothesis). However, surprisingly few studies have experimentally evaluated the proposed effects of OT on AA behavior and particularly the underlying neural mechanisms. 

In a previous study that examined the effects of intranasal OT on human AA behavior, OT was found to accelerate both approach and avoidance behavior towards emotionally negative stimuli such as disgusted faces ( ;  ). Using similar paradigms, OT also facilitated approach towards angry faces with a direct gaze ( ). Furthermore, in the context of pair bonding, OT was found to modulate interpersonal space by decreasing the preferred distance men in a romantic relationship kept between themselves and an unknown attractive woman ( ). However, these studies predominantly used emotional faces to investigate OT’s actions on AA behavior and were thus unable to determine whether observed effects were driven by its well-established actions on increased attention and attraction to faces per se ( ;  ;  ;  ;  ). Moreover, the neural substrates mediating OT’s effects on AA behavior also remain unclear, with initial evidence showing decreased amygdala activity only when approaching angry faces ( ). Since this latter study also used facial stimuli, this again precludes any definitive conclusion as to whether findings simply reflect the well-documented anxiolytic effect of OT in decreasing amygdala responses to threatening facial expressions ( ;  ) rather than specific effects on AA behavior. 

The present study has therefore employed a face-independent AA task combined with fMRI to investigate OT’s specific effects on AA behavior and the underlying neural mechanisms involved. Thus, social and nonsocial scenes rather than facial experimental stimuli were used to determine specific effects of OT on AA behavior per se to avoid its potential confounding effects on face processing. Participants were instructed to approach positive (appetitive approach) and avoid negative (aversive avoidance) stimuli during the AA task. In accordance with the GAAO that OT modulates salience of cues that are personally relevant and emotionally evocative but not necessarily specific to social contexts ( ), we hypothesized that OT would (1) facilitate approach behavior to positive stimuli, particularly more emotionally evocative social ones, and associated activity in the motivational and emotional salience core regions such as the striatum and anterior insula, and (2) decrease avoidance behavior via attenuating amygdala reactivity to negative stimuli, particularly more emotionally evocative negative social ones. 


## Methods And Materials 
  
### Participants and Treatment 
  
A total of 83 healthy male students (mean age=21.35 years, SD=2.48) participated in a randomized, double-blind, between-subject experiment and were randomly assigned to receive either intranasal OT (40 IU; Oxytocin Spray, Sichuan Meike Pharmacy Co. Ltd, China) or placebo (PLC; same ingredients other than OT, i.e., sodium chloride and glycerin). To control for potential confounding effects from personality traits or mood states, subjects completed Chinese versions of validated psychometric questionnaires before treatment, including the Positive and Negative Affect Schedule ( ), Autism Spectrum Quotient ( ), Empathy Quotient ( ), and NEO 5-factor inventory ( ). To further control for a potentially confounding influence of altered mood states, subjects were asked to complete the Positive and Negative Affect Schedule 3 times: after they first arrived (pretreatment), before MRI scanning (posttreatment), and finally after scanning (post-scan). Subjects received OT/PLC treatment in accordance with a standardized protocol ( ), and fMRI acquisition started 45 minutes after treatment. A total of 7 subjects were excluded due to technical issues during data acquisition (4 subjects) or excessive head movement (3 subjects). Thus, 39 subjects in the OT group and 37 subjects in the PLC group were included in the final analysis. In postscan interviews, subjects were unable to identify better than chance whether they had received OT or PLC (χ =0.21,   P  =.646). Written informed consent was obtained from all subjects before study inclusion. All procedures were in accordance with the latest version of the Declaration of Helsinki and approved by the ethical committee of University of Electronic Science and Technology of China. 


### The AA Task 
  
In a revised AA task ( ), participants were instructed to make approach responses to positive social or nonsocial stimuli (e.g., happy friends meeting or beautiful landscapes) and avoidance responses to social or nonsocial negative stimuli (e.g., victims or environmental pollution). In a prestudy, we selected 620 pictures mostly from the International Affective Picture System ( ) and additionally from the Internet that were rated in terms of valence and arousal (9-point Likert scale) by an independent sample of 34 healthy volunteers (18 males). Based on this data, a total of 112 stimuli (28 pictures per category, positive vs negative and social vs nonsocial) were selected: social positive (valence: mean±SD=2.36±0.27; arousal: 6.27±0.35), social negative (valence: 2.47±0.26; arousal: 6.65±0.46), nonsocial positive (valence: 1.68±0.39; arousal: 6.25±0.42), and nonsocial negative (valence: 1.87±0.55; arousal: 6.10±0.70). Note that the valence rating scores were transformed to the distance from the neutral midpoint of the 9-point scale. Each picture was presented for 3 seconds at a 624- × 468-pixel resolution followed by a jittered inter-stimulus interval of 2 to 6 seconds. Subjects were instructed to pull the positive stimuli towards their body by pressing the “down” key and push the negative stimuli away from their body by pressing the “up” key successively via a response pad during the 3-second presentation. To realistically convey approach and avoidance of the stimuli for the subjects, each pulling-associated button press would enlarge the picture by 100×75 pixels while each pushing response would decrease the size of the picture by 100×75 pixels. All subjects preformed 10 practice trials before entering the scanner and were instructed to respond as fast and accurately as possible during the experiment. 


### Image Acquisition and Data Analysis 
  
Images were collected using a 3 Tesla, GE Discovery MR750 system (General Electric Medical System, Milwaukee, WI). During each fMRI scan, a time series of volumes was acquired using a T2*-weighted echo-planar pulse sequence (repetition time: 2000 ms; echo time: 30 ms; number of slices: 39; slice thickness: 4 mm; gap: 1 mm; field of view: 240×240 mm; resolution: 64×64; flip angle: 90°). To control for any anatomic abnormalities and increase normalization accuracy during preprocessing, additional T1-weighted images were acquired obliquely with a 3-dimensional spoiled gradient echo pulse sequence (repetition time: 6 milliseconds; echo time: 2 milliseconds; flip angle: 9°; field of view: 256×256 mm; acquisition matrix: 256×256; number of slices: 156; slice thickness: 1 mm). 

Images were processed using SPM8 (Wellcome Department of Cognitive Neurology, London;   https://www.fil.ion.ucl.ac.uk/spm/software/spm8/  ) ( ). The first 5 functional images were deleted to achieve magnet-steady images, and the remaining images were realigned to correct for head movement based on a 6-parameter rigid body algorithm. After co-registering the mean functional image and the T1 image, the T1 image was segmented to determine the parameters for normalizing the functional images to Montreal Neurological Institute (MNI) space. These normalized images were finally spatially smoothed using a Gaussian kernel (8 mm full-width at half maximum). 

The first-level design matrix included 4 condition-specific regressors (social positive/negative, nonsocial positive/negative) convolved with the canonical hemodynamic response function and the 6 head-motion parameters as nuisance regressors. Contrast images for each stimulus condition, all positive and all negative were created separately. On the second level, group differences were analyzed using 2-sample   t   tests. Interactions were tested using an ANOVA model implemented in a flexible factorial design. Based on our region-specific hypotheses, the analysis focused on core regions involved in salience processing ( ;  ) and appetitive/approach (social/nonsocial reward) and withdrawal/avoidance (punishment/threat) motivational processes ( ;  ,  ;  ;  ;  ), that is, the amygdala, the AI, and the striatum. Importantly, these regions strongly overlap with the network mediating the social cognitive and affective effects of intranasal OT ( ;  ;  ;  ;  ). Regions-of-interest (ROIs) were anatomically defined using the Automated Anatomic Labeling atlas ( ). Within the unilateral a priori ROIs, a threshold of   P  <.05 family-wise error (FWE) peak-level correction was set for multiple comparisons using small volume correction (SVC). Parameter estimates used for plotting and brain behavior associations analysis were extracted for each subject from a 6-mm sphere centered on the peak voxel within corresponding ROIs. For additional exploratory whole-brain analyses, a threshold of   P  <.05 corrected at peak level was used and only clusters >10 voxels are reported. 



## Results 
  
### Questionnaires 
  
Two-sample   t   tests on questionnaires measuring mood, autistic traits, empathy, and personality traits revealed no significant differences between the treatment groups (Ps>.136;  ). 


### Behavioral Results 
  
For response times, a repeated-measures ANOVA was performed with social context (social vs nonsocial) and response type (approach vs avoidance) as within-subject factors and treatment (OT vs PLC) as between-subject factor. This revealed a significant main effect of response type (F(1, 74)=250.46,   P  <.001), with subjects being significantly faster to approach positive than to avoid negative stimuli (1617.33±176.84 vs 1776.95±184.28). The interaction between social context and response was also significant (F(1, 74)=19.04,   P  <.001), with posthoc tests reavealing that subjects were faster to approach social compared with nonsocial positive stimuli (1600.86±172.73 vs 1633.79±180.49) but slower to avoid social than nonsocial negative stimuli (1784.72±181.76 vs 1769.18±187.65). There were no other significant effects (  P  >.106). 

In terms of response accuracy (RA), there was a significant main effect of social context (F(1, 74)=15.75,   P  <.001), with a higher accuracy for social compared with nonsocial stimuli (95.4%±5.7% vs 93.7%±5.4%). The main effect of response type was also significant (F(1, 74)=109.59,   P  <.001), with a higher accuracy for approaching positive than avoiding negative stimuli (97.5%±3.4% vs 91.7%±5.8%). While the interaction between social context, response type, and treatment was not significant (F(1, 74)=0.76,   P  =.385), an exploratory pairwise comparison revealed a significantly higher RA only for social (  P  =.031) but not nonsocial positive stimuli (  P  =.568) in the OT relative to the PLC group ( ). The interaction between social context and response type was marginally significant (F(1, 74)=3.18,   P  =.079), suggesting a trend of higher accuracy to social vs nonsocial stimuli for positive (  P  <.001; 98.8%±2.1% vs 96.2%±4.0%) but not negative stimuli (  P  =.280; 92.1%±6.1% vs 91.3%±5.6%). There were no other significant effects (  P  >.361). Given the slightly higher valence scores for social compared with nonsocial positive stimuli, to clarify whether the valence difference would confound the significant OT’s effects, we further conducted a correlation analysis between valence scores for individual pictures by independent raters and RA for social and nonsocial positive stimuli in the experimental subjects and found no significant associations either for social (Pearson r=0.061, df=28,   P  =.759) or nonsocial positive stimuli (Pearson r=- 0.044, df=28,   P  =.823). Thus, the magnitude of the positive valence score for the individual pictures did not influence response accuracy. 
  
Response accuracy in response to each condition in the oxytocin and placebo groups. Error bars show standard errors. 
  

### fMRI Results 
  
We first examined unspecific effects of treatment (OT vs PLC) independent of response type and social context using a 2-sample   t   test. This revealed decreased right striatum activity (MNI=22, 2, 8, t=4.05,   P  =.025 SVC, voxels=48;  ) in the OT compared with the PLC group (OT  <PLC  ). 
  
(A) Decreased right striatum activity in the oxytocin (OT) compared with the placebo (PLC) group. (B) Decreased activity in the right striatum and the left dorsal anterior insula (AI) in the OT compared with the PLC group during appetitive approach. (C) Decreased activity in the right striatum and the right amygdala in the OT compared with the PLC group during aversive avoidance. Statistic maps were displayed with a   P  <.005 uncorrected threshold. Error bars show standard errors. 
  
Next, we examined treatment effects and interactions between treatment and social context on appetitive approach and aversive avoidance separately. For appetitive approach, decreased activity in the right striatum (MNI=20, 2, 6, t=3.96,   P  =.031 SVC, voxels=29) and the left dorsal AI (MNI=-38, 12, 6, t=3.52,   P  =.040 SVC, voxels=11;  ) was found in the OT compared with the PLC group (OT  <PLC  ). Examining the interaction between treatment and social context (OT  <PLC  ) during approach behavior revealed significant interaction effects in the left ventral AI (MNI=-42, 6, -6, t=3.57,   P  =.022 SVC, voxels=14;  ) and the right dorsal AI (MNI=48, 12, 2, t=3.40,   P  =.036 SVC, voxels=7;  ), suggesting that OT decreased activity in these regions during approach of social relative to nonsocial positive stimuli. 
  
Oxytocin (OT) decreased the left ventral anterior insula (AI) (A) and the right dorsal AI (B) activity in response to social relative to nonsocial positive stimuli (OT  <placebo [PLC]  ). Statistic maps were displayed with a   P  <.005 uncorrected threshold. Error bars show standard errors. 
  
With respect to aversive avoidance, OT decreased activity in the right striatum (MNI=24, 2, 10, t=4.31,   P  =.011 SVC, voxels=58) and the right amygdala (MNI=28, -4, -18, t=3.34,   P  =.025 SVC, voxels=2;  ) irrespective of social context (OT  <PLC  ). Examination of interaction effects between treatment and social context during avoidance behavior (OT  <PLC  ) revealed no significant effects (  P  <.05 SVC). There were also no other significant effects in the a priori ROIs (  P  <.05 SVC). For completeness, additional effects beyond the a priori ROIs on the whole-brain level are reported in   (  P  <.05). 


### Brain Behavior Associations 
  
Correlation analyses between extracted parameter estimates from the left ventral and the right dorsal AI (social positive>nonsocial positive) and RA difference scores (social positive − nonsocial positive) were conducted separately to explore associations between OT-induced modulation on neural responses and corresponding behavioral indices. Results showed a significant negative correlation between activity in the left ventral AI (MNI=-42, 6, -6) and RA difference scores in the OT (Pearson r=- 0.346, df=39,   P  =.031;  ) but not in the PLC group (Pearson r=0.039, df=37;   P  =.818). The correlation difference between groups was tested using the Fisher z-transformation test and revealed a marginally significant difference between the OT and PLC groups (Fishers z-score=-1.672,   P  =.094). 



## Discussion 
  
The present study investigated OT’s effects on AA behavior and corresponding neural mechanisms using emotional scenes and specifically examined whether the effects generalize across social and nonsocial contexts. On the neural level, a significant main effect of treatment was observed in the right striatum, with OT generally decreasing activity in this region irrespective of response type and social context. Furthermore, separate examination of appetitive approach and aversive avoidance revealed that while OT specifically decreased the left dorsal AI activity during approaching positive stimuli, it decreased right amygdala activity during avoidance of negative stimuli. Additionally, exploring the role of social context revealed evidence for a selective enhancement effect of OT on RA when approaching social relative to nonsocial positive stimuli. This behavioral effect was accompanied by decreased left ventral and right dorsal AI activity in response to social vs nonsocial positive stimuli in the OT compared with the PLC group, with the relative difference in left ventral AI activity and RA for social vs nonsocial positive stimuli exhibiting a negative association following OT. By contrast, during aversive avoidance, no evidence for the social specificity of OT was observed. These findings provide support for the GAAO by showing that OT modulates activation of motivational and emotional salience core regions during both approach to positive and avoidance to negative stimuli across social and nonsocial contexts and that OT specifically facilitates approach behavior to more personally relevant and emotionally evocative stimuli, namely positive social stimuli, via inhibiting AI activity. 

Examination of unspecific OT effects on AA behavior revealed significantly decreased activity in the right striatum following OT across both response type and social contexts. The striatum has been strongly involved in both approach (social/nonsocial reward) and avoidance (punishment/threat)-motivated behavior ( ;  ,  ;  ;  ). Thus, OT may inhibit motivational representation both during appetitive approach and aversive avoidance. Furthermore, OT additionally decreased left dorsal AI activity during approach to positive stimuli across social and nonsocial contexts. As a core hub of the salience network ( ;  ), the reduced dorsal AI activity may thus reflect an OT-evoked decrease in the salience of positive stimuli when subjects approached them. 

The observed inhibitory effects of OT on striatum and AI activity seem to conflict with both the proposal that it enhances the salience of social cues ( ) and some previous findings that OT-induced alterations on human social behavior are associated with increased activity in the striatum and AI ( ;  ;  ;  ). Given that OT effects on social behavior are often highly context and person dependent ( ), this inconsistency could be due to different paradigms and contexts used in these previous studies. In previous studies, subjects were asked to passively process certain stimuli, whereas the present study using an AA task required subjects to actively approach or avoid them. 

It is notable that OT also decreased activation of the left ventral and right dorsal AI during approaching social relative to nonsocial positive stimuli. Given the role of the ventral AI in emotional processing ( ;  ;  ) and the dorsal AI in salience processing ( ;  ), these attenuated AI activities may indicate a more robust inhibitory effect of OT on decreasing both the emotional and salience processing of social positive stimuli that are more personally relevant and emotionally evocative ( ). Consistent with previous observations that OT can enhance processing of positive facial emotion ( ;  ;  ;  ), the present study found evidence that OT may specifically facilitate RA during approaching social but not nonsocial positive stimuli. Thus, the oxytocinergic downregulation of AI activation may act to attenuate interference caused by hyperactivation of the AI when subjects approach external social positive stimuli, resulting in enhanced accuracy of social information processing and facilitation of social interaction. This assumption is further supported by the presence of a significant negative correlation between the left ventral AI activity and the RA difference between social and nonsocial positive stimuli following OT but not PLC administration. However, it should be noted that the difference in brain-behavior correlation between groups was only marginally significant, and thus inferences regarding this effect of OT need to be drawn with caution. 

Additionally, OT was found to decrease amygdala activity during avoidance responses to negative stimuli independent of social context. This finding is in line with the anxiolytic action of OT via inhibiting amygdala responses to threatening stimuli ( ;  ). Based on the GAAO ( ), the absence of a social-specific effect of OT on avoiding negative stimuli suggests that threatening social and nonsocial stimuli may be comparable in terms of personal relevance and emotional evocation, perhaps due to the high survival relevance of threating events during evolution ( ). 

Given that we found no significant personality and mood difference between OT and PLC groups, this argues against confounding effects of pretreatment between-group differences on the observed effects of OT. However, individual differences in personality traits have been shown to mediate approach and avoidance behavior, as proposed by the (revised) Reinforcement Sensitivity Theory ( ;  ). More specifically, previous studies have demonstrated associations between the functional organization of the salience network, particularly the AI, and its interactions with anxiety-related traits such as harm avoidance ( ;  ,  ). Thus, future studies should consider examining the role of individual differences in personality traits on AA behavior and their potential modulatory effects on the effects of OT in this domain. Moreover, within this context, the present findings may lend support for potential therapeutic benefits of OT for psychiatric disorders such as social anxiety and autism exhibiting altered approach/avoidance towards social stimuli ( ;  ;  ;  ). 

There are several limitations in the present study. Firstly, considering that organisms have primarily evolved mechanisms to approach stimuli associated with positive outcomes and to avoid those associated with aversive ones, we only asked subjects to approach positive and avoid negative stimuli. Effects of OT on approaching negative and avoiding positive stimuli thus remain to be determined. Secondly, we used only male subjects to avoid possible confounding effects from menstrual cycle; thus, the present conclusions are limited to males and sex differences remain to be explored. Thirdly, another potential limitation is that we cannot completely exclude the possibility of a complex interaction involving differences in social and nonsocial stimuli valence and OT effects on response accuracy during approach behavior. However, for positive valence stimuli, we found no association between individual picture valence and response accuracy for either social or nonsocial stimuli, suggesting that valence differences are unlikely to have had a major impact on our results. Finally, we do not know if the effects we observed with a 40-IU dose of OT may also be observed with lower doses. A previous study has revealed a dose-dependent effect of OT (12, 24, and 48 IU), with the 24-IU dose being most effective in inhibiting amygdala activity during negative emotional processing ( ). However, in 2 previous studies from our group, we reported evidence for comparable effects of 24- and 40-IU doses on both behavioral and neural changes in the context of empathy and self-processing in humans ( ;  ). 

In conclusion, the present study provides first evidence for the GAAO by demonstrating that while OT inhibits motivational representations both during appetitive approach and aversive avoidance, it facilitates human approach behavior to more general positive social stimuli via inhibiting AI activity. This inhibitory effect of OT may reduce interference from emotion-facilitated hyperactivation of core regions of the emotional and salience networks when approaching external social salient positive stimuli and consequently be of benefit in promoting social interaction. 


## Supplementary Materials 
  
Supplementary data are available at International Journal of Neuropsychopharmacology (IJNPPY) online. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-48'>
<h2>48. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/29813018/' target='_blank'>29813018</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Cognitive regulation alters social and dietary choice by changing attribute representations in domain-general and domain-specific brain circuits</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> eLife</p>
<p><strong>Publication Year:</strong> 2018</p>
<p><strong>DOI:</strong> 10.7554/eLife.31185</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5973829/' target='_blank'>5973829</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study used functional MRI while participants completed an altruism task probing social decision-making (focus on partner, ethics) and reports neural encoding of social attributes (others’ payoffs, fairness, TPJ, precuneus). Participants were healthy adults (N=55 altruism; subset N=37 also did food task), ages within the 17–65 range. Analyses include whole-brain multivariate searchlight decoding and group-level random-effects tests (FWE cluster correction), not limited to ROI-only results (ROI post-hoc tests are supplemental). Thus it meets: (1) social-related fMRI task addressing perception/understanding of others and social decision-making; (2) healthy adult sample reported separately; (3) whole-brain analyses are reported. No exclusion criteria are met. Therefore the study should be INCLUDED.</p>
<p><strong>Fulltext Confidence:</strong> 0.93</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Are some people generally more successful using cognitive regulation or does it depend on the choice domain? Why? We combined behavioral computational modeling and multivariate decoding of fMRI responses to identify neural loci of regulation-related shifts in value representations across goals and domains (dietary or altruistic choice). Surprisingly, regulatory goals did not alter integrative value representations in the ventromedial prefrontal cortex, which represented all choice-relevant attributes across goals and domains. Instead, the dorsolateral prefrontal cortex (DLPFC) flexibly encoded goal-consistent values and predicted regulatory success for the majority of choice-relevant attributes, using attribute-specific neural codes. We also identified domain-specific exceptions: goal-dependent encoding of prosocial attributes localized to precuneus and temporo-parietal junction (not DLPFC). Our results suggest that cognitive regulation operated by changing specific attribute representations (not integrated values). Evidence of domain-general and domain-specific neural loci reveals important divisions of labor, explaining when and why regulatory success generalizes (or doesn’t) across contexts and domains. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (79776 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Choices often require us to weigh competing considerations. Does a decadent piece of cake merit the pounds we’ll put on afterwards? Should the pleas of a homeless person trump our own selfish needs? Empirical evidence suggests that the answer to these questions depends in part on a decision maker’s goals ( ) and can be affected by intentional control ( ;  ;  ). Cognitive regulation of decision making thus serves an important function in goal-directed behavior ( ), relying on attention, working memory, and executive control to promote particular, goal-congruent choices (e.g., eat healthier, be kinder). Cognitive regulation of decision making is an important technique in therapeutic interventions for problematic behaviors, including obesity ( ), addiction ( ), and other decision making disorders ( ). Previous findings have significantly advanced our understanding of the psychological and neural bases of cognitive regulation of decision making ( ;  ;  ;  ), yet important questions about its computational underpinnings remain. At what level of the processing stream does goal-dependent cognitive regulation change the typical trajectory of choice? Does it operate in the same manner in different contexts, or does it depend on the domain? Answering these questions has important ramifications for understanding when people succeed or fail to implement their regulatory goals during decision making, why some people seem to succeed more often than others, and whether there are neural targets for treatment or biomarkers to identify at-risk individuals. 

In studies of basic choice, weighted additive utility models have been used successfully to capture patterns in human behavior across a variety of domains ( ;  ). In these models, decision makers compute the decision value (DV) of each option as the weighted sum of its choice-relevant attributes   ( ;  ) and compare them to make a choice. Recent neuroscience work provides evidence in favor of this model, observing signals related to the value of specific attributes in distinct cortical and subcortical areas, for both social ( ;  ) and non-social choices ( ;  ). In turn, signals correlated with the overall, integrated decision value of an option have been observed in multiple regions, such as the ventromedial prefrontal cortex (VMPFC) and ventral striatum ( ;  ;  ;  ;  ;  ;  ). A key goal of neuroeconomics is to describe how these attribute and decision value computations change as a function of regulatory goals and contexts, and to link such changes to regulatory success. Here, we sought to address three important questions about this process. 

First, at what level does cognitive regulation operate to change value representations? Based on the neuroeconomic model outlined above, we hypothesized two possibilities. The   attribute-level   hypothesis suggests that cognitive regulation of decision making could alter value representations at a relatively low level, by amplifying or diminishing attribute representations directly in a distributed set of specific, dedicated attribute-coding areas, similar to attentional effects on visual object encoding ( ). Alternatively, the   integration-level   hypothesis suggests that cognitive regulation of decision making might operate at comparatively higher levels in centralized, domain-general value integration areas such as the VMPFC ( ;  ). 

Second, we aimed to explicitly test whether cognitive regulation alters value representations at the   same   level regardless of domain, or whether it differs as a function of attributes, goals or choice domain. For example, some attributes (such as taste) may be innate and prepotent, while other attributes (such as health or social considerations) may be more abstract or effortful to construct ( ;  ;  ). We sought to test whether these distinctions might affect where and how cognitive regulation operates to alter value representations during decision making. We also sought to determine whether this translates into distinct regulatory capacities as a function of regulatory goal or choice domain. 

Finally, we sought to shed light on whether information represented in VMPFC and dorsolateral prefrontal cortex (DLPFC) supports either attribute-level or integration-level changes in value during cognitive regulation of decision making. For example, some experimental evidence supports the idea that the DLPFC might represent more abstract attributes like health ( ;  ), and that regulatory control could modulate interactions between the DLPFC and VMPFC to change attribute weights in integrative decision value computations ( ;  ;  ;  ). However, several failures to observe changes in the VMPFC during cognitive regulation of decision making ( ;  ;  ) suggest the need to either measure value computation in a more sensitive way, or to identify alternate routes to behavioral change. 

Addressing these issues requires investigating regulatory control across multiple attributes and domains, using a sophisticated array of approaches for identifying changes in the representations of both specific attributes and integrated value signals. We used functional magnetic resonance imaging (fMRI) to measure brain responses while subjects completed two choice tasks, separated in time by up to 24 months ( ). Choices involved foods varying in healthiness and tastiness (food task) or monetary proposals varying in payoffs for subjects and an anonymous partner (altruism task). To mimic the kinds of cognitive reframing approaches that are often used in therapy for decision making disorders ( ;  ), both tasks asked subjects to adopt distinct regulatory goals designed to highlight different choice attributes (e.g., ‘focus on the food’s healthiness’, ‘focus on your partner’s feelings’). To pinpoint whether and how regulation altered specific attribute representations or integrative value computations at the behavioral and neural level, we combined a multi-attribute extension of the drift diffusion model (DDM) ( ;  ) with multivariate pattern analyses (MVPA) of neural responses ( ;  ). MVPA approaches to fMRI data exploit information encoded across multiple voxels and have been suggested to detect information that would be missed by conventional univariate analyses ( ). Past research on cognitive regulation has relied primarily on mass univariate approaches, which could account for some of the inconsistencies observed in the literature. Our study used MVPA to examine whether and how directed attention to specific goals affects the neural information content (i.e., decoding accuracies) for attribute values in different social and non-social decision contexts. We hypothesized that goal-dependent changes in neural decoding accuracies would match predictions on altered attribute weights from the behavioral computational model. We investigated where such changes occurred, whether they operate in generic or domain-specific manner, and whether they predicted specific aspects of regulatory success across individuals. 
   fMRI Paradigms and Choices.  
(  A  ) Food Task. Subjects chose between on-screen food items that varied in tastiness and healthiness and a neutral default food. Choices were made in ‘Natural’ [NC], ‘Focus on Health’ [HC], and ‘Focus on Taste’ Conditions [TC]. (  B  ) Altruism Task. Subjects chose between on-screen proposals that affected the payoff of themselves ($Self) and an anonymous partner ($Other) and a default option ($20 for both). Choices were made in ‘Natural’ [NC], ‘Focus on Ethics’ [EC], and ‘Focus on Partner’ Conditions [PC]. (  C  ) (  D  ). Bar plots illustrate condition-wise percentages of healthy (C) and generous (D) choices (M ± SD), and subject-specific scores (circles). *p < 0.05, corrected,  p < 0.05, uncorrected. (  E  ) Computational behavioral model (DDM). Choices (yes/no) are made when the sequential accumulation of noisy value information that unfolds over time crosses the predefined upper or lower threshold for choice. The relative decision value (RDV) at a point in time (t) is computed as the weighted sum of choice relevant attributes plus noise (ε) (i.e., RDV  = RDV + w  * Tastiness + w  * Healthiness + ε ). In the example displayed here, the value of a candy bar will tend to accumulate in a positive direction if the weight on Tastiness is high (blue line), yielding a choice in favor of a tasty but unhealthy item. However, the value of the food item is more likely to accumulate in a negative direction if the weight on Healthiness is high (brown line). Note that saying Yes can sometimes indicate a healthy choice, and sometimes an unhealthy choice. (RT = reaction times [sec]; figure adapted from [ ;  ]). 
 
   Drift diffusion model (DDM) fits to behavior in both choice tasks.  
(  A  ) Correspondence in the altruism task between observed acceptance rates (top) and response times (bottom) for different proposal types (bars) and model predictions (blue circles, determined using best-fitting parameters for each subject). On average, subject-level correlation between observed and predicted acceptance rates across trial types was generally quite high. (  B  ) Correspondence in the food task between observed and model-predicted acceptance rates (top) and response times (bottom) for foods of varying taste and healthiness (subject-specific ratings outside the scanner). For illustration purposes, for both tasks model fit to behavior is shown for eight bins created based on the displayed color scheme (right) for variations in choice-relevant attributes (increased attribute values from left to right). Thus, bar colors correspond to trials with specified combination of attributes. 
  
 

## Results 
  
### Behavior 
  
To identify how value computations change to accommodate regulatory goals, our analysis strategy proceeded in the several steps. First, on the behavioral level, we confirmed that regulatory goals resulted in altered choice behavior. We also used our computational behavioral models (multi-attribute drift diffusion models, DDMs) to link these alterations to amplification or suppression of the influence of specific choice-relevant attributes on choices. 

#### Choice behavior 
  
Choices in both tasks varied considerably by regulatory goal ( ). In the food task, subjects made choices in three conditions: Respond Naturally [NC] (‘respond as you naturally would’), Focus on Health [HC] (‘focus on the healthiness of the food when making the choice’), and Focus on Taste [TC] (‘focus on the tastiness of the food when making the choice’), implemented in interleaved blocks (see Appendix 1 – Instructions for regulatory conditions in both choice tasks for instructions). We defined a healthy choice as accepting the on-screen food if it was healthier than the default food (based on subject-specific healthiness ratings obtained outside of the scanner, see Materials and methods), and rejecting it otherwise. As expected, subjects made significantly healthier choices during HC (M ± SD: 78.83% ± 18.46) compared to both NC (44.31% ± 10.71) and TC (41.99% ± 11.46; paired t-tests: p’s < 0.001, Bonferroni corrected unless stated otherwise). They also made marginally less healthy choices during TC than NC (p = 0.043, uncorrected; repeated measures ANOVA across all conditions: F(2,35) = 97.01, p < 0.001). 

In the altruism task, subjects were instructed either to Respond Naturally [NC] (‘respond as you naturally would’), Focus on Ethics [EC] (‘focus on doing the right thing and consider the ethical or moral implications of your choice’), or Focus on Partner [PC] (‘focus on your partner’s feelings and how the other person is affected by your choice’) (see Appendix 1 – Instructions for regulatory conditions in both choice tasks for instructions). We defined an altruistic choice as accepting an on-screen proposal whose outcome (relative to the default) benefitted the other at a cost to the self, or rejecting one in which the subject stood to benefit but their partner did not. As expected, subjects made altruistic choices significantly less often under NC (28.71% ± 15.48) compared to EC (49.94% ± 16.22) or PC (66.97% ± 24.35; p’s < 0.001; F(2,35) = 65.96, p < 0.001) ( ). Altruistic choices were also significantly higher in PC than EC (p < 0.001), suggesting that directing attention to another persons’ feelings generally increased altruism more effectively than considering social and moral norms. Overall, these findings confirmed that regulatory goals resulted in altered choice behavior in the food task and the altruism task. 


#### Regulatory success 
  
Given the considerable individual heterogeneity in the extent of these changes, we also sought to understand whether this heterogeneity might be consistent across tasks and regulatory instructions. Regulatory success – defined as goal-consistent changes in percent healthy or altruistic choices ( ) (e.g., the increase in healthy choices during HC compared to NC) – covaried across tasks ( ). People who chose healthy foods more often when attending to a food’s healthiness also behaved more altruistically when focusing on pro-social attributes. These results did not depend on the delay between tasks (partial correlations controlling for delay of up to 24 months, M ± SD: 16.42 ± 8.66, range: 1 to 24) or differences in baseline responding   within   a particular condition: the percentage of healthy and altruistic choices during NC blocks of both tasks did not correlate (all p’s > 0.05, uncorrected). Instead, they were driven by choice behavior during regulation: healthy choice during HC correlated with altruistic choice in both EC (r = 0.45, p < 0.05) and PC (r = 0.66, p < 0.001). Overall, these findings indicate that an individuals’ regulatory success generalized across choice domains. We found no significant correlation of self-reported motivation to comply with instructions with regulation success in the food task (all p’s > 0.14, uncorrected) or the altruism task (all p’s > 0.16, uncorrected) (Appendix 1 – Self-reported motivation to comply with instructions and observed regulation-success). 
   Correlation of regulatory success (RS) in both choice tasks.      

#### Computational parameter estimates (DDMs) 
  
We hypothesized that changes in choice behavior could result either from increased weighting of goal-consistent attributes (e.g. healthiness in HC), decreased weighting of goal-inconsistent attributes (e.g. tastiness in HC), or both. We tested these possibilities by fitting multi-attribute DDMs to behavior, separately for each subject in each condition and task (see Appendix 1 – Drift diffusion model for details). Model fits to behavior indicated that we were able to capture both choices and RTs with high accuracy ( ). Supplemental analyses also confirmed that the DDM did not perform worse in capturing behavior during regulation conditions compared to natural choices (Appendix 1 – Drift diffusion model). To determine if regulatory goals altered weights assigned to distinct attributes, we computed repeated measures ANOVAs with regulatory goal as a within-subject factor, separately for each attribute. 

As predicted, regulatory goals in the food task changed the weights assigned to tastiness and healthiness (all F(2,35) ≥ 103.36, p’s < 0.001; see   for attribute-specific estimates; for complete list of model-estimates and RTs see  ). Healthiness influenced food choices   more   in HC, and   less   in TC, compared to NC ( , all p’s ≤ 0.001). By contrast, tastiness influenced food choices less in HC, compared to both NC (p < 0.001) and TC (p < 0.001) ( ). No differences emerged between NC and TC (p = 0.47, uncorrected, 2-tailed), suggesting that decision processes in TC likely resemble natural choice contexts. 
   Goal-dependent modulation of attribute value encoding.  
 Behavioral   weights (left column) assigned to attributes in food choices (  A  . Healthiness,   C  . Tastiness) or altruistic choices (  E  . $Self,   G  . $Other,   I  . Fairness) varied by regulatory goal (estimates of drift diffusion models, DDMs).   Neural   decoding accuracies of attribute values (right column) also varied across conditions in specific brain regions (  B  . Healthiness,   D  . Tastiness,   F  . $Self,   H  . $Other,   J  . Fairness) (p < 0.05, FWE corrected at cluster-level) (estimates of Support Vector Regression models, SVRs). Bars represent median estimates (blue = behavioral DDMs, red = neural SVRs; black boxes signify 25–75 percentile, lines illustrate the overall distribution), HC = Health Condition, NC = Natural Condition, TC = Taste Condition, PC = Partner Condition, EC = Ethics Condition, L = left hemisphere, R = right hemisphere, LPFC = Lateral Prefrontal Cortex, SFG = Superior Frontal Gyrus, MFG = Mid Frontal Gyrus, TPJ = Temporoparietal Junction, SFS = Superior Frontal Gyrus. 
 
   Goal-dependent modulation of neural value encoding in DMPFC ($Self) and Precuneus ($Other) in the altruism task.  
Panel displays average decoding accuracies for clusters where neural representations of attributes varied across regulation conditions for neural Support Vector Regressions (SVRs) (p<0.001, FWE corrected at cluster-level). Bars represent median estimates; black boxes signify 25–75 percentile, lines illustrate the overall distribution. HC = Health Condition, NC = Natural Condition, TC = Taste Condition, PC = Partner Condition, EC = Ethics Condition, L = left hemisphere, R = right hemisphere. 
  
    Model-estimated weights (w) assigned to choice-relevant attributes in the food task and altruism task (DDMs).    
Regulatory goals had a similarly dramatic influence on attribute weights in the altruism task (all F(2,48) ≥ 21.48, p’s < 0.001;  ). Subjects’ choices were swayed more strongly by their own monetary outcome ($Self) in NC compared to PC (p < 0.001) and marginally compared to EC (p = 0.059, uncorrected, 2-tailed) ( ). Moreover, the influence of their own payoffs on choices decreased more dramatically in PC than EC (p < 0.001). In contrast, estimated weights on the partner’s monetary outcome ($Other) increased for both pro-social regulatory conditions compared to NC (p’s < 0.001), with marginally higher weights in PC than EC (p = 0.013, uncorrected, 2-tailed) ( ). Fairness of proposed payouts (−1*|$Self - $Other|) influenced choices significantly less in NC compared to EC (p < 0.001), and marginally less compared to PC (p = 0.021, uncorrected, 2-tailed). Weight on fairness was also significantly higher in EC than PC (p < 0.001) ( ). Note that within-task results for the altruism task are reported for the slightly larger sample size of 49 subjects. Considering only the subset of subjects that also participated in the food task (N = 36) yielded comparable weights for attributes in altruistic choices ( ). Overall, the results suggest that regulatory goals changed choice behavior by both increasing weighting of goal-consistent attributes (e.g. healthiness in HC) and decreasing weighting of goal-inconsistent attributes (e.g. tastiness in HC). 



### Neural encoding of choice attributes and effects of regulation 
  
Next, we examined neural underpinnings of goal-consistent increases/decreases in the influence of attributes on altered choices in both tasks. This analysis step was designed to provide evidence for the effects of regulation at the attribute-level or integration-level. Both hypotheses suggest that changes in the influence of distinct attributes on choice should correspond to changes in neural encoding of those attributes. However, they make different predictions about   where   these changes should be observed. The attribute-level hypothesis predicts that attributes are encoded in attribute-specific brain areas and that regulation should result in changes to these local representations. By contrast, the integration-level hypothesis suggests that attribute-specific areas should encode attributes similarly   regardless   of the regulatory goal. Instead, altered representations should appear only within centralized brain regions associated with value-integration, such as the VMPFC, and should be detectable in a common signal associated with integrated values. We tested these distinct predictions by examining where attribute values were represented in the brain, and how these representations varied as a function of regulatory focus. We also explicitly tested whether the locus of effect differed across attributes (e.g. tastiness/healthiness, $Self/$Other/Fairness) or choice domain (e.g. social, non-social). 

#### Neural encoding of choice attributes and decision values across conditions 
  
Our behavioral results suggest that a weighted combination of different choice-relevant attributes captures behavior in both choice tasks ( ), implying that attribute information should be represented in the brain. However, the generality and specificity of this encoding has important implications both for theories about how different attributes are constructed, and how regulation operates to modulate their influence. We first sought to determine which brain regions reliably encoded trial-by-trial variation in a given attribute across experimental conditions and goals. Thus, this first set of decoding analyses tested   if   neural activation patterns encode attribute values, irrespective of whether one or several conditions drive this predictive information. To this end, we averaged the condition-specific decoding maps of an attribute for each subject and tested for brain regions that reliably predict values of the attribute at the group level. Consistent with predictions, information about each attribute could be decoded significantly above chance in multiple brain regions ( ), including the VMPFC, and, for some attributes, the DLPFC. This was also true for trial-by trial encoding of decision values (DVs, corresponding to observable choices in the altruism and food task). See   (main effects) for a complete list of results and details on the clusters in the (V)MPFC and DLPFC for the neural decoding of DVs. 
   Neural prediction of trial-wise attribute values in food choices and altruistic choices.      

#### Conjunction of neural representations of choice attributes 
  
Given the robust coding of individual attributes, we asked whether any brain regions encoded   all   attribute values across all contexts, as might be expected of domain-general areas contributing to value integration processes. A formal conjunction of all attribute-specific decoding maps (Healthiness, Tastiness, $Self, $Other, Fairness; thresholded at p < 0.05, FWE cluster-level correction, height threshold of p < 0.001) identified VMPFC ([MNI −6, 49, 1],  ) as well as a handful of other regions ( ). This suggests that the VMPFC contains information on trial-wise values of   all   choice-relevant attributes, consistent with its hypothesized importance for valuation and choice. 
   Conjunction of neural representations of attribute values.  
Multivariate response patterns in the VMPFC encoded trial-wise values of all choice-relevant food attributes (Tastiness, Healthiness) and altruistic attributes ($Self, $Other, Fairness) across regulation conditions, as indicated by a conjunction of attribute-specific decoding maps thresholded at p < 0.05, FWE corrected at cluster-level. 
 
   Conjunction of brain areas that encoded trial-by-trial values of all attributes.  
Attribute values for Healthiness, Tastiness, $Self, $Other, Fairness. Each attribute was thresholded at p < 0.001, cluster-level corrected, k = 10 voxels. Not displayed are clusters in the supplemental motor area ([MNI −3 26, 46], 43 voxels) and visual cortex ([MNI −28,–85, 32], 15 voxels, [MNI −21,–67, 40], 10 voxels). Coordinates refer to center of mass for the identified clusters in MNI space (Montreal Neurological Institute), R = right hemisphere. 
  

   Exploratory functional connectivity analyses.  
(  A  ) Region of the VMPFC (red) where increased connectivity with the DLPFC during Health vs. Natural and Taste focus conditions correlates with Δw Healthiness in Health vs. Natural and Taste Focus. The yellow region shows the VMPFC ROI defined by the conjunction of all attributes. Orange indicates overlap. Inset: DLPFC seed region. (  B  ) Region of the VMPFC (red) where decreased connectivity with the DLPFC during Partner and Ethics conditions compared to Natural predicted decreases in Δw $Self in Partner and Ethics vs. Natural condition. The yellow region shows the VMPFC ROI defined by the conjunction of all attributes. Inset: DLPFC seed region. (  C  ) Region of the Precuneus where increased connectivity with the VMPFC during Partner vs. Ethics conditions Δw $Other weight in Partner vs. Ethics trials. Yellow region shows the VMPFC ROI defined by the conjunction of all attributes. Inset: Precuneus seed region. All results are shown thresholded at p < 0.005 uncorrected. 
  
 

#### Goal-dependent representations of choice attributes and decision values 
  
Having confirmed that attribute values (and decision values) could be decoded from neural response patterns, we next asked whether, how and where neural information content changed as a function of regulatory goals. We hypothesized that altered behavioral weights of an attribute should be mirrored by changes in the neural encoding of that attribute as expressed in varying predictive accuracies. Crucially, these analyses allowed us to test whether goal-dependent change in neural encoding of attribute values occurs in attribute-specific regions or at a common neural locus regardless of attribute or domain. For each attribute, we used a repeated measures ANOVA implemented in SPM together with condition-specific decoding accuracy maps to test for changes in neural information on attribute values across conditions (see  ). This allowed us to identify brain regions where neural information content about an attribute, or decision values ( ), was enhanced or diminished in a way that matched behaviorally-estimated changes in attribute weighting (thresholded at p < 0.05, cluster-level corrected, height threshold of p < 0.001; see  ). 
   Goal-dependent coding of attribute values (left to right).  
For each participant, we created a spherical searchlight (left panel, black sphere) and extracted multi-voxel response patterns for every trial of a choice task (middle panel). Next, we trained a support vector machine (SVM) regression model with data of 8 runs (80 trials), using neural response patterns as features and trial-wise attribute values as labels (e.g. a food’s perceived tastiness). Test data consisted of data of the ninth run (10 trials) for which we predicted the trial-wise attribute values solely based on neural response patterns of these trials. The decoding accuracy (average of 9-fold cross-validation) was assigned to the central voxel of the sphere from which we extracted the neural data (right upper panel). This procedure was repeated for every measured voxel (left panel, dotted red line), yielding a whole brain accuracy map for an attribute, separately for each task condition and participant. Finally, at the group level (lower right panel), we used these whole-brain accuracy maps to test for brain regions where predictive information on an attribute was increased/decreased depending on the task condition, based on predictions of the behavioral computational model (DDM). (Note that condition-specific accuracy maps also allowed testing for main effects of neural encoding of an attribute (i.e. encodes attribute values), irrespective of whether one or several conditions drive the effect.). 
     Goal-dependent change of neural information content on attribute values.      
##### Healthiness 
  
Behavioral model-fitting suggests that healthiness was weighted more heavily in HC compared to both NC and TC ( ). Consistent with model-based predictions, decoding accuracies in the right lateral prefrontal cortex (LPFC) were higher when focusing on health [HC] compared to both other task conditions ([HC >NC], and [HC >TC]) and combined [HC > (NC, TC)];  ;  ). 


##### Tastiness 
  
Behaviorally, tastiness was represented less strongly in HC compared to NC and TC, with no significant differences between the latter ( ). Decoding accuracies in the right superior frontal gyrus (SFG), extending to the mid frontal gyrus (MFG), closely matched these predictions [(NC, TC) > HC] ( ). Neural representations of trial-wise tastiness were also significantly higher for separate comparisons of [NC > HC] and [TC > HC], but did not differ between NC and TC. Only two other regions (visual cortex and left motor cortex) followed this pattern ( ). 


##### $Self 
  
Estimates of the best-fitting behavioral parameters for $Self suggest that neural information representing subjects’ own benefits should decrease in both pro-social regulation conditions (PC and EC) compared to NC ( ). Formal tests of this pattern ([NC > (EC, PC)]) identified neural responses in both DMPFC ( ) and the MFG (p < 0.001, uncorrected;  ; for [NC] > [EC] significant at p < 0.05, cluster-corrected). 


##### $Other 
  
Based on the behavioral model we predicted that, compared to NC, the partner’s benefits should be represented more strongly when attending to either ethical implications or the other’s thoughts and feelings ( ). Surprisingly, no brain regions matched this precise pattern (for [(PC, EC) > NC], or [PC > NC], or [EC > NC], at p < 0.05, cluster-corrected). However, a comparison of [PC > EC] revealed that decoding accuracies in the bilateral precuneus and right temporoparietal junction (TPJ) ( ) ( ) were significantly more predictive of the others’ payoffs when goals focused on the partner compared to ethical implications. Supplemental ROI analyses within these two areas indicated that average predictive accuracies were significantly higher in PC than NC, partially confirming the prediction of amplified information for $Other [PC > NC] from the behavioral model ( ). 


##### Fairness 
  
Behaviorally, fairness of payoffs for self and partner influenced choices more strongly when attending to ethics [EC] and, to a lesser extent, the partner’s feelings [PC] ( ). Consistent with model-based predictions, decoding accuracies in the left superior frontal sulcus (SFS) predicted the degree of fairness more strongly in the two regulatory conditions compared to natural choice contexts ( ). Contrary to the model prediction, comparisons of [EC > PC] (and [PC > EC]) did not yield any significant results, suggesting that both regulation conditions increased neural representations of fairness considerations to a comparable level. 

Notably, repeated measures ANOVAs also allowed testing for changes in neural attribute representations or decision values that were   not   predicted by changes in the behavioral DDM estimates. These supplemental tests did not yield any further significant results (p < 0.05, FWE cluster-corrected). 


##### Decision values 
  
See   for details on goal-dependent coding of decision values in both tasks. Only two regions (motor cortex in food task [TC > HC], cerebellum in altruism task [EC >PC]) were found to be significant (p < 0.05, FWE cluster-corrected). We thus focused on goal-dependent changes in information content on attribute values. 



#### A common hub for cognitive regulation of attribute values in the DLPFC 
  
To determine whether any areas might serve as a common pathway for goal-dependent changes in encoding of choice attributes, we computed 2-, 3- and 4-way conjunctions of all clusters that showed modulations of predictive information across conditions ( ). A cluster in the MFG ( ), hereafter referred to as DLPFC, emerged in the 3-way conjunction of voxels that flexibly encoded attribute values for Healthiness, Tastiness, and $Self. We found no other areas showing such a convergence of attributes. 
   Domain-general locus of goal-dependent attribute coding.  
(  A  ) Conjunction of voxels in DLPFC that flexibly encoded attribute values of Healthiness, Tastiness, and $Self across conditions within the respective task (p < 0.05, FWE corrected at cluster-level). (  B  ) Cross-condition decoding analyses tested for shared neural code in the DLPFC conjunction area across attributes and regulatory goals. Multivariate SVR models were trained on data in one condition (e.g. Taste NC) and tested on another (e.g. Taste TC), and vice versa (2-fold cross-validation; within-cell sanity checks used split-half approach). Red illustrates significant cross-condition decoding, blue illustrates non-significant results (permutation tests, cutoff-values of 95th percentile of empirical null-distribution).   Within-attribute decoding   (yellow frames): similar neural codes in DLPFC encode values of an attribute across contexts/regulatory conditions (with the exception of 2 of 18 tests).   Cross-attribute decoding  : neural response patterns that encode values of one attribute don’t allow predicting values of another attribute (neither within-task [tastiness-healthiness] nor across tasks [tastiness-$Self, healthiness-$Self]), independent of contexts. This pattern of results indicates that goal-sensitive representations of attribute values in DLPFC rely on attribute-specific neural codes. 
  
This finding suggests that the DLPFC acts as a domain-general circuit for goal-sensitive value representations. But what does this convergence in the DLPFC signify? On the one hand, the DLPFC might encode a   unitary decision value signal   that is sensitive to current goals. While limited to a specific set of attributes, this would support the integration-level hypothesis. If this was the case, the same code that represents a food’s tastiness in the food task (e.g. when focusing on taste) should also permit decoding of other attribute values used in other contexts (i.e., healthiness when focused on health, $Self in natural settings of altruistic choice). On the other hand, the DLPFC might compute attribute-specific representations in a goal-sensitive manner. This hypothesis is more consistent with attribute-level modulation. In this case, encoding of attribute values in this region should be unique to each specific attribute (i.e. codes for one attribute should not permit decoding of other attributes). We tested these competing predictions in a post-hoc ROI-based analysis examining the extent to which neural codes for one attribute in one context (e.g. tastiness in TC) generalize across attributes and contexts (e.g. healthiness in HC). These post-hoc decoding analyses differ from the previous set of analyses: more specifically, to probe for shared neural code in the DLPFC, we trained the SVM regression model on data of one attribute in one condition and see if it allows predicting trial-wise values of   another   attribute in the same or different regulatory condition (and vice versa, 2-fold cross-validation). We also tested for common neural codes for the same attribute across regulatory contexts. 

Results most clearly supported the attribute-level hypothesis. While codes for each attribute (tastiness, healthiness, and $Self) in the DLPFC generally allowed for decoding of the same attribute in other conditions at significant or marginally significant levels, no attribute allowed for coding of a   different   attribute, regardless of condition ( ). This supports the idea that the DLPFC acts as a domain-general mechanism for representing different attributes in a goal-sensitive manner, using unique codes for each attribute. 


#### No evidence for goal-dependent coding of attribute values and decision values in the VMPFC 
  
The vmPFC has previously been suggested to encode attribute values as a function of their current relevance to choice control ( ). Notably, our analyses on the whole brain level did not reveal any significant variation of attribute value encoding in this area as a function of the regulatory goal. However, in light of previous evidence, we conducted a number of post-hoc ROI-analyses to probe in a more sensitive manner for goal-dependent value coding in the VMPFC (see Appendix 1 – ROI-based post-hoc tests to identify goal-consistent value coding in the VMPFC). While activation patterns in the VMPFC (as well as several other regions) reliably predicted overall decision values in both tasks, regulation failed to modulate decoding accuracies for decision value ( ) or for   any   specific attribute (Appendix 1 – ROI-based post-hoc tests to identify goal-consistent value coding in the VMPFC), and did not predict individual differences in regulatory success (Appendix 1 – ROI-based post-hoc tests to identify goal-consistent value coding in the VMPFC). 



### Individual differences in regulatory success 
  
Are some people   generally   more successful using cognitive regulation of decision making or does it depend on the choice domain? Why? To address these questions, we examined the generality and specificity of value representations and their role in regulatory success. In particular, we predicted that if regulatory success operates through common   domain-general   mechanisms, individual success in regulating the effects of one attribute should be correlated with regulatory success in modifying different attributes in completely different contexts. Consequently, neural responses within such a domain-general neural locus should predict individual differences in people’s regulatory success across domains. By contrast, to the extent that cognitive regulation of decision making operates at the attribute-level in a   domain-specific   manner, success regulating one attribute in one domain should be uncorrelated with regulatory success for other attributes in other domains. It should also be predicted by neural activation in distinct, non-overlapping brain regions. 

#### Regulatory success in goal-dependent attribute weighting 
  
Although our previous analyses suggested that regulatory success as measured by frequency of healthy and generous choices was correlated across participants, this analysis did not examine how such success relates to changes in specific attributes. Thus, to determine whether regulatory success operates through common channels across attributes and domains, we first tested using behavior whether subjects’ ability to modulate specific attribute weights (estimated in separate DDMs) was correlated across the two tasks. Consistent with the notion of a common neural mechanism (in DLPFC), successful reduction in the weight on selfish considerations (Δw $Self) in altruistic choices was correlated with successfully amplifying the weight on health considerations in food choices (e.g., r = 0.50, for Δw $Self [NC - PC] and Δw Healthiness [HC - NC], p < 0.05, corrected) and suppressing the weight of taste considerations in food choices (e.g., r = 0.45, Δw $Self [NC - PC] and Δw Tastiness [NC - TC], p < 0.05, corrected). Notably, however, enhancement of the weight on another person’s outcomes did   not   correlate with changes in other attributes (all p’s > 0.05, uncorrected). See   for detailed list of results. Overall, this pattern suggests that regulation may operate through both common and distinct channels as a function of specific attributes, a point we return to in the neural results below. 


#### Domain-general predictions of individual differences in regulatory success in DLPFC 
  
Our preceding neural decoding results support a model in which regulation alters specific attribute representations within domain-general brain areas for some attributes (e.g., tastiness, healthiness, $Self) and within domain-specific areas for other attributes (e.g., $Other, fairness). This idea may explain the specific pattern of correlations we observed in behavioral measures of regulatory success and makes a further prediction: if the integrity and flexibility of the DLPFC is only necessary for representing certain attributes in a goal-consistent manner, then responses in this region should predict regulatory success only for those attributes that converge in this area, while regulatory success for other attributes (e.g., $Other) should be predicted by other regions (e.g., TPJ or precuneus). We tested this hypothesis using a cross-subject decoding approach: in a nutshell, this decoding analysis tested whether multi-voxel activation patterns in an ROI (e.g. DLPFC) allowed predicting an individuals regulatory success in a choice task, solely based on the participants regulation-related neural activation patterns (see Materials and methods and Appendix 1 – Multivariate regression of individual differences in regulatory success for details). The analyses focused on an ROI in DLPFC (with supplemental tests for TPJ, precuneus, and VMPFC) and regulatory success scores defined both by changes in attribute weights and by percentage of goal-consistent choices. 

As hypothesized, regulation-related neural activation patterns in the right DLPFC conjunction area ( ) during the food task reliably predicted how well a subject decreased taste weights and increased health weights in food choices (Δw Tastiness [(NC, TC) - HC]: r = 0.51, p < 0.014, permutation test; Δw Healthiness [HC - (NC, TC)]: r = 0.42, p < 0.041). Predictions further improved when we focused on altered attribute weights for HC versus TC (Δw Tastiness [TC - HC]: r = 0.68, p = 0.002; Δw Healthiness [HC - TC]: r = 0.47, p = 0.014). Similar results were found when we predicted subject-specific changes in regulation success based on improved dietary choices (ΔHealthy Choices [HC - (NC, TC)]: r = 0.50, p = 0.016; ΔHealthy Choices [HC - TC]: r = 0.46, p = 0.027), demonstrating that regulation-related neural predictions extend to actual behavior with real consequences. 

Next, we asked whether neural activation patterns in the right DLPFC also predict individual differences in regulation success in the altruism task. Remarkably, neural patterns in DLPFC during   food   choices predicted subjects’ ability to reduce the weighting of their own monetary payoffs during   altruistic   choices separated in time by an average of 16 months from the food task (Δw $Self [NC - (EC, PC)]: r = 0.50, p = 0.015; Δw Self [NC - PC]: r = 0.55, p = 0.005; permutation tests). They also predicted increases in generous behavior when attending to pro-social attributes (ΔGenerous Choices [(PC, EC) - NC]: r = 0.63, p < 0.001; ΔGenerous Choices [EC - NC]: r = 0.44, p = 0.028; ΔGenerous Choices [PC - NC]: r = 0.63, p = 0.002). Supplemental analyses suggest that predictive information on altered generosity was driven by neural information on changes in the attribute encoded in the DLPFC ($Self) and not by other attributes of the altruistic choice task (e.g., $Other, fairness) (see Appendix 1 – DLPFC-based prediction of goal-consistent changes of generosity is driven by goal-consistent changes in attribute representations of $Self (but not $Other or Fairness)). We also confirmed that decoding accuracies were not correlated with the delay between both choice tasks (all p’s > 0.05, uncorrected), indicating that predictions of individual difference scores of regulatory success were unrelated to temporal delays between tasks. Complementary decoding analyses based on brain data obtained during altruistic choices revealed similar patterns, further supporting our findings ( ). 


#### Precuneus encodes individual differences in regulatory success in altruistic choice 
  
Strikingly, patterns in the DLPFC did not decode regulatory success for social attributes that were flexibly encoded in other regions of the brain (i.e., $Other, Fairness). A post-hoc analyses tested whether neural activation patterns that encoded values of $Other in a goal-consistent manner would allow predicting individual differences in regulatory success in the altruism task. We found that response patterns in the precuneus reliably predicted individuals’ altered generosity in the altruism task (ΔGenerous Choices [PC - EC]: r = 0.57, p = 0.002 [CI: −0.41, 0.38]; ΔGenerous Choices [(NC, PC) - EC]: r = 0.61, p = 0.004 [CI: −0.41, 0.41]), suggesting that domain-specific attribute coding contributes to individual differences in regulatory control. 


#### VMPFC does not encode individual differences in regulatory success 
  
Because of its hypothesized role in valuation, a post-hoc analyses also examined whether the VMPFC region that encoded all attributes predicted regulatory success in either choice task. However, local activation patterns in VMPFC were   not   predictive of regulatory success for any attribute (all p’s > 0.31). This result suggests that while this region may encode all choice-relevant attributes, it was not the locus for changes in value representation in this task. However, exploratory functional connectivity analyses provided subtle hints that the VMPFC could be indirectly related to regulatory success through its modulation of both DLPFC and precuneus (see   and Appendix 1 – Changes in functional connectivity with the VMPFC correlate with regulatory success for details). 




## Discussion 
  
Cognitive regulation of decision making represents a crucial tool for altering behavior to fit momentary goals (e.g. eat healthy, be kinder). Capitalizing on the strengths of behavioral model-fitting ( ) and the greater sensitivity of neural multivariate pattern analysis ( ), we demonstrate how regulatory goals modulate value representations at the level of choice-relevant attributes, supporting goal-consistent behavior. Unexpectedly, cognitive regulation of decision making did   not   reliably modulate value signals within the VMPFC. Instead, regulatory effects converged to modulate a subset of distinct attribute representations in both the social and non-social domain within a region of the DLPFC that has previously been implicated in value-based choice ( ;  ;  ). Cognitive regulation of decision making also altered attribute representations for specific   social   attributes in distinct areas, including TPJ and precuneus. This pattern of neural convergence and divergence was reflected by behavioral patterns of covariation in regulatory success across tasks, made more remarkable by the fact that they were measured anywhere from weeks to more than a year apart. Our results provide important and novel insights into the domain generality and specificity of cognitive regulation of decision making, explain when and why regulatory success generalizes across contexts and domains, and raise exciting new questions for exploration. 

### Attribute-level vs. integration-level effects of cognitive regulation of decision making 
  
Do goals (e.g. eat healthier, be kinder) influence construction of value by operating on distinct attribute representations, or by changing integration of these values in centralized, common-value regions of the brain? Our results provide three key pieces of evidence in favor of attribute-level value modulation by cognitive regulatory control. First, although the VMPFC contained reliable information on the values of   all   attributes and encoded overall decision values across social and non-social contexts, these signals showed   no   modulation by regulatory goal for any attribute or decision value and did not predict individual differences in regulatory success. Moreover, no other area showed a complete correspondence between behavioral and neural effects of regulation, arguing against a single, centralized locus for effects of cognitive regulation on decision making. Second, we observed goal-dependent representations of some attributes (i.e., others’ benefits) in distinct, specialized brain regions like the TPJ and precuneus. Third, although we observed converging effects of regulation for a subset of attributes in the DLPFC (including tastiness, healthiness, and self-related benefits), representations of these attributes utilized distinct, differentiated codes. Taken together, although our results do not preclude the possibility that in other contexts cognitive regulation of decision making might operate on a single, centralized value integration mechanism, they suggest that it may often operate by changing distinct attribute representations. 


### Domain-general vs. domain-specific effects of cognitive regulation 
  
If cognitive regulation of decision making is mediated by changes in distinct attribute representations, when might we expect regulatory success – or failure – to generalize across contexts and domains? Our results indicate that although the DLPFC used distinct codes to represent different attributes, it may nevertheless be a common denominator in regulatory success across domains. Behaviorally, goal-consistent shifts toward ‘virtuous’ behavior in one domain (i.e. healthier food choice) correlated with shifts in the other (i.e. more generosity). This covariation was driven by correlated changes in the behavioral weighting of   precisely   those attributes represented in the DLPFC (i.e., tastiness, healthiness, and self-related benefits), but not in attributes encoded elsewhere (i.e. other-related benefits, fairness). These findings are even more remarkable given delays of up to 24 months separating the two choice tasks (average 16 months), ruling out alternative explanations like memory, mood, or priming effects. Thus, the DLPFC may represent a stable individual resource permitting flexible representation of specific attributes according to current goals. 

At the same time, goal-consistent changes in pro-social attributes (e.g. others benefits) appeared in areas like the TPJ and precuneus, especially when focused on the partner’s thoughts and feelings. This accords with growing evidence linking these regions to   domain-specific   computations related to Theory of Mind (ToM) ( ;  ;  ) and representing others’ mental states and needs during social choice: for instance, activation patterns in the rTPJ were recently shown to encode individual differences in the level of ToM during altruistic choice ( ). Notably, activity in these regions did not encode other social attributes (e.g., fairness) or their goal-consistent changes. Moreover, focusing on ethical and normative reasons for giving (which may require less focus on others’ specific thoughts and feelings) increased altruistic choice, but actually   decreased   representations of the other’s payoffs in these regions. Thus, the TPJ and precuneus appear to encode features specifically related to representing others’ outcomes in a goal-sensitive manner, pointing to specialized loci of cognitive regulation in social choice domains. 


### The role of VMPFC and DLPFC in valuation and cognitive regulation 
  
Our study adds to a growing body of experimental work finding that behavioral effects of regulation can occur in the absence of corresponding changes to either overall levels of VMPFC response ( ;  ;  ), or VMPFC representation of specific attributes like taste ( ). They also raise the intriguing possibility that the flexibility of DLPFC attribute representations may be particularly important for compensating when regulation of the VMPFC fails, a finding also observed in other studies of cognitive regulation of decision making ( ). This raises an important question: what determines the capacity of the DLPFC to properly represent these different attributes? Intriguingly, exploratory connectivity results suggested that this may actually derive, at least in part, from functional interactions with the VMPFC area that represented all choice-relevant attributes, with the strength of connectivity between DLPFC and VMPFC correlating with regulatory success. Although speculative, this finding is consistent with research in both animals and humans suggesting that the VMPFC may modulate affective attribute representations in other areas ( ;  ). These results could also suggest that VMPFC represents an earlier stage in the value construction process, with DLPFC representations emerging more closely to response. Future work including the use of measures with higher temporal precision may help to elucidate when and how interactions between the VMPFC and DLPFC determine regulatory success in different contexts. 


### Explaining individual differences in regulatory success and failure 
  
Our study is the first to document goal-consistent changes for   all   choice-relevant attributes, across diverse choice domains, both within and across individuals, shedding light on when and why regulatory efforts may succeed or fail. Our findings point to important divisions in regulatory success as a function of choice attributes and domain: an individual who struggles both to resist cheesecake and ignore their own self-interest may nevertheless have little difficulty in harnessing regulation to represent others’ needs and use this as input into social choices. This has important implications in treatment for decision making disorders: if therapeutic interventions fail when focused on one attribute (e.g., be less selfish), a switch to strategies focused on other attributes (e.g., think more about others) might be more effective. Future work will need to explore the full range of domains and attributes in which regulation could play an important role (e.g., risk, intertemporal choice, etc.) in order to determine the extent to which regulatory effects vary or converge across attributes and domains. 

It is also worth noting that goal-consistent changes in attribute representations were generally exceptions rather than the rule.   Most   regions permitting attribute decoding showed   no   discernable change in representation of attributes as a function of goal. This may explain why regulatory success often feels so difficult: unregulated attribute representations in some areas (including the VMPFC) may continue to leak into choices, complicating regulatory success. It also argues against a trivial interpretation of our results that the changes we observed are simply uninteresting reflections of behavior: we observed highly specific and localized success-related changes in regions like DLPFC, TPJ, and precuneus, but not in other areas. This suggests that these regions may perform a special role in mediating the impact of regulatory goals on behavior. 


### Limitations and future directions 
  
We cannot completely rule out that regulatory affects on behavior and attribute representations might partly reflect differences in motivation to satisfy expectations of the experimenter. However, we note that the specific patterns of convergence and divergence in regulatory success argue against this interpretation of our results: we suspect that if this were the case, we would not have observed either the distinct profile of within-subject correlations in regulatory success for different attributes, or differences in their neural correlates. Nevertheless, further research will be needed to fully resolve the extent to which individual differences in regulatory success result from limits in motivation or limits on capacity. Work examining whether gray matter volume in either the DLPFC and VMPFC predicts regulatory success across individuals might help to resolve such issues ( ). Tying laboratory measures of regulation to real-world consequences also remains a necessary future step in understanding the significance of these findings. 

Our results also point to a number of other open questions and future directions. The implementation of a strictly data driven approach confirmed that several   a priori   hypothesized regions of interest such as the VMPFC or the DLPFC are crucial for implementing cognitive control of goal-directed choice. However, we cannot rule out that other brain regions not identified by the current analyses (e.g. the ventral striatum) also contribute to decision making during regulation. Indeed, we observed changes in attribute decoding in restricted, non-overlapping areas of visual and motor cortex for some but not all attributes, which might reflect non-causal changes in visual attention or motor preparation, but could also be important precursors to downstream changes in areas like the DLPFC, TPJ and precuneus. 

The close correspondence between neural patterns and model-estimated changes in behavioral weighting suggests that our information-based neural measure captured a critical aspect of changes in neural computations during goal-dependent behavior. However, further investigation is necessary to understand what separates attributes whose representations converged in DLPFC from those that did not. One exciting avenue for future research will be to identify the precise factors that determine whether and when the DLPFC acts as the site for cognitive regulation of value. Understanding this distinction may help to predict when an individual will show more global deficits in regulatory success and when those deficits will tend to stand apart from success or failure in other domains or contexts. 



## Materials and methods 
  
### Participants 
  
Fifty-five healthy volunteers (25 female, M ± SD: 28 years ± 5.02) participated in the altruism task. A subset (N = 37, 17 female, 29 years ± 5.24) also completed the food task. Sample size for both established fMRI tasks were selected based on previous successful implementations of the food task ( ) and the altruism task ( ). All subjects had normal or corrected-to-normal vision and were free of psychiatric or neurological history. Subjects received $20/hour for their participation, plus the money from a trial selected randomly at the end of the altruism task. They also received a randomly selected food item at the end of the food experiment that had to be consumed in the lab. The altruism data of five subjects and the food data of one subject were excluded from further analyses due to excessive movement (>3 mm/3degree). The altruism data of another subject was excluded from the analysis due to invariant choice behavior. All subjects gave written informed consent and Caltech’s Internal Review Board approved the study. 


### Tasks 
  
Subjects performed two separate fMRI tasks as part of a large-scale cross-sectional research project. Task order was fixed, with the food task completed on average 16 months (SD: ±8.66; range: 1–24) after the altruism task to specifically probe for common and distinct computations in non-social and social goal-dependent choices. 

#### Food task 
  
 The non-social fMRI task was a modified version of an established food task ( ). On every trial, subjects chose between one of 90 food items presented on-screen (4 s) and a default food chosen prior to scanning ( ). Subjects responded by pressing one of four buttons corresponding to ‘strong yes’, ‘yes’, ‘no’, ‘strong no’ (displayed at the bottom of the screen), using a button box placed in their right hand. The assignment of choice preferences to buttons was fixed throughout the task and the right-left orientation of the scale was counterbalanced across subjects. Inter-trial intervals varied from 1 to 4 s (average of 2 s), during which a white fixation cross was presented against a black background. After scanning, one trial was randomly drawn to determine what the subject would eat before leaving the lab. If subjects failed to respond within the 4 s of the selected trial either the on-screen or the default option was randomly chosen. 

Subjects made food choices under three conditions:   Respond Naturally   (‘respond as you naturally would’, [NC]),   Focus on Health   (‘focus on the healthiness of the food when making the choice’, [HC]), or   Focus on Taste   (‘focus on the tastiness of the food when making the choice’, [TC]) (see Appendix 1 – Instructions for regulatory conditions in both choice tasks for instructions). Importantly, subjects were explicitly instructed to always make the decision based on their preference, regardless of the condition. Every condition comprised nine blocks (with 10 trials per block), resulting in a total of 90 trials per condition. Prior to every block, detailed instructions appeared for 4 s. In addition, during food display, a short description (‘Respond Naturally’, ‘Focus on Health’, ‘Focus on Taste’) appeared at the top of the screen to remind participants of the current instruction. Each of the nine functional scanning runs contained one block of every condition (i.e., three task blocks per run), with the order of conditions randomized across runs and subjects. The only exception was the first task block, which was pre-assigned to ‘natural’ for every subject. Practice trials as well as a short quiz prior to scanning ensured that subjects understood the instructions for each condition and were comfortable with the timing of the task. 

Food items varied in their perceived tastiness and healthiness and included healthy snacks (e.g., apples, broccoli) and junk foods (e.g., candy bars, chips). Items were selected based on subjects ratings in a self-paced computerized task prior to scanning that assessed perceived tastiness (5-point Likert scale, ‘very untasty’ to ‘very tasty’) and healthiness (5-point Likert scale, ‘very unhealthy’ to ‘very healthy’) of 200 food items ( ;  ). Ninety food items were selected from this larger set to cover the range of health and taste ratings in a roughly uniform manner. In addition, for each subject we chose one default food that was perceived as neutral for taste and health. Each food item was presented once in each of three choice conditions, with presentation order randomized across blocks, functional runs, and subjects. To ensure the motivational saliency of the food items, subjects were asked to refrain from eating 4 hr prior to testing. Stimulus presentation was implemented using high-resolution color pictures (72 dpi) and Psychophysics Toolbox Version 3 ( ) together with Matlab (2014a). 


#### Altruism task 
  
The altruism task was an fMRI compatible version of the dictator game modified from ( ). On every trial, subjects were presented with a monetary proposal that affected their own ($Self) and another persons’ ($Other) monetary payoff ( ). Subjects had 4 s to chose between the on-screen proposal and a constant default allocation ($20 to both) by pressing one of the four response buttons (‘strong yes’, ‘yes’, ‘no’, ‘strong no’; direction counter-balanced across subjects). Payouts for self and other ranged from $0 to $40 and always involved a tradeoff between self and other (i.e. prizes for one individual were equal or less than the default, while prizes for the other individual exceeded the default). Thus, subjects always had to choose between acting altruistically (benefitting the other at a cost to oneself) or selfishly (benefitting oneself at a cost to the other) on every trial. At the end of the experiment, one trial was randomly selected and implemented according to the subjects’ choice. If subjects failed to respond within 4 s for this trial, both individuals received $0. 

Similar to the food task, subjects performed the task under three different conditions:   Respond Naturally   (‘respond as you naturally would’, [NC]),   Focus on Ethics   (‘focus on doing the right thing and consider the ethical or moral implications of your choice’, [EC]), or   Focus on Partner   (‘focus on your partner’s feelings and how the other person is affected by your choice’, [PC]). Subjects were reminded to always make their choice based on their preference, regardless of the condition. Conditions were implemented in separate blocks of 10 trials each, with the beginning of a new block signaled by a short reminder instruction (4 s). Matching the food task, subjects performed 9 blocks of each condition (i.e., 90 trials per condition and a total of 270 trials), with the block order counter-balanced across subjects and functional runs, with the exception that the first two blocks were always natural choice trials. Choices in these NC blocks were used to estimate a logistic regression [Choice = w  * $Self + w  * $Other] and used for a subject-specific selection of 30% of proposals most likely to elicit generous behavior and 30% of proposals likely to elicit selfish behavior. The remaining 40% of trials were randomly chosen from the full proposal space. Practice trials and a quiz prior to scanning verified that subjects were capable and comfortable to make the choice within 4 s. 


#### Probabilistic choices 
  
To decrease experimental demand and to ensure anonymity in the altruism task, subjects were informed that implementation of their choices was probabilistic and that in 40% of trials their choices would be reversed ( ). Subjects were informed that their partner would only know the proposal and the outcome of the randomly chosen trial, but not their decision (i.e., if the outcome was due to the subjects’ choice or a choice reversal). The implementation was as follows: After each choice (jittered delay of 2–4 s), an outcome screen (4 s) informed subjects of the implementation of choices (implemented/choice reversal), followed by a jittered inter-trial interval of 1–4 s (average of 2 s) before the next choice screen appeared. Computerized control questions during training confirmed that subjects understood the probabilistic nature of the task and that it was still in their best interest to choose according to their individual preferences. In the food task, we matched the probabilistic implantation in the altruism task, and informed participants prior to scanning that their choices would be implemented with 60% probability. 

Data from an independent behavioral pilot study (N = 17, 11 female, M ± SD: 24.12 years ± 5.83) confirmed that choices under almost perfect implementation (90%) closely matched those observed under 60% implementation conditions (within-subject design, all p’s > 0.37, uncorrected, for paired t-tests of RTs, percentage of generous and healthy choices). These findings strongly suggest that the probabilistic nature of the task did not systematically alter preference-based choices in both tasks. 



### Behavioral computational model (DDM) 
  
We used a multi-attribute extension of the standard drift diffusion model (DDM) ( ;  ) to capture behavior in both the food and altruism task, using a maximum-likelihood procedure similar to that described in ( ) to find the best-fitting parameters (see Appendix 1 – Drift diffusion model for details). For capturing behavior in the food task, we fit a model using five parameters: two parameters for the weights on tastiness and healthiness, a parameter for non-decision time (NDT) representing perceptual and motor processes, and two parameters specifying the initial height of the choice-determining threshold (b) as well as the exponential decay rate of this threshold toward zero (d) as the time limit for responding approached. For capturing behavior in the altruism task, we fit a model using six parameters: three parameters related to the weights on $Self, $Other, and fairness (−1*|$Self - $Other|), as well as parameters related to NDT, b, and d (see   for details). 


### Functional image acquisition 
  
Functional imaging was performed on a 3T MRI scanner (Magnetom Trio, Tim System, Siemens Medical Systems, Erlangen) equipped with a 32-channel head coil. T2*-weighted functional images were obtained using an echoplanar imaging (EPI) sequence (TR = 2.5 s, TE = 30 ms, flip angle = 85°, 3 × 3 × 3 mm, matrix size 64 × 64, 47 axial slices, descending sequential acquisition order). For the altruism task, a maximum of 1521 volumes were acquired. For the food task we acquired 990 volumes. High-resolution T1-weighted structural images were acquired at the end of each scanning session using an MPRAGE sequence (TR = 1.5 s, TE = 2.91 ms, flip angle = 10°, TI = 800 ms, 1 × 1 × 1 mm, matrix size 256 × 256, 176 slices). 


### fMRI data analysis 
  
Functional images were analyzed using the statistical parametric mapping software SPM12 (  http://www.fil.ion.ucl.ac.uk/spm  ) implemented in Matlab. Preprocessing consisted of slice-time correction (reference slice 47), spatial realignment (by first registering each subjects’ data to the first image of each run, then all functional runs were co-registered with each other), and normalization to the Montreal Neurological Institute (MNI) brain template (EPI template). For every subject, we estimated several general linear models (GLMs), using a canonical hemodynamic response function (hrf), and a 128 s high-pass cutoff filter to eliminate low-frequency drifts in the data. 

#### Trial-wise estimates of choice phases: GLM1 (food task) and GLM2 (altruism task) 
  
These GLMs aimed to identify brain responses that encode trial-by-trial variations in attributes (i.e., foods’ healthiness or tastiness in the food task; payoffs for subjects and confederate and the fairness of the offer in the altruism task) and decision-values (four-point response from ‘strong no’ to ‘strong yes’) during choice periods. To this end, these models obtained a trial-wise measure of BOLD responses during food (GLM1) and altruistic choices (GLM2) at the time of the choice. For each subject, GLM1 included a regressor for each choice period (R1-R270) in the food task, lasting from the onset of a food presentation to the button press that represented the choice for the trial. In addition, the model estimated a separate regressor for the outcome phases for each functional run, movement parameters, and run-wise session constants as regressors of no interest. GLM2 mirrored GLM1 and estimated regressors of interest for every altruistic choice (R1-R270), lasting from the onset of the monetary proposal to the button press that signified the choice in this trial. GLM2 also estimated regressors of no interest including outcome phases, movement parameters, and session constants. Estimated responses for the regressors of interest – the choice periods of each task (R1-R270 from GLM1 and 2, respectively) – were then used as inputs for the multivariate decoding analyses (support vector regressions, SVRs) described below. 


#### Neural computational model: within-subject decoding of choice attributes 
  
This multivariate pattern analysis (MVPA) aimed to identify brain regions that encode trial-by-trial fluctuations of choice-relevant attributes (e.g. foods healthiness, payoff to self) or decision values (four-point response from ‘strong no’ to ‘strong yes’), and to assess how current goals affect neural information on the attribute level. Thus, these decoding analyses allowed us to explicitly test if regulation-based changes in   neural   information on choice-relevant variables (e.g., healthiness of foods) matched predictions from the   behavioral   computational model. 

For each choice attribute and each condition, we applied a separate support vector regression (SVR) analysis in combination with a whole-brain ‘searchlight’ approach ( ). The key advantage of the searchlight decoding approach is that it does not depend on a priori assumptions about informative brain regions and ensures unbiased information mapping throughout the whole brain ( ;  ). For every subject, we defined a sphere with a radius of 4 voxels around a given voxel v  of the measured brain volume ( ;  ;  ;  ) For each of the N voxels within this sphere, we extracted trial-wise parameter estimates of a particular condition (i.e., 90 of the 270 trial-wise regressors of choice periods from GLM1 (food task) or GLM2 (altruism task)). N-dimensional pattern vectors were created separately for each of the 90 trials of the respective fMRI task. Neural pattern vectors for 8 of the 9 task blocks (‘training data’) served as input features, with trial-wise values of the attribute (e.g., healthiness rating) as labels of the prediction. The prediction was realized using a linear kernel support vector machine regression (  http://www.csie.ntu.edu.tw/~cjlin/libsvm  ) (ν-SVR) with a fixed cost parameter c = 0.01 that was preselected based on previous implementations of this decoding approach ( ;  ;  ;  ). The resulting model provided the basis for the prediction of the trial-wise values of an attribute (e.g. healthiness ratings) of the 10 trials of the remaining task block (‘test data’) based on their neural response patterns. This procedure was repeated nine times, always using pattern vectors of a different task block as test data, yielding a 9-fold cross-validation. Predictive information about the choice attribute was defined as the average Fisher’s z-transformed correlation coefficient between the value predicted by the SVR model and the actual values of an attribute in these trials ( ;  ;  ;  ). This decoding accuracy value was assigned to the central voxel of the searchlight. The procedure was repeated for every voxel of the measured brain volume, yielding a three-dimensional decoding accuracy map for every subject, separately for each choice attribute and each condition. Decoding maps were smoothed (6 mm full width at half maximum, FWHM) and submitted to two different random-effects group analyses. 

First, to establish that neural response patterns encode the current value of a choice-relevant attribute during choices, we averaged subjects’ decoding accuracy maps for a particular attribute obtained in the three conditions (e.g., separate SVRs for healthiness in NC, HC, and TC). Subject-specific average information maps were than used in a random effect second level analysis (single t-test as implemented in SPM) and tested against chance level at a statistical threshold of p < 0.05 (FWE cluster-corrected, height threshold of p < 0.001). Note that if resulting cluster sizes at this statistical threshold prevented effective functional localization (i.e., clusters that exceeded 6000 voxels), we report results at p < 0.05, FWE corrected at voxel-level. Second, to examine if predictive neural information on a choice attribute varied systematically across the three conditions of the respective task, we used a repeated measures ANOVA as implemented in SPM. Only regions that passed the statistical threshold of p < 0.05 (FWE corrected at cluster-level, height threshold of p < 0.001) are reported. 

We also compared the results of the multivariate SVRs with those of a conventional univariate analysis (see  , and Appendix 1 – Univariate Analysis of fMRI Data). However, note that multivariate decoding approaches have been prosed to be more sensitive than traditional mass-univariate approaches: because multivariate pattern classifiers take advantage of information encoded across multiple voxels and exploit systematic differences in voxel selectivity within a specific brain region, they have been suggested to detect information that would be missed by conventional analyses ( ). 

There is a potential concern that the some intervals of the response scales for choice attributes (e.g. tastiness) or decision values (‘strong no’, ‘no’, ‘yes’, ‘strong yes’) might be subjectively larger than other intervals. While the present data don’t allow ruling out this potential concern, previous implementations of the response scales in both established tasks suggest that the operationalization of attribute-specific judgments and decision values allows to reliably identify value signals in the brain ( ;  ;  ;  ). 


#### Neural computational model: cross-subject decoding of individual differences in regulatory success 
  
This multivariate decoding analysis investigated whether neural activation patterns predict individual differences in regulatory success. A cross-subject decoding approach was used to test for information on the   degree   to which cognitive regulation affected attribute weights and choices. Clusters identified in the repeated measures ANOVA (see above) were defined as regions of interest (ROIs). Importantly, a main goal of our study was to test for potential common neural substrates underlying context-sensitive weighting of choice-attributes across choice-domains. Hence, these decoding analyses focused on voxels identified in a formal conjunction of the significant clusters for flexible representations of Healthiness, Tastiness, and $Self (at p < 0.05, FWE corrected at cluster-level, height threshold of p < 0.001; see  ). First, we tested if neural activation in this ROI obtained during food choices encodes subject-specific regulation success in the food task, but also in an independent social altruism task. To this end, we extracted parameter estimates for all voxels in the ROI ( ) from subjects first-level GLM1 (food choices) using the contrast image [HC > (NC, TC)] (based on DDM results suggesting differential attribute representations for this comparison,  ). Resulting pattern vectors (one per subject) were used as input features for the prediction and individual difference scores in regulation success served as labels. Regulation success was defined using difference scores in DDM parameters (e.g., Δw Tastiness [HC – (NC, TC)]) and in observed choice behavior (e.g., ΔHealthy choices [HC – (NC, TC)]). Predictions used a linear ν-SVR (libSVM) with a fixed cost parameter c = 0.01 (similar to within-subject decoding) and a leave-one-subject out approach (yielding a 36-fold cross-validation). Decoding accuracies reflect correlations of the observed and predicted regulation score. Statistical significance was assessed by comparisons to empirical null-distribution (realized by randomly permuting the pairing of subjects’ neural pattern vectors and behavioral regulation scores 1000 times). Only decoding accuracies above the 95th percentile of null-distributions were considered statistically significant ( ). As a sanity check, analyses were repeated training on data obtained during altruistic choices (see  ). 

Note that   ROI-based cross-subject   decoding analyses used permutation tests to assess the statistical significance of the predictions instead of simple t-tests (as implemented in SPM) applied to the   whole-brain within-subject   searchlight decoding maps. Regarding the latter, computational costs for estimating empirical null-distributions for several tens of thousands of searchlight analyses - implemented separately for every attribute, decision-value, condition, and subject - prevented us from using permutation tests for whole-brain decoding analyses. However, supplemental analyses that used t-tests to statistically assess ROI-based results yielded similar results as permutation tests, demonstrating that both statistical approaches generate comparable interpretations for the present data. Notably, empirical permutation-based null-distributions for ROIs also confirmed the theoretical chance level of the prediction that underlies statistical inferences for the whole-brain searchlight results (t-tests as implemented in SPM). Nevertheless, statistical tests based on empirical null-distributions can be viewed as superior insofar as they address the potential concern that means and distribution of predictions based on chance alone might vary across brain regions. 

Note also that the ROI ( ) used for this analysis was defined based on a fully independent and orthogonal set of tests for altered decoding accuracies across task conditions at the group level. Thus, ROI-selection was not subject to double dipping ( ). 



 ## Data availability

Functional imaging and behavioral data is deposited at the project's Open Science Framework (OSF) page (osf.io/wa4cs). The project page also makes available the derived statistical maps (univariate and multivariate decoding analyses), regions of interest (ROIs) used in analyses of functional imaging data, processed behavioural data, and details on the experimental procedure. </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-49'>
<h2>49. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/25671708/' target='_blank'>25671708</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Simulating Fiction: Individual Differences in Literature Comprehension Revealed with fMRI</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2015</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0116492</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4324766/' target='_blank'>4324766</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Study uses fMRI in healthy adult participants (n=18, ages 18–27) while they listened to literary stories and a Theory-of-Mind localizer, targeting mentalizing (perception/understanding of others). Both ROI and whole-brain analyses are reported (whole-brain contrasts Mentalizing vs Action with multiple-comparisons correction at p<0.05). The task and regressors explicitly probe social cognition (mentalizing/Theory-of-Mind). No exclusion criteria apply (not limited to ROI-only results; healthy participants reported separately). Therefore it meets all inclusion criteria for social-processing fMRI studies in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
When we read literary fiction, we are transported to fictional places, and we feel and think along with the characters. Despite the importance of narrative in adult life and during development, the neurocognitive mechanisms underlying fiction comprehension are unclear. We used functional magnetic resonance imaging (fMRI) to investigate how individuals differently employ neural networks important for understanding others’ beliefs and intentions (mentalizing), and for sensori-motor simulation while listening to excerpts from literary novels. Localizer tasks were used to localize both the cortical motor network and the mentalizing network in participants after they listened to excerpts from literary novels. Results show that participants who had high activation in anterior medial prefrontal cortex (aMPFC; part of the mentalizing network) when listening to mentalizing content of literary fiction, had lower motor cortex activity when they listened to action-related content of the story, and vice versa. This qualifies how people differ in their engagement with fiction: some people are mostly drawn into a story by mentalizing about the thoughts and beliefs of others, whereas others engage in literature by simulating more concrete events such as actions. This study provides on-line neural evidence for the existence of qualitatively different styles of moving into literary worlds, and adds to a growing body of literature showing the potential to study narrative comprehension with neuroimaging methods. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (36222 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Narratives play an important role in human life, and it is more and more acknowledged that fiction is a powerful player in human development as well as in adulthood (e.g. [ , , ]). Despite its importance, it is largely unknown what the brain networks are that support our unique ability to move into a fiction world. While it is uncontroversial that people   are   moved into fiction worlds [ , ], it is unclear   how   readers do this. People differ greatly in how they engage in fiction (e.g. [ , – ]), but the neurocognitive mechanisms behind narrative engagement remain unclear (see [ ] for related work on theatre). Here we use neuroimaging to investigate individual differences during the comprehension of literary fiction stories. 

One way in which participants engage with stories, is via simulation of the story’s content. Recent philosophical and neuroscientific evidence shows that it is important to distinguish at least two neurocognitively distinct components of simulation when considering the understanding of narratives (e.g. [ ]). First,   sensori-motor simulation   is evidenced by activation of motor and visual cortices when people comprehend language related to actions and scenery [ – ]. The second component relates to our ability to understand thoughts, intentions and beliefs of others, sometimes called   mentalizing   [ ]. The distinction between these two components important for fiction understanding is theoretically motivated (e.g. [ ]), and supported by neural findings (e.g. [ , ]). 

In this study participants listened to excerpts (4 to 8 minutes long) from literary novels, while neural activity was measured across the whole brain by means of fMRI. We chose to use listening rather than word-by-word reading, because relatively long fragments are used and therefore listening is expected to be the most convenient option for participants in the scanner. Supposedly, this would not result in crucial differences in terms of the mental simulation they employ. Previous studies did find differences in brain activity between listening and reading (with more individual differences in activity for reading), but also several core regions shared between modalities [ ]. More importantly for the purposes of the present study, it has been shown that regions involved in mentalizing [ ] and action understanding [ ] are activated independent of presentation modality. It is an open question whether mentalizing differs during reading or listening to narratives, but based on the previous literature we expect the two modalities to engage overlapping neural correlates. 

Stories were tagged for motor (‘action’) and mentalizing content, and memory for the stories was debriefed afterwards. Brain regions known to be involved in the two kinds of simulation were localized with standardized localizer tasks. Target regions were left and right motor regions for sensori-motor simulation [ ], and anterior medial prefrontal cortex (amPFC), right temporoparietal junction (rTPJ) and precuneus for mentalizing [ , ] (see   section). Importantly, measurement of brain activity during story comprehension was done on-line, and without additional tasks for the listener. 

Some recent neuroimaging studies relate to the issue of mentalizing and sensori-motor simulation during the comprehension of narratives. For instance, Wallentin and colleagues showed that part of the visual cortex which is sensitive to perceiving visual motion, is also activated when participants heard pieces describing movement in a retelling of ‘The Ugly Duckling’ [ ]. Similarly, Speer and colleagues showed that parts of short children’s stories containing action descriptions activated the motor cortex [ ]. In an interesting recent approach, Altmann and colleagues presented short stories (around 40 words per story) to participants. Stories were either labeled as fact (describing an event that actually took place) or as fiction. Most interesting for the current approach was that stories that were labeled as fiction led to stronger activation in medial prefrontal cortex (among other regions), whereas labeling stories as describing actual facts led to higher activation levels in the premotor cortex (again, amongst other regions) ([ ]; see also [ , ]). 

In this study we follow up on this previous work by using more extended (i.e. longer) excerpts from literary fiction, written for adults, in order to give participants an experience of engaging with fiction that is relatively close to their real-world experience. We have a special focus on individual differences in simulation and mentalizing during narrative comprehension. Previous work has found that participants differ in how much they engage parts of the mentalizing system during the reading of texts labeled as fiction [ ], as well as that participants differ in how much they engage in sensori-motor simulation during language comprehension [ , ]. Here we combine these two to see how participants differ in their engagement of these two important subprocesses of narrative comprehension while listening to natural, unmodified literary fiction. 


## Materials and Methods 
  
### Participants 
  
Eighteen healthy, naïve native speakers of Dutch without psychiatric or neurological problems, and with normal or corrected-to-normal vision and no hearing problems took part in the experiment. Four participants were male, fourteen female. The average age was 22.2 years (range 18–27). Data for the ‘Theory-of-Mind localizer’ of one participant showed artifacts (Nyquist ghosting) and were therefore removed. Written informed consent was obtained prior to the study, and ethical approval was obtained from the local ethics committee (CMO Committee on Research Involving Human Subjects, Arnhem-Nijmegen, The Netherlands, protocol number 2001/095), in line with the Declaration of Helsinki. Participants were paid either in money or in course credit at the end of the study. 


### Story stimuli 
  
Sound recordings of three literary stories were selected from the Corpus of Spoken Dutch (‘Corpus Gesproken Nederlands’, [ ]). Recordings were spoken at a normal rate, in a quiet room by female speakers (one speaker per story). The fragments were taken from literary novels, and all contained descriptions of actions, characters, scenery, and plot and character development. Duration of the fragments was 3:49, 7:50, or 7:48 minutes, and the number of words was 622, 1291, and 1131 words per story. In order to create an experimental baseline condition, reversed speech versions of the story fragments were created (using Audacity 2.03,   http://audacity.sourceforge.net  ). 

The story fragments were annotated for Action and for Mentalizing content over the course of the story. Quantification of the content at specific time points in the story was done with PRAAT [ ], and consisted of assigning sentence parts which contained Action descriptions or Mentalizing descriptions to either category. A sentence part was coded as Action if it contained action of a person or an object. A sentence part was coded as Mentalizing if a character’s mental states (emotions, desires, intentions and/or beliefs) were described, as well as when a character was described in terms of his or her personality ( ). Sentence parts were predefined in the corpus, and never contained more than one main verb. Taken together, the Mentalizing sentence parts made up 22.9% of the total story durations, and the Action sentence parts 25.6%. A sentence part could contain more than one kind of description: the two descriptors had 11.1% overlap. Mean duration of the Mentalizing events (sentence parts) was 1.58 seconds (s.d. 0.76 sec.), and 1.75 seconds for Action events (s.d. 0.70 sec.). In total there were 252 Mentalizing events, and 225 Action events. 
   Example of stimulus scoring.        

### Procedure 
  
 Main task  . The main task was always carried out first. Participants were auditorily presented with the three story fragments while they were lying in the MRI scanner. Intermixed with the stories, the three reversed speech versions of the stories were played. There was no additional task but to listen to the materials carefully and attentively. There was a short break after each fragment. The stories were presented in counterbalanced order across participants, with the reversed speech version always being played either before or after the specific story it was created from. 

 Localizers for regions of interest  . After presentation of the stories, localizer scans were taken to define regions of interest (ROIs) that were hypothesized to be active during either motor simulation or during mentalizing. ROIs for motor simulation were defined by having participants carry out a localizer task for action execution. Simple hand action was required (opening and closing of the fingers of both hands)—a fast method that has proven to reliably elicit the motor cortex in studies of action language comprehension [ , ]. Each trial started with a fixation cross presented for 1 s, followed by one of the words HANDS or REST for 10 s in white text on a black screen. Participants were required to continuously open and close their hands (Hand blocks), or to not move (Rest blocks). There were six of these trials per condition. The trials were presented in a pseudorandom order so that a specific condition was not presented more than twice subsequently. 

The task that was used to define mentalizing ROIs was based on an existing Theory-of-Mind localizer [ ]. Here, the version designed by Dodell-Feder, Koster-Hale, Bedny and Saxe was used, in a Dutch translation [ , ]. The task consists of a ‘false belief story’ task that activates regions that are known to be specifically activated when thinking about other persons’ beliefs and intentions. Followed by an initial instruction screen that stayed up until button press, participants read 20 short stories, divided in two blocks of ten. Each trial started with a fixation cross that was presented for a time interval randomly jittered between 4 and 8 s, in steps of 250 ms (intertrial interval). Then a story of two or three sentences was presented in white text on a black screen for 10 s. Each story was followed by a single-sentence statement that could be true or false. This statement stayed on the screen for 5 s, and within this time participants had to make a left button press for true, right for false statements. Half of the stories belonged to a   false photograph   (non-Mentalizing), half to a   false belief   (Mentalizing) condition: regions were defined on the basis of this contrast. That is, they reflected where activity was greater for the false belief condition than for the false photograph condition. The stories were presented in pseudorandom order, so that the same condition was never presented more than two times in a row. 

On the basis of the two localizer tasks, regions of interest were created. This was done for the action localizer, by taking significant clusters from the ‘hands > rest’ contrast, using a statistical threshold of p<0.05 Family Wise Error-corrected at the voxel level. For the Mentalizing localizer, the contrast ‘false belief > false photograph’ (story plus subsequent test statement together) was used. Results were corrected for multiple comparisons by combining a voxel-wise threshold of p<0.001 with a cluster extent threshold computed using the theory of Gaussian random fields, to arrive at a statistical threshold with a p<0.05 significance level [ ]. The different procedure for statistical thresholding was motivated by the fact that action execution leads to very strong and easily detectable activations, warranting a more conservative thresholding procedure. The mean brain activity in each ROI (technically the mean beta weights per condition) during story comprehension was extracted per regressor (Mentalizing content, Action content) per participant, using the SPM toolbox MarsBaR [ ]. 

 Post-hoc memory test  . Participants, once out of the scanner, got a surprise test to check their memory for each of the stories. Participants were not told about this memory test before the start of the experiment. There were five multiple-choice questions per story fragment, with three possible answers (A, B, C) each. The questions were asking for general content, varying in level of detail (Example: What could be seen at the horizon? A. wind mill, B. watchtower, C. radio mast). Memory scores were summed, providing an overall score of participants’ memory and on-line attention to the story. 


### fMRI data acquisition and preprocessing 
  
Images of blood-oxygen level dependent (BOLD) changes were acquired on a 3T Siemens Magnetom Trio scanner (Erlangen, Germany) with a 32-channel head coil. Pillows and tape were used to minimize participants’ movement, and earphones used for presenting the stories also minimized scanner noise. Functional images were acquired using a fast T2*-weighted 3D EPI sequence [ ], with high temporal resolution (TR: 880 ms, TE: 28 ms, flip angle: 14 degrees, voxel size: 3.5 x 3.5 x 3.5 mm, 36 slices). High resolution (1 x 1 x 1.25 mm) structural (anatomical) images were acquired using an MP-RAGE T1 GRAPPA sequence. 

Preprocessing was performed using the Matlab toolbox SPM8 (  http://www.fil.ion.ucl.ac.uk/spm  ). After removing the first four volumes to control for T1 equilibration, images were motion corrected and registered to the first image. The mean of the motion-corrected images was then coregistered with the individual participants’ anatomical scan. The anatomical and functional scans were spatially normalized to the standard MNI template. Finally, all data were spatially smoothed using an isotropic 8 mm full width at half maximum (FWHM) Gaussian kernel. 


### Stimulus presentation 
  
Stimuli were presented with Presentation software (version 16.2,   http://www.neurobs.com  ). Auditory stimuli were presented through MR-compatible earphones. Presentation of the story fragments was preceded by a volume test: a fragment from another story but with comparable voice and sound quality was presented while the scanner was collecting images. Volume was adjusted to the optimal level based on feedback from the participant. All visual stimuli were projected onto a screen using a projector outside the MR scanner room, which could be seen by participants through a mirror mounted over the head coil. Responses to the Mentalizing localizer task were recorded with two button boxes (left and right hand). The story parts of the experiment required no response (listening only). 


### Data analysis 
  
At the single-subject level, statistical analysis was performed using a general linear model, in which beta weights for each regressor of interest are estimated using multiple regression analysis [ ]. In this model, the two regressors of interest (‘Mentalizing’ descriptions and ‘Action’ descriptions) were modeled as their true durations, convolved with a canonical hemodynamic response function [ ]. The variance inflation factor (VIF) of the two regressors of interest was calculated, to ensure that unique variance could be attributed to each regressor. The VIF of ‘Mentalizing’ and ‘Action’ was 1.22, which is low, and well within the range for assessing multicollinearity, in which values bigger than 10 are problematic [ – ]. The motion estimates of the motion correction algorithm (linear, quadratic and first-derivative regressors for three translations and three rotations) were modeled as regressors of no interest to account for head motion. 

To address the question about individual differences in kinds of simulation, activity for the Action regressor in action ROIs was correlated with activity for the Mentalizing regressor in mentalizing ROIs. The rationale behind this analysis is that if people differ in whether they engage more in one type of simulation compared to the other, we should find that there is a relationship between activity in the mentalizing network during Mentalizing descriptions, and activity in the neural action network during Action descriptions. All correlations were two-sided Pearson’s correlations, and to guard against false positives, all correlation results were corrected for the number of comparisons by changing the critical alpha value using Bonferroni correction. 

As a control analysis, the same correlation analysis was repeated on the data acquired while participants listened to the reversed speech fragments, for which the Mentalizing and Action regressors are meaningless. Naturally, no significant correlations were expected between regions and different regressors in this analysis. A direct comparison between correlation values of the real and reversed speech sessions was done using Steiger’s test [ ]. 

To see if the action ROIs and the mentalizing ROIs were each co-activated during story comprehension, Action regressor activity in each of the action ROIs was correlated with the other action ROIs, and Mentalizing regressor activity in each of the mentalizing ROIs was correlated with the other mentalizing ROIs. We expect the ROIs for each condition to co-activate, in line with previous studies (see e.g. [ ] for action ROIs, and [ , ] for mentalizing ROIs). 

Finally, as another control analysis, activity for the Action regressor in mentalizing ROIs was correlated with activity for the Mentalizing regressor in action ROIs. No relationship between those regressors and ROI activity was expected, and therefore also no significant correlations between the mentalizing and action ROIs. 

Although our main hypothesis concerned the mentalizing and action neural networks, we additionally performed a whole-brain analysis to assess whether there were activations of interest outside of our target networks. Statistical group analysis was performed by directly contrasting one of the sentence part regressors with the other. Participants were treated as a random factor in this analysis (“random effects model”, [ ]). Results were corrected for multiple comparisons by combining a voxel-wise threshold of p<0.001 with a cluster extent threshold computed using the theory of Gaussian random fields to arrive at a statistical threshold of p<0.05 [ ]. 



## Results 
  
### Behavioral 
  
Participants answered on average 9.9 (s.d. 1.11) questions correct of the 15 questions asked in the post-hoc memory questionnaire (multiple choice, three alternatives, 5 questions per story). Participants performed well above chance (p<0.001 for all stories) on the memory test, and there were no differences between the three stories (F(2, 16) = 1.41, p = 0.27; mean story 1: 3.17 (s.d. 1.25), story 2: 3.67 (s.d. 1.09), story 3: 3.11 (s.d. 0.96)). This indicates that participants paid attention to the story content, and that this was equally the case for all three stories. 


### Localizers 
  
The results of the localizer tasks show that the localizers worked well: both revealed activations in sets of areas that were expected based on previous literature (see below). 

 Action localizer  . The action localizer activated the cortical motor system robustly. The ‘hands > rest’ contrast resulted in activations in the precentral and central motor regions bilaterally, as well as in the supplementary motor area (SMA), and in the cerebellum ( ). Since we had no a priori hypothesis about distinctions within the motor system during sensori-motor simulation, and to reduce the number of tests in the correlation analysis, we combined the cortical ROIs into two motor cortex ROIs, one for the left hemisphere, and one for the right hemisphere (MNI coordinates of centre voxel: left -34 -23 56, right 32 -20 58). This means the cerebellum was excluded from further analysis. 
   Results of the localizer scans.  
Whole-brain analysis results for the action localizer scan in yellow (hand action execution versus rest), and for the mentalizing localizer in blue (false belief stories versus false photograph stories [ ]). The action localizer activated the cortical motor system robustly, and the mentalizing localizer led to activations in the previously defined mentalizing (or Theory-of-Mind) network. Areas from the localizers were used in the main analysis as regions of interest. Results are displayed at a statistical threshold level of p<0.05, corrected for multiple comparisons. 
  
 Mentalizing localizer  . The regions of interest defined from the Mentalizing localizer’s ‘false belief > false photograph’ contrast were the medial prefrontal cortex, left and right temporo-parietal junction, left and right middle temporal gyrus, and the precuneus ( ). Given previous research, and in order to restrict the number of statistical tests, we selected, as mentioned above, the mentalizing ROIs from the results that are most commonly reported in previous literature, namely aMPFC (MNI coordinates -3 50 -10, rTPJ 51 -60 25, and precuneus -1 60 37 [ , ]). 


### ROI analysis 
  
Mentalizing regressor activity in the mentalizing ROIs was correlated with Action regressor activity in the action ROIs. A significant negative correlation was found between the action ROIs activation for Action descriptions, and the aMPFC mentalizing ROI activity for Mentalizing descriptions ( ;  ). This shows that participants who engaged the aMPFC when listening to mentalizing content, did engage the cortical motor system less when listening to Action descriptions, and vice versa. Importantly, the same correlations were not observed for the reversed speech data (all p>0.5;  ). A direct comparison using Steiger’s Z-test [ ] of the correlation values showed that correlations between aMPFC and motor regions during the real speech fragments were more negative than during the reversed speech fragments (z = -1.74, p = 0.04). A similarly negative correlation was found between right TPJ activity during mentalizing content and right motor cortex during action content ( ), and although this effect did not reach statistical significance, it is still sizeable (r = -0.40), and importantly in the same direction as the aMPFC-motor cortex correlation. No significant correlation was observed between Mentalizing activation in the precuneus, and Action-related activation of either of the Motor regions ( ). 
   Results of the correlation analysis.  
Scatter plots of activation levels (beta weights) of Mentalizing regions (x-axes) while participants listened to mentalizing content, and activation in Motor regions while participants listened to Action content (y-axes).   A  ) There is a negative correlation between Mentalizing regressor activity in the aMPFC mentalizing ROI (x-axis) and Action regressor activity in the left precentral action ROI (y-axis). This illustrates the individual differences in engaging with fiction, with a gradient going from those who engage exclusively in mentalizing, to participants that engage much more in motor simulation ( ).   B  ) Relationship between Mentalizing activation in right TPJ and Action content activation in right motor cortex. There is a negative relationship, which is sizeable (r = -0.40), but does not reach statistical significance.   C  ) No relationship was observed between Mentalizing activation in the precuneus and Action content in left Motor regions. Activity is expressed as the mean (over voxels in a ROI) of beta weights of a specific regressor in the regression model. The beta weights reflect the fit of BOLD activity with the modeled response to either Action or Mentalizing events. Every dot represents activation from one participant. 
     Correlations between mentalizing and action regions.           Correlations between mentalizing and action regions for the reversed speech control data.           Brain maps illustrating activation clusters for the Mentalizing regressor contrasted against the Action regressor (red) and the Action regressor contrasted against the Mentalizing regressor (blue).  
All activations are corrected for the multiple comparisons at p<0.05. 
  
The mentalizing ROIs were co-activated as is evidenced by the correlations between mentalizing ROIs while participants listened to Mentalizing content ( ). The rTPJ and precuneus showed a significant correlation with each other during mentalizing content. The correlation of aMPFC with the other two regions of the mentalizing network was not statistically significant ( ). It is possible that the aMPFC stands out from the rest of the mentalizing regions (see  ), but we are cautious to draw this conclusion from the present findings since the non-significant correlations of aMPFC with rTPJ and precuneus are still sizeable (r = 0.39 and r = 0.42 respectively), which is in between medium and large effect size in Cohen’s convention [ ]. These numbers cannot be taken as suggesting an absence of correlation. 
   Correlations within sets of co-activated regions.        
The action ROIs (left and right motor regions) correlated significantly with each other while participants listened to Action descriptions ( ). 

As a final control analysis, Mentalizing regressor activity in action ROIs was correlated with Action regressor activity in mentalizing ROIs (‘swapped correlations’), and no significant negative correlations were found, as was expected (all p>0.2). This is extra evidence that the negative correlations displayed in   and  , are specific to the content of the stories driving mentalizing and action regions. 

Activation levels in none of the ROIs were correlated with later memory for the stories, neither for the Mentalizing regressor, nor for the Action regressor (all p>0.12). 


### Whole-brain analysis 
  
Comparing activation for the Mentalizing regressor versus the Action regressor, a cluster in anterior medial prefrontal cortex was found, close to (and partially overlapping) the aMPFC region from the mentalizing localizer ( ;  ). For the Action regressor (versus the Mentalizing regressor), both left and right superior temporal gyrus were significantly activated, as well as the posterior cingulate cortex, extending into BA 7 ( ;  ). Activation levels of these four regions for both regressors compared to baseline are displayed in  . 
   Bar plots showing mean activation levels (‘beta weights’) of each of the regressors (Mentalizing in black, Action in white) against baseline, in each of the regions found in the whole-brain analysis ( ).  
 A  ) left superior temporal gyrus.   B  ) right superior temporal gyrus.   C  ) posterior cingulate cortex.   D  ) anterior medial prefrontal cortex. Error bars represent standard error of the mean (s.e.m.). 
     Results of whole-brain analysis.        


## Discussion 
  
Understanding fiction is more than an enjoyable pastime. Sharing narratives is a key component of human development (e.g. [ , , ]), and there is evidence for the long-held conjecture that engagement with fiction renders people more empathic, presumably because of its enhancement of Theory-of-Mind abilities in the short and long term [ , , ]. Another pointer towards the importance of fiction is that storytelling occurs in all cultures, and has existed throughout large part of human history [ ]. Here we used fMRI to measure individual differences in narrative engagement on-line, measuring neural activation while people listened to excerpts from literary stories. 

We show that participants employ mentalizing and motor simulation differently during fiction comprehension. There was a negative correlation between the activation in part of the cortical mentalizing network (anterior medial prefrontal cortex, aMPFC) for Mentalizing content in the story, and activation in the cortical motor network when participants listened to content related to Action. This suggests that there is a gradient among people in the way they engage with a narrative. Some rely mostly on mentalizing, others rely more on (sensori)-motor simulation, and yet others rely on both. This research gives more insight into individual differences in ways of engaging with fiction, by showing that there is no bimodal distribution with ‘simulators’ versus ‘non-simulators’, but that most readers rely on a specific type of simulation more than others. Some people are moved into a fiction story by mainly focusing on the thoughts and beliefs of others, whereas others pay more (implicit) attention to more concrete events such as action descriptions. 

These findings add to recent insights about the two complementary systems for understanding actions and goals. A meta-analysis showed that the mirroring system (anterior intraparietal sulcus and premotor cortex) and the mentalizing system (TPJ, mPFC, and precuneus) play complementary roles, depending on how abstract the presented actions and/or goals are [ ]. Another recent study, found that when participants were told to focus on the motive behind an action, the mentalizing system became active, whereas the mirroring system was activated when they focused on the implementation of an action [ ]. 

Here, we observed this distinction between the two networks on the individual difference level, and within the broader scope of not just understanding actions and goals, but entire fictional stories. Apparently, when participants are explicitly told to use either kind of simulation, they will, but without instructions individual differences will play a larger role. Clearly, the fact that participants differed in their reliance on mentalizing or motor simulation during fiction comprehension does not mean that some are   incapable   of mentalizing or engaging in motor simulation. For instance, we did observe robust group-level activations to the Theory-of-Mind localizer task. The individual differences during narrative comprehension rather reflect an implicit preference, showing what participants do when processing fiction without additional task constraints. 

It should be noted that the correlation we observed between Mentalizing and Action networks, only holds for one of the Mentalizing regions, namely the anterior medial prefrontal cortex. It is tempting to conclude that this region plays a privileged role during fiction comprehension, in comparison to the other parts of the mentalizing network (right TPJ and precuneus in the present study). Van Overwalle and Vandekerckhove [ ] suggest that aMPFC and TPJ each fulfill specific roles during mentalizing. Anterior MPFC is thought to be activated by descriptions of stable characteristics and enduring traits, TPJ by more temporary intentions and beliefs [ ]. Indeed, a large part of the mentalizing descriptions in our story materials consisted of personality trait descriptions. While it is possible that aMPFC shows up in our analysis for this reason, we are cautious with drawing strong conclusions on the respective roles of aMPFC and rTPJ / precuneus in the mentalizing network. The correlation values between right TPJ and precuneus and the motor cortex were still sizeable, and the correlations between the mentalizing regions (aMPFC, right TPJ, and precuneus) were all sizeable. Moreover, there is evidence from connectivity analyses that anterior MPFC and right TPJ are strongly connected [ , ]. Finally it is important to note that by characterizing the stimuli a priori (i.e., tagging the stories for action and mentalizing content) and by selecting relevant action and mentalizing ROIs based on functional localizers, the interpretation of the results does not rely strongly on reverse inference of the type that has been criticized before [ , ]. 

Our results nicely complement previous observations of individual differences in employment of mentalizing or sensori-motor simulation during story comprehension. Altmann and colleagues showed that individual differences in self-reported mentalizing correlate with the coupling of the aMPFC to other mentalizing regions during the reading of short stories labeled as fictional [ ]. Other studies using behavioral measures show that individuals differ in how much they engage in sensori-motor simulation during language comprehension [ , ]. Our finding of individual differences is somewhat at odds with recent neuroimaging studies that found evidence for simulation across the study sample. For instance, Speer and colleagues found that premotor cortex was activated when participants heard action related descriptions, and Wallentin and colleagues showed involvement of visual motion areas when participants listened to descriptions of motion, and activations of the amygdala when participants listened to emotionally laden parts of a narrative [ , , ]. In contrast, we do not observe consistent activations in motor regions with group-level statistics (the regions we find are, in fact, in line with [ ]), but show that there are sizeable individual differences in participants’ sensitivity to action-related parts of the narrative. Note that we did observe activation of the aMPFC at the group level for listening to mentalizing-related parts of the story. One speculative reason for the difference across studies is in the difference in stimulus materials. Speer and colleagues [ ] presented descriptions of activities of a 7 year old child (from ‘One boy’s day’, by Barker and Wright, [ ]), and Wallentin and colleagues [ , ] used a classic fairy tale (‘The ugly duckling’, by H. C. Andersen) as materials. This is in contrast to the pieces of literary fiction, written for an adult audience, that we used here. The descriptions from ‘One boy’s day’ and ‘The ugly duckling’ could either be more concrete in their descriptions to start with, or participants may flexibly adapt to the genre they listen to (e.g. [ ]), leading to a more heterogeneous response in the case of the different genres employed in the present study. The present data do not allow for testing these suggestions, and they should serve as inspiration for future research. 

A final point is that our focus on sensori-motor simulation and mentalizing, two important factors in literary comprehension, is not meant to claim that there are no other ways to engage with fiction (e.g. [ ]). 

A remaining question is how the qualitative experience of fiction differs between people that rely more on the one kind of simulation compared to the other. It is likely that a qualitatively different type of engaging with a narrative leads to a qualitatively different experience of that narrative. We found no relation between memory performance and activation levels in any of the regions of interest, indicating that the difference in reading style that we observed does not lead to a difference in memory for the stories. The memory questions that we asked were however rather general, and perhaps not sensitive enough to pick up on fine-grained differences between participants. Moreover, it was not possible to qualify memory questions as being more indicative of mentalizing or motor simulation. This is in line with the findings by Happé and colleagues who observed different activations in medial prefrontal cortex in autistic as compared to healthy control participants, but did not observe differences in memory for stories [ ]. Future research should investigate how individual differences in engaging with literature influence the phenomenological experience of a given narrative. 

From a more methodological point of view, the present study adds to a recent line of work showing that using neuroimaging to gain more insight into discourse / narrative comprehension is feasible and can give important insights about language comprehension at the level of narrative (e.g. [ , , – ]). 

In sum we provide on-line neural evidence for the existence of qualitatively different styles of engaging with fiction. Participants could be placed on a continuum of how much they relied on mentalizing or motor simulation while listening to literary fiction stories. People differ in how they are moved into a fiction world, and the current study qualifies part of how this is the case. Future work should be geared towards understanding what the consequences of these individual differences are for the understanding and appreciation of literature. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-50'>
<h2>50. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31729396/' target='_blank'>31729396</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Neural representations of honesty predict future trust behavior</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Nat Commun</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1038/s41467-019-13261-8</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6858375/' target='_blank'>6858375</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study in healthy adult participants (N=31, mean age 24.3) that probes social cognition: formation of trustworthiness impressions from advisers (honesty/dishonesty), advice-taking, and subsequent trust decisions in a trust game — clearly social-related processing (perception/understanding of others, social communication). The manuscript reports whole-brain analyses: multivariate voxel-wise searchlight MVPA (whole-brain gray matter mask) and whole-brain univariate GLM results corrected for multiple comparisons (voxel-level p<0.001, cluster-level FWE p<0.05). Although an OFC ROI was used for a post-hoc test, whole-brain results are primary and reported. Participants are healthy adults and results pertain to them. Hence all inclusion criteria are met and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Theoretical accounts propose honesty as a central determinant of trustworthiness impressions and trusting behavior. However, behavioral and neural evidence on the relationships between honesty and trust is missing. Here, combining a novel paradigm that successfully induces trustworthiness impressions with functional MRI and multivariate analyses, we demonstrate that honesty-based trustworthiness is represented in the posterior cingulate cortex, dorsolateral prefrontal cortex and intraparietal sulcus. Crucially, brain signals in these regions predict individual trust in a subsequent social interaction with the same partner. Honesty recruited the ventromedial prefrontal cortex (VMPFC), and stronger functional connectivity between the VMPFC and temporoparietal junction during honesty encoding was associated with higher trust in the subsequent interaction. These results suggest that honesty signals in the VMPFC are integrated into trustworthiness beliefs to inform present and future social behaviors. These findings improve our understanding of the neural representations of an individual’s social character that guide behaviors during interpersonal interactions. 
  
We tend to be more trusting of people who we know to be honest. Here, the authors show using fMRI that honesty-based trustworthiness is represented in the posterior cingulate cortex, dorsolateral prefrontal cortex and intraparietal sulcus, and predicts subsequent trust decisions. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (64720 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Trust is the essential component of social life enabling successful cooperation and fostering individuals’ well-being. The factors that induce trust in others remain, however, still largely unexplored. To date, at least two accounts have been proposed to explain an individual’s trust. 

One account proposes that interacting agents focus on maximizing their personal payoffs during social exchanges . This account assumes that optimally rational agents trust another as long as they will be better off with trusting than distrusting . Empirical investigations implementing economic games such as the trust game (TG) confirm that people are willing to trust as long as trusting leads to monetary rewards . However, trust levels drop significantly when external incentives lack or when trust leads to monetary losses . 

An alternative account argues that individuals take into account the social character and attitudes of the interacting partner when trusting. In this regard, individuals seek to form beliefs about the other’s social character by focusing on whether the other’s behavior fosters fairness, equality, and cooperation . Honesty, that is, the quality of being reliable and the tendency to share truthful information, has been proposed as a central determinant of trustworthiness impressions promoting prosocial behaviors . For instance, altruistic behavior, unconditional kindness, and reciprocity have been observed in response to others’ honesty . However, whether honesty also encourages others to trust is yet unexplored. 

These two accounts make different predictions on the neural mechanisms underlying trust. When individuals focus on the trade-off between advantageous and disadvantageous consequences following a trust decision, brain regions signaling actual, or hypothetical decision outcomes (such as the ventral striatum and dorsal anterior insula) should be recruited in trusting interactions . On the contrary, if trust draws on the social character of the other, brain regions associated with social evaluations (such as the ventromedial prefrontal cortex, VMPFC, and dorsolateral prefrontal cortex, DLPFC), and inferences on the other’s intentions (e.g., the posterior temporoparietal junction, pTPJ) should be engaged during trusting behaviors . However, to date, evidence on the brain regions representing the honest character of another is still missing. 

In this study, we investigated for the first time whether information about the other’s honest character evokes trustworthiness impressions that predict future trust in the other. Importantly, a reputation as a trustworthy person has been suggested to impact information processing during social learning. In particular, although individuals prefer to interact with, and learn from, trustworthy partners , beliefs about the other’s trustworthiness bias how information from the trustworthy other is processed and learnt . An explanatory hypothesis for such bias posits that beliefs about the other’s trustworthiness modulate evaluations of information from trustworthy others. For instance, previous work has linked biased beliefs about others’ reciprocity to differences in how information is encoded in the orbitofrontal cortex (OFC) , a region of pivotal importance in value representation . However, it is still unknown whether a reputation as an honest person modulates information encoding and whether the OFC plays a role in such biased information processing. 

Here, we developed a trust-inducing paradigm (take advice game, TAG), which enables us to isolate social evaluation signals related to the other person’s trustworthiness (learnt through her honest and dishonest behavior) from nonsocial value signals related to one’s task performance (neural responses to winnings and losses). Being able to disentangle these two types of information was of pivotal importance to the two main objectives of this study. On the one hand, it allowed us to isolate brain signals related to representations of the other’s honest character. On the other, it enabled us to investigate any modulatory effects of the other’s honest character on information processing. In the TAG, participants, in the role of advisee, had to learn the trustworthiness of advisers from feedback about their honest or dishonest advice. After the TAG, participants, now in the role of investor, played a one-shot TG with the advisers who advised them previously. 

Using multivariate voxel pattern analysis (MVPA) in combination with functional magnetic resonance imaging (fMRI), we examined the relationships between honesty, dishonesty, and trust on the behavioral and neural level. On the behavioral level, honest behavior increases trust irrespective of proximal benefits associated with the act of trust. On the neural level, the honesty-based trustworthiness of the partner is represented in the posterior cingulate cortex (PCC), bilateral DLPFC, and left intraparietal sulcus (IPS). Importantly, neural signal in these brain regions predicts an individual’s willingness to trust the partner in a subsequent interaction. Further, enhanced integration of honesty into trustworthiness beliefs via stronger VMPFC-pTPJ connectivity is associated with higher trust levels later on. Finally, the partner’s honest character modulates neural responses to positive and negative outcomes in the OFC. 


## Results 
  
### Paradigms 
  
In the TAG (Fig.   and Supplementary Fig.  ), participants in the role of advisee had to rely on the advice of different advisers to choose the highest of two cards. As participants did not have any information about the cards’ numbers, they depended on the honesty of the advisers for their decisions. The advisers, on the other hand, could see only one of the two cards, that is, they knew more than the advisees, but did not have complete information about the cards. Hence, their advice was not about the winning card participants should pick, but rather additional information about the number of one of the two cards. In each trial, participants were paired with a different adviser (adviser phase). After the adviser sent his advice (advice phase), the advisee decided which card she wanted to pick (decision phase). Finally, the cards were disclosed to the advisee (feedback phase), who could see whether the adviser had been honest and whether she won or lost in that trial. Participants could win/lose €1 in each trial by choosing the card with the higher/lower number. After the TAG, participants in the role of investor played a one-shot TG with each of the advisers now in the role of trustee (Fig.  ). Investors were paired with each trustee and received an initial endowment of 10 monetary units (MUs) that they could share with the partner. Investors were told that the shared amount would be tripled by the experimenter and passed on to the trustee who, in turn, could decide to share back any amount of it.   
Paradigms.   a   Schematic representation of the take advice game (TAG). Advisers were given information about one of the two cards and could communicate this information to the advisee. Participants, in the role of advisee, made a decision based on the information received (decision phase). In the feedback phase, advisees saw the actual numbers on the cards, which informed them about the adviser’s honest behavior (honest vs. dishonest), and a green or red circle, which informed them whether they won or lost, respectively.   b   After the TAG, participants in the role of investor played a one-shot trust game (TG) with the advisers now in the role of trustee. Investors received a monetary endowment and decided whether they wanted to entrust some of this amount with the trustees. Investors were told that the shared amount was tripled by the experimenter and passed on to the trustee, who could decide to share back any portion of the tripled amount. See also Supplementary Fig.  
  


### Link between honesty and trusting behavior 
  
First, we tested whether honesty is associated with higher trust levels across contexts and regardless of proximal gains. In the TAG, individuals should be more willing to take the advice of honest advisers and distrust the advice of dishonest advisers. Our results demonstrate that participants took on average more advice from honest than dishonest others (  t   = 3.68;   p   < 0.001; 95% confidence interval (CI) = [0.03, 0.10]; Cohen’s   d   = 0.7; Fig.  ). Importantly, participants grounded their decisions to take an advice in the trustworthy character of the adviser (i.e., whether the adviser was honest or dishonest;   β     =   0.38; standard error (SE) = 0.12; 95% CI = [0.14, 0.62];   p     =   0.007). On the contrary, monetary winnings and losses did not impact participants’ decisions to take an adviser’s advice (  β     =   −0.001; SE = 0.07; 95% CI = [−0.14, 0.14];   p     =   0.980; Table  ). This suggests that our participants trusted an adviser based on the adviser’s trustworthy behavior and irrespective of their proximal benefits. Indeed, the majority of our participants (  M   = 88.2%) explicitly reported in an exit questionnaire (see Methods) that their decisions were based on the trustworthiness and advice of the advisers. Importantly, participants applied such trustworthiness-based strategy even though they were aware that it was not successful to gain more benefits (  χ   = 13.68,   p     =   0.0002).   
Behavioral results.   a   Trusting behavior in the take advice game over runs (left) and on average (right) toward honest and dishonest advisers. On average, participants took significantly more advice from the honest than the dishonest adviser (  t   test). Data points on the left were interpolated for visualization purposes and shadowed areas represent standard errors. White lines in the box-plots on the right represent average advice-taking behavior across participants. Each black dot represents one participant.   b   Amount of money entrusted in the trust game with honest (left) and dishonest (right) others correlated with participants’ willingness to take advice from the advisers (Spearman’s correlations). Each dot represents one participant. ***  P   < 0.001 
    
Mixed-effects logistic regression analysis of advice-taking behavior 
  
 β   coefficients (standard errors) from the generalized mixed-effects logistic regression model with maximal random-effects structure predicting advice-taking behavior (1 = advice taken; 0 = advice not taken).   P   values were based on a likelihood ratio test 

 SE   standard error,   CI   confidence interval 

*  p   < 0.01; **  p   < 0.001 
  

Moreover, although trust in the other’s advice was comparable for both honest and dishonest advisers in the very first trials of the TAG, participants quickly adjusted their behavior to the other’s honesty over the course of the social interaction (Fig.  ). Indeed, participants’ advice-taking behaviors toward the two advisers differed increasingly over time (  β   = 0.01; SE = 0.006; 95% CI = [0.0001, 0.024];   p     =   0.048), especially due to a significant, linear decrease in trust in the advice of dishonest advisers (  β   = −0.02; SE = 0.007; 95% CI = [−0.028, −0.002];   p     =   0.021). On the contrary, advice-taking behavior toward honest advisers did not significantly change over time (  β   = −0.005; SE = 0.006; 95% CI = [−0.016, 0.007];   p     =   0.410). 

Second, we investigated whether these specific effects of the other’s trustworthiness on advice-taking behavior in the TAG generalize to a different context and measure of trust (i.e., the TG). Our results confirm this, showing that advice-taking behavior in the TAG correlated with subsequent, economic trust decisions in the TG on average (  ρ     =   0.39;   p   = 0.031), and separately for both honest (  ρ   = 0.41;   p   = 0.021) and dishonest advisers (  ρ     =   −0.37;   p   = 0.040). That is, the more likely participants were to trust the advice of an adviser, the more willing they were to entrust that adviser with money in a subsequent interaction (Fig.  ). As expected, the amount of money shared with the advisers in the TG did not significantly correlate with participants’ monetary winnings in the TAG either on average (  ρ     =   0.17;   p   = 0.350) or separately for the two advisers (honest adviser:   ρ     =   0.30;   p   = 0.106; dishonest adviser:   ρ     =   0.01;   p   = 0.978). These results confirm that economic trust decisions in the TG did not represent a form of repayment for the benefits participants obtained from the adviser’s advice in the previous interaction, but rather reflected participants’ willingness to trust the adviser’s honesty in advice giving. 

Finally, we checked the proportion of positive and negative feedback received by our participants. Participants received on average the same amount of positive and negative feedback (mean difference = 0.0013 ± SD   =   0.07;   t     =   0.11;   p   = 0.916), despite more positive feedback when interacting with honest than dishonest advisers (honest advisers:   M   = 63.5% ± SD   =   7.4; dishonest advisers:   M   = 56.7% ± SD   =   5.0;   t     =   4.09;   p   < 0.001). 


### Neural representations of trustworthiness 
  
Next, we examined the neural patterns of the advisers’ trustworthy character inferred from their honest behavior and value information related to participants’ performance. In doing so, we investigated whether these neural patterns capitalize on similar brain regions informative of individual trust. Our task design elegantly allows this, since in the feedback phase, participants received information about both the other’s trustworthiness (honest/dishonest behavior) and their own task performance (winnings/losses). Hence, by applying a whole-brain searchlight MVPA to neural activations during the feedback phase with a leave-one-run-out cross-validation (LOROCV) procedure (Fig.  ), we could separately decode trustworthiness and value information to identify brain regions belonging to a trustworthiness decoding network and value decoding network, respectively. To this end, a support vector machine (SVM) was trained on   β   parameters estimated using two general linear models (GLMs) that coded trustworthiness information (GLM1) and value information (GLM2) in the feedback phase (see Methods).   
Decoding honesty and predicting trust. In two MVPAs applied to the feedback phase of the TAG (  a  ), a support vector machine (SVM) was trained to decode honest and dishonest advice (GLM1) to determine the trustworthiness decoding network (upper), and to decode winnings and losses (GLM2) to determine the value decoding network (lower). The trustworthiness decoding network (  b  ) included brain regions such as the PCC, DLPFC, and IPS, and could successfully distinguish neural signatures of honesty and dishonesty in out-of-sample individuals (  c  ). The value decoding network (  d  ) included the striatum and ACC and could successfully distinguish neural signatures of winnings and losses in out-of-sample individuals (  e  ). Finally, a multivariate prediction analysis with support vector regression (SVR) showed that the neural patterns of the trustworthiness decoding network successfully predicted individual economic trust decisions in the TG, thereby showing across-context generalizability (  f  ). Both out-of-sample classification and prediction analyses were based on a leave-one-subject-out cross-validation procedure and their significance tested using a permutation test with 10,000 permutations. Each dot represents one participant. See also Supplementary Fig.   and Supplementary Table  . MVPA, multivariate voxel pattern analysis; TAG, take advice game; PCC, posterior cingulate cortex; IPS, intraparietal sulcus; DLPFC, dorsolateral prefrontal cortex; ACC, anterior cingulate cortex; TG, trust game. Heatmap represents   t   values 
  

The trustworthiness decoding network revealed clusters with classification accuracy above chance in the PCC, right and left DLPFC, and left IPS (cluster-level, family-wise error corrected, FWEc, <0.05; Fig.   and Supplementary Table  ). Signal in these brain regions was able to classify the neural signatures of honesty and dishonesty of out-of-sample individuals with 68% accuracy (sensitivity: 68%; specificity: 68%;   p   < 0.0001, based on a nonparametric test of 10,000 permutations; Fig.  ). On the contrary, the value decoding network consisted mainly of regions in the medial PFC extending from the anterior cingulate cortex (ACC) to the striatum (voxel-level FWE <0.05; Fig.   and Supplementary Table  ). Signal in these brain regions was able to classify the neural signatures of positive and negative outcomes of out-of-sample individuals with 82% accuracy (sensitivity: 87%; specificity: 77%;   p   < 0.0002; Fig.  ). Hence, these analyses indicate a specific neural network representing the other’s social character (i.e., trustworthiness) that could be separated from neural signal representing value information. To note, classification accuracy of value information was much better than classification accuracy of social character information. These results concur with previous findings  and may hinge on the nature of social concepts, which are distributed neural representations that might be difficult to fully capture using an anatomical-based searchlight approach. 

Finally, we set out to characterize the peculiar functional associations of the trustworthiness decoding network. We first ran GLM analyses to control for possible confounds of the observed neural patterns. In particular, we computed another GLM1 adding parametric modulators to the feedback phase for risk (as mean-squared deviation from the expected outcome given the adviser’s advice) and congruency (as deviance of the adviser’s advice from the actual card number on the advised card). These analyses revealed that our results hold also after controlling for these potential confounding factors (Supplementary Fig.  ). 

Second, using meta-analytic functional decoding (neurosynth.org) , we quantitatively evaluated the representational similarity of the trustworthiness decoding network with neural activation patterns associated with specific psychological components. In particular, we compared the neural signatures of trustworthiness in our study against reverse inference meta-analytic neural patterns of neural images of previous studies stored in the Neurosynth database and associated with particular psychological terms. For this analysis, we chose twelve terms associated with the social and nonsocial domains, such as social cognition, theory of mind, rewards, congruency and risk (Supplementary Fig.  ). Results demonstrate that the trustworthiness decoding network was preferentially associated with psychological terms related to mentalizing and social cognition (Supplementary Fig.  ), validating the ability of our task in singling out neural patterns that likely underlie the formation of trustworthiness beliefs about the advisers. Next, we set up to test this peculiar functional role of the trustworthiness decoding network in representing the trustworthy character of others. 


### Neural representations of trustworthiness predict trust 
  
A central feature of the neural representation of a character trait, such as trustworthiness, is its ability to inform decisions across contexts . Thus, neural patterns decoding the other’s trustworthiness (i.e., within the trustworthiness decoding network, but not within the value decoding network) should be able to predict individual trust decisions in the TG. To test this, a multivariate prediction analysis with a LOSOCV procedure was performed. Prediction significance was tested against a random distribution of 10,000 permutations. Results demonstrate that the trustworthiness decoding network significantly predicted the amount of money entrusted in the TG by out-of-sample individuals (standardized mean-squared error, smse, = 0.80;   p   < 0.007; Fig.   and Supplementary Fig.  ). On the contrary, the predictive model using the neural signal of the value decoding network did not yield a significant prediction (smse = 1.06;   p     =   0.84; Supplementary Fig.  ). By showing that neural patterns decoding trustworthiness information about others predict an individual’s willingness to trust in a different social context, these findings indicate a peculiar functional role of those trustworthiness-decoding brain regions in representing behaviorally relevant information about another person’s social character. 


### Stronger integration of honesty signals correlates with higher trust 
  
MVPA identified neural patterns of brain signal entailing information about another person’s trustworthiness that were informative of an individual’s trusting behavior and were different from neural patterns related to value information. To further characterize brain regions more strongly recruited by honesty and dishonesty, and to test whether and how honesty modulates neural responses to value information, whole-brain univariate analyses were performed on the brain signal during the feedback phase. 

Contrast analyses between honesty and dishonesty revealed that dishonesty more strongly activated bilateral DLPFC, left IPS and IPL (FWEc <0.05; Fig.   and Supplementary Table  ), while the VMPFC and ACC were significantly more engaged by honesty (FWEc <0.05; Fig.   and Supplementary Table  ). These results indicate a stronger reliance of dishonesty on brain regions within the trustworthiness decoding network, suggesting that dishonesty likely requires recruitment of brain regions representing the other’s character to constantly optimize one’s beliefs about the other. On the contrary, honesty more strongly relied on medial prefrontal areas associated with evaluations of positive qualities of others and self.   
Honesty vs. Dishonesty. Univariate contrasts revealed that brain areas within the trustworthiness decoding network (i.e., IPL and DLPFC) were more engaged by dishonesty than honesty (  a  ), whereas honesty more strongly recruited the VMPFC (  b  ). Error bars indicate standard errors across participants. Each dot represents one participant. See also Supplementary Table  . IPL, inferior parietal lobule; DLPFC, dorsolateral prefrontal cortex; VMPFC, ventromedial prefrontal cortex; a.u., arbitary units. Heatmap represents   t   values 
  

The definition of two separate GLMs (i.e., GLM1 and GLM2) was necessary to estimate separate   β   images to train the machine learning algorithms in our previous multivariate classification and regression analyses. However, this leaves the question unanswered as to whether the observed neural signatures for honesty and dishonesty are specific to social information processing or are confounded by neural signatures of nonsocial value information processing. We thus tested the specificity of our findings by comparing the univariate results yielded by the two separate GLMs with results of a single parametric GLM, including only one feedback regressor and two categorical, parametric modulators (one coding for value information and one for the adviser’s trustworthiness; see Methods). Notably, this single parametric GLM allowed us to control for spurious signal by orthogonalizing the two parametric modulators. As can been seen in Supplementary Fig.  , our results hold also with this GLM definition, suggesting that the observed neural signatures of trustworthiness are specific to social information processing. 

Next, as the VMPFC has previously been shown to be functionally connected with brain regions associated with social cognition during socially relevant computations , we reasoned that honesty signals in the VMPFC may be integrated into beliefs about the other’s social character via functional connectivity with brain regions associated with social cognition. To define these potential pathways, a task-dependent functional connectivity analysis was implemented using the VMPFC as seed region. This functional connectivity analysis shows that the VMPFC was more strongly coupled to the left pTPJ (−40, −50, 30,   x  ,   y  ,   z  ; FWEsvc <0.05; Fig.  ) during honesty encoding than dishonesty encoding. We then reasoned that if the information flow between the VMPFC and left pTPJ during the feedback phase were specifically associated with the formation of trustworthiness beliefs about another person, the strength of this connectivity should be related to subsequent trust decisions, but not to individual monetary winnings. Indeed, functional connectivity between the VMPFC and left pTPJ during honesty and dishonesty encoding in the TAG significantly correlated with the amount of money entrusted in the TG to honest (  ρ     =   0.54;   p   < 0.002) and dishonest (  ρ     =   0.48;   p   = 0.006) advisers (Fig.  ). On the contrary, no significant correlations were found between individual winnings and the VMPFC-pTPJ connectivity for either honest (  ρ     =   0.29;   p   = 0.111) or dishonest (  ρ     =   0.11;   p   = 0.542) advisers (Fig.  ). These results suggest that functional connectivity between the VMPFC and left pTPJ likely reflects integration of honesty information into knowledge about the other’s social character. Specifically, stronger integration of honesty signal from the VMPFC into the pTPJ led to higher trust in the adviser during a subsequent interaction, reflecting our behavioral findings that the advisers were trusted more later on the more participants believed them to be honest.   
Task-based functional connectivity analysis. Task-based functional connectivity between the VMPFC and left pTPJ was stronger for honesty than dishonesty (  a  ). Critically, this functional connectivity correlated with an individual’s willingness to trust in the TG (  b  ), but not with one’s payoffs in the TAG (  c  ) (Spearman’s correlations). Blue dots on correlation plots on the left represent behaviors toward honest advisers, orange dots on correlation plots on the right represent behaviors toward dishonest advisers. Each dot represents one participant. VMPFC, ventromedial prefrontal cortex; pTPJ, posterior temporo-parietal junction; PPI, psychophysiological interaction; a.u., arbitary units. Heatmap represents   t   values 
  


### Honesty biases value information processing 
  
We then turned to test whether and how these specific activation patterns of honesty and dishonesty modulate brain responses to value information during the feedback phase. Previous behavioral studies have suggested that positive qualities of others bias information processing . Such a bias may hinge on trait-dependent differences in neural responses to novel information. We tested this hypothesis by looking at how honesty and dishonesty modulate neural responses to positive and negative outcomes (i.e., GLM3, see Methods). 

We first examined the neural responses to positive and negative outcomes during interactions with honest and dishonest advisers separately. Positive outcomes during both interactions with honest and dishonest advisers elicited similar activations in the striatum, and for honest advisers, these activations extended to the OFC (Supplementary Table  ). Similarly, negative outcomes engaged the middle cingulate cortex and inferior frontal gyrus for both honest and dishonest advisers (Supplementary Table  ). Next, we investigated the modulatory effects of honesty and dishonesty on positive and negative outcomes. This analysis revealed that brain regions encoding positive and negative outcomes were differently modulated by the honest character of the advisers. In particular, neural signal in the parietal cortex was modulated by dishonesty during both positive (right IPL; FWEc <0.05; Fig.  ) and negative (left IPS; FWEc <0.05; Fig.  ) outcomes (Supplementary Table  ). On the contrary, modulation of neural responses to outcomes by honesty was found only in the OFC during positive outcomes (FWEc <0.05; Fig.  ). These results indicate an asymmetry in the neural responses to positive and negative outcomes for honesty.   
Modulation of neural responses to value information. Whole-brain contrast analyses from GLM3 on the feedback phase yielded significant activations in the parietal cortex for dishonesty during both positive (  a  ) and negative outcomes (  b  ). Honesty, on the contrary, modulated only positive outcomes in the OFC (  c  ). An ROI analysis (  d  ) indicated higher activity in the OFC in response to positive outcomes when interacting with honest advisers (  t   test). Error bars indicate standard errors across participants. Each dot represents one participant. See also Supplementary Tables  – . ***  P   < 0.001. ROI, region of interest; IPL, inferior parietal lobule; IPS, intraparietal sulcus; OFC, orbitofrontal cortex; a.u., arbitrary units. Heatmap represents   t   values 
  

Using an independent region of interest (ROI) in the OFC, we more closely examined in a post-hoc ROI analysis this asymmetric modulation of positive outcomes by honesty (Fig.  ). Activity in the OFC was significantly higher in response to positive outcomes when interacting with honest advisers as opposed to dishonest advisers (honesty:   M   = −0.08; SD = 0.46; dishonesty:   M   = −0.44; SD = 0.35;   t   = 4.72;   p   < 0.0001, CI = [0.21, 0.52]; Cohen’s   d   = 0.85), while OFC activity during negative outcomes was comparable for the two advisers (honesty:   M   = −0.45; SD = 0.71; dishonesty:   M   = −0.57;   SD   = 0.65;   t   = 1.16;   p   = 0.257, CI = [−0.10, 0.36]; Cohen’s   d     =   0.21). This asymmetry in the neural responses to positive outcomes in the OFC suggests that value information processing may be biased during interactions with honest individuals. 



## Discussion 
  
Understanding others is pivotal for successful cooperation. In particular, other people’s character may function as a proxy for their likely behavior in a future encounter. Thus, trustworthy partners are likely to be trusted in the future, while untrustworthy others are likely to be avoided. In this study, we showed that the honest character of an adviser makes people more likely to accept the adviser’s advice and more willing to trust the adviser in a subsequent interaction. Moreover, neural signatures of the partner’s trustworthiness in the DLPFC, IPS, and PCC predicted individual willingness to trust the partner later on, and stronger integration of an honesty signal from the VMPFC into the pTPJ correlated with higher future trust in the partner. 

When no prior information about how a partner will behave is provided, individuals try to gather evidence about the partner’s social character to inform their decisions about what to do when interacting with that partner. Over the course of multiple interactions, information about the partner’s current behavior lays the groundwork for the formation of beliefs about the other’s reputation . Consistently with previous models of trust , being reliable and telling the truth contributes to an honest reputation that made participants more likely to accept advice. On the contrary, when participants realized that their initial trust in the partner’s advice was misplaced, they increasingly discounted the advice of dishonest advisers. Interestingly, even though the adviser’s advice was not associated with the best option in the game and did not bring higher benefits to the participants, participants repaid the advisers for their honesty in advice giving during a future trusting interaction. 

As there were no incentives for the advisers to help the advisees (except goodwill or a good reputation) and the advisees did not commit to reciprocate, the dynamics in play in our study resemble real-life scenarios where individuals need to interact with each other without requirements or guarantees from the interacting partner. For instance, trusting someone to give good advice or keep a secret is an act of trust triggered by impressions of the partner’s trustworthiness without the requirement of an initial generous act by the partner . In these contexts, individuals likely assume that the other person would comply with the shared social norms, which represent a cluster of expectations an individual can use to make good-enough estimations of another person's behavior . Over the course of multiple interactions, individuals need to quickly infer the trustworthiness of the other person on the basis of what they have learned from their actual behavior and might eventually consider adopting better behavioral strategies for current and future encounters with that person . 

Thus, trusting someone else in a social interaction requires the ability to form a belief about the other’s character (i.e., who the other as a person is) and tailor one’s behavior to the other’s actions and intentions. In our study, we observed that the partner’s trustworthiness (inferred from her honest or dishonest behavior) was decoded in four brain regions (i.e., the PCC, left IPS, and bilateral DLPFC), which were able to successfully classify neural responses to honesty and dishonesty in out-of-sample individuals. In particular, recruitment of the PCC, a central hub of the mentalizing brain system , is likely related to cognitive processes associated with trait judgments , while the IPS, in line with its role in processing expectations related to current goals and stimulus–response selection , likely sustains attribution of temporary beliefs to tune action selection . Finally, the DLPFC might be responsible for translating the knowledge about the partner into action. In particular, in line with its role in generous decisions  and group-based cooperation , the DLPFC might be involved in the decision to engage in prosocial actions in response to the partner’s behavior. 

Crucially, these brain regions have previously been observed to be interconnected during interpersonal interactions. In particular, the left IPS shows selective connectivity with the DLPFC and PCC while understanding others during social interactions , suggesting that these brain regions build an intertwined brain network engaged in representations of socially-relevant qualities of others. These representations may underlie individual, behavioral attitudes based on which adequate behaviors tailored to the current partner’s character and reputation are flexibly adopted. Moreover, such representations might be retrieved in future interactions with the partner, as their content is informative of the partner’s character and is thus useful to sustain individual choices that strongly rely on those character impressions. In line with this, in our study, we observed that neural signal in the PCC, left IPS, and bilateral DLPFC predicted the future willingness to trust the partner in a social context (i.e., in the TG), where participants made trust decisions based exclusively on their trustworthiness impressions of the partner from the previous interaction (i.e., from the TAG). 

Critically, the IPS and DLPFC, together with the IPL, were also more strongly recruited by dishonesty as opposed to honesty. These findings are in line with previous evidence that the IPS is consistently activated by others’ non-cooperative behavior , and that the DLPFC, together with the IPL, tracks violations of expectations  and decisions to lie . The stronger recruitment of these brain regions by dishonesty might reflect the need to constantly track the behaviors of dishonest partners for an online belief updating and a flexible behavior revision. In fact, on the behavioral level, we observed that advice-taking behavior toward honest advisers did not significantly change over time, whereas participants continuously adjusted their advice-taking behavior for dishonest advisers with a consistent decrease of trust in them over time. These results suggest that the recruitment of the DLPFC, IPS, and IPL is more strongly required in cases of norm-deviant behaviors (e.g., when other people are dishonest, unfair, or noncooperative) to carefully track the other’s actions and optimally adjust one’s own behavior. 

On the contrary, honesty was observed to more strongly recruit the VMPFC, a brain region previously associated with behaviorally-relevant representations of positive traits of others . In particular, the VMPFC was functionally coupled to the left pTPJ during honesty encoding in the TAG, and the strength of this functional connectivity was further correlated with higher trust in the adviser during the later interaction in the TG. In line with the pTPJ role in processing inferences on others’ mental states  and social prediction errors , these findings suggest that inferences on the partner’s intentions undertaken by the pTPJ might be supported by integration of novel, incoming information about the partner’s honesty encoded in the VMPFC. Interestingly, a recent work has indicated that connectivity of the left pTPJ with other social cognition regions supports behavioral trust and that the experimentally-induced disruption of trust (via aversive affect) was concomitantly followed by the suppression of pTPJ connectivity during trust decisions. These findings suggest a pivotal role of pTPJ connectivity in integration of behaviorally-relevant signal . In our experiment, stronger integration of an honesty signal likely led to more positive beliefs about the partner’s intentions, increasing one’s willingness to trust. Thus, the interplay between the VMPFC and left pTPJ represents a central neural mechanism underlying integration of character information for behaviorally-relevant inferences on others’ actions and intentions. 

Finally, we observed modulation of neural responses to value information by honesty in the OFC during outcome evaluations. Specifically, higher OFC activity was observed for positive outcomes received when interacting with honest partners. These results suggest that in line with its role in processing subjective values of both social and nonsocial rewards , higher neural activity in the OFC reflects an enhanced subjective value of nonsocial rewards induced by the positive character of the interacting partner. These neural findings might provide a mechanistic explanation for the positivity bias toward individuals with a good reputation that has been observed to influence learning processes . Given the OFC role in learning mechanisms , an asymmetry in the representation of positive and negative events associated with an individual of good social qualities in the OFC might promote a stronger susceptibility to reputational priors and a reduced flexibility in the revision of one’s beliefs about the partner. Consistently with that, decreased OFC activity has previously been associated with stronger resistance to political belief change during information encoding . Hence, an asymmetric valuation of new incoming information likely contributes to judgmental biases and suboptimal learning. 

Taken together, our results improve our understanding of how neural patterns representing honesty-based trustworthiness guide social behaviors in interpersonal interactions. The PCC and frontoparietal brain regions represent behaviorally-relevant knowledge about the other’s social character, likely taking a role in the flexible revision of one’s current behavior for optimal adaptation to the partner’s actions. Further, social behaviors such as trust are likely enacted based on the integration of character information from the VMPFC into the left pTPJ for reliable inferences on the good intentions of the partner. Finally, an asymmetric activity in the OFC in response to positive outcomes due to the good reputation of the interacting partner likely jeopardizes an individual’s ability to optimally form and update one’s beliefs about the other, fostering a broad array of judgmental biases. 

Although we here showed that trustworthiness-related neural signal successfully predicts individual trust decisions in a future social interaction, future studies are still needed to investigate in a brain-to-brain predictive framework whether these neural signatures of trustworthiness are also able to predict the neural correlates of individual trust decisions. Further, future studies, especially in advice-taking paradigms, might also consider controlling for individual susceptibility to social influence, which might, for instance, explain an individual’s propensity to take advice from others. Another interesting research question for future studies relates to how other factors of trustworthiness impressions (like competence and benevolence) interact with honesty to elicit trust and/or distrust in others. By shedding light on how social characters are represented in the brain and influence individual decisions, this work makes an important contribution to the extant literature on human cognition in a broad range of scientific fields, such as neuroscience, social psychology, sociology, economics, and political sciences. 


## Methods 
  
### Subjects 
  
Thirty-one participants (20 females) participated in the experiment (age: 24.29 ± 3.81   M   ± SD). Participants were recruited from the student community at the University. They were all right handed and had no history of neurological or psychiatric disorders. Participants gave written informed consent after a complete description of the study was provided. All the procedures involved were in accordance with the Declaration of Helsinki and approved by the Ethical Committee of the University of Lübeck, Lübeck, Germany. 


### Take advice game 
  
In the TAG, participants played as advisee a card game with eight different advisers in a randomized order. Participants were told that these advisers were other participants who were taking part in the same experiment and were preparing themselves in other rooms. Participants were told that roles in the game were randomly assigned by drawing a ball with their role from a lottery box and that all participants were going to do it prior to the experiment. They were told that for transparency reasons, the ball-drawing procedure was going to be performed in front of a camera on top of a screen where each participant could see each of the participants in the other rooms drawing their role. However, to guarantee anonymity, all cameras were mounted on top of the screen so that each participant was recorded only up to the chin. Camera adjustments were performed prior to the ball-drawing procedure to assure this. Moreover, to further guarantee anonymity, each participant needed to choose an avatar that represented themselves in the game (Supplementary Fig.  ). In reality, participants received always the advisee role and the other videos were pre-recorded. 

As advisee, participants’ task was to draw the card with the higher number. Numbers on the cards ranged from 1 to 9 (except for 5). As participants did not have any information about the card numbers, they needed to rely exclusively on the adviser’s advice for their decisions (establishing an adviser–advisee interdependency necessary for trust). Participants were told that the advisers could see only one of the two cards (adviser phase: 2–3 s) and could communicate this information to them (advice phase: 1 s). This implies that although advisers had more information than our participants, they did not know which card was the winning one, making this setting similar to real-life scenarios in which people generally ask for advice those who may know better, but advisers rarely have complete knowledge of life situations. Participants also knew that advisers could help them but did not have any benefits in doing so. However, both partners knew that after the TAG they were going to play a second game (i.e., the TG, see below), in which participants could repay the advisers for their honesty in advice giving. Thus, in the TAG, advisers were motivated to form a good reputation in the hope that participants would repay them later on. To note, however, participants did not promise or commit to repay the advisers for their advice. The dynamics set into motion by this design resembles real-life interactions in which honest behavior (e.g., giving good advice) has often no proximal benefits to an individual but may help her form a good reputation that might turn out advantageous in the future (a possible, distal benefit). 

Moreover, to disentangle trustworthiness information about the advisers (honesty/dishonesty) from value information about participants’ decisions (winnings/losses), the advice of honest advisers was made unpredictive of the winning card (i.e., 50% of the time information about the losing card was provided by the honest adviser). Thus, cards were drawn from a uniform distribution with pseudo-random sampling without replacement. The pseudo-random sampling procedure was optimized to have a realized probability of card drawing that approximates chance in both conditions, as would be expected in random drawing. A two-sample Kolmogorov–Smirnov test confirmed that the realized distributions of card numbers did not differ between advisers (K–S test = 0.25;   p   = 0.929). Participants then chose one of the two cards (decision phase: 1 s) and saw a final feedback (feedback phase: 1 s) in which they received both social information (the card numbers based on which they could infer the adviser’s trustworthiness) and nonsocial information (a green or red circle representing winnings and losses, respectively). In each trial, participants could win or lose €1. Intertrial stimulus intervals were 2–8 s (  M   = 2.6 s) long, whereas jitters between trials were 2–8 s (  M   = 4 s) long. Participants played a total of 5 runs with 48 trials each (24 with honest and 24 with dishonest advisers) for a total of 240 trials. 

Advice-taking behavior in the TAG was operationalized as the probability of choosing a card given the informativeness of the advice received. The optimal strategy in the game would be to choose more frequently a card when the adviser communicated that a number bigger than five was on that card but choose the other card when the adviser communicated that a number smaller than five was on that card. Moreover, as we manipulated the advisers’ honesty with four honest advisers sending accurate information and four dishonest advisers sending inaccurate information (with 100% contingency), we hypothesized that participants would employ the optimal card-choice strategy differently for honest and dishonest advisers. Analyses of card choice probabilities confirmed our hypotheses (Supplementary Fig.  ). A repeated-measures analysis of variance with card numbers as repeated measure yielded a significant main effect of card number (  F   = 83.13;   p   < 0.0001;  ) with participants being more likely to choose a card when a number higher than five was said to be on the card and less likely to do so otherwise. Importantly, an interaction effect between card number and advisers was also found (  F   = 4.86;   p   < 0.0001;  ), suggesting that participants were more consistently employing the optimal strategy when interacting with honest advisers but not when interacting with dishonest ones. 

To test the hypothesis that this interaction effect was due to the difference in trust in the advisers and was not simply driven by differences between specific cards, we ran post-hoc   t   tests and compared the average choice probability for the honest and dishonest advisers for cards 1–4 and cards 6–9. Results indicate participants were less likely to choose a card when honest advisers told them a low number was on the card (honest vs. dishonest advisers for cards 1–4:   t   = −2.97;   p   < 0.006), but more likely to choose a card when honest advisers told them a high number was on the card (honest vs. dishonest advisers for cards 6–9:   t   = 2.88;   p   = 0.007). These results suggest that participants were discounting the advice of a dishonest adviser, likely because they did not believe it to be informative. In other words, this decrease in the likelihood of the use of the optimal strategy for dishonest advisers suggests a devaluation of their advice. Overall, these findings indicate that for the same piece of advice, the likelihood someone is going to take that advice hinges on their trust in the adviser or, complementary, on how much they value the adviser’s advice (i.e., recognize it as informative). 

Finally, it has to be noted that although the reputation dynamics set in motion by our design closely resemble real-life scenarios, the fact that advisers provided either correct or incorrect advice in every trial might not seem very realistic. As we had eight different advisers (four honest and four dishonest), the task was still challenging enough to look like completely unrealistic and participants needed to learn trial by trial the behavioral conduct of each adviser, as they were not instructed about the underlying behavioral contingency. We preferred a 100% contingency for the advisers’ advice-giving behaviors to, for example, a probabilistic instantiation thereof because we wanted to avoid that the multivariate algorithm for the decoding of neural signal related to the social character of the advisers might have picked some spurious signal evoked, for instance, by the partner’s behavioral inconsistency or prediction error associated with subjective expectancies. However, future studies might want to consider introducing some variability in the behavior of pre-programmed human-like agents. 


### Trust game 
  
After the scanning session, participants played as investor a one-shot TG with the same partners who advised them in the TAG. Participants were endowed with 10 MUs for each adviser in the role of trustee and decided whether they wanted to share any of this initial endowment with them (economic trust decision). They were told that any amount they decided to share would be tripled by the experimenter and passed on to the trustee who could in turn decide to share back any portion of this tripled amount (reciprocity decision). The TG was used to probe the transfer effect of the honest reputation established in the TAG on individual trust in a new social interaction. 


### Exit questionnaire 
  
To acquire an explicit measure of the criteria and motives behind participants’ behavior in the TAG, after the experiment, participants were asked to report whether they used any particular strategy and whether they thought this strategy was successful (binary answer option). Although a significant portion of participants reported that they used a strategy in the TAG (  χ   = 5.89;   p   = 0.015), except for four participants, no one believed it was successful (  χ   = 13.68;   p   = 0.0002). 

Moreover, they were also asked to describe the criteria for their decisions in the TAG (answering the question: “which strategy did you use for your choices in the first game?”). Three researchers blind to the study design and purposes categorized participants’ free answers. The first rater identified three main strategies. The second and third raters identified further subcategories for a total of seven and eight categories, respectively. These could be grouped into the three main strategies of the first rater (averaged inter-rater reliability:   r   = 0.64). For each rater’s category, we estimated the percentage of participants using a particular strategy. We then averaged the percentage of participants using each strategy across raters. On average, participants made their decisions (1) intuitively (  M   = 11.8%: rater 1: 9.7%; rater 2: 16%; rater 3: 9.7%), (2) based on the advisers’ trustworthiness (  M   = 55.9%: rater 1: 54.8%; rater 2: 51.6%; rater 3: 61.3%), or (3) based on the advisers’ advice (  M   = 32.3%: rater 1: 35.5%; rater 2: 32.3%; rater 3: 29%). Thus, the majority of our participants (88.2%) explicitly reported to have made their decisions in the TAG based on the adviser’s trustworthy character and advice. 


### Neuroimage acquisition 
  
Data were collected with a Siemens MAGNETOM TRIO 3 Tesla scanner at the Freie Universität Berlin. The fMRI scans consisted of an average of 360 contiguous volumes per run (axial slices, 37; slice thickness, 3 mm; interslice gap, 0.6 mm; repetition time (TR), 2000 ms; echo time (TE), 30 ms; flip angle, 70°; voxel size, 3.0 × 3.0 × 3.0 mm ; field of view (FOV), 192 × 192 mm ). High-resolution structural images were acquired through a 3D sagittal T1-weighted MP-RAGE (magnetization prepared-rapid gradient echo) (sagittal slices, 176; TR, 1900 ms; TE, 2.52 ms; slice thickness, 1.0 mm; voxel size, 1.0 × 1.0 × 1.0 mm ; flip angle, 9°; inversion time, 900 ms; FOV, 256 × 256 mm ). 


### Neuroimage preprocessing 
  
Neuroimaging data analyses were performed on SPM12 (v. 6905;   http://www.fil.ion.ucl.ac.uk/spm/software/spm12/  ) in MATLAB 2016b (The Mathworks, Natick, MA;   http://www.mathworks.com/  ). The functional images were slice-timing corrected, corrected for voxel displacement using field maps and realigned for head movement correction to the mean image. Using the unified segmentation procedure , functional images were co-registered to their structural images and subsequently normalized into MNI (Montreal Neurological Institute) space using deformation fields (resampling voxel size: 2 × 2 × 2 mm ). Finally, functional images used for univariate analyses were spatially smoothed using a Gaussian filter (8 × 8 × 8 mm  full-width at half-maximum) to decrease spatial noise. Movement outliers were identified and excluded if head movements/translations were above 3 mm/rad. One run of two participants met these criteria and was therefore excluded from all analyses. 


### Behavioral analyses 
  
Differences in advice-taking behaviors between honest and dishonest advisers were tested with a paired   t   test (two-sided). The effect size (Cohen’s   d  ) was computed as follows: (  M   −   M  )/  σ  , where   M   and   M   are the average advice-taking behaviors for the honest and dishonest advisers, respectively, and   σ   is the standard deviation of the behaviors’ differences. A generalized mixed-effects logistic regression was implemented to investigated whether trial-by-trial advice-taking behavior was predicted by the adviser’s honesty irrespective of the benefits associated with the act of trust. A model with the following four regressors was built to predict trust in the adviser’s advice (1 = trust; 0 = distrust): one regressor coding for the adviser’s honesty, one for the advised card, one for the advised number, and one for the feedback in the previous trial played with the current adviser. Random-effects structure was based on a ‘maximal’ approach with by-subject and by-item random intercepts and slopes .   P   values were computed with a likelihood-ratio test by comparing the full model with the same model without the fixed effect of interest, but that it is otherwise identical in random-effects structure . A mixed-effects regression was further fitted to the difference of advice-taking behaviors toward honest and dishonest advisers with run as fixed-effects time variable and subject as random intercept to test the increase of trust difference over time. Two similar mixed-effects regression models were then separately fitted to each advice-taking behavior toward honest and dishonest advisers in order to examine increases/decreases of trust in the two advisers over time. To test whether trustworthiness relates to subsequent economic trust decisions in a different social context, advice-taking behavior in the TAG was correlated with the amount of money invested in the TG (Spearman’s correlations). To further probe that trust decisions in the TG followed from participant’s impressions of the partner’s trustworthiness in the TAG and were not simply reflecting a repaying behavior, correlation analyses were performed between average winnings in the TAG and money invested in the TG. 


### Univariate and ROI analyses 
  
Two GLMs with eight regressors of interest (two for each task phase) on the first level were defined for both univariate and multivariate analyses of fMRI data to be able to estimate beta parameters that uniquely capture neural signals related to trustworthiness and value encoding, respectively. GLM1 consisted of the following regressors: two regressors for the advisor phase, two regressors for the advice phase, two regressors for the decision phase and two regressors for the feedback phase coding the adviser’s trustworthiness (honesty/dishonesty). GLM2 entailed the same regressors as GLM1, with the exception that the two regressors for the feedback phase coded value information (winning/loss). 

Control analyses were performed to check that the neural signatures of trustworthiness were not confounded by other factors. In particular, we re-ran GLM1 adding further regressors and parametric modulators to account for variance that might be due to risk and congruency effects. To control for risk, two orthogonal parametric modulators were added to the two regressors coding honesty and dishonesty in the feedback phase; namely, a first-order term for reward probability given the adviser’s advice and a second-order term for reward variance (i.e., the mean-squared deviation from expected outcome), which is quadratic in reward probability   p   and refers to the expected risk given the adviser’s advice . Second, to control for contingency effects (i.e., informational deviance between the adviser’s advice and the actual card number on the advised card), we added a regressor coding for all feedback phases (i.e., across advisers) with duration 1 s and degrees of congruency (continuous variable) as parametric modulator. Further, to control that the observed neural signatures for honesty and dishonesty are specific to social information processing and are not confounded by neural signatures of nonsocial information processing, a single parametric GLM was built with only one feedback regressor and two categorical, parametric modulators, that is, first one coding for value information (1 = winning, −1 = loss) and then one coding for the adviser’s trustworthiness (1 = honesty, −1 = dishonesty). The two parametric modulators were orthogonalized to be able to capture unique variance related to social information processing. 

Finally, to separately investigate brain activations for responses to positive and negative outcomes when interacting with honest and dishonest advisers, and to analyze the modulation of neural responses to value information by honesty and dishonesty, GLM3 was defined encompassing a total of 10 regressors of interest. All task phases had the same regressors as GLM1 and GLM2, except for the feedback phase, for which four regressors were defined coding winnings and losses received when advised by honest and dishonest advisers, separately. In all GLMs, conditions were modeled as events using a stick function (i.e., setting the duration of each condition to 0). 

Motion parameters were further included as regressors of no-interest in all GLMs. A temporal high-pass filter with a cutoff of 128 s was applied for all GLMs. Results were whole-brain corrected for multiple comparison using a voxel-level threshold of   p   < 0.001 and a FWE  corrected threshold of   p   < 0.05 . The ROI analysis for the OFC (area s32) to post-hoc examine the modulation of positive outcomes by honesty was based on the probabilistic map provided by the SPM Anatomy toolbox, v. 2.2 . 


### Multivariate voxel pattern analyses 
  
Decoding analyses to investigate the neural representations of trustworthiness (honesty/dishonesty) and value (winnings/losses) information were performed using a linear SVM algorithm for binary classification and a whole-brain searchlight approach with a searchlight’s radius size of 10 mm. Applying an LOROCV, the SVM was trained on all but one run and tested on the left-out run. This procedure was repeated   n   times with   n   = 5 (total number of runs) and the algorithm’s cross-validated accuracy was computed. To decode character information related to the advisers’ trustworthiness, β images from the feedback phase of GLM1 (fitted to unsmoothed, normalized brain images) were used. To decode value information related to winnings and losses, β images from the feedback phase of GLM2 (fitted to unsmoothed, normalized brain images) were used. Searchlight decoding analyses were applied to all voxels within the whole-brain gray matter probability mask provided by SPM and thresholded at 0.1. 

Decoding generalization of the trustworthiness and value decoding networks was tested with a classification analysis using an LOSOCV approach in which the SVM was trained on   z  -scored average β images of all but one participant and tested on the left-out participant. Cross-validated accuracy of the group-level classification was tested for significance running a permutation test with 10,000 permutations (  n_perm  ). In each permutation, the SVM was trained on randomly permuted labels using the same LOSOCV approach of the true classification model. The sum of models trained on permuted labels that performed better than the true model was then computed (  p_models  ). The nonparametric   p   value was assessed including the observed statistics according to the following formula : (1 +   p  _  models  )/(1 +   n  _  perm  ). Multivariate prediction analyses to predict subsequent, economic trust decisions in the TG (individual averages of money entrusted to the advisers) from the trustworthiness and value decoding networks were based on the same LOSOCV procedure and permutation test but used support vector regression for prediction of continuous variables. 

Decoding analyses were run using The Decoding Toolbox TDT, v. 3.99  and custom MATLAB scripts. 


### Meta-analytic functional decoding 
  
To characterize the functional specification of the trustworthiness decoding network, a meta-analytic image decoding analysis was performed using the Neurosynth Image Decoder (neurosynth.org) . The Neurosynth Image Decoder allows to quantitatively estimate the representational similarity between any task-based activation pattern and meta-analytical activation patterns associated with particular terms and generated based on brain images in the Neurosynth database . Similarity was computed as Pearson’s correlations across all voxels between the task-based and the meta-analytical maps. We selected meta-analytic maps based on 12 different terms to test the specific a priori hypothesis that the trustworthiness decoding map more likely related to functional roles in the social domain as opposed to the reward, risk, and congruency domains. It has to be noted that the observed correlations are relatively small but in line with previous research . Moreover, while the analysis is quantitative, the conclusions that can be drawn are descriptive in nature, as there is no inference statistics that tested whether any of the observed correlation coefficients is significantly higher than the others. 


### Task-dependent functional connectivity analyses 
  
To test the information flow between the VMPFC underlying honesty signals and any regions across the whole brain, a task-dependent functional connectivity analysis was implemented using a whole-brain psychophysiological interaction (PPI)  analysis with seed region (10 mm radius) around the VMPFC peak coordinates yielded by the univariate contrast. The PPI-GLM consisted of a task regressor, a physiological regressor entailing deconvolved blood-oxygen-level-dependent signal from the seed region and a regressor for the interaction term with movement parameters as regressors of no interest. Significant connectivity was assessed with a voxel-level threshold of   p   < 0.001 and an FWE cluster-level threshold of   p   < 0.05 within the ROI . 


### Labeling and data visualization 
  
The SPM Anatomy toolbox v. 2.2  and MRIcron (  http://people.cas.sc.edu/rorden/mricron/install.html/  ) were used for anatomical labeling. MRIcroGL (  https://www.mccauslandcenter.sc.edu/mricrogl/home/  ) was used for brain visualizations. 


### Reporting summary 
  
Further information on research design is available in the   linked to this article. 



## Supplementary information 
  




 ## Data availability

The data that support the findings of this study will be provided to all readers upon request. ## Code availability

All relevant MATLAB code is available from the corresponding author upon request. </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-51'>
<h2>51. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31747689/' target='_blank'>31747689</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Action perception recruits the cerebellum and is impaired in patients with spinocerebellar ataxia</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Brain</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1093/brain/awz337</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/7409410/' target='_blank'>7409410</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study reports functional MRI in healthy adult participants performing tasks that probe perception and understanding of others (action observation and weight-discrimination from observed hand actions), which maps onto the review construct ‘Perception and Understanding of Others’. The paper includes at least one group of healthy participants (n=79 across experiments; n=31 controls in the behavioral/clinical comparison) with results reported separately from the patient group. Analyses used whole-brain preprocessing/normalization and GLMs (MNI normalization, whole-brain maps and whole-brain contrasts are reported, including fusiform activations), not ROI-only analyses. Therefore it meets all inclusion criteria and does not violate exclusion criteria (not ROI-only; includes healthy participants’ whole-brain results).</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Using a combination of neuroimaging and behavioural studies, Abdelgabar   et al.   show that the cerebellum helps us perceive the actions of others. Disorders such as spinocerebellar ataxia type 6, which disrupt cerebellar functioning, impair our ability to perceive the kinematics of other people’s actions, with potential implications for social cognition. 
  
Our cerebellum has been proposed to generate prediction signals that may help us plan and execute our motor programmes. However, to what extent our cerebellum is also actively involved in perceiving the action of others remains to be elucidated. Using functional MRI, we show here that observing goal-directed hand actions of others bilaterally recruits lobules VI, VIIb and VIIIa in the cerebellar hemispheres. Moreover, whereas healthy subjects (  n   = 31) were found to be able to discriminate subtle differences in the kinematics of observed limb movements of others, patients suffering from spinocerebellar ataxia type 6 (SCA6;   n   = 21) were severely impaired in performing such tasks. Our data suggest that the human cerebellum is actively involved in perceiving the kinematics of the hand actions of others and that SCA6 patients’ deficits include a difficulty in perceiving the actions of other individuals. This finding alerts us to the fact that cerebellar disorders can alter social cognition. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (48947 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
The ability to perceive hand actions of others plays a key role in our ability to learn fine motor skills from conspecifics and interact successfully with them in cooperative and competitive settings. Cerebral cortical regions involved in motor control, including the premotor cortex and inferior parietal cortex, where mirror neurons were found in the monkey ( ;  ;  ;  ;  ;  ;  ), as well as the primary somatosensory cortex (SI) ( ;  ;  ), have all been shown to be necessary for extracting subtle information from the observed kinematics of hand actions ( ;  ). A powerful task to reveal the impact of disturbing these cortical regions requires participants to judge the weight of an object lifted by another individual ( ;  ;  ). This task depends on the ability to transform subtle kinematic cues into a weight estimate in that participants rely on the velocity of movement when the object is lifted from the table to determine the weight of the object ( ). Perturbing activity in the premotor cortex and SI disrupts the ability to perceive the weight ( ;  ), suggesting a causal role of premotor and somatosensory region in action perception. 

The cerebellum is a key partner of these neocortical brain regions during motor control, where its role is well established ( ;  ). It is perhaps not surprising that some have speculated that the cerebellum may also play a role in the perception and prediction of the kinematics of observed hand actions. Specifically, it has been proposed that the cerebellum could leverage its forward models (i.e. neural computations that transform motor signals into expected sensory consequences) to predict the actions of others ( ;  ;  ;  ;  ). Although this proposal is intuitively appealing, we still have little evidence for the cerebellum being a reliable and even necessary node of the action observation network ( ). This is because functional MRI evidence for its recruitment during action observation is mixed, and very few neuromodulation or lesion studies have explored the impact of cerebellar disruptions on hand action observation. 

With a few exceptions, imaging studies on action perception have typically focused on the involvement of the neocortex, leaving the information about cerebellar activity limited to what the field of view of functional MRI of these studies usually included, i.e. the dorsal cerebellum ( ;  ,  ;  ;  ;  ;  ;  ;  ;  ;  ). Several other experimental studies fail to observe cerebellar activation to hand action observation ( ,  ;  ;  ;  ;  ;  ;  ). This inconsistency is also reflected in meta-analyses of action observation studies, with some finding no ( ) or very limited cerebellar activations ( ), and others finding several clusters ( ). In their extensive meta-analysis, Van Overwalle   et al.   found that only 28% of the reviewed studies investigating action observation report cerebellar activity. The degree to which these inconsistencies depend on data acquisition and data analysis pipelines not optimized for the cerebellum is difficult to estimate   post hoc  , and experiments that optimize methods for the cerebellum, assess the reliability of activations in individual participants, and assess replicability across studies are required. The first part of this manuscript will therefore present four functional MRI experiments that map and replicate the recruitment of cerebellar voxels during hand action observation using MRI acquisition and analysis methods optimized for the cerebellum. These studies highlight that lobules VI and VIII of the cerebellar hemispheres are consistently recruited by action observation. 

However, to establish whether the cerebellum causally contributes to hand action observation, its activity must be perturbed and the impact on action perception measured. Unfortunately, only two studies have taken that route so far. First,   showed that four patients with tumours in the left lateral cerebellum (but not those with lesions in the vermis) were impaired in their ability to detect whether a point-light walking motion was embedded in random dot motion of that locomotor activity. However, the motor control of routine walking and of skilled hand actions is fundamentally different, as demonstrated by the fact that lesioning the pyramidal tract that transmits the cortical output to the spinal cord leaves routine treadmill walking unaltered ( ), but severely impairs skilled hand actions ( ;  ;  ). Second,   tested the involvement of the cerebellum in the perception of action sequences. They showed eight participants affected by cerebellar ischaemia sets of four still photographs taken during an action (e.g. opening a bottle and pouring a glass of water). One of the four pictures did not fit the temporal sequence of the action, and the task was to identify which one was the intruder. They found the performance of five of the cerebellar patients to be below the range of the 16 healthy control subjects. While this study does not explore the processing of the subtle kinematic cues, it provides the first evidence that cerebellar impairments can affect the ability of participants to identify acts not belonging to a particular action sequence. However, while dozens of studies in hundreds of participants establish that premotor and parietal regions of the neocortex are necessary for the optimal perception of observed actions ( ;  ), the necessary role of the cerebellum in hand action observation hinges on a single study with eight patients that does not directly test kinematics. In the second part of the study we therefore aimed to provide new evidence for a contribution of the cerebellum to action perception, and the first evidence for its role in processing subtle kinematic cues during hand action perception. To this aim, we tested the ability of 21 patients with spinocerebellar ataxia of subtype 6 (SCA6) to detect the weight of a box by observing the kinematics of a hand lifting the box in a video setting. SCA6 is a rare late-onset neurodegenerative disorder characterized by ataxia and associated with a loss of Purkinje cells in the cerebellum ( ). A voxel-based morphology study points to loss of grey matter in the hemispheres of lobule VI ( ) as being the primary cause of the upper limb ataxia—adjacent to regions in which we found cerebellar activations to action observation in part one of our study. Task performance was compared with that of 31 age-matched control subjects. Participants were tested in (i) a condition in which a sleeve on the actor’s arm occluded muscle shape information, forcing participants to focus on the arm’s kinematics to judge the weight of the box (Sleeve); and in (ii) a condition in which the sleeve was removed to reveal information on the appearance of muscle contractions, which complements the arm’s kinematic information (NoSleeve). Comparing the two groups in the Sleeve condition will reveal whether the cerebellum is necessary for kinematic processing. Comparing the gain in performance across the two conditions (i.e. the NoSleeve − Sleeve performance difference) across groups will reveal whether the cerebellum is necessary to extract additional information from biological shape. 

The two main aims of our work are therefore to establish: (i) whether and where hand action observation reliably activates the cerebellum; and (ii) whether perturbations of cerebellar functioning impair the ability to process the kinematic and/or shape of observed actions. 


## Materials and methods 
  
### Experiments and participants 
  
See   for an overview. Experiment 1 was aimed at localizing cerebellar activity to action observation using different analysis pipelines, and at comparing the results between pipelines and those found in the literature. Experiments 2 and 3 tested the replicability of the results of Experiment 1 on two independent samples of participants, and on a different MRI scanner. Experiment 4 tested the impact of the weight discrimination task on the previously identified action observation network, and Experiment 5 was aimed at directly testing the involvement of the cerebellum in action perception by comparing the accuracy in weight estimation between SCA6 patients and matched controls.
 
  
Experiment overview 
    
All tested healthy participants had a normal or corrected to normal vision, and none had a history of neurological conditions or treatments. The participants tested in the MRI also met MRI safety requirements. 

The SCA6 patient group was recruited in collaboration with the Department of Neurology at the Erasmus MC Rotterdam ( ). The severity of disease progression was clinically assessed by a licensed neurologist using the Scale of the Assessment and Rating of Ataxia (SARA) ( ;  ). SARA includes eight items (gait, stance, sitting, speech disturbance, finger chase, nose-finger test, fast alternating hand movements and heel-shin slide) reflecting neurological manifestations of cerebellar ataxia ( ). SARA scores range from 0 to 40, with higher scores corresponding to higher progression. The average SARA score for our patients’ group (  n   = 17) was 11.38 ± 5.75 [standard deviation (SD); range: 2 to 21.5]. The 31 healthy participants that were recruited as the control group, matched the SCA6 group for age [  t  (50) = 0.96,   P   = 0.34], handedness (SCA6: 19 right-handed and two left-handed, Controls: 27 right and four left-handed, Yates corrected χ  = 0,   P   = 0.94) and gender (SCA6 15 female: 6 male, Controls 15 female: 16 male, Yates corrected χ  = 1.86,   P   = 0.17). However, our patient group contained fewer males numerically, an issue that is addressed in the control analyses. Control subjects did not receive a clinical assessment. 

All participants signed an informed consent in accordance with the Declaration of Helsinki. The functional MRI study protocols were approved by the medical ethical committee of the University of Groningen (METc2012/380), the ethics review board of the University of Amsterdam (2015-BC-4697), the Academic Medical Center of Amsterdam (W15_243#15.0288), and the clinical study protocol was approved by the Medical Ethical Committee of the Erasmus MC Rotterdam (MEC-2013-095). 


### Stimuli, tasks and paradigms 
  
#### Action observation task 
  
During the observation task participants watched 39 unique videos of a human right hand interacting with objects displayed on a table (ActionOBS) ( A). The 39 control videos displayed a hand movement without a meaningful object interaction (CtrlOBS). Experiments 1 and 2 also contained a third static condition, in which the hand rested close to the object ( ;  ). This static condition was not included in Experiment 3, and therefore not included in the group analyses. Conditions were randomized across participants and presented using the Presentation  software (Version 18.0, Neurobehavioral Systems, Inc., Berkeley, CA,   www.neurobs.com  ) in a single functional MRI run. Participants were instructed to pay close attention to the videos shown.
 
  
 Experimental tasks.   (  A  ) Action observation task. Example of 1 of 39 possible actions and its control, followed by the task structure. A = action; C = control; Ctrl = control; OBS = observation. The ActionOBS and CtrlOBS videos were grouped in blocks of 7 s. Each block contained three actions from the same condition, with a total of 13 blocks for each condition. Blocks were separated by a fixation cross for a random period of 8–12 s, displayed on a background that was visually similar to the table. (  B  ) Weight discrimination task. Frame extracted from the NoSleeve (  top  ) and Sleeve (  bottom  ) weight lifting condition, followed by the trial structure for the functional MRI (  top  ) and behavioural experiments (  bottom  ). In the functional MRI (fMRI) task the window of time participants were requested to answer was indicated by a weighing scale. In the behavioural task, clips were preceded by the number 1 or 2 denoting whether it was the first or second clip of the pair. The sentence following the video was translated from Dutch for illustration purposes. RT = participant’s reaction time. (  C  ) Kinematic analysis of the weight-lifting videos. Mean ± standard error of the mean (SEM) of the vertical velocity of the forearm as a function of weight relative to the onset of the videos, averaged over the Sleeve and NoSleeve conditions. Moments in which velocity carries significant information about the weight are marked in grey, as revealed by a one-way ANOVA comparing velocity across the three weights at   P   < 0.01. 
  

#### Weight discrimination task 
  
Participants performed a two-alternative forced-choice task, in which at every trial, participants had to choose in which of the two presented videos the heavier object was lifted. The 4-s video clips showed a human arm lifting an object. To avoid participants deducing the weight from object movement only (e.g. differences in object shaking during the lifting phase), a black panel occluded both the object and the hand from vision. To disentangle whether the contribution of cerebellum mainly comes from computation of action kinematics or from arm shape information, two versions of the task were created: (i) in half of the trials, the arm lifting the object was sleeved thus making the kinematic of the arm the only information available to perform the task (Sleeve); and (ii) in the other half, the arm was uncovered thus allowing both kinematic and shape information to be used (NoSleeve) ( B). During the video recording, the actor was instructed to lift one of three weights (2850 g, 900 g and 180 g) within 4 s. A metronome was used to time the lift, and a reference line was marked on the wall in front of the actor to help maintain the same lifting height throughout all videos. The actor was aware of the object weight to avoid hesitation in the lifting. Videos were recorded using a digital video camera (Sony DSRPDX10P) and edited using Adobe Premiere Pro (Version CS5, Adobe System Incorporated, San Jose, USA). As expected, the differences in weight lead to differences in the kinematic of the video-recorded actions that allow viewers to deduce the weight ( ). Clips showing the same lifted weight were never paired. In half of the trials the heaviest object was lifted first, in the other half as second. The order was randomized in Psychopy2 ( ). After the second clip, the task instruction was presented until the subject indicated his/her response. Before the beginning of the task participants performed four training trials. 

Some minor task differences were present between Experiments 4 and 5 ( B). 


#### Experiment 5: Behaviour 
  
Participants gave the response by pressing the arrow keys on a standard QWERTY keyboard using their right hand. Ninety-six trials were presented in total, and participants had the option to take a short voluntary break after the first half of the trials. 


#### Experiment 4: Functional MRI 
  
Participants indicated their responses by means of an MRI compatible button box. Participants used their left hand to select the first clip and their right hand to select the second. Stimuli were presented using Presentation  software. For the functional MRI experiment, a numerosity task was additionally introduced and intermixed with the weight discrimination task. Participants had to estimate and compare the number of moving dots shown in Videos 1 and 2 instead of weight. The movement of the dots followed the kinematic of the arm presented in the Sleeve and NoSleeve conditions, but the arm was not visible. As an error occurred in the randomization of this condition, and this task was not performed by the SCA6 group, the numerosity condition was not included in the group analyses. Seventy-two trials were presented in total (24 for each of the three conditions). 



### Functional MRI data acquisition 
  
All MRI datasets included an anatomical scan. Experiment 1 included one functional scan of the action observation task. Experiments 2 and 3 aimed at comparing the effect of different numbers of simultaneous slice acquisition on task-based functional MRI, and included four and five functional scans of action observation, respectively. The results of this comparison are the subject of a separate manuscript ( ). As participants of Experiment 1 only saw the videos once, we only included the first view of the action observation task, independently of the number of simultaneously acquired slices. Experiment 4 included two functional runs of the weight lifting task. These two runs were randomly presented between the four observation runs of Experiment 2. The scanning parameters were chosen to achieve a coverage of the entire cerebrum and cerebellum ( ). 


### Localization of cerebellar activations, impact of different analysis pipelines and replicability 
  
The impact of different pipelines on cerebellar task-based responses was analysed on data from Experiment 1. The four considered pipelines mainly differed in the order in which the preprocessing and first level subject statistics were computed, and in the normalization template. Because the comparison revealed a no clear advantage of using pipelines optimized for the cerebellum compared to the traditional one, the method and results of this comparison are presented in the   and  . 

All of the analyses included in the main text therefore follow the traditional approach that includes: slice-time correction, realignment of functional images to the computed mean, co-registration of the anatomical image to the mean, whole brain normalization to the MNI template (final voxel size: 2 × 2 × 2 mm) based on the parameter generated during the segmentation of the co-register anatomy, a smoothing with a 6 mm full-width at half-maximum Gaussian kernel followed by a general linear model (GLM). Analyses testing the possibility of activation leakage between the anterior cerebellum and the temporal cortex due to smoothing are reported in the  . 

For Experiments 1–3, the GLM included two standard box car predictors that modelled the ActionOBS and CtrlOBS video presentation. Experiments 1 and 2 also included a predictor modelling the static conditions. All predictors were convolved with the canonical haemodynamic response function (HRF). The last six regressors of no interest included the displacements and rotations along the three axes, determined during image realignment. The ActionOBS−CtrlOBS contrast was computed at the subject-level to generate action-specific activations for observation. Analyses of variance on the ActionOBS−CtrlOBS contrast values from Experiments 1–3 were also implemented to directly compare the results of the three experiments to each other (within-subjects ANOVA) as well as to baseline (one-way ANOVA). 

All analyses were run in SPM8 and 12 (Wellcome Trust Centre for Neuroimaging, UCL, UK) using MATLAB 7.14 (The MathWorks Inc., Natick, USA) with a bounding box size-adjusted to include the entire cerebellum [−90 −126 −72; 91 91 109], complemented by custom MATLAB scripts. Unless specified otherwise, all analyses were estimated within the cerebellar mask using the cerebellar anatomical map from the Anatomy toolbox (  http://www.fz-juelich.de/ime/spm_anatomy_toolbox  ) ( ,  ,  ;  ;  ;  ;  ,  ,  ;  ;  ). The Anatomy toolbox was also used to define regions of interest, and guide anatomical descriptions of clusters of activity. 

Unless otherwise specified, all statistical maps were thresholded at   P   < 0.05 with a minimal cluster size of 10 voxels. We chose peak-level familywise error (FWE) correction as we wished to (i) interpret activation of individual voxels, and, motivated by the inconsistencies of cerebellar activations in the literature; (ii) to limit the risks of type I errors. 

To investigate the consistency in location of voxels responding to action observation between participants and studies, we computed consistency maps ( ) ( ). However, as the consistency maps cannot confirm that voxels responding to action observations are present in all participants, we counted the number of activated voxels within each participant. This counting was done separately for the four cerebellar anatomical regions of interest (left and right lobule VI, and VIIb/VIIIa) shown to be involved in the execution of complex actions ( ), and for the cerebellum as a whole. Additionally, lobule V was used as a control region as it has been shown not to differentiate simple from complex actions. To compare the reliability of cerebellar activations with that of the cortex, the counting was done for three additional cortical regions, typically associated with the action observation network ( ;  ;  ): the premotor area [Brodmann area (BA) 44], the inferior parietal complex (PF) and the SI. 


### Localization of the weight discrimination task 
  
The GLM of Experiment 4 included eight boxcar predictors: three modelled the video presentation (i.e. from the beginning of Video 1 to the end of Video 2) associated with the Sleeve, NoSleeve and numerosity conditions; two captured the participant’s responses at the time the weighting scale was presented separately for the left and right hand; one captured text information given to our participants at the beginning and the end of the each session; one included button presses that happened outside the response window; and one included the four videos used for training (only for the first session). The six head motion parameters were again added as co-variates of no interest. Analyses of variance were used to compare the Sleeve and NoSleeve conditions to each other (within-subjects ANOVA), and to baseline (one-way ANOVA). As for Experiments 1–3, unless otherwise specified, the ANOVAs were computed within the cerebellar mask, at   P  <   0.05. 

To test whether the videos used for the weight estimation task elicited activity in the areas to be found active for general action observation, an additional GLM was computed within a binary mask obtained by the global null conjunction of Experiments 1, 2 and 3 [Exp1  OR Exp2  OR Exp3 ] (  t   = 2.06) from the one-way ANOVAs that included the ActionOBS–CtrlOBS from all three experiments. Results are shown at   P   < 0.05. 


### Analyses of behavioural data 
  
Task performance scores were calculated as proportion of correct responses. We checked their normality using the Lilliefors test. Performance for the Sleeve and the NoSleeve–Sleeve difference were normally distributed (both   P   > 0.12). The performance in the NoSleeve condition and the average score of Sleeve and NoSleeve violated normality (both   P   < 0.002). Accordingly, we used non-parametric tests as our main approach, and parametric analyses (ANOVAs and Bayesian analyses) were only used to supplement analyses for the Sleeve and NoSleeve–Sleeve difference. 


### Control experiments 
  
To explore whether visual cerebellar activity reflects differential motor activity, we recorded EMG activity from the right hand while participants viewed ActionObs and ActionCtrl vidoes ( ). To explore the effect of eye movements, we measured eye tracking data from four patients and seven healthy subjects for the weight discrimination task ( ) and also functional MRI activity while participants viewed the ActionObs and ActionCtrl videos while fixating a cross, and while performing eye movements without the action videos (  and  ). 


### Data availability 
  
Data are available online at   https://openeuro.org  .  



## Results 
  
### Localization of action observation activations in the cerebellum and their reliability 
  
Viewing goal-directed hand actions compared to control stimuli (ActionOBS–CtrlOBS) in Experiment 1 bilaterally recruits lobules VI, VIIb and VIIIa of the cerebellar hemispheres ( ,  A,   and  ).
 
  
Cerebellar activations to ActionOBS–CtrlOBS for Experiments 1–3 
      
 Reliability of cerebellar action observation activations.   (  A   and   B  ) In blue the maps presented by  , and the results of the ActionOBS–CtrlOBS contrast of Experiment 1 in the hot colour scale in (  A  ) and of the global null conjunction ActionOBS OR CtrlOBS for Experiment 1 in (  B  ), both at   P   < 0.05. (  C   and   D  ) ActioOBS–CtrlOBS related activity for Experiments 2 and 3, respectively.   P   < 0.05,   t   = 4.3. (  E  ) Activations common to Experiments 1–3. Yellow, blue and green contours indicate the borders of the clusters shown in   A  ,   C   and   D   to facilitate the qualitative comparison. (  F  ) Consistency map computed on the smoothed data for the ActionOBS–CtrlOBS (  P   < 0.001,   t   = 3.1) contrast across the three experiments. The hot scale indicates the number of participants for which a particular voxel was significantly activated by the ActionOBS–CtrlOBS contrast. (  G  ) Circles indicate the number of significant voxels a given subject had in each of the four cerebellar clusters of interest (black), in the control lobule V (grey), in total in the cerebellum (green), and in three cortical regions also commonly activated by the ActionOBS–CtrlOBS contrast (blue). The median is indicated by the red lines and numbers. Data are presented on a logarithmic scale and the number of participants having no voxels in a particular cluster is indicated in black on the   x  -axis. 
  
Overlapping our activations with action observation maps from the meta-analysis of   (blue clusters of  A) reveals only a small portion of the right lobule VI is common between the two maps. To test whether the limited overlap is due to subtracting our control condition, we overlapped the meta-analysis map with a global null conjunction of our conditions (i.e. ActionOBS OR CtrlOBS,   P   < 0.05,   t   = 2.8). The overlap remains limited to right lobule VI ( B).  

Considering this inconsistency, we (i) replicated the experiment on a different scanner in two new groups of participants; and (ii) explored how many of our participants have activations in the cerebellum. 

Replicating the analysis in new participants confirms the cerebellar recruitment, despite using different scanners and sequences ( C–E and   and  ).
 
  
Comparison between Experiments 1, 2 and 3 in number of voxels and peak distance per cluster of activity 
    
Looking at individual participants reveals that all but four (all from Experiment 1) of the 79 participants have significant activations to the ActionOBS–CtrlOBS contrast when tested at   P   < 0.001 (  t   = 3.1) within the cerebellum (green in  G). The majority (68/79, 86.1%) additionally had >10 voxels activated ( G and  ) and most had at least 10 voxels in each of the cerebellar lobules identified in the group (regions of interest encompassing lobule VI or lobule VIIb+VIIIa) (black in  G). A binomial distribution indicates that finding 10 or more voxels significant by chance at   P   = 0.001 in a region of interest of 2085 voxels (the largest region of interest we have) is highly unlikely (  P   < 2 × 10 ). To explore the spatial specificity of the activity in lobule VI further, we also performed this analysis for neighbouring lobule V, which harbours very few voxels responding in this contrast, with the majority of participants (78% for the left and 75% for the right lobule V) (grey in  G and  ) having none. 

To compare the reliability of cerebellar activations with those of the cerebrum, we took three regions consistently associated with the action observation system, BA44, the PF complex and SI ( ;  ;  ), and counted activated voxels in these regions subject by subject ( ). Chi  tests comparing the proportion of participants with zero voxels activated in the four cerebellar and six cerebral regions using Fisher’s exact test in R indicates that for Experiments 1 and 2 the proportion with zero voxels activated is larger in the cerebellum (Exp1,   P   = 0.001; Exp2,   P   = 0.004; Exp3,   P   = 0.86). When combining all three experiments, the difference in proportion becomes highly significant (  P   < 0.001), with the cerebral regions of interest hosting significant voxels in a larger proportion of participants than the cerebellar regions of interest. Consistency maps indicate that the right lobule VI hosts the most consistently activated voxel, with 30 participants having significant activations in that specific voxel ( F). 

In addition to examining the contrast ActionOBS-CtrlOBS, we also extracted the average activity within our cerebellar regions of interest separately for ActionOBS and CtrlOBS ( ). 

To ensure that the observed cerebellar activity was not due to more imitative motor programs during ActionOBS than CtrlOBS, we collected EMG data while a new group of 10 participants watched the ActionOBS and CtrlOBS stimuli outside the scanner. Results show no difference in muscle activity across ActionOBS and CtrlOBS [  F  (1,9) = 1,   P   = 0.33, BF  = 0.1] ( ). 

In summary, we found that our task reliably activates the cerebellum at the individual and group level, and across scanners and pipelines. In particular, we provide evidence for a consistent involvement of cerebellar lobules VI and VIIb and VIIIa in action observation, matching the involvement of these lobules during the execution of complex actions shown by  . Despite the replicability of our results across three experiments, we did find that cerebral activations remain more consistent than the cerebellar activity across individuals, possibly explaining why smaller studies in the past may have failed to emphasize cerebellar activity. 


### Cerebellar activation to the weight discrimination task 
  
Observing an arm lifting an object to judge its weight activates several regions of the cerebellum ( A and B and  ) (  P   < 0.05,   t   = 2.8). The responses to lifting movements overlap with the ALE meta-analysis maps ( ) beyond lobule VI, in both left and right lobule VIIa of crus I. Computing the GLM of the weight discrimination experiment within the global null mask of the previous three experiments shows that all clusters observed in Experiments 1–3 were activated by the observation of lifting movement ( C and D and  ).
 
  
 Functional MRI results of the weight discrimination task.   (  A  ) Voxels significantly activated by either the Sleeve (only kinematic information available) or the NoSleeve (both kinematic and shape information) condition (global null conjunction in SPM at   P   < 0.05,   t   = 2.8, min 10 voxels). In blue the clusters identified by  , as responding to action perception. (  B  ) Voxels activated by both (conjunction-conjunction in SPM) the NoSleeve and Sleeve conditions (  P   < 0.05;   t   = 4.5, min 10 voxels). (  C  ) Same as in   A   but within the clusters of activation found in Experiments 1–3 (Exp1 > 0 OR Exp2 > 0 OR Exp3 > 0). Results are shown at   P   < 0.05,   t   = 2.8, min 10 voxel. (  D  ) Same as in   C   but within the clusters of activation found in Experiments 1–3 (  P   < 0.05;   t   = 3.9, min 10 voxels). All activations are shown on the flat map of the cerebellum offered by the SUIT toolbox. 
  
What aspect of action observation is processed in the cerebellum? By disentangling the activity common to the Sleeve and NoSleeve conditions mentioned above (conjunction Sleeve and NoSleeve) from that specific to the NoSleeve condition (NoSleeve–Sleeve), we can attempt to identify regions involved in kinematic and shape processing, respectively. The eye-tracking maps from the control participants show that the two conditions are indeed explored differently ( ). When the arm was covered, participants focus similarly on the proximal and distal part of the arm [  t  (12) = 1.523,   P   = 0.154], but if no sleeve is present, participants focus significantly more on the proximal part of the arm [  t  (12) = −9.482,   P   < 0.001] that reveals shape information in the upper arm musculature. Results from the functional MRI data indicate that in contrast to the conjunction that revealed consistent cerebellar involvement for kinematic processing, at FWE correction at peak level nothing survives for both the Sleeve–NoSleeve and the NoSleeve–Sleeve contrast within the cerebellum (  t   = 4.42,   P   > 0.05), while 22 voxels in the fusiform area FG4 become apparent for the contrast NoSleeve–Sleeve when the analyses are run for the whole brain (  t   = 5.4,   P   < 0.05). Accordingly, the cerebellum is significantly recruited by the kinematic cues common to both conditions, but not by the differential shape cue that the NoSleeve–Sleeve contrast situates in the ventral visual stream instead. 


### Cerebellar contribution to action perception 
  
The Mann-Whitney U-test on task performance reveals a significant difference between SCA6 and control subjects for the Sleeve condition (  n   = 21;   n   = 31; U = 199.5;   P   < 0.009), in which participants depend on the kinematic information ( A). The same test reveals that the gain of performance in the NoSleeve compared to the Sleeve condition (i.e. NoSleeve performance – Sleeve performance) does not differ significantly across groups (  n   = 21;   n   = 31; U = 274.5;   P   > 0.34). Not surprisingly, the two groups therefore also differ when the total performance is considered, including both the Sleeve and NoSleeve trials (  n   = 21;   n   = 31; U = 183;   P   < 0.004). Using   d’   instead of per cent correct leads to similar conclusions. To explore whether our pattern of findings, which includes a significant group difference for the Sleeve condition and a lack of significant group difference in the gain of performance, might indicate that the cerebellum contributes to kinematic but not shape processing, we performed a Bayesian   t  -test in JASP. The Bayes factors (BF) in favour of the alternative hypothesis Controls > SCA6 are BF = 14.7 (Sleeve) and BF = 0.19 (NoSleeve–Sleeve performance). Accordingly, we have strong evidence for a group difference in kinematic processing (Sleeve), and moderate evidence for a lack of difference for shape processing (NoSleeve–Sleeve).
 
  
 Behavioural results.   (  A  ) Violin plot of the performance (per cent correct responses) in the weight discrimination task for the 21 SCA6 patients (red) and 31 control subjects (green) for the different conditions. *  P   < 0.05,   P   < 0.01 using Mann-Witney U tests to compare SCA6 versus controls group in each condition. (  B  ) Distribution of   P  -values obtained from the 8008 possible subsamples of gender-matched control groups, again using the Mann-Whitney U-test to compare the total score (Sleeve and NoSleeve trials together) across groups. (  C  ) The significant negative association between symptom severity (SARA) and total score in the weight perception task. The r-value reflects the non-parametric Spearman rank-order correlation. Higher SARA scores reflect more severe symptoms and predict more perceptual impairment. ns = not significant. 
  
To explore if this group difference in the performance could be due to the less than ideal matching on gender, we carried out two further analyses. First, we performed a parametric ANOVA on the performance in the Sleeve condition with two groups (SCA6 versus Controls) × 2 genders. The interaction of Gender × Group was not significant [  F  (1,48) = 2.66,   P   = 0.11], suggesting that the group difference does not depend on gender. Second, we created control groups that were exactly matched in gender to the SCA6 group by subselecting six males out of the 16 available in the control group, keeping all the 15 females. There are 8008 ways to subsample six males out of 16, and for each of them, we calculated the   P  -value for the group difference in total performance using the Mann-Whitney U one-tailed test. The median   P  -value across the 8008 subsamples was   P   = 0.016, and 7675 of the 8008 (96%) have   P   < 0.05 ( B). This confirmed that compared to the majority of randomly subsampled, gender-matched control groups, the SCA6 group shows impaired performance in our task. 

To explore whether there is a significant association between the severity of the degenerative disorder and the performance in our task, we calculated the Spearman rank order correlations between the total performance score and the SARA score for the 17 patients for which we do have the SARA score ( C). We found that the association is significant: R = −0.55,   t  (15) = −2.54,   P   < 0.022. 

Finally, to explore whether the perceptual impairment we observe in SCA6 patients would also be visible in implicit measures, we added eye-tracking in our last participants (four SCA6 and seven control subjects), which do not show any significant group difference ( ). Thus, even though the small sample size might have biased us to find only large group differences, the qualitatively similar pattern in the two groups suggests that SCA6 did not severely alter how subjects explored the stimuli in space and time. 



## Discussion 
  
Our primary aims were (i) to explore whether and where the cerebellum is robustly activated by the observation of hand actions of other individuals; and (ii) whether disrupting the cerebellum leads to significant impairments in hand action observation. 

Regarding activations, using scanning parameters that include the entire cerebellum (both in terms of field of view during acquisition and bounding box during analysis) we found that across three studies and a total of 79 participants, the cerebellum was consistently recruited by the contrast between goal-directed hand actions and meaningless movements of the hand close to an object. Single subject analyses confirmed that the cerebellum was recruited in all but four participants. More specifically, we found that activity is reliably induced in the lateral hemispheres of lobule VI, and in a cluster encompassing lobules VIIb and VIIIa. All these activations are bilateral. Without using smoothing, it is apparent that the dorsal cluster in lobule VI is distinct from activity in the ventral visual pathway, and is thus not the result of bleeding of activity from visual neocortical regions. Each of these clusters were found to be activated in the majority of individual participants. Together these results provide strong evidence that the cerebellum is consistently recruited by hand action observation. 

This raises the question of why former studies failed to consistently report cerebellar activations. Our comparison of pipelines identifies two potential reasons: (i) up to SPM8, the default bounding box for analyses prevented the identification of some of the cerebellar clusters; and (ii) most studies focusing on the cerebrum have to choose between a larger field of view (i.e. more spatial coverage) versus a shorter acquisition time (i.e. increased task sensitivity), which often ends in favouring a smaller field of view therefore cutting out the cerebellum in at least some participants. At the second level of analysis, if part of the cerebellum is missing in the field of view for some of the participants, this region is entirely removed from the search volume on which statistical analyses are computed across all subjects. This may have further reduced the consistency with which cerebellar activity is reported. Finally, a comparison between the number of participants activating our cerebellar regions of interest compared to classic cerebral regions of interest such as BA44 or PF, shows that the cerebellar regions of interest indeed are slightly less reliably recruited, providing an additional factor. Overall, our three studies provide clear evidence that with proper measurement procedures and analysis pipelines, cerebellar recruitment during hand action observation can be demonstrated. The finding that these same regions are also activated when using a different, weight judgement task shows that this consistency does not depend on a specific task. 

It is interesting that one of our complex action foci (ActionObs–ActionCtrl) was localized in the anterior part of lobule VI, which is where Schlerf and colleagues found activity when participants performed complex but not simple motor actions ( ;  ). Our second focus was in the posterior inferior lobule VIIb expanding into VIIIa, adjacent to the secondary sensorimotor finger map ( ;  ). Lobule V, associated with less complex actions, however did not show consistent visual activation, be it in the contrast or while comparing each condition against baseline ( ). This distinction is reminiscent of that in the cerebral cortex, where M1 is not consistently recruited by action observation, while the premotor cortex, involved in more complex motor control, is ( ). That regions involved in motor control become recruited during observation is in line with the notion that cerebro-cerebellar loops involved in fine kinematic control of hand actions may also serve as a valuable system to process fine kinematics of observed actions ( ;  ;  ;  ;  ;  ). Alternatively, cerebellar activity to action observation could reflect automatic imitation of complex actions more than the control stimuli, with the cerebellum simply executing imitative motor programs. That EMG recordings show no difference in muscle activity across ActionObs and CtrlObs speak against this interpretation. 

To explore whether the cerebellum is necessary for extracting information from the kinematics of the hand actions of others, we tested whether patients with SCA6 are impaired in a weight-lifting task that has been shown to depend on precise processing of hand movement kinematics ( ). Our results indicate that SCA6 patients are indeed impaired in their kinematic processing as borne out by a group difference in the Sleeve condition that impoverishes muscle shape information. This impairment was more pronounced in patients with more severe SCA6 symptoms. Interestingly, when we analysed the data of the stimuli without the sleeves, we found that muscle shape processing appears to be preserved, as Bayesian statistics confirm that the patients benefited from the additional muscle shape as much as the controls did. That both the SCA6 patients and their controls benefit from exposing the muscle shape in the NoSleeve condition speaks to the fact that our participants did use shape information. That they benefited equally suggests that shape information was not significantly influenced by SCA6, and fits with our interpretation that the SCA6 impairment in the sleeved condition could be explained by a perturbation of kinematic perception. These results complement the results of the only other study that has, to our knowledge, examined the impact of cerebellar damage in action observation ( ), in that the two studies probed different aspects of hand action observation. In the task of  , participants viewed four still frames of an action, and had to decide which was not part of that action. Solving that task does not require fine kinematic analyses, but an understanding of whether a particular hand-object interaction would be appropriate to achieve a particular goal. In our task, all videos show a hand successfully lifting an object, and performance thus depends on analysis of kinematics. That SCA6 patients were impaired in the Sleeve condition, in which kinematics was the primary cue, but could benefit from additional muscle shape, highlights that cerebellar degeneration particularly impairs kinematic processing. Moreover, these findings dovetail with our functional MRI results, which show consistent cerebellar activity for the kinematic stimuli (Sleeve), but not for the additional shape information provided in the NoSleeve condition. Future experiments comparing performance in action perception and non-biological motion analysis will be needed to explore whether these processes rely on partially distinct cerebellar substrates, or whether the action observation deficit we observed is part of a more general visual motion deficit ( ;  ;  ;  ). 

As the cerebellum is involved in eye movement control, we were concerned that patients may be compromised in their ability to follow the movements of the arm with their gaze. However, our control data obtained from a small number of SCA6 patients do not suggest severe impairments in how our patients deploy their gaze. Future studies could include functional MRI of SCA6 patients to explore where in the cerebellum degeneration alters task-related activity, and whether this includes regions associated with gaze-control. A previous voxel-based morphometry study points to a loss of grey matter in the hemispheres of lobule VI as the primary cause of upper limb ataxia triggered by SCA6 ( ), which is in close vicinity to and partly overlaps with regions in which we found cerebellar activations to action observation, but is lateral relative to the sections of lobule VI mostly associated with eye movements ( ). Data from an additional control experiment further suggest that the differential cerebellar activity is unlikely to be due to differential eye movements ( ). 

Based on functional MRI data alone, in 2009 we hypothesized the ventral premotor cortex (vPM), SI and parietal region PF could, via the cerebellum, map visual input, from high level visual regions, onto the motor machinery involved in performing similar actions ( ). Beyond confirming the visual activation of these regions (  and  ), and more finely localizing cerebellar activity, we now show that disorders affecting the cerebellum disrupt action perception as measured by weight judgement. The same task is also disrupted by altering activity in the vPM ( ) or SI ( ). Measuring brain activity while perturbing SI, we showed altering activity in one of these nodes disrupts activity of all of those nodes ( )—including the cerebellar lobule VI (  in  ). This suggests that much like action control ( ), action observation relies on a cortico-cerebellar loop that maps sensory input onto motor control structures (inverse models) and motor programs to expected sensory input (forward models). This loop brings descending information from our cortical network (includinf vPM, SI, PF, and inferior frontal gyrus/middle temporal gyrus) to the cerebellum (lobules VI and VIIb/VIIIa) and ascending information from the cerebellum back to the cerebral cortex ( ). Anatomical studies suggest the former occurs via the pons and the latter via the thalamus and interposed nucleus of the cerebellum ( ). In line with the latter, we also found robust thalamic activity ( ). Given the strong involvement of all these structures in kinematics rather than shape ( ), we propose that this loop transforms subtle kinematic cues into reportable perceptions of observed actions. Asking what each brain region individually contributes to this perception/action loop is perhaps as ill posed as asking what each part of a gear-box contributes to torque conversion—function emerges from the interplay of parts. Our Sleeve–NoSleeve data additionally suggest when perception can draw from shape cues, ventral visual brain structures around the fusiform gyrus additionally come into play, but studies investigating the causal impact of these regions onto tasks such as weight discrimination are, to our knowledge, still lacking.
 
  
 Information flow during action observation.   Circuit we propose to be involved in the perception of other people’s actions. Cortical regions send information to the cerbellum through the pons (blue arrows), and information processed in the cerebellum flows to the cortex through the thalamus (Thal) via the cerebellar nuclei (CN, green arrows). The different colours of the arrows between cortical regions indicate the direction of the forward and inverse model. Red crosses indicate that a perturbation of the activity in those regions (either by non-invasive brain stimulation technique or degenerative deficits) influences action perception. IFG = inferior frontal gyrus; MTG = middle temporal gyrus; PF = parietal region PF; PM = premotor cortex. 
  
In the light of our findings we believe that it is time to consider the cerebellum a reliable and necessary component of the network that allows us to process the kinematics of observed hand actions. Clinically, one of the core complaints of many stroke survivors and their spouses are impairments in social cognition ( ). These social sequelae are often not on the radar of neurological staff. We hope that by showing that SCA6 patients have deficits in perceiving the kinematics of the actions performed by other individuals—deficits that gets worse with the severity of the disease—our results contribute to an increased awareness that neurological disorders affecting the cerebellum could have consequences for social perception. Being impaired in perceiving what other individuals around us do is likely to impact the way we relate to others and thereby reduce our wellbeing. 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-52'>
<h2>52. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/25885446/' target='_blank'>25885446</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Dual Logic and Cerebral Coordinates for Reciprocal Interaction in Eye Contact</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2015</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0121791</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4401735/' target='_blank'>4401735</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study used functional MRI (dyadic fMRI) during an explicit social task (face-to-face eye contact), recruiting healthy adult participants (38 individuals; ages 18–33 with mean 22). Whole-brain preprocessing and group-level whole-brain analyses are reported (GLM, paired t-tests, cluster results with MNI coordinates and atlas labeling), and ICA on whole-brain dyadic data. Results are not limited to ROI analyses and healthy participant results are reported separately. Thus all inclusion criteria are met and no exclusion criteria apply.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
In order to scientifically study the human brain’s response to face-to-face social interaction, the scientific method itself needs to be reconsidered so that both quantitative observation and symbolic reasoning can be adapted to the situation where the observer is also observed. In light of the recent development of dyadic fMRI which can directly observe dyadic brain interacting in one MRI scanner, this paper aims to establish a new form of logic, dual logic, which provides a theoretical platform for deductive reasoning in a complementary dual system with emergence mechanism. Applying the dual logic in the dfMRI experimental design and data analysis, the exogenous and endogenous dual systems in the BOLD responses can be identified; the non-reciprocal responses in the dual system can be suppressed; a cerebral coordinate for reciprocal interaction can be generated. Elucidated by dual logic deductions, the cerebral coordinate for reciprocal interaction suggests: the exogenous and endogenous systems consist of the empathy network and the mentalization network respectively; the default-mode network emerges from the resting state to activation in the endogenous system during reciprocal interaction; the cingulate plays an essential role in the emergence from the exogenous system to the endogenous system. Overall, the dual logic deductions are supported by the dfMRI experimental results and are consistent with current literature. Both the theoretical framework and experimental method set the stage to formally apply the scientific method in studying complex social interaction. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (53468 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
In order to scientifically study the human brain’s response to face-to-face social interaction, the scientific method itself may need to be improved, so that both quantitative observation and symbolic reasoning can be adapted to the situation where the observer is also observed. 

Directly detecting two interacting brain responses is only now possible with the recent development of dyadic fMRI (dfMRI) [ ]. Although EEG [ , ] and MEG [ ] have been used for dyadic data acquisition, they are limited by their coarse spatial resolution. Also, MRI “hyperscan” (scanning a dyad from two different scanners) [ ] or fMRI with recorded video for social stimulation [ ] have also been utilized in the past to indirectly observe dyadic interaction. However, the video and audio links compromise some of the reciprocity between the dyad. The newly developed dfMRI has largely removed the instrumental limitations, and provides sufficient spatial and temporal resolution for directly measuring dyadic BOLD hemodynamic activation during face-to-face social interaction. 

Given the fact that the observers are also observed in the dfMRI experiment, most existing syllogistic logic seems insufficient in providing a deductive reasoning framework for the analysis and synthesis of dfMRI data. To systematically address one of the essential issues in social interaction studies—the entwinement between reciprocal and non-reciprocal response [ ]—a dual logic derived from abstract algebraic logic is established to provide a logical framework in which an interacting brain can be formulated by a dual system [ ]. Within the dual logic framework, a propositional model was created for distinguishing reciprocal and non-reciprocal brain responses during eye contact in the dfMRI experiment. Based on this model, dual logic deductions can analytically suppress the non-reciprocity and yield the dual systems for reciprocal interaction. 

Social neuroscience has accumulated a large amount of fMRI observations [ ], including many empirical data on eye gazing [ ]. However, in the study of social interaction [ – ], explicitly distinguishing between reciprocal and non-reciprocal components in their entwined BOLD responses has been elusive. By applying dual logic deduction in a dfMRI experiment, a data-driven dual systems [ ] for reciprocal interaction during eye contact can be derived. This dual system can subserve cerebral coordinate for reciprocal interaction (CCRI), and could have broad applications in general dyadic data analysis for filtering out non-reciprocal responses. An example of CCRI used in computing reciprocal coupling modes during eye contact is provided here. 

Given the vast context of the topic, the main focus of this paper is limited to dual logic, the CCRI, and an example of an application of the CCRI. The goal is to demonstrate that logical deduction can elucidate the dfMRI data and extracts deterministic aspects of the experimental results. The detailed dyadic interaction analysis is beyond the scope of this work. 


## Theory 
  
During social interaction such as eye contact, brain responses can be classified by a dual system: the exogenous system and the endogenous system. By definition, the exogenous system directly responds to any exteroceptive stimulus; the endogenous system can only be activated by interoceptive stimulus. The dual logic is proposed for deductive reasoning in these dual systems during the eye contact in the dfMRI experiment. 

In order to observe reciprocity in eye contact, the dfMRI experiment was designed as follows: Two subjects are laid on their sides, facing each other as in  . The relative positions of their eyes and faces are locked in position as shown in   to create a “laboratory eye contact” scenario. Two functional tasks are performed as shown in  . During the tasks, the two subjects are verbally instructed to open and close their eyes either simultaneously in task A, or alternately in task B. 
   The outline of the dfMRI eye contact experiments.  
The (a) illustrates the dual-head coil and the dyadic placement in a commercial MRI scanner; the (b) is a 3D rendering of a dyadic anatomical data set, which illustrates the physical stimuli and BOLD responses in the experiments; the (c) depicts the temporal courses of dyadic stimuli: eye opening and/or closing in the task A and B. 
  
To analytically distinguish reciprocal and non-reciprocal responses in the dual system in the eye contact experiment where only binary states of task (eyes open/closed) and response (activation on/off) are of concern, the dual logic is constructed as an extension of Boolean logic. Such a construct in abstract algebraic logic is detailed in Appendix A, where the binary logic   and     are for the exogenous and endogenous system respectively, and non-binary logic operations are defined for emergence from the exogenous system to the endogenous system. 

Within the dual logic framework, a brain in the dfMRI experiments in   can be formulated by a stimulus-response model shown in  , in which every stimulus and response are decomposed into two states for the purpose of distinguishing reciprocity and non-reciprocity. 
   A block diagram describes the exogenous-endogenous dual systems and their stimuli-responses model.  
The exteroceptive stimulus σ consists of   p   and   q   states for “seeing eyes only” and “seeing face without eyes”. The arising interoceptive stimuli π and θ are the dual pairs of   p   and   q  . The BOLD response Ω consists of exogenous response Ω  and endogenous response Ω . The exogenous Ω  can be further decomposed to two states   x   and   y   for “reciprocal responses and non-reciprocal responses; the endogenous Ω  can also decomposed to two states ξ and ψ which are the dual pairs of   x   and   y  . 
  
### Stimulus states 
  
In the experiment shown in  , reciprocity only exists when the dyad’s eyes meet. Thus, when a subject looks at his/her partner, the exteroceptive stimulus, “I see a face”, can be decomposed into: “I see eyes only, with either a direct or averted gaze” (  p  ), and “I see a face without eyes” (  q  ). Here,   p   and   q   are the state variables in the logic   for the two dichotomous states of the exteroceptive stimulus. Their logic values are binary “1” or “0,” corresponding to “true” or “false” of the propositions   p   and   q  . Such bi-state exteroceptive stimuli can be expressed by the matrix σ for algebraic logic operation. The functionality of the σ is the disjunction of first and second row of the matrix,
 
The   p   and   q   represent the exteroceptive stimuli of “seeing” a face. Their corresponding interoceptive stimuli π and θ can be described by the propositions “I mentalize eyes only” and “I mentalize a face without eyes” respectively [ ], which represent “mentalizing face”. Notice that in this eye contact experiment scenario, “seeing” and “mentalizing” not only are two independent processes but also can coexist. To fully capture such orthogonality and to avoid any degeneracy in algebraic logic expression, the logic values of π and θ are adapted to binary “  i  ” or “0”, corresponding to “true” or “false” of the variables π and θ in the logic  . Here, “  i  ” is the imaginary unit of the complex number. 


### Response states 
  
The cerebral response measured by BOLD effect (Ω) is modeled by the exogenous and endogenous dual systems. The exogenous response (Ω ) is activated by the exteroceptive stimulus (  p  ,   q  ); the endogenous response (Ω ) is activated by the interoceptive stimulus (π, θ). For the same reasons in describing stimulus, the response variables Ω  and Ω  are also depicted by logic   and   respectively. In order to untwine the reciprocal and non-reciprocal responses during eye contact, the Ω  can be further decomposed into two salient states: the exogenous reciprocal state (  x  ) that is only mediated by simultaneous mutual eye contact (  p  ), and the exogenous non-reciprocal state (  y  ) that can be induced by either   p   or   q  . Here   x   and   y   are the state variables in  , with truth-values “1” or “0” which correspond to ON or OFF of the exogenous activations regardless of their magnitudes. The Ω  can also be further decomposed into two states: the endogenous reciprocal state (ξ) and the endogenous non-reciprocal state (ψ). Here ξ and ψ are the logic variables in  , with truth-values “  i  ” or “0” which correspond to ON or OFF of the endogenous activations regardless of their magnitudes. 

In the binary logic   and   sets, if both the reciprocal and non-reciprocal states share a common cerebral region within either the exogenous or endogenous system, such overlapping can be easily expressed as   x   ∨   y   or ξ ∨ ψ. However, if overlapping occurs between the exogenous and endogenous system, Ω  and Ω , the truth-value may become complex 1+  i  , and quinary logic may be needed, (see Appendix A). Given that the concerns of this experiment are only binary in nature, i.e. opening/closing eyes or activation/non-activation, the   -   logic sets seem to be mostly sufficient, except in depicting the transition between the dual systems, which is detailed in the later sections and Appendix A. 


### Axioms 
  
At the state level, to establish the logical connection between the stimulus states (  p  ,   q  ; π, θ) and the response states (  x  ,   y  ; ξ, ψ), three axioms are postulated based on self-evident truth-tables and the duality principle from De Morgan logic: 

#### Axiom 1 
  
The exteroceptive stimulus   p  , with either direct or averted gazing [ ], is logically related to the disjunction of the exogenous reciprocal response (  x  ) and the non-reciprocal response (  y  ) by the logical connective of “material equivalence”, 


#### Axiom 2 
  
The exteroceptive stimulus   q   is logically related to the exogenous non-reciprocal response (  y  ) in “material equivalence”, 


#### Axiom 3 
  
The exogenous states (  p  ,   q  ;   x  ,   y  ) and endogenous states (π, θ; ξ, ψ) are dual pairs in the logic   and  , and they obey the duality principle in De Morgan logic. Since the dual pairs for ↔ and ∨ are ⊕ (exclusive disjunction) and ∧ (conjunction) respectively, the relations between the interoceptive stimuli and their responses in endogenous system become,
 
Although this axiom is a theoretical conjecture, it is supported by some computational and experimental evidence [ , ]. More importantly, the logical predictions based on these axioms are in agreement with the experimental data in this study, as well as current literature. The derivations of the three axioms are detailed in Appendix B. Based on these three axioms, all causal stimulus-response relations in this study can be logically deduced, as shown in  . 
   The dual logic.      


### The stimulus and response states in the original tasks 
  
To describe the stimulus in task A, substituting its two temporal stages (see and not-see) illustrated in   into its dichotomous states   p   and   q   in  , the stimulus matrices for both left and right subjects are:
 
For the task A’s cerebral response Ω , although its endogenous states are elusive, its exogenous reciprocal states (  x  ) are likely entwined with its exogenous non-reciprocal states (  y  ). The symbolic expressions for such entwinements in the exogenous system are explicitly described in  , where the response (Ω  = 1) can be the results of either (  x   = 0,   y   = 1), or (  x   = 1,   y   = 0), or (  x   = 1,   y   = 1). To suppress the non-reciprocal state   y   in the Ω , an additional task B is introduced, whose stimulus matrices for both left and right subject can also be derived from   and   as:
 
Due to the lack of eye contact, the cerebral response in task B (Ω  = 1) is the result of the only non-reciprocal response (  x   = 0,   y   = 1), as shown in  . Although neither task A nor B can result in an explicit reciprocal response, the collation (defined in Appendix A) between the states in task A and B can yield the desired states. Note that the functionality   f  (σ) defined in   for the four stimulus matrices in the   and   are the unit regressors in the task A and B ( ). 
   Truth table for BOLD responses in task A, B, A-B, and B-A.      

### The composite stimuli for reciprocal interaction 
  
Because only the proposition “I see eyes only” can induce reciprocity, the goal would be to generate a stimulus matrix that contains   p   only. Applying collation operation to the left subject, between σ (L) in   and σ (L) in  , will generate two composite stimuli:
 
In both σ (L) and σ (L), the non-reciprocal state   q   is removed (  q  ≡0). For the stimulus σ (L),   p   = (0 1) and   q   = (0 0) describe that subjects periodically see their partner’s eyes but not the rest of the face. Based on  , the functionality of stimulus σ (L) becomes   f  (σ (L)) =   p  . Moreover, the fact that all the truth-values in σ (L) remain real numbers after collation suggests that σ (L) is still a Boolean matrix in logic  , and is still an exteroceptive stimulus that stimulates the exogenous system. 

The result for σ (L) is much more significant and less intuitive. Referring to Appendix A, after being subjected to the collation operation,   p   has truth-value -1 which means “inconsistent” in the three-valued logic. Such inconsistency or “error” in the real Boolean logic   can be transformed to another self-consistent imaginary Boolean logic   by “-1 =   i  *  i  ” mapping in algebraic logic. The σ (L) clearly becomes two interoceptive stimulus matrices that contain stimuli π and θ, whose propositions are “I mentalize eyes” and “I mentalize a face without eyes.” Because the first and second imaginary matrices describe π = (0   i  ) and θ = (0   i  ) respectively, the functionality of task σ (L) then becomes   f  (σ (L)) = π∧θ. Thus, the collation operations in   and “-1 =   i  *  i  ” mapping convert the exteroceptive stimuli σ (L) and σ (L) into one exteroceptive stimulus σ (L) and one interoceptive stimulus σ (L). Most significantly, the σ (L) becomes the cause for emergence of the endogenous response due to inconsistency in the exogenous response. 

As a side note, the collations of the stimulus matrices for the right-side subject group yield different composite stimuli than those from the left-side subject group in   due to the phase difference in the stimulus time courses in  :
 
Unlike the left-side composite stimuli, σ (R) is not a pure exteroceptive stimulus, and σ (R) is not a pure interoceptive stimulus. Therefore their responses are mixtures of the exogenous and endogenous systems. This is because the initial phase in a complex number time series bears significant information. Meanwhile, since time-invariant feature in a dual system could be a more complicated issue beyond the scope of this study, no time shift in σ (R) to match the σ (R)’s phase is performed here. Fortunately, the BOLD responses that are statistically derived from the left-side group by mixed-effects analysis should apply to the right-side subject group in a standard brain space. Thus, in all the later text the σ  and σ  represent only σ (L) and σ (L) in this study. 


### The responses to the composite stimuli 
  
The logical deductions of the stimulus-response transformations (σ-Ω) for the composite stimuli (σ  and σ ) are listed in   as A-B and B-A, and their derivations are detailed in Appendix C. Based on the transformations, the cerebral responses for the composite stimuli are expressed in truth-table in   as Ω  =   x  ∧¬  y   and Ω  = ¬(ξ∧ψ)∧¬ψ. Notice that Ω  is only composed of the exogenous states, while Ω  is only composed of the endogenous states. Thus, the dual logic deduction results explicitly formulates that the exteroceptive stimulus σ  causes the exogenous response Ω  and the interoceptive stimulus σ  causes the endogenous responses Ω . 

According to  , the exogenous system activation (Ω  = 1) is the result of a reciprocal state (  x   = 1,   y   = 0), where the non-reciprocal   y  -state is suppressed. However, the endogenous system activation (Ω  =   i  ) is a superposition of both the reciprocal state (ξ =   i  , ψ = 0) and a default state (ξ = 0, ψ = 0), albeit the non-reciprocal ψ-state suppression. Note that the default state is neither reciprocal nor non-reciprocal. It is an intrinsic system embedded in the endogenous system, activated when the endogenous system emerges during dyad’s reciprocal interaction. With logical rigor and determinism, the Ω  and Ω  mark the cerebral regions where reciprocity occurs during eye contact, which can subserve a cerebral coordinate for reciprocal interaction (CCRI). 



## Methods 
  
### Participants 
  
The Princeton University institutional review board specially approved this study (IRB #4946). All participants gave informed and written consent based on the approved IRB. A total of 19 pairs (38 individuals) of subjects were enrolled in the dfMRI experiment. Most of the participants were university students. Their average, standard deviation, maximum, and minimum age were 22, 5, 33, and 18 years old. The numbers of pairs for female-female, male-female, male-male were 11, 4, and 4. There were 12 females and 7 males on the left side, and 14 females and 5 males on the right side. Prior to the scans, each participant took a behavioral test called “Inclusion of Other in the Self Scale” (IOS) [ ], for evaluating the closeness between the partners. The average scores for the left and right side subjects were 4.89 and 4.95 with standard deviations 1.45 and 1.39, which indicates the balanced intimacy level between left and right side subject groups. The IOS scale was 1 to 7 (7 for being the closest). 


### Experimental procedures 
  
All subjects were instructed to be natural and calm as much as possible while maintaining spontaneous facial expression during scanning. In task A, when they heard the verbal instruction “close”, the dyad should close their eyes simultaneously; when they heard the instruction “open”, the dyad should open their eyes simultaneously and make eye contact with either a direct gaze or an averted gaze according to their comfort. In task B, when they heard the instruction “one”, the right-side subject should switch to eyes open and the left-side subject should switch to eyes closed. When they heard the instruction “two”, the right-side subject should switch to eyes closed and the left-side subject should switch to eyes opened. All verbal instructions were delivered through headphones. 


### Data acquisition 
  
All functional, anatomical, and field mapping images were acquired on a 3T Siemens Magnetom Skyra MRI scanner (Siemens, Erlangen, Germany) using a custom-made dual-head coil [ ]. The functional protocol was a gradient-echo EPI. Its spatial parameters were voxel size ~4mm×4mm×4mm, FOV 500mm×254mm, slice thickness 4mm, 32 transverse slices, and slice order interleaved. Its temporal parameters were TR 2000ms, TE 30ms, echo spacing 0.52ms, 200 repetition volumes. Its 4D sampling matrix was 128×64×32×200. The field mapping protocol was a double echo gradient-echo sequence with TE1 4.92ms, TE2 7.38ms, TR 1230ms, echo spacing 0.58ms, flip angle 60, and the spatial sampling region identical to the EPI. The anatomical protocol was a 3D MPRAGE with voxel size 2mm×2mm×2mm, 96 coronal slices per slab, FOV 500mmx250mm, and 3D sampling matrix 256x128x96. In every dfMRI experiment, in addition to the task A and B described in  , a functional baseline data was also collected, in which the dyad were closing their eyes during entire scan session. 

The factory-specified homogeneous static magnetic field region for the Skyra is an ellipsoid with three axes: 50cmx50cmx45cm. When two medium-sized subjects are positioned as in  , both of their brains are just able to fit in the ellipsoid, so that dyadic anatomical images can fully capture both brains as shown in  . However, because the EPI sequence is more sensitive to field inhomogeneity, the functional images often miss part of the occipital lobe, see Supporting Information ( ). Given that the main focus of this study is to identify social brain, such as empathy or mentalization networks, excluding the occipital lobe here bears minimal consequences for now. 


### Data post-processing for the CCRI 
  
The BOLD responses for the task A and B (Ω  and Ω ) were calculated by group analysis of general-linear-model (GLM) regression. The exogenous and endogenous systems (Ω  and Ω ) were estimated by paired t-test comparison. Both were implemented by the software package FSL (Oxford University, UK) [ ]. The CCRI was the binary masks of the Ω  and Ω . 

In the preprocessing, each of the dyadic 4D functional data sets from the task A and B was first split into two monadic data sets for separating the left and right subjects. Then all of the monadic 4D data sets were put through motion correction, slice time correction, and brain extraction, as well as spatial smoothing with HMFW 8mm and temporal high pass filtering with a cut-off period of 60s. Each of the dyadic 3D anatomical and field mapping data sets was also split to two monadic data sets for separating the left and right subjects. Then all monadic 3D data sets were put through bias field correction and brain extraction. Note that during each data split, the sampling volume and coordinate information in the header of each monadic data file were reset in order to properly register to the standard MNI152 [ ] template. Meanwhile, since the brain orientations in dyadic data are different from the orientation of the MNI152 template, to avoid rotating all the functional data sets to adapt to the MNI152 template, the MNI152 template was rotated -90° for the left subject registration and 90° for the right subjects registration. The inversed rotation matrices and the new center offset were included in the file header so that the rotated standard images retained an accurate atlas label reading from the Harvard-Oxford Atlas [ ]. The registration contained three steps: First, the “weighted registration” function in FSL was used to initially register the functional data to the bias-corrected magnitude images in field mapping in six degrees of freedom (DOF), with the mask that 25% of the posterior part of image was masked out to avoid signal drops in the occipital lobes and to maintain that the frontal, temporal, and parietal lobes were accurately registered to the MNI152 standard brain. Second, the initially registered images were then registered to high-resolution anatomical images with 12 DOF. Third, the high-resolution images were registered to the standard MNI152 template with 12 DOF. 

After data preprocessing, Group GLM analysis was performed on the preprocessed monadic data sets from both task A and B. The hemodynamic response functions (HRF) were the block waveforms in   convolved by the first three eigen-components in the linear optimal basis set [ ]. The group average GLM for Ω  and Ω  were shown in Fig   and  . The paired t-test comparison for Ω  and Ω  were shown in  – . The activation labeling was based on the “Harvard-Oxford cortical structural atlas” and the “Harvard-Oxford subcortical structural atlas,” which are built-in features of FSL. In the end, the masks of Ω  and Ω  (1 for activation, 0 for no activation) became the CCRI. The atlas labels of Ω  and Ω  became the coordinate ticks in the CCRI, where exogenous and endogenous labels are indexed by real and imaginary numbers respectively, as shown in Fig   and  . 
   The group average GLM results for all left-side subjects.  
The (a) is the BOLD response in the task A, Ω ; the (b) is the BOLD response in the task B, Ω ; the (c) is the probabilistic atlas label distributions for the activations in both the task A and the task B. Note that the abbreviations of the labels’ names in this study are defined here. 
     The reciprocal BOLD responses due to eye contact.  
The (a) is the exogenous responses in which Ω  = 1 when (  x   = 1,   y   = 0); the (b) is the endogenous responses in which Ω  = 1 when (ξ = 1, ψ = 0) and (ξ = 0, ψ = 0). Here the (c) and (d) are the three orthogonal sections of the (a) and (b) respectively; the (e) and (f) are the probabilistic atlas label distributions for the exogenous-endogenous dual system, where the exogenous labels are indexed by real number, and the endogenous labels are indexed by imaginary number. 
  

### An example for applying the CCRI 
  
During eye contact, brain synchronization induced by reciprocal interaction can be decomposed into multiple coupling modes. Each mode represents a different interactive mechanism between dyadic brains. One way to estimate such coupling modes is to apply the independent component analysis (ICA) to the dyadic data from the task A. (Because only task A has eye contact.) The results of ICA are a set of independent components (IC) in which both reciprocal and non-reciprocal responses are entwined. By projecting the IC onto the CCRI, the non-reciprocal responses should be filtered out, and the reciprocal responses in each IC remain. 

The 19 dyadic data sets from the task A were processed in following three steps: First, since FSL can only handle monadic data, in order to assign labels to a dyadic IC with FSL, the dyadic data was first split and preprocessed, then the left and right monadic data were registered to the rotated left and right MNI152 standard templates respectively by using the same procedure as in the group GLM, then merged to form a registered dyadic data set. Second, group level tensor-ICA for all 19 registered dyadic data sets was computed by FSL/melodic and yielded 35 ICs.   selectively displays one of the 35 ICs. Third, in order to project the ICs onto the CCRI, each dyadic IC was split into two monadic data sets again. The split ICs for the left and right subjects were separately multiplied by the properly oriented CCRI first, and then processed for atlas labeling. The activated labels for the right subjects were indexed as a vertical axis. The activated labels for the left subjects were indexed as a horizontal axis. In this way, each coupling mode can be quantified by a matrix based on the labels in the CCRI, as shown in  . 
   One of the dyadic brain-to-brain coupling modes.  
The (a) is one of the independent components derived from the 19 data sets in the task A by group-level ICA. The (b) is the 2D matrix representation of the coupling mode after the IC is projected onto the CCRI. Note that each axis has real and imaginary regions that correspond the exogenous and endogenous labels respectively. All complex numbers and their corresponding labels are listed in the Fig   and  . Here the vertical axis is for right subjects and the horizontal axis is for left subjects. The (c) and (d) are the temporal course and the frequency response of the synchronized process that represented by this IC. 
  


## Results 
  
First of all, applying GLM on the baseline data (dyads closed eyes in entire scan) with the regressors in  , no BOLD activation was observed in dyads, which suggests that neither non-visual stimuli nor physiological coupling contribute to the BOLD responses in the task A and B. 

### The exogenous and endogenous systems Ω  and Ω 
  
The BOLD responses for the original tasks A and B, Ω  and Ω  respectively, are the group averages of GLM with the data from all the left subjects, as shown in Fig   and  , where the inference threshold is Z>2.3 and p-value<0.05. Note that no voxels exhibiting negative BOLD responses were observed in the Ω  and Ω . (Here the right-side subject group analysis is ignored because the logical deduction in   suggests that its paired t-test comparisons between Ω  and Ω  may not yield pure exogenous or pure endogenous response due to their regressors’ phase.) The probabilistic atlas label [ ] distributions for the activated brain regions in the MNI152 standard template [ ] are listed in  , in which the probability of each label is the average probability over the conjunction of the label’s mask (probability>15%) and activation maps (Z>2.3). The selected labels are grouped in six regions: the subcortex, the limbic lobe, the insula/operculum, the frontal lobe, the parietal lobe, and the temporal lobe. All abbreviations of the names of the labels are in  . Due to field inhomogeneity artifacts in the partial occipital lobe, all occipital labels are removed in this list. 

The BOLD responses of the exogenous and endogenous system for reciprocal interaction in eye contact, Ω  and Ω , were estimated by a paired t-test comparison between Ω  and Ω  in a group analysis. Both the exogenous system Ω  and the endogenous system Ω  are shown in Fig   and  , and their cross-section views in Fig   and  . Although the t-test threshold for generating Ω  and Ω  is lowered to Z>1.96 and p-value<0.05 for scoping finer differences, the inference threshold remains Z>2.3 and p-value<0.05 in clustering Ω  and Ω  to identify the dual system. The probabilistic atlas label distributions for Ω  and Ω  in the MNI152 standard template are listed in Fig   and   respectively, where the probability of each label is the average probability over the conjunction of the label’s mask (probability>15%) and the activation maps. Note that, to distinguish the dual systems, the labels in   are indexed by real numbers, and the labels in   are indexed by imaginary numbers. In a cluster analysis, three clusters are identified in Ω ; and seven clusters are identified in Ω . The names, vicinities, voxel sizes, maximal Z-scores, and MNI152 coordinates of the clusters are listed in  . Here, cluster size > 64 voxel, given that the spatial smoothing filter is 8×8. 
   The organization of the exogenous-endogenous system.      
Elucidated by the logical deductions in  , here Ω  is the data-driven exogenous system that responds to reciprocal exteroceptive stimulus   p  ; and Ω  is the data-driven endogenous system that are the responses to both reciprocal interoceptive stimulus π and emergence of the default state during eye contact. The binary masks of the Ω  and Ω  define the data-driven CCRI. 


### An example of using the CCRI to compute dyadic coupling modes 
  
The probabilistic ICA analysis (FSL/melodic) was applied on the dyadic (not split) data sets from the task A. With the mixture-modeling threshold set to 0.8, the group level ICA for all 19 paired data sets yielded a total of 35 ICs. 22 of the ICs had temporal courses that corresponded to the regressor of task A in   and had resonance peaks at 0.025Hz in their frequency response, as in Fig   and  , which indicated that these ICs were in synchrony with eyes opening and closing. Of the 22 eye-contact-related ICs, 14 of them had single and robust resonance peaks, while the other eight had multiple frequency modulations either due to motions or related to ventricles. Of the 14 robust eye-contact-related ICs, four of them were monadic (only activated on one side of subjects), and ten of them were dyadic. These ten dyadic ICs were selected as the exploratory coupling modes. Projecting these ten ICs onto the CCRI resulted in the coupling modes that are in dual system forms and likely contain only the reciprocal responses and default state activations. Here, only one of the ten coupling modes was chosen to demonstrate the application of the CCRI. The complete dyadic coupling mode analysis will be the subject of on-going research due to its extensive contents. 

IC #29 was chosen to briefly exemplify the application of the CCRI.   is the original IC #29. After both the left- and the right-side subjects’ activation maps were projected onto the CCRI, the left-subjects’ labels were distributed on both the endogenous (PCN/PAC, FMC/FP, PRG/POG) and the exogenous (CAU, PRG/POG, SGa). The right-subjects’ labels were distributed on both the endogenous system (PCN/PAC/CGp, FMC/FP) and the exogenous system (CGa/PAC, SMC/F1, T1a/T1p/T2a), as shown in  . This mode seems to illustrate the medial frontoparietal activation in social cognition articulated in the Ref. (8), in which the endogenous (FMC—PCN) between the left-subjects and the right-subjects are synchronized. In addition,   seems to also suggest that this endogenous coupling may be mediated by their exogenous coupling between the left-subjects and right-subjects. The temporal course of this process and its prominent 0.025Hz peak in its frequency response in Fig   and   indicate that this brain-to-brain synchronization occurs when the pairs have eye contact. 



## Discussion 
  
### The dual logic for the dual systems 
  
By expanding Boolean logic, the dual logic can symbolically formulate dual systems with an emergence mechanism. It introduces two original fundamental concepts: First, although it has been elaborated in literature that dual processes operate in significantly different ways in social cognition [ , ], such differences have not been rigorously formulated at the level of formal logic. Here, given the dual system model in  , as well as the binary nature of tasks (eyes open/closed) and responses (ON/OFF) in the experiments in  , the logical connectives between stimuli and responses in the exogenous and endogenous dual systems can be explicitly defined: The exogenous process operates with material equivalence (↔); the endogenous process operates with exclusive disjunction (⊕). Based on this definition, the exogenous process behaves as that of “if and only if a stimulus occurs, then a response is activated”; the endogenous process behaves as that of “if and only if a stimulus is unexpected, then a response is activated”. These are the precise characterizations for the “thermostat” aspect of the relation between the reflexive and reflective systems [ ]. The formal logic description of this relation is the duality principle in which ↔ and (⊕) are a dual pair that are bonded by De Morgan’s law. In the dual logic model for the experiment in  , the “↔” operation in the exogenous system is manifested in the first and second axioms; the “⊕” operation in the endogenous system is manifested in the third axiom. The first and second axioms are self-evident, which are detailed in Appendix B. The third axiom is a conjecture based on both a heuristic “thermostat” description of the dual system and the duality principle. It also seems to be consistent with recent evidence that suggests that ⊕ might be a slower and rule-based way of human brain function [ , ]. 

The second original concept is the use of complex binary numbers as logical truth-values for the dual system: (1, 0) for the exogenous system and (  i  , 0) for the endogenous system. At the fundamental algebraic logic level, the complex truth-value enables formulating emergence in dual systems. As detailed in Appendix A, the logic   and   are two closed binary logic sets for dual systems without concerning the transition process details between dual systems. However, if one has to logically formulate such a transition between the exogenous and endogenous system, binary logic may become inadequate. First, to formulate a basic process of comparison between expectation and proprioception, a three-value logic operation, collation, is defined in Appendix A. Its three truth-values are 1, 0, and -1 for true, false, and inconsistent. Comparing a proprioception to expectation in the exogenous system, if the result of collation is either 1 or 0, then the impact of the proprioception remains in the exogenous system; if collation yields -1, the inconsistency in the exogenous system triggers emergence of the endogenous response. Second, to avoid the degeneracy in describing that brain regions can be shared by the dual systems, the logical truth-value in the endogenous system should be orthogonal to its peer in the exogenous system. In algebraic logic, this can be achieved by a simple mapping -1 =   i  *  i   in a five-value logic, see appendix A. Thus, emergency can be formulated in two steps: collation and -1 =   i  *  i   mapping. 

In this specific experimental situation in which dyads are locked in eye contact and isolated from other mutual or environmental stimuli, given that the tasks (eye open/close) and responses (ON/OFF) are binary, the three axioms in Eqs ( – ) establish the foundation for dual logic deduction. Based on the axioms, the exogenous and endogenous systems can be identified, the non-reciprocal responses can be suppressed, and the existence and emergence of the default state in the endogenous system can be predicted, all by deductive approach. 


### The dual systems per the dual logic 
  
Conceptually, the exogenous-endogenous dual systems can be distinguished by their stimuli being either exteroceptive or interoceptive. Logically, the dual systems operate with different logic connectives that are either material equivalence or exclusive disjunction. In any case, they may slightly deviate from the traditional automatic-controlled dual system in social psychology [ – ]. Their functionality resembles that of the reflexive-reflective dual systems [ ]. Their organization is close to the data-driven externally-focused and the internally-focused dual system framed in cognitive neuroscience [ ]. 

The dual system responses Ω  and Ω  in   and   not only are consistent with the original neural correlates of the externally-focused and internally-focused dual processes [ ], but they also provide more complete brain organizations for the dual system. For the exogenous system where Ω  = 1 if and only if (  x   = 1,   y   = 0), not only does Ω  confirm lateral frontoparietal activation [ ], but it also identifies the regions that largely overlap with the mirror neuron system (F3o, SGa) [ ], imitation circuitry (T1p, mirror neuron) [ ], and the social empathy network (INS, CGa, imitation circuitry) [ ], as well as some afferent and efferent subcortex and motor cortices. For the endogenous system where Ω  = 1 if (ξ = 1, ψ = 0) or (ξ = 0, ψ = 0), not only does Ω  confirm the medial frontoparietal activation (FMC and CGp/PCN) [ ], but it also adds the left AG and FOC to the mix. This activation pattern resembles the DMN [ ], except for its left hemisphere dominant lateral asymmetry. Given that the DMN is usually in resting-state and its function seems to be self-referential (ξ = 0) [ ], its activation may offer evidence for the superposition of the reciprocal social state (ξ = 1, ψ = 0) and the default state (ξ = 0, ψ = 0), which is predicted in  . 

Such dual systems seem to be only activated in face-to-face reciprocal eye-contact. In a separate experiment, described in the Supporting Information ( ), gazing to the eyes in a pre-recorded face video did not prompt the same dual system activations, most likely due to lack of reciprocity. In that case, there is no lateral frontoparietal activation, especially no insular activation, in the exogenous system (A-B); and no medial frontoparietal activation in the endogenous system (B-A)—the DMN remains in resting-state. So it is fair to say that dfMRI can reveal some social brain behaviors that other methods cannot. The fundamental difference between the dfMRI and other methods is that it can capture the unfiltered reciprocity. 


### Emergence mechanism 
  
Although there could be many pathways between the exogenous and endogenous systems, the most obvious transition between the dual systems seems to happen at the cingulate. According to some influential theories, the anterior cingulate (CGa) may be engaged in monitoring conflicts with expectations [ ]; the posterior cingulate (CGp) may be engaged in regulating the balance between internally and externally directed cognition [ ] and in retrieving autobiographical memories [ ]; the cingulate and paracingulate may be responsible for agent recognition in the social domain (“me” and “not me”) [ ]. From an emergence point of view, these previous observations and theories could be nicely explained by the dual system and dual logic. Based on the data-driven CCRI, as shown in  , CGa and PAC are in the exogenous system while CGp and PAC are in the endogenous system. The logical description of the emergence from the exogenous to endogenous system has two steps: the collation that compares proprioception with expectation, and the -1 =   i  *  i   mapping that transcends exogenous inconsistency to the endogenous response. Apparently the collation operation seems to be the logical expression of monitoring conflict, so it should occur in CGa. From the truth table of the collation shown in Appendix A, if the proprioception is the same as the expectations, then the collation results are false (0), which indicates that no conflict is detected and no action is needed. If there is no expectation but proprioception is positive, then the collation result is true (1), the truth-value remains a real number, which suggests an exogenous activation. Most interestingly, if there is an expectation but no proprioception, then collation yields inconsistency (-1), which means conflict or error. Such inconsistency in the exogenous system prompts emergence of the endogenous system by the -1 =   i  *  i   mapping. Given the function of the CGp in regulating the balance between exogenous and endogenous, this mapping likely occurs in the CGp. Overall, during eye contact, saccade of the partner presents constant unexpected proprioception, which results in continuous inconsistency from collation and “-1 =   i  *  i  ” mapping. Such dynamic monitoring conflict and balancing the dual systems constantly recruit the CGa and CGp, and make the cingulate an agent-specific emergence site. 



## Conclusions 
  
The dual logic is proposed for explicitly formulating the dual systems and emergence mechanism between the dual systems. It’s one of the few initial attempts to use the closed logic system to analyze agent-specific observations, especially when the observer is also being observed. It offers a deterministic approach to complement the existing common statistical approaches in neuroimaging analysis. By applying the dual logic in the dfMRI experiment design and analysis, the data-driven exogenous and endogenous systems that delineate the dual logic deduction provide a generic CCRI in which the exogenous and endogenous system consist of mainly the empathy network and mentalization network respectively. Moreover, the logical interpretation of the data-driven endogenous activations elucidates the intrinsic and social characteristics of the DMN; the logical formulation of the transition between the exogenous and endogenous system elicit the role of CG in agent recognition in the social domain. Overall, the dual logic deductions are supported by the dfMRI experimental results and are consistent with current literature. Both the theoretical framework and experimental method set a stage to formally apply the scientific method in studying complex social interaction. 


## Appendices 
  
### A. Construct of a dual system with abstract algebraic logic 
  
In the well-established abstract algebraic logic approach [ ], a logic problem can be transformed to algebraic forms, and resolved with algebra, and transformed back to a logic solution. Given the dual system model in  , as well as the binary tasks (eyes open/closed) and responses (ON/OFF), the binary Boolean logic is mostly sufficient to formulate the dfMRI experiment in this study. Here the definition of the original Boolean logic is given as:
 
Here   wff   means well-formed formula. The truth-values are 1 for true and 0 for false. Although a two-value logic can have a total of 2  logic operations, all of them can be composed by a minimum set of operations ⊕, ∧, and ¬. The   can be transformed to the Boolean algebra
 
Here, the   Alg   is the transformation from logic to algebra. The   F  (  x  ) is the algebraic expression over variables   x  , and   x   has binary values 0 or 1. The logic operations ⊕, ∧, and ¬ coincide with the arithmetic operation +, *, and 1+x, meaning they have the same truth-table operation respectively. Note that addition (+) is performed modulo 2 here. As shown in  , the Br is a subset of a three-valued algebra
 
Here   x   has ternary values 1, 0, and -1. The arithmetic operation subtraction (-) is also performed modulo 2. Its corresponding logic operation (with the same truth-table operation,  ) is defined as collation with symbol ⊖. The logical meaning of 1 is true, 0 is false, and -1 is inconsistent. The practical explanation of the collation (  β   ⊖   α  ) can be described as α being the expectation value, β being the proprioception value. If the proprioception matches the expectations (either α = β = 0 or α = β = 1), then no action is needed (  β   ⊖   α   = 0). However, if the proprioception comes as unexpected (α = 0, β = 1), then the proprioception will prompt action to address the unexpected (  β   ⊖   α   = 1). More interestingly, if the expectation is there but the proprioception is not (α = 1, β = 0), then no proprioception can prompt action to address the unexpected, which results in inconsistency or “error” (  β   ⊖   α   = −1). 
   The transformation between the algebra and the logic.       Collation & Subtraction.      
Meanwhile,   also suggests that the algebra Cr is a subset of a five-valued algebra
 
Here   x   becomes a complex number that has quinary values 1, -1, i,-i, and 0. Note that binary algebra has 2  operations, ternary algebra has 3  operations, and quinary algebra has 5  operations. 

As illustrated in  , applying subtraction (-) over Br area (the 2-by-2 area at the upper left corner in  ) can yield -1. Its corresponding logic explanation is that applying the collation operation will generate an inconsistency in Boolean logic. However, in the algebra D, -1 can be mapped to   i  *  i   with the arithmetic multiplication operation. Given the entire algebra D (∀D), there should be existence of a subset algebra Bi (∃Bi),
 
Here   i  ⊙  i   =   i*i  , the imaginary unit self rotates 2π in the complex plane. If the corresponding logic to the algebra Bi is  , then a subset of   that is bonded with   by the duality principle can be constructed by
 
Here the superscript + represents dual. The   is constructed from the   based on the duality principle. Thus, inconsistency in the logic   prompts emergency of a consistent logic  . 

To avoid confusion, please note that the reason for using ⊕ to define base operation in   is because its logic operation and algebraic operation have the same truth-table. However, when the   is used to model the exogenous system for the experiment, its operation is defined as ↔ in the axiom 1 and 2, in which ↔ can be simply expressed as ¬⊕ in the  . For the similar reason, ↔ is used to define the base operation in   because it is the dual of ⊕. When the   is used to model the endogenous system for the experiment, its operation is defined as ⊕ in the axiom 3, in which ⊕ can simply expressed as ¬↔ in the  . 


### B. Derivation of the dual logic’s three axioms 
  
To determine whether the logical connectives in the first and second axioms are “material equivalence” (↔), and whether the connectives in the third axiom are “exclusive disjunction” (⊕), the truth-table method is employed to avoid ambiguity of the English language. The complete derivation process is shown in  : First off, assuming that all truth-values in the “connective” columns are unknown, then using the exhaustive method determines their values based on self-evidence and the duality principle. Once the truth-tables are completed, the connectives can be uniquely determined. 
   The truth table for the premises.      
The first axiom in   is basic stimulus-response logic for eye-contact in the exogenous system. Generally, it is not only self-evident but also well articulated that seeing other’s eyes (direct or averted gaze) will prompt either social interaction or emotional responses [ ]. In order to use a truth-table to fully describe this event under the experimental condition in   within the frame of the dual system model in  , the “seeing eyes” is expressed as the exteroceptive stimulus (  p  ) and its cerebral responses are expressed as reciprocal   x  -state and non-reciprocal   y  -state. Please note that “seeing eyes” (  p  ) in the first axiom and “seeing face without eyes” (  q  ) in the second axiom are two independent logic variables. They act like two orthogonal axes in describing the task “seeing face”. Thus, when discussing   p   and its responses, none of the responses due to   q   should be any concern. This is important for avoiding confusion in the self-evident explanations. 

The connective between   p   and (  x  ,   y  ) can be derived from the truth-table based on the following self-evidence: In the case that observers cannot see their partners’ eyes, obviously there is neither reciprocal nor non-reciprocal exogenous responses due to exteroceptive stimulus by eye contact. For the proposition that describes this statement, “If   p   = 0, then neither   x   nor   y   can be activated (  x   = 0,   y   = 0)”, its truth-value is true or “1”. For the proposition that contradicts this statement, “If   p   = 0, then there will be activation due to either (  x   = 1,   y   = 0), (  x   = 0,   y   = 1), or (  x   = 1,   y   = 1)”, its truth-value is false or “0”. In the case that the observers can see their partners’ eyes, thus, the exteroceptive stimulus can cause either reciprocal, or non-reciprocal, or both exogenous responses. For the proposition that contradicts this statement “if (  p   = 1), then neither   x   nor   y   can be activated (  x   = 0,   y   = 0)”, its truth-value is “0”. For the proposition that describes this statement, “if (  p   = 1), then there will be activation due to either (  x   = 1,   y   = 0), (  x   = 0,   y   = 1), or (  x   = 1,   y   = 1)”, its truth-value is “1”. A connective with such a truth table is called “material equivalence”, and its formal symbol is ↔. 

With the same argument, the connective in the second axiom in   can be attributed to “material equivalence” (↔) as well. The third axiom in   is basic stimulus-response logic for eye-contact in the endogenous system. Based on the definition in   in Appendix A, the duality principle dictates that all the logic variables and connectives in the endogenous system are simply the dual pairs of the variables and connectives in the exogenous system. 


### C. Deduction for the four transformations 
  
The four stimulus-response transformations in   are the propositional logic descriptions for two original tasks (task A and B) and their two composite tasks (A-B and B-A). Transformation A can be deduced from the first and second axioms:
 
Here, given the stimulus σ  whose functionality f(σ ) =   p  ∨  q  , as shown in the  , the response is inferred as Ω  =   x  ∨  y  , which is entwined reciprocal and non-reciprocal states. Transformation B is a trivial case, since it is equivalent to the second axiom. Given stimulus σ  whose functionality f(σ ) =   q   based on  , the response is inferred as Ω  =   y  . 

The collation operations in the task space in   transform the two exteroceptive tasks σ  and σ  into one exteroceptive task σ  and one interoceptive task σ , where the functionality of σ  becomes   f  (σ ) = (  p  ∨  q  )¬∧  q  , and the functionality of σ  becomes f(σ ) = π∧θ. Note that by definition, the   p   and   q   are dichotomous and independent in stimulus space. Therefore, the   f  (σ ) can be logically simplified to “  p  ” within the stimulus space, which is also consistent with the σ ’s bi-state matrix expression in  . However, due to the first axiom, the relation between tasks (  p  ,   q  ) and their responses (  x  ,   y  ) is not one-to-one mapping, and the operations in the stimulus space and the operations in the response space are not homomorphic. Thus, during the process of deduction from stimulus space to response space, the logical operation steps embedded in the functionality expression of the stimulus (premise) should remain without simplification. The transformation A-B can be deduced from the first and second axiom:
 
So, given the composite stimulus σ  whose functionality   f  (σ  ) =   p   (now it can be expressed in its simplified form after deduction), the response is inferred as exogenous Ω  =   x   ∧ ¬   y  . 

The transformation B-A needs to be deduced in two steps: The first is to show that it yields no exogenous response. The second is to establish the emergence of endogenous response. The exogenous part of the transformation B-A is:
 
Logically speaking, the composite stimulus σ  does not yield any exogenous response. As shown in the  , based on the rule “-1 =   i  *  i  ” in complex numbers, the transformation B-A formulates an emergence of the interoceptive stimulus σ  whose functionality f(σ ) = π∧θ. The endogenous part of transformation B-A can be deduced from the third axiom:
 
Given the composite stimulus σ , the endogenous response is inferred to be Ω  = ¬(ξ∧ψ)∧¬ψ. Since the ⊕ logic is somewhat counterintuitive, the detailed deduction of   by truth-table is provided in   in which ζ = ξ∧ψ. Note that ¬ζ∧¬ψ is the only solution for maintaining conjunction logic. 
   Deduction for the transformation in endogenous system.      


## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-53'>
<h2>53. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/23345577/' target='_blank'>23345577</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Major histocompatibility complex peptide ligands as olfactory cues in human body odour assessment</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Proc Biol Sci</p>
<p><strong>Publication Year:</strong> 2013</p>
<p><strong>DOI:</strong> 10.1098/rspb.2012.2889</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3574394/' target='_blank'>3574394</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Study reports an fMRI experiment in healthy adult participants (women aged 18–35) who performed a self-related task (rating whether odors/peptide-supplemented body odors were ones they would like to smell like), which falls under the review construct 'Perception and Understanding of Self'. The paper explicitly states that whole-brain analysis was performed (in addition to small-volume ROI analyses) and reports activation coordinates in MNI space. Results for healthy participants are reported separately and there are no clinical groups only. Therefore all inclusion criteria are met and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
In many animal species, social communication and mate choice are influenced by cues encoded by the major histocompatibility complex (MHC). The mechanism by which the MHC influences sexual selection is a matter of intense debate. In mice, peptide ligands of MHC molecules activate subsets of vomeronasal and olfactory sensory neurons and influence social memory formation; in sticklebacks, such peptides predictably modify the outcome of mate choice. Here, we examine whether this evolutionarily conserved mechanism of interindividual communication extends to humans. In psychometric tests, volunteers recognized the supplementation of their body odour by MHC peptides and preferred ‘self’ to ‘non-self’ ligands when asked to decide whether the modified odour smelled ‘like themselves’ or ‘like their favourite perfume’. Functional magnetic resonance imaging indicated that ‘self’-peptides specifically activated a region in the right middle frontal cortex. Our results suggest that despite the absence of a vomeronasal organ, humans have the ability to detect and evaluate MHC peptides in body odour. This may provide a basis for the sensory evaluation of potential partners during human mate choice. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (24714 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Major histocompatibility complex (MHC) molecules are involved in antigen presentation and their structure determines the probability with which a given pathogen will be recognized by the individual's immune system [ ]. Because MHC molecules critically influence the susceptibility to infection, maintenance of a sufficient degree of MHC diversity in natural populations is a key survival parameter in the face of constantly changing pathogen spectra [ – ]. Behavioural mechanisms that guide non-random mating based on MHC genotypes are considered to be a means by which an optimum degree of individual MHC diversity is maintained in the offspring. While there is strong experimental support for MHC-associated behaviour in animals [ – ], including non-human primates [ , ], the situation in humans is more complex. Evidence in favour of MHC-associated behaviour has emerged from studies on the sexual interest of females [ ] and their preferences for certain male body odour [ , ]; studies on the degree of genetic relatedness of mated and unmated couples of the opposite sex have produced mixed results, suggesting a role for MHC genotype in some [ , ] but not all populations [ ]. 

In a double-blind study, Wedekind   et al.   [ ] found that women preferred the odour of shirts worn by men with different MHC alleles to those of men with more closely matching MHC alleles; a similar observation was made with male participants [ ]. These findings (reviewed in [ ]) suggested a relationship between MHC-dependent odour signalling and preference for a specific personal perfume. In a subsequent study with the MHC-typed student cohort originally tested by Wedekind   et al.   [ ], Milinski & Wedekind [ ] tested this prediction directly; participants who shared MHC alleles expressed a strong preference for the same natural perfume ingredient for use on themselves, but not on a potential partner. Thus, because MHC genotypes determine individual perfume preferences, it appears that perfumes function as amplifiers of MHC-related individual body odours [ ]. Indeed, a recent study showed that self-preferred perfumes added to body odour are preferred to perfumes allocated by the investigator and added to the same body odour [ ]. Collectively, these findings may provide an explanation for the fact that humans of all cultures have used fragrances for at least 5000 years and for the observation that persistent interindividual differences exist for the preference of certain perfumes [ ]. 

Recent work on the molecular nature of the chemosensory stimuli underlying MHC-associated behaviour in animals indicates that peptide antigens presented by MHC molecules act as olfactory cues in different species in addition to their well-known function in eliciting immune responses [ – ]. Here, we have examined the ability of humans to recognize and evaluate the modification of their body odour by allele-specific MHC peptide ligands. The present psychophysical and neurophysiological studies suggest that MHC peptide ligands convey information about the MHC genotype and may thus represent at least part of natural MHC-dependent human body odour signals. 


## Material and methods 
  
### Study participants 
  
Female students were recruited from the Universities of Hamburg and Kiel. They were genotyped for human leucocyte antigen (HLA) HLA-A and HLA-B [ ] at the University Hospital Hamburg using the reverse SSO line blot assay (Dynal Reli SSO, Invitrogen); note that for historical reasons, the products of the human MHC locus are designated as HLA. This analysis revealed that 19 were positive for HLA-A*02, six were positive for HLA-A*24 (of which two were also positive for HLA-A*02) and nine carried neither HLA-A*02 nor HLA-A*24. In one participant (no. 6), the presence of the A*3002 allele was considered to be functionally equivalent to A*2402, because their peptide specificity is identical [ ]. Sixteen participants carried one or more alleles (in addition to HLA-A*02 or HLA-A*24) with unknown peptide specificity, which were considered to be ‘non-self’; however, given the diversity of residues at anchor positions, the probability that such a ‘non-self’-peptide has the quality of ‘self’ is much less than 0.5; in this case, the effect on our results would be conservative, that is, it would weaken any observed effect. Four participants carried alleles whose peptide specificities are not precisely known, but are unlikely to be identical to those used as a stimulus peptide; if not, their influence would diminish rather than increase the observed effects, because scores would then be given the wrong sign. At the time of performing the psychometric tests, the age of participants was 25.9±0.9 years (mean±s.e.;   n   = 25; range 21–36 years). Details of the study population are summarized in the electronic supplementary material, table S1. 


### Design of peptide ligands 
  
On the basis of known ligand specificities [ ], nonamer peptides were synthesized and purified by Thermo Fisher Scientific GmbH (Ulm, Germany). The peptides and their cognate HLA alleles are listed in the electronic supplementary material, table S2. 


### Psychometric test procedure 
  
Participants were provided with a perfume-free body soap, an untreated cotton T-shirt and two pairs of two bottles per test day containing synthesized HLA ligand peptides, specific for either HLA A*0201 or HLA A*2402 (0.005 mM in phosphate-buffered saline (PBS)), or solvent (PBS). After a shower using the body soap and wearing the T-shirt overnight, the participant put four drops from bottle 1 in her left hand and rubbed them under her right armpit, then put four drops from bottle 2 in her right hand and rubbed them under her left armpit. In mice [ ] and sticklebacks [ ], MHC peptide ligands elicit a behavioural response only when accompanied by a natural validating factor. We assumed that validation is also necessary in humans and that it is likely to be produced by certain glands in the armpit [ – ]. The participant was then asked to evaluate the smell of each of her armpits by sniffing repeatedly from a close distance and to decide whether one side, and if so, which side, smells like herself or a perfume she would like to smell on herself (‘would you like to smell like this?’). She marked on a questionnaire ‘I prefer for myself the smell of my left armpit/my right armpit; I do not smell a difference; if I have a preference, it is weak, medium or strong.’ The following night, wearing the same T-shirt, the protocol was repeated with bottles 3 and 4; this time sides allocated to peptide and solvent were swapped in order to control for possible side effects [ ]. In the questionnaire, the participants were asked about their smoking habits, their use of contraceptive medication, and whether they had a cold during the test. Participants took part in two to six of such test sessions depending on availability at intervals of at least three months. 


### Data analysis for psychometric test 
  
The psychometric tests were carried out in a double-blind fashion and the results of the genotype were revealed only after completion of the tests. The scores assigned to ‘non-self‘ stimuli were subtracted from scores given to ‘self’ stimuli (resulting in positive values when self is preferred to non-self (see text for details)); the following scores could be given: no preference, 0; weak preference, 1; medium preference, 2, strong preference, 3. Data from each participant were averaged and only the average entered into the analysis to avoid pseudo-replication. 


### Functional magnetic resonance imaging study: participants 
  
Twenty-two right-handed women participated in the functional magnetic resonance imaging (fMRI) study; medical histories indicated that all participants were in good health. Olfactory function, assessed by means of ‘Sniffin Sticks’, (Burghart, Wedel, Germany) [ ] was compatible with a normal sense of smell for all but one person who was excluded from the analysis; two further participants had to be excluded from the analysis, one because of pronounced brain abnormalities, the other because of technical problems with the dataset. Data from participants 15–33 (see the electronic supplementary material, table S1 for details of the study population) were processed. At the time of the fMRI studies, the age of participants was 27±1.1 years (mean±s.e.;   n   = 19; range 18–35 years). 


### Functional magnetic resonance imaging procedure 
  
The study was performed with a 1.5 T MR-scanner (Sonata; Siemens, Erlangen, Germany). Peptide solutions were prepared from lyophilized stocks at a final concentration of 25 mM in PBS. Peptide and mock control solutions were prepared using the same type of plastic ware (50 ml polypropylene Falcon tubes; BectonDickinson). Two peptide solutions, the solvent control, and an additional odour (peach) were presented to both nostrils in a total of eight sessions. Peach is an odour known to cause reliable activation in olfactory-relevant areas and was therefore used as a control to ascertain the validity of the experiment; the solvent without peptides also generated activation of olfactorily relevant areas, presumably owing to contaminants in the plastic containers used. The order of the sessions using peptides or solvent was counterbalanced between participants. Peach was always presented in sessions 7 and 8. To focus their attention on self-assessment, participants were instructed that, after each session, they would be asked to rate the quality of odours on a scale of 0–10 (0, I would not like to smell like this at all; 10, I would very much like to smell like this). Each experimental session comprised six on/off blocks lasting 20 s each. Participants were blind to compound identity. The odours were applied to the participants using a computer-controlled olfactometer (Sommer, Mannheim; Germany). Stimuli were embedded in a constant flow of odourless air (total flow 2 l min ). The stimuli were directed through a small tube from the olfactometer to the participants' noses. During the ‘on’-blocks odourized air was intermittently (1 s air, followed by 2 s pause) delivered to the nasal cavity, at a rate of 2 l min . During the ‘off’-block, participants received pulses of odourless air. With respect to the intensity of the odours, participants reported no significant differences between solvent (8.4±3.6 (mean±s.d.)), self-peptide (9.4±4.7) and non-self-peptide (8.5±4.1) (scores, from undetectable odour (0) to very strong odour (20) (the scores from applications to both nostrils were totalled for the analysis); control peach odour intensity rating, 16.4±3.6). These results indicate that self-peptide and non-self-peptide stimuli were presented supraliminally. With respect to the preference as self-odours, no significant differences were observed when the participants gave their scores after the short exposure to each odour during the individual sessions of the fMRI experiment (solvent, 9.1±3.7; self-peptide, 7.3±3.5; non-self-peptide, 8.8±2.7). Note the different experimental design of the psychometric test that involves a comparative rather than an independent assessment of odours without time restrictions. 

For functional brain activation data, 96 volumes per session were acquired by means of a 26 axial-slice matrix 2D spin-echo/echo-planar sequence (repetition time (TR): 2500 ms/echo time (TE): 40 ms, matrix = 64 × 64, voxel size 3 × 3 × 3 mm³). Following the fMRI sessions, a T1-weighted image was acquired by using a T1-MPR sequence (TR: 2180ms/TE: 3.9 ms; TI 1100 ms, matrix 352 × 384). 


### Functional magnetic resonance imaging data analysis 
  
Data analysis was performed with SPM 8 software (Statistical Parametric Mapping; Wellcome Department of Imaging Neuroscience, Institute of Neurology at University College London, UK), implemented in M  R2007b (Math Works Inc., Natick, MA, USA), following spatial pre-processing with the same software (spatial filtering: high-pass filter 128 Hz, registering, realignment, co-registration between functional and structural images, normalization using segmentation procedure, smoothing by means of 6 × 6 × 6 mm  FWHM Gaussian kernel). Motion parameters were included as covariates. Activation coordinates are presented in MNI space. SPM-matrices reflecting the ON–OFF differences were calculated for each session and participant. Analysis was based on the general linear modelling approach. Individual SPM-contrasts were subjected to a full-factorial second level analysis with the two conditions ‘side’ (two: left, right) and ‘substance’ (four: two peptides in solvent, solvent, additional odour (peach)). Whole brain analysis and small volume region of interest (ROI) analysis were performed for seven cortical areas previously reported to be related to self-processing: right middle frontal cortex, superior and inferior parietal cortex and fusiform cortex [ ], right inferior frontal and anterior cingulated cortex and left insular cortex [ ]. Masks were created using the aal atlas [ ] embedded in the WFU P A  v. 2.4 software [ ]. Four   t  -contrasts were calculated (‘self’-peptide minus solvent, ‘self’-peptide minus ‘non-self’-peptide, ‘non-self’-peptide minus solvent, ‘non-self’-peptide minus ‘self’-peptide). A comparative analysis of activated brain areas resulting from exposure to two different olfactory stimuli tends to cancel out olfactory areas and instead highlights differentially activated regions only, such as those activated by either self or non-self-peptides. Note that the solvent control also activated olfactory regions, presumably owing to the presence of trace contaminants in the disposable plastic containers used throughout the study; therefore, subtractive analysis was considered the most reliable approach to reveal peptide-induced activation. Moreover, activation of a certain brain area was considered to be present only when signals were detected in a particular region for both self-peptide versus solvent and self-peptide versus non-self-peptide, or non-self-peptide versus solvent and non-self-peptide versus self-peptide, respectively. Analysis was based on   t  -tests with global height threshold   p   < 0.001, Bonferroni-corrected for the seven search areas and extent threshold of   k   = 3. Additionally, the family-wise error (FWE) rates for activations found within the search areas are presented. 



## Results 
  
### Psychometric assessment of body odour 
  
In a first set of experiments with human volunteers, we examined self-assessment of natural body odour emanating from the armpits after supplementation with prototypic MHC peptide ligands. Hence, in contrast to previous studies, our experimental paradigm specifically focused on self-preference. As expected from HLA allele frequencies in the catchment area for our study population, 18 out of 22 participants were positive for either HLA-A2 or HLA-A24 alleles (or both; electronic supplementary material, table S1), justifying the use of two prototypic peptide ligands (SLLPAIVEL for HLA-A2 and KYPENFFLL for HLA-A24; electronic supplementary material, table S2) as self and non-self stimuli in the double-blind study design (see §2 for details). In individual test sessions, comparisons were made for peptide versus solvent, or A2 versus A24 peptides. The participants were asked to apply two different solutions to their left and right armpits on two consecutive days and then to compare the smell of both armpits (see §2 for details). In the solutions provided to the participants for the second day, the contents were exchanged relative to the previous session to control for potential side bias. Participants had to decide which armpit smelled ‘like themselves’ (or ‘like their favourite perfume’). They were also asked if their preference was weak, medium or strong, or whether they detected no difference between the two armpits. 

In the participants positive for HLA-A2, but negative for HLA-A24, the scores for the armpit exposed to HLA-A2 peptide (‘self’) were given positive values, the scores for the armpit exposed to HLA-A24 peptide or solvent (both ‘non-self’ relative to the HLA-A2 peptide) were given negative values. For the participants negative for HLA-A2, but positive for HLA-A24, only the scores for the armpits exposed to HLA-A24 peptide (‘self’) were given positive values. For HLA-A2/HLA-A24 double-positive participants, the scores for either peptide (‘self’) were given positive, those for solvent (‘non-self’) negative values; for HLA-A2/HLA-A24 double-negative participants, the scores for solvent were given positive (‘self’, relative to peptides) and the scores for either peptide (‘non-self’) negative values. We also recorded whether participants were smokers or had a cold when they carried out the test. Individual scores were averaged across all test sessions. When the data for all sessions of non-smokers without a cold were analysed (two-tailed Wilcoxon one-sample test; average preference compared with 0), a significant preference for the ‘self’ side was found (  n   = 17 participants (total number of trials = 37; average number of trials per participant = 2.2±0.3 s.e.m),   z   = −2.394,   p   = 0.0167, two-tailed;  ). When the sessions of the same cohort with a cold were examined, no significant difference was found (  n   = 12,   z   = −0462,   p   = 0.647, two-tailed); similarly, sessions of smokers without a cold failed to show a difference (  n   = 4,   z   = −0.365,   p   = 0.715, two-tailed;  ). Thus, the preference for ‘self’ (either self-peptide or solvent) to ‘non-self’ (either non-self-peptide or solvent) was clearly evident when all participants with potential impairment of their sense of smell (smoking and/or cold) [ , ] were omitted.
   
Preference for body odour supplemented with ‘self’ stimuli. Participants indicated preference on a scale from +3 to −3. Although participants took part in several trials, only the mean values were used to avoid pseudo-replication. Preference is shown for all sessions of non-smokers without a cold (left), non-smokers with a cold (middle), and smokers without a cold (right). Mean±s.e.m.; *  p   = 0.0167, two-tailed. 
  


### Functional magnetic resonance imaging 
  
The results of the above psychometric tests indicate that human participants are capable of recognizing modifications of their body odour by MHC peptides. Our aim was to confirm this distinct perceptual capacity using fMRI. For this, peptides were delivered to the nostrils of study participants in aerosolized form, and the activation of particular brain areas was determined. To focus the attention of participants on self-assessment, they were asked to rate whether they preferred to smell like the presented odour and to repeat this after each session (see §2 for details). Eleven of 19 participants (all right-handed) included in this analysis had also participated in the psychometric tests (see the electronic supplementary material, table S1). Four different stimuli (solvent; ‘self’-peptide; ‘non-self’-peptide; peach odour as control) were delivered to both nostrils in eight consecutive sessions (see §2 for details). Peptide stimuli (see the electronic supplementary material, table S2) were selected according to the HLA genotype of the test participants (see the electronic supplementary material, table S1). ROI analysis was performed for seven cortical areas previously reported to be related to self-processing: right middle frontal cortex, superior and inferior parietal cortex and fusiform cortex, right inferior frontal and anterior cingulated cortex, and left insular cortex [ , , ]. ‘Self’-peptides induced specific activation in the right middle frontal region, when compared with both solvent (Montreal Neurological Institute, MNI, coordinates (  x  ,  y  ,  z  ) = 26,32,32;   P   < 0.001) and ‘non-self’-peptides (MNI (  x  ,  y  ,  z  ) = 28,32,34;   P   < 0.001;  ). Middle frontal structures are known to be involved in cognitive self-representation [ ]. By contrast, activation induced by ‘non-self’-peptides was much weaker, as expected from the ‘self’-centric paradigm of the study; in this case,   t  -values were lower and the overlap of activated regions resulting from comparisons of non-self-peptide versus solvent and of non-self-peptide versus self-peptide was less obvious (see the electronic supplementary material, figure S1). The peach odour elicited robust activation of olfactory brain areas (see the electronic supplementary material, table S3). Collectively, these results indicate that ‘self’-peptides elicit a response in a distinct brain region.
   
Activation of the right middle frontal cortex by ‘self’-peptides. Activated areas are visualized in a T1-weighted structural template. (  a  ) Transverse section; this section encompasses parts of the right middle and inferior frontal cortex as ROI (outlined). The   t  -values for activations induced by ‘self’-peptides relative to solvent are indicated on a blue-to-green scale, those for ‘self’-peptides relative to ‘non-self’-peptides on a red-to-yellow scale. Note the co-localization of the activated regions. (  b  ) Sagittal section with ROIs indicated. (  c  ) Coronal section with ROIs indicated. (  d  ) Spatial activation profile for ‘self’-peptide relative to solvent. The MNI coordinates are indicated as are the colour-coded   t  -values (  P  (FWE)corr = 0.074; height threshold was set to   p   < 0.001 (Bonferroni-corrected) and extend threshold to   k   = 3 (see (  f  ) for contrast estimates). (  e  ) Spatial activation profile for ‘self’-peptide relative to ‘non-self’-peptide. The MNI coordinates are indicated as are the colour-coded   t  -values (  P  (FWE)corr = 0.111); height threshold was set to   p   < 0.001 (Bonferroni-corrected) and extend threshold to   k   = 3 (see (  f  ) for contrast estimates). (  f  ) Contrast estimates for selected regions after stimulation with ‘self’-peptides. *,  p   < 0.001, Bonferroni-corrected. Activated areas are visualized in a T1-weighted structural template. 
  



## Discussion 
  
The non-classical function of MHC peptides as activating cues for sensory neurons of the olfactory system provides a mechanistic explanation for the role of MHC alleles in guiding behavioural decisions in a variety of contexts and animal species. Our study suggests that MHC peptide ligands may play a similar role in humans. In a behavioural paradigm of self-preference, participants considered the modification of their body odour by ‘self’-peptides more desirable than the modification by ‘non-self’-peptides, indicating that MHC peptide ligands comprise a functionally relevant component of human body odour. These findings are in keeping with previous observations that humans sharing specific MHC alleles also share a preference for particular natural perfume ingredients [ ] and posit that perfumes may contain structurally diverse peptide mimics. Interestingly, customers usually buy perfumes for their own use [ ] and have always done so [ ]. If perfumes are indeed chosen to reveal and/or enhance one's own body odour [ , ], it is not surprising that one dislikes on others what one likes for oneself [ ]. This switch of choice preference with respect to perfume usage might be explained by ‘phenotype-matching’ [ ], a process that is also implicated in kin-recognition. 

Remarkably, exposure to MHC peptide ligands activated specific brain regions, indicating that humans, despite lacking a functional vomeronasal organ [ ], possess the sensory facility to recognize the presence of MHC-associated olfactory cues. It is possible therefore that peptides activate sensory neurons located in the main olfactory epithelium, as was observed in mice [ ]. Our results are compatible with the notion that the right middle frontal region is a multimodal convergence zone [ ] that might provide the anatomical basis for self-referentiality by integrating various extero- and interoceptive inputs, including peptide stimuli. Notably, the activation of particular brain regions by exposure to peptides does not reflect the precise chemical structure of MHC peptides but rather their ‘self’ or ‘non-self’ qualities relative to the individual's MHC genotype. This suggests the presence of an internal reference for MHC genotype and is reminiscent of an equivalent facility in MHC-associated behavioural decisions in mice [ , ] and sticklebacks [ ]. Hence, our study suggests that, as in mice and fish, sensory evaluation of MHC diversity through the recognition of structurally diverse MHC ligands may be involved in human MHC-associated behaviour. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-54'>
<h2>54. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31100434/' target='_blank'>31100434</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Dyadic interaction processing in the posterior temporal cortex</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Neuroimage</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1016/j.neuroimage.2019.05.027</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6610332/' target='_blank'>6610332</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study with healthy adult participants (N=21, ages 18–35) investigating perception of social interactions (viewing dyadic interaction videos) — a social-related task relevant to the review constructs. The paper reports whole-brain analyses (GLM beta maps generated run-wise and whole-brain searchlight analyses) in addition to ROI analyses, so it does not rely solely on ROI results. Healthy participant results are reported separately and meet the age criterion (within 17–65). Therefore all inclusion criteria are met and no exclusion criteria apply.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Recent behavioural evidence shows that visual displays of two individuals interacting are not simply encoded as separate individuals, but as an interactive unit that is 'more than the sum of its parts'. Recent functional magnetic resonance imaging (fMRI) evidence shows the importance of the posterior superior temporal sulcus (pSTS) in processing human social interactions, and suggests that it may represent human-object interactions as qualitatively 'greater' than the average of their constituent parts. The current study aimed to investigate whether the pSTS or other posterior temporal lobe region(s): 1) Demonstrated evidence of a dyadic information effect - that is, qualitatively different responses to an interacting dyad than to averaged responses of the same two interactors, presented in isolation, and; 2) Significantly differentiated between different types of social interactions. 

Multivoxel pattern analysis was performed in which a classifier was trained to differentiate between qualitatively different types of dyadic interactions. Above-chance classification of interactions was observed in 'interaction selective' pSTS-I and extrastriate body area (EBA), but not in other regions of interest (i.e. face-selective STS and mentalizing-selective temporo-parietal junction). A dyadic information effect was not observed in the pSTS-I, but instead was shown in the EBA; that is, classification of dyadic interactions did not fully generalise to averaged responses to the isolated interactors, indicating that dyadic representations in the EBA contain unique information that cannot be recovered from the interactors presented in isolation. These findings complement previous observations for congruent grouping of human bodies and objects in the broader lateral occipital temporal cortex area. 
   Highlights  
  
pSTS and EBA classify between different dynamic interactions. 
  
EBA is sensitive to (uniquely) dyadic interaction information. 
  
These findings support previous evidence for grouping of interacting people/objects in LOTC. 
  
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (38608 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Social interactions are ubiquitous, yet little research has investigated visual perceptual responses to these common social scenarios, relative to individual-person perception ( ). Interestingly, recent behavioural evidence demonstrates that visual responses to two human individuals that are positioned to imply an interaction evoke different responses than when not positioned in this manner. These effects are demonstrated most strikingly by the findings of  : In this study, subjects viewed pairs of briefly presented (30 ms) human bodies or control objects (i.e. chairs), that either faced   towards   or   away   from each other, in either upright or inverted orientation, and were instructed to respond to the stimulus category they saw (i.e. bodies or chairs). Greater recognition accuracy was shown for upright than inverted dyads when an interaction was implied by the two bodies facing towards each other, but crucially, not when facing away from each other. Similarly, visual search facilitation is shown for full body dyads that are positioned to   face towards   – rather than   away   from – each other ( ), while facing direction effects are shown to modulate the evaluation of facial emotion of a target face (i.e. the perceived emotional expression of a target face is modulated by the emotion of a simultaneously presented non-target face, but only when positioned to   face towards   the target;  ). 

Together, these behavioural findings demonstrate that interacting individuals are not merely perceived as separate individuals, but as an   interactive dyad  . Indeed, similar   non-linear   neural responses have been observed recently – that is,   that responses to dyadic interaction stimuli are not the same as a linear combination of responses to the isolated elements of an interaction  . Specifically,   demonstrated evidence of non-linear responses to human-object interaction stimuli in the posterior temporal cortex; the authors used a pattern classification approach to test whether responses to images of human-object interactions (e.g. a person pushing a shopping cart) are distinct from   the mean-averaged response   to the constituent parts of the interaction (i.e. the averaged response to an isolated human and isolated cart); it was found that voxel patterns for human-object interactions in the posterior superior temporal sulcus (pSTS) and lateral occipital cortex (LOC) were statistically distinct from the averaged patterns evoked by isolated ‘interaction parts’. These findings suggest that these regions are sensitive to   unique   interactive information that is accessed only through holistic processing of interactions, and not through part-wise analysis (i.e. processing of constituent ‘interaction parts’ in isolation). 

Interestingly, this response in the pSTS complements previous findings that this region plays an important role in the visual processing of dynamic social interactions; for example, greater pSTS responses are shown for interacting point-light human dyads relative to two non-interacting figures, as well as for similar stimuli depicted by moving geometric shapes that do not contain body information ( ;  ). This region also differentiates between types of interactions performed by live-action human stimuli ( ), and is sensitive to ‘interactive’ motion cues such as the movement contingency between two interacting human figures ( ), or the degree of correlated motion between interacting animate geometric shapes ( ;  ). These findings implicate the pSTS as a region that may be optimized for processing social interaction information. 

The main aim of the present study was to determine whether pSTS encodes dynamic human interactions between two individuals in a non-linear fashion, using a similar approach to  . We herein adopt the phrase ‘  dyadic information effect  ’ rather than ‘non-linear’ effect, to emphasize a   sensitivity to unique information that is only present in dyadic interactions and not the averaged responses evoked by each interactor, presented in isolation  . Specifically, we used support vector machine (SVM) classification to test whether voxel-pattern responses to dyadic stimuli in the pSTS were statistically differentiable from   averaged response patterns   of isolated interactors. Additionally, it was predicted that significantly differentiable responses to   different types   of dyadic interaction would be observed in the pSTS, replicating previous findings (e.g.  ;  ). Responses were also tested in 3 other functionally localized regions of interest (ROIs) that are selective for social information that likely contributes to social interaction processing, and therefore might also plausibly show the hypothesized effects: Extrastriate body area (EBA), mentalizing-selective temporo-parietal junction (TPJ-M), and face-selective STS (STS-F). 


## Material & methods 
  
### Participants 
  
21 right-handed adults (mean age = 23.40 years; SD = 3.74; range = 18–35; 12 females) participated in the study. Participants gave informed consent and received monetary compensation for taking part. Ethical procedures were approved by the Bangor University psychology ethics board. 


### Stimuli 
  
Stimuli consisted of 4 s (s) video clips that were taken from custom footage of paired actors engaging in semi-improvised interactions. Actors were instructed to improvise these scenarios while enacting scripted ‘  action-gestures  ’; for example, for a given arguing scenario, one actor might be instructed to   point angrily   at the other person while the other   shook their fists   in frustration. Therefore, each interaction depicted two individuals performing a given pair of complementary action-gestures that they were encouraged to enact in a natural, authentic way (see supplementary materials A for example videos). An initial set of   dyad stimuli   were created (along with a separate set of   alone stimuli  , as described below; see   for examples of both dyad and alone stimuli). Dyad stimuli depicted two actors engaging in one of 3   interactive scenarios  :   Arguing   (i.e. both actors engaging in an angry/frustrated confrontation),   celebrating   (i.e. both actors celebrating together, excitedly), and   laughing   (i.e. both actors were laughing together, or at each other). These specific scenarios were chosen for the ‘tonal consistency’ of actions performed by a given pair of interactors, such that the intentions, emotions, and valence information conveyed by both individuals in a given scenario were always similar (e.g. angry/frustrated) rather than contrasting (e.g. angry/sad). This ensured that successful classification of the different scenarios was not driven by systematic differences in intentional, emotional, or valence content   between   interactors. Therefore, these scenarios represented three interactive scenarios that were intended to be easily distinguishable.   
a. Example video frames from the dyad versions of the three interaction scenarios. Each row represents one of three unique female-male interactor pairs. b. Two example alone stimuli (created from a given dyad stimulus). 
  Fig. 1   

Within each interaction scenario (e.g. arguing), 4 exemplar videos were created, each using a unique pair of action-gestures, such that each video showed the two individuals performing a complementary pair of action-gestures (e.g. while arguing, interactor A accusatorily points at interactor B who is shaking their hands in frustration). Importantly, no gestures were ‘reused’ in any of the other action-gesture pairings (i.e. a total of 8 action gestures were used across the 4 exemplar videos for each scenario). Similarly, 3 different female-male   interactor pairs   enacted these scenarios, yielding a total of 36 dyad stimuli: 3 interaction scenarios (arguing, celebrating, laughing) x 4 unique action-gesture pairings x 3 interactor pairs. The final stimuli were chosen from a wider set of stimuli based on the highest ‘interactive-ness’ and ‘naturalness’ ratings from a pilot study (N = 10; see supplementary materials A). 

For these stimuli, the average horizontal distance between actors was closely matched – the visual angle between the centre of each actor's torso was approximately 4.80°, and actor height ranged between 3.73 and 4.26°. As dynamic facial information is known to activate the STS (e.g.  ), the presence of facial information was controlled such that classification could not be attributed to different facial expressions. Accordingly, these stimuli did not contain high spatial frequency face information, but body information was preserved. To achieve this, a circle-shaped Gaussian blur mask was placed on each of the actors' heads for each video frame. This preserved the overall shape of the head, preventing the potentially eerie appearance of headless interacting bodies. 

To test neural responses to the same interactive information – but without specifically   dyadic information   (i.e. information available from two interactors presented simultaneously) – a separate set of 72   alone stimuli   were created by removing either individual from each of the 36 dyad stimuli (see  b for examples of two alone stimuli). It is important to note that although these stimuli depicted an isolated interactor by themselves, they still conveyed interactive information (e.g. communicative gesturing towards an implied interactor). Two horizontally-flipped variants of these 108 unique stimuli (36 dyad ​+ ​72 alone stimuli) resulted in a final set of 216 stimuli. 


### Design & procedure 
  
A rapid event-related design was used, and each run was optimized using optseq2 (  http://surfer.nmr.mgh.harvard.edu/optseq  ), based on differentiating 6 conditions (i.e. both dyad and alone variants of the arguing, celebrating, and laughing interaction scenarios), with an inter-stimulus interval range between 0 and 10s (along with 8s fixation at the beginning of each run, and 16 s at the end to capture most of the haemodynamic response). The 6 designs with the highest detection sensitivity were selected to determine event timings for runs. 

Inside the scanner, participants viewed stimuli that were presented centrally on the screen within a 9.17 × 5.11° rectangular space. 6 runs were completed, each lasted exactly 7 minutes and contained 8 stimuli for each dyad version and 16 stimuli for each alone version of each of the 3 scenarios, resulting in 72 experimental stimuli per run. Three important stimulus ordering considerations are also noted here: Firstly, left and right horizontal presentations of each stimulus were balanced within the design, such that any resulting effects could not be attributed to low-level confounds in the horizontal position of interactors (i.e. left and right horizontally-flipped variants of the stimuli appeared equally often); secondly, that any given pair of alone stimuli (i.e. that originated from the same dyad stimulus) were always presented in the same run as each other so that classification of alone stimuli did not contain additional between-run variance that was not present for the dyad stimuli; thirdly, to minimize repetition effects (i.e. seeing the exact same action-gestures from a given dyad stimulus and the corresponding pair of alone stimuli), alone stimuli that appeared in any given run were always from dyad stimuli that were allocated to a different run. 

In addition to the stimuli already described, nine additional catch stimuli were presented (three dyad stimuli, and six alone stimuli) but were not later analysed. These trials contained a ‘frame-freeze’ in which 12 consecutive video frames (duration = 500 ms) were randomly removed from the video and replaced with one repeated frame for that period, creating the impression of a momentary video pause. Participants were instructed to simply watch the videos and to give a button-press response whenever a frame-freeze was detected, and to refrain from making explicit judgements about the interactors. 


### Localizer tasks & ROI creation 
  
Participants completed several localizer tasks in a separate scanning session, on a separate day (see supplementary materials B for full description of these tasks). Briefly explained, three different video tasks were used to localize brain regions that are sensitive to different types of social information: 1) A point-light figure social interaction task similar to that used previously ( ;  ) was used to localize interaction-selective pSTS (pSTS-I) regions of interest (ROI) with the interaction > scrambled interaction contrast (i.e. two intact human figures interacting vs. spatially scrambled versions of the same stimuli in which body and interactive information was disrupted). 2) A dynamic body and face localizer that was adapted from stimuli used previously ( ) – this served to localize body-selective EBA and face-selective STS cortex (i.e. STS-F), with the bodies > objects, and faces > objects contrasts, respectively. 3) A free-viewing animated film (‘Partly Cloudy’; Pixar Animation Studios:   https://www.pixar.com/partly-cloudy  ) identical to that used previously ( ) was used to localize mentalizing-selective TPJ-M with the mentalizing > pain contrast (i.e. mentalizing > pain time-points). 

These tasks allowed for the localization of 4 bilateral subject-specific ROIs (i.e. pSTS-I, EBA, STS-F, & TPJ-M; see supplementary materials C for a visualization of these ROIs). These ROIs were created with a group-constrained definition procedure (e.g.  ) as follows. For a given subject and contrast (e.g. interaction > scrambled interaction, for the pSTS-I), a 5 mm-radius ‘search sphere’ was created by running a whole-brain analysis for N-1 group subjects (i.e. with the ‘current’ subject excluded) and centring the sphere at the peak voxel (i.e. highest t-value) in the designated region. This relatively small sphere was chosen to ensure subject's ROIs did not deviate too far from a given designated anatomical region (e.g. pSTS). To determine the position of the final ROI, a whole-brain analysis for the current subject (for the same contrast) was run, and resulting activation was constrained to the search sphere. A 7 mm-radius sphere was then centred at the peak voxel in this search region; this ROI sphere size was chosen as an ideal compromise between capturing a relatively large number of voxels that would benefit classification performance (e.g.  ), and ensuring minimal overlap between neighbouring STS ROIs. 

All ROIs contained 179 voxels, with the exception of two subjects that had small regions of overlap between the right pSTS-I and right TPJ-M, and a further two subjects with similar overlap between the right pSTS-I and right STS-F. Across these four subjects, a mean overlap of 18 voxels (range: 12–24) was found. To ensure independence of ROI voxels within each of these four subjects, overlapping voxels were removed and ROIs were recreated (respective final ROI sizes for these four subjects were: 167, 161, 161, 155 voxels; all other ROIs for these subjects contained 179 voxels). 


### MRI parameters, pre-processing, & GLM estimation 
  
Scanning was performed with a Philips 3T scanner at Bangor University. Functional images were acquired with the following parameters: T2*-weighted gradient-echo single-shot EPI pulse sequence; TR ​= ​2000 ​ms, TE ​= ​30 ​ms, flip angle ​= ​83°, FOV(mm) ​= ​240 ​× ​240 x 108, acquisition matrix ​= ​80 ​× ​78 (reconstruction matrix ​= ​80); 36 contiguous axial slices were acquired, with a reconstructed voxel size of 3 mm . Four dummy scans were discarded prior to image acquisition for each run. Structural images were obtained with the following parameters: T1-weighted image acquisition using a gradient echo, multi-shot turbo field echo pulse sequence, with a five echo average; TR = 12 ms, average TE = 3.4 ms, in 1.7 ms steps, total acquisition time = 136s, FA = 8°, FOV = 240 × 240, acquisition matrix = 240 × 224 (reconstruction matrix = 240); 128 contiguous axial slices, acquired voxel size (mm) = 1.0 × 1.07 x 2.0 (reconstructed voxel size = 1 mm ). 

Pre-processing was performed with SPM12 (fil.ion.ucl.ac.uk/spm/software/spm12). This entailed slice-timing correction, re-alignment (and re-slicing), co-registration, segmentation, normalization, and smoothing. All default parameters were used except for a 6 mm FWHM Gaussian smoothing kernel. General linear model (GLM) estimation was performed in SPM12 on participants’ normalized images. For the main task, whole-brain beta maps were generated on a run-wise basis with events estimated as 6   classification conditions   – both dyad and alone variants of the arguing, celebrating, and laughing stimuli. One further set of maps were created where each event was modelled separately, to allow for stimulus-wise analyses (see supplementary materials D). 


### SVM classification analyses 
  
Leave-one-run-out linear support vector machine (SVM) classification was implemented with CoSMoMVPA ( ). Briefly explained, for a given subject, an SVM classifier was trained on ROI voxels (i.e. beta values) for the conditions of interest (e.g. dyad variants of the arguing, celebrating, and laughing conditions) in all but one run of data – with the ‘left-out’ run of data used to independently test classification performance on. This was iterated 6 times with each run serving as the left-out test run, and classification accuracy was averaged across iterations. These values were then entered into group level   t  -tests. All reported tests were significant at the corrected Bonferroni threshold (α) unless otherwise stated. A different threshold was calculated separately for each set of analyses (i.e. based on 8, 8, & 4 comparisons for dyad, alone, and cross-classification analyses, respectively), as stated in each sub-section in the results. All   t  -test   p-  values are one-tailed. 

This approach was almost identical for both ‘standard’ classification (e.g. between the three dyad conditions, or between the three alone conditions) and   cross-classification   analyses except that the allocation of training and test conditions differed; that is, for cross-classification, the classifier was trained on the three dyad conditions, but   tested   on the three alone conditions. Significant cross-classification demonstrates that the patterns underlying the two sets of conditions are similar to each other, and therefore are largely driven by the same information. However, we reasoned that if a region showed significantly greater dyad classification than cross-classification (i.e. between dyad and alone conditions), this would indicate sensitivity to dyadic information that could not be ‘recovered’ from the individual interactors presented in isolation (i.e. averaged responses to alone stimuli). As explained previously (see section  ) several stimulus ordering constraints were imposed within each run, and importantly, alone stimuli from a given dyad stimulus were always presented in a different run to minimize repetition effects. Notably, this likely resulted in a   more conservative   estimation of the dyadic information effect due to greater similarity between stimuli in test and train data splits for cross-classification, than for ‘standard’ classification (see supplementary materials E for further details). 



## Results 
  
### SVM classification analyses 
  
For each of the 8 functionally localized ROIs, a series of analyses were performed in which a linear SVM classifier was trained and tested on different variants of the 3 interaction scenarios (i.e. arguing, celebrating, and laughing). One-sample   t  -tests were used to determine whether classification accuracy was above chance level (i.e. 100% / 3 categories = 33.3% chance accuracy; Bonferroni corrected α = 0.006). 

Significant above-chance classification of the three interaction scenarios of dyad stimuli (see  ) was observed in the right pSTS-I (Classification accuracy (%):   M   = 41.39,   SD   = 9.10;   t   (19) = 3.96,   p   < .001) and both the right EBA (  M   = 49.38,   SD   = 12.19;   t   (17) = 5.59,   p   < .001) and left EBA (  M   = 50.88,   SD   = 13.00;   t   (18) = 5.88,   p   < .001), and at an uncorrected threshold in the left pSTS-I (  M   = 38.60,   SD   = 10.55;   t   (18) = 2.17,   p   = .022). None of the 4 other ROIs – bilateral STS-F and TPJ-M – showed above-chance classification of the dyad stimuli (all   ps   > .100; see  ; see supplementary materials F for full statistics).   
A bar chart showing classification accuracy values for dyad, alone, and cross-classification analyses for bilateral pSTS-I and EBA ROIs. Dashed line represents chance-level accuracy (33.3%). *** ​= ​  p   ​≤ ​.001; ** ​= ​  p   ​≤ ​.010; * ​= ​  p   ​≤ ​.05; +=   p = .  073. Error bars are SEM. 
  Fig. 2     
A bar chart showing classification accuracy values for dyad and alone classification for bilateral STS-F and TPJ-M ROIs. Dashed line represents chance-level accuracy (33.3%). No results were significant. Error bars are SEM. 
  Fig. 3   

It is possible that significant classification of dyad stimuli in the bilateral pSTS-I and EBA does not completely rely on inherently dyadic information, and may also encode information conveyed by isolated individuals (e.g. interactive gestures directed towards an implied – but physically absent – interaction partner). To test if this was true, another classification analysis (Bonferroni corrected α = 0.006) was run to see if these regions could differentiate the three interaction scenarios for the alone stimuli (see  ,  ). It is worth reiterating that the   same overall information   was present as in the dyad classification analysis (i.e. same scenarios, actors, & gestures). Above-chance classification was shown in right pSTS-I (  M   = 43.33,   SD   = 12.57;   t   (19) = 3.56,   p   = .001) but only marginally in left pSTS-I (  M   = 37.43,   SD   = 12.81;   t   (18) = 1.39,   p   = .090). Both right EBA (  M   = 46.30,   SD   = 7.86;   t   (17) = 7.00,   p   < .001), and left EBA (  M   = 46.49,   SD   = 6.73;   t   (18) = 8.52,   p   < .001) also showed significant classification. As for dyad classification, bilateral STS-F and TPJ-M ROIs did not show above-chance classification (all   ps   > .088), and therefore, these regions were excluded from further analyses. 

Together, these two classification analyses demonstrate interaction sensitive responses in the right pSTS-I and bilateral EBA regions, and to a marginal extent in the left pSTS-I; specifically, these regions were able to differentiate between the three different interaction scenarios, both when observing an intact dyad and when observing the same constituent interactors presented in isolation. However, although these regions are sensitive to both modes of presentation, this does not mean that the underlying information driving classification in both dyadic and alone scenarios is the same (e.g. information about the spatial-relations between interactors may contribute to classification of the dyad stimuli, but not the alone stimuli). Indeed, if voxel pattern classification in any region does not fully generalise from dyad stimuli to the alone stimuli, this would suggest that there is information encoded by these regions during dyadic interaction perception that cannot be recovered by the same information presented in the alone stimuli. 

Next, a cross-classification analysis was implemented (Bonferroni corrected α = 0.013) whereby an SVM classifier was trained to discriminate responses to the three interaction scenarios with the dyad stimuli, but performance was tested on responses to the alone stimuli. Significant cross-classification was shown for all 4 ROIs (right pSTS-I:   M   = 41.39,   SD   = 8.92;   t   (19) = 4.04,   p   < .001; left pSTS-I:   M   = 40.64,   SD   = 9.63;   t   (18) = 3.31,   p   = .002; right EBA:   M   = 43.21,   SD   = 7.75;   t   (17) = 5.40,   p   < .001; left EBA:   M   = 46.20,   SD   = 11.27;   t   (18) = 4.97,   p   < .001), demonstrating that these regions encode similar information in both the dyad and alone stimuli. 

To test for the main hypothesis (i.e. a dyadic information effect) paired   t  -tests were then performed (Bonferroni corrected α = 0.013) between dyad classification accuracy scores and cross-classification accuracy scores. No difference was observed for either the right pSTS-I (  t   (19) = 0.00,   p   = .500) or left pSTS-I (  t   (18) = −0.73,   p   = .763), showing no dyadic information effect, indicating that the main hypothesis was not supported. However, significantly greater accuracy for dyad classification than cross-classification was shown in the right EBA at an uncorrected level (  t   (17) = 2.07,   p   = .027). A similar, although weaker, marginal effect was also shown in the left EBA (  t   (18) = 1.52,   p   = .073). Therefore, evidence suggestive of a dyadic information effect was shown in the bilateral EBA only. 

To determine whether regions outside the functionally defined ROIs demonstrated a dyadic information effect, whole-brain searchlight analyses ( ) were performed (see supplementary materials G for a full description of searchlight methods and results). Peak classification accuracies (i.e. for dyad and alone classification separately, and also for cross-classification) were observed in the bilateral lateral occipito-temporal cortex (LOTC) and pSTS, along with weaker responses in other areas. However, no dyadic information effects were observed in the LOTC/EBA for this analysis (or in any other brain region), further demonstrating the subtle nature of the effect in the ROI analysis. 


### Reliability of the dyadic information effect in EBA 
  
Due to the marginal nature of these results in the EBA, several follow up tests were performed to determine the reliability of this effect. First, Cohen's   d   effect-sizes were calculated for both the right and left EBA. A medium effect-size was found for the right EBA (  d   = 0.60), and a small-to-medium effect was shown in the left EBA (  d   = 0.38). 

To ensure that these effects were not spuriously driven by the ‘direction’ of cross-classification training and testing roles, cross-classification was performed again, but with the training and testing roles reversed. That is, the classifier was now trained on the   alone   stimuli and tested on the   dyad   stimuli. Both right EBA (  M   = 43.83, SD = 7.60;   t   (17) = 5.86,   p   < .001) and left EBA (  M   = 46.20, SD = 10.32;   t   (17) = 5.43,   p   < .001) showed significant cross-classification. Crucially, dyadic information effects were replicated; greater accuracy for dyad classification than cross-classification was again shown in the right EBA (  t   (17) = 2.03,   p   = .029;   d   = 0.55) and marginally in the left EBA (  t   (18) = 1.41,   p   = .088;   d   = 0.40). 

One further test was performed to determine how reliable these effects were across different ROI sizes (i.e. in addition to the original 7 mm radius ROIs, 5, 6, 8, 9, 10, 11, & 12 mm radius ROIs were created). Consistent with the dyadic information effect in the in the original right EBA ROI, greater accuracy for dyad classification than cross-classification was shown across all ROI sizes, but was most pronounced in larger ROIs (i.e.   ps   < .05 for 8, 9, 11, & 12 mm radii; see supplementary materials H). By contrast, in the left EBA, the dyadic information trend was only shown for smaller ROI sizes (i.e. 5 mm radius:   p   < .05; 6 and 7 mm radii: marginal   ps   ≤ .073); indeed, these hemispheric differences appear to be consistent with larger regions of body selectivity in the right than left EBA as previously reported ( ). 


### Results summary 
  
In summary, although right pSTS-I – and marginally, left pSTS-I – differentiated between the three interaction scenarios, no evidence for specific   dyadic information   encoding was observed in these regions. Instead, this effect was observed in the right EBA at an uncorrected threshold (the data for this analysis are available to download; see supplementary materials I). Follow-up analyses demonstrated that this effect was reliable and interpretable, and is further supported by similar (although weaker) effects in left EBA. Control analyses revealed that these effects are not accounted for by low-level differences in stimulus motion energy between conditions (see supplementary materials J). Additionally, exploratory representational similarity analyses were also performed to further characterize EBA responses to dyad and alone stimuli (see supplementary materials D). 



## Discussion 
  
### Overview of results 
  
The present study aimed to determine whether the pSTS – or any other posterior temporal lobe region – showed sensitivity to   unique   dyadic information in visually observed interactive scenarios that is not present for isolated individual interactors. Two main findings were shown: 1) EBA – but not pSTS – showed evidence consistent with the encoding of unique dyadic information; 2) pSTS (and EBA) classified between three interaction scenarios (i.e. arguing, celebrating, & laughing) replicating similar differentiation of types of interactions between abstract moving shapes ( ;  ). 


### Interaction classification in the pSTS & EBA 
  
Specifically, which type of information might drive differentiation of interaction scenarios in the pSTS and EBA? The pSTS plays an important role in biological motion perception (e.g.  ;  ;  ), and is strongly responsive to movement contingencies between interacting figures (e.g.  ), as well as dynamic cues that imply interactive behaviour between animate moving shapes ( ;  ). Similarly, the pSTS is also sensitive to the intentional contents of actions ( ;  ;  ). It therefore seems plausible that classification in the pSTS is driven by differential intentional content between interaction scenarios that is extracted from different dynamic contingencies between interactors. 

Additionally, the EBA also classified between interaction scenarios. A direct interpretation of this result is that body posture information contributes strongly to the differentiation of these three scenarios. EBA is shown to be sensitive to dynamic postural information (i.e. continuous sequences of body postures that form coherent actions) and is suggested to encode body-based actions ( ). In the current study, distinctively different sequences of coherent body postures – or action-gestures – may have driven classification of interaction scenarios. Although distinct action-gestures were used within each interactive scenario, these tended to be relatively similar to each other (e.g. arguing gestures usually depicted short, sharp movements, while laughing gestures typically contained convulsive torso movements). Therefore, it seems possible that classification of interaction scenarios in the EBA was likely the result of similar action-gestures   within   each scenario, that were markedly different   across   the three scenarios. 


### No dyadic information effect in the pSTS 
  
Despite the pSTS classifying interactive scenarios, the main prediction was not supported; no   dyadic information effect   was observed for the pSTS. This contrasts with the findings of   that showed an analogous effect in the pSTS for static depictions of human-object (inter)actions compared to the averaged responses to isolated objects and humans. One possible explanation for this concerns STS sensitivity to implied biological motion in static images ( ;  ); static human-object interactions might imply greater biological motion or more effortful movement that is not ‘recoverable’ from isolated human and objects; for example, an image of a person pushing a cart implies greater movement than the same body pose and cart presented separately, by virtue of greater physical effort required to move the cart, along with the corresponding impression that the cart is moving. Additionally, pSTS sensitivity to causal contingencies (e.g. a billiard ball hitting another, causing a transfer in motion;  ) suggests the strong influence of physical contact in human-object interactions that was not present in the isolated stimuli. By contrast, the current study used dynamic stimuli that contained biological motion information but no physical contact, and as such, the dyad and alone stimuli were closely matched for these two sources of information that might have driven responses to the stimuli used by  . 

Although no dyadic information effect was found in the pSTS, it is important to note that interactive information was still conveyed in the alone stimuli (e.g. communicative gesturing to an unseen interactive partner was strongly implied). Therefore, successful classification of the alone stimuli does not necessarily reflect that pSTS responses are non-interactive. Indeed, in the context of the sorts of gestural interactions used in the current study, it is possible that classification of the alone and dyad stimuli relied on the same cues (i.e. communicative gestures). Similarly, the current data supports the possibility that representations of interactions in this region may encode the presence of two interactors in a linear fashion (i.e. dyad = the average of the two individuals). Alternatively, it is possible that the pSTS responses to both dyad and alone stimuli are driven by interactive gestures ‘directed’ at another individual, regardless of whether the other individual is present or not. 


### Dyadic information processing in the EBA 
  
Although not observed for the pSTS, a dyadic information effect was shown for the right EBA and to a lesser extent, the left EBA. Although not predicted, this does fit with previous findings observed in the wider LOTC area. Specifically,   observed differentiable responses to human-object interactions than averaged responses to humans and objects in object-selective LOTC (i.e. LOC – in close proximity to EBA); however, this trend did not quite reach significance in the EBA, likely due to weaker responses to object stimuli, suggesting that the currently observed EBA responses could be specific to human body information. Recent evidence also shows that object-selective LOTC is sensitive to ‘regular’ spatial configurations of objects that imply a congruent scene (e.g. different responses are shown for scenes that depict a sofa positioned in front of a television, rather than behind it;  ). Similarly, object-selective LOTC is sensitive to spatial configurations of objects that imply an action (e.g. a pitcher tilted towards an empty cup), relative to configurations that do not ( ). 

Broadly, these findings might suggest a converging role for configural processing of   distinct   objects and people in the LOTC. In relation to the present findings, it is conceivable that LOTC – and here the EBA specifically – performs similar configural processing or grouping based on the action-, body-, and movement information conveyed by interactors. If true, to what extent does   dynamic   information contribute to this effect? In contrast to previous work investigating LOTC grouping responses for static stimuli ( ;  ;  ), the current study used dynamic stimuli. Although the EBA is highly sensitive to static pose information, and may process body movements as a series of static ‘snapshots’ ( ;  ) body (and face) responses are shown to generalise across static and dynamic depictions in broad regions of the posterior temporal cortex ( ). Similarly, representations in the LOTC generalise across dynamic and static depictions of actions and are invariant to other low-level features such as movement direction, or the specific hand used to perform an action ( ;  ). 

In line with these findings, it is likely that dyadic representations of (inter)actions in the EBA generalise across static-dynamic depictions. While dynamic information may not be necessary to encode such scenarios, it may, potentially, allow for more elaborate encoding of body-based actions than similar, static depictions. Additionally, other spatial cues (e.g. interpersonal distance, physical contact, and facing direction), and temporal cues (e.g. movement contingencies and correlated motion) may also contribute to dyadic encoding in the EBA, and further research may directly clarify which cues contribute most prominently. 

It is also worth briefly considering the extent to which dyadic information processing is present for other types of interaction, for example, interactions depicted by moving geometric shapes that do not contain body information. These types of stimuli are known to drive responses in LOTC, ostensibly due to the presence of simple actions such as pushing and pulling movements ( ). As mentioned previously, the wider LOTC area shows some sensitivity to spatial-temporal relations between interacting or scene entities, and therefore cortex in close proximity to (and overlapping with) EBA might plausibly encode dyadic information for these abstract scenarios. 

The present stimuli consisted of interactions between individuals that did not involve physical contact, a potentially powerful interaction cue that is worthy of further investigation; indeed, stronger dyadic information effects might be predicted for contact-based interactions (e.g. two individuals shaking hands), by virtue of categorical differences in physical contact (i.e. presence of physical contact in dyadic interactions vs. absence of physical contact in ‘alone’ variants of these stimuli). 


### Conclusion 
  
In summary, the present results show that both EBA and pSTS differentiate between different types of social interactions. Crucially, representations of dyadic social interactions in the EBA are sensitive to information beyond that which is encoded by the simple average of two separate interactors presented in isolation. This so-called   dyadic information effect   suggests that the EBA is sensitive to unique interactive information that is present only when two individuals interact simultaneously. These findings complement previously observed sensitivity in the wider LOTC area to spatial configurations of objects or bodies that support the processing of holistic, congruent scenarios. 



## Author contributions 
  
J.W & K.K: study design, data-collection, analysis, writing, and editing. 


## Conflicts of interest 
  
None declared. 


## Funding 
  
This work has received funding from the   under the   (ERC starting grant: Becoming Social). 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-55'>
<h2>55. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/20098696/' target='_blank'>20098696</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Common Premotor Regions for the Perception and Production of Prosody and Correlations with Empathy and Prosodic Ability</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2010</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0008759</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/2808341/' target='_blank'>2808341</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is a task-based fMRI study (3T) of prosody perception and production, which falls under Social Communication (a social-related construct). Participants were healthy adults (n=19, ages 18–58). The paper reports whole-brain, random-effects analyses (thresholded at p<0.05 FDR, k>5) and presents whole-brain results (in addition to SVC), not ROI-only analyses. Behavioral and fMRI correlations with empathy (IRI and PPI-R) are reported for the healthy sample. No exclusion criteria apply (no patient-only sample, and whole-brain outcomes are reported). Therefore it meets all inclusion criteria for the review.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
## Background 
  
Prosody, the melody and intonation of speech, involves the rhythm, rate, pitch and voice quality to relay linguistic and emotional information from one individual to another. A significant component of human social communication depends upon interpreting and responding to another person's prosodic tone as well as one's own ability to produce prosodic speech. However there has been little work on whether the perception and production of prosody share common neural processes, and if so, how these might correlate with individual differences in social ability. 


## Methods 
  
The aim of the present study was to determine the degree to which perception and production of prosody rely on shared neural systems. Using fMRI, neural activity during perception and production of a meaningless phrase in different prosodic intonations was measured. Regions of overlap for production and perception of prosody were found in premotor regions, in particular the left inferior frontal gyrus (IFG). Activity in these regions was further found to correlate with how high an individual scored on two different measures of affective empathy as well as a measure on prosodic production ability. 


## Conclusions 
  
These data indicate, for the first time, that areas that are important for prosody production may also be utilized for prosody perception, as well as other aspects of social communication and social understanding, such as aspects of empathy and prosodic ability. 

 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (36433 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Prosody, the melody and intonation of speech, involves the rhythm, rate, pitch and voice quality to relay linguistic and emotional information from one individual to another. A significant component of human social communication depends upon interpreting and responding to another person's prosodic tone as well as one's own ability to produce prosodic speech. However there has been little work on whether the perception and production of prosody share common neural processes, and if so, how these might correlate with individual differences in social ability. 

The   production   of prosody is well known to be a specialization of the premotor cortex, in particular the inferior frontal gyrus (IFG), with emotional prosody more strongly activating the right hemisphere and linguistic prosody more strongly activating the left hemisphere  ,  . Research on the   perception   of prosody has largely focused on the right temporal lobe. However, despite this emphasis, there is some indication that the premotor cortex may also be involved  ,  ,  . Nevertheless, premotor contributions to prosody perception have not been well studied. 

There is limited evidence that there may be common frontal areas active for both the perception and production of prosody; patients with lesions to frontal areas seem to have difficulty with both the perception and production of prosody  . However, these lesions are often very large and it is difficult to discern if the same brain areas are utilized in the two tasks. If the same areas were to be involved, it may indicate that, at least under some circumstances, the acoustic signals from another person's prosodic speech are transformed into articulatory signals in order to understand prosodic meaning. That is, it may imply that in order to understand someone else's prosodic intonation, we may utilize our own motor representations of how we would produce the given intonation. 

Indeed, there is a growing body of data indicating that premotor areas are sensitive to the sounds of actions  – . This activation is somatotopic, such that the sounds of hand actions activate the hand premotor areas and the sounds of mouth actions activate the mouth premotor areas  . The finding that regions in motor-related cortices are active for both the production and perception of a particular action is commonly referred to as “mirror system” activation. This data has also been extended for speech perception, showing that premotor mouth areas involved in producing speech are also involved in perceiving speech  ,  . The latter data indicate that motor areas may be involved in the processing of speech, particularly in noisy environments like the fMRI scanner room  . The current research investigates whether a similar pattern could be found for prosody. It also extends the findings of the auditory mirror system to include processing that is relevant to social and emotional information  . 

Furthermore, there is evidence that activity in premotor areas that respond to the sounds of actions correlates with one's ability to empathize with others  . This finding supports the idea that mapping the perception of other people's actions onto one's own motor representations (simulation) may be an important aspect of empathy. There is also evidence that individuals who score low on measures of empathy (as in psychopathic personality as well as autism) have poor prosodic ability  . Investigating the role of prosodic ability and its neural processes has clinical implications in clarifying the role of affective deficits in psychopathy. For this reason, we are particularly interested in exploring the relationship between prosody, empathy, and the mirror system. 


## Materials and Methods 
  
### Participants 
  
Twenty right-handed, native-English speaking volunteers with no history of neurological or psychiatric conditions participated in the experiment. One subject was eliminated from all analyses due to technical errors, bringing the total to 19 subjects (13 females; 18–58 range, mean 28.1). All subjects had normal or corrected-to-normal vision and normal hearing. All assessments were made by screening questionnaires and all subjects gave informed written consent. Human subjects approval for this study was approved by the Institutional Review Board at the University of Southern California. 


### Stimuli and Task Procedures 
  
The main goal of the study is to determine if there are common regions for the production and perception of prosody. For this reason, the functional imaging component of the experiment consisted of two tasks, one to investigate prosody production and another to investigate prosody perception. Half of the subjects performed the production task runs first, while the other half performed the perception task first. Subjects were trained on the tasks prior to scanning. 

#### Production task 
  
Nonsense syllables were used to reduce/exclude additional linguistic processing (e.g., syntax, semantics)  . Subjects were asked to produce the phrase “da da da da da” in different intonations: happy, sad, question, and neutral. Participants were also instructed to produce no speech on some trials (rest condition). Note that our control condition, “neutral” intonation, will still contain intonation, as a flat pitch profile is still a pitch profile. However, it should nevertheless contain less prosodic information than the other conditions. Subjects were presented with a visual cue at the onset of each trial. A line drawing of a face was used to cue the participant to produce one of five task conditions (happy, sad, question, neutral, rest). As   shows, the mouth of the line drawing varied for each cue (smile, frown, question mark for question, straight line for neutral, and X for rest). The visual cue was presented on the screen for 1 s followed by a gray screen and subjects were asked to produce speech as soon as the gray screen appeared. Subjects were trained prior to scanning to produce speech in a tone of voice that matched the presented visual cue. Each seven and a half minute functional run consisted of ten trials of each condition (including rest) for a total of 50 trials, and each subject performed three functional runs of the production task (30 trials per condition total). Participants' performance during the production task were monitored by an experimenter via headphones and recorded through an fMRI-safe microphone and digital voice recorder. Prior testing of the recording setup indicated that while the quality of the recordings were affected by the MRI background noise and conduction through the tubing, these degradations were minimal and did not affect subsequent analyses of voice data. A further concern when subjects produce speech is the possibility for motion artifacts. Our design minimized movement artifact by training subjects prior to scanning to move their heads minimally while producing speech, by using phrases that require minimal jaw movement (e.g.,“da”), and by using other sophisticated motion correction techniques (e.g., an on-line acquisition correction technique during scanning, and use of motion parameters as regressors in the analyses). 
   Schematic of the prosody production task design.  
A visual cue is presented 1 s, followed by 8 s of blank screen. Acquisition of functional volumes occurred during the last 2 s of the blank screen. The conditions were “happy”, “sad”, “question”, “neutral” (not shown in figure), and “rest”. The presentation order of the conditions was randomized for each subject. 
  

#### Perception task 
  
The perception task had the identical design as the production task except for the stimuli; no visual stimuli were presented. Instead, each trial began with a delay of 1 s followed by an auditory stimulus of duration 2 s. The auditory stimuli consisted of voice recordings (“da-da-da-da-da” recorded by an actress) that depicted the conditions happy, sad, question, and neutral. As in the production task, nonsense syllables were chosen to minimize effects of semantics and syntax. Subjects were instructed to listen to the auditory stimulus and to especially attend to the intonation of the voice. All auditory stimuli were pre-tested prior to the experiment. As in the production task, each seven and a half minute functional run consisted of 10 trials of each condition, plus 10 trials where no auditory stimulus was delivered (rest trials), for a total of 50 trials. Each subject performed three functional runs of the perception task (30 trials per condition total). 



### Image Acquisition 
  
Functional MRI images were acquired with a Siemens MAGNETOM Trio 3T machine. In order to ensure that participants could hear the auditory stimuli during the perception task and that we could take audible voice samples during scanning of the production task, we used a sparse sampling paradigm throughout the experiment  ,  . In this paradigm, we minimized scanner noise by acquiring one volume 6 s after event onset to capture the peak of the hemodynamic response to the stimulus  . In the production task, volumes were acquired 6 s after the offset of the visual cue (which was approximately the onset of the subjects' speech production); in the perception task, functional acquisitions occurred 6 s following stimulus onset. Functional volumes were acquired with a echo planar T2*-weighted gradient echo sequence (TR = 9000 ms; TA = 2000 ms; TE = 30 ms; flip angle = 90°; 192 mm FoV; 64×64 voxel matrix; 29 axial slices (interleaved); 3×3×4.5 mm voxels, no gap). A high-resolution T1-weighted structural scan (MPRAGE; TR = 1950 ms; TE = 2.56 ms; flip angle = 90°; 256 mm FoV; 256×256 voxel matrix; 208 coronal slices; 1×1×1 mm voxels) as well as a T1-weighted structural scan with the same slice prescription as the functional images (coplanar; TR = 702 ms; TE = 17 ms; flip angle = 55°; FoV = 192 mm; 192×192 voxel matrix; 29 axial slices; 1×1×4.5 mm voxels) were also acquired from all subjects. Acquisition of functional volumes employed Siemens' prospective acquisition correction (PACE) technique for motion correction, in which head movements are calculated by comparing successively acquired volumes and are corrected on-line  ,  . 


### Image Processing 
  
Functional images were preprocessed and analyzed with SPM2 software (  www.fil.ion.ucl.ac.uk/spm/  ; Wellcome Department of Imaging Neuroscience, London, UK). Images were corrected for slice timing and then normalized to MNI space (using the EPI.mnc template) to allow across-subject comparisons. Motion parameters were calculated for the functional images. Images were then un-warped using the motion parameters and then spatially smoothed with a 7.5 mm Gaussian filter. In each task (production and perception), each condition (happy, sad, question, neutral, rest) was estimated with a Finite Impulse Response, and motion parameters were added to the design matrix as nuisance variables to minimize the effects of head movements during scanning. Scans were excluded from analysis if translational motion greater than 3 mm was detected; no participant exceeded this amount of translational motion. The finite impulse response model was used because our sparse sampling paradigm made it impossible for us to model the entire length/shape of the hemodynamic response function, and thus we needed to analyze each trial/volume as an impulse function. T-contrasts were computed to observe differences between conditions. Group analyses were performed using random effects models with contrast estimates from individual subjects and were thresholded at p<0.05 (FDR multiple comparisons correction) with a minimum cluster size of 5 contiguous voxels. 

#### Task-related activity for prosody 
  
To observe brain regions involved in the processing of prosody, we performed the contrasts “happy-neutral” and “question-neutral”. These contrasts were performed for the production and the perception task separately. The “happy-neutral” and contrast will reveal brain regions involved in emotional prosody processing, while the “question-neutral” contrast will reveal brain regions involved in linguistic prosody processing. The “sad” condition was not used in this analysis because 1) “happy” and “sad” emotions may be processed differently (e.g., Davidson's Approach-Withdrawal Hypothesis  ); 2) if “sad” were included, then the “emotional” and “linguistic” prosody tasks will not be balanced; 3) acoustical analysis indicated that “sad” is more similar to the neutral prosody condition than the “happy” condition, and different from both “happy” and “question” conditions (see supplementary materials,  ). Thus omitting the “sad” condition from this analysis allows us to maximize the difference between our control condition and question prosody condition. 


#### Common regions for perception and production of prosody 
  
To determine brain regions involved in both the production and the perception of emotional prosody, we observed whether regions associated with emotional prosody production were also active during emotional prosody perception. The same procedure was applied for linguistic prosody production and perception. We first obtained a thresholded map for the production task contrast (“happy-neutral” for emotional prosody; “question-neutral” for linguistic prosody; p<0.05, FDR, k>5). Individual clusters from the thresholded production contrast maps were then used as masks to determine whether prosody perception also activated voxels within those regions. These masks were then used to apply small volume correction (SVC) to the corresponding prosody perception contrasts. 



### Behavioral Measures 
  
We were further interested in how activity in brain areas involved in prosody production/perception may correlate with an individual's ability to produce or perceive prosody. Furthermore, because of the relationship between prosody perception and empathy described in clinical literature  , we were also interested in finding a correlation between brain regions active during prosody perception and an individual's scores on measures of affective empathy. Thus, in addition to the fMRI experiment, we also administered questionnaires to our participants outside of the scanner in order to obtain measures of prosody ability and empathy. These measures were used to correlate prosodic ability to empathy as well as with the functional activations during the fMRI experiment. 

#### Assessment of prosodic ability 
  
To assess prosody   production   ability, two raters subjectively scored the voice recordings taken from participants during the fMRI production task on the level of expression of a subset of the trials. The scoring was performed after the scanning session. A 5-point Likert scale was used to judge prosodic ability, with “1” corresponding with “could not determine intended condition”, to “5” corresponding with “could absolutely determine intended condition; superb expression.” Three randomly selected “happy” and “sad” trials from each scanning run were scored, and average scores for “happy”, “sad”, and “happy&sad” were obtained for each subject. To assess prosody   perception   ability, we administered a separate questionnaire where subjects listened to 28 audio clips depicting the conditions happy, sad, question, and neutral, and were to determine the four conditions each clip belonged to. An accuracy score of the proportion of correctly determined clips was obtained for each subject as a measure of how well a person can distinguish between different prosody conditions. 


#### Assessment of empathy 
  
To obtain a measure of empathy in our subjects, we administered two questionnaires: the Interpersonal Reactivity Index (IRI)   and the Psychopathic Personality Inventory-Revised (PPI-R)  . The IRI, a self-report measure assessing specific dimensions of empathy, consists of 4 subscales, each measuring a unique component of empathy. As our aim was to correlate emotional aspects of empathy with individual ability to perceive emotional prosody, we focused on the component of the IRI thought to reflect an affective component of empathy, Personal Distress (PD; e.g., “When I see someone who badly needs help in an emergency, I go to pieces”  . The other subscales of the IRI are Fantasy Scale (FS), Empathic Concern (EC), and Perspective Taking (PT). EC is another form of affective empathy, while FS and PT are considered to be cognitive forms of empathy. These subscales were not included in the hypotheses. The PPI-R also consists of multiple subscales and factors, each representing some psychopathic personality trait. The affective component of psychopathic personality has generally been thought to be inversely related to empathy; individuals who exhibit psychopathic personality traits and show symptoms of antisocial personality disorder are also likely to show callousness and a lack of empathy  ,  . Specifically, the Coldheartedness scale (C) of the PPI-R reflects a propensity toward callousness, guiltlessness, and lack of sentimentality, and is related to a lack of affective empathy. Thus, the PPI-R Coldheartedness scale was used as an additional measure of affective empathy, and we predicted that it would negatively correlate with prosody perception. 



### Correlations between Prosody Perception and Empathy 
  
#### Behavioral 
  
To determine whether an individual's ability to perceive prosody is related to their empathy, we performed correlations between subjects' scores on the prosody perception questionnaire and empathy scores. Once again we focused on components of empathy and performed correlation analyses using subscales that relate specifically to affective empathy, the Personal Distress scale of the IRI and the Coldheartedness scale of the PPI-R. 


#### fMRI 
  
To determine prosody-related brain regions whose activity correlates with prosody perception and empathy ability, we ran simple regression models at the group level for the contrast “happy&sad-neutral” using individuals' empathy scores as regressors. To observe which brain regions show a linear relationship to empathy, contrast estimates of “happy&sad-neutral” perception were correlated with PD scores from the IRI and C scores from the PPI-R to elucidate correlations between affective empathy and neural activity during emotional prosody perception. These analyses were thresholded at p<0.005 uncorrected with a cluster threshold of k>5 voxels. Both the “happy” and “sad” conditions were included in this analysis as we posited that the neural systems involved in perceive both these intonations was related to empathic ability. 



### Prosody Production Ability Correlated with Emotional Prosody Production 
  
Do individuals who are better at producing prosody show more activity in motor regions involved in prosody production? To investigate this we correlated areas that were active for emotional prosody production with the behavioral measure of prosody production ability. To observe which brain regions show a linear relationship to prosody production ability (i.e., the voice production ratings), we correlated each subject's “happy&sad-neutral” production task contrast estimates with their voice ratings. 



## Results 
  
### Task-Related Activity for Prosody 
  
#### Emotional prosody production 
  
The contrast “happy-neutral” for the production task revealed activations in the left inferior frontal gyrus, bilateral anterior middle temporal gyri, bilateral lingual gyri, left cuneus, right midbrain, right fusiform gyrus, left middle frontal gyrus, right anterior cingulate gyrus, bilateral thalami, left superior frontal gyrus, right middle occipital gyrus, left middle cingulate gyrus, right caudate, right insula, left anterior superior medial gyrus, and bilateral posterior superior medial gyri (p<0.05, FDR, k>5). A complete list of results is available in the supplementary materials ( ). In addition, a whole-brain contrast against rest is shown in   and against control in  . Regions specifically involved in emotional prosody perception as compared to control are shown in  . 


#### Linguistic prosody production 
  
The contrast “question-neutral” for the production task revealed widespread activations across many regions, including portions of the superior, middle, and inferior frontal gyri bilaterally, the supplementary motor area, medial regions of the parietal and occipital cortices, the lingual gyri bilaterally, portions of the left insula, posterior regions of the middle temporal gyri bilaterally, the left superior temporal gyrus, and portions of the anterior cingulate cortex (p<0.05, FDR, k>5. A complete list of results is available in the supplementary materials ( ). In addition, a whole-brain contrast against rest is shown in   and against control in  . Regions specifically involved in linguistic prosody perception as compared to control are shown in  . 



### Shared Networks for Emotional Prosody 
  
In order to determine whether brain regions active while producing emotional prosody were also active when perceiving emotional prosody, we created masks from the thresholded production contrast “happy-neutral”, and observed whether these regions were also active in perception. Masks from the production contrast were used to perform small volume corrections to the perception contrast “happy-neutral”. As predicted, motor related regions in the left inferior frontal gyrus (pars opercularis; BA44) and the left middle frontal gyrus (BA 6; dorsal premotor cortex) were significantly active. The left middle cingulate gyrus, right caudate, and right thalamus also survived SVC (p<0.05, FWE, k>5) ( ). 
   Regions of overlap between prosody production and perception.  
Red = Emotional prosody production regions (p<0.05, FDR; T>3.48) that were also active for perception (p<0.05, FDR (SVC); T>2.38). Green = Linguistic prosody production regions (p<0.05, FDR; T>3.80) that were also active for perception (p<0.05, FDR (SVC); T>2.45). A region in the left inferior frontal gyrus appears to be involved for the production and perception of both emotional and linguistic prosody. 
  

### Shared Networks for Linguistic Prosody 
  
We further predicted that motor-related regions would be commonly active for the perception and production of linguistic prosody. In support of our hypothesis, motor-related regions including the left inferior frontal gyrus (pars opercularis; BA44) and left middle frontal gyrus (BA 6; dorsal premotor cortex) and bilateral superior frontal gyri (BA 6) were active for both tasks. The left anterior cingulate cortex and left insula also survived SVC (p<0.05, FWE, k>5) ( ). 


### Behavioral Results 
  
#### Empathy scales 
  
 IRI  . All 19 subjects completed the IRI. The mean scores (and standard deviations) for each subscale are as follows: FS = 19.21 (5); EC = 18.63 (4.7); PD = 8.58 (5.31); PT = 18.26 (5.94). These values are similar to those originally reported by Davis (1980) and are within two standard deviations of the normed mean.   PPI-R  . One subject did not complete the PPI-R due to experimental difficulties; one participant reported 2 standard deviations above the mean and the remaining 17 participants scored within normal range (+/− 1.5 SD) (mean = 29.16; std = 6.33). As the PPI was originally normed on a college population, our patterns reflect the normal bell curve expected for this measure. 


#### Correlations between prosody perception ability and empathy 
  
As expected, correlations between behavioral measures of prosody and empathy revealed significant results for the PD scale of the IRI and for the C scale of the PPI-R. The PD scale correlated positively with performance on the prosody perception task (r = 0.46; R-sq = 0.21; p(one-tailed) <0.0287). This finding is consistent with our prediction that prosody perception ability will be related with affective empathy. The C scale was found to correlate negatively with performance on the prosody perception task (r = −0.47; R-sq = 0.22; p(one-tailed) <0.0297). Because the C scale is an indicator of deficits in affective empathy, the finding of a negative correlation between C scale scores with prosody perception is expected. It should be noted that in future studies, larger sample sizes would be more optimal in testing these scales, and further allow for more stringent analyses to test the hypotheses. Graphs of performance and production scores are shown in   and scatter plots for these correlations are shown in  . 



### Affective Empathy Scores Correlated with Emotional Prosody Perception: fMRI Results 
  
A correlation analysis between individual differences in the PD score from the IRI and contrast estimates during emotional prosody perception indicates regions in the left inferior frontal gyrus (pars triangularis) and right cerebellum as showing activity that positively correlates with PD scores (p<0.005; uncorrected, k>5) ( ). The R-sq for the left IFG is 0.42 with a 95% confidence interval of 0.12–0.73. 
   Regions involved in emotional prosody perception correlated with empathy.  
 A  ) Correlation between emotional prosody perception brain regions and individual differences in PD (IRI) scores. Orange  =  regions that show positive correlation (p<0.005 uncorrected; Z>2.88).   B  ) Correlation between emotional prosody perception brain regions and individual differences in C (PPI-R) scores. Blue  =  regions that show negative correlation (p<0.005 uncorrected; Z>2.88).   C  ) Correlations between emotional prosody production brain regions and performance on prosody production task (rating scores) (p<0.005 uncorrected; Z>2.88). 
  
For the PPI-R, higher scores in the cold-heartedness scale (C) indicate deficits in empathic ability. Thus here we focused on a negative correlation with the C score and neural activity during emotional prosody perception. A correlation analysis between individual differences in the C score from the PPI-R and contrast estimates during emotional prosody perception indicates regions in the frontal cortex, including bilateral superior, middle, and inferior frontal gyri, bilateral cingulate sulcus, bilateral anterior insula, bilateral transverse temporal gyrus (Heschl's gyrus), bilateral superior temporal gyrus, and right TPJ show activity that negatively correlates with C score (p<0.005; uncorrected, k>5) ( ). The R-sq for a region within the left inferior frontal gyrus (pars opercularis) is 0.54 with a 95% confidence interval of 0.26–0.92. While the results reported here support our hypotheses, it should be noted that larger sample sizes would greatly reinforce this finding, and would better allow for effects to be tested with more stringent tests. 

Further post-hoc analyses in the perception/IRI and perception/PPI-R analyses, indicate that the correlations are driven in part by processing of neutral stimuli. Whereas we report a positive correlation in the left inferior frontal sulcus between PD score (IRI) and the “happy&sad - neutral” contrast, this correlation is influenced by a negative correlation between activity during “neutral” and PD score. Likewise, in the left inferior frontal gyrus (L IFG), we report a strong negative correlation between the Coldheartedness score (C; PPI-R) and the “happy&sad - neutral” contrast. This correlation is also in part influenced by a positive correlation between C score and “neutral” activity. 


### Prosody Production Ability Correlated with Emotional Prosody Production 
  
A linear regression between individual differences in prosody production ability and contrast estimates during emotional prosody production indicates motor-related regions in the right inferior frontal gyrus (pars triangularis), the left superior frontal gyrus, and right middle frontal gyrus to be positively correlated to prosody production ability (p<0.005; uncorrected,  ), although this result did not meet the cluster threshold of k>5 voxels. The R-squared for this result is 0.36 with a 95% confidence interval of 0.04–0.67. 



## Discussion 
  
### Common Brain Regions for the Production and Perception of Prosody 
  
We found areas in the premotor cortex, including the left inferior frontal gyrus and the left dorsal premotor cortex were active for both the perception and production of prosody. This was true for both emotional prosody and linguistic prosody. These results are consistent with previous findings of activity in premotor regions during prosody perception  ,  . The current result indicates a link between perception and production, where brain areas that are commonly thought to be involved with motor planning are also active for perception. While there have been numerous previous reports of perceptual processing in motor areas for action observation  – , for the sounds of actions  ,  , and even for speech  , to our knowledge this is the first report of “mirror” processing for prosody. It may indicate that some components of prosodic perception involve mapping the heard speech to areas that are important for producing that same speech. Such mapping of acoustic signals to articulatory signals is reminiscent of the motor theory of speech perception  . This finding is also in line with the proposed “‘as-if’ body loop” where individuals utilize sensory-motor regions to implicitly simulate perceived or imagined experiences  , as well as other studies that indicate that frontal regions are involved in prosodic perception  ,  ,  ,  . While we do not state that this is the only way that prosodic perceptual processing occurs (and clearly other regions are found to be active when just comparing prosody perception to control), activity in the premotor regions might contribute to the processing more or less strongly in particular circumstances, such as in subtle or more ambiguous instances  . Indeed, the topic of motor contributions to speech processing has been a subject of great debate  ,  , and we take the view that motor contributions to speech processing are one several processing strategies that may be utilized, depending on speech context (e.g., noisy/quiet)   and the task demands. 

The inferior frontal gyrus and premotor cortices are known to have connections to auditory areas, in particular though the arcuate fasciculus  . This “dorsal stream” of speech perception from auditory regions to inferior frontal regions may provide a sensory-motor interface that is important for mapping perceived speech onto articulatory processes  ,  . Thus, inferior frontal areas have the possibility for auditory and motor processing, and in fact are known to respond to the sounds of a variety of hand and mouth actions  . In the case of prosody, we hear our own prosody as we produce it. With time, co-activation of production and perception, through Hebbian learning, could strengthen the activity in multimodal premotor areas to either the afferent or efferent component of the speech, thus producing the areas that we find in this study to be active for both perception and production of prosodic speech. 

Interestingly, our data indicate that common motor areas for production and perception of prosody were found in only the left hemisphere (left IFG and premotor cortices). This was true for both linguistic and emotional prosody. Thus, while emotional prosody perception and also prosody production are known to activate the right hemisphere each  , “mirror” regions for prosody seem to be stronger in the left hemisphere. This is consistent with all previous reports of an auditory mirror system as being lateralized to the left hemisphere  ,  , and may indicate a special role in the left premotor cortex for more multimodal processing (motor, visual, and auditory), while the right equivalent areas instead may be stronger in motor and visual properties rather than auditory properties. 

One possible limitation in this analysis is the possibility that participants implicitly made facial movements during perception trials. Outside the scanner, electromyographic recordings were taken from some subjects to test this possibility, and these results of this analysis, indicating a lack of facial muscle movement during perception trials, are included in the supplementary materials ( ). However it should be noted that any study on perception is limited by the possibility of implicit movement unless measured directly inside the scanning session. 


### Correlations with Affective Empathy 
  
Prosodic ability is known to correlate with deficits associated with affective components of empathic processing. This is best observed in individuals with psychopathy. These individuals, who often score low on emotional aspects of empathy, also tend to score poorly on the ability to perceive prosody  . Our behavioral results further support a positive correlation between ability to perceive prosody and ability to feel emotional aspects of empathy, constructs measured by the PPI-R scale of cold-heartedness (C) and the IRI scale of personal distress (PD). Thus we also looked at individual differences in emotional components of empathy [lower scores on (C) measure on the PPI-R, and personal distress (PD) measure on the IRI], and correlated these with areas that were active for the perception of emotional prosody. We found that individuals who scored higher on these measures of empathy showed more activity during emotional prosody perception in anatomically the same premotor areas that we previously found to be active for the perception and production of prosody, including the bilateral inferior frontal gyrus and premotor cortex. They also were found to show less activity in this region during neutral prosodic intonation, indicating that more empathic individuals utilize premotor regions for emotional prosodic perception, but less for non-emotional stimuli. This data support the notion that components of empathy to emotional stimuli may rely on simulation processes carried out, in part, by motor-related areas  ,  . Thus, in order to understand someone else's prosodic intonation, we may simulate how we would produce the given intonation ourselves, which in turn may be a component of the process involved in creating empathic feeling for that individual. These data indicate that individuals who score higher on scales of affective empathy also show more activity in motor-related areas during prosody perception. Our findings extend previous correlations between the mirror neuron system and individual differences in empathy to include, for the first time, an emotional auditory stimulus: happy or sad prosodic intonation. 

The negative correlation with the C score showed additional areas in the left anterior insula and the superior temporal gyrus. The insula activation might indicate more emotional processing when perceiving emotional stimuli by individuals who are more empathic. Activity in temporal areas may indicate that individuals who are more empathic might also initially process the perceived intonation more than other individuals as well. It is interesting to note that the motor-related activations are bilateral while the temporal activations are observed only in the right hemisphere. The right hemisphere temporal activations are consistent with previous studies of prosody perception; however the motor activities are instead consistent with the bilateral control of the mouth muscles, important for prosody production (see supplementary materials,  ). 


### Correlations with Prosodic Ability 
  
Correlations between behavioral measures of prosody production ability and brain regions that are active during prosody production indicate that individuals who are better at producing prosody activate areas important for motor planning of prosody more than individuals that are poor at prosody production. Because here we focus on affective prosody production alone, we find activity predominately in the right hemisphere, as one would expect. While such a finding has been found for other areas of motor expertise  , this is the first time we find such an effect for aspects of non-verbal aspects of language processing. A similar correlation for prosody perception, while interesting, was not possible due to a ceiling effect on the behavioral measures of perception ability; an abnormal population may be more relevant for such a correlation. 



## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-56'>
<h2>56. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22590530/' target='_blank'>22590530</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Regional Brain Responses in Nulliparous Women to Emotional Infant Stimuli</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2012</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0036270</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3349667/' target='_blank'>3349667</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This fMRI study investigates neural responses of healthy nulliparous adult women (ages 19–29) to emotional infant stimuli (cries and faces), which fits social-related processing (perception/understanding of others, attachment/affiliation cues). Participants are a healthy group reported separately (N=17 analyzed). The authors report whole-brain, random-effects analyses with family-wise error correction and specify voxel/cluster thresholds (i.e., not ROI-only). No exclusion criteria apply. Therefore the study meets all inclusion criteria for the review.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Infant cries and facial expressions influence social interactions and elicit caretaking behaviors from adults. Recent neuroimaging studies suggest that neural responses to infant stimuli involve brain regions that process rewards. However, these studies have yet to investigate individual differences in tendencies to engage or withdraw from motivationally relevant stimuli. To investigate this, we used event-related fMRI to scan 17 nulliparous women. Participants were presented with novel infant cries of two distress levels (low and high) and unknown infant faces of varying affect (happy, sad, and neutral) in a randomized, counter-balanced order. Brain activation was subsequently correlated with scores on the Behavioral Inhibition System/Behavioral Activation System scale. Infant cries activated bilateral superior and middle temporal gyri (STG and MTG) and precentral and postcentral gyri. Activation was greater in bilateral temporal cortices for low- relative to high-distress cries. Happy relative to neutral faces activated the ventral striatum, caudate, ventromedial prefrontal, and orbitofrontal cortices. Sad versus neutral faces activated the precuneus, cuneus, and posterior cingulate cortex, and behavioral activation drive correlated with occipital cortical activations in this contrast. Behavioral inhibition correlated with activation in the right STG for high- and low-distress cries relative to pink noise. Behavioral drive correlated inversely with putamen, caudate, and thalamic activations for the comparison of high-distress cries to pink noise. Reward-responsiveness correlated with activation in the left precentral gyrus during the perception of low-distress cries relative to pink noise. Our findings indicate that infant cry stimuli elicit activations in areas implicated in auditory processing and social cognition. Happy infant faces may be encoded as rewarding, whereas sad faces activate regions associated with empathic processing. Differences in motivational tendencies may modulate neural responses to infant cues. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (35644 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
During early development, pre-linguistic vocalizations, such as cries, and facial expressions are the primary means of infant communication. Both cries and facial expressions from the infant communicate salient information regarding their emotional states and needs and may elicit affection and nurturing from adults  . The interpretation and response to needs underlying infants’ sensory cues may significantly influence the infant’s development  ; thus, the processing of the emotional content of infant stimuli is of developmental significance. 

Utilizing auditory and visual sensory cues, functional magnetic resonance imaging (fMRI) studies have begun to examine mothers’ neural responses to emotional infant stimuli (e.g.,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ). Although auditory stimuli, like cries, may be experienced behaviorally differently than images of infants, considerable overlap is found in neural activation patterns  ,  . Specifically, regions such as the midbrain, hypothalamus, thalamus, basal ganglia, anterior cingulate cortex (ACC), and prefrontal cortex are commonly activated in fMRI studies of parental responses to infant cues, suggesting the involvement of motivation and reward circuitry  ,  . 

As individual differences in motivational tendencies may influence sensitivity to emotional stimuli and/or attachment processes, an exploratory examination of the relationship between brain activation patterns and individual differences in behavioral tendencies may be helpful in characterizing the neural responses to emotional infant stimuli. A prominent theory of behavioral tendencies predicts individual differences to engage or withdraw from emotionally or motivationally relevant stimuli  ,  . In this model, a behavioral activation system (BAS) exists to govern approach behavior toward rewarding stimuli, operating orthogonally to a behavioral inhibition system (BIS) that mediates withdrawal behavior from punishing stimuli. Measures such as the BIS/BAS scale   can be used to assess these tendencies. An improved understanding of how individual differences in behavioral inhibition and activation might relate to neural correlates of infant emotion processing could prove important in identifying features influencing adult-infant interactions. 

In addition to BIS/BAS, evidence suggests that other factors may influence neural responding to infant stimuli. For example, comparisons of different stages in parenting (e.g., two to four weeks postpartum versus three to four months postpartum) have revealed differential patterns of brain activation, suggesting that experience with an infant over the initial months postpartum likely involves significant changes in responsivity to infant cues  ,  . As the experience of parenting may influence responses to infant stimuli, it is necessary to investigate the neural responses to infant stimuli in nulliparous women. Such investigations are important as they will not only inform studies of maternal responses to infant stimuli and help characterize shifts in maternal brain function, but also provide insight into a large group of women with more variable experiences with, and propensities towards, infants. 

Therefore, in the current study, we sought to examine neural responses of nulliparous women to infant cries and faces of varying intensity and valence, respectively. Specifically, we investigated infant cries of differing distress (high, low) levels and infant faces of varying affect (happy, sad, neutral) in nulliparous women using fMRI. We hypothesized that both cry types, relative to a neutral auditory stimulus, would recruit regions previously implicated in response to cries, including the superior temporal gyrus (STG), insula, and cingulate cortices. Moreover, based on the perceived aversiveness of the cries, we predicted that high-distress cries, compared to low-distress cries, would be associated with relatively increased activity in these same regions. With regard to infant facial stimuli, we predicted that happy faces, compared to neutral ones, would activate regions associated with positive emotion and reward processing, including the ventral striatum and orbitofrontal cortex (OFC)  ,  ,  ,  ,  ,  . Sad faces, compared to neutral ones, were hypothesized to activate brain areas implicated in dysphoric and/or empathic responses such as the amygdala and cingulate cortex  . Using a BIS/BAS measure, we predicted that behavioral activation, which reflects responses to stimuli of reward and non-punishment  , would correlate with activations related to rewarding stimuli such as happy infant faces. We further predicted that behavioral inhibition, which is associated with heightened arousal, passive avoidance, and anxiety  , would correlate with regional brain activations related to more aversive stimuli, such as high- and low-distress cries. 


## Methods 
  
### Subjects 
  
Nineteen native-English-speaking, right-handed nulliparous women gave informed written consent and participated in this study approved by the Yale Human Investigation Committee. All research was conducted in accordance with the Declaration of Helsinki. One subject had excessive motion in multiple fMRI runs and was excluded from analyses; another subject completed only four of seven functional runs and was also excluded. The remaining 17 subjects were between the ages of 19 and 29 (M = 22.7, SD = 2.9) years and were in good health with no history of psychiatric or neurological disorders, and had normal or corrected-to-normal vision. Racial and ethnic composition consisted of ten Caucasian, two Asian-American, two African-American, one Pacific-Islander, and two Hispanic women. 

All subjects completed the BIS/BAS scale  , a 24-item valid and reliable self-report questionnaire rated on a 4-point scale (strong agreement to strong disagreement) measuring behaviorally aversive (i.e., behavioral inhibition) and appetitive (i.e., behavioral activation) motivations. The BIS/BAS factors into four subscales, with one factor assessing inhibition (BIS) and three factors assessing activation. The three BAS subscales assess the pursuit of appetitive goals (BAS drive), tendency to seek rewarding experiences (BAS fun-seeking), and responsiveness to reward (BAS reward-responsiveness). 


### Auditory Stimuli – Infant Cries 
  
Cry stimuli were generated from stimuli described previously  . Cries were elicited from infants between the ages of 27 and 32 days who were without serious illness at birth and during their one-month checkup. Cries were recorded in the infants’ homes before the infants were fed and required no additional external stimulation. Detailed information about the recording procedure is reported elsewhere  . We used four two-second segments generated by two infants. The cries were categorized as either high- or low-distress, resulting in both a high- and low-distress exemplar from both infants. We used two exemplars for each level of distress to avoid measuring differences associated with the physical properties of one particular cry. Prior to imaging, the distress level of the cries was verified by an independent group of ten nulliparous female participants (ages 19 to 24 years) who rated the cries on a scale of 1 (calm) to 10 (distressed). High-distress cries were rated as significantly more distressed (M = 8.06, SD = 1.3) than low-distress cries (M = 3.54, SD = .82) (  t   = 11.52,   p  <.0001). 

In addition to cries, subjects heard a “neutral” auditory stimulus, which consisted of a two-second segment of 1/f, or “pink” noise. Pink noise has a frequency of 1/f, indicating that the power spectral density is inversely proportional to the frequency. Pink noise was used as a neutral stimulus because it is not produced by a human and, as compared to white noise, is considered more naturalistic as it occurs in natural systems, speech, and music  . Additional information on the acoustic properties of the cries and neutral stimulus has been previously reported  . 


### Visual Stimuli 
  
Photographs of infant faces between the ages of five and ten months were adapted from Strathearn and McClure   and were previously used by our group  . Twenty-one images from each of the six infants, resulting in a total of 126 images, were balanced for both gender and race (Caucasian and African American). The infant-face images displayed happy, neutral, and sad affective states. The size, luminance, and contrast for all face stimuli were standardized, and faces were presented on a black background. Prior to imaging, face stimuli were rated by an independent group of 11 participants on a scale of 1 (happy) to 10 (distressed) to assess the perceived affect level. A repeated measures ANOVA of the infant-face ratings on the three emotions (happy, neutral, sad) was significant (  F  (2, 20) = 146.43,   p  <.001). Pairwise comparisons showed that happy faces (M = 2.19, SD = 0.75) were rated as significantly less distressed (Mean difference = −1.55, SD = 1.15,   p   = .006) than neutral faces (M = 3.74, SD = 1.43). Neutral faces were rated as significantly less distressed (Mean difference = −4.16, SD = 1.28,   p  <.001) than sad faces (M = 7.90, SD = 0.34). 


### Design 
  
Stimuli were presented using E-Prime software (Version 1.2; Psychology Software Tools Inc., Pittsburgh, PA). The auditory stimuli were delivered via headphones with no visual display. The visual stimuli were displayed foveally at the fixation point for 1000 ms and followed by a fixation cross. Subjects received seven functional runs, each consisting of 42 trials (six trials of each condition of interest and six one-back memory trials). The conditions of interest were high-distress cry, low-distress cry, pink noise, happy face, sad face, and neutral face. Trials of all conditions were presented in a counter-balanced succession. The duration of the inter-trial-interval (ITI) was jittered (4000–14000 ms) to allow event-related analysis and to minimize stimulus expectation. 

During each run, subjects were asked to attend to the stimulus sequence of faces and cries. A one-back memory task was included to maintain and assess subjects’ attention during the task and were modeled but not included in further analyses. On a small proportion of trials (14%), subjects were presented with a row of question marks and either a visual stimulus (infant face) was presented above the question marks or an auditory stimulus (cry or pink noise) was delivered via the headphones. The question marks cued the subject to make a yes/no decision via a stimulus response box as to whether the current stimulus was identical to the stimulus of the preceding trial (i.e., a one-back memory task). Analysis of catch trial data revealed a mean accuracy rate of 91.27±0.05% (mean ± SD). 


### Data Acquisition 
  
Data were acquired with a Siemens Trio 3T magnetic resonance imaging system (Siemens AG, Erlangen, Germany) using a standard 12-channel head coil. Localizer images were acquired for prescribing the functional image volumes, aligning the eighth slice parallel to the plane transecting the anterior and posterior commissures. Functional images were collected using a gradient echo, echoplanar sequence (repetition time [TR] = 2000 ms; echo time [TE] = 30 ms; flip angle [FA] = 80°, field of view [FOV] 20 cm×20 cm, 64×64 matrix, 3.4 mm 3.4 mm in-plane resolution, 4 mm slice thickness, 32 slices). Each stimulus run consisted of 163 volumes, including an initial rest period of 12 seconds (to achieve signal stability) that was removed from analyses. High-resolution structural images were also collected (sagittal MPRAGE acquisition, TR = 2530 ms; TE = 3.66 ms; FA = 7°; FOV = 25.6 cm×25.6 cm; number of excitations [NEX] = 256×256×1; 1 mm slice thickness, no gap; 176 slices). 


### Image Analysis 
  
Following prior published protocols  , functional data were preprocessed using SPM5 (Wellcome Functional Imaging Laboratory, London, United Kingdom). Preprocessing included slice-time correction to the first slice of each volume; SPM5’s two-pass realign-to-mean strategy, which ultimately realigns all functional images to a mean functional image; coregistration of the anatomical image and the average of these realigned functional images; coregistration of all functional images using the parameters obtained from coregistration of the mean image; application of the SPM Unified Segmentation process to the anatomical scan, using prior information from the International Consortium for Brain Mapping (ICBM) Tissue Probabilistic Atlas and estimation of non-linear warping parameters  ; warping the functional images to the Montreal Neurological Institute (MNI) template space; reslicing into isometric 3 mm×3 mm×3 mm voxels; and subsequent smoothing of functional images using a 6 mm Gaussian kernel. All functional runs were inspected for motion in excess of one voxel, for which one participant was excluded from the analysis. 

Once the functional images were preprocessed, first-level robust regression was performed using the standard general linear model but with iteratively reweighted least squares using the bisquare weighting function for robustness  ,  , as implemented in MATLAB 7.3 (Mathworks, Natick, MA; robust.m). Motion parameters and high-pass filter parameters were added as additional regressors of no interest. Once conditions were estimated using percent signal change for each participant, a second-level, random effects analysis was performed to estimate contrasts between conditions using NeuroElf (NeuroElf.net) and following our prior methods. To correct for multiple comparisons we then used a Monte Carlo simulation, which takes into account the voxel-wise and cluster-volume thresholds to establish family-wise error (FWE) correction. Only regions with corrected   p  <.05 (i.e., α<.05) threshold at an uncorrected voxel-level threshold of   p  <.01 at each tail and a cluster of 45 were considered to be significantly activated or deactivated in the whole-brain analysis. Whole-brain correlations were computed to assess the relationship between brain activation and behavioral inhibition and activation as assessed by the BIS/BAS. To adequately correct for the multiple comparisons conducted in the correlation analysis with multiple measures, we employed a conservative Bonferroni correction to both height and whole-brain level thresholds across 24 exploratory correlations. Clusters were considered significant at a FWE corrected   p  <.05 threshold and subsequently Bonferroni-corrected with a corrected   p  <.002 threshold (at an uncorrected voxel-level threshold of   p  <.0005 at each tail and a cluster of 17). Anatomical labels of all results were confirmed using the Talairach Daemon toolbox as well as manually, using a human brain atlas  . 



## Results 
  
### Brain Activations to Infant Cries 
  
When comparing low-distress cries to pink noise, increased activation was observed in bilateral STG, right middle temporal gyrus (MTG), bilateral precentral and postcentral gyri, right inferior parietal lobe (IPL), left superior and medial frontal gyri (SFG and MFG), left putamen and left claustrum. Relatively diminished activation was observed in left caudate and right MFG/OFC. When comparing high-distress cries to pink noise, increased activation was observed in bilateral STG, right MTG, right precentral and postcentral gyri, right SFG, right MFG, right inferior frontal gyrus (IFG), bilateral amygdala, and left culmen. Relatively diminished activation was observed in the right STG and right insula. When comparing high-distress cries to low-distress cries, diminished activation was observed in bilateral STG, right MTG, left IPL, right superior occipital gyrus, and left precuneus; no regions showed increased activation ( ;  ). 
   Regional Brain Activations during the Perception of Infant Cries.           Regional Brain Activations during the Perception of Infant Cries.  
Axial slices of regional brain activations for a) low-distress cries versus pink noise, b) high-distress cries versus pink noise, c) and high-distress cries versus low-distress cries. Color on T1 template images from SPM5 indicates significant increases (red color) and decreases (blue color) in BOLD signal. The right side of the brain is on the right. The number under each brain image indicates z-axis coordinates of the image in the MNI (Montreal Neurological Institute) template space. The only voxels displayed on the brain images are regions with corrected p<.05 threshold at an uncorrected voxel-level threshold of p<.01 at each tail and a cluster of 45. 
  

### Brain Activations to Infant Faces 
  
For happy versus neutral infant faces, greater activation was observed in left ventral striatum, left caudate head, left ventromedial prefrontal cortex (vmPFC)/OFC, and right IFG. Relatively diminished activation was observed in left cingulate gyrus, bilateral precentral gyrus, right SFG, right STG, left supramarginal gyrus, and left insula. For sad versus neutral infant faces, greater activation was observed in bilateral precuneus, left cingulate gyrus, right MTG, bilateral middle and inferior occipital gyri, right fusiform gyrus (FG), left precentral gyrus, left IPL, left lingual gyrus, right SFG, bilateral MFG, right IFG/OFC, and left ACC. Relatively reduced activation was observed in the left insula, left transverse temporal gyrus, and right STG. For happy versus sad faces, relatively greater activation during the presentation of sad faces was observed in the right IFG, bilateral FG, right STG, right supramarginal gyrus, right cuneus, left MTG, left middle occipital gyrus, right precentral gyrus, and right MFG; no regions demonstrated greater activation for the presentation of happy faces relative to sad faces ( ;  ). 
   Regional Brain Activations during the Perception of Infant Faces.           Regional Brain Activations during the Perception of Infant Faces.  
Axial slices of regional brain activations for a) happy versus neutral infant faces and b) sad versus neutral infant faces. Color on T1 template images from SPM5 indicates significant increases (red color) and decreases (blue color) in BOLD signal. The right side of the brain is on the right. The number under each brain image indicates z-axis coordinates of the image in the MNI (Montreal Neurological Institute) template space. The only voxels displayed on the brain images are regions with corrected p<.05 threshold at an uncorrected voxel-level threshold of p<.01 at each tail and a cluster of 45. 
  

### BIS/BAS Scores and Correlations with Brain Activity 
  
The mean ± SD scores of the 17 subjects on the BIS/BAS scale components were 22.12±2.76 for the BIS, 10.76±2.22 for BAS drive, 11.29±1.93 for BAS fun seeking, and 17.35±1.54 for BAS reward-responsiveness. These scores fall within the standard mean score range for healthy subjects  . 

The scores on the BIS and two BAS subscales (drive and reward-responsiveness) were correlated with brain activation contrasts. BIS scores positively correlated with right STG activity in both the comparisons of high-distress cries versus pink noise and low-distress cry versus pink noise. The BAS drive subscale scores inversely correlated with activations in the: 1) right putamen, right caudate extending into the thalamus, right lateral globus pallidus, and left medial globus pallidus in the contrast between high-distress cries and pink noise; and 2) left angular gyrus in the contrast between high-distress cries and low-distress cries. The BAS drive subscale scores positively correlated with right superior occipital gyrus in the contrast between sad and neutral faces. BAS reward-responsiveness scores inversely correlated with left precentral gyral activation in the contrast between low-distress cries and pink noise ( ;  ). 
   Regional Brain Activations during the Perception of Infant Cries and Faces Correlated with Behavioral Measures of Motivation as Assessed by BIS/BAS Subscales.           Regional Brain Activations during the Perception of Infant Cries and Faces Correlated with Behavioral Measures of Motivation as Assessed by BIS/BAS Subscales.  
a) Axial slice of regional brain response for low-distress cry versus pink noise that correlates with scores on the BIS scale. b) Axial slice of regional brain response for high-distress cry versus pink noise that correlates with scores on the BIS scale. c) Axial slice of regional brain response for high-distress cry versus pink noise that correlates with scores on the BAS drive scale d) Axial slice of regional brain response for sad versus neutral infant faces that correlates with scores on the BAS drive scale. e) Axial slice of regional brain response for low-distress cry versus pink noise that correlates with scores on the BAS reward-responsiveness scale. Color on T1 template images from SPM5 indicates significant increases (red color) and decreases (blue color) in BOLD signal. The right side of the brain is on the right. The number under each brain image indicates z-axis coordinates of the image in the MNI (Montreal Neurological Institute) template space. The only voxels displayed on the brain images are regions with corrected p<.002 threshold at an uncorrected voxel-level threshold of p<.0005 at each tail and a cluster of 17. 
  


## Discussion 
  
The current study used fMRI to examine the neural correlates of how nulliparous women respond to emotional infant stimuli, specifically cries of varying distress levels and facial expressions of varying affect. Overall, regions activated in response to cries in nulliparous women (e.g., the STG and MTG) are consistent with those identified in cry processing in previous studies of both non-parents and parents  ,  ,  . For the face stimuli, we observed different regional brain activations in response to sad and happy infant faces. Regions such as the vmPFC, OFC, and ACC, which are commonly activated in fMRI studies of parental responses to infant cues, demonstrated activation during the presentation of infant faces  ,  . Furthermore, neural responses to the cry and face contrasts correlated with self-reported measures of behavioral inhibition and activation suggesting that neural responses to infant stimuli vary as a function of motivational approach and avoidance tendencies. 

### Regional Brain Activations during the Perception of Low- and High-Distress Cries Relative to the Control Stimulus 
  
We found increased activation to low-distress cries relative to the control stimulus in bilateral STG, right MTG, right IPL, and bilateral precentral and postcentral gyri. Similarly, high-distress cries relative to pink noise identified increased activation in bilateral STG, right MTG, and bilateral precentral and postcentral gyri. Findings in STG and frontal cortices are common in fMRI paradigms utilizing infant cry stimuli and may reflect auditory processing and social cognition  ,  . Several fMRI studies have linked activations of STG and IPL to representations of others’ intentions and mental states  ,  . Thus, activation in these areas during the perception of cries may reflect an attempt to understand the emotional states associated with cries of varying distress levels. The STG has also demonstrated increased activity in response to angry speech relative to neutral speech  ,  . Therefore, activation in STG may reflect the aversive nature of the cries. 


### Regional Brain Activations during the Perception of Low- Relative to High-Distress Cries 
  
Nulliparous women demonstrated greater activation for low-distress relative to high-distress cries in bilateral STG, right MTG and left IPL. Increased activation in auditory-processing regions for low- relative to high-distress cries may reflect the greater acoustic variability in the low-distress cries. Specifically, low-distress cries tend to have more numerous shorter bouts whereas high-distress cries tend to have fewer bouts and fewer breaths (see Appendix for cry characteristics). Accordingly, low-distress cries might be considered more complex and may generate relatively increased STG and MTG activation. From a behavioral perspective, high-distress cries may produce more unequivocal responses in adults (e.g., “The infant is clearly distressed and needs immediate attention.”), whereas low-distress cries may produce more complex, and potentially ambiguous, behavioral responses as the adult attempts to understand the cries’ meanings (e.g., “How greatly distressed is the infant? Will the cries cease without my attention?”). The potentially equivocal nature of these responses may relate to the observed increased insular activation, which has been associated with decision-making processes and empathy  ,  . Additionally, the greater recruitment of brain regions during low-distress cries relative to high-distress cries may stem from differential previous experiences of the nulliparous women with infants, which was not assessed in this study. Further research on the relationship between specific acoustic properties of cries and the neural and emotional responses they generate is necessary for understanding the differential responses to cries of varying properties. 


### Regional Brain Activations during Viewing of Happy Faces 
  
Consistent with our hypothesis and findings from previous studies involving the processing of infant visual stimuli  ,  ,  ,  , viewing of happy infant faces compared to neutral ones engaged the OFC. The OFC contributes importantly to maternal “reward” circuitry  ,  , and increased activation in this region may reflect the rewarding nature of a happy infant face, which may help elicit care-giving behaviors. Considered a component of the brain’s “reward system,” the OFC receives ascending dopamine projections from the ventral tegmental area (VTA)  ,  . Studies with pleasant visual, tactile, and olfactory stimuli have found increased activation in the OFC that depends on the pleasantness rather than the intensity of stimulation  ,  . The OFC is therefore considered to have a critical role in representing the reward value of a stimulus. Greater activation for happy faces was also seen in the striatum, a structure receiving projections from the VTA and OFC   and implicated in reward-related learning and motivated behaviors  ,  ,  . The increased striatal activation in nulliparous women may relate to the coding of happy infant affect as a positive sensory cue. 


### Regional Brain Activations during Viewing of Sad Faces 
  
For the sad versus neutral face contrast, activation was observed in the precuneus, cuneus, and left posterior cingulate cortex (PCC). Both the precuneus and PCC have been implicated in the processing of sad adult faces   and show greater activation when adults evaluate their own or other’s emotional states  . A longitudinal neuroimaging study of depressed patients found differential brain activations according to depression status  , suggesting that areas involved in the discernment of negative affective facial expressions may relate to dysphoric response patterns. The PCC has also been implicated in stress responses  , suggesting that stress neurocircuitry may be activated by sad faces. Alternatively, the activation of the precuneus and PCC may indicate that nulliparous women engage in the attribution of emotion while viewing sad infant visual stimuli, as the PCC has been associated with evaluating the affective valence of external stimuli  , and the precuneus has been implicated in empathic processes  . 

Sad faces also activated the ACC, a region involved in the processing of emotional information  . Data implicate the ACC in attending to, and regulating, arousal associated with affective states  , as increased blood flow has been reported in dorsal and rostral regions of the ACC when attending to subjective emotional states and experiences  ,  . Regions along the border between the rostral ACC and the mPFC have been associated with theory of mind tasks, such as the ability to infer mental states of others  . The increased activation in ACC therefore suggests that the nulliparous women in this study may have engaged in social and emotive processing while viewing the sad infant facial stimuli. 


### Regional Brain Activations during Viewing of Sad-Relative-to-Happy Faces 
  
For the comparison of sad versus happy faces, the right IFG, bilateral FG, and right cuneus demonstrated increased activity. Both the IFG and FG have been widely implicated within circuitry involved in the processing of adult emotional faces and are considered as “core” regions of emotional face processing  ,  . The FG has been implicated in the processing of facial stimuli  , including in learning affective values of faces  , with greater FG activation observed to faces of negative affect  . The precuneus has also been implicated in the processing of adult emotional faces, particularly in response to sad faces  . Precuneus response to emotional faces appears influenced by individual genetic variation   suggesting the value of face perception investigations of individual differences. Together, the findings suggest that the neural underpinnings of infant emotional face processing share similarities with those underlying adult emotional face processing and that that individual differences are important to consider in the processing of facial stimuli. 


### Regional Brain Activations and Individual Differences in Behavioral Inhibition and Activation 
  
Our findings suggest that individual differences in motivational tendencies may influence neural correlates underlying the processing of infant emotional cues. Specifically, higher self-reported behavioral inhibition was related to greater activation in right STG during the perception of low-distress cries relative to pink noise, as well as high-distress cries relative to pink noise. The BIS measure assesses responsiveness to signals of negative outcomes, particularly tendencies to inhibit behavior that may result in undesirable consequences (e.g., “If I think something unpleasant is going to happen, I usually get pretty worked up.”). The recruitment of right STG during the perception of low- and high-distress cries preferentially in women with high BIS scores may therefore relate to the aversive nature of cries, with individuals more prone to behavioral inhibition demonstrating a greater STG response. 

Higher self-reported behavioral drive was associated with greater activation in the right superior occipital gyrus when viewing sad versus neutral faces. The occipital cortex, including the superior occipital gyrus, has been linked to affective processing, with occipital cortical activity correlating with poor social adjustment and impaired social cognition in individuals with psychotic disorders  . Thus, the current findings relating behavioral drive to superior occipital gyral activation during viewing of sad faces not only implicates a region implicated in social processing in a population often characterized by poor motivation drive and interpersonal difficulties, but also suggests that early visual processing may be particularly relevant to responses to sad infant facial cues in behaviorally driven individuals. 

In the current study, individuals with higher reward-responsiveness showed lower activity in the left precentral gyrus when listening to low-distress cries compared to pink noise. The precentral gyrus, involved in motoric responding, has been implicated in the processing of rewarding and aversive stimuli. For example, healthy subjects as compared to individuals with borderline personality disorder, a condition characterized by emotional dysregulation, showed greater recruitment of the precentral gyrus during responses to aversive as compared to neutral stimuli  . Healthy women but not those with bulimia nervosa showed increased activation of the precentral gyrus in anticipation and receipt of a milkshake reward  . Thus, these findings suggest that individual differences in precentral gyral activations to aversive and rewarding cues may have important clinical implications. The current findings suggest that individual differences in both approach and avoidance motivational tendencies are related to neural activations involved in attentional and emotional processing. The extent to which these behavioral and neural measures relate to specific aspects of adult-infant interactions requires additional investigation. 


### Limitations, Strengths, and Future Directions 
  
Several limitations exist. First, the facial stimuli were derived solely from infants. Future investigations involving facial stimuli from individuals of varying ages may be helpful in elucidating how brain responses may be modulated by the physical maturity of facial features being viewed. Furthermore, the cries were gathered solely from newborn infants, limiting the possibility of having a comparable happy auditory condition such as laughter. Additionally, the age difference of the infants used for the cry and face stimuli makes comparisons between the two sensory domains difficult. However, we did find increased activation in precuneus, right MTG, left precentral gyrus, and left IPL for sad faces relative to neutral ones, as well as for cries relative to pink noise. Future fMRI investigations are needed to continue identifying regions activated across these sensory modalities. Second, the subjects in the study were healthy nulliparous women of childbearing age. Information regarding subjects’ desire and plans to be in a caretaker role, as well as the degree of their present interaction with infants, may help to further account for individual differences in the processing of infant stimuli. Additionally, studies of childbearing women could examine how neural responses to infant affective cues may change in healthy mothers at varying times postpartum. Third, the study excluded men. Examination of similarly aged men and parents of both sexes could investigate potential influences of sex and parenthood, respectively. Fourth, the study involved healthy subjects. Future studies of mothers and nulliparous women in whom parent-child interactions may become impaired, such as during maternal depression and substance abuse, could help investigate processes of particular relevance to the health of vulnerable youth. Despite these limitations, the findings provide initial insight into the neural processing of infant cues in nulliparous women and how individual differences in motivational tendencies relate to brain responses to infant stimuli. 

In summary, the current study provides an initial examination of how emotional infant stimuli are perceived by healthy, nulliparous women. Cries of varying distress levels differentially recruited regions associated with auditory and empathic processing. With regard to the visual infant stimuli, our findings suggest that happy faces are encoded as rewarding stimuli in the brain, whereas sad faces induce increased activation in regions associated with empathic processing. The study is also the first to investigate appetitive and aversive motivational tendencies in relationship to the processing of infant emotional cues, and the findings suggest a relationship between individual differences in motivational tendencies and brain response patterns to infant cues. These findings also indicate the utility of this approach to investigate a broader range of individual differences with respect to neural activations and their clinical correlates in response to infant stimuli. 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-57'>
<h2>57. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/28242678/' target='_blank'>28242678</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> A neural model of valuation and information virality</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Proc Natl Acad Sci U S A</p>
<p><strong>Publication Year:</strong> 2017</p>
<p><strong>DOI:</strong> 10.1073/pnas.1615259114</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5358393/' target='_blank'>5358393</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study reports fMRI data collected while participants engaged in social-related tasks (considerations of sharing, mentalizing/social cognition, and self-related processing) relevant to ‘Perception and Understanding of Self’ and ‘Perception and Understanding of Others.’ Participants were healthy adults (study samples: ages 18–24). The manuscript reports both ROI-based analyses and exploratory whole-brain analyses (per SI: whole-brain searches, cluster and permutation corrections, and whole-brain tables), so results are not limited to ROI-only reporting. No clinical/psychiatric participant-only results are presented. Therefore all inclusion criteria are met: (1) fMRI during social-related tasks, (2) healthy adult sample within 17–65, and (3) whole-brain analyses reported. Hence the study should be included in the review.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>   Significance  
Why do humans share information with others? Large-scale sharing is one of the most prominent social phenomena of the 21st century, with roots in the oldest forms of communication. We argue that expectations of self-related and social consequences of sharing are integrated into a domain-general value signal, representing the value of information sharing, which translates into population-level virality. We analyzed brain responses to   New York Times   articles in two separate groups of people to predict objectively logged sharing of those same articles around the world (virality). Converging evidence from the two studies supports a unifying, parsimonious neurocognitive framework of mechanisms underlying health news virality; these results may help advance theory, improve predictive models, and inform new approaches to effective intervention. 
  
Information sharing is an integral part of human interaction that serves to build social relationships and affects attitudes and behaviors in individuals and large groups. We present a unifying neurocognitive framework of mechanisms underlying information sharing at scale (virality). We argue that expectations regarding self-related and social consequences of sharing (e.g., in the form of potential for self-enhancement or social approval) are integrated into a domain-general value signal that encodes the value of sharing a piece of information. This value signal translates into population-level virality. In two studies (  n   = 41 and 39 participants), we tested these hypotheses using functional neuroimaging. Neural activity in response to 80   New York Times   articles was observed in theory-driven regions of interest associated with value, self, and social cognitions. This activity then was linked to objectively logged population-level data encompassing   n   = 117,611 internet shares of the articles. In both studies, activity in neural regions associated with self-related and social cognition was indirectly related to population-level sharing through increased neural activation in the brain's value system. Neural activity further predicted population-level outcomes over and above the variance explained by article characteristics and commonly used self-report measures of sharing intentions. This parsimonious framework may help advance theory, improve predictive models, and inform new approaches to effective intervention. More broadly, these data shed light on the core functions of sharing—to express ourselves in positive ways and to strengthen our social bonds. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (59578 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
Human social interaction is centered on sharing information with others ( ), and this sharing critically affects the reach and impact of news, ideas, and knowledge over time ( – ). The more than 4 billion Facebook messages ( ), 500 million tweets ( ), and 200 billion e-mails ( ) shared daily highlight this phenomenon. However, not all information is equally likely to be shared ( ,  ). Although a growing body of research describes large-scale patterns of sharing ( – ), the types of data that are used to describe such patterns cannot speak to the underlying psychological and neurocognitive antecedents of sharing. Furthermore, extant empirical research on the psychological mechanisms of sharing ( ,  ) is limited by social desirability bias, memory gaps, and the inaccessibility of unconscious, basic processes inherent in self-report and other commonly used measures ( – ). 

To this end, we assess the neurocognitive processes in individuals that translate into population-level sharing of health news articles (i.e., virality, defined as the mass popularity of a piece of information among those with direct access to that information). Real-time measurement of brain activity offers a mechanistic window into the processes underlying sharing decisions, is less biased by the factors noted above ( ,  ), and hence may offer a new way to understand and predict virality. 

## Value-Based Virality 
  
We tested a parsimonious model of virality centered around the value of sharing. Value-based virality posits that (  i  ) two types of inputs—expectations of self-related outcomes and the social impact of sharing—inform an overall computation of the value of sharing a piece of information with others, and (  ii  ) this domain-general value signal translates into population-level information virality. Operationally, we relied on meta-analyses and large-scale studies in social neuroscience and neuroeconomics to define theory-driven brain regions of interest (ROIs) from which to extract neural activity as a proxy for each of the three psychological processes central to value-based virality ( ). 
  
ROIs in study 1 and study 2 
    

## Information-Sharing Value 
  
Neuroscientists have identified subregions of the ventromedial prefrontal cortex (VMPFC) and ventral striatum (VS) that compute value in various contexts ( ). Importantly, prior work has characterized the domain-general nature of the value signal that is computed in this neural system ( ,  ). That is, if a decision maker is faced with different types of value (e.g., primary and secondary rewards), the brain’s value system enables direct comparisons by transforming them onto a common scale during decision making. Value-based virality argues that this same mechanism enables sharers to compute an overall value of the act of sharing a specific piece of information based on considerations of the self-related and social consequences of sharing. Operationally, the neural valuation system includes VS and VMPFC subclusters which are linked to preference judgments and valuation in decision making across hundreds of studies ( ) and which have been linked to sharing decisions in individuals ( ,  ). 


## Self-Related Outcome Expectations as an Antecedent of Sharing 
  
Value-based virality suggests that expectations of self-related outcomes are one primary antecedent to sharing. In line with work on self-relatedness, this concept assumes thoughts about how sharing information affects “our self-presentation or mental concept” ( ). This broad definition encompasses various specific thought processes, for instance about the effects of sharing on one’s self-presentation or its potential to support self-enhancement, which have been studied separately elsewhere ( ,  ). Value-based virality suggests that neural activity in the brain’s self-related processing system is the greatest common denominator of these broadly self-related processes, allowing us to capture within one measure a set of related cognitions that can vary across people and contexts. Similar to content that enhances such self-related thoughts ( ,  ), information that engages neural activity in regions related to such processes, especially in medial prefrontal cortex (MPFC) ( ,  ), has been linked to self-reported intentions to share information ( ,  ). 

Extant observational evidence further suggests that self-relevant issues are among the most frequent conversation topics ( ,  ), especially in social media ( ), and that disclosing information about the self may be inherently rewarding ( ). Value-based virality suggests that, through this neural mechanism, expectations of positive self-related outcomes of sharing increase the perceived value of information sharing, which in turn increases the likelihood of actual sharing. 

Operationally, we focus on a self-related processing ROI consisting of clusters in the MPFC and precuneus/posterior cingulate cortex (PC/PCC), regions commonly activated by the types of self-related judgments detailed above ( ,  ). 


## Social Outcome Expectations as an Antecedent of Sharing 
  
In parallel, value-based virality suggests that expectations of social outcomes of sharing are another primary antecedent of sharing decisions. Sharing is an inherently social process, and social considerations can strongly impact how content is received and acted upon ( ,  ). In particular, sharers need to consider others’ mental states (e.g., knowledge, opinions, and interests) to predict the potential reactions of their audience and to share successfully ( ,  ). This type of social cognition is called “mentalizing” and involves cognitions or forecasts about the mental states of others ( ), for instance, predicting what others are likely to think and feel about the shared information and about the sharer. Value-based virality suggests that neural activity in the brain’s social cognition system constitutes the greatest common denominator of a range of socially relevant thought processes in sharers, including thoughts about the meaning of the information to receivers and the potential for positive social interactions with others. Neurally, activity in the mentalizing system has been linked to sharing decisions in individuals ( ), and successful persuaders engage brain regions strongly associated with mentalizing ( ) more than unsuccessful persuaders within two-person propagation chains ( ). 

Furthermore, sharing information with others has been found to be rewarding ( ). Value-based virality predicts that, by this mechanism, thoughts about potential positive social outcomes of sharing (e.g., having another person know you better or gaining others’ approval) increase the perceived value of information sharing. This is reflected by positive associations between neural activity in social cognition and value systems. 

We operationalize social cognition as defined above with an ROI consisting of clusters in the middle and dorsal MPFC, bilateral temporoparietal junction, and right superior temporal sulcus, regions which are robustly activated by tasks involving mentalizing ( ) and which specifically overlap with considerations of whether others’ mental states are rational and social ( ). 


## Current Study 
  
We tested the value-based virality framework empirically by combining data from two fMRI experiments with objectively logged population-level data on the sharing of   New York Times   (NYTimes) health news articles that were collected using the NYTimes’ Most Popular application programming interface (API) search tool ( ). We focused on neural activity in theory-driven ROIs associated with key psychological processes (positive valuation, self-related, and social processing) measured while participants in two samples were exposed to headlines and abstracts of NYTimes health news articles. fMRI participants also provided ratings of the likelihood with which they would share each article with their Facebook friends. To create a more realistic sharing context, participants were informed that they would be asked to act on their self-reported intentions after the fMRI scan by sharing articles they rated positively with actual Facebook friends. Furthermore, several article characteristics, such as positivity and perceived usefulness, were available from a prior content-focused investigation of the articles used here ( ). Participants completed similar tasks in the two studies ( ), and parallel analyses were applied to the two datasets to allow the replication of our results linking neural and population-level data. The population-level framework presented here substantially extends orthogonal analyses of individual-level results based on study 1 data showing that decisions about information sharing engage more activity in value, self-related, and social cognition ROIs than do other types of decisions and that this neural activity scales with self-reported, individual-level sharing preferences ( ). 
  
fMRI tasks. (  A  ) Reading trial of the article task (study 1). (  B  ) Abstract trial of the article task (study 2). The trial modeled in main analyses is marked in red. 
  

## Results 
  
Based on the predictions made by value-based virality ( ), path models were specified to link percent signal change of brain activity measured in the three theory-driven ROIs while our participants read headlines and abstracts to the population-level sharing counts of each article. The 80 NYTimes articles were shared a total of 117,611 times (mean ± SD, 1,470.1 ± 2,304.3 times; range, 34–12,743 times) via Facebook, Twitter, and email by the NYTimes online reader population within 30 d of each item's publishing date. 
  
Value-based virality path model. The path diagram shows maximum likelihood estimates (unstandardized coefficients). The table presents indirect effect coefficients and bias-corrected, bootstrapped 95% CIs (1,000 replications). As in prior work predicting population-level message effects from neural data ( ), all variables were rank-ordered.   n   = 80 in study 1 and 76 in study 2; *  P   < 0.05, **  P   < 0.01, ***  P   < 0.001, n.s., not significant. 
  
In both samples, we found robust support for value-based virality (  and  ). First, articles that had high sharing value indicated by stronger neural activity in the valuation ROI in each of our samples were shared more frequently by NYTimes readers. This result is in line with the idea that, in the context of sharing, the brain’s valuation system encodes the value of sharing information with others. Further, there are commonalities across people in the extent to which information engages this neural system. 
  
Correlation matrices underlying the path models in   (variables 1–4) and   (variables 1–5) 
    
In addition, the effects of neural activity in self- and social-cognition systems on population-level virality were fully mediated through value-related activity in both samples. This finding is consistent with the idea that considerations of self-related and social outcomes of sharing impact the overall perceived value of the act of sharing, which in turn directly affects sharing behavior. 

These results were robust when using unranked variables ( ,  , and  ). Further, models specifying value-related neural activity as the mediator of the effects of social and self-related processing on virality showed acceptable model fit and outperformed alternative path models ( ,  ). Finally, following our planned ROI analyses, a whole-brain search for regions associated with population-level virality did not reveal widespread activity outside our ROIs ( ,  , and  ). 
  
Value-based virality path model including unranked variables. The path diagram shows maximum likelihood estimates (unstandardized coefficients). The table presents indirect effect coefficients and bias-corrected, bootstrapped 95% CIs (1,000 replications). Population-level virality was log-transformed because of its positively skewed distribution.   n   = 80 in study 1 and 76 in study 2; *  P   < 0.05, **  P   < 0.01, ***  P   < 0.001, n.s., not significant. 
    
Correlation matrices underlying the path model in   that includes unranked variables 
      
Model fit comparison for alternative path structures 
      
Whole-brain analyses of regions associated with each article's rank of population-level sharing counts in study 1 and study 2. Whole-brain maps were thresholded using (  A  ) a nonparametric permutation analysis corrected at FDR-corrected   P   < 0.05,   K   ≥10 and (  B  ) a cluster-based approach thresholded at   P   < 0.005 uncorrected and   K   ≥320 in study 1 and K ≥296 in study 2, respectively where   K   is the number of vowels per cluster on a 3dClustSim simulation together corresponding to   P   < 0.05 corrected. 
    
Whole-brain tables: Clusters significantly associated with population-level virality ranks of the NYTimes articles shown in each trial during reading screen periods (study 1) or abstract trials (study 2) 
    
We further compared the predictive power of neural activity in regions predicted by value-based virality with variance explained by commonly used self-report measures (intentions to share each article on Facebook) and tested the robustness of the framework when controlling for the effects of article characteristics that have been associated with news virality in prior work ( ,  ). For both the study 1 and study 2 samples, self-reported intentions were significant predictors of population-level sharing (explaining 11.3% and 13.8% of its variance, respectively). Neural activity alone explained 17.5% and 9.6% of the variance in the virality outcome in studies 1 and 2, respectively ( ). When combined, both self-reported intentions and brain activity remained significant predictors, together explaining 19.2 and 19.1% of the variance in studies 1 and 2, respectively (  and  ). In addition, all effects reported in   were robust, even when controlling for any of nine content characteristics available for the article headlines and abstracts ( ). Thus, brain activity measured with fMRI can significantly improve the prediction of large-scale sharing behavior beyond other commonly used metrics. 
  
Effects of self-reported intention. (  A  ) Model using intention ratings to predict population-level virality. (  B  ) Model using both intention ratings and value-based virality to predict virality. All variables are rank-ordered; *  P   < 0.05, **  P   < 0.01, ***  P   < 0.001,   P   = 0.056, n.s., not significant. 
  

## Discussion 
  
Information sharing is an integral part of human nature ( ) that enables and accelerates innovation and development in modern societies ( ,  ). We iteratively combined neuroimaging data with objectively logged population-level data on hundreds of thousands of shares from the NYTimes API search tool to test a parsimonious, neurocognitive framework of the psychological mechanisms underlying sharing decisions that translate into population-level virality. Specifically, we argue that potential sharers consider a broad range of self-related and social consequences of sharing a piece of information with others. The resulting self-related and social-relevance judgments then serve as inputs to the brain’s valuation system, which converts them to a common scale. This overall value of information sharing is directly predictive of large-scale sharing dynamics. 

Consistent with this framework, we found that brain activity in the valuation system (VS and VMPFC) in two groups of participants was associated with virality in the larger population (117,611 total shares of 80 NYTimes articles). That is, articles associated with higher information-sharing value in the brain when individuals first read the headlines and abstracts were shared more frequently by the population of NYTimes readers. Information-sharing value may be a primary psychological motivator and central theoretical concept that guides sharing behavior at scale. Prior work has shown that neural activity in the brain’s valuation system is not only associated robustly with personal preferences ( ) but also with the expectation of positive outcomes ( ,  ). Brain activity in response to persuasive messages in these regions also is associated with message-consistent behaviors at the individual ( ,  ) and population level ( ,  ,  ). Our findings show that the predictive validity of neural valuation activity extends to the realm of information virality and highlights the domain-general nature of this brain signal ( ,  ). In the case of sharing, value-based virality suggests that considerations of self-related and social consequences of sharing are key inputs in the computation of the value of sharing information, even though the specific nature of the self-related and social inputs that inform that value signal may vary depending on qualities of the information sharer, the receiver, or their relationship. 

In line with this argument, we found robust, indirect effects of brain activity in regions associated with self-related processing during article exposure on population-level sharing behavior through value-related activity. Prior evidence has linked a range of self-related judgments to sharing. For example, the promotion of a positive self-image ( ,  ) is an important goal in social interactions, and information that allows potential sharers to appear in a more positive light is more likely to go viral ( ,  ), perhaps because it increases the perceived value of information sharing. Further, self-disclosure increases activity in the brain’s valuation system, suggesting that providing information about or reflecting about the self might be inherently rewarding ( ). Value-based virality brings together prior findings, arguing that self-related neural activity is the greatest common denominator for various self-related thought processes, including reflecting self-concept and self-presentational concerns, and constitutes a primary antecedent of sharing value. 

Further, our results show an indirect effect of activity in neural regions associated with social cognition, and in particular mentalizing, on population-level article virality through value-related activity. Existing work has shown that the expectation of positive social outcomes such as positive interactions with others engages the brain’s valuation system ( ,  ), and our ROI overlaps with brain regions supporting considerations of whether others’ mental states are rational and whether they are social ( ). Social belonging is a basic human need and motivation ( ,  ), and relationship maintenance has been suggested as a motivator of information sharing ( ,  ). A range of basic social motives focused on understanding others’ minds and forecasting their reactions, and expectations about positive social outcomes of sharing information with others may increase the perceived value of information sharing; in turn, the perceived increase in the value of information increases the potential that the information will go viral. Value-based virality brings together prior findings, arguing that neural activity in areas associated with social cognition is the greatest common denominator for various social thought processes and informs sharing value. 

Although we removed voxels within the VMPFC and PCC [regions commonly associated with both self-related and social processing ( ,  ,  )] from our social-processing ROI to ensure statistical validity, self-related and social thoughts are conceptually intertwined. Social psychologists have suggested that one’s sense of self is defined by simple rules that include or exclude an individual from certain social groups and practices, resulting in a “social self” concept ( ,  ). In the context of value-based virality, it follows that content that is expected to have positive social outcomes when shared (e.g., because it is helpful to the receiver or results in a positive social interaction) will likely reinforce the perceived positivity of self-related outcomes of sharing (e.g., by making the sharer look charitable and friendly) and vice versa. Nonetheless, our analyses demonstrate that when operationalizations of both self-related and social processing are included in one model, each concept contributes unique variance to the calculation of overall sharing value. In the future, explorations of the relative importance of each cognition and the patterns of their interaction in the calculation of information-sharing value will be valuable. 

Finally, in line with prior investigations in other contexts ( ,  – ,  ), we show links between brain activity in small groups of individuals and large-scale virality, even though the perception of the sharing value of the same content might vary across people, and the same content might appear valuable to different people for different reasons. Although what is personally relevant to the self and useful to share with others might differ somewhat across individuals, human societies are characterized by a set of basic common values and social norms that drive behavior across individuals ( ,  ). Sharing decisions rely on such basic motives, namely, the pursuit of a positive self-image and social belonging ( ,  ). Consequently, similar types of information are likely to be perceived to have high sharing value across individuals. Furthermore, expectations of self-related and social outcomes, two core concepts within value-based virality, are defined broadly as the greatest common denominators of various self-related and social thought processes, respectively. In other words, population-level prediction of virality from neuroimaging of small groups is likely facilitated by broad societal values, the inclusiveness of our theoretical conceptualizations, and the unique information afforded by neuroimaging. Specifically, neuroimaging is optimally situated to identify such high-level, hard-to-articulate cognitions, allowing us to capture relevant cognitions in a parsimonious way despite the variability in the thought processes that different individuals might associate with the same content. Along with this strength, however, we relied on functionally defined ROIs to take optimal advantage of neuroimaging to operationalize these constructs, which are inherently subject to the limitations of reverse inference ( ). 

The results summarized in this article were robust across several methods of analysis, and the hypothesized model outperformed alternative path structures, although causal inferences are limited by the cross-sectional nature of our data. Additionally, a whole-brain analysis did not provide strong evidence for the involvement of neural regions outside our ROIs in population-level virality. Nevertheless, future work might reveal other basic processes that could complement the theory, for instance as additional inputs to the value signal or its antecedents. Further, our effects were robust, even when controlling for self-reported sharing intentions and various article characteristics. In sum, our data highlight the value of including neural variables in the conceptualization of virality in the context of health news and offer a testable and parsimonious framework that could be extended to virality in other contexts. This mechanistic account of sharing decisions complements insights from previous studies using self-report measures or big data approaches (e.g.,  ,  ). 


## Conclusion 
  
Information that elicits greater brain response in self-, social-, and in turn value-related systems is more likely to be shared. These processes may reflect thoughts about the potential outcomes of sharing to the self and to one’s social relationships. If so, self-related and social processes could serve as targets for content designers aiming to increase the virality potential of their messages. Taken together, our data support a parsimonious neurocognitive model of virality, one of the most prominent social phenomena in the 21st century, and shed light on the core functions of sharing—to express aspects of ourselves and to strengthen our social bonds. 


## Methods 
  
Neural activity was examined while two samples of participants (study 1 and study 2) completed the article task ( ) in which participants were exposed to headlines and abstracts of news items taken from the NYTimes website (  https://www.nytimes.com/  ). We then tested for associations between activity within functionally defined, theory-driven ROIs associated with self-relatedness, social processing, and valuation and the number of article retransmissions performed online by NYTimes readers as a population-level indicator of virality. 

Similar protocols were administered in both studies, and each group of participants was presented with the same news items. Differences in data collection and processing between the two studies are detailed below. All models and results reported here were derived using parallel statistical approaches across studies. All participants provided informed consent, and all procedures were approved by the Institutional Review Board at the University of Pennsylvania. 

### Hypothesis Preregistration. 
  
At the onset of study 1, we preregistered our study design ( ), and upon completion of data collection we explored the relationship between neural data and population-level article retransmission. Based on the results in study 1, hypotheses specifying the effects of self- and social-processing on value-related neural activity and of activity in the value-related ROI on population-level virality were preregistered before the analysis of study 2 data ( ). 


### Sample NYTimes Article. 
  
During the article task, participants in both samples were exposed to the original headline and abstract of 80 articles from the Health section of the NYTimes website (  https://www.nytimes.com/  ). The articles were chosen from a complete census (excluding certain article categories to preserve homogeneity in article format; see ref.   for details) of articles (  n   = 760) published online in the 7.7 mo between 11 July 2012 and 28 February 2013. Population-level data about the number of retransmissions of each article through email, Twitter, and Facebook were collected via the NYTimes API. The 80 articles were chosen to maximize comparability regarding topic (healthy living and physical activity) and length (for the word count of title and abstract, see  ). The 80 articles selected into the final sample were of comparable lengths, i.e., a word count (mean ± SD) of 29.43 ± 3.87 words (range, 21–35 words). To control for reading speed in study 1, we produced audio files in which a female voice read each of the article headlines and abstracts. Depending on word count, each audio file was produced to last 8, 10, or 12 s. 

Coded characteristics of each article’s headline and abstract were available as described by Kim ( ). 


### Population-Level Retransmission. 
  
An article’s population-level retransmission count was measured through the NYTimes’ Most Popular API and defined as the sum of retransmissions via Facebook, Twitter, and email using sharing tools available on the NYTimes website within 30 d of the article’s first appearance on the website (mean ± SD, 1,470.14 ± 2,304.32 retransmissions; range, 34–12,743 retransmissions). Retransmission counts for social media (Twitter and Facebook) and email were highly correlated (  r   = 0.917) and thus are not presented separately, although results remain substantively identical when each type of sharing is considered separately. 


### Study 1 Participants. 
  
From a larger sample of respondents who participated in a project examining the neural correlates of retransmission and social influence by filling out a short online survey, we selected 43 participants. These 43 participants completed an online screening process and an in-person appointment including a 60-min fMRI scan. To be eligible for the fMRI portion, screened participants had to meet standard fMRI eligibility criteria including no metal in the body, no history of psychiatric or neurological disorders, not currently pregnant or breast-feeding, and not currently taking psychiatric or illicit drugs. All participants were right-handed. 

Two participants were excluded from analysis because of data corruption. One participant saw only three of the four conditions during the article task, and one participant showed poor normalization to the template brain. Additionally, for four participants a smaller number of trials was available for analysis because of the loss of data from one run of the article task (  n   = 1), excessive head motion in one run of the task (  n   = 2), and technical difficulties in which 23 articles were shown twice, resulting in only 57 trials that qualified as initial exposures to an article (  n   = 1). The partial data from these participants were included in the analyses. The age of the final sample of 41 participants (29 females) was 20.6 ± 2.1 y (mean ± SD) (range, 18–24 y). 


### Study 2 Participants. 
  
Forty participants were selected from the pool of respondents used to select the study 1 sample using inclusion criteria that paralleled those in study 1. These participants underwent an fMRI session. 

Because of excess head movement during the article task, one participant was removed from all analyses, and one run of the article task was discarded for a second participant. The remaining 39 participants (28 female) were 18–24 y old (mean ± SD, 21.0 ± 2.02 y). 


### Study 1 Article Task. 
  
Inside the fMRI scanner, study 1 participants completed two runs of the article task consisting of 40 trials each ( ). Each trial lasted an average of 14.7 s without fixation. At the beginning of each trial a cue screen indicating the current condition was presented for 1.5 s. Then participants read the article’s title and abstract while considering a condition-specific question. In the four conditions participants were asked to consider (  i  ) whether to read the full text of the article themselves, (  ii  ) whether to share the article via a post on their Facebook wall; (  iii  ) whether to share the article via a private Facebook message to one friend (5-point Likert-type scales from very unlikely to very likely), and (  iv  ) whether age/nutrition/fitness/science/laws/well-being/cancer was the topic of this article (5-point Likert-type scale from certainly not to certainly yes). Conditions were presented in a pseudorandom order based on a Latin-square. To control for reading speed, headlines and abstracts were also presented in auditory format through scanner-compatible headphones while the text was presented on the screen. Article abstracts were categorized in three groups depending on the length of the text. Consequently, the reading screen was presented for 8 (  n =   16), 10 (  n =   40), or 12 (  n =   24) s. Article length was counterbalanced across conditions and task runs. The reading screen was followed by a randomly jittered fixation screen that lasted 1.5 s on average (range, 0.5–4.7 s). Participants then used a button box to indicate their answer to the condition-specific question (3 s). Finally, there was a randomly jittered intertrial interval with an average length of 2 s (range, 1–4.7 s). 

In this analysis, we focused on reading trials in which participants viewed the article headlines and abstracts to decide whether they wanted to read the full text of the article (see   for results in other conditions). Furthermore, we only included reading screens within each trial (i.e., periods in which article headlines and abstracts were visible). This task condition closely mimics natural situations in which readers are initially exposed to articles online. 


### Study 2 Article Task. 
  
Study 2 participants completed two runs (21 trials each) of a modified version of the article task ( ). First, each article’s headline and a description of the article were presented on the reading screen for 10 s, and participants were instructed to read the text on the screen. Articles were not presented in auditory format in study 2. Three types of article descriptions were used: Participants saw the original article headline and abstract that also was seen by study 1 participants (  i  ) or saw the original article headline and a Tweet-length message written by a participant in study 1 to be shared either with one Facebook friend (  ii  ) or on the participants’ Facebook wall (  iii  ). The reading screen was followed by a randomly jittered fixation period (mean, 1.5 s; range, 0.3–4.8 s). Afterward, participants provided two ratings per trial: (  i  ) the likelihood they would share the article on their Facebook wall and (  ii  ) the likelihood (on 5-point Likert-type scales paralleling those used in study 1) that they would share the article via a private Facebook message with one friend. Each rating screen was available for 3 s. Rating screens were separated by a short, jittered fixation period (mean, 1.5 s; range, 0.4–4.3 s). Finally, there was a randomly jittered intertrial interval (mean, 2.9 s; range, 0.5–11.5 s). To parallel study 1 analyses closely, only reading screen periods within each trial (i.e., when article headlines and descriptions were visible) and only abstract trials that presented original NYTimes abstracts were analyzed here. The 80 articles used in study 1 were pseudorandomly assigned to experimental conditions for each participant in study 2; however, because of randomization, only 76 articles were presented in the relevant abstract condition across all study 2 participants. 


### A Priori ROIs. 
  
Three neural masks were constructed as functional ROIs based on extensive prior work in each of the respective subject areas ( ). The self-relatedness ROI was defined based on a prior study ( ) that collected neural data using a well-validated self-localizer task ( ) in which participants judge whether personality traits describe them or not (the self-condition) or whether the adjective shown is positive or negative (the valence condition). Blocks of self-judgments are contrasted with blocks of valence judgments to isolate neural activity associated with self-relatedness. 

The social-processing ROI was defined based on a large-scale study that used the well-validated false-belief localizer during which participants engage in mentalizing ( ). Trials during which participants judged whether beliefs held by others were true or false were contrasted to trials in which they judged whether physical representations were true or false to retrieve the mask used here. To avoid inflated correlations among activity in the three neural systems, we created a reduced version of the social cognition mask, excluding the clusters in VMPFC and PCC that overlap with the self and value ROIs. This mask is used in all analyses presented here. Models using the full social-cognition ROI instead of the reduced social-cognition ROI yielded very similar results and support identical conclusions. 

Finally, the valuation ROI was defined based on a quantitative meta-analysis of 206 studies that reported neural correlates of subjective valuation during decision making. This mask represents the conjunction of several valuation-relevant contrasts, all of which required some form of value-based decision making (figure 9 in ref.  ). 


### MRI Image Acquisition. 
  
Neuroimaging data were collected using a 3-T Siemens Magnetom Tim Trio scanner equipped with a 32-channel head coil was used for 40 participants in study 1 and 33 participants in study 2, and a Siemens Prisma 3T whole-body MRI with a 64-channel head/neck array was used for one participant in study 1 and six participants in study 2. Identical specifications were used on both scanners, except for the number of slices acquired for T2*-weighted images (54 at the Tim Trio and 52 at the Prisma scanner). This difference was accounted for in the slice-time correction step during preprocessing. Standard parameters used to acquire T2*- (two runs of 500 volumes in study 1 and two runs of 311 volumes in study 2), T2-, and T1-weighted anatomical image sequences are described in detail in the  . 


### Imaging Data Preprocessing. 
  
For the analysis of data from both studies, we used SPM8 (Wellcome Department of Cognitive Neurology, Institute of Neurology, the University of London), incorporating tools from AFNI (Analysis of Functional NeuroImages) ( ) and FSL (FMRIB Software Library) ( ) during data preprocessing. The first five volumes of each run were not collected to allow stabilization of the blood oxygenation level-dependent (BOLD) signal. Functional images were despiked using 3dDespike as implemented in AFNI. Slice time correction was performed using Sinc (Stanford University ideal bandlimited) interpolation in FSL. Data then were spatially realigned to the first image and were coregistered in two six-parameter affine stages. First, mean functional images were registered to in-plane T2-weighted images. Next, high-resolution T1 images were registered to the in-plane image. After coregistration, high-resolution structural images were segmented into gray matter, white matter, and cerebral spinal fluid to create a brain mask used to determine the voxels to be included in first- and second-level models. The masked structural images then were normalized to the skull-stripped Montreal Neurological Institute (MNI) template provided by FSL (MNI152_T1_1mm_brain.nii). Finally, functional images were smoothed using a Gaussian kernel (8 mm FWHM). The fMRI data were modeled for each participant using fixed-effects models within the general linear model as implemented in SPM8, using SPM’s canonical difference of gamma hemodynamic response function (HRF). The six rigid-body translation and rotation parameters derived from spatial realignment were also included as nuisance regressors in all first-level models. Data were high-pass filtered with a cutoff of 128 s. Random effects models for the article task were also implemented in SPM8. 


### Analysis of Study 1 Imaging Data. 
  
We took an itemwise approach to modeling the article task using procedures similar to those used elsewhere ( ,  ). Specifically, using a single boxcar function for each trial (i.e., each of the 80 articles) encompassing the 8- to 12-s reading screen, we extracted neural activity in each ROI during each trial compared with the implicit baseline resting state. Activity related to cue and all rating screens was pooled into a separate regressor of no interest each. In addition, the model for one participant who accidentally saw several articles twice included an additional regressor of no interest for each second occurrence of an article. Fixation periods were pooled into the implicit baseline rest. 


### Analysis of Study 2 Imaging Data. 
  
Study 2 data were analyzed using methods parallel to those applied to study 1 data to yield comparable models. Specifically, using a single boxcar function for each of the 42 trials per participant, encompassing the 10-s reading screen, we extracted neural activity observed during each trial compared with the implicit baseline resting state. A regressor of no interest was included for each of the two rating screens. Fixation periods were pooled into the implicit baseline rest. 


### Path Models. 
  
For each a priori ROI, average parameter estimates of activity across all voxels within the region were extracted for each participant and each article using Marsbar ( ). Each set of parameter estimates was divided by the grand mean to derive estimates of the percent signal change. Percent signal change vectors for each participant were reduced to those trials shown in the reading condition for study 1 and in the abstract condition for study 2. For each participant, these reduced vectors were then z-scored and ranked across articles. As in prior work ( ), we then computed the mean ranks of each article across participants and linked these data with the ranked population-level data from the NYTimes API separately. 

Specifically, we conducted path analyses using maximum likelihood estimation in lavaan ( ) to yield the results presented in  . Nonparametric, bias-corrected 95% confidence intervals (CIs) for indirect effects using 1,000 bootstrap samples were further estimated using the mediation package for R ( ) to test for indirect effects of self-related processing and social processing on population-level retransmission through valuation (  for relevant correlation matrices). 


### Robustness Checks. 
  
To check the robustness of our results, we fit (  i  ) models using unranked variables in which population-level retransmission counts were log-transformed because of the positively skewed distribution (  and  ), (  ii  ) models excluding the insignificant direct effects of the exogenous variables shown in   to obtain model fit statistics ( ), and (  iii  ) alternative structural models to those estimated in step   ii   to compare model fit (  and  ). 


### Whole-Brain Analysis. 
  
We conducted exploratory whole-brain searches for regions associated with population-level retransmission ranks in study 1 and study 2 to verify the specificity of our results to our ROIs and to explore whether additional activity outside these ROIs is associated with population-level virality ( ). 


### Models Including Self-Reported Sharing Intentions and Article Characteristics. 
  
We further tested whether the predictions of value-based virality held above and beyond the variance explained by self-reported sharing intentions (  and  ) and article characteristics ( ). 

Study 1 participants provided one rating (intention either to broadcast or narrowcast) for 40 articles. For each article, we computed a mean sharing intention across participants including all available narrowcast and broadcasting ratings. 

Study 2 participants provided both narrowcast and broadcasting ratings for all 42 articles shown to them. For trials shown in the abstract condition, we first calculated a mean sharing intention across the two ratings for each article within participants and then computed a mean sharing intention for each article across participants. 

First, ranked population-level retransmission was regressed onto sharing intentions to estimate the effect of intentions on virality in each sample. Second, we reestimated the models shown in   with self-reported intentions specified as an additional exogenous variable with a direct effect on population-level retransmission. This step was further repeated for each available article characteristic ( ). 



## SI NY Times Article Sample 
  
We selected 80 articles from the full set of 760 articles analyzed in ref.   with the goal of maximizing comparability in topic and length. Specifically, we conducted a keyword search of the full set of 760 articles using the following terms: exercise, fitness, physical activity, running, swimming, skiing, soccer, walking, food (excluding “Food and Drug Administration”), eating, nutrition, nutrient, diet, vitamin, calcium, carbohydrates, gluten, caffeine, cholesterol, obesity, and weight. The search retrieved 143 articles. A closer examination revealed that four articles were irrelevant, and these articles were removed. Of the remaining 139 articles, the 80 that were most similar in length were chosen. 


## SI Scanning Parameters 
  
We captured neural activity during two runs of the article task (500 volumes in each run in study 1 and 311 volumes in each run in study 2) using a T2*-weighted image sequence [repetition time (TR) = 1.5 s, echo time (TE) = 25 ms, flip angle = 70°, −30° tilt relative to the anterior commissure–posterior commissure (AC–PC) line, 54 slices at the Magnetom Tim Trio scanner, 52 slices at the Prisma scanner, field of view (FOV) = 200 mm, slice thickness = 3 mm, multiband acceleration factor = 2, voxel size = 3 × 3 × 3 mm]. High-resolution T1-weighted anatomical images were collected using a magnetization-prepared rapid gradient-echo (MPRAGE) sequence [inversion time (TI) = 1,110 ms, 160 axial slices, voxel size = 0.9 × 0.9 × 1 mm]. Finally, we collected an in-plane, structural, T2-weighted image (slice thickness = 1 mm, 176 axial slices, voxel size = 1 × 1 × 1 mm) to implement a two-stage coregistration procedure between functional and anatomical images. 


## SI Robustness Checks 
  
To test the robustness of our main results reported in  , we estimated models using unranked variables. These analyses produced results similar to those presented in the main text and supported identical conclusions (  and  ). Further, models excluding the insignificant direct effects of the two exogenous variables on virality shown in   were estimated to obtain model fit statistics. Both models revealed satisfactory model fit for the hypothesized structural model, considering its small degrees of freedom (df) and small sample size ( ):   (2) = 2.36,   P   = 0.31, comparative fit index (CFI) = 0.997, residual mean square error of approximation (RMSEA) = 0.05, 90% CI (0.00, 0.23) for study 1;   (2) = 3.26,   P   = 0.20, CFI = 0.986, RMSEA = 0.09, 90% CI (0.00, 0.26) for study 2. Additional analyses revealed the model fit for the hypothesized path structure was superior to that of alternative structural models ( ), providing additional confidence to our proposal that valuation, taking inputs from self and social considerations, serves as a final common pathway. 


## SI Study 1 Whole-Brain Analysis 
  
To test the specificity of our results to our theory-driven ROIs, we conducted exploratory whole-brain analyses. We first created first-level models for each participant that included a separate boxcar function for activity across all trials within a certain condition (content, reading, broadcasting, narrowcasting) for the reading screen and the rating screen of the article task, respectively (eight regressors). An additional regressor represented the boxcar function representing the reading screen during reading trials modified by a mean-centered parametric modulator of population-level virality ranks of each article. Population-level virality ranks were derived by ranking all articles presented within the reading condition by their population-level retransmission counts for each participant (range, 1–20). The model also included a boxcar function for activity across all trials within the cue screen and six nuisance regressors to control for motion. Finally, to ensure that only first exposures were modeled in the main regressor of interest, one regressor of no interest was entered to account for trials in which one participant was accidentally presented with an article for a second time. Second, at the group level, neural activity was pooled for all participants to examine the main contrasts of interest: activity during the reading screen in reading trials modulated by population-level retransmission ranks compared with implicit baseline. 

To balance the risks of false positives and false negatives, we conducted two different kinds of correction for multiple comparisons to derive whole-brain maps and tables of voxels in which neural activity scales with population-level virality (  and  ). The first whole-brain map was thresholded at   P   < 0.005 and   K   ≥320, where   K   is the number of voxels per cluster, to produce a threshold of   P   < 0.05, corrected using 3dClustSim simulation (version AFNI_16.2.02). Although the type 2 error rate can be expected to be lower for this method of analysis, prior work has shown that cluster correction tends to overestimate the number of significant voxels and thus increases the type 1 error rate ( ). Consequently, we also present the results of a more stringent whole-brain correction that controls the number of false positives more efficiently. Specifically, we used nonparametric permutation testing (5,000 iterations) and false-discovery rate (FDR) correction for a voxelwise   P  -threshold of   P   < 0.05 and   K   ≥10 as implemented in the SnPM13 toolbox ( ). (Study 1 results for multiple comparisons correction using nonparametric permutation testing corrected at FDR   P   < 0.05 vary across individual runs of the 5,000 permutations protocol implemented here, because of random elements in this analysis technique. Specifically, although several runs produced maps similar to the map printed in  , these results border on   P   < 0.05. All runs of the permutation protocol for study 1 produced maps that looked very similar to the one printed here at   P   < 0.06 or   P   < 0.07. Study 2 results are highly robust across several runs of the permutation protocol,   P   < 0.05, FDR corrected.) 


## SI Study 2 Whole-Brain Analysis 
  
To conduct a parallel whole-brain analysis for study 2 participants, we first created first-level models for each participant that included a separate boxcar function for activity across all trials within a certain condition (abstract, narrowcasting, broadcasting) for the reading screen (three regressors) of the article task. Separate regressors for rating screens were further derived depending on the condition presented on the reading screen (six regressors in total). Crucially, an additional regressor specified the boxcar function representing the reading screen during abstract trials modified by a mean-centered parametric modulator of population-level virality ranks of each article. As for study 1, virality ranks were derived by ranking articles shown within the abstract condition by their population-level retransmission counts for each participant (range, 1–14). The model also included six nuisance regressors to control for motion. Second, at the group level, neural activity during the main task was pooled for all participants to examine the main contrasts of interest: activity during the reading screen in abstract trials modulated by population-level virality ranks compared with the baseline resting state.  ,  , and   for details and results. 

In parallel to study 1 analyses, whole-brain maps were thresholded via 3dClustSim simulation at   P   < 0.005 and   K   ≥296 (version AFNI_16.2.02) and nonparametric permutation testing (5,000 iterations) and FDR correction for a voxelwise   P  -threshold of   P   < 0.05 and   K   ≥10 as implemented in the SnPM13 toolbox ( ). Results are reported in   and  . 


## SI Analysis of Other Article Task Conditions 
  
In the main text, we focus on neural activity extracted from reading trials in the study 1 article task ( ) because the reading condition most closely represents real-world experiences of NYTimes readers who are unlikely to visit the website to find an article to share with somebody. Instead, readers are more likely to browse abstracts and consider reading various articles until one article motivates them to share it with somebody else. 

Nonetheless, an additional question to consider is the extent to which task instructions affect the relationship between neural activity during article exposure and population-level sharing. Therefore we examined the relationship between value-related neural activity in our value ROI in response to an article’s headline and abstract and population-level article retransmission data, focusing separately on narrowcasting trials in which participants were primed before each trial via a cue screen to consider sharing articles with one Facebook friend and broadcasting trials in which participants were primed to consider sharing the article on their Facebook wall. Note that this analysis is not possible for study 2 data, because the other two conditions, not analyzed in the main text, are not comparable to those in study 1 and did not include the presentation of original article abstracts. 

Results show that value-related neural activity in response to articles shown in a sharing condition is marginally related to population-level virality in the case of narrowcasting trials [  r   = 0.184,   P   = 0.10] and is not significantly related to population-level virality in the case of broadcasting trials [  r   = 0.133,   P   = 0.24]. Individual-level data from study 1 suggest that explicit instructions to share (i.e., the two sharing conditions) increase the overall level of sharing-relevant brain activity compared with instructions to consider reading the full text of an article (i.e., the reading condition analyzed here; ref.  ). However, we also found that these explicit instructions reduce the variance in value-related activity, which is larger for reading trials (s  = 5.10) than for narrowcasting (s  = 4.18) and broadcasting (s  = 3.24) trials. This ordering of conditions according to variance in information-sharing value corresponds to the condition ordering in terms of the strength of the relationship between value-related activity and population-level virality. If this interpretation is correct, one potential implication could be that sharers are likely to share articles based on “gut” decisions, which are better represented by the reading trials, which did not specifically give participants the goal of sharing in each trial, than by longer elaboration, which is better represented by sharing trials. 


## SI Article Characteristics 
  
In a content-focused investigation of 760 NYTimes health news articles that included the 80 articles used here, Kim ( ) characterized the article headlines and abstracts by analyzing human (i.e., the presence of efficacy information or the mention of diseases or bad health conditions) and computerized (expressed positivity: the difference between the number of positive and negative words; expressed evocativeness/arousal: the sum of positive and negative words) content and with the help of lay human raters (perceived usefulness, induced positivity, perceived controversiality, induced evocativeness/arousal, and perceived novelty). Here we explore the relationship between these content characteristics and concepts within our value-based virality framework as well as population-level virality. 


## SI Analysis of Article Characteristics 
  
Prior work has shown that content characteristics can impact virality ( ,  ), and this argument has been made particularly effectively in the case of news articles ( ,  ). Consequently, we explored the role of content characteristics in value-based virality. Specifically, content characteristics might be involved in three different ways. (  i  ) Article characteristics might affect virality directly and independently of variables included in the value-based virality model. If so, it would be of interest whether neural data explain the variance in population-level sharing over and above that explained by article characteristics. (  ii  ) Article characteristics might affect information-sharing value directly or via some other mechanism not currently included in the value-based virality model. (  iii  ) Article characteristics might be antecedents of thoughts regarding the self-related and social outcomes of sharing. 

To explore these possibilities, we first checked whether the predictions made by value-based virality ( ) hold even when controlling for article characteristics. For this purpose, we estimated models identical to the one in   but for the sake of parsimony excluded the insignificant direct effects of self-related and social processing on virality. Each model additionally included a direct effect of one article characteristic on population-level virality. Paralleling other analyses presented in this article, all variables were rank-ordered. In both studies, the effects presented in   were robust when controlling for any of the nine article characteristics considered here. In fact, the only article characteristic that showed a significant effect on population-level virality in these models was the perceived usefulness of an article [  B   (unstandardized estimate of this parameter) = 0.202, SE = 0.101,   P   = 0.04] in study 1, but this effect did not replicate in study 2. 

Second, we examined the relationships between each of the nine content characteristics available to us and average neural activity in regions associated with self-related and social processing in response to each article using   t   tests and Pearson correlation where appropriate. Paralleling other analyses presented in this article, all variables were rank-ordered. 

In study 1, we found a positive relationship between induced positivity in an article and neural activity in the self-related processing ROI [  r   = 0.231;   P   = 0.04]. In addition, articles that mentioned diseases or negative health issues (mean, 9.74) were associated with less self-related processing than articles that did not [mean, 10.70;   T  (78) = 2.24;   P   = 0.03] in study 1. However, these effects did not replicate in study 2. 

Finally, we explored direct effects of article characteristics on information-sharing value (i.e., average neural activity in our value-related processing ROI) using analytical strategies identical to those explained above. Value-related neural activity was positively related to the extent to which articles induced positivity in human raters [  r   = 0.309;   P   = 0.005], and articles that mentioned diseases or bad health conditions (mean, 9.50) engaged less value-related activity than articles that did not [mean, 10.96;   T  (78) = 3.04;   P   = 0.003]. However, these effects did not replicate in study 2. 

In sum, our results hold, even when controlling for the effects of various article characteristics on virality, suggesting that neural activity contributes information over and above what can be learned from variables commonly used in the literature on virality ( ,  ). In contrast to prior work, most article characteristics did not predict population-level sharing. This dissonance with existing studies might be the result of methodological differences among studies. Most notably, previous reports of effects between article characteristics and population-level sharing showed relatively small effect sizes that were identified only in very large samples (e.g.,   n   > 6,000 in ref.   and   n   = 760 in ref.  ). Because of time restrictions in the fMRI scan, we were not able to replicate these article sample sizes. Nonetheless, our ability to predict virality from neural variables even in this small sample of articles speaks to the strength and utility of fMRI. 

In addition, we identified selected relationships between individual article characteristics and the extent to which articles engaged neural activity associated with self-related, social, or value-related cognition in study 1. Although these relationships generally did not replicate in study 2, these findings might suggest that content characteristics could be promising candidates in the search for antecedents of the psychological processes that affect sharing. The lack of robustness of these effects might be due to the small sample size and homogeneity of articles. In addition, it is possible that sharing-relevant cognitions are more sensitive to combinations of article characteristics (e.g., the emotional tone in combination with the topic) than to isolated characteristics. However, the specific combination of article characteristics that enhances expectations of positive social or self-related outcomes of sharing might be highly context dependent. An exploration of the large number of potential interaction terms is beyond the scope of this investigation. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-58'>
<h2>58. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/19826471/' target='_blank'>19826471</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Understanding Others' Regret: A fMRI Study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2009</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0007402</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/2756584/' target='_blank'>2756584</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This fMRI study investigates the neural basis of understanding others’ regret (a social cognition task: perception and understanding of others). Participants were healthy adults (two studies; n=24 each; ages within 19–31.8), meeting the age and health criteria. Analysis used whole-brain random-effects voxelwise analyses (SPM5), conjunction and parametric whole-brain contrasts thresholded at p<0.001 uncorrected and reported cluster results across the brain (not restricted to ROIs). Results for healthy participants are reported separately. No exclusion criteria are violated. Therefore the study meets all inclusion criteria for whole-brain fMRI studies of social-related processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Previous studies showed that the understanding of others' basic emotional experiences is based on a “resonant” mechanism, i.e., on the reactivation, in the observer's brain, of the cerebral areas associated with those experiences. The present study aimed to investigate whether the same neural mechanism is activated both when experiencing and attending complex, cognitively-generated, emotions. A gambling task and functional-Magnetic-Resonance-Imaging (  f  MRI) were used to test this hypothesis using   regret  , the negative cognitively-based emotion resulting from an unfavorable counterfactual comparison between the outcomes of chosen and discarded options. Do the same brain structures that mediate the experience of regret become active in the observation of situations eliciting regret in another individual? Here we show that observing the regretful outcomes of someone else's choices activates the same regions that are activated during a first-person experience of regret, i.e. the ventromedial prefrontal cortex, anterior cingulate cortex and hippocampus. These results extend the possible role of a mirror-like mechanism beyond basic emotions. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (44749 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
From the early stages of cognitive development, humans are able to represent and understand others' mental and emotional states  . It has been suggested that the neural bases of this ability may rely on the mirror mechanism  ,  . The mirror mechanism has been investigated in two major domains, i.e. sensorimotor and emotional, involving two main circuits. One is located on the lateral convexity of the cortex, and includes the inferior parietal lobule (IPL) and the ventral premotor cortex plus the caudal part of the inferior frontal gyrus (IFG). This circuit mediates the understanding of gestures and meaningful actions  ,  . The second circuit, which includes the insula and anterior cingulate cortex (ACC), is involved in the experiential understanding of others' emotional states shaping interpersonal relations at a basic level  – . 

Although there may be several ways in which others' emotions can be understood, recent studies indicate that one such mechanism is based on the reactivation of the cerebral areas associated with the observer's direct emotional experience  . Yet, neural mirror-responses have been assessed only in conditions involving basic-level emotional stimuli, such as visual expressions of disgust   or cues signaling pain  . As far as complex emotions are concerned, to date there is only behavioral evidence to suggest the involvement of a mirror-like mechanism in the automatic understanding of others' emotional states  ,  . 

To further advance our understanding of complex emotional processes, the present study investigates whether the understanding of others' negative emotions involves the activation of the same neural mechanism as in the first-person experience. Specifically, we investigated whether a neural resonance system is also engaged in situations involving complex emotions that emerge at the interface with high-level cognitive processing. To this purpose we used   regret  , a cognitively-based emotion that occurs when one's outcome is worse than the outcome one would have obtained had one made a different choice. Unlike basic emotions, regret stems from the counterfactual comparison between alternative outcomes, as when the chosen option in a gamble results in a negative outcome   compared with   that of the unselected alternative  . The possibility to quantify and evaluate the values associated with unselected alternatives, resulting in better outcomes than the one obtained, is crucial for regret to occur. Additionally, the emotion of regret is elicited when the individual feels a personal responsibility upon the outcome of her/his deliberate choice. Without these prerequisites, regret would be replaced by the basic emotion of disappointment. 

Evidence that regret and disappointment are mediated by neural structures only partially overlapping comes from clinical   and brain imaging studies  , that employed gambling to assess the neural underpinnings of these emotions. These studies showed that the experience of regret specifically involves the activation of the medial orbito frontal cortex (mOFC)  ,  , ACC and hippocampus  . 

In the present work, we extended the studies on regret by investigating whether the same cortical areas involved in the first person experience of regret become active also when the individual is faced with emotional experiences of regret in others. Two   f  MRI studies testing mirror-like responses to regret were carried out. In both studies, participants chose one of two gambles resulting in real wins or losses, like in previous investigations  ,  . Unlike previous works, though, in the present studies the participants also observed the same sequence of events (gambles evaluation, decision, outcome evaluation), this time experienced by another individual (see  ). 
   Experimental conditions, Studies 1 and 2.  
From left to right, schematic depiction of the sequence of events in the conditions IP (“I play”, top) and OP (“Other plays”, bottom). Within each condition there are 5 phases: instruction, evaluation of the wheels, choice of the gamble, outcome evaluation and judgment of the outcome. In the depicted example, the participant chose the loosing wheel. The length in seconds of each sub-event in the two studies is shown, in the inferior-most part of the figure. 
  
As noted above, regret results from a sense of responsibility. Therefore, to address specifically regret, as opposed to disappointment, in two control conditions a computer program randomly chose one of the gambles for the participant or for the other player. In these instances, the computer choices still resulted in real monetary gains or losses for the players but, given the participants' lack of responsibility upon the gamble selection, the game outcome did not result in the feeling of regret  . 

The main difference between the two studies lies in the nature of the participants' task when presented with the outcomes obtained. In the first study, we ensured that the participants' emotional reaction to the results of the gambles was consistent with the actual counterfactual comparison between the obtained and unobtained outcomes (i.e., satisfied or unsatisfied with the outcome). In this way, we could also assess the participants' understanding of the other players' emotional state at outcome evaluation during “Other Plays” condition. More precisely, the participants were asked to indicate, after each trial, whether they were satisfied with their own decision (“I Play” condition) or whether, in their opinion, the other player was satisfied with her/his decision (“Other Plays” condition). Although this response was necessary to unfold the participants' emotional coherence with the actual outcomes in both IP and OP tasks, this type of judgment, by its nature, is likely to prompt an emotional response in the beholder. Since one requirement for a mirror response is its automaticity, to make sure that the observed activations were not affected by the explicit emotional appraisal of the gamble results, in the second study participants were required to give a non-emotional evaluation of the outcomes indicating whether results represented a win or loss. 

Finally, to shed light on the question of whether the engagement of a resonance mechanism when attending someone else's experience of regret is affected by the individuals' empathic aptitude, we compared brain activations of females and males, under the assumption that females are more empathic than males  . 


## Results 
  
### Study 1 
  
The reported activations are based on the contrasts between the conditions where the players (the participant or the actor) made the decision   versus   the control conditions (IP   minus   IF; OP   minus   OF). These contrasts aimed at controlling for activations merely related to the carrying out of the tasks (e.g. visual, motor, etc.) and to highlight those underlying regret, i.e. outcome evaluation when one was responsible for her/his own choices. Behavioral measures confirmed that participants paid attention to the outcomes of all experimental conditions (see   for details). 

In line with previous works on the neural correlates of regret processing  , a   parametric   analysis was carried out to highlight the regions showing a positive linear relationship between regional signal change and the objective amount of regret in the condition “IP   minus   IF” or “OP   minus   OF”. Additionally, to investigate the possible involvement of a resonance-mapping system for regret, we focused on the   common   parametric effects across tasks, that is on the cerebral regions activated both when experiencing regret (IP   minus   IF) and when being aware of regret experienced by someone else (OP   minus   OF) (see  –  and   for the description of the activated foci in the IP and OP tasks separately, as well as in the formal direct comparisons between them). 

The conjunction analysis between IP and OP statistical maps (relative to IF and OF, respectively; p<0.001 uncorrected) revealed significant common parametric activations in the left ventromedial prefrontal cortex (vmPFC), left amygdala and bilaterally in the hippocampus ( ,  ). Common parametric activations were also observed in the dorsal anterior cingulate cortex (ACC), and in a cluster extending from the supplementary motor area (SMA) to the middle cingulate cortex, as well as in the right middle temporal gyrus. 
   Common parametric effects of   regret   in Studies 1 and 2.  
Activations linearly and positively related to the objective amount of regret (measured as the difference between the outcomes of the chosen and unchosen gambles) in   both   the IP (  minus   IF) and OP (  minus   OF) conditions in Studies 1 and 2 (Conjunction analysis; p<0.001 uncorrected). a) Study 1: representative sections from the MNI305 template brain. From left to right: sagittal section showing activations in supplementary motor area (SMA), middle cingulate cortex and anterior cingulate cortex (ACC); horizontal section showing activations in ventromedial prefrontal cortex (vmPFC) and hippocampus (HIP); horizontal section showing left amygdala and right middle temporal gyrus activations. b) Study 1: from left to right, percent BOLD signal change (4 mm-radius sphere centered on the local maxima) in the Anterior Cingulate Cortex (ACC), ventromedial prefrontal cortex (vmPFC) and Hippocampus (HIP) is shown for both “I Play” (IP, yellow) and “Other Plays” (OP, blue) conditions. c) Study 2: representative sections from the MNI305 template brain. From left to right: sagittal section showing activations in middle cingulate cortex and ACC; horizontal section showing activations in vmPFC and HIP; coronal section showing right HIP activation. d) Study 2: from left to right, percent BOLD signal change in the same areas as in b). 
     Study 1, parametric analysis of   regret  : conjunction IP and OP conditions.        
To make sure that these results did not only reflect an emotional response to a negative outcome   per se  , in a separate analysis we investigated the regions where activity was related to   disappointment   (i.e., win or loss in the chosen gamble, independent of the outcome of the unselected one). Common parametric activations to IP and OP tasks were observed in a number of areas including the left postcentral gyrus, the parahippocampal gyrus bilaterally, thalamus and brainstem periaqueductal grey matter ( ,  ) but, crucially, in neither vmPFC nor ACC. 
   Common parametric effects of disappointment in Study 1.  
Shared effect of the parametric amount of disappointment (measured as the difference between the actual and unobtained outcome of the chosen gamble) across IP (  minus   IF) and OP (  minus   OF) conditions in Study 1, as shown by the results of a conjunction-analysis (p<0.001). 
     Study 1, parametric analysis of   disappointment  : conjunction IP and OP conditions.        

### Study 2 
  
Like in study 1, here we carried out a conjunction analysis of the parametric effects observed between IP (  minus   IF) and OP (  minus   OF) conditions. This analysis confirmed the results of study 1, in that mirror-like effects were found in the left ventromedial PFC and dorsal anterior cingulate cortex ( ,  ). As far as hippocampal activation is concerned, in study 2 we found a stronger activation in the right hemisphere, as opposed to an enhanced activation observed in the left hemisphere in study 1. However, these results are not in conflict since, as it can be observed from  , a parametric effect of regret was observed in the right hippocampus in both IP and OP conditions also in study 1, though the respective foci did not overlap. Finally, a few differences were observed with respect to study 1, the most notable being a lack of activation of the left amygdala. 
   Study 2, parametric analysis of   regret  : conjunction IP and OP conditions.        

### Individual Empathy-Scores and Gender Effects 
  
During a post-scanning session, participants had to complete an Italian translation   of the Balanced-Emotional-Empathy-Scale (BEES;  ), a test assessing emotional empathy. 

Behavioral data from the BEES showed that the mean scores for our participants in study 1 were 34.83 (s.d. = 16.75) for females and 19.33 (s.d. = 18.39) for males. These data were representative of the normal Italian population (female mean = 37, s.d. = 18; male mean = 21, s.d. = 18;  ) and revealed a significant gender difference, females being more empathic than males (Kolmogorov-Smirnov test for normality:   d   = 0.091,   p  >0.2; two-sample t-test, N = 24,   t  (22) = 2.15,   p   = 0.042). 

Consistent with these results, direct gender comparisons carried out in the parametric statistical maps of the third-person task (OP   minus   OF) revealed stronger activations for females than males in the ventromedial PFC, in ACC and in portions of the parietal cortex bilaterally, including the somatosensory cortex and the inferior parietal lobule ( ,  ). 
   Differential parametric effects of gender on attended regret in the “Other Plays” (OP) condition.  
The different linear parametric effect of regret for female   vs  . male participants in Studies 1 (a) and 2 (b) (thresholded at p<0.001 uncorrected) in the OP (  minus   OF) condition are shown on 3D-renderings and representative slices of the MNI305 template brain. 
     Study 1, parametric analysis of   regret  : direct gender-comparisons in OP condition.        
These findings were confirmed in OP condition (  minus   OF) of study 2, where enhanced activations for females with respect to males were observed in the ventromedial PFC and somatosensory cortex bilaterally ( ,  ). However, unlike study 1, an enhanced activation for females was also observed in the anterior insula bilaterally ( ). This result can be interpreted in relation to the behavioral scores obtained on the BEES in study 2, that not only showed a higher mean difference between females and males than that observed in study 1, but also higher scores for females with respect to those obtained by their peers from study 1 (females' mean = 53.83, s.d. = 11.37; males' mean = 23.08, s.d. = 27.11; Kolmogorov-Smirnov test for normality:   d   = 0.19, p>0.2; two-sample t-test, N = 24,   t  (22) = 3.62,   p   = 0.007). 
   Study 2, parametric analysis of   regret  : direct gender-comparisons in OP condition.        


## Discussion 
  
The aim of the present study was to investigate whether the understanding of complex emotions, like regret, in others involves the reactivation of the cerebral areas associated with the observer's direct emotional experience. Regret is a negative emotion arising from a counterfactual comparison between the outcome of chosen and discarded options, whereby the discarded option would have produced higher benefits to the individual  . Regret thus requires two conditions to occur: namely, the feeling of responsibility for the decision made and a post-decisional evaluation of possible unselected alternatives associated with better outcomes than the one obtained. These two conditions define the emotional and cognitive differences underpinning regret with respect to other negative emotions like disappointment for a loss  . 

In this study we controlled for the effect of regret on cerebral activity by means of methodological and statistical measures. Methodologically, we dealt with the players' feeling of responsibility by comparing the conditions in which the participants actively made a deliberate choice (IP, OP) with control conditions in which choices were randomly made by the computer (IF, OF). Statistically, we used a parametric analysis to investigate only those areas whose activity showed a positive relation with increasing levels of regret. Specifically, we modeled the difference between the outcome of the chosen and unchosen gambles, so that also positive outcomes could result in regret if compared to an even more positive unselected outcome. Violation to these assumptions (feeling of the responsibility and counterfactual evaluation) lead to another emotional state, namely disappointment, even when faced with the same amount of loss. 

The neural correlates of regret processing have been previously investigated using   f  MRI. These studies, carried out on healthy volunteers playing a gambling task similar to that employed in the present experiments, showed that the experience of regret is associated with the activation of OFC alongside structures involved in cognitively-induced responses to aversive and painful stimuli (ACC), and in declarative memory (hippocampal regions)   (see also   below). 

What distinguishes the present study from the previous ones is a specific focus to the understanding of the experience of regret when observing someone else experiencing it, i.e. a resonance mirror effect that, to date, has been investigated only with basic-level emotional stimuli. Among the studies addressing mirroring in the emotional system, of particular interest is the   f  MRI study by Singer   et al.  , where volunteers either experienced a painful stimulus or observed a cue indicating that their loved one, present in the same room, was receiving a similar stimulation. The areas that were activated both when the volunteers were experiencing pain and when they knew that the other individual was experiencing it, were the anterior insula bilaterally and the ACC. Similar results were reported also for disgust. As for pain, feeling disgust or observing someone expressing it activates the anterior insula and the ACC  . 

In line with these studies  ,   (see also  ,   and   for a review), we focused on the common effects observed in the cerebral regions that were activated both when experiencing regret (IP   minus   IF) and when observing the regretful outcome of another player (OP   minus   OF). 

Our data on the parametric effects common to IP and OP tasks (relative to baseline) in both studies 1 and 2 revealed several activation foci including the ventromedial prefrontal cortex, the dorsal anterior cingulate cortex (ACC) and hippocampus (  and  ,  ). These results confirm previous findings  ,   and, crucially, show that the activation of these regions also occurs when participants observe the other player's regretful outcomes. It is worth noting that the results from study 1 revealed a modulation of activity also in the amygdala that was not confirmed in our second study. In this respect, it is likely that, in study 1, amygdala activation was enhanced by the emotional nature of the judgment provided by the participants, and lack of activation in study 2 shows that modulation of its activity is not specific for regret. This lack of emotion-specificity is in contrast with vmPFC activation that, on the other hand, is core to the expression of regret. 

Largely on the basis of evidence coming from animal studies, the   medial   portion of ventral prefrontal cortex is thought to be associated with positive reward processing, as opposed to its   lateral   part that instead is supposed to be involved in the processing of negative stimulus valence  . However, several studies have highlighted a more complex picture, according to which the medial portion of ventral prefrontal cortex is engaged in the processing of both positive and negative emotional events  . What the present and previous works strongly suggest, however, is that not all types of emotion are associated with vmPFC activation; rather there seems to be a specific involvement of this area in the processing of complex emotions. A convincing evidence in this respect comes from clinical studies, showing that patients with medial PFC lesions that performed a gambling task similar to that employed in this study could not process the emotion of regret elicited by the counterfactual comparison between the selected outcome and those of unselected alternatives  . Notably, however, those patients could exhibit emotional arousal to a loss when the observation of post-decisional outcome did not induce any counterfactual reasoning, i.e. disappointment. 

These results confirm the view that vmPFC defines the emotional value of the error given by the difference between the obtained outcome and the unselected alternatives that, if chosen, would have produced better results. This error, which emotionally results in the negative feeling of regret, is a necessary drive for behavioral reorganization. Anterior cingulate cortex uses information about the emotional valence of unsuccessful behavior to re-organize future choices accordingly  . In other words, the negative emotion associated with regret is the basis of the motivation to workout alternative solutions in response to the reoccurrence of future similar situations. This motivation lacks in disappointment, where the individual has no feeling of responsibility upon the outcome and is powerless with respect to her/his loss. 

Core of this study are the common effects observed between the conditions IP and OP (after baseline subtraction), which indicate that vmPFC-ACC and hippocampal activations mediate the processing of regret not only when directly experienced, but also when knowing that someone else is facing a counterfactual negative outcome. More specifically, this finding shows that the understanding of others' regret is mediated by the reactivation of the same core cerebral regions that induce the feeling of regret in the beholder during a first person experience, hence supporting the involvement of a resonance, mirror-like, mechanism in the comprehension of the high-order emotion of regret when experienced by others. Through this mechanism, others' emotional states are mapped onto the same areas that underlie ones' own direct experiences, therefore allowing an automatic understanding of the cognitive/emotional states intrinsic to the complex emotion of regret in others. 

So far, there was only behavioral evidence to suggest that the mere observation of a negative situation occurring to another individual evokes in the observer the same mental processes as those of the acting individual. These investigations assessed counterfactual reasoning in social contexts by comparing reported mental simulation  s   of actors, readers and observers of different situations all resolving negatively  ,  . These studies showed that actors (who made a decision and obtained a negative outcome) and readers (who read a story describing the actor's choice and outcome) produce different counterfactuals by focusing attention on different aspects of the situation  . However, when comparing actors' and observers' counterfactuals, these studies show that observers (who directly observed the actors' negative resolving situations) tend to mentally simulate alternative post-decisional solutions to those situations as actors themselves do  . These results suggest that, when faced with the negative outcome of another person's choices, individuals tend to react as they were personally involved in that situation. 

Attending another's negative emotion, however, is a complex phenomenon that can elicit different and conflicting reactions in the beholder, as shown by two recent studies that have highlighted some of the several facets related to the understanding of others' emotions. These studies have addressed individuals' emotional responses arising from direct   social comparisons  ,  . In Takahashi   et al.  , experimental contexts were defined a priori so as to elicit in the participants either the emotion of envy or gloating (  schadenfreude  ).   f  MRI technique allowed to associate these emotions to the activation of dorsal ACC (envy) and of ventral striatum plus medial OFC (gloating), supporting the view that OFC activation is not specific for the processing of negative emotions. Bault   et al.  ,  , on the other hand, assessed the effects of one's own and others' previous outcomes on choice behavior in a gambling task. The authors observed that, when individuals played simultaneously on the same trials, the emotional (as assessed trough skin conductance response and heart-rate recording) and behavioral effects of envy and gloating (when the players made different choices) are stronger than the effects of regret and relief (when they made the same choices). In other words, these data show that, in a direct social confrontation, individuals' choice behavior is more strongly affected by the feelings of envy and gloating than by the emotions of regret or relief. 

At a first glance, based on data from both these investigations, one might argue that the neural activations observed in the present study during “Other Plays” condition could relate to the emotion of gloating for the other player's misfortunes, rather than to regret. However, several considerations speak against this interpretation. Firstly, those studies were constructed so to elicit direct social comparisons between individuals by either manipulating participants' specific information or by having individuals playing on same trials. In the present study, the effect of possible social comparisons on the reported results was minimized. In fact, participants played on different trials and, particularly in study 1, the OP trials occurred immediately after the IP ones (direct social comparison) statistically only in 1 out of 32 trials. Additionally, outcomes producing the feelings of regret and relief were counterbalanced, thus further reducing the effect of gloating also when OP trials directly followed IP ones. Moreover, evidence that our results are not spoilt by the effects of gloating is represented by a lack of activation of the ventral striatum in OP task, which Takahashi   et al.   indicate as its neural signature. Nonetheless, we do not reject the idea of possible different emotions, than regret, ultimately arising from the individual's awareness of someone else's regret. Still, our data clearly show that, in given contextual frames, e.g. when direct social comparison is minimized, and when individuals are aware of the process that leads to regret in others, observers neurally respond as they were directly involved in that situation. This neural process allows one to cognitively and emotionally reproduce the feeling experienced by a third person, thus leading to its automatic understanding. 

A critical factor in the level of an individual's   shared   experience is her/his empathic aptitude. In this study, the behavioral results obtained on the BEES showed higher scores for females than males, particularly in study 2, suggesting that higher emphatic aptitude is associated with enhanced activation observed for females in vmPFC (see also  ) and, only in study 2, in anterior insula (see   and  ,  ). Enhanced vmPFC activation for females during OP condition suggests that the engagement of the “resonant” mechanism in the regret network is particularly strong in emphatic individuals; insular activation, on the other hand, appears to be not related to regret   per se  , rather it can be more generally associated with the processing of emotional empathic responses, as also shown in previous studies  ,  ,  . 

On the whole, our data suggest that the emotional understanding of regret in others is specifically reflected by the activation of a subset of the regions involved in its direct, first-person, experience. Among these regions, vmPFC appears to be at the core of a counterfactual evaluation of the outcomes, updating the emotional valence of the obtained outcome with respect to that unobtained  . This evaluation results in the appropriate behavioral response associated with activity in ACC even when attending another's negative results. The finding of a resonance mapping system for the high-order experience of regret entails an important notion. In real social decisional contexts, one's own decisions and behaviors may be strongly influenced by interactive learning, i.e., learning from what other individuals experience as a result of their choices  . One might then wonder how such learning occurs, i.e. how the negative, regretful, outcomes of other individuals are coded in the decision-maker's brain. Does such a process involve the mere cold encoding of numerical quantities? The results of the present study show that this is not entirely the case. Rather, knowing the regretful outcomes of others' choices do lead to similar counterfactual comparisons and, via the reactivation of the same underlying cerebral regions, to the comprehension of the related emotional reactions, as experienced in a first-person perspective. This resonant emotion may represent a drive for behavioral reorganization even when attended in somebody else's experiences. 


## Materials and Methods 
  
### Study 1 
  
#### Participants 
  
Twenty-four healthy right-handed   monolingual native speakers of Italian (12 females [mean age = 25.75, s.d. = 2.18, range = 23.5–31.8] and 12 males [mean age = 25.34, s.d. = 2.90, range = 22–29.7]) participated in study 1. All participants had normal or corrected-to-normal visual acuity. None reported a history of psychiatric or neurological disorders, or current use of any psychoactive medications. They gave their written informed consent to the experimental procedure, which was approved by the Ethics Committee of San Raffaele Scientific Institute. 


#### Task 
  
The participants performed a classical gambling task  . In every trial, they were required to choose one of two gambles depicted as “wheels of fortune”, in which different probabilities of financial gain or loss are represented by the relative size of colored sectors of a circle. The gambles were then played and the results shown. Participants could thus evaluate not only the financial consequences of their decision, but also the outcome they might have obtained had they selected the alternative gamble. These evaluations gave them a sense of responsibility for their choices and determined a counterfactual reasoning, i.e., the main hallmarks of regret, when decisions produce relatively-negative outcome. 

In the present investigation, there were two basic experimental conditions (see  ). In the “  I play  ” (IP) condition, participants were asked to choose one of two gambles, leading to a financial gain or loss for themselves. The gambles were shown for 5 s, during which they could evaluate them and make a decision. Next, the appearance of an asterisk in the centre of the screen prompted the participants to choose, by pressing one of two buttons on a keyboard with their right index or middle finger. The participants had 2 s to choose the gamble. In case they did not answer within this temporal window, they received an “out of time” message, and a new trial started. Once selected, the chosen gamble was highlighted by a white contour, and 3 s after the appearance of the asterisk the outcome of both gambles was shown for 3 s. In the “  Other plays  ” (OP) condition, the participants were shown the same sequence of events (evaluation, decision and outcome, with the same timings) of the gamble played by an actor in a nearby room. In the OP condition, a small white square was shown along with the asterisk, either on its left or right side. The asterisk position indicated which gamble had just been chosen by the actor, and participants were asked to press the corresponding button. In order to focus their attention on the gamble-results in both IP and OP conditions, and to assess the participants' understanding of the other players' emotional state at outcome evaluation, after outcome presentation the participants had to indicate whether they were satisfied with their own result (IP) or whether the actor was satisfied with her result (OP), by pressing one of two buttons (left: yes, right: no; 3 s). 

As an explicit-baseline, two further conditions were used: in the “  I follow  ” (IF) and “  Other follows  ” (OF) conditions, participants were informed that the computer would randomly choose one of the gambles, for themselves or for the other player, respectively. In these conditions, the decision-period lasted 2 s. Like in the OP condition, the decision made by the computer was signaled by a small white square appearing along with the asterisk, and participants were simply asked to press the corresponding left/right button. These trials still resulted in financial gains or losses for the participants or the actor, yet enabled us to control for the feeling of responsibility for the gamble choice, which is a crucial determinant of the emotion of regret. 

Each trial started with a specific instruction indicating the condition type (1 s), which remained at the bottom of the screen throughout the trial length. All instructions were presented in Italian. 


#### Gambles structure 
  
The participants underwent a total of 256 trials (64 for each experimental condition). The complete list of trials was predetermined and identical for all the participants. In each gamble, the 4 possible outcomes resulted from paired combinations of 200, 50, −50 and −200 (arbitrary units), associated with 8 different levels of probability (30-70, 35-65, 40-60, 45-55, 55-45, 60-40, 65-35, 70-30). Thus, the possible combinations of wins and losses gave four potential levels of regret (−100, −150, −250 and −400) and relief (100, 150, 250 and 400). The possible combinations of payoffs and levels of probability were equally balanced across all experimental conditions. In each trial, payoffs and probabilities were associated so that a) one of the gambles was riskier than the other, and b) the difference between the gambles was minimized with regard to the expected-value (i.e., the sum of the probability of the two possible gamble outcomes, each multiplied by the corresponding outcome value). In order to compare the effects of different experienced   vs  . attended amounts of regret, it was crucial to outbalance the number of events of interest across the different experimental conditions. Therefore, unbeknownst to the participants, the list of stimuli was arranged so that in OP, IF and OF conditions every single trial resulted in a pre-determined pair of outcomes (and thus in a pre-specified amount of either regret or relief in the OP condition). In order to make sure that the number of regret and relief events balanced out in the IP task (where we had no control on the participant's choice), every trial was pre-determined to necessarily result in a variable amount of either regret or relief by means of a feedback-routine. For every task, the obtained “regret” and “relief” trials were then assigned to the different functional runs so to obtain a variable proportion of events of regret and relief. Crucially, to preserve a most realistic probabilistic scenario, in all conditions we ensured that, across trials, the least probable gamble outcomes would occur in a proportion equal or inferior to 50% (OP = 47%; IF and OF = 50%; IP = 42%). In fact, as confirmed by the post-scanning debriefing, all participants were unaware of the experimental control on the probabilistic occurrence of wins and losses. 


#### Instructions and procedure 
  
The participants underwent a training session and were introduced to the same unknown female actor before the beginning of the study. Moreover, they were informed that both their and the actor's performance in IP/IF and OP/OF tasks, respectively, would have resulted in a financial gain or loss with respect to an initial endowment. Importantly, to constrain a competitive attitude towards the actor's performance, participants were explicitly informed that their potential gains/losses were completely independent of those of the other player. Additionally, when introducing the actor to the participants, the actor's personal profile was purposely kept very low. The participants were informed about their cumulative earnings only outside the scanner, after the functional acquisition. 

The study was composed of 8 functional runs. Every run comprised 32 trials (8 for each experimental condition). These were randomly assigned to 8 blocks, each of which contained 4 consecutive trials of the same condition. The order of the functional runs, of the blocks within each run and of the trials within each block were randomized across participants. Null events were also included in every run, to allow estimation of low-level baseline brain activity. In order to desynchronize the timings of event-types with respect to the acquisition of single slices within functional volumes, interstimulus intervals (ISI) between successive trials were presented in different (“jittered”) durations across trials (1350, 1950, and 2550 s, in proportion of 4∶2∶1;  ). 

Visual stimuli were viewed via a back-projection screen located in front of the scanner and a mirror placed on the head-coil. The software Presentation 11.0 (Neurobehavioral systems, Albany, CA,   http://www.neurobs.com  ) was used both for stimulus presentation and participants' answers recording. 

After the scanning, participants were asked to report their personal impressions about the task. Then, they completed an Italian version   of the Balanced Emotional Empathy Scale (BEES;  ), a 30-item questionnaire on emphatic abilities designed to measure individual tendency to empathize with others' emotional experiences (i.e., emotional empathy). 



### Study 2: Differences with respect to study 1 
  
#### Participants 
  
Twenty-four healthy right-handed   monolingual native speakers of Italian (12 females [mean age = 20.28, s.d. = 1.16, range = 19–23] and 12 males [mean age = 22.86, s.d. = 3.26, range = 19–30]) participated in study 2. 


#### Task 
  
Three main differences distinguished study 2 from study 1 with regard to the task. Firstly, the emotional component of post-outcome judgment was replaced by a “cold” appraisal of the obtained outcome. Namely, instead of providing a satisfaction-judgment, the participants were required to indicate whether the gamble outcome was a win or a loss. Second, in study 2 participants' response was required in all four conditions (IP, OP, IF, OF) and only on 10% of the trials. Finally, the length of the evaluation phase (gambles presentation) was identical in all four conditions (4.5 s). 


#### Gambles structure 
  
Different from study 1, in each gamble the 4 possible outcomes resulted from paired combinations of 200, 50, −50 and −200 (arbitrary units), associated with only 3 different levels of probability (25-75, 50-50, 75-25). However, the possible combinations of wins and losses still gave four potential levels of regret (−100, −150, −250 and −400) and relief (100, 150, 250 and 400). 


#### Instructions and procedure 
  
All participants underwent a training session, and were introduced to an unknown actor. In study 2, half of them (50% females and 50% males) were presented to a female actor and the other half to a male actor. 


#### fMRI data acquisition and statistical analysis 
  
Anatomical T1-weighted and functional T2*-weighted MR images were acquired with a 3 Tesla Philips Achieva scanner (Philips Medical Systems, Best, NL), using an 8-channels Sense head coil (sense reduction factor = 2). Functional images were acquired using a T2*-weighted gradient-echo, echo-planar (EPI) pulse sequence (38 interleaved coronal slices covering the whole brain, TR = 2200 ms, TE = 30 ms, flip-angle = 85 degrees, FOV = 240 mm×240 mm, inter-slice gap = 0.5 mm, slice thickness = 4 mm, in-plane resolution 2.5 mm×2.5 mm). Each scanning sequence comprised 215 sequential volumes. Immediately after the functional scanning a high-resolution T1-weighted anatomical scan (150 slices, TR = 600 ms, TE = 20 ms, slice thickness = 1 mm, in-plane resolution 1 mm×1 mm) was acquired for each participants. 

Image pre-processing and statistical analysis were performed using SPM5 (Wellcome Department of Cognitive Neurology,   http://www.fil.ion.ucl.ac.uk/spm  ), implemented in Matlab v7.4 (Mathworks, Inc., Sherborn, MA)  . The first 5 volumes of each participant were discarded to allow for T1 equilibration effects. All volumes were then spatially realigned   to the first volume of the first session to correct for between-scan motion and unwarped  , and a mean-image from the realigned volumes was created. This image was spatially normalized to the Montreal Neurological Institute 305 (MNI305) brain template using a 12-parameter affine normalization and 16 nonlinear iterations with 7×9×7 basis functions  . The derived spatial transformations were then applied to the realigned-and-unwarped T2*-weighted volumes, that were resampled in 2×2×2-mm voxels after normalization. All functional volumes were then spatially smoothed with an 8-mm full-width half-maximum (FWHM) isotropic Gaussian kernel to compensate for residual between-subject variability after spatial normalization, and globally scaled to 100. The resulting time series across each voxel were then high-pass filtered to 1/128 Hz, and serial autocorrelations were modeled as an Auto-Regressive AR(1) process. 

Statistical maps were generated using a random-effect model, implemented in a 2-levels procedure  . 

At the first level, two sets of analyses were performed. Firstly, outcome trials were partitioned according to the 4 conditions (IP, IF, OP, OF) which were separately modeled as mini-epoch lasting 3 s. For each of the 4 conditions, one additional regressor modeled a linear parametric modulation of the outcome-related activity by the degree of objective amount of   regret/relief   (computed as the difference between the actual and unobtained outcomes). In line with Coricelli   et al.  's   procedure , in a second analysis we modeled a linear parametric modulation by the degree of   satisfaction/disappointment  , i.e., the amount of discrepancy between the obtained and unobtained outcomes in the   chosen   gamble only. All the within-trials events other than the outcomes, as well as those trials in which a wrong response or no response was given, were modeled in a single regressor of no interest. Regressors modeling events were convolved with a canonical Haemodynamic Response Function (HRF), and parameter estimates for all regressors were obtained at each voxel by maximum-likelihood estimation. Contrasts of parameter estimates were then calculated to produce “contrast images” for each contrast of interest (“IP   minus   IF” and “OP   minus   OF” for both regret- and disappointment-related parametric regressors). 

At the second (group) level, these two types of contrast-image were used to perform separate parametric (i.e., dependent on the degree of either regret or disappointment) analyses. Furthermore, since we aimed at investigating also potential gender effects on “mirror-like” cerebral activity, the 1 -level contrast images for “IP   minus   IF” and “OP   minus   OF” for male and female participants were entered into a 2×2 [perspective (“IP   vs  . OP”) by gender (female   vs  . male)] factorial design with sphericity-correction for repeated measures  . Based on a-priori hypotheses from a previous study  , the resulting statistical maps were thresholded at p<0.001 uncorrected for multiple comparisons, and only clusters larger than 5 voxels were reported. 

In order to assess common effects across IP and OP tasks, we carried out a conjunction analysis on the IP (  minus   IF) and OP (  minus   OF) statistical maps for both the disappointment- and the regret-related parametric effects. This analysis was done using an inclusive masking procedure, in which the statistical maps for OP conditions were inclusively masked by those for the IP condition. Finally, direct comparisons were performed to assess perspective- and gender-effects on condition-related cerebral activity in both analyses. The resulting statistical maps were thresholded at p<0.001 uncorrected for multiple comparisons and, in order to ensure that the observed activations did not result from relative deactivations, they were inclusively masked at p<0.05 uncorrected by those associated with the conditions of interest   minus   the baseline task. 

The location of the activation foci in terms of Brodmann Areas (BAs) was determined in the stereotaxic space of Talairach and Tournoux   after correcting for differences between the latter and the MNI coordinate systems by means of a nonlinear transformation (see   http://www.mrc-cbu.cam.ac.uk/Imaging/Common/mnispace.shtml  ). Those cerebral regions for which maps are provided were also localized with reference to cytoarchitectonical probabilistic maps of the human brain, using the SPM-Anatomy toolbox  . 




## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-59'>
<h2>59. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/27579051/' target='_blank'>27579051</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Neural Modulation in Aversive Emotion Processing: An Independent Component Analysis Study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Comput Math Methods Med</p>
<p><strong>Publication Year:</strong> 2016</p>
<p><strong>DOI:</strong> 10.1155/2016/2816567</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4992784/' target='_blank'>4992784</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> fMRI study using a social-related task (Face Matching Task assessing perception of others’ emotional faces, fear vs neutral). Participants: a healthy adult sample (N=10; mean age 25, within 17–65). Whole-brain analyses reported: second-level whole-brain GLM (one-sample t-tests) and ICA-derived spatial maps tested across the brain (FDR-corrected), not limited to ROI analyses. Results for healthy participants are reported separately (only healthy group). Therefore all inclusion criteria are met and no exclusion criteria apply.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Emotional processing has an important role in social interaction. We report the findings about the Independent Component Analysis carried out on a fMRI set obtained with a paradigm of face emotional processing. The results showed that an independent component, mainly cerebellar-medial-frontal, had a positive modulation associated with fear processing. Also, another independent component, mainly parahippocampal-prefrontal, showed a negative modulation that could be associated with implicit reappraisal of emotional stimuli. Independent Component Analysis could serve as a method to understand complex cognitive processes and their underlying neural dynamics. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (32521 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## 1. Introduction 
  
Emotion processing is crucial for social interaction. It has been suggested that both neuronal and behavioral responses are facilitated, whenever emotional faces with negative valence, such as fear or anger, are observed. It has been reported that the perception of affective scary faces indicates the presence of indirect stimuli that could potentially threaten individual integrity [ ]. 

The processing of affective faces of fear has an important social role, because it triggers emotional information capable of provoking a visceral response and thus enabling the necessary actions to preserve physical integrity [ ]. It also allows the detection of other persons' emotional state to modulate our responses during social interaction, by controlling or attenuating conduct; this is due to the human ability to consciously assess emotional stimuli through continuous reasoning and experience labeling [ – ]. 

A brain circuit implicated in emotions' processing has been described; it is composed mainly of the amygdala, anterior cingulate, insula, prefrontal cortex (mainly ventromedial and lateral orbitofrontal portions), and anterior portions of the temporal lobe [ – ]. 

Several paradigms have been used in fMRI studies to assess affective faces processing. Experiments have been reported, going from passive perception of emotional faces to those including conditions where the subject must produce a behavioral response involving decision making; in this case, responses can be either implicit, that is, the selection or judgment about the identity or gender of stimuli, or explicit, where emotions are assessed directly. Consistent findings have been reported in healthy and clinical populations, describing the increase in the BOLD response when aversive affective faces are compared to neutral faces, mainly in the amygdala; frontal regions such as the superior frontal gyrus, medial frontal gyrus, orbitofrontal cortex, and ventromedial cortex; temporal regions including the superior and medial temporal gyrus; other regions such as the fusiform gyrus, insula, anterior cingulate, among other structures [ – ]. 

Processing of aversive faces is also considered a biomarker of negative affectivity, which has been associated with neuropsychiatric pathologies and maladaptive personality traits. In a recent study, it is reported that an affective-cognitive bias (or the tendency to respond faster to a stimulus) facilitated the recognition of fear faces and led to shorter reaction times (compared to neutral faces), which correlated positively with a bilateral increment of ventromedial cortex, left subgenual cortex, and right caudate nucleus activities. This bias was also associated with personality traits such as harm avoidance [ ]. In another study, carried out in a population of heroin-dependent subjects, an increase in the left amygdala activity was observed, when heroin was administered to participants during the fearful face condition; this increase was positively correlated with other measures related to stress [ ]. 

Face Matching Task (FMT) [ ,  ] is one of the most commonly used paradigms to study affective processing; different versions have been adapted, which consider several conditions, but all of them allow the implicit and explicit assessment of affective processing, including aversive emotions, such as fear or anger (see Materials and Methods for the task description). In several studies, mainly based on region of interest (ROI) analysis and small volume correction analysis (SVC), the amygdala has been associated with FMT resolution, especially in aversive conditions [ ,  ]; furthermore, other hyperactive regions besides the amygdala have been observed, such as ventromedial cortex, orbitofrontal cortex, insula, and anterior cingulate in diverse populations of patients with affective disorders, for instance, acute stress [ ], depressive episodes [ – ], and first psychotic episode [ ]. These findings suggest that the performance during FMT can be considered a biological marker of emotional reactivity to aversive stimuli, besides being a consistent endophenotype of genetic susceptibility to the development of affective disorders characterized by emotional hypersensibility [ – ] and of traits such as impulsivity, aggression, and violence [ ]. 

The BOLD signal obtained by fMRI is based on the general linear model (GLM); its traditional analysis presents some limitations: on the one hand, it assumes voxels' independency, which limits the BOLD signal study to massive univariate analysis, which in most cases cannot capture the principle of biological plausibility, namely, the biological mechanism that underlies a process, such as cognitive functioning; on the other hand, it needs a reference model based on the hemodynamic response, which makes the analysis based on GLM less flexible than other approaches [ ]. 

An alternative to study and to characterize the neural networks associated with cognitive processing is functional connectivity; for its study several techniques, generally expressing the statistical dependency on observed data, have been proposed. Among them, Independent Component Analysis (ICA) is a multivariate technique that allows the observed BOLD signals' decomposition into neural networks or independent components (ICs). ICs refer to functionally independent neural networks that are simultaneously activated [ ]. After elimination of noise-related signals and the proper selection, these ICs represent the activity modulation of a set of brain structures that, in the case of fMRI, are time-related either to stimulus presentation or to a given condition. This technique does not depend on a reference model and as a final result allows the analysis of components, instead of voxels; that is, the brain regions represented by each component have a similar response associated with the cognitive process of interest and show temporarily coherent fluctuations [ ]. 

There are only a few studies, where ICA has been applied to observe the neural networks modulation during emotion processing. Escartí et al. [ ] used an auditory paradigm, where they manipulated the words' emotional tone; for a control group they reported four ICs temporally correlated with emotional stimuli, located at temporal, frontoparietotemporal, limbic-subcortical, and occipitocerebelar regions. The limbic-subcortical IC was then compared between schizophrenic subjects with and without auditory hallucinations, and they found a similar behavior between control and nonhallucinating subjects, while schizophrenic patients with hallucinations presented a hyperactivation of this component. 

In another ICA-based study a group of women with borderline personality was compared to a control group. A paradigm including neutral, masked fear and explicit fearful faces was used; the responses' analysis yielded a bilateral component that included the amygdala as a “seed” coactivated with the rostral portion of the anterior cingulate in the explicit fear condition; this functional connectivity was increased for the borderline personality group [ ]. 

Broicher et al. [ ] reported an amygdala IC, which showed coactivations with temporal, frontal, anterior cingulate, and hippocampal and cerebellar regions, under the passive view of intense fear faces videos; the functional connectivity of the amygdala with the aforementioned regions was reduced in a group of temporal lobe epilepsy patients. 

ICA has also helped to describe active networks in basal or resting state conditions; it has been suggested that those networks have a strong contribution for the development of some pathologies. In a study carried out in raped female teenagers, compared to a control group, fearful faces stimuli were used to observe the activity modulation of three networks associated with resting state: frontal-parietal, frontal-cingulate, and default mode network (DMN). The authors reported that the frontal-cingulate network, composed mainly of the anterior insula and anterior cingulate, showed an increased activity in the fear condition, more so in women having suffered a rape event [ ]. Another study in the same direction reported that the structures overlapping DMN (prefrontal medial cortex, ventral anterior cingulate, and precuneus) showed a negative modulation or deactivation to emotional stimuli, which suggests that DMN participates in the monitoring of internal emotional processing [ ]. 

To our knowledge, only one study of functional connectivity using the FMT has been reported. In that work, the time courses corresponding to the amygdala were extracted and correlation maps were computed between these time courses and those corresponding to all the other voxels, with the purpose of describing how the amygdala's activity modulates the rest of the regions when processing aversive emotions. It was reported that the right amygdala activation had a negative modulation on medial and superior frontal regions, anterior cingulate, inferior parietal, precuneus, and cuneus. On the other hand, the right amygdala activity modulated positively the activities of inferior frontal gyrus, insula, and superior temporal and subcortical regions [ ]. 

In summary, the findings about the brain regions implicated in emotional processing have been consistent in the literature. However, few studies have been reported using an approximation of functional connectivity, such as ICA, that captures the principles of biological plausibility, fundamental to understand cognitive processing; that is, it assesses the positive and negative modulations of temporally coherent neural networks. Furthermore, ICA have not been used to analyze responses to the widely used FMT paradigm, which has been suggested as a good biological marker of emotional reactivity and as a reliable endophenotype of genetic susceptibility to the development of affective disorders and maladaptive behaviors. Therefore, the purpose of the present study was to characterize the neural networks implicated in aversive emotional processing measured by FMT, using Independent Component Analysis. We hypothesized that ICs temporally associated with fearful stimuli processing will correspond to brain regions implicated in perception and regulation of aversive emotion stimuli, as well as negative affectivity, such as prefrontal, ventromedial, orbitofrontal, and anterior temporal areas. 


## 2. Materials and Methods 
  
### 2.1. Participants 
  
The sample was composed of ten healthy adults (5 males, 5 females) with a mean age of 25 ± 5.29 years and a mean of 15.5 ± 2.32 years of education (see Table S1 of the Supplementary Material for more details about sample selection available online at   http://dx.doi.org/10.1155/2016/2816567  ). All subjects signed an informed consent; they did not receive economical compensation for their participation; the project was approved by the ethics committee of the Centro Nacional de Investigación en Imagenología e Instrumentación Médica of the Universidad Autónoma Metropolitana. 


### 2.2. fMRI Paradigm 
  
An adaptation of Face Matching Task (FMT) [ ,  ] was developed; in this perceptual task subjects saw a trio of faces and they have to select one of the two faces (top) that was identical to the face in the bottom of the screen, so it was an implicit emotional task in which the subject made a judgment about the identity of the stimulus. Trials were presented in an event-related design. A total of 48 emotional faces (24 neutral, 24 fear) derived from a set of affective emotional faces were presented [ ]. In addition, 24 sensory-motor control stimuli, in which the emotional faces were replaced by scenes of interiors of houses, were presented in an interleaved manner with emotional faces. Each trial was presented sequentially in a pseudorandom order during 2000 ms with an interstimulus interval of 2100 ms. In summary, the fMRI paradigm consisted of three conditions: aversive affect processing (fear), neutral affective processing (neutral), and sensory-motor control (control) ( ). The experimental paradigm was presented by E-Prime 2.0 software (Psychology Software Tools, Pittsburg, PA, USA); stimuli were projected in a BOLD-screen (Cambridge Research Systems); reaction times (RT) were recorded using a two-button response pad (Current Designs). 


### 2.3. Image Acquisition 
  
Structural and functional magnetic resonance images were acquired in a Philips 3T Achieva scanner (Philips Medical Systems) using an 8-channel SENSE Head coil. Functional images were acquired using a Gradient-Echo Planar Imaging (EPI) sequence with the following parameters: TR = 2000 ms; TE = 28 ms; acquisition matrix = 80 × 80; voxel size = 1.87 mm × 1.87 mm × 5 mm; slice thickness = 4 mm; gap = 1 mm; flip angle = 90°; FOV = 128 × 128 mm; 24 axial slices, order of acquisition = interleaved. A 3D T1-weighted structural image was acquired for coregistration with the following parameters: TR = 7.5 ms; TE = 3.7 ms; acquisition matrix = 240 × 240; voxel size = 1 mm × 1 mm × 1 mm; slice thickness = 2 mm; no gap; flip angle = 8°; FOV = 256 × 256 mm. 


### 2.4. Image Preprocessing 
  
Images were preprocessed using Statistical Parametric Mapping software (SPM12,   http://www.fil.ion.ucl.ac.uk/spm/  ) implemented in Matlab 2014b (Math Works, Natick, MA, USA). Functional images were realigned to first volume, slice-timing-corrected, coregistered to structural image, normalized to MNI space with a voxel size of 2 × 2 × 2 mm , and then smoothed with a Gaussian FWHM kernel of 8 mm. 


### 2.5. GLM Analysis 
  
First level analysis for each subject was carried out using SPM12; the three experimental conditions were included as regressors, applying the canonic hemodynamic response function without derivatives. The six motion-correction parameters of each subject were also included in the model. A high-pass filter with a cutoff point of 128 seconds was applied to time series. Statistical images of the following contrasts were obtained with   P   < 0.005 (uncorrected),   k   = 10: face processing activation (neutral + fear > control); fear activation (fear > neutral); fear activation controlled by sensory-motor activity (fear > neutral + control). 

The second level whole-brain analysis was carried out through a one-sample   t  -test using the contrast images obtained in first level analysis, with   P   < 0.005 (uncorrected),   k   = 10. The labeling of coordinates was done according to the stereotactic atlas of Talairach and Tournoux [ ], as implemented in Talairach Client tool [ ,  ]. These results are presented in Table S2 and Figures S1, S2, and S3 of the Supplementary Material. 


### 2.6. Independent Component Analysis (ICA) 
  
ICA was carried out using the GIFT software (  http://icatb.sourceforge.net/  ). The procedure to estimate independent components (ICs) consists of several steps: first, the optimal number of ICs is estimated following the minimum description length criteria (MDL) [ ]. Then a two-step data reduction through principal component analysis is made [ ]. ICs are then decomposed to obtain the final number of components previously estimated through MDL; in the present study this step was carried out using the Infomax algorithm [ ]. An optional step is to test the stability of the estimated ICs via ICASSO [ ]. Then spatial maps of ICs and the associated time courses are calculated using a back-reconstruction approach, considering the results from ICA and data reduction steps [ ]. ICs are normalized to   z  -scores. 

GIFT determines the brain structures associated with each time course using a random factor analysis (one-sample   t  -test) as implemented in SPM8 with a threshold of   P   < 1 × 10  FDR-corrected;   k   = 30. This procedure allows obtaining spatial maps of the functionally connected brain structures in each IC. 

In the present study 29 ICs were estimated via MDL; the Infomax algorithm was used and 20 iterations were carried out using ICASSO method. The number associated with each IC (IC1, IC2,…, IC29) is arbitrary and corresponds to the output of the GIFT platform. 

The ICs of interest are usually selected as follows [ – ]:   
ICs with a stability index <0.9 in ICASSO must be removed; in the present study none of the estimated ICs were eliminated using this criterion. 
  
ICs are spatially sorted according to the templates of gray matter (GM), white matter (WM), and cerebrospinal fluid (CSF) included in SPM8; those ICs whose values of   R   > 0.02 for WM,   R   > 0.05 for CSF, and those whose value of   R   for GM is lesser than that obtained for WM and/or CSF are also discarded. In this study, after performing this step 6 ICs with values of   R   > 0.02 for WM were discarded; no ICs with   R   > 0.05 for CSF were found; and 8 ICs with   R   value for GM less than that obtained for the other tissues were discarded. 
  
The remaining 15 ICs were temporally sorted (multiple regression method) using the model estimation of the first level analysis, to obtain the beta values associated with the experimental conditions (control, neutral, and fear). The beta values represent the modulation of activity of the ICs temporally associated with the onset of the event convolved with the hemodynamic response. The modulation could be positive or negative, which corresponds, respectively, to activation or deactivation patterns during the stimulus processing. 
  


### 2.7. Statistical Analysis 
  
Reaction times and number of correct responses were analyzed using SPSS 20 software (SPSS, Chicago, IL). The number of correct responses was not normally distributed (  P  s < 0.05, Shapiro-Wilk) and therefore it was analyzed using a Friedman test for related samples. The pairwise comparisons were analyzed using the Wilcoxon signed-rank test for related samples, and a level of   P   < 0.05 was adopted. Reaction times were normally distributed (  P  s > 0.05, Shapiro-Wilk) and were analyzed using a repeated measures ANOVA; “condition” was included as within-subjects factor with three levels (control, neutral, and fear); a level of   P   < 0.05 was adopted. 

The statistical analysis of ICs was carried out as follows: because the remaining 15 ICs were normally distributed (  P  s > 0.05, Shapiro-Wilk), a repeated-measures ANOVA for each IC was carried out, to detect those ICs that were differentially implicated in each condition, as within-subject factor “condition” was included with three levels (control, neutral, and fear). Afterwards another repeated-measures ANOVA for each IC was carried out, to detect the differences in the modulation between neutral and fear faces, as within-subjects factor “condition” was included with two levels. These analyses were carried out using SPSS 20; a level of significance of   P   ≤ 0.05 was adopted. 



## 3. Results and Discussion 
  
### 3.1. Behavioral Performance 
  
The number of correct responses (CR) between conditions was statistically different (  P   = 0.001, Friedman) in all cases. In the control condition, subjects were more accurate (CR = 23.8 ± 0.42), followed by the fear condition (CR = 22.8 ± 0.63) and finally the neutral condition (CR = 21.5 ± 1.17). Pairwise comparisons indicated that all conditions were different (control versus neutral   P   = 0.005; control versus fear   P   = 0.020; neutral versus fear   P   = 0.023, all Wilcoxon). 

A principal effect of “condition” on reaction time was found (  F   = 20,399,   P   < 0.000). The subjects responded faster in the control condition (reaction time = 967.4 ± 201.35 ms), followed by the fear condition (reaction time = 1057.2 ± 215.25 ms) and finally the neutral condition (reaction time = 1207.69 ± 297.92 ms). According to the results of pairwise comparisons, all conditions were different from each other. 

Increases in accuracy and decreases in reaction times associated with fearful faces processing concur with previous reports indicating that the shift of attentional focus is manipulated during emotional processing in tasks similar to FMT [ ]. The speed to process aversive emotional stimuli (fear) has been interpreted as a cognitive-affective bias to categorize fearful stimuli, even in healthy populations. It has been suggested that this bias is related to personality traits such as harming avoidance, which has been associated with no clinical traits of anxiety [ ]. In the present study one of the inclusion criteria was to have normal levels of anxiety according to the Beck Anxiety Inventory; therefore, this speed in the categorization of fearful stimuli may be associated with a more cautious personality of our subjects, which does not imply a risk factor for the development of mood disorders [ ]. 


### 3.2. ICA Results 
  
The comparison of the ICs in the 3 conditions (control, neutral, and fear) allowed detecting that modulation of IC2 was different between conditions (main effect of condition:   F   = 4.5,   P   = 0.025). Pairwise comparisons indicated that the difference was between control and fear conditions (  P   = 0.003); this component showed a negative modulation during the fear condition. The “Write Talairach Table” function implemented in GIFT with the default options was used to detect regions with a strong negative modulation within IC2. Due to the functionally connected brain regions, the IC2 was named as “parahippocampal-prefrontal” ( , Figures   and  ). 

This analysis, in which the sensory-motor control condition was included, allowed observing that the negative modulation of IC2 “parahippocampal-prefrontal” included structures involved in emotional face processing. It should be noted that in pairwise comparisons the fear condition was different from the control condition; however, the neutral condition also had a negative modulation, without being different from the other two conditions, suggesting that this negative modulation could be associated with the processing of emotional facial stimuli. It is worth noting that it has been reported that neutral faces processing shares the neural substrate of nonneutral emotional conditions, with the only difference that what defines the neuronal differential response in these brain structures is the sensitivity, depending on the emotional conditions [ ,  ,  ]. It has also been reported by whole-brain analysis that neutral conditions are not different from those of fear [ ], suggesting that neutral faces processing involves some emotional contribution. 

Since our aim was to characterize functionally connected brain networks during aversive processing and given that the only difference between the neutral and fear condition was the expressed emotion, the neutral condition represents a more subtle control condition for fear processing; therefore beta values were obtained by multiple regression of both conditions. The repeated-measures ANOVA showed a significant component related to the aversive emotional processing (IC4) (main effect of condition:   F   = 5.99,   P   = 0.037). This component presented a pattern of positive modulation during aversive emotional processing; the corresponding network included frontal, limbic, occipital, temporal, and cerebellar regions, so it was named “cerebellar-medial-frontal” ( , Figures   and  ). 

Results obtained from comparing neutral and fear conditions showed a positive modulation in a network predominantly cerebellar-medial-frontal, which also included activations in temporal regions. Activations in regions such as parahippocampal, frontal, and fusiform gyrus are according to the findings reported in paradigms of face emotional processing and recognition in passive view [ ], shifting of the attentional focus [ ], and implicit emotional tasks [ ]. Specifically, our results are consistent with those reported using FMT in aversive emotional conditions (faces of fear and anger) against a motor control task (geometrical shapes) [ ,  ]. 

It is noteworthy that studies which have used the FMT have methodological differences in the contrasts between conditions. Traditionally, reported results are based on activations to aversive emotions (fear + anger) compared with control tasks that involve the pairing of geometric shapes. One of the advantages of using the FMT is its potential value as a biomarker of disorders and behavioral traits associated with negative affectivity [ ,  ,  ,  – ]. It has been suggested that the processing of faces of fear plays an important role in social interaction, as it allows modulating the behavioral response by observing the emotional state of the other [ ]. In this sense the negative affect is more related to fear: fear stimuli cause states of distress and this is perceived by the observer, facilitating socioemotional adaptive responses [ ]. Therefore, we believe that adapting the FMT to a condition of fear and making a direct comparison with the neutral condition allowed us to detect the neural network that may be more associated with negative affectivity. 

On the other hand, previous studies of FMT have focused on the amygdala activation, using ROIs and SVC analysis, reaching very consistent results regarding the role of the amygdala in the aversive emotional processing [ ,  – ]. In this sense, our results were not according to the differential activation of the amygdala between neutral and fear conditions; this may be due to differences in the analysis used in previous studies and the present study. 

Seed studies based on ICA and FMT have yielded interesting results. Seed analysis is based on the extraction of the time course of a ROI, which is associated with the presentation of a stimulus; correlation maps are then obtained between the time courses of the remaining voxels and the time course of the ROI [ ]. By using seed analysis amygdala activation in aversive emotion conditions has been reported; this activation modulated the functional connectivity in brain structures, included in the medial-frontal-occipital IC4 reported in this study [ ,  ]. Therefore it is probable that the analysis used in the present study is sensitive enough to detect the modulation of other regions outside the amygdala that are involved in the aversive emotional processing. Other studies of ICA and FMT have focused on the modulation of resting state such as the DMN and frontocingulate network, concluding that the modulation reported in these networks can be a good indicator of emotional reactivity and internal emotional monitoring [ ,  ]. It is interesting that the stimuli used by Cisler et al. [ ] are fearful faces and that the activity of frontocingulate network has been associated with the interoceptive sensory integration, suggesting that the increase in activity in conditions of fear is associated with the development of adaptive responses. 

One of the structures that showed a temporally coherent modulation during the fear condition within the IC4 was the superior temporal gyrus. This region in its anterior portions is anatomically connected with the orbitofrontal cortex and the amygdala [ ,  ], and it has been reported that alterations in structural connectivity between these regions may predispose to behaviors related to alterations in emotional processing, such as violence [ ]. The superior temporal gyrus, in animal and human models, has been implicated in socioemotional processing [ ,  ] indicating that the anatomical and functional integrity of this structure is essential for social interaction, since it allows modulating acceptable social responses. 

In fMRI studies about the processing of abstract concepts that define social behaviors, activations have been reported in anterior regions of the right superior temporal gyrus in healthy subjects [ ]; this is relevant as it has been proposed that the knowledge of these social actions, together with the emotional recognition and expression, is critical to establishing and maintaining relationships [ ,  ]. 

Other structures within the IC4, whose modulation in the fear condition was of interest, were those belonging to the cerebellum. Through ICA it was possible to detect that these regions are functionally connected with other corticosubcortical regions involved in emotional processing. The regulatory role of the cerebellum in the higher functions such as emotional processing has been previously described; in fact it has been described that cerebellar lesions produce significant clinical alterations in emotional processing and social skills [ – ]. In a recent study of functional connectivity in resting state, it was suggested that violent behavior, characterized by abnormalities in emotional processing, is related to dysfunction in a cerebellum-prefrontal cortex neural network, which was differentially connected between control and violent groups [ ]. This evidence in resting state, together with the results of positive modulation and cerebellar functional connectivity within IC4 of the present study, suggests that the cerebellum is involved in emotional processing. 

Another interesting finding was the negative modulation of IC2 which, as mentioned previously, includes regions involved in emotional processing. 

ICA allows decomposing the observed BOLD signal into independent components; however, a limitation of this technique is the accuracy to detect which state of the cognitive process or which feature of the stimulus is associated with each time course [ ]. In order to understand the type of modulation of the ICs of interest (i.e., IC4 had a positive modulation in the fear condition while IC2 presented a negative modulation to facial stimuli), the coefficients of temporal correlation between the onsets of fear and the time courses of these two components were reviewed. We observed that the correlation of the positively modulated IC4 was higher than the correlation of the negatively modulated IC2 (  r   = 0.1;   r   = 0.07), which may indicate that the activity observed in these components may be associated with different aspects of the emotional processing. That is, positively modulated IC4 could be associated with the perception and integration of emotional stimulus, while negatively modulated IC2, that was less temporally correlated with the onset of fear stimulus and included structures associated with emotional processing, may be associated with regulatory processes of emotion. In this sense it has been reported that the training of reappraisal skills decreases the response to stimuli that provoke emotional reactivity in brain regions involved in facial emotional processing [ ]. In behavioral studies it has been suggested that reappraisal of emotional stimuli is present even in an implicit way; that is, a high level of emotional awareness is not necessary to reduce emotional reactivity [ ]. It is likely that the sample of the present study, that was composed of healthy subjects, has an implicit mechanism of reappraisal of emotional stimuli that could be expressed as a negative modulation in active regions during processing of emotional stimuli. 

As a limitation of the present study we refer to the phenomenon of reappraisal of emotional stimuli as a possible mechanism that may be related to the negative modulation of IC2. In future studies it would be interesting to make an experimental design to evaluate this phenomenon directly. One of the strengths was the modification of FMT including fearful stimuli, which are more directly associated with negative affectivity. As previously mentioned, the FMT has been considered a good biological marker of this personality trait. 



## 4. Conclusions 
  
In summary, the results of the present study allowed us to observe that there are temporally coherent neural networks whose modulation, positive or negative, contributes to a complex phenomenon such as emotional processing. Through different statistical strategies we were able to disentangle some aspects of the emotional processing and also to detect differential modulation within brain structures implicated in both facial and emotional processing. 

ICA has advantages in the decomposition of the observed BOLD signal and has an important clinical value to detect functionally connected neural networks during cognitive processing. We believe that, from the perspective of brain function, ICA captures many of the theoretical principles about biological plausibility, resulting in more efficient modeling of the neural dynamics. 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-60'>
<h2>60. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/23324559/' target='_blank'>23324559</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Direct Gaze Elicits Atypical Activation of the Theory-of-Mind Network in Autism Spectrum Conditions</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Cereb Cortex</p>
<p><strong>Publication Year:</strong> 2013</p>
<p><strong>DOI:</strong> 10.1093/cercor/bht003</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4014180/' target='_blank'>4014180</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of social processing (direct vs. averted gaze; theory-of-mind network) in adults that includes a healthy control group with results reported separately. The task involves social perception/understanding of others (gaze as ostensive/communicative cue). Although a priori ROIs and small-volume corrections were used for key contrasts, the paper also reports whole-brain analyses (e.g., faces vs. null contrast with FWE correction used to define visual/motor networks), so whole-brain results are present in addition to ROI analyses. Participants are adult healthy controls (male, high-functioning) alongside an ASC group, and behavioral/eye-tracking/fMRI results for controls are reported separately. Thus the study meets all inclusion criteria and does not meet exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Eye contact plays a key role in social interaction and is frequently reported to be atypical in individuals with autism spectrum conditions (ASCs). Despite the importance of direct gaze, previous functional magnetic resonance imaging in ASC has generally focused on paradigms using averted gaze. The current study sought to determine the neural processing of faces displaying direct and averted gaze in 18 males with ASC and 23 matched controls. Controls showed an increased response to direct gaze in brain areas implicated in theory-of-mind and gaze perception, including medial prefrontal cortex, temporoparietal junction, posterior superior temporal sulcus region, and amygdala. In contrast, the same regions showed an increased response to averted gaze in individuals with an ASC. This difference was confirmed by a significant gaze direction × group interaction. Relative to controls, participants with ASC also showed reduced functional connectivity between these regions. We suggest that, in the typical brain, perceiving another person gazing directly at you triggers spontaneous attributions of mental states (e.g. he is “interested” in me), and that such mental state attributions to direct gaze may be reduced or absent in the autistic brain. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (34121 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Eye gaze is a salient social cue that plays an important role in social interaction and communication. Gaze perception activates a network of brain regions, including both the posterior superior temporal sulcus (pSTS) and amygdala, which are central to the perception of biological motion and social cognition ( ,  ;  ). In keeping with the idea that the eyes provide a “window on the mind,” gaze perception also activates regions implicated in inferring the mental states of others (or “theory-of-mind”, ToM), including the medial prefrontal cortex and temporoparietal junction (TPJ;  ;  ;  ;  ). 

The direction of gaze is particularly relevant in social interactions, with mutual or direct gaze forming a key component, signaling interest in the recipient, the intent to communicate, and potential approach, whereas averted gaze generally signals a lack of interest and avoidance. The relative importance of direct over averted gaze is apparent from a very early age with newborns spending longer looking at a face with direct gaze than one with averted gaze ( ). By 6 months, infants only follow an adult's gaze toward an object when it is preceded either by direct gaze or by infant directed speech. Direct gaze also captures and holds attention more readily than averted gaze ( ;  ;  ), and facilitates recognition memory for faces, and categorization of facial gender and selected facial expressions ( ;  ,  ;  ). Toddlers also use gaze direction in language learning ( ). 

In autism spectrum conditions (ASCs), a group of neurodevelopmental conditions characterized by difficulties in social interactions and communication alongside unusually narrow interests and resistance to change, direct gaze does not confer these same perceptual benefits. For example, individuals with an ASC do not show faster detection of direct relative to averted gaze ( ,  ), and their categorization of faces' sex and emotional expression are not modulated by gaze direction ( ;  ). Atypical processing of direct gaze in ASC is further underlined by electrophysiological studies showing abnormal event-related potentials to direct gaze in children with autism ( ;  ) and infant siblings of children with autism ( ,  ). 

Although atypical processing of gaze in ASC is thought to reflect an impairment in understanding the intentional nature of gaze cues, little evidence has emerged in the form of atypical engagement of brain regions implicated in ToM or mentalizing (e.g. medial prefrontal cortex and TPJ) during gaze perception. Recent neuroimaging studies have shown that individuals with an ASC show an atypical neural response in the pSTS and areas of the attention networks when viewing faces orienting their gaze toward or away from target objects ( ;  ). This has been interpreted as atypical social orienting ( ) or problems in differentiating between expected and unexpected gaze shifts ( ) in individuals with ASC. However, given the central nature of atypical eye contact in ASC, and the prominent role of direct gaze in social interaction and communication ( ), the current study focused on identifying brain areas showing differential processing of direct gaze in adults with ASC relative to typical individuals. In particular, we focused on the medial prefrontal cortex, TPJ, pSTS, and amygdala, in light of previous evidence showing their involvement in inferring the mental states of others and gaze perception ( ;  ;  ;  ). 

Since direct gaze often conveys communicative intent directed toward the observer, we were particularly interested in   proposal that the anterior section of rostral medial frontal cortex (arMFC) is activated when there is a perceived attempt to communicate with the observer ( ;  ;  ). Of particular relevance for the current study, increased activation in this region has been reported in response to viewing direct gaze relative to averted gaze ( ;  ), as well as in response to the longer duration of direct gaze ( ). Similarly, the same area of arMFC responds to hearing one's own name relative to hearing another person's name, another ostensive cue conveying communicative intent directed toward the observer ( ). Additional evidence comes from work using very different paradigms.   showed increased activation in the arMFC in response to communicative intent conveyed by gestures, such as presenting a map as if to ask for directions. In contrast, viewing a scene conveying the private intentions of an agent (e.g. changing a lightbulb to read) showed no significant activation in this region.   found greater arMFC activation when participants detected that an actor was attempting to deceive them about the weight of a box they were lifting, relative to when the lifting action was perceived as genuine. Thus, we were interested in whether direct gaze would elicit reduced arMFC activation in individuals with ASC, suggesting atypical response to ostensive, self-oriented cues. 

A well-established clinical observation is the tendency of some individuals with ASC to avoid direct gaze or eye contact. This observation has been confirmed by several eye-tracking studies, which show that individuals with ASC spend more time looking at both the mouth and nose regions of a face than at the eyes, the opposite pattern to neurotypical controls ( ;  ;  ). To ensure that any differences we observed could not be attributed to avoidance of the eye region, we instructed participants to look at the eyes and monitored their eye movements throughout. 


## Materials and Methods 
  
### Participants 
  
Twenty-five “typical” male participants and 21 males with ASC (2 with high-functioning autism and 19 with Asperger's syndrome) participated in the study for payment. All ASC subjects had a confirmed diagnosis of an ASC: 5 using the Autism Diagnostic Interview-Revised (ADI-R;  ) as part of a previous study at the Autism Research Centre, University of Cambridge, 2 by using the Autism Diagnostic Observation Schedule (ADOS;  ), and the remainder had written confirmation of independent diagnosis by a qualified clinician using DSM-IV (1994) criteria. None of the control group had a diagnosis of ASC or a history of any other psychiatric or neurological disorder. 

All participants had normal or corrected-to-normal vision and completed the Wechsler Abbreviated Scale of Intelligence (WASI, The Psychological Corporation, 1999) and the Autism Spectrum Quotient (AQ;  ). Details of all participants, following the removal of 2 controls and 3 ASCs due to excessive movement in the scanner (see fMRI preprocessing section below), are shown in Table  . The study was approved by the National Research Ethics Service Committee East of England, and all participants provided written informed consent.
   
Participant details 
    


### Experimental Design 
  
Full-face, computer-generated images of 5 male and 5 female identities with neutral facial expressions were generated with the DAZ Studio software (DAZ Productions, Draper, UT, USA). Participants viewed alternating epochs of dynamic averted gaze and dynamic direct gaze events. Epochs were 21 s long and consisted of 6 presentations of averted gaze or direct gaze intermixed with 6 null events. A single trial comprised a 1000-ms presentation of a face displaying direct or averted gaze followed by a low-contrast central cross (750 ms). Averted gaze shift events comprised 2 consecutive 500-ms frames showing leftward gaze followed by rightward gaze or vice versa; this produced a strong illusion of a dynamic gaze shift (Fig.   A  ). Similarly, direct gaze events consisted of consecutive 500-ms presentations of closed eyes followed by open eyes with direct gaze or vice versa, again this produced an illusion of movement (Fig.   B  ). Null events comprised a 1750-ms presentation of the low-contrast cross (Fig.   C  ). The faces' gender and identity were fully counterbalanced across averted and direct gaze epochs, which contained an equal number of the 2 averted and 2 direct gaze event types, respectively. Participants were instructed to decide whether the face was male or female and to respond by button press. They were also instructed to keep their eyes on the eye region of the face and were told that their eye movements were being monitored through the use of an eyetracker. Participants practiced the task outside the scanner prior to the functional magnetic resonance imaging (fMRI) experiment.
   
Trial structure for a sample averted gaze trial (  A  ), direct gaze trial (  B  ), and null trial (  C  ). 
  

Four control subjects and 3 ASC participants viewed 10 epochs of each stimulus condition, for a total of 120 face trials (60 averted gaze shifts and 60 direct gaze blinks). The remaining participants viewed 14 epochs of each stimulus condition for a total of 168 face trials (84 averted gaze shifts and 84 direct gaze blinks). The order of the stimuli during each epoch was pseudorandomized with respect to the trial type (face or null), such that no more than 3 consecutive trials were of the same type. This pseudorandomization enhanced design efficiency while preserving the unpredictability of stimulus onsets in naive participants. The total task duration was 7 min for 10 epochs of the experiment, and 9 min 48 s for 14 epochs. 


### Eye tracking 
  
A 50-Hz monocular MRI-compatible infrared eyetracker (SensoMotoric Instruments [SMI], Teltow, Germany) was used to monitor and record participants' eye movements while in the scanner. Eye tracking data were analyzed with the SMI BeGaze3.0 software. Due to difficulties in tracking some participants' pupils (e.g. drooping eyelids, corrective lenses), reliable eye tracking data were collected in 15 of the 23 control participants, and in 13 of the 18 ASC participants. A rectangular area-of-interest (AOI) was created around the eye region of the stimuli (same size and location for all face stimuli), and the average dwell time in that AOI was determined as a percentage of total time the face was present (excluding artifacts like blinks) to ascertain whether typical and ASC participants looked at the eye region of the faces for similar amounts of time. 


### fMRI Data Acquisition 
  
Data were acquired using a 3-T Tim Trio (Siemens, Erlangen, Germany) scanner. Whole-brain   T  *-weighted echo planar images (EPIs) were acquired with a repetition time (TR) = 2190 ms, echo time (TE) = 30 ms, flip angle = 78°, 36 oblique slices, 3 × 3 mm inplane resolution, and 3-mm slice thickness with a 0.75-mm slice gap. A total of 204 image volumes (for 10 epochs) or 282 image volumes (for 14 epochs) were acquired. In each case, the first 3 volumes were discarded to allow for equilibration effects. A high-resolution structural magnetization-prepared rapid-acquisition gradient echo scan was also acquired for normalization purposes (voxel size 1 × 1 × 1 mm, TR = 2250 ms, TE = 2.99 ms, inversion time = 900 ms, flip angle = 9°, total scan time 4 min 16 s). 


### fMRI Preprocessing 
  
fMRI data preprocessing and analysis were carried out in SPM5 (Wellcome Trust Centre for Neuroimaging,  ). The EPI images were sinc interpolated in time to correct for slice time differences and realigned to the first scan by rigid body transformations to correct for head movements. EPI and structural scans were coregistered and normalized to the   T   standard template in Montreal Neurological Institute space (Montreal Neurological Institute—International Consortium for Brain Mapping) using linear and nonlinear transformations and smoothed with a Gaussian kernel of 8-mm full-width at half-maximum. Three subjects with ASC and 2 control subjects had to be removed from the analysis due to excessive head movements (>3 mm). 


### fMRI Statistics 
  
Data were analyzed by 2-stage implementation of a random effects model. At the first level, the general linear model (GLM) included regressors for 3 conditions: Averted gaze, direct gaze, and null events. Spatial realignment parameters were included as regressors of no interest in the model to account for residual movement-related variance. Data were high-pass filtered at 128 s to remove low-frequency signal drifts. Individual subjects' contrast images were created by contrasting each of the averted gaze and direct gaze conditions with null trials. The second-level GLM consisted of a 2 × 2 factorial design with both group (controls and ASCs) and gaze direction (averted gaze vs. null and direct gaze vs. null) as the main factors. 

As we were expecting group differences in the processing of the social aspects of eye gaze, we had a priori regions-of-interest (ROIs) based on the ToM network: Bilateral TPJ and pSTS, arMFC, and bilateral amygdala. We used these ROIs to correct for multiple comparisons at the family-wise error (FWE) level using small-volume corrections. As the amygdala is a discrete anatomical region, we used the Automated Anatomical Labeling to define both the left and right amygdala ROIs. For bilateral TPJ, pSTS, and arMFC, we used 20-mm radius spheres centered on the average activation coordinates of 10 ToM studies listed in   (combined pSTS and TPJ ROIs: Left   x   = −53,   y   = −56,   z   = 11 and right   x   = 57,   y   = −52,   z   = 10; arMFC:   x   = −1,   y   = 47,   z   = 4). 


### fMRI Connectivity 
  
To determine the strength of correlation or connectivity between the activated regions, time series data across all conditions (direct gaze, averted gaze, and null) were extracted for each subject from spherical 5-mm radius ROIs centered on the peak coordinates of significant gaze direction by group interactions in the arMFC (  x   = 14,   y   = 60,   z   = 2), left TPJ (  x   = −52,   y   = −64,   z   = 24), right TPJ (  x   = 54,   y   = −56,   z   = 18), right middle temporal gyrus (MTG) including pSTS (  x   = 62,   y   = −46,   z   = −6) and left amygdala (  x   = −26,   y   = −2,   z   = −24). Extracted time series were adjusted for effects of interest in each subject. The first eigenvariate was determined from the extracted time series, and Pearson's correlations between each pair of regions were determined. Correlation values were Z-transformed (Fisher's Z) to normalize the distribution, and group differences determined by analysis of variance (ANOVA) with group (control and ASC; between subjects) and connection (all combinations of ROIs above for a total of 10 connections; repeated measures) as factors. When appropriate,   P  -values were corrected for nonsphericity using the Huynh–Feldt correction. 

In order to determine whether connectivity differences were specific to the ToM network or reflected widespread reduction in connectivity in ASC, we performed correlation analyses on 2 additional “control” networks: A motor network and a visual network based on the contrast of faces versus null. Using the same methods as described above, time series data were extracted from 4 ROIs comprising a motor network, and 3 ROIs comprising a visual network. Each ROI had a radius of 5 mm and was centered on the peak coordinate in that region for the contrast of all gaze trials (direct and averted) compared with all null trials (FWE corrected for multiple comparisons at the whole-brain level). The motor network comprised of left primary motor cortex (  x   = −40,   y   = −22,   z   = 58), left supplemental motor area (  x   = −4,   y   = −2,   z   = 54), and left (  x   = −56,   y   = 4,   z   = 38) and right (  x   = 54,   y   = 4,   z   = 44) premotor cortex. The visual network comprised of left (  x   = −34,   y   = −78,   z   = −16) and right (  x   = 30,   y   = −78,   z   = −12) inferior occipital gyrus, and right fusiform gyrus (  x   = 38,   y   = −46,   z   = −22). 

Although we incorporated movement parameters into both our first-level GLM and our connectivity analysis, we also calculated root mean square movement in each of the 3 translation and rotation directions for each subject and entered these data into a repeated-measures ANOVA. There were no significant group differences in movement (  F   < 1,   P   = 0.7). Hence, any group differences in the results are unlikely to be driven by differences in simple movement. 



## Results 
  
### Behavioral Results 
  
There was no difference between groups in accuracy on the gender discrimination task with both groups showing high levels of performance (mean ± standard deviation: Controls 98 ± 3% and ASC 97 ± 4%). An analysis of correct reaction times showed no significant main effect of group (  F   = 0.005,   P   = 0.94) or gaze direction (  F   = 0.42,   P   = 0.52), neither was there a significant group × gaze direction interaction (  F   = 0.39,   P   = 0.54). 


### Eye tracking 
  
An analysis of the average dwell time within the AOI encompassing the eye region showed no significant main effect of group (  F   = 0.06,   P   = 0.80) or gaze direction (  F   = 0.84,   P   = 0.37), neither was there a significant group × gaze direction interaction (  F   = 0.33,   P   = 0.57; Fig.  ).
   
Average percent total dwell time on the eye region for each gaze direction condition and each group. Error bars represent the standard error of the mean. 
  


### fMRI: Gaze Direction 
  
We compared the responses to both averted and direct gaze between the groups in a 2 × 2 factorial design with group (controls and ASCs) and gaze direction (averted gaze vs. null and direct gaze vs. null) as the main factors. Consistent with our hypothesis, we found a significant gaze direction by group interaction in the arMFC. A breakdown of this interaction revealed that controls showed an increased response to direct gaze relative to averted gaze, consistent with previous research ( ;  ). In contrast, individuals with ASC showed the reverse, with an increased response to averted gaze. This pattern was mirrored across other regions of the ToM network, including bilateral TPJ, left amygdala, and right MTG extending into the pSTS; borderline significant effects were found in both the left pSTS and right amygdala (Fig.   and Table  ). While the significant interactions in each of the a priori ROIs highlight statistically distinct patterns in the 2 groups, separate analyses for each group showed that this was most robust in the arMFC, TPJ, and amygdala (Table  ). No ROIs displayed a greater response to averted gaze than to direct gaze in the control group. Similarly, none showed a greater activation in the ASC group when direct gaze was compared with averted gaze.
   
Coordinates and   P  -values for group (control and ASC) by gaze direction (direct vs. null and averted vs. null) interaction, controls direct gaze > averted gaze, and ASC averted gaze > direct gaze 
      
Areas showing a significant group by condition interaction. (  A   and   B  ) arMFC; (  C   and   D  ) left TPJ and left pSTS; (  E   and   F  ) left amygdala. Graphs represent the parameter estimates at the peak voxel for averted and direct gaze. Error bars represent the standard error of the mean. Brain images are displayed at a threshold of   P   < 0.001 uncorrected for visualization purposes. 
  

There was no main effect of gaze direction irrespective of group in any of our ROIs. There was also no main effect of group in our ROIs, indicating that the 2 groups did not differ in the overall response of these regions to gaze cues. 

In order to rule out the possibility that individuals for whom we did not have eye tracking data were driving the group differences we observed, we repeated the group analysis using only those subjects with eye tracking data (15 controls and 13 ASCs). We again found a significant group by gaze direction interaction effect in right TPJ, arMFC, and left amygdala (  Supplementary Table 1  ). Including the fraction of time spent in the eye region of the face as a covariate of no interest in the model also did not change these results (  Supplementary Table 2  ). 


### fMRI Connectivity 
  
In order to examine whether connectivity between pairs of areas involved in gaze processing differed between the control and ASC groups, we performed a correlation analysis of the time series data for all regions that showed a significant group by gaze direction interaction (arMFC, left and right TPJ, right MTG/pSTS, and left amygdala). The correlations between these regions were significantly different between groups (Fig.  ;   F   = 5.05,   P   = 0.03) with the ASC group showing an overall reduction in connectivity. There was also a main effect of connection (  F   = 28.8,   P   < 0.001), but no significant group by connection interaction (  F   = 1.1,   P   = 0.37). Thus, while areas of the ToM and gaze perception networks in the control and ASC groups did not differ in their overall response to direct and averted gazes (no main effect of group in the above analysis of voxel wise effects), the connectivity between the components of this network is significantly reduced in ASC during a sequence of direct and averted gaze trials. Note that this connectivity analysis refers to the correlation between regions across the whole time series, not differential connectivity between trial types: It is independent of whether particular trials display direct gaze, averted gaze, or null events.
   
Mean Fisher Z-transformed correlations for control and ASC groups for the fMRI time series between regions with a significant group by gaze direction interaction: arMFC, left and right TPJ, right MTG (extending into pSTS), and left amygdala. 
  

Connectivity within 2 further networks, a motor network and an early visual network, was also examined in order to determine whether differences in connectivity were specific to the ToM network or simply reflected generally reduced connectivity in the ASC group. As with the ToM network regions, none of the motor or visual regions identified in the faces versus null contrast showed a main effect of group. A correlation analysis of the motor and visual networks showed no differences in connectivity between the 2 groups (  F  s < 1,   P  s > 0.8), despite showing a main effect of connection (motor   F   = 36.5, visual   F   = 61.8,   P  s < 0.001). There were no group by connection interactions (  F  s < 2,   P  s > 0.3). Since these 2 networks are local in their extent and do not include longer range connections, similar to those seen in the ToM network, we also ran a correlation analysis of the visual and motor network combined (  Supplementary Figure 1  ). Again, we found no significant differences between groups (  F   < 1,   P   = 0.98), no connection by group interaction (  F   < 1,   P   = 0.87), but a main effect of connection as expected (  F   = 54,   P   < 0.001). 



## Discussion 
  
Research with typical individuals has shown that the arMFC is involved in reading another's intent to communicate with the observer ( ). We provide the first evidence that individuals with ASC show an atypical response pattern in this region to direct gaze, a salient ostensive cue conveying communicative intent directed at the observer. This was expressed as a gaze direction by group interaction, with typical controls showing the expected increased response in the arMFC to direct relative to averted gaze, and individuals with ASC showing the opposite pattern. This same pattern was mirrored across other regions of the ToM network, specifically the TPJ, amygdala, and pSTS. Our results suggest that gaze directed toward the self does not convey the same communicative salience in individuals with ASC as it does in typical controls. These group differences occurred despite the faces' gaze being incidental to the experimental task, which involved in categorizing the face's sex. Our study therefore suggests that individuals with ASC show atypical spontaneous or implicit processing of eye gaze in the ToM network. 

Given the evidence for the avoidance of eye contact and the eye region more generally in the ASC ( ;  ;  ), it was important to exclude that the atypical neural response in the ASC group resulted from such different viewing patterns per se. However, our eye tracking data verify that there were no group differences in the amount of time spent looking at the eyes for either the direct or averted gaze conditions. Although eye tracking data were only available for a subset of the participants, an analysis of fMRI data for this subgroup supported the findings from the entire sample. The contrasting activation patterns we observed in the control and ASC groups are therefore unlikely to reflect differences in time spent looking at the eyes. 

The results confirm our hypothesis that individuals with ASC show abnormal activation of the ToM network when viewing direct gaze. However, given that the pattern of activation to both direct and averted gaze is reversed in the ASC group (averted > direct) relative to the controls (direct > averted), it is clear that the same brain regions show an atypical response to both direct and averted gaze in ASC. Note that the ToM regions (arMFC, TPJ, pSTS, and amygdala) also showed no main effect of group, indicating that it is the relative response to both direct and averted gaze that is atypical in ASC, rather than the overall extent to which these regions are engaged. Whether it is meaningful that individuals with ASC show an increased response to averted gaze in the ToM network is unclear. For instance, it may be that, in ASC, averted gaze is a more salient or a preferred mode of social interaction and therefore engages the ToM network in a similar way to direct gaze in typical individuals. At present, however, our study shows that the relative response to direct and averted gaze in these regions is atypical in individuals with ASC. And more specifically, individuals with ASC do not show the previously established increased response to direct gaze in the arMFC found in typical individuals ( ;  ). 

The absence of an increased response to direct gaze in the arMFC and other ToM regions is consistent with the hypothesis that individuals with ASC are not attributing intentions to direct gaze faces in the same way as controls (e.g. he is interested in me, he wants to talk to me). Previous fMRI studies have found that individuals with ASC show reduced response in ToM regions relative to typical individuals when the task is designed to elicit the attribution of intentionality, for instance to moving shapes ( ). Similarly,  ) found that unexpected gaze shifts away from an object, seen as a violation of subjects' expectations, did not elicit an increased response in pSTS in individuals with ASC, suggesting that they had not formed any expectations about the intentionality of the gaze shift. Although our paradigm is very different and did not involve gaze shifts toward or away from an object, the observed reduction to direct gaze in individuals with ASC relative to controls can also be interpreted as atypical extraction of intentionality in the ASC group, that is, direct gaze does not signal the same communicative intent to individuals with ASC. However, it is unclear whether the increased response to averted gaze in ASC might reflect an increased attribution of intentionality, for instance, because averted gaze signals greater communicative intent or salience to the observer with ASC. 

It is worth noting that averted gaze can also convey communicative intent, particularly in joint attention scenarios where the gaze cue is designed to draw the observer's attention toward, for example, an object in the environment. However, our stimuli were presented in the absence of an explicit target and did not involve gaze shifts toward or away from the observer or an object, making it unlikely that our averted gaze condition elicited joint attention mechanisms. We also found no regions with an increased response to averted gaze in our control group, again suggesting joint attention mechanisms were not significantly engaged ( ;  ). Although initiating and responding to bids of joint attention have been shown to elicit atypical brain responses in individuals with ASC ( ), our results suggest that atypical processing of gaze in ASC is present even in the absence of a joint attention style format. 

The results of our connectivity analysis demonstrate that, relative to the controls, individuals with ASC showed decreased connectivity among the regions of the ToM network that showed a significant group by gaze direction interaction (arMFC, TPJ, pSTS, and amygdala). Note that the connectivity analyses looked at the correlations among these regions across the entire time series comprising direct gaze, averted gaze, and null events. It was not a psychophysiological interaction between stimulus type and connectivity. Hence, the reduced connectivity in the ASC individuals is not explained simply by the reverse patterns of local activation to direct and averted gaze in the control and ASC groups. Importantly, the change in correlations is also not explained by differences in overall engagement of these regions in the 2 groups, as there was no significant main effect of group in the analysis of regional effects. Finally, connectivity analyses of 2 further networks, a motor network and a visual network as well as a combined visuo-motor network, suggest that the connectivity differences observed in the ToM network are specific to that network rather than reflecting an overall reduction in connectivity in ASC. 

To our knowledge, only one other study has looked at differences in the neural processing of direct gaze in ASC relative to typical individuals ( ). Consistent with the present study, they found a significant group by gaze direction interaction in the right TPJ, with controls showing greater activity in this region to direct relative to averted gaze, and the opposite pattern in ASC; however, they did not find differences in activation in the arMFC and other regions of the ToM network identified in our current study. Neither did   find that these regions, including the TPJ, showed main effects of gaze direction in separate analyses of the control and ASC groups. The discrepancies with our current study might be explained by a number of factors.   used a very different design to our own in which the stimuli consisted of a video clip of a man walking toward the viewer while looking at or away from them, so there were no changes or shifts in the person's gaze. Inclusion of the man's entire body and the background context may also have encouraged the participants to focus on parts of the stimuli other than the face. In the absence of eye tracking data, it is also unclear whether the observed differences could be attributed to atypical looking behavior in ASC. It is also worth noting that the TPJ showed the largest mean difference in activation for direct relative to averted gaze in both groups in our study, hence   study may underestimate the extent of the atypical processing of direct gaze direction in ASC, identifying only regions with the largest amplitude difference. 

### Limitations 
  
Although our gaze stimuli created an illusion of movement and are therefore more typical of eye gaze encountered during social interactions than static images, our faces were computer generated. Hence, future research should determine whether similar findings are found for real-life videos. It is also worth noting that our participants with ASC consisted primarily of individuals with Asperger syndrome, and all of our participants were high functioning with IQs of 85 or higher. It remains to be seen, therefore, whether the current findings generalize to lower-functioning forms of ASC. In addition, our participants were explicitly instructed to look at the eye region of the face, a behavior that may not come naturally to some individuals with ASC ( ;  ;  ). While this instruction helps discount that a failure to look at the eyes in the direct or averted gaze conditions underlies the different neural patterns in the control and ASC groups, it is unclear whether asking ASC participants to look at faces in a potentially unnatural way may have contributed to our results. Finally, recent work has highlighted contributory artifacts to connectivity measures, particularly differences in motion ( ;  ). We cannot wholly exclude this possibility, but note that the sum of movement displacements (of any amplitude) did not differ between the groups, indicating no systematic difference in head motion. We also modeled motion parameters in the first level, corrected for motion parameters when extracting the regional time series, and found that connectivity differences were not restricted by connection length (a feature of motion-induced artifactual connectivity changes). 

In conclusion, we have shown that individuals with ASC show distinct response patterns to dynamic changes in direct and averted eye gaze relative to controls. Although the controls displayed an increased response to direct relative to averted gaze in the arMFC and other areas of the ToM network, the ASC group showed the opposite pattern. Individuals with ASC also showed significantly reduced connectivity between brain areas showing a group by gaze direction interaction. Thus, in individuals with ASC, areas of the ToM network show both atypical localized changes in processing gaze direction and atypical communication. We suggest that direct gaze does not convey the same communicative intent for individuals with ASC as it does for controls, and that averted gaze may be a more socially meaningful stimulus in ASC. Whether the increased activation in the ToM network in ASC in response to averted gaze fulfills a similar role to direct gaze in typical individuals remains to be seen. 



## Supplementary Material 
  
 Supplementary material can be found at: http://www.cercor.oxfordjournals.org/  


## Funding 
  
This work was funded by the   (  to A.J.C. and a program grant to S.B.C.). J.B.R. is supported by the   ( ). Funding to pay the Open Access publication charges for this article was provided by the UK Medical Research Council. 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-61'>
<h2>61. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/25611512/' target='_blank'>25611512</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Learning-Induced Plasticity in Medial Prefrontal Cortex Predicts Preference Malleability</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Neuron</p>
<p><strong>Publication Year:</strong> 2015</p>
<p><strong>DOI:</strong> 10.1016/j.neuron.2014.12.033</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4306543/' target='_blank'>4306543</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study reports an fMRI experiment in healthy adult participants (29 scanned, 27 analyzed; mean age 25.6) using a social task (delegated inter-temporal choice; learning/simulating another person’s preferences—perception and understanding of others). Imaging analyses used whole-brain random-effects GLMs with cluster-defining thresholds and FWE correction (whole-brain results reported), not restricted to ROI-only findings. Healthy participant results are reported separately and meet the age range criterion. Thus all inclusion criteria are satisfied and no exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>   Summary  
Learning induces plasticity in neuronal networks. As neuronal populations contribute to multiple representations, we reasoned plasticity in one representation might influence others. We used human fMRI repetition suppression to show that plasticity induced by learning another individual’s values impacts upon a value representation for oneself in medial prefrontal cortex (mPFC), a plasticity also evident behaviorally in a preference shift. We show this plasticity is driven by a striatal “prediction error,” signaling the discrepancy between the other’s choice and a subject’s own preferences. Thus, our data highlight that mPFC encodes agent-independent representations of subjective value, such that prediction errors simultaneously update multiple agents’ value representations. As the resulting change in representational similarity predicts interindividual differences in the malleability of subjective preferences, our findings shed mechanistic light on complex human processes such as the powerful influence of social interaction on beliefs and preferences. 
   Highlights  
  
Learning the values of another causes plasticity in a mPFC value representation 
  
This plasticity predicts how much subjects’ own preferences change 
  
Plasticity is explained by a striatal surprise signal 
  
Value coding in mPFC occurs independently of the agent for whom a decision is made 
  
  
Garvert et al. demonstrate that learning the preferences of another person increases the similarity between neural value representations for self and other. This plasticity in medial prefrontal cortex predicts how much one’s own preferences shift toward those of the other. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (41627 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Information in the brain is encoded within distributed neuronal populations such that individual neurons typically support more than one representation or computation. Neurons in medial prefrontal cortex (mPFC), for example, perform self-referential as well as social value computations ( ). Whereas it is traditionally suggested that computations for self and other are performed within separate populations of neurons ( ), recent work suggests a functional organization within this region does not neatly conform to such a distinction by agent. Instead, value computations on behalf of any individual can be realized by the same circuitry ( ), and the neural code depends only on the subjective value of an offer. In light of this, we conjectured that multiple value computations might be updated simultaneously if plasticity is introduced into this circuitry. 

The contribution of overlapping neural circuitry to distinct computations has previously been demonstrated during delegated inter-temporal choice ( ). In inter-temporal choice paradigms, subjects reveal their preferences for larger reward delivered later versus smaller reward that arrive sooner. Choice in this context is quantified by a “temporal discount rate” ( ), believed to index forms of behavioral impulsivity ( ) and an ability to imagine future outcomes ( ). When subjects are asked to make such inter-temporal choices on behalf of another individual (“delegated inter-temporal choice”), they rapidly learn the confederate’s discount rate ( ). This adaptability depends on the medial prefrontal cortex, where a neural circuitry used to compute a subject’s own values also computes those of a confederate, enabling rapid switches between the two computations ( ). 

We reasoned that if the same circuitry in the mPFC computes the value of a delayed offer irrespective of agents, plastic changes necessary to learn a new partner’s preferences might have consequences for a subject’s own value computations. The presence of such plasticity would also be expected to induce behavioral change in the subject’s own temporal discount rate, a parameter usually assumed to index a stable personality trait ( ). One can conjecture that such plasticity might underlie social conformity effects, where individuals adjust their beliefs or preferences to align more with those with whom they interact ( ). 

At a neuronal level, a formal test of these predictions requires a fine-grained access to neural populations supporting distinct value computations, as well as a robust measure of learning-induced change in activity of these same populations. Despite its coarse spatial resolution, fMRI can reveal relationships between underlying cellular representations. In particular, fMRI adaptation paradigms can be finessed to measure plastic changes associated with the behavioral pairing of different items ( ). The principle of fMRI adaptation builds on the idea that the repeated engagement of the same neuronal population leads to a diminished response and attenuated BOLD signal, even though the underlying biophysical mechanism remains ambiguous ( ). 

Here we used an fMRI adaptation paradigm to measure the relationship between neuronal value representations for self, a familiar other whose preferences had been learnt prior to scanning and a novel confederate as this latter agent’s preferences were learnt. We deployed a dynamic repetition suppression procedure to provide us with a probe of plastic neural changes associated with learning a new flexible computation. We hypothesized that plasticity associated with this new learning would impact upon the preference representation for self as a consequence of a neuronal representation that maps agent and offer onto an agent-independent measure of subjective value. In essence, this predicts that neuronal value representations between self and a novel other should become more similar with learning, in line with a behavioral shift in preference. An alternative hypothesis posits separate value computations for distinct agents. In such a case, a subject might use their own separate neural representations as a proxy for understanding another’s traits, and an independent neuronal value representation for this other would be constructed through learning-induced plasticity ( ). This alternative scenario predicts that neural value representations for self and other should become less similar with learning. In terms of a mechanism driving such plasticity, we reasoned that the same prediction errors that drive learning about a new partner’s inter-temporal preferences would also induce shifts in the subject’s own discount rate toward that of the partner. 


## Results 
  
### Discount Rates Are Susceptible to Social Influence 
  
To examine whether learning about the preferences of another agent impacts on subjective inter-temporal preferences, we tested 27 subjects on a standard inter-temporal choice task both before, and after, performing the identical task on behalf of a partner ( A and 1B). As in the standard format, subjects deciding for themselves chose between an immediately available smaller reward and a delayed larger reward. The degree to which delay diminishes the value of a reward was then quantified by a discount rate, computed from each subject’s actual choices both before and after the experimental manipulation. The latter involved a context whereby subjects performed the very same task but now chose the option they inferred a confederate would prefer. After each trial they were given feedback about the choice the confederate had actually made, such that they could learn to simulate these choices in future trials. 

Subjects learnt quickly, and accurately, to choose according to a novel partner’s preferences ( C and S1D). Subjects believed that the partner was a human participant playing the game in a neighboring room ( G and S1H). In actual fact, and in part motivated by a need for good experimental control, we delivered feedback of a simulated player with preferences very different from the subjects’ own (see  ). 

Notably, we found that, after learning a partner’s preferences, subjects’ own discount rate shifted in the direction of the partner ( , t  = 3.06, p = 0.006,  C). Their estimate of the novel other’s preferences remained stationary ( , t  = 0.99, p = 0.33) and was not biased toward subjects’ own preferences (t  = 0.49, p = 0.63). This effect is not easily understood as a social norm effect ( ), as we also observed discount rates shifted similarly when subjects were instructed they were deciding on behalf of a computer agent (t  = 3.89, p < 0.001,  F). 

One account of this shift in preference is that it arises out of a simulation of the other’s preferences. In order to test whether such simulation is crucial for this shift or whether the behavior can be explained by simple stimulus- or action-based reinforcement, we designed a category-learning control experiment ( ). This consisted of the same stimuli and actions, but the necessity to simulate another’s discount rate was removed. Subjects were presented with a geometric depiction of a given choice on the screen (x axis: delay of the latter option; y axis: ratio of magnitudes M /M ;  A, right) and instructed to choose according to the location of the dot with respect to an imaginary isoprobability line. Rather than using feedback to update a value simulation, subjects now updated their belief about the orientation of this line. In this scenario, subjects’ discount rates did not shift, indicating that subjects were not merely repeating previous choices they had made on behalf of the other (t  = 0.61, p = 0.55; see  F). This latter finding emphasizes a necessity for preference simulation for another agent in order to modulate a discount rate. 


### Subjective Value Changes Are Induced by Learning 
  
The above account suggests that learning to compute the preferences of another agent induces plastic changes in the neural architecture responsible for personal valuation. This in turn predicts the neural population engaged during the computation of self valuation should change over the course of the experiment. This population should either become closer to that evoked during valuation for the partner if the representational structure of an offer depends solely on its subjective value irrespective of the individual. Alternatively, it should become less close if separate agent-specific representations exist and subjects construct an independent representation for the novel other as a consequence of learning. To test for such change in similarity between neural representations for self and others we interleaved trials from the delegated inter-temporal choice task with “probe” trials in the fMRI scanner. These probe trials enabled us to measure repetition suppression between individuals ( D and 1E). We reasoned that if self and partner valuation mechanisms overlapped more after learning than before, in line with an increase in behavioral similarity, then this predicts greater repetition suppression at the end of the experiment than at the beginning. If, however, subjects constructed a representation of the novel other from their representation of self, then this predicts the very opposite, namely repetition suppression at the beginning of the experiment, which disappears as subjects build a separate representation of the novel partner. 

To be certain that any effects were driven by learning about the partner, as opposed to exercising a choice per se, we introduced a third player (a familiar partner) whose discount rate had been learnt prior to scanning. This controlled for non-specific time-dependent signal changes not associated with learning of new preferences. Thus, our experiment comprised three players: the subject (“self”), a partner whose preferences were learnt prior to scanning (“familiar other”), and a partner whose preferences were learnt during scanning (“novel other”). The familiar and novel others’ choices were simulated based on discount rates placed equally far apart on opposite, and counterbalanced, sides of the subject’s original discount rate. This meant that one partner had a smaller, and the other partner a larger, discount rate than the subject himself. 

We scanned 27 subjects while they performed the two interleaved tasks. In choice trials, as in the behavioral experiment described above, subjects again made inter-temporal choices for themselves and for the two partners. In “probe trials,” subjects performed evaluations serially on behalf of different players, allowing us to measure repetition suppression between the value representations of different individuals ( E). After each choice trial for the novel or the familiar partner, but not after probe trials, subjects were given feedback about the choice the confederate had made. 

In line with our behavioral results, subjects’ discount rates shifted toward the discount rate of the familiar partner during preference learning prior to scanning (t  = 3.17, p = 0.004,  F). During scanning, both subjects’ own discount rate (t  = 3.05, p = 0.006) and subjects’ estimated discount rate of the familiar partner (t  = 2.87, p = 0.008) shifted toward the newly learnt discount rate of the novel partner, with a stronger relative shift evident for subjects’ own discount rate (t  = 2.18, p = 0.04) but comparable absolute shifts (t  = 0.72, p = 0.48). These preference shifts were therefore not simply associated with repeating the partner’s choices but instead are most parsimoniously explained as induced by learning a new individual’s preferences. 


### Plasticity between Neural Representations of Self and Other 
  
To address whether a measured change in subjective preference is linked to plasticity in neural populations computing valuations for self, we focused our analysis on the probe trials. We first established that we could measure repetition suppression by comparing brain activity elicited by simulating values for an agent when preceded by the same agent compared to a situation where an agent was preceded by another agent. Different agents were indicated to the subject by different colors on screen ( D). Unsurprisingly, we observed fMRI adaptation in the visual cortex (p < 0.001, peak t  = 16.93, [30, −61, −8], reported here and in subsequent fMRI analyses as familywise error (FWE) corrected on cluster level,  A) ( ), but also in a network that included mPFC (p = 0.02, peak t  = 5.76, [3, 53, −11]) and left superior temporal sulcus (STS) (p < 0.001, peak t  = 4.95, [−51, −13, −8]). The latter two regions are associated with mentalizing ( ), valuation for self ( ), and valuation for others ( ). While this main effect of repetition suppression does not dissociate visual from agent-specific effects, it confirms that similarity in neural patterns evoked in a valuation network can be indexed by repetition suppression ( ). 

We reasoned that we could use this index of neural similarity to investigate whether the observed shift in subjective preferences was linked to plastic changes in the valuation network. If the neural code depends on the subjective values of a given offer alone, then repetition suppression should emerge between self and novel other over the course of the experiment, given that discount rates for self align with discount rates for the novel other. If, on the other hand, the mPFC encodes value differentially depending on agent, where learning another’s preferences involves the construction of an independent representation of this novel other from a representation of self, then repetition suppression should decrease over the course of the experiment. While a similar change in suppression might also be predicted between novel and familiar others, there should be no such change in suppression between self and familiar other if in fact we are indexing changes induced by new learning. 

We designed a contrast that measured the change in repetition suppression between self and novel other from block 1 to block 3, controlled for by the change in repetition suppression between self and familiar other over the same blocks (see  ). The only brain region to survive whole-brain statistical correction was in mPFC ( B, p = 0.01, peak t  = 3.82, [−12, 53, 1]), although sub-threshold clusters in the left and right STS were also present (p = 0.27, peak t  = 3.77 and p = 0.48, peak t  = 3.38, respectively). This region overlaps with an area involved in self-referential processing and in encoding value on probe trials ( B and S3C). There were no significant effects for the opposite interaction. This change cannot be due to visual effects, as we controlled for these both by inclusion of the familiar agent and separately by the comparison between early and late blocks in the experiment. Consequently, visual regions do not show these condition-specific changes in suppression ( ). Neither can the effect be due to novelty or differences in processing speed, as no differences between main effects of novel and familiar others were seen in this region ( A) or in the response times ( A and S4B). Furthermore, an equivalent contrast measuring the change in suppression between self and novel other, but now controlling for the change in suppression between familiar and novel other, revealed a similar change in activity in an overlapping brain region ( C). Hence, in the mPFC learning the preferences of a novel agent specifically increased repetition suppression between representations of self and this novel partner. 

To further investigate these mPFC suppression effects, we employed a jack-knife procedure across subjects to extract parameter estimates from the cluster of interest. Consistent with the whole-brain analysis, we found a significant change in novel-to-self/self-to-novel suppression ( D, t  = 2.86, p = 0.008), but not in self-to-familiar/familiar-to-self suppression from block 1 to block 3 (t  = 0.64, p = 0.52). The change in novel-to-familiar/familiar-to-novel suppression in the same region of interest (ROI) was in the same direction, but did not reach significance (t  = 1.54, p = 0.14), and was smaller than the change in novel-to-self/self-to-novel suppression (t  = 1.65, p = 0.05). Since overall activity in mPFC for self trials was greater than activity for other trials ( B), sensitivity to repetition suppression may differ depending on the order of the two agents. To explore potential differences, we decomposed the contrasts described above. Changes in repetition suppression between self and novel other were observed in both directions ( E) but were only significant when self trials were the priming and not the test trials ( E; ANOVA: left, F  = 3.39, p = 0.04, right F  = 1.55, p = 0.21). 


### Plasticity in mPFC Predicts Discount Rate Shifts 
  
If the observed behavioral change in preference is related to learning-induced plasticity in value computations, then the increase in representational similarity between self and novel other should predict a subject’s shift in preference. The increase in self-to-novel relative to self-to-familiar suppression over blocks did indeed predict the shift in subjects’ own discount rate toward the novel other (partial correlation, r = 0.54, p = 0.007,  A), but not the same shift in the subjects’ estimate of the familiar other’s discount rate (partial correlation, r = 0.15, p = 0.46,  B), although a direct comparison of these effects in a multiple regression analysis did not reach significance (t  = 0.71, p = 0.24). The shift in subjects’ estimate of the familiar other’s preferences was instead loosely related to an increase in representational similarity between familiar and novel other ( ). The fact that the behavioral estimate for a shift in discount rate was derived from choice trials, whereas the neural plasticity effect was extracted from probe trials, strongly suggests that learning a partner’s choice induces a stable plasticity in regions involved in value computation. 


### Plasticity in mPFC Is Predicted by Surprise Coding in the Striatum 
  
A plausible mechanism for inducing plastic change is surprise or prediction error, which in this context arises when the familiar or the novel partner’s choices diverge from the choice the subjects themselves would have made given the same choice context. Bayes-optimal estimates of this measure (see  ) were reflected in the posterior medial frontal cortex (pMFC) ( A, p = 0.04, peak t  = 4.09, [−9, 29, 58]), a region previously associated with surprise coding in monkeys ( ), as well as in both insula and striatum (caudate nucleus), although these did not survive a stringent multiple comparisons correction (right insula: p = 0.16, peak t  = 8.37, [30, 26, −8]; left insula: p = 0.19, peak t  = 6.25, [−33, 26, −5]; left striatum (p = 0.84, peak t  = 3.44, [3, −25, −8]). pMFC and striatum are strongly implicated in the expression of a prediction error type signal in reinforcement learning ( ), as well as in signaling a discrepancy between an individual’s behavior and the behavior of a group ( ). An alternative measure of prediction error, where surprise was quantified as the discrepancy between the predicted choices of the partner and the partner’s actual choices, did not yield significant activity in any area of the brain. A more lenient cluster-defining threshold of p = 0.05 revealed much smaller clusters in a similar network as the first surprise measure that did not survive multiple comparisons correction (e.g. pMFC, p = 1.0, peak t  = 2.72, [6, 35, 40]). 

A striatal prediction error type signal is known to drive learning through an influence on cortico-striatal plasticity ( ). In line with this notion, the BOLD correlate of the surprise about the novel partner’s choices in the striatum predicted the behavioral shift in subjects’ own discount rate ( B, r = 0.50, p = 0.01) as well as the change in self-to-novel versus change in self-to-familiar neuronal suppression over blocks in mPFC ( C, r = 0.41, p = 0.04). No such relationship was evident for pMFC or insula activity and mPFC plasticity (r = 0.04, p = 0.84 and r = 0.14, p = 0.48, respectively). 

Finally, if prediction errors cause plasticity, and plasticity in turn causes the shift in subjects’ discount rate, then plasticity in mPFC should formally mediate the impact of the striatal surprise signal on the shift in discount rate. We used single-level mediation to test this hypothesis ( ). The path model jointly tests three effects required if indeed mPFC plasticity provides the link between a surprise signal and the shift in discount rate: namely, the relationship between striatal surprise effects and mPFC plasticity (path a), the relationship between mPFC plasticity and shift in discount rate (path b), and a formal mediation effect (path ab) that indicates that each explains a part of the discount rate shift covariance while controlling for effects attributable to the other mediator. All three effects were significant in a mediation analysis (path a = 0.15, SE = 0.07, p = 0.04; path b = 0.30, SE = 0.12, p < 0.001; path ab = 0.05, SE = 0.03, p = 0.01,  ), supporting the idea that prediction errors influence the discount rate by inducing mPFC plasticity, which in turn impacts upon choice behavior. Hence, subjects with the largest striatal surprise signal at outcome of choice trials exhibited both the largest changes in representational similarity on probe trials and the largest changes in preferences, suggesting a role for striatal prediction error signals in inducing cortical plasticity and associated behavioral change. 



## Discussion 
  
The brain’s representational architecture involves population codes wherein individual neurons contribute to a multitude of computations. We set out to investigate whether multiple neuronal representations can be updated simultaneously by learning-induced plasticity targeting one computation alone. The approach we developed exploited repetition suppression ( ) to probe the similarity between distinct neural representations ( ) by interleaving probe valuation trials with decision blocks that induced prediction errors and learning. While the biophysical mechanisms underlying fMRI repetition suppression remain ambiguous ( ), in a careful experimental design this approach allows inferences about population coding with respect to precise features of stimuli ( ) or computations ( ). 

We were interested in changes of value representational similarity over time. By asking subjects to evaluate presented options on behalf of themselves, a novel other whose preferences were acquired during on-line scanning and a familiar other whose preferences had previously been learnt, we could interrogate representational similarity in neuronal populations encoding valuation for these three agents. In line with previous reports that highlight a social influence on the valuation of objects ( ), we found learning about the preferences of a novel agent had clear behavioral consequences evident in a shift in subjects’ own, as well as their estimation of a familiar other’s, discount rate. This behavioral effect coincided with an increase in neural representational similarity in the mPFC. This supports a view that value representations in the mPFC are not aligned to the frame of reference of an individual. Instead, the increase in neuronal overlap tied to a shift in behavioral preferences suggests that the mPFC encodes agent-independent representations of subjective value. 

The presence of a learning-induced representational plasticity for value is likely to depend on generic learning mechanisms. The most influential computational account posits a role for a reward prediction error implemented via phasic activity of dopamine neurons ( ), a putative teaching signal for cortico-striatal learning ( ). Prediction errors align with the dimension relevant for learning in a given situation. They manifest as a sensory prediction error when subjects learn to predict a sensory event ( ), a probability prediction error when subjects learn about reward probability ( ), and a social expectancy prediction error when group preferences diverge from subjects’ own valuations ( ). In the current experiment, a prediction error (expressed in pMFC, insula, and striatum) corresponds to the surprise subjects experience when a partner’s choice is incongruent with their own preference. This accords with previous studies demonstrating an expression of a similar signal representing a discrepancy between one’s own and a group’s opinion ( ). Crucially, our results extend on these reports by showing this error coding is directly related to an expression of plasticity in mPFC, a region widely implicated in tracking preferences for stimuli ( ) as well as inter-temporal preferences ( ). 

The mPFC region displaying the change in repetition suppression is a complex and heterogeneous area with strong connections to regions such as the amygdala, hippocampus, hypothalamus, and insula enabling access to sensory, visceral, and emotional information. It is considered ideally placed for self-referential processing ( ) and for attributing value to stimuli across many reward contexts ( ) and internally generated states ( ). However, a mPFC value computation is also remarkably flexible, and can occur even if direct experience is not available ( ) or if there is a requirement for an abstract model of task structure ( ). This flexibility is vital in social cognition, where a model of the preferences and intentions of another individual needs to be decoupled from the physical and perceptual reality of a subject’s own internal state ( ). Traditionally, it has been suggested that such computations occur in distinct circuitries, where a ventral sector of the mPFC encoding subjective stimulus values ( ) is complemented by a dorsal sector representing the mental states of others ( ). However, this notion is challenged by an observation that a dorsal-ventral axis can be better understood in terms of executed versus modeled choices ( ). The latter observation supports the idea that the very same area encodes subjective value irrespective of the frame of reference, a notion strongly supported by our current observation that a behavioral shift toward the value of a novel agent is mirrored by an increase in neural overlap. 

Irrespective of the exact nature of the observed plasticity, the underlying mechanism would seem to necessitate an overlap in neural populations encoding values for a novel other, self, and a familiar other. How exactly might the brain calculate discounting preferences with neural populations that are prone to the observed shifts in preference? Theoretical studies suggest an agent’s overall preferences might arise out of a summation over a distributed set of discounting units ( ). This is consistent with recordings in rat orbitofrontal cortex demonstrating a distributed encoding of inter-temporal choice parameters across a neuronal population ( ). Similar gradients of discount factors have also been found in the human striatum ( ) and mPFC ( ). This suggests that some neuronal assemblies may represent a preference for fast discounting, favoring smaller-sooner returns, while others favor slow discounting. The discounting preference of each agent would be represented by population codes, implementing sets of weights over these discounting assemblies. The prediction errors a subject perceives when the novel other’s choices differ from what they would have chosen for themselves could in principle change the weights within this pool, resulting in altered populations codes. 

The fact that a common brain region is recruited when computing preferences for self and other might suggest that people initially draw on self-representations to make inferences about another person and only construct a novel representation through learning. Such a mechanism has been observed when constructing a representation for a novel good from a simultaneous activation of familiar components ( ). However, this theory makes opposite neural predictions, as it predicts repetition suppression at the beginning of the experiment as subjects draw on the same representation to choose for self and other. In this scenario a separate representation for a novel other is built over time and would predict disappearance of repetition suppression. Instead, we observe an increase in repetition suppression across time, an effect reminiscent of an increase in similarity between representations observed when subjects repeatedly evoke independent memories ( ). Importantly, we can demonstrate this plasticity is not solely a neuronal phenomenon but also has profound behavioral consequences. 

Our approach uses repetition suppression to provide insight into a similarity in neural representations. Comparable measures of representational content can be obtained by multivariate pattern analysis ( ); however, it is thought the two techniques show a difference in sensitivity to precise features of the neuronal code ( ). Without an explicit measure of MVPA in this study, we are therefore cautious in predicting a comparable increase in similarity between representations for self and a novel other in mPFC when using MVPA. 

Note that subjects grow increasingly familiar with the novel other’s preferences as the task progresses, whereas familiarity remains constant for the familiar other in the sense that there is no new learning in relation to this other. Since psychological constructs such as familiarity, but also similarity and physical proximity, have previously been demonstrated to upregulate mPFC activity ( ), this raises the question whether an increase in familiarity might drive the plasticity effect. Importantly, our data are not consistent with such an account. First, activity for familiar and novel other does not differ in mPFC, not even at the beginning of the experiment, suggesting that the mPFC in our task does not respond to familiarity per se. Second, a mediation analysis suggests that it is a striatal surprise signal, the very opposite of familiarity, that drives the plasticity effect, which in turn drives the behavioral shift. 

Subjects’ own discount rate shifted toward the discount rate of their partner irrespective of whether their partner was human or a computer. This is in line with studies demonstrating that individuals use strategies akin to those used in real social contexts when interacting with a computer agent ( ). Crucially, a control condition with the same stimuli and actions, but without the need to employ a discounting computation, did not evoke a change in subjects’ own preferences. This indicates that the behavioral effect is tied to subjects’ deployment of the very same discounting mechanism to learn on behalf of another agent, be it a human or non-human agent. Thus, it is a learning-induced plasticity in acquiring a novel value representation that impacted on subjects’ own subjective value computation. This also suggests that most subjects do not actively choose to change their preferences but instead do so as the consequence of an mPFC plasticity they are not consciously aware of. Such an implicit mechanism presumably contributes to involuntarily aligning goals with others and might play an important role in spreading values throughout a population ( ). 

In conclusion, our data detail a neuronal mechanism by which personal traits are susceptible to social influence. Such plasticity might be one of the key features underlying learning, because it allows for an integration of past experience with novel information. More broadly, our findings pave the way for further studies of human social interactions at a more mechanistic level. 


## Experimental Procedures 
  
### Subjects 
  
27 volunteers (mean age ± SD: 23.6 ± 3.7, 14 females) participated in the behavioral experiment, and 29 volunteers (mean age ± SD: 25.6 ± 5.6 years, 14 females) participated in the subsequent fMRI experiment. Two subjects were excluded from fMRI analyses, because they had previously participated in the behavioral experiment and because of technical difficulties during the scan. All subjects were neurologically and psychiatrically healthy. The study took place at the Wellcome Trust Centre for Neuroimaging in London, UK. The experimental procedure was approved by the University College London Hospitals Ethics Committee and written informed consent was obtained from all subjects. 


### Task Behavioral Study 
  
For a detailed description of the task and our analyses, see the  . In brief, subjects made a series of choices between a smaller amount paid on the same day and a larger amount paid later ( A). The experiment was divided into three blocks ( B). In the first block, consisting of 100 trials, subjects made decisions for themselves. In block 2, they made decisions on behalf of their partner. They were also provided with trial-by-trial feedback on whether their choice for the partner was correct. Block 2 ended when subjects made 85% correct responses for their partner in a sliding window of 20 trials or after a maximum of 60 trials. In block 3, smaller blocks of ten trials of choosing for self alternated with blocks of ten trials of choosing for the partner. Block 3 ended after a total of 200 trials. Choices were optimized to give us a precise estimate of subjects’ discount rates. 


### Estimation of Discount Rates 
  
We estimated subjects’ discount rates by fitting a hyperbolic model to their choices ( ) separately for each experimental block. Subjects’ shift in discount rates was defined as the change in discount rate from block 1 to block 3 (log k  − log k ) relative to the distance between their estimate of the partner’s discount rate from their own discount rate (log k  − log k ): 

A positive shift represents a movement toward, and a negative shift a movement away from, the partner’s discount rate. Outliers (outside the range mean ± 3⋅SD), as well as subjects who estimated their partner’s discount rate to be less than 0.3 units away from their own discount rate, were excluded from population analyses because of inflated shift estimates (see  E). 


### Simulation of the Other’s Choices 
  
To generate feedback for the confederate’s choices, we simulated a partner with a discount rate that differed from the subject’s own baseline discount rate by 1 (i.e., log k  = log k  ± 1). Choices were correct if they corresponded to the decision that would be preferred by a hyperbolic discounter with this discount rate. Importantly, the simulated partner’s choices were noisy, as the other’s subjective value was translated to a choice probability with a softmax function (temperature parameter β = 1). 


### Task fMRI Study 
  
The fMRI experiment consisted of two trial types: choice trials, as described for the behavioral experiment above, and probe trials, in which subjects evaluated a single option on a scale from 1 to 4 ( D). Subjects learned the preferences of a second partner (“familiar other”) before the scan ( E, top). 

In contrast to the behavioral experiment and the pretraining, subjects learned about the novel other’s discount rate while we assessed their own discount rate. To make sure that we captured a potential shift in discount rate in this scenario, we excluded the first third of all choice trials subjects performed in the scanner when estimating k , k , and k . The relative shift effects reported in  F were then calculated as follows: 

For the estimation of absolute shifts, the denominator z was set to sign(z). Outliers (outside the range mean ± 3 SD) as well as subjects for whom the denominator was smaller than 0.3 (two subjects for shift , three subjects for shift , and two subjects for shift ) were excluded from the analyses. 


### Surprise Measure 
  
We estimated subjects’ own discount rates on a trial-by-trial basis (see  ) and used this measure to compute differences in subjective value for the choices subjects observed their partner make (V  − V ). This difference in subjective value was transformed to a probability using a softmax function applied to a trial-to-trial estimation of subject’s inverse temperature parameter β. This measure gave us an estimate of how likely the subject would have been to make the same choice himself. We subtracted this likelihood from 1 to translate this to a surprise measure. 


### Scan Procedure, fMRI Data Acquisition, and Preprocessing 
  
We used standard procedures for acquiring fMRI data where these were designed to minimize susceptibility related artifacts in the ventral prefrontal cortex ( ). We used SPM8 for image preprocessing and data analysis (Wellcome Trust Centre for Neuroimaging, London). We corrected for signal bias, co-registered functional scans to the first volume in the sequence, and corrected for distortions using the fieldmap. Data were spatially normalized to a standard EPI template and smoothed using an 8 mm full-width at half maximum Gaussian kernel. 


### fMRI Data Analysis 
  
Data were analyzed with an event-related general linear model (GLM). Probe trials were sorted into nine different conditions (self preceded by self [SS], novel preceded by self [SN], familiar preceded by self [SF], self preceded by novel [NS], novel preceded by novel [NN], familiar preceded by novel [NF), self preceded by familiar [FS), novel preceded by familiar [FN], and familiar preceded by familiar [FF]) with 20 trials per condition and block. Each regressor was accompanied by a parametric modulator reflecting subjective value from the respective agent’s perspective. This value was calculated based on a trial-by-trial estimate of the subject’s current belief about their partners’ discount rate k. Furthermore, we defined one choice regressor per agent and block indexing the time at which subjects indicated their decision on choice trials and received feedback. Each was accompanied by a parametric regressor corresponding to the surprise subjects experienced as they observed the partner’s choice. Button presses were included as a regressor of no interest. Because of the sensitivity of the BOLD signal in the OFC region to subject motion and physiological noise, we included six motion regressors obtained during realignment as well as ten regressors for cardiac phase, six for respiratory phase, and one for respiratory volume extracted with an in-house-developed Matlab toolbox as nuisance regressors ( ). Blocks were modeled separately within the GLM. 

To detect areas showing adaptation to repeated agents as depicted in  A, we used the contrast   (i.e.,  ). To test for areas displaying greater increases in suppression between self and the novel other compared to between self and familiar other ( B), we defined the following contrast:  . To test for greater increases in suppression between self and novel other than between novel other and familiar other, we defined a contrast as follows:  . 

The contrast images of all subjects from the first level were analyzed as a second-level random effects analysis. Results are reported at a cluster-defining threshold of p < 0.01 uncorrected combined with a FWE-corrected significance level of p < 0.05. 

We performed a jack-knife procedure from the mPFC ROI ( B) to extract parameter estimates from this region without biasing the selection. To this end, we extracted parameter estimates for each subject from an ROI defined according to all other subjects (threshold at p < 0.01 uncorrected). This signal was used to perform all analyses depicted in   and  A. 

We performed partial correlations to control for correlations between shift  and shift  in our analysis of the relationship of a behavioral shift effect and neural plasticity. This removes the shift of the familiar other toward the novel other from the subjects’ own discount rate shifts and the neural plasticity index [SN − SF]  ( A) and the shift of self toward the novel other from the familiar other’s shift toward the novel other and the neural plasticity index ( B). We also estimated a linear regression model on the same data with shift  and shift  as independent variables and [SN − SF]  as the dependent variable. The relationship between shift  and [SN − SF]  was directly contrasted with the relationship between shift  and [SN − SF] . 

To test for the influence of surprise on mPFC plasticity, we defined a contrast assessing BOLD correlate of the surprise subjects experienced as they got feedback about the novel and the familiar partners’ choices. This contrast revealed activity in ACC, in bilateral insula and dorsal striatum ( A; note that insula and striatal activity did not survive cluster-based FEW thresholding). To identify the surprise experienced when learning about the novel other, parameter estimates were then extracted from these ROIs for the novel other’s choices only. This surprise measure in the striatum was correlated with subjects’ shift in discount rate ( B) and the plasticity measure [SN − SF]  extracted from the mPFC ROI ( C). 

We used the Mediation and Moderation Toolbox ( ) to perform a mediation analysis on this surprise signal, our plasticity measure, and the discount rate shift. 

To test the specificity of adaptation effects, we analyzed repetition suppression effects in visual regions. We defined an ROI from a contrast identifying a main effect to any visual event, averaged across all blocks, and performed the same analyses as for the mPFC ROI (thresholded at p < 0.0001 uncorrected;  ). 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-62'>
<h2>62. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22403154/' target='_blank'>22403154</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Neuroimaging self-esteem: a fMRI study of individual differences in women</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Soc Cogn Affect Neurosci</p>
<p><strong>Publication Year:</strong> 2012</p>
<p><strong>DOI:</strong> 10.1093/scan/nss032</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3682439/' target='_blank'>3682439</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study reports fMRI data collected while participants performed a social-referential task (Visual–Verbal Self-Other Referential Processing Task) directly probing Perception/Understanding of Self and Others, meeting the review’s domain. The sample comprises 20 healthy adult women (ages 18–52), within the 17–65 range, with results reported for the healthy group. Analyses include whole-brain random-effects SPM8 results (GLM contrasts reported across the whole brain) alongside ROI/SVC follow-ups; whole-brain findings are presented (voxel-wise thresholds and cluster reporting), not ROI-only. No exclusion criteria apply. Therefore the study meets all inclusion criteria for the meta-analysis.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Although neuroimaging studies strongly implicate the medial prefrontal cortex (ventral and dorsal), cingulate gyrus (anterior and posterior), precuneus and temporoparietal cortex in mediating self-referential processing (SRP), little is known about the neural bases mediating individual differences in valenced SRP, that is, processes intrinsic to self-esteem. This study investigated the neural correlates of experimentally engendered valenced SRP via the Visual–Verbal Self-Other Referential Processing Task in 20 women with fMRI. Participants viewed pictures of themselves or unknown other women during separate trials while covertly rehearsing ‘I am’ or ‘She is’, followed by reading valenced trait adjectives, thus variably associating the self/other with positivity/negativity. Response within dorsal and ventral medial prefrontal cortex, cingulate cortex and left temporoparietal cortex varied with individual differences in both pre-task rated self-descriptiveness of the words, as well as task-induced affective responses. Results are discussed as they relate to a social cognitive and affective neuroscience view of self-esteem. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (36040 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## INTRODUCTION 
  
Trait self-esteem, or the tendency to evaluate oneself positively rather than negatively, is a robust predictor of mental health and well-being ( ). Neuroimaging studies strongly implicate the medial prefrontal cortex (ventral and dorsal), cingulate gyrus (anterior and posterior), precuneus and temporoparietal cortex (reviews by  ;  ;  ) in mediating our ability to consciously reflect about ourselves, that is, self-referential processing (SRP;  ). However, little is known about the neural bases mediating individual differences in valenced SRP, that is, why most people tend to think about themselves positively, whereas others regard themselves negatively, cognitive and affective processes that are intrinsic to self-esteem. 

Previous studies investigating valenced SRP measured neural response while healthy participants explicitly judged the self-descriptiveness of trait adjectives (e.g. ‘liked’   vs   ‘disliked’, ‘success’   vs   ‘failure’) ( ;  ;  ) or self-relevance of valenced pictures ( ;  ), tasks not unlike completing a self-esteem questionnaire within the scanner. However, healthy individuals typically endorse positive stimuli (e.g. the words ‘liked’, ‘success’) as more self-descriptive than negative stimuli (e.g. ‘disliked’, ‘failure’) ( ), confounding valence with self-descriptiveness, and rendering these designs less sensitive to detecting neural processes mediating negatively valenced SRP. Limitations inherent to the use of direct survey-based measures of SRP also include susceptibility to self-presentational biases and the likelihood that not all valenced self-representations are fully accessible to conscious reflection (e.g.  ). To circumvent these concerns, priming methodologies are increasingly used in experimental social psychology as indirect measures of associations between valence and self-representation (reviews by  ;  ). However, no previous studies have utilized these methods in order to assess the neural processes mediating valenced SRP (for a study examining implicit SRP of stimuli that were not overtly valenced, however, see  ). 

The present study addressed the above limits of past literature by directly comparing the neural correlates of valenced SRP with valenced ‘other-referential processing’ (ORP) using a priming methodology. Specifically, to obviate the effect of the self-positivity bias, we previously designed a ‘Visual–Verbal Self-Other Referential Processing Task’ (VV-SORP-T; see  ) that directly engenders valenced SRP and ORP ( ). The VV-SORP-T requires participants to covertly rehearse the words ‘  I am  ’ or ‘  He/She is  ’ when presented with either their own or another person’s picture and then read positive or negative words, thereby experimentally engendering an association between the self/other and positivity/negativity on different trials (e.g. ‘I am’ … ‘disliked’). The encoded representation (e.g. ‘I am’ … ‘disliked’) may or may not match individuals’ internal self-representations (e.g. ‘I am’ … ‘liked’) as determined by individual differences in trait self-esteem. Participants monitor and report their affective response to the task, the outcome of which we further interpret as partly reflecting the match between the task-induced encoded representation and internal representations. Specifically, matching negative self-representations (e.g. ‘I am’ … ‘disliked’) are more likely to engender negative affect and matching positive self-representations (e.g. ‘I am’ … ‘liked’) are more likely to engender positive affect. The impact of the task on cognitive processing is also measured indirectly via response time (RT) providing a conjoint passive button-pressing requirement. We previously demonstrated in young adults that the VV-SORP-T is sensitive to individual differences in valenced SRP such that individuals with lower explicit self-esteem (as indexed by the Rosenberg Self-Esteem Scale;  ) are more likely to experience negative affect during negative SRP, less likely to experience positive affect during positive SRP, and evidence slower RT particularly during negative SRP ( ).
   
Illustration of one block of the VV-SORP-T. The individual shown in the photograph is the second author. Participants posed for their own photographs in neutral expression as for a passport application. Photographs of strangers (‘other’-condition) were taken from the NimStim set ( ) and matched to the participant as closely as possible for the following attributes: ethnicity, hair colour and hair length. Participants viewed the photographs and silently rehearsed ‘I am’ (for the self) or ‘She is’ (for the other), and then silently read the words, thus associating the self/other with positivity/negativity on different trials. 
  

In the present fMRI study we investigated the neural correlates of cognitive and affective processes relating to individual differences in self-esteem by examining variability in the BOLD response to the VV-SORP-T in 20 women. Consistent with previous research, we expected relatively few differences between valenced SRP and valenced ORP at the group level ( ). However, we hypothesized that individual differences in valenced adjective endorsement, and affective responses to the VV-SORP-T, would predict between-person variation in the BOLD response within regions of interest including within the medial prefrontal cortex, cingulate gyrus, temporoparietal cortex and amygdala. 


## METHODS 
  
### Participants 
  
Twenty women varying from young to middle adulthood (18–52 years, M age = 27.80, s.d. = 8.33) recruited by advertisement from the general community took part in this study. Participants’ ethnic status was distributed as follows: European–Caucasian (  n   = 12, 60%), East Indian (  n   = 3, 15%), Asian (  n   = 2, 10%), African (  n   = 2, 10%) and Middle Eastern (  n   = 1, 5%). As a group, participants reported normative levels of trait self-esteem [Rosenberg Self-Esteem Scale ( ): M = 22.61, s.d. = 6.01, Range 13–30] and self-critical thinking [Cognitive Distortion Scale–Self-Criticism subscale ( ); M = 14.22, s.d. = 6.25, Range 8  –  33]. Current or past psychiatric history, head injury with loss of consciousness and left-handedness were study exclusion criteria as assessed by structured clinical interviews. 

#### VV-SORP-T 
  
The VV-SORP-T involved three components: (i) completion of a paper-and-pencil survey asking about the descriptiveness of negative and positive traits for the self   vs   others (completed outside scanning), (ii) completion of an experimental task while undergoing fMRI and (iii) a post-task rating questionnaire asking about affective responses (completed outside scanning). The instructions given for the VV-SORP-T are reported verbatim in supplementary data to our prior report ( ). 

Approximately 2 weeks prior to scanning, within a battery of related questionnaires, participants rated for each of 10 positive and 10 negative words ‘how much each word describes (i) how you think about yourself, and describes (ii) how you think about other people, in general’ on 11-point (0–10) scales anchored by ‘Not at all’ (0), ‘Moderately’ (5) and ‘Completely’ (10). The adjective list was the same as that used in  , originally based on that used in  , and covered social (e.g. loved, rejected) and achievement-related (e.g. successful, incompetent) themes. We conceptualize such scores as indicative of trait self-esteem and consistent with that assumption adjective endorsement scores correlated   r   = 0.73 with Rosenberg Self-Esteem Scale scores in our prior study ( ). We did not purposely match the negative and positive word sets we used for frequency of general use as this would have violated natural usage within the English language ( ), nor did we seek to equate the word sets for salience as this would also be contrary to norms (e.g.  ). Nevertheless,   post hoc   comparisons revealed the word sets to be statistically comparable in terms of length in letters, frequency of use within the English language relative Hyperspace Analogue of Language (HAL) norms ( ), as well as normed mean reaction time in lexical decision and naming, all as investigated and compiled within the English Lexicon Project ( ; number of letters,   P   = 0.24; normed frequency of use,   P   = 0.42; log-frequency of use,   P   = 0.69; RT in lexical decision,   P   = 0.23; RT in naming,   P   = 0.27). Furthermore, no differences were observed in arousal ratings relative to the Affective Norms for English Words ( ) for the subset of the words we used that are contained therein (  n   = 12 of 20;   P   = 0.27). 

 illustrates how the experimental component of the VV-SORP-T was conducted. Participants’ photographs were taken in neutral expression (instructions were to pose ‘as if for a passport photograph’) using a standard-use electronic camera (4.1 megapixels) against an off-white office wall. Photographs were then standardized in order to match in essential respects those used in the development of the NimStim set of facial expressions ( ). The latter were used as pictures for a comparison ‘other’ (i.e. a female was selected from the NimStim set for each study participant, matched as closely as possible for ethnicity, hair colour and hair length). Before beginning the VV-SORP-T participants were habituated to the photographs for 6–10 s (as desired) in order to reduce their novelty, with the ‘other’ instructed to be regarded as ‘a typical person they might meet in their day-to-day life but presently do not know personally’. This manipulation was intended to limit error associated with responding to specific persons as has been used in previous fMRI studies (e.g. individual differences in how one regards former American President George Bush;  ). 

Instructions underscored that completing the VV-SORP-T would require participants ‘to do three things: 1) internally rehearse statements and read words, 2) press response buttons on a keypad, and 3) all the while pay close attention to how you are feeling throughout the different parts of the task’. Participants were instructed to view a fixation cross (presented for 12 s in between task-blocks) until they were presented with the word ‘SELF’ or ‘OTHER’ (for 3 s) signalling which of the respective pictures they were about to see. Upon seeing their own or the other person’s photograph (also presented for 3 s), they silently rehearsed to themselves ‘I am’ or ‘She is’, respectively, and then pressed a keypad button with either their index or middle finger (counter-balanced). Participants were then presented with a single positive or negative word for 3 s, asked to silently read the word and then pressed another keypad button with their other finger. Four additional pictures and words were then presented following the same ‘picture-then-word’ rotation, with the identical picture displayed in all cases, and the words being of common valence. Therefore the stimulus presentations were blocked in terms of the conditions Reference (Self   vs   Other, i.e. photographs) and Valence (words), creating four trial types: self-negative (S-N), self-positive (S-P), other-negative (O-N) and other-positive (O-P). Participants were not instructed that they ‘should try to press the buttons as fast as possible’ as is often done in social cognition experiments. In contrast, participants were instructed only to press the buttons ‘so that we can assess afterwards whether you are paying attention to and completing the task’. This passive orientation was intended to focus attention towards introspection and interoception with participants reminded repeatedly of the importance of ‘paying close attention to how you are feeling throughout the different parts of the task’. 

While undergoing FMRI, participants were presented with eight-blocks in each of three 6-min runs in which the self and other photographs were presented in combination with two negative and two positive word lists. The order of the eight blocks within runs was fully randomized within and across participants. A full 6-min practice run was also completed outside of the scanner in an office setting ∼30 min before scanning in order to normalize participants to the task. 

Immediately after completing the experimental task component and exiting the scanner, participants were asked open-ended and percentage rating-scale questions about their response to the four experimental conditions (S-N, S-P, O-N, O-P). The percentage rating-scale asked participants to rate from 0 (‘Not at all’) to 100% (‘Strongly’), with 50% indicating ‘Moderately’, ‘ … how much you felt certain specific feelings in response to each picture and word type combination’. Ratings were provided for the following five negative affective states: ‘Anger’, ‘Sad’, ‘Anxiety-Fear’, ‘Disgust’, ‘Bad About Self’, and for two positive affective states: ‘Happy’ and ‘Good about Self’. As previously noted we conceptualize affective responses to the task as providing an additional measure of relevance to individual differences in self-esteem-related processes. Specifically, our prior study observed that individuals with lower trait self-esteem reported experiencing greater negative affect during S-N trials, and lesser positive affect during S-P trials ( ). Results for quantitative ratings collected from the present sample are presented herein and open-ended comments are included as   Supplementary Table S1  . 



### Procedure 
  
All procedures were approved by the health sciences research ethics board of Western University in London, Ontario, Canada. As noted previously, participants were assessed for study inclusion criteria and completed a short questionnaire battery including the adjective rating component of the VV-SORP-T ∼2 weeks prior to scanning. Participants completed a single-block practice version of the experimental component of the VV-SORP-T in an office setting ∼30 min prior to fMRI scanning, and three blocks of the experimental component of the VV-SORP-T while undergoing fMRI. Participants then rated their affective response to the VV-SORP-T immediately post-scan. The entire experiment took ∼75 min to complete. 

Imaging took place at the Robarts Research Institute in London, Ontario, Canada. All imaging data were collected using a 3.0 Tesla whole-body MRI scanner (Magnetom Tim Trio, Siemens Medical Solutions, Erlangen, Germany) with the manufacturer’s 32-channel phased array head coil. Orthogonal scout images were collected and used to prescribe a tri-dimensional T1-weighted anatomical image of the whole head with 1 mm isotropic resolution (MP-RAGE, TR/TE/TI = 2300/2.98/900 ms, flip angle = 9°, FOV (  x  ,   y  ,   z  ) = 256 × 240 × 192 mm, acc. factor = 4, total acq. time = 3 min 12 s). The anatomical volume was used to determine the angle of the transverse plane passing through both the anterior and posterior commeasures mid-sagittaly and as the source image for inter-individual spatial normalization. A set of 64 contiguous, 2 mm thick imaging planes for BOLD fMRI were prescribed parallel to the AC  –  PC plane and positioned to ensure coverage of the top of the brain. BOLD fMRI images were acquired with the manufacturer’s standard gradient echo EPI pulse sequence (single-shot blipped EPI) using an interleaved slice acquisition order and tri-dimensional prospective acquisition correction (3D-PACE). EPI volumes were acquired with 2 mm isotropic resolution and the following parameters: FOV = 192 × 192 mm, 94 × 94 matrix, TR/TE = 3000/20 ms, flip angle = 90°, 64 slices, 178 measurements. Before completing the VV-SORP-T while undergoing fMRI a ‘resting-state’ functional scan of each participant’s brain was also acquired, to be described elsewhere. 


### Data preparation and statistical analysis 
  
Across blocks and runs for each of the four experimental conditions (S-N, S-P, O-N, O-P), VV-SORP-T survey scores were summed, and button-press RT and affect ratings were averaged. The effect of experimental condition on each of these variables was examined by ANOVA with results reported in  .
   
Descriptive statistics and paired comparisons between conditions of the VV-SORP-T 
    

Analyses of the BOLD signal were conducted via SPM8 (Welcome Department of Imaging Neuroscience, University College, London, UK). Standard preprocessing was conducted within SPM8, with volumes realigned to the first functional image acquired (unidirectional movements were <4 mm from origin in all cases), normalized to a common EPI template [rendering 2 mm  voxels in accordance with the coordinate system of the Montreal Neurological Institute (MNI)], and data smoothed across 8 mm (FWHM). A canonical haemodynamic response function was modelled as a response to each stimulus in individual participants (first-level), with group-averaged results evaluated as random effects (second-level). The BOLD response observed during each of the four task trials relative to between-block fixation was examined via the general linear model. Planned contrasts also compared response occurring during S-N relative to S-P trials, S-N relative to O-N trials, and S-P relative to O-P trials, thus examining the effects of Valence within Reference, and Reference within Valence. Group-averaged results for these contrasts are reported in   and  . We also report the results of main effect contrasts for Reference and Valence in   Supplementary Table S2   and   Supplementary Figures F1 and F2  .
   
BOLD response during the four conditions of the VV-SORP-T   vs   baseline fixation. Response during S-N trials is shown in red, during S-P trials in green, during O-N trials in magenta, during O-P trials in yellow. Voxel-wise   P   < 0.005 with a cluster threshold   k   ≥ 67 voxels. 
    
Group-level differences between VV-SORP-T trial types 
    

Of primary interest to this study, however, was a multiple regression analysis associating individual differences in survey and affective response scores with between-participant variability in the BOLD contrast between S-N trials and both fixation and O-N trials, and S-P trials and both fixation and O-P trials. Note that we preferred to evaluate BOLD correlations with adjective endorsement rather than Rosenberg Self-Esteem scores in this study, which allowed direct examination of associations between response to a common stimulus set (words) evaluated in differing contexts (i.e. paper-and-pencil survey rating of self and other descriptiveness   vs   performance of the experimental component of the VV-SORP-T). Results concerning individual differences are reported in   and  , and   and  .
   
BOLD response during S-N trials   vs   baseline fixation (BL) and O-N trials. Within the legend, positive correlations are denoted with a plus symbol; there were no significant negative correlations. Positive correlation between survey endorsement of negative traits and response during S-N trials (>BL) is shown in red. Positive correlation between survey endorsement of negative traits and response during S-N trials (>O-N trials) is shown in magenta. Positive correlation between experienced negative affect and response during S-N trials (>O-N trials) is shown in blue. Voxel-wise   P   < 0.005 with a cluster threshold   k   ≥ 67 voxels. 
    
BOLD response during S-P trials   vs   baseline fixation (BL) and O-P trials. Within the legend, positive correlations are denoted with a plus symbol, and negative correlations are denoted with a minus symbol. Regarding survey endorsement of positive traits and response during S-P trials (>BL), positive correlations are shown in green and negative correlations are shown in red. Positive correlation between experienced positive affect and response during S-P trials (>BL) is shown in yellow. Negative correlation between survey endorsement of positive traits and response during S-P trials (>O-P trials) is shown in magenta. Positive correlation between experienced positive affect and response during S-P trials (>O-P trials) is shown in cyan. Voxel-wise   P   < 0.005 with a cluster threshold   k   ≥ 67 voxels. 
    
Individual differences in response to S-N trials of VV-SORP-T 
      
Individual differences in response to S-P trials of the VV-SORP-T 
    

We report within Tables clusters of size   k   ≥ 67 voxels (approximating the volume of the smoothing kernel) with uncorrected voxel-wise   P   < 0.005 as a criterion selected so as to balance risk against type-I and type-II errors ( ). To examine the location of BOLD responses we observed in relation to previous studies, we also report the number of voxels that fell within an 8-mm radius (equally the smoothing kernel) of coordinates reported in recent meta-analyses of SRP ( ;  ;  ) and key study results ( ;  ;  ,  ;  ); an ROI for the left and right temporoparietal junction (TPJ) was also prescribed from   meta-analysis of neuroimaging studies of social cognition (as calculated in  ). Voxels in ROI analyses include those exhibiting   P   < 0.05 after correction for multiple comparisons (family-wise error rate) within the indicated centred spherical search volume, denoted   k   for Small-Volume Corrected. Cluster loci are labelled by the voxel exhibiting maximal effect size within MNI space. 



## RESULTS 
  
### Self-report, experiential and behavioural response 
  
 reports the descriptive and inferential statistics describing self-report and behavioural response to the VV-SORP-T. Replicating previous results ( ), survey endorsements were higher for S-P as compared with O-P (  d  ′ = 1.04), consistent with the self-positivity bias. Positive affect was also higher during S-P than O-P trials (  d  ′ = 1.21), although negative affect was not significantly higher during S-N than O-N trials (  d  ′ = 0.02). Finally, RT was marginally slower during S-N than O-N trials (  d  ′ = 0.35), and during S-P than O-P trials (  d  ′ = 0.15). 

Further replicating previous results ( ), participants who described themselves more positively (S-P survey endorsement) experienced less negative affect during S-N trials (  r   = −0.77,   P   < 0.001), less negative affect during S-P trials (  r   = −0.57,   P   = 0.006) and greater positive affect during S-P trials (  r   = 0.52,   P   = 0.011). In comparison, associations between S-N survey endorsement and affective responses were non-significant. 


### fMRI-BOLD response 
  
#### Group-level differences between trial types 
  
 and   report significant responses observed as specific to each of the four distinct trial types at the group level in comparison with between-block fixation (in  , S-N = red, S-P = green, O-N = magenta, O-P = yellow). S-N trials activated three clusters: the posterior mid-cingulate (at ROI 0, −13, 31,  ;   k   = 66), right superior parietal cortex and dorsal ACC-MPFC (at ROI −3, 19, 38,  ;   k   = 32). S-P trials activated two clusters: ventral MPFC and left middle frontal cortex. O-P trials activated two clusters: right DLPFC and right temporal pole. Finally, response during O-N trials was more distributed, with the maximal effect size observed within the right posterior insula, and additional activations observed within the left posterior insula, right middle frontal gyrus (at ROI 50, 24, 10,  ;   k   = 28), left middle frontal gyrus (at ROI −56, 15, 10,  ;   k   = 132), left precentral gyrus, left posterior mid-cingulate and left cuneus. 

Planned contrasts examining the effects of Valence within SRP and Reference within Valence are also reported in  . S-N trials were associated with greater response than S-P trials within two regions: the posterior mid-cingulate and right superior parietal cortex. In contrast, S-P trials were not associated with greater response in comparison with S-N trials in any brain region, and contrasts of Reference within Valence were non-significant. 


#### Individual differences in response to S-N trials 
  
 and   report correlations between self-report and affective responses, on the one hand, and response during S-N trials, relative to both between-block fixation and O-N trials, on the other. Concerning the contrast S-N > fixation, a positive correlation was observed between how negatively participants regarded themselves and response within the ventral MPFC-ACC (including within ROI 0, 22, −9,  ;   k   = 26). In addition, women who rated themselves more negatively demonstrated increased response within left VMPFC (including within ROI −6, 42, −12,  ;   k   = 7). In comparison, there were no significant correlations with variability in negative affective response. 

Concerning the contrast S-N > O-N, participants who regarded themselves more negatively demonstrated less response within the supplementary motor area (including within ROI −3, 14, 49,  ;   k   = 61) and retrosplenial cortex. In comparison, participants who experienced greater negative affect exhibited greater response within the parahippocampal gyrus and right amygdala. 


#### Individual differences in response to S-P trials 
  
 and   report correlations across the whole-brain between self-report and affective responses, on the one hand, and BOLD response during S-P trials, relative to both between-block fixation and O-P trials, on the other. Concerning the contrast S-P > fixation, a negative correlation was observed between how positively participants regarded themselves and response within the right parahippocampal gyrus/amygdala and right temporal pole. A positive correlation was observed between positive affect experienced during S-P trials and response within the DMPFC (within ROI 2, 55, 17,  ;   k   = 87), left TPJ (within ROI −52, −56, 22,  ;   k   = 48) and right temporal pole. 

Concerning the contrast S-P > O-P, a negative correlation was observed between how positively participants regarded themselves and response within VMPFC (at ROI −3, 36, −18,  ;   k   = 48), right DMPFC (at ROI 6, 27, 42,  ;   k   = 18), left TPJ (two clusters within ROI −52, −56, 22,  ;   k   = 22 and 36), right temporal pole and bilateral inferior frontal gyri. In comparison, the more positive affect participants experienced during S-P trials, the greater was their response within many of the same regions, specifically VMPFC (at ROI −3, 36, −18,  ;   k   = 20), DMPFC (at ROI 6, 27, 42,  ;   k   = 35), left TPJ (within ROI −52, −56, 22,  ;   k   = 31), left inferior frontal gyrus, as well as within the precuneus. 




## DISCUSSION 
  
How people represent themselves in comparison with others, and the role played by affective processing in such representations, are matters of significant interest to a social cognitive and affective neuroscience of core personality constructs including trait self-esteem. We investigated the neural correlates of self-esteem-related processes in response to the VV-SORP-T using an individual differences design. 

Although recent meta-analyses confirm greater response within MPFC, perigenual ACC and PCC during SRP than during ORP ( ;  ;  ), individual studies using relatively neutral adjectives rarely observe this effect (e.g.  ; cf  ;  ).  , using valenced adjectives, similarly observed few differences between SRP and ORP. Within the present study, the spatial maps obtained relative to fixation differed between valenced SRP and ORP ( ), while null effects were observed when conditions were directly compared, as conducted by  . We speculate that the neural correlates of SRP and ORP will differ principally in so far as SRP is regarded as more affectively salient (e.g.  ). In other words, we expect that trait endorsement must not only differentiate the self from others, but this result must sufficiently matter to participants to evoke corresponding differences in the BOLD signal. The use of valenced adjectives as in   study and the present one cannot assure this because, as was clearly the case in the present study, most participants will endorse robustly positive views of both themselves and others, leading trials requiring negative SRP and ORP to be regarded as relatively neutral and irrelevant ( ). 

In contrast to the modal self-positivity bias, however, a certain number of participants with lower self-esteem will endorse relatively negative views of themselves and a corresponding range of affective responses when such representations are primed such as via the VV-SORP-T. Consistent with expectations, in the present study these individual differences dovetailed considerably with between-subject variability in the BOLD response within ROIs including MPFC, PCC, left temporoparietal cortex and right amygdala. These potentials for heterogeneity across subjects in experiential response to a common stimulus pattern make them well suited to the study of the neural correlates of personality and individual differences ( ;  ). Further knowledge about the neural underpinnings of negative SRP may also enlighten our understanding of psychiatric disorders associated with maladaptive SRP including depression ( ;  ;  ) and post-traumatic stress disorder ( ). 

The present findings are consistent with and further inform current theorizing about the neural correlates of the ‘emotional self’ ( ). In particular, it has been posited that ventral MPFC (inclusive of ventral ACC;  ;  ) may be particularly associated with SRP that is affectively (and perhaps uniquely negatively) salient, whereas dorsal MPFC may be particularly involved in conscious, reflective processes that are either neutral or positive in nature ( ;  ). Consistent with previous observations, relative to fixation, we observed ventral MPFC/ACC response during negative SRP particularly in women who regarded themselves more negatively (see  ,   x   = 0,   z   = −10, red blobs), but dorsal MPFC response particularly in women who experienced greater positive affect during positive SRP (see  ,   x   = 0,   z   = +10 and +20, yellow blobs). However, when contrasting response occurring during positive SRP with positive ORP, ventral MPFC regions were particularly involved such that, interestingly, response was increased as a function of increasing positive affect but decreasing self-regard (see  ,   x   = 0,   z   = −20, cyan and magenta blobs, respectively). This dissociation suggests the merit of   distinction between the significance of referential   vs   affective ratings and may inform interpretations regarding the ‘validity’ of direct (e.g. self-report survey)   vs   indirect (e.g. task-induced affective response) assessments of self-esteem-related processes ( ;  ). Our findings that decreasing self-regard predicted positive SRP response (  magenta) agree with the hypothesis of VMPFC involvement in negative SRP. However, the dissociation with positive affective experience within a brain region strongly associated with reward requires interpretation. One interpretation is that VMPFC response is particularly increased in mediating positive affect in individuals for which positive affect is otherwise not easily activated, such as in individuals disposed towards alexithymia ( ) and anhedonia ( ;  ). However, that the same dissociation was observed concerning response within the left TPJ, which is widely implicated in social cognition and mentalizing (e.g.  ), suggests individual differences during ORP likely complicate interpretation. Consistent with this, self-reports obtained from the present participants as well as those collected from participants in a previous study suggest that response during ORP within the VV-SORP-T represents anything but simply a neutral comparator condition ( ). Investigation of individual differences in affective response during ORP as a predictor of the BOLD response could clarify this concern, but were considered beyond the scope of the present project given its focus on valenced SRP as it relates to self-esteem. It should also be noted that Lemogne and colleagues observed increasing response during SRP within dorsal MPFC in both depressed individuals ( ) and individuals high in trait negative affect ( ), which challenges a model emphasizing only the ventral MPFC in the affective aspects of SRP. 

Besides response within higher cortical areas, Yoshimura and colleagues recently revealed a dissociation between left   vs   right amygdala response and negative   vs   positive SRP, respectively ( ). The right amygdala has also been associated with   social   emotional processing ( ;  ;  ) as is inherent to the VV-SORP-T (see  , for descriptions of socio-emotional responses during ORP including guilt, shame and envy). In our study, however, not only those women who experienced greater negative affect during negative SRP, but also those women who regarded themselves less positively before positive SRP, exhibited an increased right amygdala response. If right amygdala response is to be interpreted as signifying a negative self-appraisal within the context of SRP ( ), our individual difference effects extend the significance of right amygdala response to positively valenced SRP. However, our results may qualify the finding in suggesting that the amygdala response may signify the outcome of the appraisal, that is, the experienced negativity of a stimulus or task, rather than the negativity inherent to the stimulus or task,   per se  . In other words, even objectively positive stimuli may be responded to   as if   they are negative (e.g.  ,  ;  ,  ), with the right amygdala response during SRP perhaps revealing the valence or salience of the result of that appraisal. 

The loci of activations observed within the present study overlapped most closely with those observed by  ,   and  , the only other studies, to our knowledge, directly addressing between-subject variability in SRP using a correlational design. MPFC response within the present study was more inferior to loci summarized by recent meta-analyses (wherein   z  -values are typically > 5;  ;  ;  ), but consistent with that observed with the methodology of Phan   et al.   ( ; also used by  ). Provided current models emphasize VMPFC in the affective aspects of SRP ( ;  ), this confluence of findings for the VV-SORP-T and Phan   et al.   methodology are interesting provided that both methods likely encourage affective processing more greatly than do most other standard judgments tasks (the Phan   et al.   method through the use of arousing pictures and the VV-SORP-T by engendering an association between self and valence and encouraging attention to that association). Overlapping responses observed herein with those observed by Moran   et al.   occurred in regions that differentiated reaction time in Moran   et al.  ’s study, implicating these regions in online SRP. Future neuroimaging studies might compare different SRP tasks to provide a more nuanced assessment of the specific subprocesses involved in SRP. 

Limitations of the present study should be addressed in future work. We recruited only female participants for the present study due to widely known gender differences in trait self-esteem and associated risk for depression ( ); future studies may wish to directly investigate the neural basis for these gender differences. Clarity of interpretation could have been enhanced had we also administered neutral words and assessed affective response to the task not only subjectively but also via peripheral physiological measures of arousal. It should further be noted that contrasts of both SRP and ORP with passive fixation may be underpowered due to similarity between the neural processes involved in SRP, ORP and the passive resting state ( ); inclusion of active control tasks other than passive fixation would be useful in future studies, which might utilize a rest-stimulus interaction paradigm to examine valenced SRP and ORP ( ). Finally, the external ‘real-world’ validity of the VV-SORP-T for predicting socio-emotional behaviour remains to be established. 


## SUPPLEMENTARY DATA 
  
 Supplementary data   are available at   SCAN   online. 


## Conflict of Interest 
  
None declared. 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-63'>
<h2>63. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31884223/' target='_blank'>31884223</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Atypical processing of social anticipation and feedback in borderline personality disorder</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Neuroimage Clin</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1016/j.nicl.2019.102126</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6938803/' target='_blank'>6938803</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study used functional MRI while participants completed a social-related task (social vs non-social incentive delay with facial cues and feedback). It includes a healthy control group (N=24; ages 19–36) with results reported separately. Analyses include voxel-wise whole-brain second-level models (event-related, full-brain contrasts reported for Models 1 and 3) in addition to ROI analyses; thus it is not ROI-only. The task and contrasts target social processing (anticipation and evaluative social feedback), matching the review constructs. Therefore all inclusion criteria are met (social fMRI task, healthy adult participants within age range, and whole-brain analyses reported).</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>   Highlights  
  
Borderline personality disorder (BPD) is characterized by interpersonal dysfunction. 
  
In BPD, the superior temporal sulcus is hyperactivated during social anticipation. 
  
In BPD, amygdala response to evaluative social feedback is also reduced. 
  
Amygdala suppression is induced by anterior cingulate rise during social anticipation. 
  
Atypical frontolimbic interactions may contribute to interpersonal dysfunction in BPD. 
  
  
## Background- 
  
Borderline personality disorder (BPD) is characterized by maladaptive social functioning, and widespread negativity biases. The neural underpinnings of these impairments remain elusive. We thus tested whether BPD patients show atypical neural activity when processing social (compared to non-social) anticipation, feedback, and particularly, how they relate to each other. 


## Methods- 
  
We acquired functional MRI data from 21 BPD women and 24 matched healthy controls (HCs) while they performed a task in which cues and feedbacks were either social (neutral faces for cues; happy or angry faces for positive and negative feedbacks, respectively) or non-social (dollar sign; winning or losing money for positive and negative feedbacks, respectively). This task allowed for the analysis of social anticipatory cues, performance-based feedback, and their interaction. 


## Results- 
  
Compared to HCs, BPD patients expressed increased activation in the superior temporal sulcus during the processing of social cues, consistent with elevated salience associated with an upcoming social event. BPD patients also showed reduced activation in the amygdala while processing evaluative social feedback. Importantly, perigenual anterior cingulate cortex (pgACC) activity during the presentation of the social cue correlated with reduced amygdala activity during the presentation of the negative social feedback in the BPD patients. 


## Conclusions- 
  
These neuroimaging results clarify how BPD patients express altered responses to different types of social stimuli (i.e. social anticipatory cues and evaluative feedback) and uncover an atypical relationship between frontolimbic regions (pgACC-amygdala) over the time span of a social interaction. These findings may help to explain why BPD patients suffer from pervasive difficulties adapting their behavior in the context of interpersonal relationships and should be considered while designing better-targeted interventions. 

 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (39261 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## INTRODUCTION 
  
Borderline personality disorder (BPD) is a serious illness affecting up to 6% of the general population ( ;  ). BPD is characterized by interpersonal dysfunction, including a severe fear of abandonment, marked impulsivity, negative self-evaluations, and emotional dysregulation ( ). 

According to prominent theories of BPD, particularly Linehan's biosocial theory ( ;  ;  ), disrupted attachment profiles, alongside heightened trait emotional sensitivity, and a propensity to experience high levels of negative affect are all relevant to the development of BPD psychopathology. Together, these components result in an inability to learn appropriate emotional regulation strategies resulting in the development and use of dysregulated behaviors to manage and reduce negative affect, particularly during social interactions. Compared to healthy controls (HCs), BPD patients have been shown to be especially sensitive to social rejection (e.g. ( )), express an attentional bias toward negative emotional information (BPD adults: ( ;  ); adolescents with BPD/high levels of BPD features: ( ;  )), integrate undesirable social feedback (based on their character traits) to a greater degree ( ;  ;  ), and experience more intense negative (and reduced positive) affective responses as a result of social feedback ( ;  ). Additionally, these patients generally perceive the faces of others to be untrustworthy, which is consistent with heightened threat anticipation from social contexts ( ;  ;  ), even anticipating potential threat   before   a confrontive social interaction ( ). It is thus by no means surprising that these patients experience difficulties in varied social contexts and yet the interpersonal/social dysfunction component of BPD tends to be the most difficult and unsatisfactorily treated ( ). Unfortunately, relatively few studies have investigated social interactions in BPD, especially from a neuroimaging perspective. Moreover, accounting for how the processing of a social interaction unfolds, from anticipation to the actual experience of a social event, would likely help to develop more targeted therapeutic approaches and thus provide increased quality of life (e.g. improving social integration; ( ;  )). 

Thus far, the majority of fMRI studies on negative emotionality in BPD have focused on the (mostly passive) processing of (unpleasant) emotional stimuli, including mainly faces, but also scenes (e.g. ( ;  ;  ); for meta-analyses see: ( ;  ;  )). These studies have highlighted atypical activations and functional interplay between brain areas subserving top-down emotional processes, including the medial prefrontal cortex (mPFC) and anterior cingulate cortex (ACC) ( ;  ;  ), and limbic areas, especially the amygdala ( ;  ;  ). Specifically, compared to HCs, the processing of negative emotional stimuli generally resulted in hyper-reactivity of the amygdala/limbic system, which is thought to be associated with subjectively more intense experiences of negative emotions in these patients ( ;  ;  ;  ). Furthermore, frontolimbic networks were found to be differentially recruited even during the anticipation of negative emotional stimuli (i.e. during the presentation of a cue predictive of an upcoming negative event; ( ;  )), which may catalyze faulty emotional adjustment in these patients ( ;  ). While reactions to social/emotional stimuli are controlled by these abovementioned top-down processes ( ), it is not yet clear whether and how differential anticipation influences the processing of subsequent social stimuli (particularly for performance-based socially evaluative feedback, see below). 

Generally, throughout the day we are confronted with a variety of emotional/social information, whose underlying meaning must be interpreted as a function of the ongoing context. When a negative (e.g., angry) face is seen following one's erroneous behavior, the face takes on a double meaning: it expresses a negative emotion, and it also conveys a negative social evaluation. Additionally, if that social evaluation is preceded by an anticipatory signal (e.g. someone warning you about an imminent judgment), we are able to emotionally “prepare” ourselves to receive that signal. Given that BPD patients are likely always expecting negative feedback, especially in the context of a social interaction, they might not only express altered recruitment of limbic brain regions in response to social feedback, but the degree of this difference might also be modulated by the anticipatory activity of top-down mechanisms from frontal regions (e.g. mPFC, dACC, and pgACC; ( )). 

The aim of the present study was to determine the processing of social (compared to non-social) cues and feedbacks in patients with BPD compared to HCs. We utilized fMRI and a modified incentive delay task ( ;  ) in which anticipatory cues and subsequent performance-based feedbacks (i.e. winning and losing outcomes) were either social (neutral faces for cues; happy or angry faces for positive and negative feedbacks, respectively) or non-social (dollar sign; winning or losing money for positive and negative feedbacks, respectively). Because of the way this task was designed, participants rapidly (and efficiently) learned that a cue (i.e. neutral face in the social condition, or dollar sign in the non-social condition) would be followed by feedback directly corresponding to their performance (i.e. performance-based feedback). For example, in the social condition, the neutral face was followed either by a smiling, happy face whenever participants responded “properly” (i.e. fast enough), or by an angry face whenever they were too slow. This design allowed us to test our three main hypotheses. The first hypothesis (H1) was that BPD patients, compared to HCs, would exhibit differential neural activation mainly of frontal regions (e.g. mPFC, and ACC; similar to ( ;  )) in response to social compared to non-social anticipatory cues (i.e. neutral faces compared to monetary cues). The second hypothesis (H2) was that BPD patients would express differential limbic reactivity to evaluative social feedback (e.g. angry faces), particularly in the amygdala (e.g. ( ;  )). Finally, because BPD patients have been shown to express atypical processing across frontolimbic networks (see above), our third, and main, hypothesis (H3) was that how the processing of an anticipatory cue (by frontal regions) relates to the subsequent social feedback (amygdala) may be a key feature of BPD. Specifically, given the pervasive negative bias of these patients, this relationship should be critically involved during negative social evaluations (e.g. hypo-regulatory anticipatory frontal activity should lead to a hyper-reactive limbic response to negative social feedback). 


## Methods and materials 
  
### Participants 
  
Twenty-one female BPD patients, age 21–38 (  M   = =27.43, SD=5.22), who met the DSM-5 criteria for BPD and 24 female HCs participants, age 19–36 (  M   = =24.71, SD=5.50), without any lifetime psychiatric diagnoses were included. We recruited BPD outpatients from a specialized ambulatory service in Geneva (Switzerland), and the HCs were contacted by advertisements. 

All participants were first screened for inclusion criteria and then assessed by a trained psychologist and a psychiatrist (see Supplementary Material). BPD diagnosis was established through medical records and standardized measures (Diagnostic Interview for Genetic Studies [DIGS]; ( )) and the SCID-II (Screening Interview for Axis II; ( )) BPD part (see  ). Similar to our previously published article ( ), we created an index of “medication load” for each patient in order to test for the effects of medication on significantly activated brain regions (see Supplementary Material). We also assessed BPD symptom severity using the Borderline-Symptom-List (i.e. the BSL-23; ( ;  )) rated within one week before the scanning session. Level of depression was assessed by the Montgomery and Asberg Depression Rating Scale (MADRS; ( )) and the 13 item Beck Depression Inventory II (BDI-II; ( )). History of childhood maltreatment was assessed by Childhood Trauma Questionnaire (CTQ) French version ( ) (All questionnaires are reported in  ). For more details about clinical assessment, please see the Supplementary Material.   
Comorbidity and medication list for the BPD group (  N   = =21). 
  Table 1       
Questionnaire results. 
  Table 2       

The study was approved by the Ethics committee of the Geneva University Hospitals. Each participant provided written informed consent. 


### Experimental design and tasks 
  
The task was designed to be a modified version of the monetary and social incentive delay task (see ( ;  )) with two different conditions, social and non-social, and two distinct time points of interest in each trial, cues and feedbacks. Each trial began with a cue indicating the type of trial (social or non-social) followed by a fixation cross ( ). Participants were then asked to rapidly press a button as soon as a target appeared on the screen. If they pressed the button while the target was still on the screen, they were presented with a winning feedback and if not, they were presented with a losing feedback. The delay between cue onset and feedback onset was jittered between 3350 ms and 5100 ms. Target presentation time depended on the outcome of the participant's previous trial of the same condition. The presentation time of the target for the first trial was 400 ms and if the participant responded during the allotted time, 25 ms was subtracted from the next presentation time of the same condition, if the participants responded after the allotted time, 25 ms was added. This allowed for an online adaptation of the target's presentation time for each participant, to reach an overall performance of approximately 60% winning. Any trial where a participant pressed the button before the onset of the target was considered a miss, and no adaptation of presentation time was performed.   
Schematic depiction of the social reward task (A) and example stimuli (B). 
  Fig.. 1   

The task was modeled with 20 mini-blocks of 4 consecutive trials of the same condition (e.g. 4 consecutive social trials followed by 4 non-social trials) resulting in 40 of each social and non-social conditions. Mini-blocks were employed in order to reduce attentional load required for the participants, as well as to avoid any “spillover” effects from one condition to the next (e.g. in BPD patients, ( )). These mini-blocks were counter-balanced and delivered in a pseudorandom order (with never more than 2 mini-blocks of the same type in a row). For the social condition, we used 40 individual faces (20 female) with neutral (for the cues), happy and angry expressions (for the feedbacks) from the Karolinska Directed Emotional Faces database ( ). To familiarize the participants with the task and to remove any effects of learning, a practice session was performed before the fMRI session, outside the scanner, using faces which were not included in the fMRI experiment. To ensure that all participants understood the task fully, we questioned them about the meaning of the feedback following each trial. 


### MRI data acquisition and analysis 
  
Functional images were acquired using a multiplexed EPI sequence ( ) with repetition time (TR)=650 ms, echo time (TE)=30 ms, flip angle=50°, 36 slices, 64 × 64 pixels, voxel size=3 × 3 × 3 mm. The multiband acceleration factor was 4, and parallel acquisition technique (PAT) was not used. Structural images were acquired with a T1 weighted 3D sequence (MPRAGE, TR/inversion time/TE=1900/900/2.27 ms, flip angle=9°, PAT factor=2, matrix size=256 × 256 × 192, voxel size=1 × 1 × 1 mm). 

All fMRI data analyses, including image preprocessing and analyses, were performed using SPM8 software (  http://www.fil.ion.ucl.ac.uk/spm  ) implemented in Matlab R2012b. During preprocessing, the functional volumes were first realigned to the mean image, normalized using the EPI template provided with the SPM toolbox, and finally smoothed with an 8 mm  Gaussian kernel. To account for any residual movement artefacts after realignment, we used the Artefact Detection Toolbox (ART;   http://web.mit.edu/swg/software.htm  ; see Supplementary Material for thresholds employed). In addition to utilizing the ART toolbox, we also visualized a portion of the images from each participant at each analysis step in order to ensure the quality of the data. 

Statistical analyses were performed on a voxel-wise basis across the whole-brain. Using an event-related approach, individual events were convolved with a standard synthetic hemodynamic response function (HRF). Six individual regressors represented the main event types. For the cues: social and non-social cues; for the feedback: social win outcome, social lose outcome, non-social win outcome, non-social lose outcome. Events corresponding to feedback for erroneous responses (i.e. key presses before target onset), the key presses themselves, motion parameters, and outlier scans identified by ART were modeled as nuisance regressors. A high-pass filter with 128 s was also applied. The relevant first-level contrasts were built and used during the second-level analyses. 

To answer our three hypotheses, we modelled three separate second-level analyses. Model 1 aimed to test H1, by determining the differences between HCs and BPD patients for the processing of social cues versus non-social cues. Hence, the corresponding linear contrasts for each participant were entered into a 2 × 2 full factorial model with one within-subjects factor ‘Social Condition’ (social, non-social) and one between-subjects factor ‘Group’ (HC, BPD). Model 2 was conducted to test H2, by determining the differences between the groups when processing social feedback. The corresponding linear contrasts were entered into a separate 2 × 2 × 2 full factorial model with two within-subject factors ‘Social Condition’ (social, non-social) and ‘Reward Outcome’ (win, lose), and one between-subjects factor ‘Group’ (HC, BPD). As we expected to find group differences in the frontal brain in Model 1 (i.e. anticipatory social cue processing) and the amygdala in Model 2 (i.e. socially evaluative feedback processing), we utilized a region-of-interest (ROI) analysis approach using the WFU PickAtlas toolbox for SPM ( ;  ). Specifically, we created one mask of the frontal lobe (used to test H1 in Model 1) and a second mask of the bilateral amygdala (used to test H2 in Model 2), both of which were from the Talairach Daemon database. Follow-up exploratory full brain analyses were then conducted (see below for thresholding information). 

Model 3 was created   ad hoc   in order to test H3 following the outcome of the first two models. In particular, we speculated that there would be group differences between frontal regions at the time-point of the cues (as tested by Model 1) and the limbic processing during the following negative social feedback (as tested by Model 2). However, as we did find group differences in the amygdala for Model 2, but not in the frontal cortex for Model 1 (see the Results section), we ran a seed-based analysis, using the amygdala feedback-related activity for the negative social (compared to non-social) component of Model 2 as the predictor and testing against potential relationship with cue-evoked signal at a voxel-wise level within Model 1. Specifically, the beta estimates for both groups from the bilateral amygdala ROI for the negative social feedback (i.e. social loss>non-social loss) were extracted from Model 2 and entered as a covariate into an independent samples   t  -test using the specific contrast social>non-social cues (see the SPM design matrix in Supplementary Figure S1). We then tested for the effects of the amygdala covariate in each group separately and compared the differences between the groups. Please note that, although this analysis shares many properties with seed-based connectivity approaches (e.g., psycho-physiological interactions), it differs from the latter by testing the interaction between different epochs (anticipatory cue versus feedback). Hence, results should not be necessarily interpreted in terms of online communication between brain areas, but rather in terms of delayed influence, wherein the anticipatory activity in the highlighted regions explains the subsequent amygdala response during negative social feedback (versus non-social). Finally, for sake of completeness, we repeated the seed-based analysis using instead the betas extracted from the positive social feedback (i.e. social win>non-social win). The results from this model (i.e. Model 4) are described in the supplementary materials. 

ROI analyses were conducted using the pipeline implemented in the WFU PickAtlas toolbox with a familywise error (FWE) correction of   p  <.05. Follow-up whole-brain activations are reported at a significance level of   p  <.001 and a   k  >88, which corresponds to   p  <.05 corrected, based on the most stringent of three Monte Carlo Simulations (one for each fMRI Model) conducted using the toolbox RestPlus ( ). Employing this combination of height and cluster correction has been shown to lead to reliable results, with an acceptable tradeoff between type-I and type-II errors ( ). In order to illustrate the relative activation of the different brain regions, mean beta estimates were extracted from 8 mm spheres surrounding the activation peak. 


### Psychometric and statistical analysis 
  
To test the differences in the self-report questionnaires between the two groups, independent   t  -tests were performed. Additionally, where appropriate, analyses of variances/co-variances (ANOVA/ANCOVA) were used to compare the differences between reaction times and check for effects of medication load as well as comorbid disorders (see Supplementary Materials for results). Finally, we used Spearman's correlation to help understand how childhood trauma, a main BPD risk factor, might relate to amygdala activity in the BPD patients (following the outcome of Model 2, see Results). We chose the amygdala because this region has not only consistently been shown to express dysfunctional activation in a variety of BPD neuroimaging studies (see Introduction section), but childhood trauma (measured via the CTQ) has also been shown to correlate with amygdala responsiveness to negatively valenced faces in HC subjects ( ). We used the software package IBM SPSS 22 (SPSS Inc., Chicago, IL) with a significance threshold set to   a   = =0.05. 



## Results 
  
### Behavioral results 
  
#### Reaction times 
  
The ANOVA comparing reaction times for responses to the target presentation did not show any significant main effects nor an interaction between the two groups for the social and non-social conditions (mean (SD) ms for HCs: social=250.14 (35.16), non-social=246.02 (31.43); BPD patients: social=257.75 (43.00), non-social=258.30 (51.46); all   p  >.29), suggesting that BPD patients did not differ from the HCs. 


#### Neuroimaging results 
  
##### Model 1: interaction social condition by group for cues 
  
To test H1, that BPD patients expressed dysfunctional recruitment of frontal brain regions in response to social (compared to non-social) cues, we directly compared both groups by computing the 2-way interaction ‘Social Condition’ (social, non-social cues) by ‘Group’ (HC, BPD) within the frontal lobe mask. This ROI analysis did not reveal any significantly activated voxels. When seeking effects across the whole brain, we found that the BPD patients (compared to HCs) hyperactivated the right superior temporal sulcus (STS) for social versus non-social cues ( ; Supplementary Table S1). Raw beta estimates extracted from the peak of this region (i.e.  B) showed that BPD patients expressed greater STS activation to social cues compared to the HCs, a difference not observed for the non-social cues. It should be noted that estimates extracted from the STS are often below the baseline (i.e. negative), most likely due to the high activations in this region during resting state (e.g. ( ;  )). There were no significantly activated voxels in the opposite contrast.   
Model 1 whole brain fMRI results for the Social Condition by Group Cue Contrast. A) Whole brain analysis results from Model 1 showing the contrast social > non-social cues. The STS (yellow cluster) was shown to be significantly more activated by the BPD patients (95 consecutive voxels, peak [60 −37 −14]). Images are thresholded at   p  =.001,   k  >88, Monte Carlo corrected and overlaid on the averaged normalized T1-weighted anatomical images created from all participants (  N   = =45). B) Dot plots of the beta estimates extracted from an 8 mm sphere around the peak STS (from A). Average estimates of each category are illustrated by the yellow diamonds. a.u.=arbitrary units; BPD=borderline personality disorder patients; HC=healthy controls; STS=superior temporal sulcus. 
  Fig.. 2   


##### Model 2: interaction social condition by group for feedback 
  
To test H2, that BPD patients would show impaired amygdala response to social feedback, we conducted ROI analyses (i.e. frontal lobe and amygdala masks) using the 2-way interaction ‘Group’ x ‘Social Condition’ for the feedback analysis. BPD patients expressed a blunted response of the bilateral amygdala compared to the HCs for the social versus non-social feedback contrast ( ). Extracting the raw beta estimates from the peak ( B) showed that the HCs, compared to the BPDs, expressed a larger difference in activity for the social compared to the non-social conditions. When seeking effects across the whole brain we found no suprathreshold results (see Supplementary Table S2 for full voxel-wise analysis). Interestingly, exploratory analyses showed that amygdala activity in the BPD patients for the social loss (versus non-social loss) contrast negatively correlated with CTQ physical abuse subscale (  ρ  =−0.46,   p  =.036; but not CTQ total score,   ρ  =−0.35,   p  =.12). However, this effect did not survive correction for multiple comparisons for all subscales employed (see Supplementary Table S6 for more detail).   
Model 2 amygdala ROI activation in the interaction Social Condition by Group Feedback Contrast. A) Significant amygdala ROI activation is shown in yellow (right: 26 consecutive voxels, peak [21 −1 −14],   t   = =3.57, p  =0.007; left: 1 voxel, peak [−18, −4, −14],   t   = =2.90, p  =0.048) in the 2-way interaction (Social Condition x Group) overlaid on the ROI mask created using the WFU PickAtlas (red). ROI activations are shown with   p  =.05 FWE corrected, and overlaid on the averaged normalized T1-weighted anatomical images created from all participants. B) Dot plots underlaid by boxplots of the beta estimates extracted from the bilateral amygdala mask (i.e. red voxels in A). Average estimates of each category are illustrated by the yellow diamonds. a.u.=arbitrary units; BPD=borderline personality disorder patients; HC=healthy controls; ROI=region of interest. 
  Fig.. 3:   


##### Model 3: independent samples   t  -test regression analysis 
  
Finally, to test the H3, that the processing of the cues by frontal regions would be related to dysfunctional negative social feedback processing, we entered the beta estimates from the bilateral amygdala ROI as a covariate in an independent samples   t  -test for social versus non-social cues, for each group separately ( A). This analysis revealed a negative relationship for the BPD group in the left putamen/caudate, the bilateral middle frontal gyrus, and the pgACC (see Supplementary Table S3). There were no significantly activated voxels in the HCs (positive nor negative). A direct group comparison showed that the pgACC-amygdala coupling changed significantly between BPD patients and HCs. To better characterize this relationship, we extracted the beta estimates from the pgACC and conducted a correlation in each group with the beta estimates from the amygdala. We found a strong negative relationship in the BPD group ( B;   ρ  = −0.74,   p  <.001) but not the HCs (  ρ  =0.31,   p  =.146). More specifically, increased pgACC activity during the social versus non-social cue was followed by decreased activity in the amygdala during the processing of the negative social feedback in the BPD group but not the HCs. Please also note, conducting the same analysis, but utilizing the amygdala activity extracted from the positive social feedback (i.e. social win>non-social win) as a covariate in an independent samples   t  -test for social>non-social cues did not reveal any significantly activated voxels for either group alone, nor in the contrast between the two. Hence, our evidence of altered pgACC-amygdala coupling in BPD (relative to HCs) was restricted to the relationship between social anticipation and   negative   social evaluation.   
Model 3 Whole-brain fMRI results from the independent samples   t  -test amygdala feedback regression analysis. A) The change in signal (i.e. beta estimates) from the bilateral amygdala ROI ( ) was extracted from the processing of the social loss>non-social loss feedback and entered as a covariate in an independent samples   t  -test for each group (i.e. HCs and BPDs) testing the difference between the processing of the social>non-social cues. The negative regression in the BPD group is shown in yellow and includes the pgACC, bilateral middle frontal gyrus, and left putamen. The main effect of group (i.e. HC>BPD) is shown in red (and the overlap is shown in orange), and includes solely the pgACC (93 consecutive voxels, peak [9 41 10],   t   = =4.97). B) Illustration of the above-mentioned modulation. The y-axis shows the extracted amygdala activity (which was entered as a covariate in the fMRI model), and the mean pgACC activity extracted from A (white circle) is shown on the x-axis. There was a significant correlation in the BPD group (rho= −0.74,   p  <.001) but not the HCs (rho=0.31,   p  =.146).*  p  <.05; a.u.=arbitrary units; BPD=borderline personality disorder patients; HC=healthy controls. 
  Fig.. 4:   





## Discussion 
  
We utilized fMRI to investigate how BPD patients (compared to HCs) process socially relevant signals (cues and feedbacks) compared to non-social signals. The overarching goal of this study was to understand how anticipatory social cues and subsequent performance-based socially evaluative signals are coded and integrated in this clinical population. BPD patients showed a stronger signal than HCs in left STS while processing social anticipatory cues (compared to non-social cues). During the processing of performance-based socially evaluative feedback, BPD patients exhibited less activity than HCs in the right amygdala. Differential amygdala activity during the negative (but not the positive) social feedback evaluation was also modulated by prior pgACC reactivity to social anticipatory cues in the BPD group, but not the HCs. This study provides support for the hypothesis that BPD patients express altered neural processing even during the anticipation of social stimuli (e.g. heightened STS activity; ( )), as well an atypical relationship between frontolimbic regions across the timespan of a social interaction. 

The results from Model 1 revealed an increased activation of the right STS in the BPD patients compared to the HCs while processing social versus non-social cues (i.e. social anticipatory cues). Although this region was not a part of our original hypothesis (i.e. the STS is not part of the frontolimbic network), this region is frequently implicated in mentalizing, face perception, social cognition, and is involved in decoding the intentions and dispositions of others ( ;  ;  ). Additionally, the right STS has been shown to be sensitive to the perceived congruency between a person's action and their emotional expression ( ), and has also been shown to be hyperactivated during an emotional empathy (and hypoactivated during cognitive empathy) task in BPD patients ( ). Differential STS activity at this point (i.e. social anticipation) may also suggest a dysfunction by the BPD patients regarding the “social learning” (or even the facial processing) component required from the cues in this kind of task (e.g. ( )). However, given that we did not find any other evidence supporting a faulty processing of facial expressions in the patients (e.g. no differences between the reaction times, and no other differences in brain areas specialized for face processing), we can reasonably assume that this was not a confounding factor. Rather, this pattern of results suggests that the social cues were acutely relevant (i.e. highly salient) for the patients in our experiment, which is in-line with both BPD characteristics and clinical observations. 

The results from Model 2 indicate that, when processing social versus non-social feedback, the BPD patients expressed less activity than HCs in the bilateral amygdala, a brain region which detects emotional salience from faces ( ). Decreased response in this region points to a reduced reactivity to evaluative social feedback signals in BPD. From the findings in Model 1 and 2 together, we can speculate that BPD patients may rapidly detect social cues indicative of potentially adverse consequences (resulting in increased STS activity), while they would then suppress limbic responses to upcoming negative social feedback. It should be noted that although the amygdala was originally implicated in the processing of negative emotional stimuli (particularly fear), it is also an integral node in the “social brain”, much like the STS, and together these regions play an important role in social cognition ( ;  ). Thus, these results further highlight differential processing of social stimuli by BPD patients. Intriguingly, amygdala activity for the negative social (versus non-social) feedback negatively correlated with the degree of childhood physical abuse in the BPD patients, i.e., heightened childhood physical abuse likely exacerbated dampened limbic emotional reactivity. It is possible that those who suffered from physical abuse in childhood may have developed a coping strategy ( ), which is reminiscent of trauma-related dissociation characteristic of these patients (see ( )). However, given the fact that this correlation was not corrected for multiple comparisons, this result requires further investigation/verification before any conclusions can be solidified. 

Finally, the results from Model 3 revealed that, solely in the BPD group, the reduced amygdala response to negative social feedback was inversely related to anticipatory activity in the pgACC, left putamen/caudate, and bilateral middle frontal gyrus. Furthermore, the degree of pgACC-amygdala coupling was also significantly different between the two groups. The higher the pgACC activation during the processing of the social anticipatory cue, the less the amygdala reactivity during the processing of the negative social feedback in the BPD patients compared to the HCs. These results are particularly interesting because the pgACC is not only involved in automatic forms of emotion regulation ( ), but has also been shown to suppress limbic reactivity following negative emotion induction in non-clinical, healthy participants ( ;  ), and may thus resolve heightened emotional conflict via top-down inhibition of the amygdala ( ). In line with these findings, Carlson and colleagues ( ) showed that healthy individuals with a bias for increased attention to threatening stimuli expressed an increase in functional coupling between the amygdala and pgACC. Further, in a recent meta-analysis,   proposed that dysfunctional resting-state connectivity between the pgACC and amygdala may reflect a common neurobiological substrate (referred to in the paper as a “functional fingerprint”) in disorders that express heightened internalization and dysfunctional emotional processing (thus including BPD; ( )). However, this meta-analysis included only one study (out of 46) with a sample of BPD patients. Therefore, we would like to speculate that this pattern of results (i.e. the relationship between pgACC social cue anticipation and amygdala negative social feedback processing) provides support for the idea that impaired pgACC-amygdala connections may contribute to dysfunctional social processing in BPD. 

Taken together, the present findings demonstrate that BPD patients express an exacerbated neural reactivity to social anticipatory cues (i.e. heightened STS), as well as an atypical relationship between the pgACC and amygdala, whereby pgACC relates to a top-down suppression/inhibition of limbic activity during the processing of negative social feedback. Further supporting this interpretation, the pgACC-cue and amygdala-feedback relationship was only observed for the negative social feedback, and not for the positive social feedback. This pattern of activation could reflect a form of coping that the patients have been conditioned to engage in, possibly via increased childhood abuse, in order to alleviate the impact of the negative feelings arising from negative evaluative social feedback (or from negative social signals in general). Thus, when the patients actually receive negative feedback, or feedback that is only slightly negative (e.g. an angry face is obviously less negative than physical abuse), they are unable to process this information in an emotionally adaptive way (e.g. decreased amygdala activity) and may thus also react inappropriately to it. This is in line with several developmental models of BPD, such as Linehan's model (e.g. ( ;  )) whereby heightened emotion dysregulation results in distorted information processing and can then lead to shutting down/freezing resulting in dissociation. 

The present findings expand on previous work in several ways. In particular, our results suggest a possible progression of dysfunction throughout social interactions (i.e. from social anticipatory processing, through to the processing of the feedback) in these patients. It is reasonable to speculate that these patients do not exhibit atypical responses solely during the processing of feedback (i.e. during the social interaction itself), but also during the mere anticipation of the upcoming socially evaluative context. These conclusions are promising, particularly for creating new targeted treatment options for these patients. For example mindfulness training (e.g. ( )) or neurofeedback (e.g. ( )) may be utilized in order to decrease the anxiety and negative feelings associated with an upcoming social interaction (i.e. social anticipation). This could then have a cascading positive effect on social functioning within this patient population. Additionally, given the heightened STS activity at the onset of the social cue, utilizing more mentalization based treatments could likely have long-lasting significant effects on BPD symptomatology ( ). Finally, the overarching ideas investigated in this paper (namely understanding how the amygdala is modulated by previously seen stimuli) have impactful consequences for clinical research. The vast majority of fMRI studies have shown atypical recruitment of the amygdala in this patient population (for a meta-analysis see ( )), yet few have aimed to investigate how this differential processing might unfold across the time-span of a social interaction beyond simply resting-state connectivity. Aside from the development of new intervention strategies, understanding how the amygdala is affected by up- and down-stream connections throughout a social interaction may ultimately help to elucidate the neural bases of interpersonal dysfunction in BPD. 

The main limitation of the present study relates to the fact that many of the BPD patients were medicated during scanning. Including only medication-free patients could have created a selection bias in our sample, while removing current medications was not possible due to ethical implications and could have had other negative effects linked to the momentary increase in symptomatology. Thus, patient medication may have an effect on differential activity seen in the relative brain signal, especially for the amygdala (see ( )). Additionally, several of our patients were diagnosed with comorbid disorders (particularly depression and ADHD). Even though we carefully checked for any interactions between medication load or comorbid disorders and brain activations (see Supplementary Tables S4-5), we cannot fully rule them out as confounding factors. It should however be noted that the majority of the general BPD population is medicated (up to 84%) ( ), and also present with comorbid disorders ( ;  ), therefore likely increasing the generalizability of our results. In addition, we cannot conclude that the results in this manuscript are specific to BPD patients, as we did not include another non-BPD patient cohort. Finally, we also chose to utilize a paradigm where the cue itself was social (i.e. a neutral face) rather than the traditional symbol that is often used with social incentive delay tasks (e.g. ( )). Thus, we cannot conclude for certain that the effect of the social cue was specifically related to the “emotional” response elicited by the face, the anticipation of the upcoming feedback, or both. In a real-world setting however, we can suggest that there is likely a mix between both aspects, thus again potentially increasing the generalizability of these results. 

In conclusion, our findings suggest an alteration of the neural processing of social signals in BPD. This supports the notion that BPD is a disorder characterized not only by atypical amygdala activity during emotion processing, but by a differential frontolimbic relationship, which may result in difficulties adapting in the context of a social situation. It is possible that these results may help to explain why BPD patients are unable to produce adapted responses regarding relevant environmental information, particularly salient social information ( ;  ). These results help to explain why BPD patients suffer from pervasive difficulties in adjusting their behavior, particularly in the context of interpersonal relationships. 


## Financial disclosures 
  
None 


## CRediT authorship contribution statement 
  
 Kimberly C. Doell:   Conceptualization, Methodology, Software, Formal analysis, Investigation, Data curation, Writing - original draft, Writing - review & editing, Visualization, Project administration.   Emilie Olié:   Conceptualization, Methodology, Investigation, Writing - review & editing, Visualization, Project administration, Funding acquisition.   Philippe Courtet:   Conceptualization, Supervision.   Corrado Corradi-Dell'Acqua:   Methodology, Software, Formal analysis, Writing - review & editing.   Nader Perroud:   Conceptualization, Resources, Supervision.   Sophie Schwartz:   Conceptualization, Methodology, Formal analysis, Resources, Writing - review & editing, Visualization, Supervision, Funding acquisition. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-64'>
<h2>64. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/32711391/' target='_blank'>32711391</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Default mode network modulation by mentalizing in young adults with autism spectrum disorder or schizophrenia</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Neuroimage Clin</p>
<p><strong>Publication Year:</strong> 2020</p>
<p><strong>DOI:</strong> 10.1016/j.nicl.2020.102343</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/7381691/' target='_blank'>7381691</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> Study acquired task-based BOLD fMRI during an interactive social (mentalizing) Domino game and included a healthy typically-developing (TD) control group (ages 18–34). Results are reported for TD separately alongside ASD and SZ groups. Analysis used whole-brain data-driven ICA (GIG-ICA) and temporal sorting to identify and test default mode network components (not limited to ROIs), with group-level whole-brain component maps and task-related beta-weights reported. Thus the paper meets: (1) social-related fMRI task, (2) includes healthy adults within 17–65 with separate reporting, and (3) whole-brain analyses (ICA). No exclusion criteria (ROI-only or only clinical participants) apply.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>   Highlights  
  
Autism spectrum disorder (ASD) & schizophrenia (SZ) have mentalizing deficits. 
  
Spatially constrained ICA reveals shared deficits in mentalizing default mode activity. 
  
Mentalizing-related temporoparietal junction activity correlated with ADOS scores in ASD. 
  
Mentalizing-related precuneus activity correlated with tendency to fantasize in SZ. 
  
Both categorical and RDoC approaches to study neural deficits in SZ & ASD are supported. 
  
  
Schizophrenia and autism spectrum disorder (ASD) are nosologically distinct neurodevelopmental disorders with similar deficits in social cognition, including the ability to form mental representations of others (i.e., mentalizing). However, the extent of patient deficit overlap in underlying neural mechanisms is unclear. Our goal was to examine deficits in mentalizing task-related (MTR) activity modulation in schizophrenia and ASD and the relationship of such deficits with social functioning and psychotic symptoms in patients. Adults, ages 18–34, diagnosed with either ASD or schizophrenia, and typically developed controls (n = 30/group), performed an interactive functional MRI Domino task. Using independent component analysis, we analyzed game intervals known to stimulate mentalizing in the default mode network (DMN), i.e., medial prefrontal cortex (MPFC), posterior cingulate cortex (PCC), precuneus, and temporoparietal junction (TPJ), for group differences in MTR activity and associations between MTR activity and social and psychosis measures. Compared to controls, both schizophrenia and ASD groups showed MTR activity deficits in PCC and TPJ. In TPJ and MPFC, MTR activity modulation was associated with social communication impairments only in ASD. In precuneus, MTR activity was associated with increased self-reported fantasizing only in schizophrenia. In schizophrenia, we found no indication of over-mentalizing activity or an association between MTR activity and psychotic symptoms. Results suggest shared neural deficits between ASD and schizophrenia in mentalizing-associated DMN regions; however, neural organization might correspond to different dimensional social deficits. Our results therefore indicate the importance of examining both categorical-clinical diagnosis and social functioning dimensional constructs when examining neural deficits in schizophrenia and ASD. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (38589 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Schizophrenia (SZ) and Autism Spectrum Disorder (ASD), traditionally conceptualized as separate clinical entities ( ), are severe neurodevelopmental disorders that share symptom traits, cognitive deficits and risk factors ( ). Behaviorally, social processing impairments are central to both ASD and SZ ( ,  ,  ) and are related to functional outcome ( ,  ,  ,  ). Social processing is conceptualized as cognitive processes supporting interaction with conspecifics, which include basic and complex social processes with distinct characteristics and underlying neural circuits ( ,  ). Basic processes are automatic and include perception and production of social cues. Complex processes require active inference ( ,  ), such as understanding other’s feelings and goals (i.e., mentalizing/theory of mind). While there is evidence that both are impaired in ASD and SZ ( ,  ), meta-analyses demonstrated similar quantitative deficits in mentalizing ( ,  ), but not in basic emotion perception tasks ( ). Despite phenotypic (i.e., symptomatic) differences between ASD and SZ, studies comparing these patient groups directly confirm similar patterns of mentalizing deficits based on available quantitative social cognitive tasks ( ,  ,  ). However, it is not known if shared impairments are the manifestation of overlapping or different (disease-specific) underlying neural mechanisms. 

Neuroimaging studies suggest specific neural networks subserve different social processes ( ,  ). The mentalizing network includes the medial prefrontal cortex (MPFC), posterior cingulate cortex (PCC), precuneus (PrC) and temporoparietal junction (TPJ), including superior temporal sulcus (STS) as core regions ( ,  ). Both ASD and SZ, studied separately, show abnormalities in this network, and a review found that while both groups exhibit decreased activations of regions around the STS, they differ in other regions, e.g., MPFC ( ). 

Only three studies, however, compared these groups directly on social tasks. Pinkham et al. ( ) showed similar activation deficits in ASD and paranoid-SZ during a trustworthiness task in the right amygdala, fusiform face area and left ventrolateral PFC. Conversely, Ciaramidaro et al. ( ) and   used mentalizing tasks and found diagnostic specific deficits in PFC and temporal regions, including TPJ and STS.   additionally demonstrated that when compared with ASD and controls, SZ patients showed increased activation in the right posterior STS during non-intentional events (i.e., events not involving social interaction). This increased activity in the mentalizing network during non-intentional events in SZ corresponds with the theory that patients with SZ, especially those with prominent positive symptoms such as paranoia, might attribute excess meaning or over-attribute intentions to physical (non-social) events and/or people ( ,  ). This phenomenon is variably known as “hyper-intentionality” ( ), “hyper-mentalizing” ( ), or “over-mentalizing” ( ,  ). The number of neuroimaging studies that have examined the neural correlates of the potential over-mentalizing in SZ is small, but these few studies have in common the finding of increased activity in the MPFC in SZ patients, when compared with controls, during non-social fMRI task events ( ,  ,  ). Additional neuroimaging studies are required to examine more closely the over-mentalizing theory in SZ and its relationship to positive and negative symptoms. 

Other studies that examine the mentalizing network in SZ and ASD employ resting state (RS) fMRI (i.e., when no task is presented) to delineate the default mode network (DMN). This network largely overlaps the mentalizing network and is associated with high-order social processes ( ,  ). Impaired DMN functional connectivity (FC; a measure of synchronous neural activity between remote brain areas that define neural networks) has been demonstrated in SZ and ASD, each studied separately ( ,  ), and is associated with social functioning and cognitive deficits in these disorders ( ,  ). A meta-analysis showed that RS FC deficits within DMN, and between DMN and task-positive networks, are common to several psychiatric diagnoses, including ASD and SZ, and are related to cognitive impairments ( ). Additionally, an RS-based classifier of ASD was effective at differentiating SZ (but not ADHD or depression) from controls ( ), suggesting a significant overlap in abnormal DMN-FC patterns between ASD and SZ. However, RS imaging studies directly comparing ASD and SZ DMN-FC are scarce. Chen et al. ( ) demonstrated shared deficits in RS-DMN and salience network (SN) between ASD and SZ, correlating with social deficits in ASD (no social measures in SZ were available). We recently showed that whole brain RS dynamic FC patterns of SZ and ASD have some similar abnormalities, spending more time in a state of weak, intra-network connectivity; however, SZ shows more pervasive deficits ( ). Importantly, this work was not specific to either DMN or mentalizing. 

Here we aimed to compare mentalizing task-related (MTR) neural activity modulation in the DMN in ASD and SZ during performance of an ecologically valid, social (i.e., interactive) competitive task, a Domino game. We previously showed, in an application of independent component analysis (ICA) to fMRI data from typically developed (TD) adults, that the task interval associated with mentalizing positively modulates activity within specific default mode sub-regions encompassing all of its core regions (i.e., MPFC, PCC/PrC and TPJ) ( ). We now extend this work to young adults with ASD or SZ, along with TD controls, to assess the modulation of MTR activity in default mode subnetworks. In this study, we performed exploratory analyses characterizing the relationships between MTR activity and basic and complex dimensional traits of social abilities (measured with observational, self-reported and performance-based tools) and negative and positive symptoms (SZ) as opposed to clinical categories, to better understand patient abnormalities, in accord with NIMH’s Research Domain Criteria (RDoC) initiative ( ). Our specific hypotheses were that, 1) both patient groups would differ in MTR activity modulation from TD but, due to “over-mentalizing”, only SZ would show increased MTR activity modulation relative to both ASD and TD during task events typically eliciting less mentalizing and, 2) patient neural impairment would be associated with social deficits, and 3) SZ would show a correlation between positive symptoms and DMN neural activity during task events typically eliciting less mentalizing. 


## Methods 
  
### Participants 
  
We present data from 90 participants, 30 per group (high-functioning ASD, SZ and TD) ages 18–34 with estimated full-scale IQ > 80, that completed the Domino fMRI task. We provide inclusion/exclusion criteria and selection process from a larger sample in  . 

Participants provided written informed consent after the study had been explained to them and were paid for their time. The authors assert that all procedures contributing to this work comply with the ethical standards of the relevant national and institutional committees on human experimentation and with the Helsinki Declaration of 1975, as revised in 2008. All procedures involving human subjects/patients were approved by the Institutional Review Boards of Hartford Hospital and Yale University. 


### Clinical symptoms & social functioning testing 
  
Assessment battery is described in  . Psychiatric assessment included the structured clinical interview for DSM-IV axis I disorders (SCID) ( ) and the autism diagnosis observation schedule (ADOS)–module 4 ( ). 

We administered the Positive and Negative Syndrome Scale (PANSS) ( ) to patients and ADOS to all groups to quantify the severity of psychotic and social communication deficits, respectively; TD were excluded from clinical symptom analyses. 

To assess social cognition and function, we administered the following tests: 1) Interpersonal Reactivity Index (IRI) ( ), 2) Quality of Life Scale (QLS) ( ), 3) Reading the Mind in the Eyes Task (RMET) ( ), and 4) Social Attribution Test (SAT) ( ). 


### Domino fMRI task 
  
We presented a detailed description of this task previously ( ,  ,  ) and in  ; a brief explanation is provided here. 

Each participant performed four domino runs, each including multiple games. While all opponent moves were automated and random, at the beginning of each run we told participants they were playing against either a computer, executing automated, random moves, or a human, making strategic decisions. For each game, the participant was given 12 domino playing chips, all of which had to be dispensed by the game’s end for him/her to win. Each game also had a master domino chip that, during each turn, the participant could decide to either match or not match it, placing one of his/her remaining playing chips face down. During this game phase, termed ‘Response to Outcome’ (RTO), the opponent asked the participant to either expose their chip (  show   event) or not (  no-show   event). The participant dispensed of the played chip if the opponent elected to ‘  no-show  ’, regardless of whether the participant’s chip matched the master chip and dispensed of the played chip plus an extra chip if an opponent elected to ‘  show  ’ a matching chip. A ‘  show  ’ of a non-matching chip resulted in gaining back the played chip plus one more. 

Participants completed a post-scan debriefing that assessed their motivation and playing strategy, using statements scored on a Likert scale, ranging from 1, “does not apply to you at all”, to 5, “applies to you very much”. 


### fMRI scan acquisition 
  
We collected BOLD fMRI data with a T2*-weighted echo planar imaging (EPI) sequence (TR/TE = 475/30 msec, flip angle = 60°, FOV = 24 cm, acquisition matrix 80 × 80), using a Siemens Skyra 3 Tesla scanner (Siemens, Malvern, Pennsylvania) at the Olin Neuropsychiatry Research Center (ONRC; Hartford, CT). We acquired forty-eight contiguous axial functional slices of 3.0 mm thickness (interleaved slice order) resulting in 3.0 mm  voxels. We acquired four ten-minute Domino fMRI runs, each consisting of 1248 images. 


### fMRI data preprocessing and motion-artifact correction 
  
We processed functional MRI datasets using SPM8 (  http://www.fil.ion.ucl.ac.uk/spm  ) running under Matlab 2008b (Natick, MA). We realigned each subject’s data set to the first ‘non-dummy’ T2* image using the INRIAlign toolbox (  http://www-sop.inria.fr/epidaure/software/INRIAlign  , A. Roche, EPIDAURE Group) to compensate for any subject head movement. We then screened each subject for excess head movement (>6 mm). We included six motion covariates (  x, y, z, roll, pitch, yaw  , obtained from the realignment) in the temporal sorting procedure described below. After realignment, we spatially normalized the images to the Montreal Neurological Institute (MNI) standard template ( ). Finally, we spatially smoothed images with an 8 mm isotropic (FWHM) Gaussian kernel, and then applied a high-pass filter with a cutoff of 128 s to correct for EPI signal low-frequency drift. Note that slice timing correction was not performed due to the multiband short TR sequence, as recommended by the HCP pipeline ( ). As a final step, we scrubbed the fMRI data using the ArtRepair toolbox (  https://cibsr.stanford.edu/tools/human-brain-project/artrepair-software.html  , RRID:SCR_005990) ( ) to exclude from analysis fMRI time series sections with excessive movement. Since patients often characterized by high head movement during fMRI, we set ArtRepair at a relatively liberal maximum acceptable movement at 1.0 mm/TR (assuming a 65 mm head radius), and the intensity variation at a maximum percent threshold of 1.3% of the mean global average signal. 

We determined that of the participants retained (<6 mm movement) none had >30% of scans repaired from any two common-opponent (computer or human) Domino sessions. The number of participants with >12.5% of scans repaired (but always <30%) for any two common-opponent sessions were as follows: six ASD, three SZ, and one TD. Means and standard deviations of scans repaired were 162 ± 242 (ASD), 94 ± 180 (SZ) and 49 ± 137 (TD) out of a total of 4992 scans. A Kruskal-Wallis test indicated a non-significant difference between groups (χ  = 5.881,   p   = 0.053) on the number of repaired scans. 

To further reduce the effect of head motion on our results, we included the mean of the root mean square (RMS) of the framewise displacement, or   mean   FD , for each participant as a second (group) level covariate in all statistical analyses. To calculate   mean   FD  for each participant, we computed a single mean value of the root-mean-square framewise head displacement, determined using the six realignment parameters (over all four Domino sessions) with an assumed head radius of 65 mm for all participants. 

We should also note that the GIG-ICA procedure we used has been shown in a previous study ( ) to very effectively reduce the effect of head motion artifact on the data. 


### Statistical analyses 
  
Behavioral analyses to assess participants’ engagement in the game, strategies while playing (e.g. risk taking) and engagement in mentalizing are described in  . 

Imaging analyses focused on the RTO phase. We previously demonstrated that DMN regions are activated and modulated during this phase due to mentalizing processes, e.g., trying to infer the opponent’s strategy and planning the next play accordingly. This is measured by the   show > no-show   contrast regardless of the played chip ( ,  ,  ). As stated in our previous work, although we consider both   show   and   no-show   events to involve mentalizing,   show   events will require significantly greater levels of player mentalizing than   no-show   events ( ). The reason for this is as follows. The opponent obtains new information about the player only during   show   events (e.g., if the player bluffed or played fairly). The player then knows that the opponent can use this information to change his/her strategy. This in turn requires the player to take more information into account when updating his/her mental representation of the opponent (i.e., requires greater mentalizing). 

We calculated subject-level statistics using a general linear model (GLM) design matrix in SPM8 (  www.fil.ion.ucl.ac.uk/spm/software/spm8/  ; RRID:SCR_007037) using the following RTO-phase regressors of interest: ‘  show match  ’, ‘  show non-match  ’, ‘  no-show match  ’ and ‘  no-show non-match  ’ events. Individual GLMs were used for ICA temporal sorting (see below). 


### Estimation of subject-level independent components (IC) via spatially constrained ICA 
  
In this study we used spatially constrained ICA (i.e., GIG-ICA) ( ) to extend our earlier work ( ) to clinical populations. Briefly, we used prior group-level ICs from an independent sample (53 TD participants) to guide the extraction of subject-specific ICs while automatically providing labeled components. The benefits of GIG-ICA are that single-subject ICA statistical independence is optimized ( ) and artifact suppression is improved ( ) when compared with traditional single-subject ICA. Note, in contrast to work in Du et al. ( ) which used group maps from the same data, we are using maps derived from independent data, which has the same benefits, but also provides completely independent single-subject results and automatic labeling of components. Using GIG-ICA, we extracted 45 subject-specific ICs, including ten DMN-specific ICs, which matched the 45/10 group-level ICs previously determined to be BOLD-related networks (i.e., not physiological artifacts) and DMN-specific (see   for details) ( ). 


### Group analysis 
  
ICA-based analysis is often applied to resting-state fMRI data. In this study, however, we applied spatially constrained single-subject ICA not to resting-state fMRI data, but to the analysis of a socially interactive fMRI Domino task. We analyzed subject-level components derived from spatially constrained ICA for task-relatedness (RTO task events) using the Group ICA of fMRI Toolbox (GIFT,   https://trendscenter.org/software/gift/  , RRID:SCR_001953) ‘temporal sort’ multiple-regression feature. Temporal sorting is analogous to GLM regression performed on fMRI voxel timecourses, except regression is performed on subject-level ICA timecourses. The resulting   β  -weights represent the degree to which component networks were engaged by task events ( ). Here we were interested in the events-contrast defining the mentalizing effect:   show   >   no-show   ( ). Thus, the   β  -weights were entered into a mixed-model ANCOVA in SPSS, with within-subjects factor being   mentalizing   (two levels,   show   and   no-show  ), and between-subject factor being   group  . The model included the   group  -by-  mentalizing   interaction. 

To examine the phenomenon of “over-mentalizing” in SZ, we also assessed between-group differences separately for   show   events and for   no-show   events, with   no-show   events here considered as task events typically eliciting less mentalizing in players. We included age, estimated full-scale IQ, and mean framewise head displacement (root mean square; FD ) as covariates and results were Bonferroni-corrected for multiple comparisons ( ). To test for possible associations between mentalizing and medication intake, sensitivity analyses were performed ( ).   
Participant characterization. 
      
Characteristics of the default mode network ICs. Current (n = 30, TD only) versus previous study (n = 53) (see Supplementary 6 for more details). 
      
Group-by-mentalizing interaction effects. Statistics shown are for the   show > no-show   contrast for ICs demonstrating this effect (thus, ICs 16 and 19 are excluded). 
    


### Exploratory correlation of symptom severity with mentalizing 
  
We assessed the correlation of symptom severity with mentalizing-related neural activity in patients. The temporal sorting beta-weights for   show   and   no-show   for each subject were averaged over all four Domino fMRI runs and then subtracted to produce one measure of mentalizing task-related (MTR) neural activity (Δ  β   =   β   −   β  ). We then used GLM to examine the correlation between the MTR variable (Δ  β  ), and independent variables of symptom severity (clinical testing subscores), and their interactions. Age, IQ and FD  were included as covariates and results were false discovery rate (FDR) corrected ( ).   
Statistics of Group (ASD and SZ only) by ADOS Communication (ADOS-C) score interaction, with the overall   show > noshow   difference (Δ  β  ) as the dependent variable. Also included is the post hoc analysis of the linear slopes between   show > noshow   versus ADOS-C, for each group separately. 
    



## Results 
  
### Participant characterization 
  
 lists group demographics and assessments’ scores, including statistical comparisons. Groups matched on gender but not on age and estimated IQ, thus analyses were controlled for the latter.   shows that both ASD and SZ patients, when compared with TD, had 1) larger mean framewise displacement (indicating greater head motion), 2) larger ADOS scores (on both Communication and Social Interaction subscores), 3) larger IRI Personal Distress subscores, 4) smaller RMET scores and 5) smaller QLS scores. On IRI Perspective Taking subscores, only patients with ASD scored smaller than TD. These results are largely consistent with known clinical symptoms and social cognition deficits of both patient groups. 


### Behavioral results 
  
 presents information on games played, post-scan debriefing and risk taking while playing. The post-scan debriefing questions relevant to mentalizing are provided in  . Briefly, there were no significant between-group differences in number of games played, won, or shorter than one-minute. Groups also did not differ on overall game engagement and tendency to engage in mentalizing. Finally, risk taking behavior increased with time (i.e., minutes elapsed) without group differences. Taken together, these results indicate that the ASD and SZ patient groups participated in the Domino task to the same extent as the TD group. 


### Default mode network mentalizing task-related (MTR) activity modulation 
  
 lists the ten core DMN ICs examined in this study along with the corresponding ICs from the previous study ( ) (see   for more information on IC extraction).   shows these same ICs as derived from spatially constrained ICA subject-specific component spatial maps (  z  -scores). A complete description comparing default mode network ICs in TD participants in this study with a previous study ( ) is provided in  .   
The ten ICs identified as DMN components. Maps were created using a SPM8 one-sample   t-  test from GIG-ICA back-reconstructed subject-specific IC spatial maps from all participants. Panel   A   shows posterior DMN ICs, panel   B  , TPJ/STS ICs, and panel   C  , prefrontal ICs. Threshold was set at a   t  -score of 50.0. 
  


### DMN task recruitment: MTR activity group differences 
  
A mixed-model ANCOVA of   show   and   no-show   event   β  -weights revealed that three DMN components, of the eight ICs involved in MTR activity, showed a significant (Bonferroni-corrected over eight ICs)   group  -by-  mentalizing   interaction: ICs 8 (PCC), 27 (right TPJ) and 33 (left TPJ). Post-hoc pairwise analyses showed that TD had significantly greater MTR activity modulation (i.e., Δ  β  ) than both ASD and SZ in two posterior default mode networks (ICs 8 (PCC) and 27 (right TPJ)), while in IC 33 (left TPJ), TD had significantly greater modulation of MTR activity than SZ only (  and  ).   
Bar plots showing the three ICs characterized by a significant   group  -by-  mentalizing   interaction (  show > no-show  ). Panel   A   presents estimated means (  β  -weights) for PCC (IC 8), panel   B  , right TPJ (IC 27), and panel   C  , left TPJ (IC 33). For pairwise   show > no-show   statistics (denoted by brackets) see  . *  p   < .05;   ns  : not significant. 
  

The mixed model ANCOVA above included an analysis of   show   and   no-show   events beta values separately. Although the bar charts in   appear to show that SZ had greater MTR activity modulation during   no-show   events (red bars) than ASD and TD, suggesting over-mentalizing per our hypothesis, none of the tests for group differences in   no-show   event beta values (indicating possible over-mentalizing-related activity) reached statistical significance in any DMN component after correction for multiple comparisons. 


### Relationship of symptom severity scores with MTR activity modulation: ASD and SZ differences 
  
GLM of the correlation of symptom severity subscores with MTR activity showed a statistically significant interaction of group-by-ADOS communication subscore (ADOS-C) in six of the eight MTR ICs: ICs 27, 33 (lateral DMN) and ICs 26, 35, 38 and 40 (medial PFC DMN) (see   for statistical values). 

In all six of these ICs, there was a significant negative correlation between MTR activity modulation and ADOS-C for ASD, but not SZ (i.e., correlation slopes not significantly different than zero). 

Although the two ICs in posterior DMN (ICs 8 and 32) did not show a significant group-by-ADOS-C interaction (i.e., ASD and SZ slopes were not significantly different), MTR activity in ASD significantly negatively correlated with ADOS-C in IC 8 (PCC) (see  ). Conversely, we found no significant interaction of group-by-ADOS social interaction subscore in any MTR ICs. Additionally, we found no significant main effect of ADOS or PANSS subscores, which indicates that there was no correlation between MTR activity modulation in the DMN and behavioral symptom scores that was common to both ASD and SZ diagnoses. 

For the IRI scores, we found a significant group-by-IRI Fantasizing subscore interaction in DMN component IC 32, Precuneus, (  F  (2,71) = 7.849,   p   = 0.007), where post-hoc analyses showed a significant (negative) slope only for SZ (  t   = −3.412,   df   = 71,   p   = 0.009), with significant group differences in slopes between ASD and SZ (ASD > SZ,   F  (1,71) = 14.36,   p   = 0.003) and TD and SZ (TD > SZ,   F  (1,71) = 10.87,   p   = 0.012). No other effects were found for the IRI subscores in the MTR ICs. Correlation of SAT, QLS, RMET and PANSS scores with MTR activity showed no significant group-by-test interactions. In an assessment of over-mentalizing in SZ, a linear regression analysis of   show   event and   no-show   event beta values with PANSS Positive and Negative symptom scores in SZ showed no significant relationships in any DMN region. Lastly, there was no significant effect of SZ patient duration of illness on the relationship between MTR activity modulation and behavioral scores, or social cognition scores (see  ). 



## Discussion 
  
In this study we focused on identifying the neural correlates of social interaction in ASD and SZ. Traditionally considered distinct, SZ and ASD share clinical aspects, including marked social deficits ( ). We used an ecologically valid, interactive, competitive fMRI Domino game to assess the modulation of mentalizing task-related (MTR) activity within the default mode network in young adults with ASD, SZ and TD. We first established that all groups were similar in understanding and engagement in the Domino game, including taking their opponent’s moves into account (i.e., mentalizing), and in risk-taking behavior over time. Next, we assessed MTR activity modulation in relation to both clinical (categorical) diagnosis and dimensional social functioning. We hypothesized that, when compared with TD, SZ and ASD would have MTR activity deficits in the DMN. In agreement with our hypothesis, both patient groups showed reduced MTR activity modulation in two default mode subnetworks, PCC and bilateral TPJ. We also hypothesized that SZ would show greater MTR activity modulation during   no-show   events (i.e., events normally eliciting less mentalizing activity) than either TD or ASD, but did not find evidence for this over-mentalizing effect, nor did we find any association between mentalizing activity and positive or negative psychotic symptoms. Importantly, while some behavioral studies have suggested over-mentalizing in SZ with specific association with positive symptoms (e.g., see ( ,  ,  ,  )), only a few neuroimaging studies have shown over-mentalizing-related brain activity in SZ ( ,  ,  ). Finally, our exploratory analyses comparing dimensional constructs of social deficits with MTR activity showed diagnosis-specific relationships. Specifically, only patients with ASD showed that MTR activity modulation was associated with social communication deficits in bilateral TPJ and MPFC. Additionally, only in SZ was MTR activity in the PrC associated with the reported tendency to fantasize (i.e., the ability to imaginatively identify oneself with the feelings and actions of fictitious characters ( )). Thus, although our main results suggest shared MTR neural deficits between ASD and SZ in DMN regions, our exploratory analyses potentially point to diagnostic-specific underlying symptom mechanisms, corresponding to either behaviorally observed social deficits (ASD) or perceived affinity to fantasize (SZ). 

Our work has been motivated by the current shift in psychiatric research, as exemplified by the RDoC initiative, from emphasizing categorical symptom-based clinical nosology (e.g. DSM-based diagnosis) to exploring dimensional, overlapping constructs that span the range from healthy individuals to individuals with severe psychiatric illnesses ( ). Despite significant research efforts devoted to identifying consistent and valid biological biomarkers for categorical symptom-based clinical disorders to develop objective diagnostic tests and individualized treatments based on neural mechanisms, success has been elusive. In contrast, RDoC emphasizes the heterogeneity within and similarities between clinical diagnoses, taking into account dimensional constructs, such as emotional, neurocognitive, and social cognitive functions. Several groups have taken this approach   within   diagnostic group or symptom category, such as the psychosis spectrum ( ), anxiety disorders ( ,  ) and ASD ( ), as well as   between   distinct diagnostic groups, e.g. ASD-SZ ( ,  ,  ) and ASD-ADHD ( ). Notably, the RDoC approach has been criticized as not fully validated, nor proven superior to clinical nosology systems in improving clinical understanding and practice ( ). Our results suggest that rather than being mutually exclusive, these two approaches might capture different aspects of associations between symptoms/behaviors and neural disease mechanisms. This conclusion is in accord with recent work in anxiety disorders ( ,  ). Further research is required to elucidate the relative significance of categorical vs. dimensional biological markers to the diagnosis, etiology, and treatment of psychiatric disorders. 

Behaviorally, our results confirmed previous reports of social deficit overlap between ASD and SZ ( ,  ). Both groups showed deficits in observed communication and social interactions (note that ASD-SZ differences on ADOS were expected as it was an inclusion criteria for ASD only), self-reported perspective-taking (i.e., mentalizing), although SZ-TD difference did not reach significance potentially due to self-report bias in this patient group ( ) and personal-distress (self-anxiety experiencing others’ distress), and identifying others’ emotions based on eyes expression. Importantly, although Domino is an interactive game, identified social deficits did not affect patients’ game engagement, strategies, or understanding the game’s rules. 

Our imaging analyses focused on DMN functional coherence. Although the DMN has been previously described as being active during task-negative activities (e.g., rest, daydreaming), multiple studies have shown its involvement in social cognitive processes, including mentalizing ( ,  ). Eight DMN ICs showed neural activity modulated by the opponent’s response, which we ascribe to mentalizing processes (i.e., MTR neural activity) ( ,  ,  ) covering all three hubs: MPFC, PCC/PrC and TPJ/STS. Of these, posterior and lateral regions had a significant group effect, driven by both patient groups, indicating decreased modulation of MTR activity compared to TD. 

As an observational tool, the ADOS quantifies integrated social behavior rather than a specific social process. Therefore, correlations of MTR activity in bilateral TPJ and MPFC with ADOS communication subscore in ASD agree with the suggested critical role of these regions in integrating information from multiple social cognitive processes, including social perception and mentalizing and information about self versus others ( ,  ,  ). Another posterior region, PrC, which was modulated by MTR activity in all groups, showed correlation with self-reported tendency to fantasize or daydream in SZ. This agrees with PrC’s suggested role in directing self-referential processes ( ). 

When comparing ASD and SZ each separately to TD, multiple studies have shown abnormal activations and functional connectivity (FC) in DMN during rest and social tasks ( ,  ), which have been concluded to largely overlap in meta-analyses ( ,  ). However, our results of similar MTR activity deficits in ASD and SZ are largely inconsistent with two fMRI studies also investigating the neural correlates of mentalizing in these groups concurrently.  ) used a cartoon mentalizing task with adolescents and young adults, and  ) used a visual perspective-taking task in adults. Both studies demonstrated diagnosis-specific activation and FC pattern alternations in TPJ/STS and MPFC regions. While   also reported significant correlations between impaired activation and PANSS-Positive scores, neither study reported any additional symptom (e.g., ADOS, PANSS-N) or social cognition (e.g., IRI, RMET) test correlations with brain activity. Thus, direct comparisons to our correlation results are not feasible. Notably, the TPJ/STS clusters reported in both studies are part of ICs 27 and 33 here, which in our study showed similar MTR activity deficits in SZ and ASD. Additionally, one of the frontal clusters that showed impaired activation in SZ in the Eack report (coordinate: 8, 40, 22) is part of IC 26 (dmPFC/ACC), which in our study was associated with MTR activity, but showed no significant group effect. These discrepancies can be attributed to the different tasks used and analysis methods. However, they can also potentially be explained by the notable heterogeneity seen in ASD and SZ ( ,  ), as even in our study, correlations of social-communication abilities with MTR activity were diagnosis-specific in bilateral TPJ, MPFC and PrC. 

Conversely, our results are mostly in agreement with a previous study of DMN in ASD and SZ that used resting state data. Using multivariate pattern analysis (MVPA), Chen et al. ( ) demonstrated shared impairments in PCC/PrC, right angular gyrus (part of TPJ) and a couple of PFC areas. In contrast, left angular gyrus and vMPFC and few PCC/PrC sub-regions showed diagnosis specific deficits. Additionally, DMN and salience network (SN) shared deficits were associated with ADOS social interaction subscales in ASD (not available for SZ). Our study showed correlation of MTR activity in ASD with the ADOS communication subscale, but not the ADOS social interaction subscale. This inconsistency might be explained by different analysis methods, and inclusion of SN deficits in Chen’s analyses. However, both studies indicate association between shared DMN deficits and observed social communication behaviors in ASD, suggesting a similar neural mechanism underlying these impairments. Notably, Chen et al. also did not demonstrate an association between DMN deficits and PANSS scores in SZ, suggesting dissociation between DMN deficits and psychotic symptoms both during rest and a social task involving mentalizing. Alternative fMRI tasks tapping into psychotic symptoms, such as hallucinations and delusions, might specifically be required to delineate their relationship to MTR activity modulation in the DMN. 

We note a minor discrepancy between our previous work in TD ( ) and current results, with the former showing five, as oppose to eight, DMN ICs with significant MTR activity. The discrepancy arises from three additional MPFC ICs (26, 35 and 38) showing this effect in the current sample. These three ICs overlap with dmPFC (current study IC 40, previous study IC 64) a default-mode subnetwork which showed significant MTR activity modulation in both studies. This discrepancy might indicate less specific MTR modulation of activity in the MPFC in the current sample due to different sample characteristics, the previous sample being older (range = 17–60), and including more females (~55% vs. 27%), as associations have been reported between DMN connectivity and aging, including in relation to social cognition and gender ( ). Our current sample’s narrow age range and small number of females preclude direct testing of these effects. We should also note that we expected greater MTR activity modulation in the DMN for human versus computer opponent for the   show   versus   no-show   contrast but did not find any such differences. We observed a similar pattern in our previous study ( ) and theorized that this lack of opponent-type differences is due to possible participant attribution of social reasoning to computers, also known as Computers-Are-Social-Actors (CASA) paradigm (see ( )). 

### Study limitations 
  
Our study has several limitations. First, sample size is relatively small and larger replication studies are essential. Second, the groups did not match on age and IQ, both shown to be related to social cognition and functioning ( ), and controlling for these parameters might not fully account for their effect. Third, medication effects on group differences in MTR activity in the DMN were not ruled out; however, sensitivity analyses and group comparisons ( ) showed no associations between MTR (Δ  β  -weights) and medication, making this an unlikely confounder. Fourth, the no-show event, consistently showing less modulation of mentalizing activities ( ,  ), cannot be considered a truly non-social task event, because an opponent is still involved during this task event. However, no-show events, as comparatively neutral social stimuli, might be better posited conceptually to demonstrate greater “over-mentalizing” responses than physical (non-social) task events used in other studies ( ,  ). Lastly, the mentalizing network might be modulated by activity in other networks in the brain, thus future studies should explore additional cognitive domains and neural networks, as well as examine whole brain activity. 



## Conclusions 
  
The current report describes the modulatory effect of mentalizing processes on the DMN during social interaction in individuals with ASD, SZ and TD. While both patient groups showed similar impaired MTR effect in posterior and lateral DMN regions, they differed in relationship between MTR activity and observed social communication behavior and reported tendency to fantasize. If replicated, these results support the importance of both clinical diagnosis and dimensional constructs related to social functioning in understanding the underlying neural mechanism of social deficits in ASD and SZ. 


## CRediT authorship contribution statement 
  
 Christopher J. Hyatt:   Writing - original draft, Writing - review & editing, Formal analysis, Methodology, Software.   Vince D. Calhoun:   Writing - original draft, Writing - review & editing, Resources, Methodology, Software.   Brian Pittman:   Formal analysis.   Silvia Corbera:   Writing - original draft, Resources.   Morris D. Bell:   Writing - original draft.   Liron Rabany:   Formal analysis.   Kevin Pelphrey:   Resources.   Godfrey D. Pearlson:   Writing - original draft, Conceptualization, Resources.   Michal Assaf:   Writing - original draft, Writing - review & editing, Conceptualization, Supervision, Project administration, Funding acquisition. 

 ## Data availability statement

The data that support the findings of this study are available at the National Database for Autism Research (NDAR). </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-65'>
<h2>65. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/20371509/' target='_blank'>20371509</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Empathic brain responses in insula are modulated by levels of alexithymia but not autism</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Brain</p>
<p><strong>Publication Year:</strong> 2010</p>
<p><strong>DOI:</strong> 10.1093/brain/awq060</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/2859151/' target='_blank'>2859151</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study uses task-based fMRI (empathy-for-pain) addressing social processing (empathy/perception of others’ pain). It includes a healthy control group of adults (ages 19–63) with results reported separately (group-specific correlations in anterior insula). Although a priori ROI analyses were performed, the authors also report whole-brain analyses (Supplementary Table 1 and whole-brain contrasts with reported coordinates) and group comparisons outside the ROI. Thus all inclusion criteria are met: social-related fMRI task, healthy adult participants within 17–65, and whole-brain results are presented (in addition to ROI analyses). No exclusion criteria are violated.</p>
<p><strong>Fulltext Confidence:</strong> 0.92</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Difficulties in social cognition are well recognized in individuals with autism spectrum conditions (henceforth ‘autism’). Here we focus on one crucial aspect of social cognition: the ability to empathize with the feelings of another. In contrast to theory of mind, a capacity that has often been observed to be impaired in individuals with autism, much less is known about the capacity of individuals with autism for affect sharing. Based on previous data suggesting that empathy deficits in autism are a function of interoceptive deficits related to alexithymia, we aimed to investigate empathic brain responses in autistic and control participants with high and low degrees of alexithymia. Using functional magnetic resonance imaging, we measured empathic brain responses with an ‘empathy for pain’ paradigm assessing empathic brain responses in a real-life social setting that does not rely on attention to, or recognition of, facial affect cues. Confirming previous findings, empathic brain responses to the suffering of others were associated with increased activation in left anterior insula and the strength of this signal was predictive of the degree of alexithymia in both autistic and control groups but did not vary as a function of group. Importantly, there was no difference in the degree of empathy between autistic and control groups after accounting for alexithymia. These findings suggest that empathy deficits observed in autism may be due to the large comorbidity between alexithymic traits and autism, rather than representing a necessary feature of the social impairments in autism. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (45498 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
In recent years, the field of social neuroscience has made rapid progress in elucidating the neuronal basis of our capacity to understand mental states such as the thoughts and feelings of others. According to recent neuroscientific models (Decety and Jackson,  ; Blair,  ,  ; Decety and Grèzes,  ; de Vignemont and Singer,  ; Singer,  ; Singer and Lamm,  ), at least two different routes to the understanding of other minds can be distinguished: our ability to understand the abstract beliefs and intentions of others, which is referred to as Theory of Mind, cognitive perspective taking or mentalizing (Premack and Woodruff,  ; Frith and Frith,  ) and our ability to share the feelings of others, which is referred to as empathy (Wispé,  ; Eisenberg and Strayer,  ; Eisenberg and Fabes,  ; Eisenberg,  ; Hoffman,  ; Preston and de Waal,  ; Singer   et al.  ,  ,  ; Blair,  ; Decety and Lamm,  ; de Vignemont and Singer,  ; Keysers and Gazzola,  ). Empathy in turn involves at least two major components: an affective component, which allows us to share the feelings of others, and a cognitive component, which is related to our capacity for self-other distinction. When we empathize, we vicariously experience the emotional state of another person, realizing that what we are feeling is not our own emotional state but that of the other person (e.g. Eisenberg,  ; Decety and Lamm,  ; de Vignemont and Singer,  ). 

Even though empathizing and Theory of Mind are usually simultaneously engaged in social cognition, recent imaging studies have suggested that the two postulated routes to understanding others rely on distinct neural networks. Theory of Mind has been mainly linked to activity of the medial prefrontal cortex, the superior temporal sulcus and the adjacent temporoparietal junction (for a review see Frith and Frith,  ; Saxe,  ; Saxe and Baron-Cohen,  ; also Mitchell   et al.  ,  ; Mitchell,  ). In contrast, our ability to empathize with other people’s emotional states (such as disgust or pain) activates parts of those neuronal networks that are involved when the emotional states are experienced by the self. Thus, activation of brain areas relevant for emotion processing such as somatosensory, insular and anterior cingulate cortices have been observed during empathy (Carr   et al.  ,  ; Wicker   et al.  ,  ; Keysers   et al.  ,  ; Morrison   et al.  ,  ; Singer   et al.  ,  ,  ,  ; Jackson   et al.  ,  ,  ; Jabbi   et al.  ,  ). The most robust evidence for such shared networks in empathy stems from a multitude of studies on empathy for pain. These suggest the necessary involvement of anterior insula and, less consistently, the anterior cingulate cortices when people empathize with the suffering of others (Morrison   et al.  ,  ,  ; Singer   et al.  ,  ,  ,  ; Jackson   et al.  ,  ,  ; Cheng   et al.  ,  ; Gu and Han,  ; Lamm   et al.  ,   , b  ; Saarela   et al.  ,  ). More generally, insular cortex, also called ‘interoceptive cortex’, has been shown to be involved in mapping internal bodily and subjective feeling states (Damasio,  ; Craig,  ,  ,  ; Critchley   et al.  ,  ,  ; Singer   et al.  ,  ). These findings have led to the suggestion that cortical representations underlying the representation of feeling states in the self also underlie our ability to share the emotional state of the other (so-called ‘shared-network’ models). 

Further evidence speaking to the existence of multiple and dissociable neural networks which underlie different socio-cognitive abilities comes from studies of patients with specific social disorders such as psychopathy or autism spectrum conditions. Psychopaths, for example, seem to have an impaired ability to empathize, but not an impaired ability to understand other people’s intentions and goals, a pattern reflected in the oft-reported Machiavellian nature of psychopaths (Blair,  ,  ). Conversely, individuals with autism spectrum conditions have a general deficit in the social domain, with evidence for reduced Theory of Mind (see Frith and Happé,   for a review) and reduced activity of the brain network associated with this mentalizing capacity (see Frith and Frith,   for a review). In addition, individuals with autism spectrum conditions have frequently been characterized as lacking in empathy (Gillberg,  ; Shamay-Tsoory   et al.  ,  ; Baron-Cohen and Wheelwright,  ; McIntosh   et al.  ,  ; Lombardo   et al.  ,  ; Minio-Paluello   et al.  ,  ). Baron-Cohen ( ) argues that individuals with autism spectrum conditions are best described as being low on empathizing (a construct which includes both cognitive perspective taking and empathy) and high on systemizing (a construct described as the drive to analyse or construct systems). In support of this characterization, individuals with autism spectrum conditions score lower on the Empathy Quotient (Baron-Cohen and Wheelwright,  ; Johnson   et al.  ,  ), which assesses the self-reported capacity to take another person’s mental perspective as well as the capacity to share their feelings. Further evidence is provided by reduced inhibition of corticospinal excitability in individuals with autism spectrum conditions when they observe a painful stimulus being applied to another (Minio-Paluello   et al.  ,  ) and lower self-reported empathy in autism spectrum condition populations on empathy questionnaires such as the Interpersonal Reactivity Index (IRI: Davis,  ; Lombardo   et al.  ,  ; however, see Rogers   et al.  ,   and Dziobek   et al.  ,   for conflicting findings). Furthermore, when children with autism were shown vignettes depicting other children experiencing various emotions, they reported less emotional empathy (matching emotional states) with the characters depicted in the vignettes (Yirmiya   et al.  ,  ). 

The claim of a global empathy deficit in autism spectrum conditions does not always reflect, however, the more detailed distinction made between our capacities to mentalize and to empathize. For example, a test widely used in autism research as a marker for empathy is the ‘reading the mind in the eyes test’ (Baron-Cohen   et al.  ,  ,  ,  ). However, this test does not directly assess emotional responses as it requires one to infer the expressed mental state from the eye region of emotional facial expressions, but does not directly measure the vicarious emotional response elicited by the expression. 

A further, important complication with the ‘empathy-deficit’ characterization of autism spectrum conditions is the high comorbidity between autism spectrum conditions and alexithymia. Alexithymia has been described as a subclinical phenomenon marked by difficulties in identifying and describing feelings and difficulties in distinguishing feelings from the bodily sensations of emotional arousal (Nemiah   et al.  ,  ). Alexithymia is thought to characterize 10% of the general population (Linden   et al.  ,  ; Salminen   et al.  ,  ). However, although neither a necessary nor sufficient feature of autism spectrum conditions, recent studies have found severe degrees of alexithymia in ∼50% of individuals with autism spectrum conditions, with the majority showing slight or severe impairments (Hill   et al.  ,  ; Berthoz and Hill,  ; see also Lombardo   et al.  ,   and Silani   et al.  ,  ). Thus, it is unclear whether the empathy deficit reported in individuals with autism spectrum conditions is a result of the autism spectrum condition, or whether it is a result of comorbid alexithymia. Indeed, a previous study suggests that the lack of empathy in autism spectrum conditions is a function of interoceptive deficits associated with alexithymia rather than a function of autism spectrum conditions   per se   (Silani   et al.  ,  ). Silani   et al.   showed that the degree to which participants were able to understand their own emotions (i.e. their degree of alexithymia) was correlated with activity in the anterior insula during an interoceptive task (Silani   et al.  ). Importantly, the relationship between participants’ self-reported degree of alexithymia, and activity in the anterior insula when introspecting on their emotions, was the same for both the autism spectrum conditions and control groups. Participants with autism spectrum conditions but without alexithymia showed normal activity in the anterior insula during interoception, suggesting that they were unimpaired in understanding their own emotions. Furthermore, participants’ self-reported degree of alexithymia, and activity in the anterior insula when introspecting on emotion, were correlated with scores on a classical self-report measure of trait empathy (Davis,  ). 

The association between alexithymia and empathy is predicted by the previously described ‘shared network’ models of empathy: these models suggest that the networks responsible for processing emotions in the self are the same networks used to represent the emotions of others. Thus, a difficulty representing one’s own emotions would result in a deficit in representing others’ emotions (e.g. Singer   et al.  ,  ,  ). The findings of Silani   et al.   ( ) provide initial support for the hypothesized role of the anterior insula in alexithymia and empathy and suggest that degree of empathy within individuals with autism spectrum conditions is associated with their degree of alexithymia. However, Silani   et al.  ’s ( ) study leaves at least two crucial questions unanswered. As the study included only a self-reported measure of empathy without testing empathy directly, it could only show that alexithymia was associated with the degree to which individuals with autism spectrum conditions were consciously aware of their empathic response. As alexithymia is a deficit in identifying and describing one’s own emotion, it is possible that the alexithymic individuals with autism spectrum conditions did have an empathic reaction, but were unable to identify and therefore report this reaction. 

The second question left unanswered by Silani   et al.  ’s ( ) study is whether there is a general empathic deficit associated with autism spectrum conditions that is not explained by alexithymia; that is, whether even non-alexithymic individuals with autism spectrum conditions show reduced empathy. 

Therefore, in the present study, we aimed to test empathy in individuals with autism spectrum conditions directly and to determine whether any deficits are due to their autism spectrum condition and/or a result of the increased level of alexithymia in this group. We therefore tested empathy in a group of individuals with autism spectrum conditions selected to ensure a wide distribution of alexithymia scores and a matched control group (of individuals without autism spectrum conditions) with the same wide distribution of alexithymia scores. Significantly, we tested empathy in the domain of pain using a well-established empathy-for-pain functional magnetic resonance imaging (fMRI) paradigm that has been shown to involve activation of the interoceptive cortices but not the cognitive perspective taking network (Singer   et al.  ,  ,  ,  ). Therefore, we contend that this task provides a purer measure of empathy than more commonly used tests and is minimally confounded by mentalizing. Furthermore, this paradigm has the advantage of assessing empathy   in vivo   by measuring the empathic brain responses of participants while their partners or friends receive pain. Thus, the social emotions are tested in a real social context. Importantly, the use of symbolic cues instead of pictorial material helps to overcome the significant methodological problems associated with testing empathy using pictures of emotional facial expressions in autism spectrum condition populations. Several studies have found that individuals with autism spectrum conditions show decreased attention to the face, and particularly to eye regions of the face, in comparison to non-autism spectrum conditions control groups (Boucher and Lewis,  ; Klin   et al.  ,  ,  ; Blair   et al.  ,  ) and may also have problems recognizing emotional facial expressions (Howard   et al.  ,  ; Humphreys   et al.  ,  ; see Adolphs   et al.  ,   for conflicting findings). Using the present paradigm, any empathy deficit seen in the autism spectrum conditions group cannot be due to reduced attention to the eye regions, which may be crucial in signalling the pain of the other when pictures of facial emotion are presented (Adolphs,  ,  ), or a failure in interpreting the emotional state of the other. Finally, the present paradigm allows for the assessment of empathic responses without requiring verbal reports from participants, a feature which may facilitate finding empathic responses in alexithymic individuals and those with autism spectrum conditions. 

Based on the findings of Silani   et al.   ( ), we hypothesized that autism spectrum conditions do not result in an empathy deficit   per se  . Rather, we hypothesized that empathy-related activity will vary as a function of the degree of alexithymia in both groups and be associated with activation in insular cortices. 


## Materials and methods 
  
### Participants 
  
This study required an equal distribution of high and low alexithymic participants in control and autism spectrum condition groups. As the prevalence rate of alexithymia differs in autistic and normal control populations (Hill   et al.  ,  ; Tani   et al.  ,  ), we pre-screened a larger sample of participants with the 20-item Toronto Alexithymia Scale (TAS-20) (Bagby   et al.  ,  ) as a measure of alexithymia to reach our final sample of 18 male participants with autism spectrum conditions and 18 male controls who were matched on alexithymia scores, age and IQ. Two-sample   t-  tests confirmed that the groups were not significantly different in terms of alexithymia (autism spectrum condition mean ± SD = 57.2 ± 11.8, range 37–80; control mean ± SD = 50.3 ± 14.5, range 27–72), age (autism spectrum condition mean ± SD = 34.6 ± 13.3, range 19–60; control mean ± SD = 35.0 ± 12.8, range 22–63), or IQ (autism spectrum condition mean ± SD = 115.8 ± 14.6, range 91–140; control mean ± SD = 118.8 ± 11.7, range 103–149), whereby IQ was assessed with the Wechsler Adult Intelligence Scale (WAIS®-III UK; Wechsler,  ) (  and  ). A Kolmogorov–Smirnov goodness of fit test confirmed that both samples are normally distributed on the TAS (autism spectrum condition   D   = 0.117, exact   P   = 0.942; controls   D   = 0.169, exact   P   = 0.624).
   
Demographic characteristics and pain thresholds 
      
Questionnaire data 
    

All participants in the autism spectrum condition group were high functioning and had previously received a diagnosis of autism or Asperger’s Syndrome from an independent clinician according to the standard Diagnostic and Statistical Manual of Mental Disorders-IV criteria (American Psychiatric Association,  ). Fifteen participants had received a diagnosis of Asperger’s Syndrome and three of autism. In addition to the clinical diagnosis, we used the Autism Diagnostic Observational Schedule (ADOS-G; Lord   et al.  ,  ) to characterize the current level of functioning for the autism spectrum conditions group further ( ). On this measurement, eight participants met ADOS criteria for autism and five participants met criteria for autistic spectrum disorders. Four participants scored above the cut-off point only in one of the two subscales and one participant was below the cut-off point in both subscales (see ‘Discussion’ section).
   
Diagnosis, ADOS-G and alexithymia scores 
    

Control participants did not exhibit autistic features and were screened for any pre-existing neurological or psychiatric disorders using a questionnaire/interview. All participants gave their informed consent to participate in the study, which was approved by the Local Ethics Committee and conducted in accordance with the ethical standards laid down in the 1964 Declaration of Helsinki. 

The empathy-for-pain paradigm used in this study (e.g. Singer   et al.  ,  ) required participants to bring another individual (henceforth ‘partner’). In contrast to the original paradigm used by Singer   et al.   ( ), the participants’ partner was not necessarily their romantic partner. As the majority of the participants with autism spectrum conditions were not in a romantic relationship, participants were asked to bring a person with whom they had a significant relationship (family member, friend or carer). A total of 36 participant pairs took part in the experiment. Five participants in the autism spectrum condition group came with their romantic partner, nine with a family member and one with a close friend. Three participants in the autism spectrum condition group were not able to bring a partner so they completed the experiment with a researcher from the Institute of Cognitive Neuroscience, UCL, with whom they had spent considerable time during previous testing sessions and thus had developed a friendly relationship. Ten of the control group came with their romantic partner, two with family members and five with friends. One participant from the control group was not able to bring a partner and was therefore also matched with a researcher with whom he had spent time during pre-testing. Comparison of the results of previous studies using this paradigm (Singer   et al.  ,  ,  ) suggests that empathy towards romantic partners may be higher than towards relative strangers. It is possible that the autism spectrum condition group would therefore exhibit less empathy as a result of their partner profiles, even in the absence of any true empathy deficit. Accordingly, the Relationship Closeness Inventory (Berscheid   et al.  ,  ) was used to assess the quality and duration of the relationship between the participants and their respective partners. Analysis of the Relationship Questionnaire did not reveal any significant difference between the autism spectrum condition and control groups [  t  (24) = −0.8;   P   > 0.05] or a significant correlation with degree of alexithymia (autism spectrum condition:   r   = 0.239,   P   > 0.05; control:   r   = 0.119,   P   > 0.05), suggesting that any observed differences in empathic brain response were not due to a selection bias in the quality and duration of the relationship between the participant and their partner. As a final check, scores from the Relationship Closeness Inventory were entered into the analysis (reported below) as a covariate. Inclusion of the covariate did not change the reported results, and it was also not predictive of empathy-related brain activity in either the autism spectrum condition or control groups. It should be acknowledged that the validity of this analysis assumes that participants in both the autism spectrum conditions and control groups were equally able to complete the Relationship Closeness Inventory. At present this assumption has not been empirically tested. We contend, however, that the available data suggest that the different partner profiles between the autism spectrum condition and control groups do not explain the observed results. 


### Questionnaire measures 
  
In addition to the brain measures, we also assessed individual differences in empathy with the IRI (Davis,  ) and validated the TAS-20 alexithymia measure using an alternative alexithymia scale, the Bermond-Vorst Alexithymia Questionnaire (BVAQ; Vorst and Bermond,  ). 


### Experimental paradigm and procedure 
  
In this study, we adopted the same procedure as described by Singer   et al.   ( ). In brief, before entering the scanner room, participants were familiarized with the experimental task and individual pain thresholds were determined for each participant pair (see Singer   et al.  ,   for a full description of the procedure). Pain stimulation was obtained by passing electrical current through a bipolar concentric surface electrode placed on the dorsum of the left hand of the participants and on the dorsum of the right hand of their partners (square pulse waveform, 100 Hz, 4 ms pulse length, 1 s duration). 

After determination of individual pain thresholds, participants were placed into the scanner and the partner was seated next to the scanner. The participant’s left hand and the partner’s right hand were placed on a tilted board which enabled the participant to see both hands with the help of a mirror system. Coloured arrows indicating the person who was to receive the next painful stimulation were projected onto a large screen placed in front of the participant. Stimulation intensity was indicated by the brightness of the arrow, light arrows indicating non-painful low stimulation and dark arrows indicating painful high stimulation. After each trial, participants rated the subjective level of unpleasantness on an analogue scale ranging from −10 (very unpleasant) to +10 (very pleasant) by moving a cursor along the scale with their right index and middle fingers. Each trial consisted of the presentation of an anticipatory cue (the arrow) which was followed after 3.5 s by a small circle of the same colour centred on the screen indicating the beginning of the electrical stimulation. After 2 s, the rating scale appeared on the screen for a total duration of 4 s. In order to reduce socially desirable responding when the participant rated how unpleasant they found their partner’s pain, the rating scale was presented in a position on the screen which was not visible to the partner. The invisibility of the participant’s response to their partner was emphasized to each participant. The scanning phase consisted of two 9 min sessions and a 10 min structural scan. Each session consisted of 20 trials for each condition (painful high stimulation and non-painful low stimulation) and 50% null events where only a fixation cross was presented. The two sessions were blocked with respect to the recipient of the stimulation. During the first session only the partner was stimulated (‘other’ condition) and during the second session only the participant was stimulated (‘self’ condition). Throughout both sessions the only part of the partner’s body viewable to the participant was the partner’s hand. 


### Imaging data acquisition 
  
MRI brain images were acquired with a 1.5 Tesla system (Siemens Sonata). Functional whole brain data were obtained using a T * echoplanar sequence sensitive to blood oxygen level dependent contrast (44 slices, 3 mm thickness, gap 0.75 mm, echo time 90 ms, repetition time 3960 ms per volume). To reduce inhomogeneities in amygdala and orbitofrontal cortex, a sequence with axial slices tilted by 30° and a flip angle of 90° was used (Deichmann   et al.  ,  ). The functional data were acquired in 2 sessions; the first six volumes of each session were discarded to allow for T  equilibration effects. Stimulus presentation began after the sixth volume. A total of 308 full-brain volumes for each participant were acquired. Structural images were obtained with a T  sequence using a phased-array head coil at the end of the two functional sessions. 


### Imaging data analysis 
  
fMRI data were analysed using Statistical Parametric Mapping (SPM)-5 (Wellcome Department of Imaging Neuroscience, London;   www.fil.ion.ucl.ac.uk/spm  ). During preprocessing, functional images were realigned to the first volume, spatially normalized to a standard template with a resampled voxel size of 3 × 3 × 3 mm, and smoothed using a Gaussian kernel width of 10 mm full width at half maximum (6 mm at the first level, 8 mm at the second level) (Friston   et al.  ,  ). After preprocessing, functional images were analysed in an event-related fashion (Worsley and Friston,  ), using the general linear model (Friston   et al.  ,  ). 

The paradigm is based on a 2 × 2 × 2 factorial design with within-subject factors of ‘Pain’ (pain versus no-pain) and ‘Target’ (self versus other) and a between-subjects factor of ‘Group’ (autism spectrum conditions versus control). To create regressors of interest, each condition was modelled by convolving a delta function at each trial onset (presentation of the anticipatory cue) and at each rating onset (presentation of the rating scale) with a canonical haemodynamic response function over the duration of the event (5.5 and 4 s, respectively). Residual effects of head motion were corrected for by including the six estimated motion parameters for each participant as regressors of no interest. Contrast images were then calculated by applying appropriate linear contrasts to the parameter estimates for the regressors of interest. 


### Region of interest analyses 
  
For our main analysis, we chose a region of interest approach (ROI) based on two independent empathy-for-pain studies performed previously with a similar paradigm in male populations only (Singer   et al.  ,  ,  ). The ROIs were formally defined by reanalysing functional data from these two previous studies to identify areas that were more active in response to high pain than low pain in the ‘other’ condition in conjunction with high versus low pain in the self condition. Thus, contrast images for the contrast Other High Pain–Other Low Pain and Self High Pain–Self Low Pain were entered into a second-level random effects model using SPM5. An ANOVA, thresholded at   P   < 0.05, familywise error corrected for the whole brain, identified a cluster in left anterior insula (centre of mass −36, 33, 3; volume 108 mm ; max/min   x   − 39/−33, max/min   y   30/33, max/min   z   3/3) that defined the ROI. A statistical threshold of   P   < 0.05 was used for all ROI analyses. 

In order to investigate brain responses outside the   a priori   ROIs, additional whole brain analyses were performed. Results of these additional analyses are reported in   Supplementary Table 1   at a threshold of   P   < 0.001, uncorrected. 



## Results 
  
### Questionnaires 
  
As expected, the two questionnaire measures of alexithymia (TAS and BVAQ) were highly correlated (autism spectrum condition:   r   = 0.772,   P   < 0.01; control:   r   = 0.703,   P   < 0.01), suggesting that individual differences in alexithymia could be reliably measured in both groups. As in our previous study (Silani   et al.  ,  ), a significant negative correlation was found between scores on the alexithymia questionnaire (TAS-20) and scores on the IRI (  r   = −0.422,   P   < 0.05), suggesting a relationship between degree of alexithymia and self-reported empathy. An independent samples   t  -test revealed that the autism spectrum condition and control groups did not differ significantly on self-reported trait empathy as measured by the IRI [  t  (30) = −1.6;   P   > 0.05]. 


### Stimulus sensitivity and behavioural ratings of unpleasantness 
  
In order to test for differences in stimulus sensitivity between groups, the amplitude of the stimulation measured in mA (i.e. the participants’ high and low pain thresholds) was entered in a repeated measures ANOVA with a within-subjects factor of Pain (high versus low pain) and a between-subjects factor of Group (autism spectrum conditions versus control). The analysis revealed a main effect of Pain [  F  (1,29) = 37.4,   P   < 0.001], but the main effect of Group was not significant [  F  (1,29) = 1.24,   P   > 0.05] ( ).
   
Pain stimulation thresholds and pain ratings 
    

In order to corroborate the subjective nature of the pain thresholding procedure, we performed an ANOVA on the unpleasantness ratings for low and high pain stimulation during the self and the other conditions with two within-subjects factors (Pain: pain versus no-pain; Target: self versus other) and one between-subjects factor (Group: autism spectrum condition versus control). The ANOVA revealed a main effect of Pain [  F  (1,29) = 80.2,   P   < 0.001] and a significant interaction between Pain and Group   F  (1,29) = 7.49,   P   < 0.011]. Follow-up   t  -tests revealed that the groups gave significantly different unpleasantness ratings for the low pain condition {both for the self [  t  (29) = −2.7;   P   < 0.01, unpaired   t  -test] and the other [  t  (29) = −2.4;   P   < 0.05, unpaired   t  -test]}, but not for the high pain condition. Inspection of the mean ratings shows that the autism spectrum condition group judged the unpleasantness of the low pain stimulation to be close to zero, while the controls rated the low pain as slightly pleasant ( ). 

Interestingly, a significant correlation was not found between participants’ self-reported level of alexithymia and ratings of unpleasantness in either the self or the other condition [self condition: autism spectrum condition:   r   = −0.127,   P   > 0.05; control:   r   = −0.164,   P   > 0.05; other condition: autism spectrum condition:   r   = −0.055,   P   > 0.05; control:   r   = 0.153,   P   > 0.05]. These results are in line with the findings of our previous study (Silani   et al.  ,  ), in which behavioural ratings did not differ as a function of alexithymia in spite of clear differential brain responses in anterior insula for high and low alexithymic participants during interoception on emotions. Although speculative, this finding may suggest that alexithymic individuals are able to use a cognitive rule, perhaps based on social desirability, to make their response when tasks are as simple as those used in these studies. 


### Functional imaging results 
  
To determine whether the often-reported empathy deficit in autism spectrum conditions is due to the alexithymia comorbidity within this group or to the presence of an autism spectrum condition, we sought to investigate: (i) whether empathic brain responses were correlated with degree of alexithymia in autism spectrum condition and control groups; (ii) whether the relationship between degree of alexithymia and empathic brain response varied as a function of autism spectrum condition diagnosis; and (iii) whether the autism spectrum condition and control groups exhibited differential levels of empathic brain activity after accounting for levels of alexithymia. 

To perform these analyses, mean contrast values in the ROI were extracted using the MaRsBaR toolbox (Brett   et al.  ,  ) for the contrast High Pain in the Other–Low Pain in the Other group. These values served as an index of empathic brain response and were entered as the dependant variable into regression models including TAS-20 scores for each group separately, and in combined models. 

Our first analysis revealed that mean activity in the left anterior insula was significantly negatively correlated with TAS scores in both groups ( ). The higher the self-reported degree of alexithymia, the lower the empathy-related activity in this region when the partner received pain (autism spectrum condition:   r   = −0.506,   P   < 0.05; control,   r   = −0.536,   P   < 0.05).
   
Mean activation levels (parameter estimates) of the voxels lying in the left anterior insula [–36 33 3] defined by the independent mask (see ‘Materials and methods’ section for details about ROI analyses) during empathy-related conditions (Pain–No pain in other) are significantly correlated with individual differences in alexithymia as measured by the TAS in both autism spectrum condition (ASD) (red dots) and control (blue dots) participants. The line represents the linear best fit. All correlations are significant at the   P   < 0.05 level. 
  

Secondly, in order to investigate whether the relationship between empathic brain responses and alexithymia varies as a function of group, we performed a Potthoff ( ) analysis to test the null hypothesis of no difference between groups in the correlation coefficients, slopes, and intercepts of the two regressions. This analysis revealed that neither the degree of association (  r  ) between activity in the anterior insula and alexithymia, nor the slope of the regression line, nor the intercept differed significantly between groups [  F  (2.32) < 1,   P   = 0.548,   t  (32) = −0.749,   P   = 0.459,   t  (32) = 0.919,   P   = 0.365, respectively]. 

Thirdly, in order to test for any group differences in empathic brain activity in the anterior insula independent of the degree of alexithymia, activity in the anterior insula was entered into an ANCOVA with Group (autism spectrum condition versus control) as a between-subjects factor and the TAS scores as a covariate. This analysis showed that the groups were not significantly different [  F  (1,35) < 1], indicating that there were no differences in empathic brain activity due to the presence or absence of an autism spectrum condition diagnosis after controlling for the degree of alexithymia. 

In subsequent analyses, we explored the validity of our ROI analyses using whole brain analyses. First, in order to replicate the typical pattern of empathic brain activation observed in previous empathy-for-pain studies and confirm the relationship between empathy and alexithymia, participants were divided into high and low alexithymic groups (median split low alexithymia, mean ± SD = 42.3 ± 8.2,   n   = 18 and high alexithymia, mean ± SD = 65.2 ± 5.8,   n   = 18) and activity in interoceptive cortices were compared (  Supplementary Table 1  ). As in previous studies (Singer   et al.  ,  ,  ,  ), pain-related empathic brain responses were identified by masking the contrast of painful versus non-painful trials in the other condition with the contrast of painful versus non-painful trials in the self condition. This procedure allows us to identify brain regions that are activated by both the processing of pain in the self and empathy for pain in the other (i.e. a shared pain network for the self and other). Consistent with our ROI analysis, the results of this analysis revealed peak activation in left anterior insula in the low alexithymic group (−33, 30, 0;   z   = 3.79,   P   < 0.001, uncorrected) and for the difference between low and high alexithymic groups (−33, 33, 0;   z   = 3.33,   P   < 0.001, uncorrected). 

We further tested for group differences between patients with autism spectrum conditions and control participants to guard against the possibility that empathic differences between the autism spectrum condition and control groups occur in areas outside the pre-defined ROI. This is especially pertinent as the ROIs were defined on the basis of a sample of individuals without an autism spectrum condition, and although one would expect that this would result in a relative ‘advantage’ for the control group in demonstrating empathic brain responses, it is important to test for empathic differences between groups across the whole brain. The contrast High Pain–Low Pain in the other, masked on High Pain–Low Pain in the Self, revealed that the only area in which the control group showed increased activity in response to pain in the other was in visual cortex (24 − 81 −9;   z   = 3.72,   P   < 0.001, uncorrected), which is not part of the typical pain matrix, nor a part of the empathy or Theory of Mind networks. 

A final analysis was conducted to investigate a possible concern with respect to the current study: that alexithymia scores are a proxy for symptom severity in autism spectrum conditions. If true, the present findings could be explained by hypothesizing that controlling for degree of alexithymia before testing for group differences in empathy causes all variance due to autism spectrum condition symptom severity to be removed. This would result in a spurious null result and a false conclusion of there being no empathy deficit in autism spectrum conditions after controlling for alexithymia. Such a possibility is made plausible by the inclusion of participants who, despite having received a clinical diagnosis of autism or Asperger’s Syndrome, do not meet ADOS-G cut-off in the sample of individuals with autism spectrum conditions. These individuals may raise the mean empathic brain response in the autism spectrum condition group and mask any differences in empathy due to diagnosis of an autism spectrum condition (if alexithymia scores are a proxy for autism spectrum condition symptom severity the corollary of this would also be true; highly alexithymic participants in the control group may also have high levels of autism spectrum condition symptoms). To guard against the possibility that any null effects observed in the data could be caused by overly inclusive diagnostic classification, or statistical covariance between ADOS scores and alexithymia scores, the ADOS scores were regressed against empathy-related brain data and alexithymia scores as measured by the TAS. ADOS scores were unrelated to these measures (all correlations   P   > 0.4). Inspection of scatterplots (  Supplementary Figs 1–3  ) showing the relationship between the ADOS and empathy-related brain data, TAS and BVAQ scores, reveals that it is not the case that participants with low ADOS scores are clustered at the extremes of the distributions of any measure. In addition, the relationship between alexithymia (TAS scores) and empathic brain responses was found in both the autism spectrum condition and control groups, who were matched for degree of alexithymia. Thus, it is unlikely that any of the observed effects are an artefact of inappropriate diagnosis, or a statistical artefact due to high covariance between autism spectrum conditions symptom severity and degree of alexithymia. 



## Discussion 
  
The main goal of this study was to test the widespread assumption that autistic spectrum conditions are associated with a general lack of empathy. In order to test for specific empathy deficits in autism spectrum conditions, we first provided a fine-graded distinction between two different capacities underlying social cognition: mentalizing ability (Theory of Mind) and empathic ability. Whereas autism has been shown to be associated with a deficit in Theory of Mind (see Frith and Happé,   for a review), it is much less clear whether individuals with autism spectrum conditions also suffer from interoceptive and empathy deficits. An earlier fMRI study focussing on interoceptive awareness in individuals with an autism spectrum condition with and without alexithymic symptoms (Silani   et al.  ,  ) suggested that it is the degree of alexithymia, which is frequently elevated in individuals with an autism spectrum condition, rather than the autism spectrum conditions   per se  , that is predictive of activation in interoceptive cortex (specifically, anterior insula), and therefore reduced levels of empathy. To test this hypothesis, we chose an empathy-for-pain paradigm that counteracts possible problems associated with the measurement of empathy in autistic populations (i.e. a deficit in facial emotion recognition, or reduced attention to the eye region of faces). 

The results of the present study confirm the main hypotheses that the degree of alexithymic traits assessed with the TAS-20 would be associated with the level of empathic brain activation in anterior insula when participants witnessed a close partner suffering pain. More importantly, this association was not significantly different for control and autism spectrum condition groups, and after accounting for degree of alexithymia, individuals with an autism spectrum condition were not different from control participants in terms of empathic brain responses in the ROI, or in the rest of the brain. These results suggest that it is not autism   per se  , but high levels of alexithymia (in both individuals with and without an autism spectrum condition diagnosis) that are predictive of reduced empathic brain responses. Note, however, that the present samples of control participants and patients with an autism spectrum condition are not representative with respect to their distribution of alexithymic traits within each group, as we aimed to achieve an equal distribution of alexithymic scores in both samples. Far higher rates of alexithymia are reported across those with autism spectrum conditions than in the typical population. Thus, if we were to replicate these findings in a representative sample of control and individuals with an autism spectrum condition, we would expect to observe weaker empathy-related brain activation in anterior insula in the autism spectrum condition group, reflecting the higher prevalence of alexithymia in the autism spectrum condition population. 

These results replicate previous findings of a crucial role for insular cortex in pain-related empathy (Morrison   et al.  ,  ,  ; Singer   et al.  ,  ,  ,  ; Jackson   et al.  ,  ,  ; Cheng   et al.  ,  ; Gu and Han,  ; Lamm   et al.  ,  ,  ; Saarela   et al.  ,  ). Thus, the activation observed in left anterior insula when participants empathized with their partners when they were suffering overlapped with coordinates of empathic brain responses in anterior insula described in previous empathy studies (Singer   et al.  ,  ,  ,  ). More importantly, we extended previous findings that showed modulation of empathic brain responses in insular cortices as a function of contextual appraisal and affective link (Singer   et al.  ,  ; Lamm   et al.  ,   , b  ; Hein and Singer,  ) to the domain of individual trait characteristics. Here we show that individual characteristics such as the ability to interocept upon one’s own emotions are also a modulatory factor for empathic brain responses. 

Taken together, the previous (Silani   et al.  ,  ) and the present findings suggest that people with interoceptive deficits reflected in high levels of alexithymia show reduced activation in insular cortices while interocepting on their own emotions as well as when empathizing with others who are feeling pain. In both studies, high correlations between an alexithymia scale (TAS-20) and a classical trait empathy scale (Davis IRI), were observed. This pattern of results is consistent with the notion that our ability to empathize relies on the same neural circuitries underlying our capacity to understand our own feeling states and that these capacities are intimately linked with functions of the anterior insula cortices (Singer   et al.  ,  ,  ). 

Studying individual differences in alexithymia within a population of individuals with an autism spectrum condition enabled us to obtain a more detailed picture of the social deficits observed in autism spectrum conditions. This picture illustrates the heterogeneity of individuals with an autism spectrum condition with regard to empathy deficits. Thus, not all individuals with an autism spectrum condition, but only a subgroup with interoceptive deficits, seem to be impaired on the empathic route to social cognition. This finding is in agreement with earlier research pointing to a large heterogeneity in cognitive profiles within the autistic populations (Pellicano   et al.  ,  ; White   et al.  ,  ,  ) and cautions against overgeneralization of deficits commonly attributed to autism spectrum conditions to every individual on the autistic spectrum. Despite this heterogeneity within individuals with autism spectrum conditions, it is clear that an outstanding research question in this area relates to the increased prevalence of high levels of alexithymia in this group compared to neurotypical individuals. 

Finally, these findings speak to the differentiation between Theory of Mind and empathy and point to a dissociation between these two streams of social cognition. Interestingly, analysis of the subscale scores from the Davis IRI (  Supplementary Table 2  ) support the previously-reported deficit in cognitive perspective taking in autism spectrum conditions (Frith and Happé,  ). The autism spectrum condition group reported significantly less perspective taking (see Rogers   et al.  ,   who reported a similar pattern of subscale scores). Demonstrations of a Theory of Mind deficit in autism spectrum conditions, together with intact empathy shown by the present study, support the suggestion that empathy and Theory of Mind are dissociable. It should be noted however, that Theory of Mind was not directly tested in the present study. Therefore, future research should focus on testing four groups of individuals, individuals with and without autism spectrum conditions with low and high degrees of alexithymia, using pure empathy and Theory of Mind tasks in order to test whether participants with an autism spectrum condition show Theory of Mind but not empathy deficits, and those with alexithymia empathy but not theory of mind deficits. Evidence for such a double dissociation would not only inform the development of clinical interventions tailored to the specific difficulties of these groups, but could also help us to obtain a more sophisticated picture of the different neural networks underlying social cognition in adults. 


## Funding 
  
The National Centre of Competence in Research (NCCR) for the Affective Sciences, Geneva, the University of Zurich (Research Priority Program on the Foundations of Human Social Behaviour), and the European Research Council under the European Community's Seventh Framework Programme (FP7/2007-2013)/ERC Grant agreement   n  °205557 EMPATHICBRAIN (to T.S.). In addition, it was funded by a Medical Research Council UK (Grant No. G9617036) (to U.F.), and by the Wellcome Trust. 


## Supplementary material 
  
 Supplementary material   is available at   Brain   online. 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-66'>
<h2>66. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/30615116/' target='_blank'>30615116</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> I See Your Effort: Force-Related BOLD Effects in an Extended Action Execution–Observation Network Involving the Cerebellum</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Cereb Cortex</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1093/cercor/bhy322</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/6373696/' target='_blank'>6373696</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This is an fMRI study of healthy adult participants (final N=12, mean age 26) that investigates perception/understanding of others’ actions (ability to infer others’ applied grip force), which fits the review construct “Perception and Understanding of Others.” The experiment uses whole-brain analyses (SPM12 voxel-wise GLM with parametric modulation; voxel-wise thresholds and cluster correction) and reports whole-brain results (and SUIT cerebellar analyses). Results for healthy participants are reported separately and no clinical-only group is used. Analyses are not restricted to ROIs. Therefore the paper meets all inclusion criteria: social-related fMRI task, healthy adult sample within the age range, and whole-brain results provided.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Action observation (AO) is crucial for motor planning, imitation learning, and social interaction, but it is not clear whether and how an action execution–observation network (AEON) processes the effort of others engaged in performing actions. In this functional magnetic resonance imaging (fMRI) study, we used a “squeeze ball” task involving different grip forces to investigate whether AEON activation showed similar patterns when executing the task or observing others performing it. Both in action execution, AE (subjects performed the visuomotor task) and action observation, AO (subjects watched a video of the task being performed by someone else), the fMRI signal was detected in cerebral and cerebellar regions. These responses showed various relationships with force mapping onto specific areas of the sensorimotor and cognitive systems. Conjunction analysis of AE and AO was repeated for the “0th” order and linear and nonlinear responses, and revealed multiple AEON nodes remapping the detection of actions, and also effort, of another person onto the observer’s own cerebrocerebellar system. This result implies that the AEON exploits the cerebellum, which is known to process sensorimotor predictions and simulations, performing an internal assessment of forces and integrating information into high-level schemes, providing a crucial substrate for action imitation. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (45878 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Social behavior is based on understanding the actions of others and predicting appropriate reactions and subsequent interactions. In this context, perceiving the force applied to objects by others is crucial for understanding their intentions, for predicting the success of self-generated actions, and for dynamic movement control in interactions. However, there is still debate over the question of whether, when observing someone else performing an action, we mirror the actual movement dynamics or simply its goals ( ;  ;  ;  ;  ;  ;  ). Understanding, through observation, the force involved in movements performed by others can prime the force imparted during subsequent action executions (AE) ( ). The achievement of a better understanding of how force is represented in observation could facilitate and improve the clinical application of action observation (AO) in neurorehabilitation ( ;  ;  ). Although AE and observation have been studied using several techniques ( ;  ;  ;  ;  ), the neuronal processes involved in mirroring the motor effort of others have still not been fully explored. 

The most renowned imitation learning hypothesis claims that “mirror neurons” are activated by observation of actions performed by others ( ) and that the brain simulates the observed action by using the motor system as a forward model ( ;  ;  ;  ;  ), recruiting hierarchically organized brain circuits ( ;  ). On a broader perspective, the brain has been proposed to include a “mirroring system” which can understand the intentions of others from observing movements (“body” reading) and a “mentalizing system” which can infer the intentions of others reconstructing hypothetical events (“mind” reading) ( ;  ). In this context, even though magnetic resonance imaging (MRI) does not allow neuronal populations to be studied directly, functional MRI (fMRI), thanks to the blood-oxygenation-level-dependent (BOLD) effect ( ), can be used to study neuronal activation during both execution and observation of actions. fMRI studies ( ;  ;  ;  ) support the notion that, during observation of a complex motor task, the AE network (AEN) and the AO network (AON) combine to form an action execution–observation network (AEON), which provides the neural infrastructure for imitation learning. Although the “core AEON” structures are the premotor cortex and a limited number of parietal and temporal cortical areas ( ), it is now clear that the AEON also comprises the supplementary motor area and the inferior frontal gyrus, as well as large sections of the somatosensory and occipitotemporal cortices ( ). Furthermore, the cerebellum and basal ganglia have also been suggested to play a role in an extended circuit underlying action understanding ( ), to the point that the cerebellum is now considered to play a role as an adaptive predictor in AO ( ). This idea derives from the general theory of cerebellar functioning, wherein the cerebellum is seen as a forward controller in behavioral schemes that concern the interaction of the body with the external world, instructing the cerebral cortex in a predictive manner ( ;  ;  ;  ;  ). Moreover, a growing body of evidence from both lesion and fMRI studies ( ;  ;  ;  ;  ) suggests that the cerebellum plays a crucial role in action–perception coupling, coordinating the application of an appropriate force and its timing to generate movement, and thus operating in a forward mode ( ;  ;  ). On these bases, it can be hypothesized that predicting how to move by observation entails processing of force and involves an extended AEON that includes the cerebellum together with a complex set of cortical areas. 

In the present study, aiming to identify the network involved in force perception, we exploited a paradigm that recently showed how a complex set of linear and nonlinear BOLD responses are elicited in several brain regions, including the cerebellum, when varying the force applied to an object ( ;  ;  ). We used this grip-force (GF) squeeze ball paradigm to assess whether: 1) the AON presents both linear and nonlinear BOLD-GF associations during observation of the squeeze ball task; 2) the AEN and the AON share a common neural substrate, corresponding to the extended AEON; and 3) regions identified as part of the AEON exhibit linear and nonlinear BOLD-GF associations. The results of this work indeed support the existence of force-related BOLD effects not only in AE but also in the extended AEON, which includes the cerebellum. 


## Materials and Methods 
  
### Subjects 
  
A total of 14 right-handed healthy volunteers (9 females) were initially recruited for this study. However, 2 participants were excluded from further analysis: one who failed to follow the task instructions and another who presented head motion (translation in the   z   direction) >2 mm. The final sample thus comprised 12 subjects (7 females; mean age 26 ± 3.5 years). The handedness of each subject was evaluated using the Edinburgh handedness scaling questionnaire ( ); the mean laterality index was 82 (±16). All participants had normal or corrected-to-normal vision. No subject had a history of neurological or psychiatric disease. All the participants received a detailed explanation of the experimental procedures before participating in the experiment. The local research and ethics committee approved the study and all participants gave their written informed consent. 


### MRI Scanner and Scanning Sequences 
  
A 3 T Philips Achieva MR scanner (Philips Healthcare, Best, The Netherlands) with a 32-channel head coil was used to perform a 3D T1-weighted anatomical scan and 3 T2*-weighted echo-planner imaging (EPI) fMRI scans. The 3D T1-weighted sequence acquisition parameters were as follows: 3D inversion-recovery prepared gradient-echo (fast field echo) sequence with inversion time (TI) 824 ms, echo time (TE)/repetition time (TR) 3.1/6.9 ms, flip angle 8° and voxel size 1 mm isotropic. The fMRI acquisition parameters were: TR/TE 2.5/35 ms, 2.7 mm thick slices with interslice gap of 0.3 mm positioned axial-oblique to include the cerebellum, 3 × 3 mm  in-plane resolution, field of view 192 × 192 mm , SENSE factor 2, flip angle 90° and 200 repeated volumes. 


### Experimental Design 
  
All the participants completed 3 randomized event-related fMRI sessions (Fig.  ): AE, AO, and AO with visual cue (AOvc). In all cases, all the stimuli were projected onto the same white screen, which was kept in the same position throughout; short-sighted participants used nonmagnetic visual aid goggles. The 3 experimental sessions are described below. 
  
Experimental paradigm. The figure shows a pictorial representation of the 3 conditions that were used in the behavioral and fMRI sessions: (  A  ) action execution (AE), (  B  ) action observation (AO), and (  C  ) action observation with visual cue (AOvc). The stimuli are shown above the arrow whereas the activity of the subject is shown below the arrow. During fMRI, every session lasted 8:33 min and the trials were administered in a counterbalanced and randomized order. The active trials (each lasting 3 s) were repeated 75 times and were divided equally between the 5 grip forces. A rest time of 2–12 s was allowed between active trials. 
  

### Squeeze Ball Event-Related Paradigm 
  
This paradigm, previously described elsewhere ( ;  ;  ), consisted of a visuomotor event-related power grip task, in which the order and timing of trials and rest periods was optimized to introduce temporal jittering and randomization of the applied GF strength (see below). The task was performed using an MR-compatible sphygmomanometer inflation bulb (“squeeze ball”) connected to a computer suite (located outside the scanner room) running the fMRI paradigm presentation. Compression of the ball resulted in an air pressure measurement proportional to the force exerted, which was recorded at a sampling rate of 20 Hz. In all, 75 active trials were performed, divided equally into sets of 15 corresponding, respectively, to GF levels representing 20%, 30%, 40%, 50%, and 60% of the subject’s maximum voluntary contraction (MVC). MVC had previously been measured in each subject using the same force device (i.e., by asking the subject to continuously squeeze the power ball) and this value was used to set the GF target for each trial. 

Trials were performed in a counterbalanced and randomized order as obtained using the OptSeq optimization software ( ). The rest time between squeezing trials—this lasted between a minimum of 2 s and a maximum of 12 s, and was cued by a black crosshair located at the center of the screen—was also randomized to introduce temporal jittering between the task and data acquisition. Rest time accounted for 55% of the whole fMRI session (500 s). The visual cue used in the trials was a black static horizontal bar (presented for 3 s), which indicated the target GF level to reach. This cue was projected onto an MR-compatible white screen and shown together with an interactive colored bar, indicating the actual force level reached and thus providing real-time feedback to the subject about his/her own performance. The GF task was performed with the right (dominant) hand during the AE session. 

A female actor was also filmed while performing the task in the control room of the scanner suite. The resulting video showed her whole right hand and forearm, filmed against a plain colored background, with the palm facing up. While recording the task, the computer also recorded the visual feedback she received (i.e., the visual cue bar), which was used to create a further video (in which the cue bar was superimposed on the forearm and hand) to be used in the AOvc session. Premiere Pro CS5 (Adobe System Software, CA, USA) was used for video editing. 


### AO (AO and AOvc) Behavioral Sessions 
  
Before and after the fMRI sessions, subjects underwent behavioral sessions during which they were asked to watch the AO and AOvc videos (the order of presentation of the videos was randomized among subjects) and to verbally report their own perception of the GF, that is, 20%, 30%, 40%, 50%, or 60% of the MVC of the actor’s hand shown squeezing the ball in the video (perceived GF). These sessions served to test their recognition of the GFs observed, to saturate any learning effect before the actual fMRI experiment, and to test possible differences in learning effects between the pre- and post-MRI behavioral sessions. The purpose of running 2 AO behavioral sessions, AO and AOvc, was to assess whether GFs can be appreciated from subtle (and natural) cues alone—as in the AO condition (e.g., changes in the color of the hand with increasing effort and accompanying tendon contraction)—or whether subjects also need to see symbolic visual feedback, as in the AOvc condition. Performance accuracy was assessed for each of the 5 GF levels by calculating the number of correct answers and the mean difference between the perceived GF (pGF) and the GF actually applied by the actor during the video recording (aGF). 


### AE Training Session 
  
After the AO behavioral sessions, just before the fMRI one, subjects were trained using a 2-min paradigm having a design similar to the above-described event-related one, with GF levels ranging from 10% to 70% of their MVC. The training session involved practising the task outside the scanner bore. 


### AE Session 
  
Subjects performed the AE task following the visual instructions described above. Their feedback was recorded at a sampling rate of 20 Hz during the task. The data collected served to include subject-specific performance in the statistical analysis. 


### AO Session 
  
Subjects observed the video showing the right hand of the actor performing the squeeze ball task. They were asked to keep their gaze at the center of the projection screen indicated by a cross during rest periods, to relax, not to touch the squeeze ball, and to think about nothing throughout this fMRI recording session (as opposed to trying to guess the force or the next action). 


### AOvc Session 
  
The subjects received the same instructions as in the AO session. The only difference, compared with the AO condition, concerned the stimuli: the video again showed the actor’s right hand performing the squeeze ball task, but this time the image was overlaid with a translucent representation of the visual feedback that the actor had received during the recording of the video (thus an indication of her performance). This session was originally included as part of the behavioral study as it was unclear whether force perception demands some kind of visual feedback on the performance, such as that provided by the real-time bar (symbolic guided action observation). However, since the AO condition alone was found to be sufficient to disclose perception of force-related effects, the AOvc data were not considered further for the purposes of this study. 


### Data Analysis 
  
#### Behavioral Data Analysis 
  
The group mean accuracy of the subjects’ perceptions (pGF) was calculated overall by measuring all correct responses as a percentage of all perceived forces (at 20%, 30%, 40%, 50%, and 60% of MVC of the hand squeezing the ball in the video), and also separately for each of the following sessions: AO before MRI, AOvc before MRI, AO after MRI, and AOvc after MRI. A number of statistical tests were performed. First, we used paired sample   t  -tests to assess possible significant differences between ratings in the AO versus the AOvc sessions; that is, considering the mean accuracy of pGF in the 2 conditions (considering “AO before MRI” vs. “AOvc before MRI” and then “AO after MRI” vs. “AOvc after MRI”). Second, a repeated measures ANOVA with Bonferroni correction was implemented to investigate learning effects, that is, testing for different performances within the AO and the AOvc sessions (“AO before MRI” vs. “AO after MRI” and then “AOvc before MRI” vs. “AOvc after MRI”). A statistical threshold of   P   < 0.001 was considered significant. Finally, to characterize the challenging nature of the AO task, we assessed the correlation between the actor’s actual performance (i.e., the GF applied by the actor performing the task and recorded while filming) and the subjects’ perceptions of that GF (i.e., the pGF, as reported by each subject during the “AO before MRI” behavioral session), using the correlation coefficient (  r  ) and the significance level (  P  -value). The statistical analysis was performed using the Statistical Package for the Social Sciences (SPSS) software (version 21.0). 



### fMRI Data Analysis 
  
#### Whole Brain 
  
Image analysis was performed with SPM12 ( ), implemented in Matlab15b (Mathworks, Sheborn, MA), using conventional preprocessing steps: slice timing, realignment, coregistration, estimation of (nonlinear spatial) normalization parameters between the 3D T1-weighted volume and the standard SPM12 template, application of the normalization parameters to the fMRI EPI volumes, and smoothing with an 8 mm isotropic full-width half maximum (FWHM) Gaussian kernel. The GF trials were modeled as delta functions ( ) with parametric modulation according to GF. A general linear model (GLM) including polynomial expansions up to the fourth order was applied following the procedures described by Alahmadi et al. ( ;  ). As discussed in previous work, the polynomial expansion allows nonlinear relationships to be characterized in an unbiased way, by modeling a mixture of linear and nonlinear responses in a parsimonious fashion. Interpretation of the nonlinear order lends itself to hierarchical testing (e.g., second-order effects are interesting only after removing first-order effects) ( ) and neurophysiological studies have reported different response profiles that have distinct nonlinear forms ( ;  ;  ;  ). Moreover, polynomial expansions are the most common form of expansion (in the absence of boundary conditions) when estimating neurometric functions from imaging data ( ;  ). 

In our setting, the 0th order represents the main effect of hand gripping (executed or observed) compared with the rest condition, irrespective of the level of GF applied. The first order represents any linear dependency on GF level (executed or observed), while nonlinear orders represent more complicated neurometric functions such as U-shaped (second order), sigmoid (third order) and quadratic (fourth order) functions. The parametric modulation of the stick functions—encoding grip trials—with the polynomial expansion of GF produces stimulus functions that can then be convolved with a canonical haemodynamic response function for subsequent standard GLM analyses ( ). 

At the first level of analysis (within subject), the realignment parameters were included in the GLM as regressors of no interest ( ) and   t   statistics were used to test for the effects of each polynomial coefficient. The associated contrast images of each of the 5 polynomial coefficients were then entered into a second (between-subject) level analysis and tested with one-sample   t  -tests, following standard procedures. The same analysis pipeline was followed for the AE and AO sessions. In the AO session, the GF levels corresponded to those recorded from the actor’s performance. A voxel-wise threshold of   P   < 0.001 (minimum extent 5 voxels,   P  =   P   uncorrected for multiple comparisons) was used to define clusters. A threshold of   P   < 0.05 was applied to the spatial extent of clusters that survived multiple comparisons corrections. The anatomical designations of significant clusters were determined using the SPM Anatomy Toolbox (Version 2.2b). The same criteria were used for AE and AO sessions. 


#### SUIT 
  
The fMRI analysis pipeline, optimized for whole-brain analysis, can give suboptimal results in the cerebellum ( ). Therefore, to focus on the cerebellum, we used SUIT (spatially unbiased infratentorial template), a high-resolution atlas template of the human cerebellum and brainstem, which is part of the SPM12 software package ( ). The following steps were performed: 1) Extraction of each subject’s cerebellum and brainstem from their corresponding whole-brain 3D T1-weighted anatomical images; 2) Normalization of the anatomical images to the SUIT template using nonlinear deformations; 3) Re-slicing of the functional contrast images produced from the first-level analysis using the deformation produced from step 2) and masking out activation outside the region of interest (i.e., the cerebellum). The normalized cerebellum functional contrast images (of each polynomial order) from each subject were then smoothed with an 8 mm FWHM Gaussian kernel and submitted to a (between-subject) standard second-level random effects analysis, testing for increasingly higher-order nonlinear effects within the cerebellum with one-sample   t  -tests. Significant clusters were defined using a height threshold of   P   < 0.001 (and a minimum extent of 5 voxels). The anatomical designations of regionally specific effects were defined using a high-resolution probabilistic atlas defined within the SUIT template ( ). The resulting statistical parametric maps (SPMs) were projected on to the flat map of the cerebellum provided with the SUIT template ( ). 


#### Conjunction 
  
To identify, in terms of a parametric response to GF, the extended AEON, engaged both in AE and AO, we performed a simple conjunction analysis. This entailed testing for action observation effects at a corrected level of significance within a search volume defined by AE. 

We first used the SPM, testing for 0th order effects in order to localize the combined effect of AE and AO independently of GF, that is, to identify regions that showed a conjunction of AE/AO effects, irrespective of parametric force effects. We then identified regions that showed potential nonlinear responses to GF in both action observation and execution. In order to do so, we used a full factorial design and SPMs of the   F   statistic, testing for one or more significant polynomial coefficients in both execution and observation to obtain maps of the combined AE/AO force-related effect (FRE). Specifically, we used the SPMs of the   F   statistic, testing for a parametric effect of GF under AE (threshold   P  < 0.0001 for the whole brain analysis and   P   < 0.001 for the SUIT analysis) as a localizing contrast to define a search region within which to identify nonlinear effects under action observation (using the equivalent   F   contrast and a small volume correction to   P   < 0.05). Finally, we used the   F   statistic of the first-order effects to investigate the linear FRE and the   F   statistic of the higher-order effects to investigate the nonlinear FRE. 




## Results 
  
BOLD fMRI signals were recorded from 12 healthy subjects during one visuomotor and 2 visual tasks for the purpose of comparing brain activation under AE and AO conditions, when different GF levels are applied to an object (in this case a squeeze ball). 

### AO Behavioral Responses 
  
The behavioral performance, at group level, when watching the AO and AOvc videos, is shown in Fig.  . The accuracy of the perceived grip force (pGF) significantly differed between AO and AOvc, both before (  P   = 0.002) and after (  P   = 0.00008) the MRI session. Within the AOvc condition, pGF accuracy was higher after MRI (  P   = 0.003), while no significant differences were found in the AO condition (  P   = 0.955). As expected, GF recognition was higher in AOvc than AO (mean accuracy ± SD, 76 ± 22 and 39 ± 7, respectively), although at the end of the experiment, some subjects reported that the bar indicating levels of force (the visual cue) had not influenced their behavioral responses during AOvc. AO data showed a positive correlation between aGF and pGF (  r   = 0.98,   P   = 0.005) (Fig.  ), thus, confirming that the subjects were able to infer the actor’s movement in quantitative terms. Given that subjects correctly perceived the strength of the applied GF also when watching the AO video without the visual cue, subsequent analysis of fMRI data concerned only the AE and AO conditions. 
  
Group performance during action observation behavioral tasks. The box plot shows the relative accuracy (ACC) of force estimation in the different action observation (AO) and action observation with visual cue (AOvc) behavioral sessions (before and after the fMRI sessions). Significant differences between conditions are indicated (paired   t  -test). 
    
Relationship between applied and perceived grip force during the action observation behavioral task. The plot shows the relationship between grip force (GF) actually applied (aGF, i.e., GF presented on the video) and GF perceived (pGF, i.e., by the subjects watching the video) during the behavioral action observation (AO) task performed before and after fMRI recordings. The circles are individual subject responses and the line represents the group mean performance. A significant positive correlation was found between aGF and pGF (  R   = 0.98,   P   = 0.005). 
  

### Whole Brain—BOLD Effects 
  
Regionally specific effects for 0th (main effect), linear (+1st, −1st) and nonlinear (+2nd, +3rd, +4th, -3rd) order responses were detected, using whole-brain analysis, on AE and AO. Full data with figures and tables detailing significant effects (including coordinates,   T   values and cluster extents) are provided as  . AE activated many more regions than AO (Fig.  ), while both experimental conditions elicited regionally specific effects at 0th, −1st, and −3rd orders. Specifically, AO induced effects not only at the 0th order, but also at +3rd, 1st, and −3rd orders. These results reflect the presence of FRE during action observation. 
  
Whole-brain BOLD effects in action execution and observation. Brain maps at the group level corresponding to different orders of the BOLD-GF association in the action execution (AE, in red) and action observation (AO, in blue) conditions. The images show areas of activation at different orders. Note that both force-related and unrelated BOLD effects are found in the cerebral cortex and cerebellum. A threshold   P  < 0.001 (  k   ≥ 10;   P   =   P   uncorrected for multiple comparisons) was used for display purposes. The shape of the orthogonalised polynomial function that was fitted to the signals is shown for the (A) 0, (  B  ) +1st, (  C  ) +2nd, (  D  ) +3rd, (  E  ) +4th, (  F  ) −1st, and (  G  ) -3rd orders, to the right of the corresponding image showing significant clusters. In this and all the following figures, right is right and left is left. 
  

### Whole Brain Conjunction 
  
#### AE and AO Main Effect (0th Order) 
  
Several areas belonged to the extended AEON (in terms of a conjunction of zero order effects), and they included the occipital and temporal lobes, inferior and superior parietal cortices, precentral and postcentral gyri, inferior frontal gyrus, insula, thalamus and cerebellum. The occipitotemporal cluster extended into the cerebellar lobules VI and VII and cerebellar Crus I (Fig.   and Table  ). 
  
AEON: BOLD main effect. 3D whole-brain renderings of the main effects (0th order) in action execution (AEN), action observation (AON) and action execution–observation (AEON) networks. Note, in the AEON, the considerable overlap of effects in both the cerebral cortex and the cerebellum. Different thresholds were used for the 3 maps:   P   < 0.0001 (  k   ≥ 10;   P   =   P   uncorrected for multiple comparisons) was used for the AE condition;   P   < 0.05 (  k   ≥ 10;   P   =   P   uncorrected for multiple comparisons) was used for the AO condition; and   P   < 0.05 (  k   ≥ 10), with a small volume correction applied to the AO map, was used to obtain the AEON. 
  
  
AEON: main effect (0th order) 
    


#### Force-Related Effects (Linear and Nonlinear Orders) 
  
FREs (Fig.   A   and Table  ) were jointly expressed in several brain regions: supramarginal gyrus, calcarine gyrus, temporal gyrus, parietal lobe, insula, postcentral and precentral gyri, inferior frontal gyrus, middle cingulate cortex, posterior–medial and superior frontal cortices, rolandic operculum, lingual gyrus, basal ganglia, and cerebellum. A limited number of brain regions, that is, the precentral and postcentral gyri (Fig.   B  ), exhibited a linear FRE (+1st and −1st orders) in both AE and AO. The most prevalent joint FREs were nonlinear (+2nd, +3rd, +4th, −2nd, −3rd, −4th orders) and identified in the: supramarginal gyrus, angular gyrus, precentral and postcentral gyri, occipital lobe, inferior and middle temporal gyri, rolandic operculum, inferior and superior parietal cortices, inferior and middle frontal gyri, middle cingulate cortex, insula, thalamus and cerebellum (Fig.   C  ).
   
AEON: force-related BOLD effects 
    
  
AEON: force-related BOLD effects. 3D whole-brain renderings of the force-related effects: (  A  ) force-related effects (FRE), (  B  ) linear force-related effects (linear FRE), and (  C  ) nonlinear force-related effects (nonlinear FRE) in action execution (AEN), action observation (AON) and action execution–observation (AEON) networks. Note, in AEON, the prevalence of nonlinear associations in both the cerebral cortex and the cerebellum. Different thresholds were used for the 3 maps:   P   < 0.0001 (  k   ≥ 10;   P   =   P   uncorrected for multiple comparisons) was used for the action execution condition;   P   < 0.05 (  k   ≥ 10;   P   =   P   uncorrected for multiple comparisons) was used for the action observation condition; and   P   < 0.05 (  k   ≥ 10), with a small volume correction applied to the AO map, was used to obtain the AEON. 
  


### SUIT—BOLD Effects 
  
The AE condition detected more activated cerebellar regions than the AO one did (Fig.  ). In AE cerebellar specific effects were detected in lobule V and VIII (+1st order), lobule VI (0th and +4th orders), lobule VII (0th order), and Crus I (0th, +4th and −3rd orders). AO effects were observed in lobule VI (0th and −3rd orders), Crus I (0th order), and Crus II (+4th order). 
  
Cerebellar BOLD effects in action execution and observation. SUIT flat maps at the group level corresponding to different orders of the BOLD–GF association in action execution (AE) and action observation (AO) conditions. Note the force-related and main (0th order) BOLD effects in different cerebellar areas. In the images, areas of activation at different orders of effect are shown for both AE (in red) and AO (in blue). A SUIT flat map with labels of cerebellar lobules is shown in the bottom right corner. A threshold   P   < 0.001 (  k   ≥ 10;   P  =   P   uncorrected for multiple comparisons) was used for display purposes. 
  

### SUIT—Conjunction 
  
#### AE and AO Effect (0th Order) 
  
Lobules VI and VII and Crus I and II were jointly involved in AE and AO (Fig.  ). 
  
Cerebellar component of AEON: main BOLD effects. SUIT flat maps of the main effects (0th order) in the cerebellar component of the action execution (AEN), action observation (AON) and action execution–observation (AEON) networks. Note, in AEON, the extended involvement of posterior and lateral areas of the cerebellum. Different thresholds were used for the 3 maps:   P  < 0.001 (  k   ≥ 10;   P   =   P   uncorrected for multiple comparisons) was used for the action execution condition;   P   < 0.05 (  k   ≥ 10;   P   =   P   uncorrected for multiple comparisons) was used for the action observation condition; and   P   < 0.05 (  k   ≥ 10), with a small volume correction applied to the AON map, was used to obtain the AEON. 
  

#### Force-Related Effects (Linear and Nonlinear Orders) 
  
FREs were jointly identified in: Crus I and lobules V and VI (Fig.   A  ). A cluster in lobule V presented a linear FRE (+1st and −1st orders) while a nonlinear FRE (+2nd, +3rd +4th, −2nd, −3rd, −4th orders) was found in 2 clusters in lobule VI and IX (Fig.   B   and   C  , respectively). 
  
Cerebellar component of AEON: force-related BOLD effects. SUIT flat maps of the (  A  ) force-related effects (FRE), (  B  ) linear force-related effects (linear FRE), and (  C  ) nonlinear force-related effects (nonlinear FRE) in the cerebellar component of the action execution (AEN), action observation (AON) and action execution–observation (AEON) networks. Note, in AEON, the distribution of force-related BOLD effects over several cerebellar areas in the anterior and posterior cerebellum. Different thresholds were used for the 3 maps:   P   < 0.001 (  k   ≥ 10;   P  =   P   uncorrected for multiple comparisons) was used for the action execution condition;   P   < 0.05 (  k   ≥ 10;   P  =   P   uncorrected for multiple comparisons) was used for the action observation condition; and   P   < 0.05 (  k   ≥ 10), with a small volume correction applied to the AON map, was used to obtain the AEON. 
  



## Discussion 
  
In this study, we report for the first time the existence of force-related BOLD effects in an extended AEON involving cerebral and cerebellar regions that are both motor and associative in nature. These regions not only respond to observed and executed actions, but also share patterns of linear and nonlinear BOLD responses to parametric variations in GF. Linear BOLD–GF associations occurred in motor regions, while nonlinear BOLD–GF associations were found in regions specific to somatosensory state estimation, motor simulation and cognitive control. The cerebellum was found to be a key structure within the AEON, showing regional-specific correlations with force. These effects support the concept that the AEON extends to the cerebellum and to a set of cortical regions that are critical for imitation learning. The results are discussed and integrated with our current understanding of brain function in terms of the intrinsic functional connectivity of 7 fundamental networks (visual, somatomotor, ventral and dorsal attention, frontoparietal, limbic and default networks) ( ). 

### Behavioral Performance and Learning Effects 
  
The subjects were found to be able to evaluate visually the efforts of others. There are 3 considerations indicating that this ability was independent of learning during the test ( ). First, in order to saturate learning, all the subjects underwent AO training before the fMRI experimental sessions; this training is known to facilitate motor learning ( ;  ) and increase force production by optimizing motor neuron recruitment ( ). Second, the order of presentation of the AE, AO, AOvc sessions was randomized, thus limiting a potential variability in attentional load (e.g., induced by fatigue). Third, the accuracy in force detection was higher in AOvc than in the AO sessions. Therefore, independently of subject performance, the visual cue has a facilitator effect with respect to naturalistic stimulation (i.e., actual movement and changes in body parts during action), but the latter is nonetheless sufficient to perceive the intensity of another’s movements. 

It should be noted that in the AOvc condition we detected a learning effect, implying a facilitation of force recognition along trials. Moreover, we detected a higher variability of performance between participants in the AOvc compared with the AO condition; this might be due to attention being focused either on the visual cue or on the hand itself. However, the debriefing at the end of the experiment indicated that several participants had ignored the bar. For these reasons, we did not further consider the AOvc condition in our analysis. 


### BOLD Effects Elicited by AE and AO 
  
The BOLD effects elicited by AE occurred mostly in areas directly involved in motor planning, execution, and control ( ) (for a detailed description see Table  ). The main effect of AE was observed in premotor and sensorimotor cortices as well as in parietal, occipital and cerebellar cortices devoted to global sensorimotor processing ( ) and included in visual, dorsal attention and somatomotor networks, while a linear activation with force was found in primary motor cortex and anterior cerebellum, that actually do encode force ( ) and belong to the somatomotor network. Nonlinear relationships with GF were found in parietal, frontal, cingulate and insular cortices, and in thalamus, basal ganglia and cerebellum, which form large-scale loops involved in the control of fine precision grip forces and motor learning ( ;  ;  ). These loops could be linked with visual, ventral and dorsal attention, frontoparietal, somatomotor and default networks. Minor differences with previous squeeze ball studies ( ) could be related to the higher complexity of the present paradigm (which included behavioral training sessions and 3 different tasks).
   
Summary of BOLD effects for AEN, AON, and AEON 
    

The BOLD effects elicited by AO were recorded in an extended and distinctive set of occipital, parietal and frontal regions involved in motor but also sensory and cognitive processing (for a detailed description see Table  ). The main effect of AO was observed in the occipital and parietal regions related to motion perception and attention ( ;  ) that are considered to be part of the visual network and the ventral and dorsal attention networks. Linear responses with respect to GF occurred mainly in the postcentral gyrus, involved in processing proprioceptive and tactile representations of the manipulated object ( ) and included in the somatomotor network. Nonlinear responses with respect to GF occurred in occipital and temporal cortices and inferior parietal lobule, involved in object recognition ( ), inhibition of movement ( ), spatial focusing of attention ( ), and intention understanding ( ). These functions are supported by the inclusion of activated regions in the visual, dorsal attention and default networks. These components, either main or FREs, probably provide the substrate for the interpretation and simulation of the actions of others ( ), while actual movement is inhibited. 

The detection of specific nonlinear force-related BOLD effects in areas involved in AE or AO could imply complex task-related interplay of different neuronal populations (e.g., inhibitory and excitatory) within local networks. Understanding the biophysical basis of such nonlinearities will need realistic models and further investigation of neurovascular coupling under different conditions. 


### The Common Neural Substrate of AE and AO 
  
The AEON, identified as the voxels shared by AEN and AON, was observed in cerebral cortex, thalamus, basal ganglia, and cerebellum ( ) (for a detailed description see Table  ). The main effect of AEON was observed in occipital cortex, middle temporal gyrus, precentral and postcentral gyri, inferior and superior parietal lobules, insula, thalamus, and posterior cerebellum. These areas are involved in visual imagery of hand gestures, including visuospatial and motion processing ( ;  ), forward/inverse control for movement planning and execution, action style processing ( ), inhibition of motor execution to prevent imitative responses ( ). These are, indeed, the fundamental ingredients of motor planning based on observation of actions ( ). The activation of inferior and superior parietal lobules (which are part of the core mirror network) ( ) with occipital cortex, precentral and postcentral gyri and insula, suggest that AEON includes components from the visual, mirroring/somatomotor, ventral and dorsal attention networks. 

The AEON areas showing FREs were also extensively distributed in occipital cortex, superior temporal gyri, inferior and superior parietal lobules, precentral and postcentral gyri, inferior frontal gyrus, medial frontal gyrus, precuneus, cingulate gyrus, caudate, thalamus, and cerebellum. These areas are involved in the experience and observation of touch ( ), maintenance of spatial attention during goal-directed actions ( ;  ;  ), sensorimotor integration, and force amplitude generation and prediction ( ;  ). Moreover, the medial frontal gyrus is considered, with the temporoparietal junction, the “core network” of attribution of mental states ( ;  ) while the precuneus has been proposed to have a role in mental imagery to represent others’ perspective ( ). Therefore, FREs are particularly important in conferring the ability to detect the effort of others not just requiring the intervention of the mirroring/somatomotor, ventral and dorsal attention and frontoparietal networks but also of the mentalizing/default network. 

Interestingly, activation in the AEON areas was mostly nonlinear, while linear relationships with GF were found only in a restricted part of the precentral and postcentral cortices ( ) that are included in the mirroring/somatomotor network. Therefore, the AEON is engaged mainly in a nonlinear fashion during force processing. 


### Cerebellar Involvement in AEON 
  
The cerebellum is known to operate as a generalized forward controller ( ) that aids motor planning by predicting the sensory consequences of a motor act, such that a motor plan is coded in terms of an anticipatory sensory state ( ;  ;  ). In the present context, the sensory state would be provided by AO, and motor predictions would be based on internal cerebellar representations of the system (body and muscle) state ( ;  ). Thus, the cerebellum is well geared for simulating movements after receiving information about the movement of others, in terms of the appropriate sequence (timing) and force (gain) ( ;  ). 

The cerebellum is strongly interconnected with the cerebral cortex through 7 fundamental resting-state networks ( ). In particular,  ) clearly identified in the cerebellum distinct mirroring and mentalizing networks (as part of the larger somatomotor and default networks respectively) that were directly connected to homolog networks in the cerebral cortex. Confirming this network structure, Van Overwalle and colleagues reinterpreted their initial meta-analysis ( ) in terms of this network structure and found strong evidence for it ( ). In addition, a meta-analytical connectivity analysis revealed a strong distinction between anterior mirroring and posterior mentalizing areas in the cerebellum linked to classic mirror and mentalizing areas in the cerebral cortex ( ). This was confirmed by functional connectivity studies relating mentalizing and executive control functioning to the cerebellum ( ). Therefore, the cerebellum could also be involved in predicting the consequences and scope of other’s actions by reconstructing hypothetical events ( ;  ). 

It should be noted that, in our study, cerebellar responses were embedded in a larger cluster that included occipitotemporal areas. The combined activation in the AEON in lobules VI and VII and Crus I and II could be considered part of the ventral and dorsal attention, frontoparietal, and mentalizing/default networks compounded by the mirroring/somatomotor network from specific FREs ( ). Indeed, the linear FRE in lobules V, part of the mirroring/somatomotor network, reveals the involvement of cerebellum in motor functions ( ;  ;  ). The nonlinear effect in lobules VI and IX, part of both mirroring/somatomotor and mentalizing/default networks, would suggest the cerebellar involvement in the integration of motor processing and cognitive/emotional control ( ). 

Altogether, these effects confirm the cerebellar involvement in both mirroring and mentalizing networks. Moreover, these patterns of linear and nonlinear responses in the cerebellar components of the AEON are consistent with results showing that motor-generating areas respond linearly with GF, while associative and cognitive areas have a more complex relationship with GF. These response profiles may reflect distributed responses, mediated by connections that have been characterized structurally and physiologically in rodents, primates, and humans ( ;  ;  ;  ;  ;  ,  ). 


### High-Order Force–BOLD Relationships in the Cerebellum and Cerebral Cortex 
  
While a monotonic relationship between BOLD response and GF levels was found in primary motor areas (M1 and anterior cerebellum)—and could be related to the increased neuronal recruitment with increasing GF ( ;  )—nonlinearities were typically detected in areas implicated in multimodal integration and higher aspects of motor control (premotor, associative and sensory areas both in the cerebral cortex and the cerebellum), where a complex blend of signals converges to regulate motor output. It has been previously argued ( ) that second-order responses at intermediate force levels could be “metabolically optimal” and reflect more efficient processing in a motor regime requiring fewer corrective actions and less attention to sensory inputs. For example, nonlinearity may be due to fluctuation of attention levels modulating neural activity ( ). However, it should be appreciated that it is difficult to make detailed neurophysiological inferences based exclusively on fMRI signals. For example, nonlinearities (including nonlinear neuronal responses, nonlinear engagement of local inhibitory circuits, nonlinear mapping from neuronal activity to haemodynamic responses and finally, nonlinearities associated with the haemodynamic response function generating T2* signals) could arise at a number of different levels ( ;  ). The engagement of the underlying neuronal circuits, both in the cerebral cortex and the cerebellum, may benefit from further investigation using repetition-suppression fMRI paradigms ( ;  ) or multivoxel pattern analysis ( ) in conjunction with animal recordings and large-scale model simulations ( ). 


### Potential Limitations 
  
Despite the coherent functional framework emerging from this investigation, the relatively small number of subjects may affect its statistical power in detecting active areas. Although previous studies used similar numbers of subjects, a larger sample may be beneficial to confirm our findings. However, it is important to note that significant results obtained using a small sample usually mean that the effect size is large ( ). From a statistical point of view, the use of parametric models is an efficient way of accommodating nonlinear (neurometric) response functions within the established GLM framework ( ). However, given the concern that detection of active areas may have been reduced because of habituation due to multiple engagement in AO ( ), it would be useful to devise alternative paradigms in order to refine our AEON parametric characterization. 



## Conclusions 
  
The extended AEON identified in this fMRI study engages large-scale brain networks capable of remapping the visual detection of the actions, and also effort, of others onto the observer’s own motor system. These circuits, furnish not only understanding of other people’s goals, that is, the “mirror” effect ( ), but also the building blocks of executive control, impacting on various aspects of motor planning and programming, working memory, selective attention, and behavioral inhibition ( ;  ;  ;  ;  ;  ;  ). The cerebrocerebellar loops, using the motor system as a forward model ( ;  ;  ;  ;  ), could play a crucial role in sensorimotor prediction and internal simulation of movement. It has been suggested that the insular and cingulate cortices, activated in parallel to the sensorimotor loops, allow exteroception to be integrated with interoception ( ;  ;  ) and external observational cues to be transformed into internal sensorimotor plans. The identification of this extended AEON as a plausible substrate for imitation learning could facilitate and improve the clinical application of action observation in neurorehabilitation ( ;  ;  ). 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-67'>
<h2>67. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/27814379/' target='_blank'>27814379</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> The Difference between Aesthetic Appreciation of Artistic and Popular Music: Evidence from an fMRI Study</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2016</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0165377</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5096663/' target='_blank'>5096663</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study used task-based fMRI in healthy adult participants (male, 18–24) who performed an aesthetic judgment (beauty ratings) while listening to popular and artistic music. The authors report whole-brain voxel-wise contrasts and one-way ANOVA with cluster-level FDR correction (in addition to ROI analyses), satisfying the whole-brain analysis requirement. Although the task was an aesthetic judgment rather than an explicit social task, the study specifically investigates and reports engagement of default mode/ToM and cognitive empathy regions (arMFC, PCC/PC, TPJ/temporal pole, hippocampus) and interprets these as social-cognitive/mentalizing processes (Perception and Understanding of Others). Thus it meets the meta-analysis objective of fMRI studies of social-related processing in healthy adults. Note: task is indirect social processing (inferred mentalizing), but authors’ analyses and interpretations align with inclusion constructs.</p>
<p><strong>Fulltext Confidence:</strong> 0.85</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
To test the hypothesis that pleasure from artistic music is intellectual while that from popular music is physiological, this study investigated the different functional mechanisms between aesthetic appreciation of artistic and popular music using fMRI. 18 male non-musicians were scanned while they performed an aesthetic rating task for excerpts of artistic music, popular music and musical notes playing and singing (control). The rating scores of artistic and popular music excerpts were both significantly higher than that of control materials while the scores of them were not different. The fMRI results showed both artistic and popular conditions activated the VS and vmPFC, compared with control condition. When contrasted popular and artistic condition directly, we found popular music activated right putamen, while artistic music activated right mPFC. By parametric analysis, we found the activation of right putamen tracked the aesthetic ratings of popular music, whereas the BOLD signal in right mPFC tracked the aesthetic ratings of artistic music. These results indicate the reward induced by popular music is closer to a primary reward while that induced by artistic music is closer to a secondary reward. We also found artistic music activated ToM areas, including PCC/PC, arMFC and TPJ, when compared with popular music. And these areas also tracked aesthetic ratings of artistic music but not those of popular music. These results imply that the pleasure from former comes from cognitive empathy. In conclusion, this study gives clear neuronal evidences supporting the view that artistic music is of intelligence and social cognition involved while the popular music is of physiology. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (30202 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
The aesthetics of artistic work has long been considered as disinterested, detached and intellectual, while that of popular work is perceptual and physical [ – ]. However, such speculative perspective is far from the essential characteristic within diverse levels of aethetics. Due to the advancement of neuroscience technologies, more researchers were committed to explore the neural basic of aesthetics, emerging a new research field of “Neuroaesthetics”. In the early period of the 1900s, the neural mechanism of aesthetic judgment or preference for artistic objects attracted the more interest of neuroscientists[ ]. It was found that brain regions recruited by artistic appreciation were highly overlapped with the reward circuit. For example, OFC and ventral striatum which are two typical reward regions were found to be activated during the appreciation of beautiful paintings[ – ]. Recently, researchers have tried to figure out the universal brain correlates for more extensive aesthetics. In research by Ishizu and Zeki, the arousals of mOFC and ventral striatum was reported for both the visual (artistic painting) and acoustic (music) aesthetics[ ]. Furthermore, Brown and his colleagues applied the meta analyses of activation likelihood estimation to demonstrate a core circuit for positive-valence aesthetic appraisal[ ]. The anterior insular, NAcc, pregenual ACC, anterior midcingulate cortex, dorsomedial nucleus of thalamus, ventral basal ganglia, and mOFC were concordantly activated across all four modalities (i.e., visual, acoustic, tactile and osphretic) during aesthetic processing. These regions defined a general aesthetic network including the anterior insular, ventral basal ganglia, rACC and mOFC. In this article, aesthetic processing was naturalized as the appraisal of valence of perceived objects, which involves an interaction between interoceptive and exteroceptive processing. In other words, aesthetic is rooted in a comparison between subjective awareness of current homeostatic state and exteroceptive perception of objects in the environment. However, it has been argued that this is just a general cognitive process that not only can be applied to art objects but also to non-art objects[ ]. 

Though these studies contributed significantly to exploring the general neural mechanism for aesthetics, the implications for artistic appreciation still have not been charaterized. For instance, Brown’s aesthetic model assumes an integrated neural basis for aesthetics of all sensory modalities rather than a different basis for different types, resulting in a finite identification for disparate kinds of aesthetics. Moreover, a meta-analysis research comparing the brain responses to monetary, erotic and food reward outcomes found that for the secondary reward elicited higher activation in the frontal of OFC, whereas the primary reward elicited higher activation in the frontal insular. This meta-analysis study found possible segregated regions involved in different reward processes [ ]. Krik and his colleagues[ ] found a similar pattern of results. Architects and non-architects were asked to make aesthetic judgments of architectural and control stimuli. The results indicated that experts and non-experts differentially recruited bilateral medial orbitofrontal cortex (OFC) and subcallosal cingulate gyrus during the task, even in the absence of a difference in the aesthetic rating made by these two groups. By contrast, activity in nucleus accumbens (NAcc) exhibited a similar response pattern. These findings suggested a dissociable role between these regions in the aesthetic evaluation. 

To answer the question “why music and other artworks activate this same circuitry”, Brown et al.[ ] argued that “[aesthetic processing] evolved first for the appraisal of objects of survival advantage, such as food sources, and was later co-opted in humans for the experience of artworks for the satisfaction of social needs.” Given the high correlation between regions for reward and aesthetic processing, we speculated that brain activation would also be disparate for different kinds of aesthetics. In a recent fMRI study [ ], our laboratory found that facial beauty involved both the subcortical reward region putamen and the cortical reward region OFC, while moral beauty involved only the OFC. The selective activation of the ventral striatum(VS) and OFC for different types of aesthetic was suggested to represent the association between aesthetics and the physiological or social demands. Given this finding, we hypothesized that the high level artistic work that was related with social needs would elicit higher activation in the frontal cortex, whereas the low level popular work that was related with physical needs would elicit higher activation in the striatum region. 

In the modernist view, genres of art develop a hierarchy[ ,  ]. Artistic music, as a higher and complex form, demands an intellectual response. While popular music can not combine popularity and complexity, because popularity requires accessibility. In contrast to artistic music, popular music is more simplistic and repetitive. Therefore, popular music encourages a passive perceptual and physical engagement. It is lack of intellectual challenge and social truth. In the present study, we employed the functional magnetic resonance imaging (fMRI) to explore the neural processes of reward that arise in the appreciation of artistic and popular music. We assumed that high level music would elicit larger activity in OFC or other cortical reward region, and low level music would elicit larger activity in subcortical reward region. 


## Material and Methods 
  
### Ethics Statement 
  
The current study was approved by the Academic Committee of the School of Psychology at South China Normal University. All participants gave written informed consent before participating in the experiments. 


### Participants 
  
Eighteen volunteers (male; 18–24 years old) were recruited from local universities for the fMRI experiment. All of them were philharmonics, but not music professional, who had engaged in some musical training or activities (e.g., choir, Musical Instruments class) before the experiment. They were right handed and reported no prior history of neurological or psychiatric problems. Participants were given a small payment after the experiment. 


### Stimuli 
  
The musical materials selected for the present research consisted of popular music excerpts, artistic music excerpts (opera), and clips of meaningless musical notes in form of playing and singing (please see supplementary material for demo, including  : popular music sample,  : artistic music sample and  : control material sample). The former two musical materials were snipped from songs from CDs or the internet with the theme of love. These songs were all performed by female vocalists, and the lyrics were in languages other than English and Chinese. The notes clips were made in our lab and applied as control stimuli. With the GoldWave (Version 5.58, GoldWave Inc.,   www.goldwave.com  ), all stimuli were standardized to a proper length and identical volume (16dB). Each excerpt began with 500 ms of gradual fade in, and ended up with 500 ms of gradual fade out. 30 popular music, 32 artistic music and 35 notes clips were prepared for pretesting. The duration of the popular and artistic music was between 12–24 s, and that of the notes was 10–15 s. Moreover, beauty and familiarity evaluations for all these materials were collected using a 7-point Likert scale from another eighteen participants, who shared the same age and musical experience with the fMRI participants. 

Based on the pretesting, 40 musical excerpts were selected by matching the beauty, familiarity and length, with half for the popular music and half for the artistic music. The familarity ratings for popular and artistic music were: 3.41±0.33 vs. 3.31±0.37; the beauty ratings for popular and artistic music were: 5.17±0.35 vs. 4.98±0.37; and the lengths for popular and artistic music were: 17.80±2.65s vs. 17.85±3.88s. For these three dimensions, there was no significant difference between popular and artistic music (  ps  >0.05,all). 28 clips of musical notes playing and singing were chosen for the baseline condition by matching the familiarity and total duration between musical (popular and artistic music) and non-musical (note) materials. The average length of notes clips was 12.14±1.27s. The familiarity ratings for note clips (3.29±0.49) were not remarkably different from those for popular and artistic music excerpts, whereas the beauty ratings of note clips (2.81±0.33) were significantly lower than those of musical materials, both   p   = .000 (LSD). 

All the auditory stimuli were present binaurally with a high-quality MRI-compatible headphone system (SA-9800B, Shenzhen Sinorad Medical Electronics, Inc.). The volume of auditory stimuli was individually adjusted before fMRI scanning. Participants were asked to close their eyes during the experiment and open their eyes during the break. Visual instructions were presented on a screen back-projected on a head coil-mounted mirror. 


### Procedures 
  
The experiment program was conducted by the E-Prime 1.2 (Psychology Software Tools, Inc., Pittsburgh, PA). Prior to fMRI scanning, participants underwent a training session to become acquainted with the procedures. In the training session, the materials and the number of trials were not the same as formal experiment. 

The fMRI experiment consisted of 4 consecutive scanning runs. Each run contained 17 stimuli epochs, with 5 for each musical condition and 7 for the control condition. The sequences of stimuli for the four runs were presented as follows (p = popular epoch; a = artistic epoch; c = control epoch): 1) c, p, c, a, c, a, c, p, c, a, p, p, a, c, a, p, c; 2)c, p, a, c, a, p, p, a, c, p, c, a, c, a, p, a, c; 3)p, a, c, p, c, a, c, a, p, c, a, a, c, p, c, p, a, c; 4) c, a, p, c, a, c, p, c, p, a, c, a, p, c, p, a, c. Half of the participants were assigned to the main stimuli sequence (i.e., 1,2,3,4), and half were assigned to the alternative sequence (i.e., 3,4,1,2). Each run started with a blank lasting for 4 s, and then the music excerpt was presented. During inter-stimulus interval (ISI), participants had to rate the beauty of each stimulus by pressing the corresponding key. The duration of ISI was about two thirds of the presentation time of previous stimuli. The whole experimental run lasted for 420 s without any stimuli during the last 10s. All participants were asked to close their eyes during each experimental run, and open their eyes during rest. 

After the fMRI session, participants were required to rate the following two questions for all stimuli using a 7-point Likert scale (response format: 1 = "not at all"; 4 = "medium"; 7 = "extremely"): A. The beauty of the music; and B. The familiarity of the music. 


### MRI Data Acquisition 
  
MRI data were acquired using a 3T whole-body scanner (Siemens TIM TRIO). Functional images were obtained using a multislice echo plannar imaging (EPI) sequence (36 slices, slice thickness 3.5+0.7 mm gap, TR = 2.2 S, TE = 30ms, field of view = 220*220mm2, 64*64 matrix, flip angle: 90°). Scanning slices were aligned approximately parallel to the AP-PC plane, and interval scanning was carried out from the bottom up. For spatial normalization, a high-resolution T1-weighted anatomical image was acquired after EPI acquisition, using fast spin echo sequence(176 slices, 1×1×1mm, FOV = 256*256mm2, TE = 2.43ms, TR = 2530ms). 


### fMRI Data Analysis 
  
The obtained fMRI data were preprocessed and analyzed using the statistical parametric mapping (SPM8; Wellcome Trust Center for Imaging, London, UK;   http://www.fil.ion.ucl.ac.uk/spm  ). For stabilization of magnetization, the first five volumes of each session were discarded. Data preprocessing was done with default setting of SPM8. EPI images were co-registered and normalized to the T1 standard template in Montreal Neurological Institute (MNI) space (resampling voxel size: 2×2×2mm), and smoothed with a Gaussian kernel with 6 mm FWHM. 

After preprocessing, we carried out both factorial model and parametric model analyses [ ]. For the factorial model, first level analysis was performed on each subject by estimating the variance of musical epoch according to a general linear model (GLM). Three kinds of musical epochs were modeled as separate regressors convolved with the canonical hemodynamic response function. For the parametric model, trials of pop music or artistic music were respectively included into a single regressor, accompanied by a parametric regressor of according post-aesthetic rating. For both models, six motion parameters estimated during the realignment procedure were included as covariates of no interest. 

At the group level, all images were subjected to a voxel-wise contrast and one way ANOVA-within subject analysis to assess statistical significance for the factorial model. ROI analyses with two sample t-tests were further performed in whole brain clusters showing a significant contract between popular music and artistic music conditions. Marsbar (version 0.42) was applied to extract the beta value, with spherical ROIs of 10mm radius for putamen, 12mm radius for other areas. The central location of each ROI was determined by the results of factorial model analysis. For the parametric analysis, one-sample t-tests were used to reveal the regions in which the BOLD signal correlatively changed with the aesthetic rating scores of popular and artistic music, respectively. A tow-sample t-test was also used to find out the areas response differently to the rating of the two type of music. For the above models, global analyses were conducted at a voxel threshold of   P  <0.002 (uncorrected), and a cluster threshold of FDR<0.05. Small volume correction (SVC) was used, with a 10 mm radius centering a sphere on the coordinate of the ventral striatum peak voxel, and a 12 mm radius centering a sphere on the coordinate of the peak voxels of other regions. 

The behavioral data of scanning rating, and post-scanning ratings were analyzed by the One-way ANOVA (using LSD in post hoc analysis) via software SPSS16. 



## Results 
  
### Behavioral Results 
  
Beauty ratings during scan and post-scan were both concerned and analyzed. During fMRI scanning the beauty ratings of popular music (3.29±0.52) did not differ from those of artistic music (3.24±0.58),   P   = 0.80 (LSD); however, beauty ratings of both musical materials were significantly higher than those of control notes (1.88±0.57), both   P  <0.01 (LSD). In the post-scanning the beauty ratings for the three types of stimuli displayed the same pattern as those in the fMRI scanning, with larger ratings for popular (5.16±0.29) and artistic (5.00±0.28) music than control notes (2.21±0.55), both   P  <0.01 (LSD). The analysis of the familiarity ratings in the post-scanning was also performed, yielding no remarkable differences between these three types of stimuli, with 3.45±0.49 for popular music, 3.31±0.41 for artistic music, and 3.26±0.31 for control notes,   P   = 0.25 (one-way ANOVA). 


### fMRI Results 
  
As can be seen in  , higher BOLD responses in bilateral mOFC and ventral striatum were observed for popular and artistic music than for notes.   shows coordinates, T value, and cluster sizes of the significant activation revealed by these contrasts respectively. A direct contrast between popular and artistic music demonstrated that popular music induced more activation in right putamen (see  ), and artistic music induced more activation in right rACC (see   and  ). Further analyses on the beta values extracted from these two ROIs revealed that, for the right putamen, there were greater activation for popular music condition than for artistic music condition,   t  (34) = 2.30,   P   = 0.03. In contrast, for the right rACC, there were greater activation for the artistic music condition than for the popular music condition,   t  (34) = 2.68,   P   = 0.01. 
   Brain activation of popular and artistic music vs. control material.  
Larger activity in bilateral mOFC and bilateral ventral striatum were found for popular(A) and artistic(B) music than for control material. 
     Activation of reward circuit in the contrast of popular and artistic music.  
(A) Popular music evoked larger BOLD response in the right putamen (26, 6,2) than artistic music; (B) Artistic music evoked larger BOLD response in the right rACC than popular music (BA24/32, 12,36,0). (C) Mean beta values and SD of the ROI analysis in putamen and right rACC for popular music and artistic music comparing control condition, respectively. Within every single ROI, beta values of both popular music and artistic music conditions were first subtracted by the mean beta value of control condition in the same ROI, before two sample t-test. 
     Regions showing a main effect at   p  <0.05 with FDR correction at the cluster level for contrasts Popular music > Notes Clip and Artistic music>Notes Clip.           Regions showing a main effect at p<0.05 with FDR correction at the cluster level for contrasts Popular music > Artistic music and Artistic music>Popular music.        
We also found popular and artistic music both elicited more default mode network/Theory of Mind (DMN/ToM) regions, such as arMFC, PCC/PC, temporal pole, and parahippocampal gyrus, than the notes clip (please see  ). Some other regions, such as angular gyrus and hippocampus, were also observed to show significantly more activation for artistic music than for control note (see  ). DMN/ToM regions, such as left arMFC (BA32/10), left angular gyrus, left inferior temporal gyrus, left hippocampus/parahippocampus, right hippocampus and right inferior temporal gyrus, showed greater BOLD response to artistic music than to popular music (see   and  ). The result of ROI analysis also revealed the significant difference of Beta values in these areas(  P  < 0.01,   t   = 2.80;   P  < 0.01,   t   = 4.02;   P  < 0.01,   t   = 2.89;   P  < 0.01,   t   = 2.91). 
   Cognitive empathy regions were activated in the contrast of artistic vs. popular music.  
(A) The regions consisted of left arMFC, left PC/PCC, left angular gyrus, left hippocampus /parahippocampus, and left and right inferior temporal gyrus. (B) Mean beta values and SD of the ROI analysis in left arMFC (-6,36,20), left PC/PCC (-4,-42,46), left angular gyrus (-32,-80,32) and left hippocampus (-28,-22,-14) for popular music and artistic music comparing control condition, respectively. Within every single ROI, beta values of both popular music and artistic music conditions were first subtracted by the mean beta value of control condition in the same ROI, before two sample t-test. 
  
The parametric analysis revealed similar results. For popular music, as the post aesthetic ratings increased the activation level of right putamen increased (see   and  ). The activity of right interior frontal gyrus and some cerebellar area such as culmen, tonsil and declive also showed linear relationships to aesthetic ratings. We also found a cluster located in supplementary motor area (SMA) in which the activity tracked with aesthetic ratings of popular music. However, the small volume correction only revealed a marginal significant(  P   = 0.058). For artistic music, we found positive linear correlation between the aesthetic ratings and the activation level in several regions, including rACC, arMFC and PCC(see   and  ). However, we can not found any brain regions tracking aesthetic ratings of popular music more synchronously than those of artistic music or regions tracking aesthetic ratings of artistic music more synchronously than those of popular music. 
   Cerebral regions tracking increasing aesthetic rating of popular music and artistic music.  
(A) Cerebral regions tracking increasing rating of popular music included right putamen and IFG. (B) Regions tracking increasing rating of artistic music included right rACC, left arMFC and PCC. 
     Regions tracking increasing aesthetic ratings of popular music and artistic music.        


## Discussion 
  
In the present study, artistic music, popular music and musical notes playing and singing were manipulated to investigate the general and specific neural correlate for acoustical aesthetic. The artistic music was related with higher VS activation compared with control notes. Moreover, the artistic music activated more right mPFC than popular music. These findings indicated the mechanism differences between artistic music and non-artistic music reflects in the reward circuits. In the previous studies focused on neuroaesthetics, parameter or category design was commonly applied, and they focused on the form beauty based on abstract graphics [ ], external beauty based on facial stimuli [ – ], and art beauty based on painting, music, dancing, and sculpture stimuli [ ,  ,  – ]. Two reward circuits were found to be involved in processing of different kinds of beauty: one is the cortical reward circuit (includes mOFC); another is the sub-cortical reward circuit, such as striatum (includes putamen, caudate, and nucleus accumbens). However, inconsistent activation patterns of these two circuits for aesthetics were reported in previous research. For facial beauty, nucleus accumbens and OFC were separately found to be activated in the condition of facial beauty in some research[ ,  ,  ]; whereas in some other studies, these two regions were simultaneously activated for beautiful faces [ ,  ,  ]. For painting beauty, Vartanian and Goel found that the BOLD response of caudate was decreased as the likable ratings got smaller [ ]; Kavabata and Zeke [ ] reported a larger activation of OFC during the appreciation of a beautiful painting. Moreover, OFC and caudate were simultaneously activated when viewing beautiful paintings in other research [ ,  ]. 

These findings demonstrate possible diverse activation patterns in cortical and sub-cortical reward circuits for different aesthetics, which raises a further question about which factors would determine the connection between aesthetics and brain activity. Most recently, an attempt by Wang and Mo [ ] produced some exciting findings and should shed light on this issue. They compared the networks of moral beauty and facial beauty, and found that moral beauty representing advanced social needs recruited only the cortical reward region OFC, whereas facial beauty recruited both the OFC and the subcortical reward region putamen. Given that, we supposed that the correlation between aesthetic objects and the physical (basic) or social (advanced) demand would determine the activation pattern of prefrontal reward region and striatum in reward circuit. That is, the more the aesthetic object relied on basic demand, the more VS would be involved; the more the aesthetic object relied on advanced social demand, the more prefrontal reward regions would be involved. 

The present research was conducted to further verify our aesthetic-demand hypothesis by comparing the appreciation process between artistic music (high level) and popular music (low level) via fMRI technology. As expected, popular and artistic music both elicited larger activation in VS than control note, and popular music evoked larger activation in right putamen than artistic music. The parametric analyses also revealed that the activation of putamen tracked aesthetic ratings of popular music significantly more synchronously than those of artistic music. For the cortical circuit, popular and artistic music both elicited larger BOLD response in mOFC (BA11) than control note. Moreover, artistic music evoked larger BOLD response in right rACC (BA32) than popular music. The BOLD signal in right rACC and the adjacent anterior prefrontal cortex (aPFC, BA10) also showed higher correlation with the aesthetic rating of artistic music than with the popular music. 

mOFC and rACC were found activated in response to the reward stimuli[ ,  – ]. In a study about cross-modality aesthetic, the activity of mOFC in BA11 was observed during visual or acoustical art appreciation. The nearby regions such as rACC (BA32) and aPFC (BA10) also showed sensitivity to the beauty[ ]. The latter two regions were collectively considered as medial prefrontal cortex (mPFC) [ ,  ], which would also be preferentially recruited by the value of rewards as mOFC [ – ]. It is worth noting that, in the present study, the beauty ratings for artistic and popular music were not significantly different. Therefore, the beauty rating difference can not be responsible for the higher activation of mPFC for artistic music than for popular music. Considering the parametric analysis results which suggested that the activation level of mPFC was much more correlative with artistic music rating, we propose that the increased mPFC activity for artistic music would derive from the greater affection for artistic stimuli. Our view agreed with the results of Trost and colleagues in which they examined the neural correlates for disparate musical emotions[ ]. In this study, emotions, such as tenderness, peacefulness, transcendence, and nostalgia, which were characterized by sublime aesthetic also features recruited more rACC than other emotions. Alternatively, rACC has been considered to serve a role in recruiting greater attentional control for emotion processing[ ,  ]. Under these circumstances, the activation of rACC in artistic music appreciation in present study might reflect more intensive intellectual efforts. In summary, the results of present study supported our first hypothesis that the high level artistic work, which was relevant to social needs or more intensive intellectual response, would elicit higher activation in the frontal cortex, whereas the low level popular work, which was relevant to physical needs, would elicit higher activation in the striatum region. 

In addition, we also found that artistic music evoked higher arousal in the default network/ToM than popular music, which indicated larger involvement of social cognition for artistic music appreciation. Empathic engagement between an audience and art works is considered as another crucial element for artistic appreciation[ – ], especially in the music domain. From this point of view, an audience could understand or experience the intention, affective and feeling implicated in the artworks through empathy. Based on the studies of normal and brain lesion participants, two types of empathy—emotional empathy and cognitive empathy—have been identified[ ,  ]. Emotional empathy is a pure emotional contagion, which relies on the mirror neuron system (MNS), while cognitive empathy is more advanced and relies on the mentalizing or theory of mind (ToM) system. Although default network/ToM regions were also found to be activated during art work appreciation in previous studies, activation in these areas was never considered to reflect cognitive empathy [ ,  ,  ]. For example, in a study of Brown and colleagues[ ], participants were asked to listen to beautiful but unfamiliar music, which elicited activation in the left rACC (BA32), retrosplenial cortex (BA29/30), and hippocampus. The activation of these regions was interpreted as the representation of emotion processing. In another work of musical appreciation, sublime music evoked the activity of vmPFC and hippocampus/ parahippocampus, this finding was determined to be an automatically associative processes for this kind of music [ ]. But more and more evidence verifies the possible association between the default mode network for art appreciation and social cognition. In the study of Geday and Gjedde [ ], strong emotion caused a decrease of the deactivation of the arMFC during the task. Moreover, this effect disappeared in the situation without self-involvement, which demonstrated the possible influence of social cognition on arMFC activation. More recently, Vessel [ ] found that the most moving art works were related to the higher arousal in arMFC, PCC, and hippocampus. These findings were attributed to the personal relevance during aesthetic experience. Aesthetic was proposed as a process that requires personal relevance to combine the perception and emotional reaction. Given that, the larger activation for artistic music than for popular music in default network/ToM related regions should not represent the beauty difference between these two types of music, because no significant difference in beauty rating were found in our study. The parametric analysis results in this paper also gave additional evidence for the role of these areas in music appreciation. These results also exclude the possibility that the DNM have just been recruited in artistic music condition for a simple music monitoring task, even given that DMN is also relevant to internal goal or simple tasks. In summary, the more sensitive response in DMN/ToM related regions to artistic music appreciation than popular music appreciation would represent the greater involvement of advanced social cognitive empathy for artistic music than popular music. 


## Conclusions 
  
This study applied fMRI technology to explore the disparate neural activations in appreciation of popular and artistic music. Both sub-cortical (e.g., VS) and cortical (e.g., vmPFC) reward regions engaged in artistic and popular music aesthetic appreciation, while the sub-cortical reward region (e.g., putamen) was more sensitive to popular music while the cortical region (e.g., mPFC) was more sensitive to artistic music. In addition, the cognitive empathy regions, including PCC/PC, TPJp and arMFC, were more responsive to artistic music than popular music and control notes, implying more social cognition involved artistic music aesthetic appreciation. In conclusion, this study gives clear neuronal evidences supporting the view that artistic music is of intelligence while the popular music is of physiology. 


## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-68'>
<h2>68. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/25700742/' target='_blank'>25700742</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> The role of the amygdala during emotional processing in Huntington's disease: From pre-manifest to late stage disease</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Neuropsychologia</p>
<p><strong>Publication Year:</strong> 2015</p>
<p><strong>DOI:</strong> 10.1016/j.neuropsychologia.2015.02.017</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4415907/' target='_blank'>4415907</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study reports functional MRI during an implicit social task (angry vs neutral faces—perception/understanding of others). Healthy control groups (ages within 17–65) are included and results comparing controls to pre-manifest HD gene carriers are reported separately. Imaging analyses include whole-brain second-level GLM contrasts (angry vs neutral faces and group comparisons) and whole-brain PPI connectivity analyses (with cluster-level correction). Although a left amygdala seed ROI was used for the PPI, the paper does not report only ROI results—the study presents whole-brain analyses and group-level effects. Thus it meets all inclusion criteria (fMRI social task, healthy participants reported separately, whole-brain analyses) and does not meet any exclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
## Background 
  
Deficits in emotional processing can be detected in the pre-manifest stage of Huntington's disease and negative emotion recognition has been identified as a predictor of clinical diagnosis. The underlying neuropathological correlates of such deficits are typically established using correlative structural MRI studies. This approach does not take into consideration the impact of disruption to the complex interactions between multiple brain circuits on emotional processing. Therefore, exploration of the neural substrates of emotional processing in pre-manifest HD using fMRI connectivity analysis may be a useful way of evaluating the way brain regions interrelate in the period prior to diagnosis. 


## Methods 
  
We investigated the impact of predicted time to disease onset on brain activation when participants were exposed to pictures of faces with angry and neutral expressions, in 20 pre-manifest HD gene carriers and 23 healthy controls. On the basis of the results of this initial study went on to look at amygdala dependent cognitive performance in 79 Huntington's disease patients from a cross-section of disease stages (pre-manifest to late disease) and 26 healthy controls, using a validated theory of mind task: “the Reading the Mind in the Eyes Test” which has been previously been shown to be amygdala dependent. 


## Results 
  
Psychophysiological interaction analysis identified reduced connectivity between the left amygdala and right fusiform facial area in pre-manifest HD gene carriers compared to controls when viewing angry compared to neutral faces. Change in PPI connectivity scores correlated with predicted time to disease onset (  r  =0.45,   p  <0.05). Furthermore, performance on the “Reading the Mind in the Eyes Test” correlated negatively with proximity to disease onset and became progressively worse with each stage of disease. 


## Conclusion 
  
Abnormalities in the neural networks underlying social cognition and emotional processing can be detected prior to clinical diagnosis in Huntington's disease. Connectivity between the amygdala and other brain regions is impacted by the disease process in pre-manifest HD and may therefore be a useful way of identifying participants who are approaching a clinical diagnosis. Furthermore, the “Reading the Mind in the Eyes Test” is a surrogate measure of amygdala function that is clinically useful across the entire cross-section of disease stages in HD. 

   Highlights  
  
Reduced connectivity between the left amygdala and right FFA during emotional processing in pre-HD. 
  
Amygdala dependent theory of mind performance correlated with estimated time to onset in pre-HD. 
  
Theory of mind performance correlated with PPI connectivity in a small pre-HD sub-group. 
  
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (32970 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Huntington's disease (HD) is an incurable, progressive, neurodegenerative disorder characterised clinically by a triad of motor, cognitive and psychiatric problems ( ) which is caused by an expanded cytosine–adenine–guanine (CAG) repeat in exon 1 of the huntingtin gene. Neuropathological changes can be detected decades before clinical signs emerge ( ) beginning in the striatum and progressing to widespread brain atrophy ( ). Although HD is diagnosed based on the presence of unequivocal motor abnormalities, cognitive abnormalities can be detected in most gene carriers prior to this point. 

The cognitive profile of manifest HD includes deficits in executive function, emotional processing and memory ( ). In the prodromal phase the impairment is more subtle but abnormalities in psychomotor processing speed, verbal fluency and the recognition of negative emotions are common ( ). The direct functional implications of these cognitive changes are still unclear ( ) but, reduced occupational performance and difficulty managing finances can be seen in pre-manifest HD gene carriers (pre-HD) who are approaching diagnosis ( ). Furthermore, changes in personality and difficulties with social interaction are key features of early HD. One explanation for these occupational and social problems is an emerging impairment in emotional oversight e.g. accurately identifying, interpreting and responding to the emotions and intentions of others all of which are necessary for maintaining interpersonal interactions and socially appropriate behaviour. 

Multiple studies have shown that HD patients are impaired on emotion recognition tasks ( ). A recent systematic review of the literature demonstrated that anger recognition is the most consistently reported impairment, closely followed by disgust and fear recognition ( ) in manifest disease. While in PMGC's, selective impairments in disgust recognition have been found ( ) and a relationship between anger recognition and proximity to estimated time of disease onset has been reported ( ). However, some studies argue that there is a more generalised impairment encompassing all negative emotions ( ), with change in negative emotion recognition over a three year period having positive predictive value for identifying PMGC's who reached a clinical diagnosis during that time ( ). As such, emotion recognition may be a useful marker of very early disease related changes in HD. 

The underlying neural substrates of emotion recognition deficits in HD have typically been established using correlative structural MRI studies ( ). Such studies have identified correlations between tissue degeneration in the striatum associated with impaired recognition of surprise, disgust, anger and fear ( ); between the cerebellum ( ) and anger recognition and between the anterior insula and disgust recognition in both manifest ( ) and pre-manifest patients ( ). It has been argued however, that disease-related behavioural changes in HD are more likely to relate to disruption of the complex interactions between multiple brain circuits rather than as a result of distinct regional tissue degeneration ( ) which cannot be measured on structural MRI. 

Functional MRI has been used to interrogate emotional processing in PMGC's in a small number of studies which look at changes in Bold Oxygen Level Dependent (BOLD) response in brain regions during emotional processing. This approach can therefore detect disease related changes earlier than the classic approach.   asked PMGC's to complete an emotion recognition task whilst undergoing fMRI and reported that negative stimuli evoked decreased activation in the amygdala, hippocampus, striatum, insula, cingulate and prefrontal cortices, as well as in sensorimotor, temporal and visual areas. Other studies measure implicit emotion perception to reduce the confounding effects of performance on BOLD response, by asking participants to perform a distracter task such as a gender decision task. Hennenlotter and colleagues ( ) looked at neural activation to grey scale pictures of faces displaying either disgusted, surprised or neutral expressions in PMGC's. BOLD response was reported to be lower than controls in the left dorsal (intermediate) anterior insula/opercular region and left putamen during disgust (relative to neutral) processing. However, Novak and colleagues found activation differences in a widely distributed network of brain regions involved including prefrontal, partietal and cingulate cortices during disgust, anger and happiness processing which was not restricted to any particular emotional expression or emotion valence ( ). 

ToM refers to an individual's ability to understand the presence of beliefs, feelings, intentions and interests in other people that can differ from their own and from reality ( ). The ability to attribute mental states to others is likely to have a central role on human social interaction as it allows us to predict the behaviour of others. Furthermore, affective ToM and emotion recognition have been shown to activate overlapping brain regions, namely the inferior frontal gyrus, the superior temporal sulcus, the temporal pole and the amygdala ( ) Despite this, ToM is an area of research that has received relatively little attention in HD. Changes in empathy have been found in patients with manifest HD demonstrated by their impaired interpretation of humorous cartoons and story vignettes ( ). Further abnormalities have been shown in similar populations of HD patients on ToM tasks such as the “Reading the Mind in the Eyes Task” (RMET) and the faux pas task ( ) with deficits in ToM found to relate to executive functioning ( ) however, to our knowledge however, ToM has not been studied in PMGC's. In this study the RMET was used as a surrogate clinical measure of amygdala function on the basis of previous studies ( ), rather than to interrogate ToM in HD. 

In the current study we used an implicit emotional processing task to look for differences in neural activation between PMGC's and healthy controls when viewing grey scale pictures of angry and neutral faces. Unlike previous studies, the pictures of faces were contrasted with pictures of buildings and participants were asked to respond indicating whether they saw a face or a house on the screen. Houses were used as a contrast in this task to increase the power to functionally detect differences in BOLD response during the processing of angry but not neutral faces and not to mask the effect of brain regions which have been previously shown to be activated, non-discriminately by all facial emotions ( ). 

Connectivity analysis of the results indicated that abnormalities in the way that activity in the amygdala covaries with other brain regions during emotional processing may be an early disease related marker in PMGC's. To identify whether this could be measured clinically, a validated theory of mind test (ToM) which has previously been shown to impaired in patients with lesions to the amygdala ( ): the Reading the Mind in the Eyes Test (RMET) ( ), was used in a population of PMGC's (11 of whom also underwent the fMRI study) and extended to a population of manifest patient from all different stages of the disease. 

The combination of the two experiments provides a comprehensive assessment of amygdala related emotional processing in HD from the earliest pre-manifest stage of the disease through to advanced HD. On the basis of the existing literature we initially predicted that PMGC's would have decreased activation in and connectivity in a wide network of brain regions compared to controls when processing emotional stimuli during fMRI. Following the imaging study we then went on to hypothesise that abnormalities in ToM performance would increase progressively at more advanced stages of the disease in HD. 


## Methods, materials and results 
  
### Participants 
  
All participants were recruited from the multidisciplinary Huntington's disease service clinic at the John Van Geest Centre for Brain Repair, UK. Control subjects were recruited through links with the clinic. Approval for this study was granted by the Local Regional Ethics Committee and Addenbrooke's hospital R&D department. Informed consent was taken from participants. 

Two cohorts of participants were recruited:   
20 Pre-manifest HD gene carriers (PMGC) (10 males, average age=45.8 years S.D=11.16) and 23 controls (10 males, average age=42.1 years S.D.=12.04) underwent functional imaging. 
  
29 PMGC (14 males, average age=43.5 years S.D=9.5) 11 of whom were also scanned (5 males, average age=47.7 years S.D=13.2), 50 manifest patients (27 males, average age=54.4 S.D=12.1) and a further 26 different healthy controls (14 male, average age=59.0 S.D=11.7) were tested on the RMET. 
  

Participant demographics are detailed in   (cohort 1) and   (cohort 2). 


### Study 1: methods 
  
#### fMRI task 
  
To test neural activation in response to pictures of angry faces, participants underwent functional MRI scanning. Stimuli were visible via an angled mirror positioned above their eyes reflecting images projected onto a screen at the end of the scanner bor. Responses were made using the first 2 buttons on a 4 button response box held in the participant's right hand. Participants were instructed to press button 1 to identify a house and button 2 to identify a face. 

The “face” stimuli had either an angry or a neutral expression, although participants were not informed of the difference in emotional expressions and were not required to respond differently to faces of different emotions. The “face” photographs were selected from the NimStim Face Stimulus Set (  www.macbrain.org  ) and the Karolinska directed emotional faces (KDEF); they were chosen on the basis of independent emotional ratings. Participants were presented with each expression 32 times giving a total of 64 pictures of faces from 33 separate actors. The gender and identify of faces was fully randomised. 320 pictorial stimuli were presented in total with the remaining 256 pictures made up of 20 different houses. The two performance effects of interest were infrequent (face) vs. frequent (house) stimuli and angry vs. neutral face stimuli. 

Pictures were presented in a predefined pseudo-randomised order followed by a low contrast central cross. Each stimulus was presented for 750 ms, with an inter-trial interval of 750 ms to encourage participants to respond quickly and instinctively to the pictures and to reduce awareness of the overt emotional content of the face stimulus. The total experiment lasted for 9 min 20 s. 


#### fMRI data acquisition 
  
Patients were scanned at the MRC Cognition and Brain Sciences Unit, Cambridge, using a 3T Siemens TIM Trio MRI scanner. During the task 290 T2-weighted echo-planar images depicting BOLD signal were acquired, the first 10 of which were discarded to avoid T1-equilibrium effects. Each image consisted of 32 slices of 3 mm thickness with a 1 mm interslice gap and an in-plane resolution of 3×3 mm . The repetition time (TR) was 2 s with an echo time (TE) of 30 s. Slices were angled away from the orbits to avoid signal dropout due to magnetic susceptibility inhomogeneity. Stimuli were presented on a screen with a resolution of 1024×768 pixels which was visualised using a mirror positioned within the scanner at a viewing distance of 90 mm. 


#### Data analysis 
  
##### Behavioural data 
  
Behavioural performance was evaluated using two outcome measures: accuracy (percentage of pictures correctly classified) and mean latency to response for both angry and neutral faces. No accuracy measures were taken for the “house” stimuli. Multivariate analysis of variance (MANOVA) was used to compare performance between gene carriers and controls and a repeated measures analysis of variance (rm-ANOVA) was used to compare performance between emotional conditions. 


##### Imaging data preprocessing 
  
MRI data were processed using SPM8 (  www.fil.ion.ucl.ac.uk/spm  ). Functional MRI data were converted from DICOM to NIFTII images, spatially realigned to the first image, and corrected for acquisition delay with references to the middle slice. There was no exclusion of subjects. All subjects that had finished the EGNG task were included in the analysis. To determine whether the preHD group had greater movements during image acquisition than controls', a measure of displacement was obtained for each subject using the motion correction parameters from SPM realignment function. We took the translation and rotation measurements in   x  ,   y  , and   z   co-ordinates between each volume and then calculated the root mean square of the three translations and the three rotations. We then summed the translation and rotation measures across all the volumes to give indexes of the total displacement for each subject. There was no significant effect of group (pre-HD or control) on total amount of translation (  F  (1,42)=3.24,   p  =0.08) or rotation (  F  (1,42)=1.64,   p  =0.21) during scanning. The mean fMRI and MP-RAGE images were coregistered using mutual information, and the MP-RAGE image was segmented and normalised to the Montreal Neurological Institute (MNI) T1 template by linear and non-linear deformations. The normalisation parameters were applied to all spatiotemporally realigned functional images, and normalised images were resampled to 2×2×2 mm  before smoothing with an isotropic Gaussian kernel with full-width half-maximum of 8 mm. 


##### fMRI data analysis 
  
A first level general linear model (GLM) included three epoch regressors (angry faces, neutral faces, and houses) for trials with correct responses. Additional regressors representing trials with incorrect or omitted responses and six rigid-body motion correction parameters were included as nuisance covariates. Regressors were convolved with a canonical hemodynamic response function, and the data were high-pass filtered with a frequency cutoff at 128 s. 

To assess brain activity associated with angry processing, first-level contrast images were generated for angry vs. neutral faces and these were entered into a second-level analysis to test for averaged effects across participants and group effects between PMGC and controls. 


##### Psychophysiological interactions for brain connectivity analysis 
  
A PPI analysis was performed to examine the functional connectivity between the amygdala and other potential brain regions during emotional processing ( ). The PPI analysis tested how physiological connectivity between a source region at amygdala and the rest of the brain varied with the psychological context (i.e., angry vs. neutral faces). 

Our primary interest is the angry vs. neutral faces comparison in the connectivity analysis. A second contrast, angry faces vs. houses was used to increase the power to functionally detect the amygdala, because neutral faces have also been shown to active the amygdala ( ). Two further contrasts (faces vs. houses and houses vs. faces) were conducted as a sanity check, ensuring that our task activates the functionally specific regions. Note that previous studies showed that the comparison between angry faces to houses increased the power to detect the amygdala ( ). Although the task has been shown to active the amygdala in this and previous studies, the cluster extends beyond amygdala (see  , supplementary data). Therefore it is not straightforward to use the fMRI results as a localizer. Here we used the same approach as in our previous study ( ) where the contrast angry faces vs. houses was used to find the peak voxel in the amygdala (−24, −4, −16), and defined a 10-mm sphere around this peak coordinate. Our previous study showed that this approach gave similar result as defining a subject-specific ROIs ( ). 

For each participant, we computed the first eigenvariate of the BOLD time courses from all voxels in the left amygdala ROI and derived the “neural signal” of the source region by deconvolving the hemodynamic response function. The psychophysiological interaction regressor was calculated as the product of the deconvolved time course and a vector coding for the psychological variable (1 for angry faces, −1 for neutral faces). Participant specific PPI models included the psychological (angry faces vs. neutral faces), physiological (left amygdala signal), and psychophysiological variables and were re-convolved by the canonical hemodynamic response function. Six motion correction parameters were included as nuisance covariates. First-level contrast images were generated for PPIs and were entered into second level GLM analysis for contrasts of interest. 




### Study 1: results 
  
#### Demographics 
  
Patient demographics and clinical characteristics are shown in detail in  . PMCG's were well matched with controls for age. As predicted the PMGC “close” and “far” groups differed from each other in terms of estimated time to onset (  F  (1,19)=26.68,   p  <0.0001), disease burden score (  F  (1,19)=17.02,   p  <0.001) and UHDRS score (  F  (1,19)=6.25,   p  <0.05). 


#### Behavioural results 
  
Patients responded to pictures of faces as quickly (  F  (3,47)=0.925,   p  =0.44) and accurately (  F  (3,47)=2.08,   p  =0.13) as controls. The angry/neutral contrast was an implicit feature of the task design, however there was no significant effect of emotion on accuracy (  F  (3,40)=1.803,   p  =0.162) or latency (  F  (3,40)=0.783,   p  =0.511). 


#### Connectivity analysis 
  
Details on the brain regions activated during the task have been reported in supplementary  . we defined the left amygdala as the seed region (10 mM sphere centred at −24, −4, −16) from an “angry faces” minus “houses” contrast for PPI analysis (supplementary  , also see PPI connectivity analysis in  ). neural activity in the seed region was found to covary positively with the bilateral fusiform facial area (FFA) (left: −32, −78, −8; right: 38, −78, −4) and caudal anterior cingulate (left: −10, 20, 36; right: 16, 8, 34) across all participants during exposure to angry faces ( A). Differences were detected in the extent of PPI activity between the left amygdala and the right FFA (30, −70, −10) ( B) with PMGC exhibiting reduced connectivity compared to controls, corrected for multiple comparison at the cluster level (FDR corrected   p  <0.05). 

PPI connectivity between the left amygdala and the right FFA correlated significantly with estimated years to disease onset (  r  =0.45,   p  <0.05) but not disease burden score (  r  =−0.28,   p  =0.24) ( ). Change in PPI connectivity scores did not correlate significantly with age for controls (  r  =−0.04,   p  =0.86) but there was a significant relationship in PMGC (  r  =−0.54,   p  <0.01). 



### Study 2: methods 
  
#### Background assessments 
  
Pre-morbid verbal IQ was estimated using the National Adult Reading Test (NART) ( ). Depressive symptomatology was evaluated using the Beck Depression Inventory revised (BDI) ( ), global cognitive function was measured using the Mini Mental State Exam (MMSE) ( ) and verbal fluency was measured to provide a small insight into executive dysfunction ( ). 

Motor impairment and daily functioning were assessed by an experienced neurologist using the UHDRS ( ) motor, total functional assessment, total functional capacity and independence score subscales for all HD gene carriers. Gene carriers with a UHDRS score of ≤5 were classified as PMCG's. Manifest patients were staged according to previously published criteria based on the Total Functional Capacity (TFC) score: scores of between 11 and 13 were classified as early disease, between 7 and 10 as moderate disease and scores of 6 and less as late disease ( ). 


#### Social cognition task 
  
The Reading the Mind in the Eyes Task (RMET) ( ) is a measure of affective ToM. Participants are presented with a picture showing the eye region in isolation from the rest of the face. The participant is required to say which of 4 emotional/mental state words positioned around the picture best captures the thoughts or feelings portrayed in the eyes. Total number of correct responses was recorded. 


#### Data analysis 
  
Levene's test for Equality of Error Variances confirmed homogeneity of variance therefore between-group differences were examined using analysis of variance (ANOVA) with post-hoc comparison by   t  -tests with Bonferroni correction for multiple comparisons. However, when tested at the whole group level using a Shapiro–Wilk test (  p  =0.18), performance on the RMET was not normally distributed therefore performance was correlated with clinical markers of disease progression (UHDRS motor score and disease burden score) and daily functioning (TFA) using a Spearman's Rho non-parametric correlation. Furthermore, the data was normalised and linear regression analyses were used to quantify the strength of the relationship between RMET and UHDRS, DBS, and NART. The following variables were not included because of their relationship with other variables in the regression analyses: age because it was strongly associated with DBS, verbal fluency because it was associated with NART and BDI because it was associated with UHDRS. All analyses were performed on Predictive Analytic SoftWare (PASW) Statistics, version 21. 



### Study 2: results 
  
#### Demographics 
  
Participant demographics and clinical characteristics are shown in detail in  . In general the manifest patients were well matched with controls for age, NART and BDI however, PMGC were significantly younger than controls (  F  (5,97)=5.50,   p  <0.001) and late stage patients had a significantly lower NART than controls (  F  (5,96)=2.57,   p  <0.05). As anticipated, manifest patients were found to have a higher UHDRS (  F  (4,74)=65.56,   p  <0.001), lower total functional assessment (FA) scores (  F  (4,74)=156.5,   p  <0.001), lower verbal fluency score than PMGC's (  F  (3,72)=10.00,   p  <0.01) and lower MMSE scores (  F  (5,92)=12.37,   p  <0.001) compared to PMGC's. It should also be noted that gender distribution in the early HD group was uneven with more men than women and may therefore effect the analysis. 


#### Manifest HD 
  
Total number of correct responses on the RMET task deteriorated significantly with disease stage (  F  (7,65)=9.377,   p  <0.001) ( ). Post hoc investigation revealed that PMCG's were the only group not to differ from controls (  p  =1.0). 

Performance on the RMET task correlated with motor impairment (  r  =−0.71,   p  <0.001), disease burden score (  r  = −0.69,   p  <0.001) and the UHDRS functional assessment (FA) score (  r  =0.60,   p  <0.01),  . Linear regression analyses identified that RMET performance related to UHDRS (  t  =−4.0,   p  <0.001), NART (  t  =3.64,   p  <0.001) and DBS (  t  =−2.17,   p  <0.05). 


#### Pre-manifest HD gene carriers 
  
Performance on the RMET task correlated with the number of estimated years to disease onset (  r  =0.52,   p  <0.005) and disease burden score (  r  =−0.41,   p  <0.05) ( ) in PMGC's with performance deteriorating as the time to disease onset shortened. However, on all other measures PMGC's were equivalent to controls. 


#### PPI connectivity and performance on the RMET 
  
Performance on the RMET and change in PPI connectivity between the left amydgala and rFFA was not significantly correlated ( ;   r  =0.38,   p  =0.25). However, when the data from the 2 PMGC's who completed the two studies greater than 1 year apart was removed, performance on the RMET significantly correlated with change in PPI connectivity (  r  =0.77,   p  <0.05). Although caution should be expressed when interpreting these data due to the small sample size they provide relevant exploratory insights. 




## Discussion 
  
The combined results of these studies suggest that the amygdala is affected early in the course of HD; even from the late pre-manifest stage. Specifically, connectivity between the left amygdala and the right FFA reduces in line with estimated time to disease onset during emotional processing; the magnitude of this effect relates to proximity to disease onset. Additionally, performance on the RMET, a task known to activate the amygdala ( ), in PMGC's also correlated with estimated proximity to disease onset and deteriorated further with every cross-sectional disease stage. Finally, PPI connectivity and RMET performance correlated highly in the small subgroup of PMGC's who completed both studies within a 1 year window. 

To our knowledge this is the first study to look at the influence of disease stage on social cognition performance and the first to report a relationship with predicted time to disease onset in PMGC's. Consistent with the work of others, the RMET was found to be a sensitive tool capable of detecting deficits in social cognition in HD ( ). In addition however, we were able to demonstrate that performance on the RMET was influenced by the length of exposure to the pathological effects of the CAG expansion (DBS), motor symptomatology (UHDRS) and cognitive reserve (NART). All of which support the use of the RMET as a clinical outcome measure in HD. 

Successful completion of the RMET is heavily reliant upon activation of the amygdala ( ); a region that has been implicated in face ( ) and facial emotion processing ( ), specifically during recognition of fearful faces ( ). Analysis of functional MRI data collected in this study found reduced functional connectivity between the left amygdala and rFFA in PMGC's compared to healthy controls when exposed to pictures of angry faces. Reduced functional connectivity has previously been shown in PMGC's during tasks of working memory ( ), planning ( ) and motor performance ( ). However, to the best of our knowledge, this is the first study to look at functional connectivity during emotional processing in such a group. Of relevance to this is a recent meta-analysis looking at regions of degeneration in PMGC's which identified the amygdala as a region commonly reported as vulnerable to HD neuropathology ( ). In addition the amygdala has also been linked to subjective fear responses in manifest HD ( ) and the recognition of emotions such as disgust and happiness ( ) in PMGC's; while in rodent models of HD neuropathology in the amygdala has been shown to be associated with social and emotional memory ( ), and motivational processes ( ). Consistent with this literature the current study provides evidence of amygdala dysfunction in HD beginning prior to the onset of overt clinical features. 

Both tasks used in this study involve some element of social cognition and are both reliant upon amygdala function thereby implicating the amygdala in the process of interpreting social meaning ( ) rather than in the identification of specific emotions. Additional support for this theory comes from emerging evidence from the wider literature that suggests that the amygdala is responsible for detecting perceptual salience and biological relevance in facial emotions ( ). Furthermore, a recent study of neurosurgical patients with chronically implanted depth electrodes in the amygdalae demonstrated that there are neurons in this structure that code specifically for both fearful and happy faces ( ). 

The complementary evidence from both the RMET and fMRI studies presented here, especially the involvement of the amygdala in both tasks support the rationale that both social cognition and emotional processing in HD share a common neural pathway. Moreover, it has previously been reported that impairments in the recognition of fear following amygdala damage are a result of an inability to fixate on the eye region of the face ( ), therefore we propose that the wider emotional processing/social cognition problems seen in HD are caused by a similar impairment: a shift in attention away from the eye region of the face during emotional processing, mediated by neuronal dysfunction in the amygdala. Further work is needed to directly test this theory and the RMET may be a useful and reliable way of measuring the functional integrity of this pathway. It may also be useful, in combination with measures such as statistical estimates of disease burden and the presence of subtle motor signs, as a way of identifying PMGC's at risk of phenoconverting. 

It is noteworthy that the PPI connectivity correlated with predicted time to disease onset but not DBS which initially appears surprising however, may be explained by the differences between the two models. Predicted time to disease onset was calculated using the   survival analysis equation in this study. This model deals exclusively with the pre-manifest stage of HD and estimates the age at which a gene carrier will meet the criteria for clinical diagnosis. Age at diagnosis has been shown to be highly influenced by the CAG length ( ). However, CAG length has less of an effect on the rate of disease progression in manifest disease. Therefore, when looking at the relationship between RMET and clinical measures of HD, the DBS ( ) was used as a continuous variable that could be applied to all gene carriers (both PMGC's and manifest patients). The DBS is a linear equation that places less emphasis on the CAG repeat size and more on the age of the participant (or the time of exposure to the effects of the expansion) which provides an estimate of HD pathology. The DBS has been shown to be a good predictor of striatal pathology in post-mortem tissue ( ). Based upon this, reduced PPI connectivity between the amygdala and FFA could be a useful outcome measure for monitoring proximity to disease onset but not disease progression. Therefore it may be useful future disease modifying trials in PMGC's. Conversely, the RMET is a useful tool by which to assess disease onset and progression. 

The findings of this study may be useful when trying to understand the cause of the deterioration seen in daily functioning in the early stages of HD ( ) although further work is needed to establish a link between the two. However, it is difficult to ascertain the impact that such a change has on the quality of life (QoL) of PMGC's and their families as the scales and assessments that are currently available to measure QoL, while useful in manifest disease, are not sensitive enough to detect change in the pre-manifest stage. Based upon the findings of this study this is an area that warrants further investigation. 

There are clear limitations to the work presented here which need to be acknowledged. Due to the evolution of this project over a number of years, only a small number of PMGC's completed both the functional imaging and the RMET within a 1 year window. This reduced our power to detect between group differences, although a significant relationship was identified, but also potentially limits the generalisability of the data to a wider HD population. Further work is needed to confirm the link between amygdala connectivity and RMET in a larger cohort of PMGC's taking these points into consideration. Furthermore, emotion recognition was not tested in the PMGC's therefore we do not know whether or how reduced PPI connectivity relates to clinically measureable abnormalities in emotional processing. Also, given the potential utility of the RMET for both clinical and research endpoints, a systematic evaluation of the factors influencing ToM and emotional processing in HD is warranted. For example, executive function ( ), mood ( ) and age ( ) have all been shown to effect performance in other disorders, however, due to time restraints and the complexity of studying advanced HD patients these were not adequately considered in the current study but should be considered in future work. Furthermore, it should be noted that the PPI analyses were completed using a more liberal threshold for comparison than was used in the whole brain imaging analyses. This was because the effect seen following the PPI analysis was not of sufficient strength to withstand correction for multiple comparisons; mostly likely due to the number of participants studied. Therefore these results need to be studied further. 

In summary, this work provides evidence that the amygdala and its connections are involved in the loss of high order emotional processing in HD. Both loss of effective connectivity between the amygdala and the FFA and performance on the social cognition task, correlated with time to disease onset and may be useful in identifying PMGC's who are at immediate risk of developing overt disease. In addition, social cognition performance continues to be a useful marker of emotional processing capabilities and social cognition throughout advancing disease making it a promising task for monitoring the complex cognitive changes associated with disease progression. 


## Conflict of interest 
  
None. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-69'>
<h2>69. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/22828495/' target='_blank'>22828495</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Genetic variants affecting the neural processing of human facial expressions: evidence using a genome-wide functional imaging approach</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Transl Psychiatry</p>
<p><strong>Publication Year:</strong> 2012</p>
<p><strong>DOI:</strong> 10.1038/tp.2012.67</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3410629/' target='_blank'>3410629</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study uses fMRI during a social-related task (face/emotion perception) relevant to ‘Perception and Understanding of Others’. It includes healthy adult participants within 17–65 (Norwegian healthy controls and an independent North American healthy sample). Whole-brain analyses were performed in the discovery Norwegian sample (voxel-wise genome-wide analyses across ~20,000 task-sensitive voxels); ROI analyses were also reported for the replication sample. The inclusion criteria allow studies with both whole-brain and ROI analyses; here whole-brain results are presented and healthy participants are part of the sample, with further replication in a healthy-only cohort. No exclusion criteria (only-ROI analyses or only patient samples) apply. Therefore the study meets the review’s objectives and inclusion criteria.</p>
<p><strong>Fulltext Confidence:</strong> 0.8</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Human faces present crucial visual information for social interaction. Specialized brain regions are involved in the perception of faces, with the fusiform face area (FFA) a key neuronal substrate. Face processing is genetically controlled, but by which specific genes is unknown. A genome-wide approach identified common single nucleotide polymorphisms (SNPs) associated with areas of increased brain activity in response to affective facial expressions, measured with functional magnetic resonance imaging. SNPs in 20 genetic regions were linked with neural responses to negative facial expressions in a Norwegian sample (  n  =246), which included patients with mental illness. Three genetic regions were linked with FFA activation in a further discovery experiment using positive facial expressions and involving many of the same individuals (  n  =284). Two of these three regions showed significant association with right FFA activation to negative facial expressions in an independent North American replication sample of healthy Caucasians (  n  =85, 3q26.31,   P  =0.004; 20p12.3,   P  =0.045). The activation patterns were particularly striking for the SNP in 3q26.31, which lies in a gene   TMEM212  ; only the FFA was activated. The specialized function of this brain region suggests that   TMEM212   could contribute to the innate architecture of face processing. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (24282 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Face processing is a crucial cognitive ability. Rapid recognition of faces identifies individuals and informs us about basic properties such as age, gender and race, as well as complex processes such as direction of attention, mood and intent. Thus, the ability to extract such information from even a momentary viewing of a face is critically important for normal social interactions. 

Several lines of evidence indicate that face processing is unique and qualitatively different from processing of other visual stimuli.  Studies of neurological disorders suggest a dedicated circuitry exists in the human brain for face processing. Converging evidence now suggests that a network of multiple brain regions, in particular the right fusiform gyrus, supports face perception. 

Similar specialized processing of faces has been reported in macaques,  and it has been suggested that specialized pathways for face processing were critical for the survival of our primate ancestors.  This implies that face processing is under some genetic control, and findings in infants show that face recognition is an innate human capability.  In fact, using behavioral tasks several twin studies have detected a high degree of heritability in face processing  (one study found that correlation of one particular score of face recognition for monozygotic twins (0.70) was more than double that of dizygotic twins correlation (0.29) ). However, the specific genes involved in face processing are unknown, as is the effects of such genes on the neural networks supporting this specialized behavior. 

The aim of the current study was to identify common genetic variants associated with neural activation during face processing. Using genome-wide genotype microarray technology together with functional magnetic resonance imaging (fMRI) in an ethnically homogenous sample of healthy controls and psychiatric patients from Norway,  and an independent replication sample of Caucasians from North America,  we discovered two genomic regions associated with neural activation during face processing. 


## Materials and methods 
  
The Norwegian TOP sample consisted of 246 individuals after quality control on the genotype and imaging data. The fMRI protocol consisted of a widely utilized emotional faces paradigm,  involving the perceptual processing (matching) of emotional facial expressions (experimental condition) or geometric shapes (control condition). Subjects completed two sessions, one with all   negativ  e (angry or afraid) and another all   positive   (happy) expressions, in a counterbalanced order. We will refer to these experiments as the   negative   and   positive faces   experiments. No one was excluded based on performance as it was a very easy task and subjects practiced it to demonstrate understanding before entering the scanner. In the negative faces experiment, the age was 34±10 (mean±s.d.) years and there were 130 men and 116 women. There were 138 participants with mental disorder, whereas 108 were healthy controls. For the positive faces paradigm, we included 284 individuals, age 34±9 years; 157 male, 127 female, 160 with mental disorder and 124 healthy controls. Single nucleotide polymorphism (SNP) genotyping was performed using the Affymetrix Gene Chip Genome Wide SNP 6.0 array (Affymetrix Inc., Santa Clara, CA, USA,   http://www.affymetrix.com  ). Individuals with discrepancies between reported and genotype-inferred gender and those whose ancestry differed from the majority of the sample were removed. Mitochondrial and X-chromosome SNPs were also removed, and we excluded individuals and SNPs with >3% missing data, and SNPs with a minor allele frequency of <0.05. 

The fMRI data from both tasks were processed using the SPM2 software  to produce contrast maps. For both negative and positive faces experiments, we focused on the 20,000 voxels with most evidence of differential activation to reduce multiple testing. A further prescreening stage rejected voxels in clusters of <50. In the negative faces experiment, every voxel was tested for association with every SNP using an additive model of genetic effect. For each voxel, the   P  -value for the most significant SNP was adjusted for multiple testing across the SNPs using the Šidák correction.  Multiple testing across the voxels was accounted for by controlling the false discovery rate (FDR) under the assumption of positive dependencies using a common adjustment method.  We validated our associations in the positive faces experiment by testing each voxel for association with 35 SNPs suggested by the negative faces experiment; multiple testing across voxels was controlled for each SNP separately.  In both analyses, voxels were only included in the results if they lay within clusters of >10. 

The North American replication sample consisted of 85 healthy middle-aged Caucasian subjects, 41 males, 44 females; age 45±7 years). All fMRI data preprocessing and single-subject analyses were completed using SPM2.  These participants were genotyped using the Illumina 610-Quad BeadChip (Illumina Inc., San Diego, CA, USA). Perfect proxies were available on this array in two of the genetic regions under study, while the third region had no proxy and so was separately genotyped using fluorescence polarization methods. Single-subject contrast images were entered into separate regression analyses with the rs12485367, rs6038686 and rs6081495 genotypes, including gender and age as nuisance covariates; these analyzes were conducted in SPM8  (  http://www.fil.ion.ucl.ac.uk/spm  ). 

More details, including a full description of the subjects, and the processing and analysis of the data can be found in   available online. 


## Results 
  
### Faces task in Norwegian sample 
  
We carried out genome-wide analyses using the Affymetrix 6.0 Array on the subjects who had successfully completed the fMRI protocol. Clusters of voxels exhibiting significant differential activation in the direct comparisons of the experimental and control conditions were used. The 20,000 most significant voxels were identified and any clusters of <50 voxels were discarded, in order to choose groups of voxels able to contain diffuse associations. After this procedure, 19,742 voxels remained for analysis from the negative faces scan, and 19,864 from the positive faces scan. For both the negative and positive faces, voxels exhibiting a significant main effects of task (that is, experimental>control condition) were principally located in ventral visual cortices as well as frontal and subcortical regions. There is highly significant evidence of differential activation for these voxels (Bonferroni-corrected family-wise error (FWE) rate for the voxels in the negative faces is 1.2 × 10 ). The exact location of the voxels selected for both scans is provided in   online. 


### Genetic variants suggested by negative faces experiment 
  
Initially, fMRI data from the scan with negative facial expressions were analyzed as these stimuli have been more commonly used than positive expressions in the larger neuroimaging literature.  Each of the voxels as chosen above was tested for an association with each SNP (a total of 549,640 SNPs, meaning approximately 10  tests) using an additive model of genetic effect. The   P  -values were adjusted to account for multiple testing: first using the Šidák correction  to produce   P  -values, adjusted for multiple testing across the SNPs. Then the Benjamini Hochberg procedure  was applied to these adjusted   P  -values to control the FDR (the procedure controls the expected proportion of false positive results), accounting for multiple testing across both SNPs and voxels. With the exception of the preselection of task-related voxels described above, this is a similar strategy to one previously presented applied in a genome-wide association study of structural imaging phenotypes.  In that paper, identical procedures for controlling for multiple testing across SNPs and phenotypes (vertices as opposed to voxels) were followed, with the exception that we applied a more conservative procedure to control for multiple testing across SNPs (ignoring linkage disequilibrium structure and correcting for every SNP rather than calculating an ‘effective number of tests'). Similarly, a set of phenotype–genotype associations is presented, with the appropriate estimate of the FDR. More details can be found in  , including   available online, a visual representation of the correction procedure. 

Evidence that the activation of 455 voxels had a genetic component was found, with an associated FDR of 0.5. This is a highly liberal threshold, but as this first part of the study was intended to contribute to the initial   discovery   of potential SNPs and significance will be assessed in the   replication   experiments, a higher proportion of false positives was tolerated to avoid discarding interesting results. 

Only clusters of at least 10 voxels were selected. This is a smaller threshold than that used for preselection of the 20,000 voxels (which insisted clusters had at least 50 voxels), as here we simply wished to discard spurious findings. There were 10 such clusters, totaling 226 voxels, located in the cuneus and occipital gyrus, both known to be involved in visual processing, and bilateral fusiform gyrus, which is implicated as central to face processing specifically.  These clusters were associated with 37 SNPs located in 20 genomic regions <40 kb. These 20 genetic regions and the associated brain regions are listed in   available online.   available online show Manhattan and Q-Q plots for three voxel phenotypes, those most significantly associated with SNPs rs12485367, rs16992973 and rs2208796, these are SNPs we will develop further. There is little evidence that any of these SNPs are not in Hardy Weinberg Equilibrium (for rs12485367,   P  =1.00; rs16992973,   P  =0.14; and rs2208796,   P  =0.13). We see little evidence of genomic inflation for these phenotypes, for example, λ=0.997 for the phenotype associated with rs12485367.   available online shows in more detail the   P  -values for these phenotypes in the genetic regions where they show most significant associations. In   available online, we see that the association relates to a single signal, as no other SNPs in high linkage disequilibrium with rs12485367 were available in this dataset. This increases the chance that the association could be a false positive induced by genotyping errors; to rule this out, we have explored the population genetics of this SNP in comparison with the North American sample and the CEU sample from the 1000 genomes pilot project  for evidence of biased ascertainment. This information is contained in the  . We also note that in   available online, we see that a number of SNPs closest to rs12485367 show   P  -values between 10  and 10  despite being in only weak linkage disequilibrium with rs12485367, some evidence that they may be weakly tagging the causal variant. 

We plot genotype against peak phenotype for these three SNPs in   available online. All three SNPs seem to show a consistent trend across genotype; there is little evidence these associations are induced by a few extreme outliers. Finally,   available online shows Manhattan and Q-Q plots for the peak voxel associated with each of the 20 genetic regions listed in   online. Phenotypes from certain brain regions, in particular the cuneus, show more evidence of genomic inflation. This could be because these regions show greater variation in brain activation, possibly breaking the normality assumptions of the model. 


### Validation of results in positive faces experiment 
  
The 37 most significant SNPs from the negative faces scan were tested in the positive faces scan. This is not an independent replication in a new population, as the experiments were performed on mostly the same people during the same scanning occasion performing a similar task and thus the   P  -values reported are biased towards significance. However, recruitment into the study continued after data for the negative faces scan were collated and analyzed and so genotype data on 57 new individuals were available for the positive faces scan. Two SNPs were discarded as their minor allele frequency was <0.05 in this new population, leaving 35 SNPs. Again using an additive model of genetic effect, associations between SNPs in seven genetic regions and neural activation were identified in 26 clusters of >10 voxels, located in the cuneus, lingual and superior occipital gyri as well as in the bilateral fusiform gyrus (the associated voxel-wise FDR was 0.05, the associations with regions of the fusiform gyrus, a structure particularly involved in face processing, are listed in  , all associations discovered are listed in   online). 

The neural regions associated with the seven genetic regions across both the negative and positive faces data are all known to be involved in visual processing. Some of these regions, such as the primary occipital gyrus, are involved with general visual processing. Others overlap with the so-called occipital face area which, together with the fusiform gyrus, is considered necessary for normal face processing.  For the fusiform gyrus, the right hemisphere is known to be preferentially involved in face processing.  The results in the negative faces scan are consistent with this, a greater number of associations were found with fusiform gyrus voxels in the right hemisphere than the left hemisphere (36 voxels in the right fusiform gyrus were associated with genetic variants, as opposed to 19 in the left fusiform gyrus). The pattern of activation in the Norwegian sample is particularly striking in the case of rs12485367; significant associations with the fusiform gyrus, only in the right hemisphere in the negative faces scan (16 voxels), and more pronounced in the right than left hemisphere for the positive faces scan were discovered (linked to 47 voxels in the right hemisphere and 43 in the left). This SNP was not associated with any other brain regions in either experiment. In addition, the peak activation in the right hemisphere to negative faces is in almost exactly the same location as the activation associated with this SNP in the positive faces scan (see  ). In the positive faces experiment, the rs16992973 variant was also associated with bilateral fusiform area activation (though more pronounced in the left hemisphere); the remaining genetic region was associated only with activation in the left fusiform gyrus. 

Our initial analysis ignored disease status, as analyses of pilot data found no trend effects on activation. However, as others have found associations between regional brain activation and mental illness,  it was important to investigate whether the present results could be caused by confounding with this factor. We found no significant associations between disease status and the activation of the 20,000 preselected voxels in either experiment. We have also investigated how much controlling for disease status, using indicator variables coding for schizophrenia, bipolar and other psychosis, would affect the results.   available online shows the   P  -values declared significant in both experiments against the same   P  -values calculated when diagnosis is included in the model (for the negative faces experiment, all associations listed in   available online were reanalyzed, this time regressing on SNP dose and disease status; for the positive faces experiment, all associations listed in   available online were analyzed similarly). We see little change; for both experiments, results were actually slightly improved when diagnosis was included in the model, with a small majority of associations more significant (in the negative faces experiment, 207 associations were more significant including diagnosis, 197 were more significant ignoring it; for the positive faces experiment, these numbers were 627 and 615, respectively). 

We have also repeated the full analysis performed on the positive faces experiment, but again, controlling for diagnosis. Similarly, we found that the results were largely unchanged, indeed slightly improved. Considering diagnosis makes very little difference to the conclusions we draw and would not affect the choice of SNPs to be investigated further in the replication experiment described below. This agrees with previous work, which found preserved function of the fusiform face area (FFA) in schizophrenia.  These results are covered in more detail in the   online. 


### Replicating fusiform gyrus activations in North American sample 
  
Associations across the negative and positive faces datasets were identified. However, in the first negative faces dataset, we expect half of the associations to be false positives, and in the second positive faces dataset, the estimates of significance are difficult to interpret as the SNPs were selected using related data. Therefore, and in line with recent guidelines for replicating genotype–phenotype associations,  a subset of the significant SNPs was investigated in an independent sample of Caucasians from North America. The replication experiments were designed to concentrate on those SNPs most likely to be involved in face processing. The different levels of complexity of the stimuli could cause activations; viewing faces could also inspire higher levels of attention than geometric figures as could the emotional content. However, there is a substantial body of literature pointing to a specialized role for the FFA in face processing  and thus we concentrate our focus on SNPs linked to this brain region, in particular in the positive faces paradigm (one SNP of particular interest, rs12485367, was associated with FFA activation in both negative and positive faces paradigms). We use the literature to argue that activations in this region are related to face processing rather than any other cognitive subtractions. For SNPs associated with other regions, a replicated finding would not have this body of work to aid in the interpretation. 

The SNPs that were identified in the negative faces dataset and associated with FFA activation in the positive faces dataset were selected (there were five such SNPs, located in three regions). The analyses on activations in the fusiform gyrus used an anatomical region of interest approach, using standard fMRI analyses, which are impractical in the genome-wide association study context due to the large number of tests. The NCI-NHGRI Working Group guidelines state that replication experiments and analyses should be as similar as possible, though this is chiefly in order to remove study differences as a reason for failure to replicate. 

The replication sample consisted of healthy middle-aged volunteers who completed a similar fMRI task  from which the Norwegian paradigms were derived. These participants were genotyped using the Illumina platform. The SNPs upstream of   SLC24A3   (20p11.23), had a proxy on the Illumina platform (rs6081495). Another SNP, rs16992973 near   RP4-764O22-001   (20p12.3), had a proxy in rs6038686. All proxies were in complete linkage disequilibrium (  R   and   D  ′ equal 1 in the European ancestry population of the HapMap project ). The final SNP, rs12485367 in   TMEM212   (3q26.31), did not have a proxy on the Illumina platform and was individually genotyped. 

A significant association between rs12485367 (  TMEM212  ) and right fusiform gyrus activation was obtained (  x  =20,   y  =−68,   z  =−14,   t  =4.77,   P  =0.004, FWE-corrected,   k  =92; see also  ). As in the original experiments, participants carrying the minor (G) allele showed higher fusiform gyrus activation relative to C homozygotes. Significant association between rs6038686 (  RP4-764O22-001  ) and right fusiform gyrus activation (  x  =26,   y  =−52,   z  =−14;   T  =4.07,   P  =0.043, FWE-corrected,   k  =80; see  ) was also found; such that participants carrying the minor (G) allele showed relatively heightened activation. Again, this matches the result from the Norwegian sample. As in the rs12485367 analyses, the right fusiform gyrus activation remained significant after FWE correction over the search volume of an anatomical fusiform gyrus region of interest. Finally, rs6081495 did not show a significant association with fusiform gyrus activation. 



## Discussion 
  
The present findings represent a demonstration of an association between common gene variation and neural function associated with face processing. Validation of some of the initial results using a parallel experiment and replication of the most promising candidates in an independent population was used. It is also important to note that the original associations with fusiform gyrus activation in the Norwegian discovery sample were identified when searching across all neural regions sensitive to the task and not through the narrow window of an anatomical region of interest approach. 

There is little knowledge about the function of the genes that were identified, but there are some indications that   TMEM212   is expressed in the brain. Affymetrix provides a test of whether a transcript is present or absent within a sample,  and   TMEM212   is present in five out of seven samples of the whole brain tissue collated in the Gene Enrichment Profiler  (  http://xavierlab2.mgh.harvard.edu/EnrichmentProfiler/index.html  ), and in one out of two samples from the occipital lobe. 

Interestingly, both genes replicated in the North American sample lie within regions for which associations have been proposed to disorders involving impairment of social functioning.  But, as no association to diagnosis was found, and the replication sample excludes any individuals with a current DSM-IV (Diagnostic and Statistical Manual for Mental Disorders) Axis I disorder, we believe these genes to be involved in regulating fundamental brain functions related to face processing unrelated to psychiatric disorders. Further, as these variants were identified and validated using faces expressing negative and positive emotions, these pathways may be broadly important for face processing independent of emotional expression. 

The current findings are in line with recent evidence of high heritability of the ability to process face information,  which suggests a strong biological control of this important human function. Previous studies indicate that the ability for face recognition has little overlap with other cognitive abilities,  which suggests that the face processing ability is specific. This is supported by the present findings of specific activation patterns related to face processing associated with distinct gene variants, indicating a specific genetic basis. Particularly   TMEM212   seems to be specifically involved in the innate architecture of face processing, as it was associated with activation in the FFA only. 

This supports the position that distinct cognitive and neuronal mental processes may have specific genetic determinants, as has been seen with language disability.  Thus, the genes identified in the current study would be interesting candidate genes to investigate for association with developmental prosopagnosia,  a disorder characterized by impairments in face recognition that are unaccompanied by brain lesions; multiple cases of this disorder have been seen in the same family.  Investigations into pedigrees has suggested that forms of congenital prosopagnosia can have a dominant, autosomal mode of inheritance.  Although we have looked for common variation, these genes could be investigated to find rare variants causing pathological results in such families. However, the development of such distinct mental processes probably depends on gene–environment interactions. 

To conclude, specific genes that may be important for the modulation of basic neurobiological processes, which underlie human social interactions, have been identified. In addition, we have demonstrated how the synthesis of fMRI and genome-wide data can be used to discover and replicate links between common genomic variation and behaviorally relevant brain function. 

 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-70'>
<h2>70. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/28575506/' target='_blank'>28575506</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Limbic Interference During Social Action Planning in Schizophrenia</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Schizophr Bull</p>
<p><strong>Publication Year:</strong> 2017</p>
<p><strong>DOI:</strong> 10.1093/schbul/sbx059</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5814975/' target='_blank'>5814975</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study reports task-based fMRI during gesture planning and execution (pantomime), which is a social-communication task (nonverbal social action). A healthy control group (n=25) is included and results for controls are reported alongside patients; healthy participants are adults (recruited among staff and students) and matched for age. Whole-brain, random-effects second-level analyses were performed and reported (SPM8; whole-brain thresholding with P ≤ .001 and cluster extent), not limited to ROI-only analyses. Therefore the study meets the review’s key inclusion criteria: social-related fMRI task, inclusion of healthy adult participants with separately reported results, and whole-brain analyses. Note: the full text excerpt does not explicitly state the exact age range of participants (17–65), so confidence is lowered slightly, but recruitment of adults and age-matching make it very likely they fall within the eligible adult range.</p>
<p><strong>Fulltext Confidence:</strong> 0.85</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Schizophrenia is characterized by social interaction deficits contributing to poor functional outcome. Hand gesture use is particularly impaired, linked to frontal lobe dysfunction and frontal grey matter deficits. The functional neural correlates of impaired gesturing are currently unclear. We therefore investigated aberrant brain activity during impaired gesturing in schizophrenia. We included 22 patients with schizophrenia and 25 healthy control participants matched for age, gender, and education level. We obtained functional magnetic resonance imaging data using an event-related paradigm to assess brain activation during gesture planning and execution. Group differences in whole brain effects were calculated using factorial designs. Gesture ratings were performed by a single rater, blind to diagnoses and clinical presentation. During gesture planning and execution both groups activated brain areas of the praxis network. However, patients had reduced dorsolateral prefrontal cortex (DLPFC) and increased inferior parietal lobe (IPL) activity. Performance accuracy was associated with IPL activity in patients. Furthermore, patients activated temporal poles, amygdala and hippocampus during gesture planning, which was associated with delusion severity. Finally, patients demonstrated increased dorsomedial prefrontal cortex activity during planning of novel gestures. We demonstrate less prefrontal, but more IPL and limbic activity during gesturing in schizophrenia. IPL activity was associated with performance accuracy, whereas limbic activity was linked to delusion severity. These findings may reflect impaired social action planning and a limbic interference with gestures in schizophrenia contributing to poor gesture performance and consequently poor social functioning in schizophrenia. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (25844 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Schizophrenia is characterized by impaired social interaction contributing to poor functional outcome.  Particularly nonverbal communication is disturbed including gesture performance in both patients and subjects at risk for psychosis.  Gestures are skilled movements critical for social interaction,  conveying relevant nonverbal information. Gesture deficits have been linked to impaired frontal lobe function, working memory deficits and altered motor behavior.  Gesture impairments in schizophrenia predict poor functional outcome after 6 months.  Furthermore, poor nonverbal social perception and impaired gesture performance are strongly associated.  Finally, alterations in the mirror neuron system may lead to poor gesture performance. 

Three key aspects of gesturing may be investigated: gesture perception, interpretation and production.  Recent functional magnetic resonance imaging (fMRI) studies indicated aberrant neural processing in the language network in schizophrenia during perception of abstract metaphoric gestures.  Behavioral data suggests misinterpretation of incidental movements as gestures in patients with delusions.  Delusions in turn are associated with altered brain activity in the limbic system.  Therefore, functional alterations in the limbic system may foster misinterpretation of gestures in schizophrenia. Two recent fMRI studies investigated the imitation of meaningless finger movements in schizophrenia: One reported preserved neural activity,  while the other found reduced right parietal lobe activation in patients.  Imitation of finger movements may be related to imitation of gestures, yet lacking the communicative context. Even though performance of gestures on command (termed pantomimes) is defective in up to 67% of schizophrenia patients,  the underlying pathophysiology is unknown and their functional neural correlates have not been studied yet. Pantomimes represent a critical nonverbal component of real-life social encounters, for instance as co-speech gestures. 

Current neurocognitive models  including evidence from fMRI studies in healthy subjects  as well as lesion studies  suggest a widespread, left lateralized, fronto-temporo-parietal cortical network for planning pantomime gestures and imitation of tool use. According to these models distinct ventral and dorsal streams of this so called praxis network are relevant for motor control. In detail, the dorso-dorsal stream provides “online” control of actions and is running from the primary visual cortex, the superior parietal lobe to the dorsal premotor area.  In contrast, the ventro-dorsal stream is relevant for action semantics connecting medial superior temporal areas with the inferior parietal cortex and dorsal premotor cortex.  Finally, visual object processing and object semantics is processed in the ventral stream running from the visual cortex through the temporal lobe to the inferior frontal gyrus. 

Investigating gesture performance in schizophrenia provides further information on the contribution of the praxis network. In fact, schizophrenia patients with defective pantomime performance had reduced gray matter (GM) in the ventral-dorsal pathway, most prominent in the left IFG in contrast to patients with correct gesture performance. 

Despite the growing evidence and clinical relevance of gesture abnormalities in schizophrenia, the neural correlates of impaired gesture performance are currently unclear. However, this pathophysiological knowledge may stimulate the development of treatment approaches. Therefore, we tested functional correlates of gesture performance on visual verbal command (pantomime) in schizophrenia patients and healthy controls with fMRI. We hypothesized aberrant activation of the praxis network in schizophrenia during both planning and actual performance of gestures and altered prefrontal cortex activation during gesture planning. In particular, we hypothesized planning of novel gestures to be demanding and to be associated with prominent alterations in the frontal lobe in schizophrenia. In contrast, brain activity during planning of familiar, highly overlearned gestures (such as tool related gestures) may be more preserved in schizophrenia. Finally, we tested a possible association of defective social action planning with delusional experience in patients. 


## Methods 
  
### Subjects 
  
This study included 22 patients with schizophrenia spectrum disorders according to the Diagnostic and Statistical Manual of Mental Disorders (DSM5) criteria and 25 healthy control subjects matched for age, gender, and duration of education. Patients were recruited between December 2013 and November 2014 at the inpatient and outpatient departments of the University Hospital of Psychiatry, Bern. Healthy controls were recruited via advertisement and among staff and students. All participants were right-handed. General exclusion criteria were substance abuse or dependence other than nicotine, history of motor impairments such as dystonia, idiopathic parkinsonism or stroke, history of head trauma with concurrent loss of consciousness and history of electroconvulsive treatment. Exclusion criteria for controls were history of any psychiatric disorder, as well as any first-degree relatives with schizophrenia or schizoaffective disorder. All participants provided written informed consent. The study protocol adhered to the declaration of Helsinki and was approved by the local Ethics Committee. 

All patients received antipsychotic medication, average daily chlorpromazine equivalents (CPZ) during the last 5 years were calculated.  Symptom severity in patients was assessed with the Comprehensive Assessment of Symptoms and History (CASH)  and the Positive And Negative Syndrome Scale (PANSS).  All participants were further interviewed with the Mini International Neuropsychiatric Interview (MINI).  In addition, frontal lobe function, verbal working memory and nonverbal intelligence were assessed using the Frontal Assessment Battery (FAB),  the digit span backwards (DSB) task (subtest from the Wechsler Memory Scale [WMS-III]  and the Test of nonverbal Intelligence [TONI]).  Assessment of symptoms was conducted on the day of MRI scan. 


### Experimental Procedures 
  
#### Task: Gesture Performance on Verbal Command. 
  
We employed a modified instructed delay paradigm  for pantomime gestures ( ). Participants performed 20 novel and 20 familiar gestures in random order with their right hand in 2 runs. Instructions were presented visually as written commands. Familiar gestures included 10 transitive (tool related, eg, use of scissors) and 10 intransitive symbolic actions (eg, waving good bye). Novel gestures are meaningless actions, such as spreading the little finger outward. During the linguistic control condition trials (10 neutral sentences, eg, “The weather is cold during winter.”),  participants were asked to relax and neither plan nor undertake any movements. Thus, linguistic control was matched for attention and visual processing, but lacked any specific demands in motor planning ( ). Within runs, gesture condition and linguistic control condition were intermixed. Each command was presented twice. Each run started with the rest instruction followed by written movement commands or linguistic control for 3 seconds ( ). Next, a fixation cross was presented for 3 seconds, during which participants had to plan movements. Immediately after the planning phase, a round symbol indicated the execution phase of 3 seconds, which in turn was followed by a jittered interstimulus interval of 3–10 seconds. The total duration of the fMRI task was 13 minutes. 
  
Pantomime gesture task. 
  
Participants performed gestures with the right hand and arm. Subjects lay horizontal in the MR scanner and their arms rested beside their trunk. To reduce head motion foam pads were placed around the participants’ head and we explicitly instructed participants to avoid head motion, in particular while performing gestures. Furthermore, most of the gestures involved the hand and forelimb in proximity to the hand. In case of movements including the arm participants were explicitly asked to mainly use the forelimb. 

An independent rater blinded for diagnosis and clinical status evaluated the video-recorded gesture performance according to the Test of Upper Limb Apraxia (TULIA)  criteria (eg, according to spatial, temporal or content errors, higher scores indicating better performance accuracy; full criteria see  ). 


#### Functional Magnetic Resonance Imaging. 
  
Imaging was performed on a 3T MRI scanner (Siemens Magnetom Trio; Siemens Medical Solutions) with a 12-channel radio frequency headcoil for signal reception. 3D-T1-weighted (Modified Driven Equilibrium Fourier Transform Pulse Sequence; MDEFT) images for each subject have been obtained,  providing 176 sagittal slices with 256 × 256 matrix points with a non-cubic field of view (FOV) of 256 mm, yielding a nominal isotopic resolution of 1 mm3 (ie, 1 mm × 1 mm × 1 mm). Further scan parameters for the anatomical data were 7.92 ms repetition time (TR), 2.48 ms echo time (TE) and a flip angle of 16° (FA). 

For functional sequences, 390 T2*-weighted echo planar single-shot images (EPI) were acquired. Further scan parameters for the functional images were 38 slices, and slice thickness = 3 mm, 64 × 64 matrix size, 3.59 mm × 3.59 mm × 3 mm voxel dimension, FOV 230 mm, TR = 2 seconds and TE = 30 ms. In addition the acquisition of a B  image was performed in order to quantify inhomogeneity within the echo planar imaging (EPI) images. The following parameters were used: 38 axial slices with slice thickness = 3.0 mm, interslice distance = 0 mm, FOV = 230 × 230 mm , matrix size = 64 × 64; TR = 488 ms, TEshort = 4.92 ms, TElong = 7.38 ms, gradient-EPI readout, interleaved order, acquisition time 65 seconds, number of measurements   N   = 1, Flow compensation pulse, Bandwidth 260 Hz/Px and effective Echo spacing 0.215 ms. These images were positioned exactly as the fMRI images. 



### Statistical Analysis 
  
Statistical tests of behavioral, clinical and demographic data were performed using SPSS 22.0 (IBM SPSS Statistics: IBM Corp). Two-sample   t   tests and chi-square tests (χ ) were used to test for group differences in clinical and demographic data. Gesture performance data were normally distributed. A repeated measure ANOVA tested the effects of category, group and their interaction on gesture performance applying Greenhouse-Geisser correction. Level of significance was set at   P   < .05, 2-tailed. 

Missing trials and trials with severe gesture errors (eg, unrecognizable or movement present, but hard to decipher) were excluded from further fMRI analysis. To assess planning- and execution-related increases in blood oxygenation level dependent (BOLD) signal we used Statistical Parametric Mapping (SPM8) software (Wellcome Department of Imaging Neuroscience, University of London). Preprocessing included slice time correction, realignment, coregistration, normalization, and spatial smoothing with a Gaussian kernel of 8 mm full-width at half-maximum. In addition, preprocessing included correction of distortion of EPI images due to possible regional variations of the static magnetic field (eg, B ). 

Statistical analysis of the preprocessed data was conducted via a 2-stage mixed effects model. At the single subject level, the activity for planning and execution of familiar and novel gestures as well as the linguistic controls was modeled in one General Linear Model (GLM) using the standard SPM canonical hemodynamic response function. For each participant, realignment parameters were included in the GLM as regressors of no interest to correct for residual motion. In order to identify brain areas specifically associated with planning and execution of familiar and novel gestures, gesture conditions (familiar and novel) were contrasted against the linguistic control condition at the single subject level (eg, planning familiar gestures vs linguistic control; execution novel gestures vs linguistic control). 

Next, contrasts from each single subject were entered into second-level random effects analyses. Whole brain effects were calculated using 2 flexible factorial designs with the factors group, planning and execution for each of the 2 gesture categories (familiar and novel) separately. Between group effects were calculated comparing both conditions (planning and execution) between patients and controls within the factorial designs (eg, patients vs controls: planning familiar gestures; controls vs patients: planning familiar gestures). We report results with a uniform threshold of   P   ≤ .001 and a minimum cluster size of 180 voxels. 

We explored potential influences of motion on the BOLD signal. Neither group nor phase of the experiment had an influence on head motion during the scan (see  : Analysis S1, table S1). Finally, we calculated post hoc Spearman’s rank correlations (2-tailed) to assess the relationship between performance ratings (TULIA scores), psychopathological characteristics of delusional experience from the CASH present state and neural activity during gesture planning. Therefore, we extracted mean beta estimate values of full brain clusters differentially activated during the planning condition as regions of interest (ROIs) for each subject using a toolbox for SPM (MarsBaR). 



## Results 
  
### Behavioral and Clinical Data 
  
Demographic and clinical data are given in  . Patients performed poorer than controls in both gesture categories (familiar and novel, see   and  : figure S1). The gesture deficit comprised temporal, spatial, semantic and content errors. We found significant effects of gesture category (  F   = 67.1,   P   < .001), and group (  F   = 20.0,   P   < .001), but no category × group interaction (  F   = .1,   P   = .70). However, the proportion of excluded trials (missing trials and trials with severe errors) did not differ between patients and controls ( ). 
  
Demographic and Clinical Data 
    

### fMRI Results 
  
#### Planning Novel and Familiar Gestures. 
  
Within-group results are given in the   ( : Analyses S2 and S3, figure S2 and table S2). During planning of novel gestures between-group contrasts indicated reduced activation in patients in brain areas commonly related to gesture planning, ie, in the ventral and dorsal stream, the motor cortex and the right dorsolateral prefrontal cortex (DLPFC) (controls > patients) (  and  ). Furthermore, we detected abnormal bilateral activation in temporal pole, amygdala and hippocampus in schizophrenia (patients > controls). In addition, patients demonstrated increased activation in the middle frontal gyrus (dorsomedial frontal cortex: DMPFC; patients > controls) (  and  ). Likewise, during planning of familiar gestures patients showed hypoactivation in the praxis network, the motor cortex and the DLPFC, while again patients presented abnormal bilateral activation in the temporal pole and amygdala (  and  ). The full list of between group results (controls > patients and patients > controls) is given in   To rule out the putative effects of frontal lobe function on our whole brain findings we provide additional analyses with frontal lobe function (FAB) as covariate. The analyses yielded substantially the same results independent of frontal lobe function (see  , table S3). 
  
Neural activity during gesture planning in schizophrenia patients and healthy controls. Between group effects of planning novel (A and B) and familiar (C and D) gestures. The bars indicate   T  -values. The images are depicted at standard MNI-templates (threshold of   P   < .001, minimum voxel size 180). 
    
Neural Activity During Planning and Execution of Novel and Familiar Gestures in Schizophrenia Patients and Healthy Controls 
    

#### Execution Novel and Familiar Gestures. 
  
We analyzed between group effects during gesture execution to determine the relationship of actual gesturing and brain activity. Groups did not differ in neural activation during performance of novel gestures (controls > patients and patients > controls). However, patients displayed hypoactivation during execution of familiar gestures within the premotor cortices (bilateral SMA, pre-SMA and cingulate motor areas; see  ). 


#### Association of Gesture Behavior With Neural Activation During Gesture Planning. 
  
Accuracy of gesture performance was associated with the right DLPFC (middle frontal gyrus) activation during gesture planning in controls but with left inferior parietal lobe (IPL) activation in patients (  and  : table S4). Moreover, the abnormal BOLD activity in limbic regions (right temporal pole, amygdala and hippocampus) during planning was significantly associated with the level of delusions in patients (  and  : table S4). 
  
Association between gesture performance, delusion severity and neural activity in differentially activated brain areas. Spearman’s rank correlation analysis of the neural activity in (A) the left IPL, (B) the right middle frontal gyrus and (C) association of neural activity in the right amygdala, hippocampus and temporal pole and severity of delusions within patients. MFG—middle frontal gyrus (DLPFC), IPL—inferior parietal lobe. 
  



## Discussion 
  
Defective gesture performance in schizophrenia substantially hampers social interaction, predicting poor functional outcome.  Thus, investigating gesture behavior provides a window to social communicative impairments in schizophrenia.  During social interaction gestures substitute or support verbal information. When encountering subjects with schizophrenia, both faulty or reduced nonverbal expression and biased nonverbal perception may contribute to poor understanding. While gesture impairments are currently being explored in schizophrenia spectrum disorders, very little is known on the neural underpinnings of this deficit.  Here we investigated neural correlates of gestural deficits in schizophrenia patients and well-matched healthy controls using fMRI. Results indicate aberrant neural activity most prominent during planning of gestures, which may contribute to poor gesture performance. 

In line with previous studies, participants activated the praxis network when planning and executing hand gestures.  However, neural activation was generally less prominent and more left-lateralized in patients, which may explain behavioral gestural deficits. Furthermore, patients demonstrated aberrant activation of the bilateral amygdala, hippocampus and temporal pole during gesture planning. Involvement of limbic areas such as amygdala in gesture performance has not been reported before, neither in studies in healthy subjects  nor in lesion studies.  Strikingly, limbic activation was associated with delusion severity in patients. 

### Altered Activation of the Action Network and Mirror System in Patients 
  
Several factors may contribute to poor gesture processing in schizophrenia, eg, impaired action planning, working memory deficits, and motor abnormalities.  Therefore, one would expect aberrant brain activity in patients particularly in the IPL and frontal lobe including premotor cortex and areas of cognitive control. Here, patients demonstrated a relative hyperactivation of the IPL and the DMPFC as well as a relative hypoactivation of the DLPFC when planning novel gestures. In fact, this pattern contributed to the actual gesture accuracy: in patients performance was associated with left IPL activation, but in controls performance relied on right DLPFC activation. Thus, patients seem to engage the parietal components of the action network instead of the DLPFC. The frontal lobe is relevant for higher order motor control including action planning and execution.  In line with this, impaired gesturing in schizophrenia was linked to impaired frontal lobe function.  The DMPFC has been suggested to elaborate the meaning of communicative and social ambiguous stimuli.  Thus, the DMPFC hyperactivity in patients planning novel gestures may indicate the unsuccessful search for meaning in meaningless gestures. 

Our results substantiate earlier findings demonstrating aberrant mirror neuron activation within the IPL during both action observation and action execution in schizophrenia.  The IPL contains so-called mirror-neurons.  Gesture performance and gesture perception are tightly coupled in schizophrenia.  In order to perform a gesture correctly, we need to integrate action planning and the semantic meaning. The mirror neuron system provides topographical overlap of motor and semantic representations.  Therefore, our results suggest that defective mirror system contributes to gestural deficits in schizophrenia. 

Furthermore, our results complement reports investigating gesture perception in schizophrenia. In particular, gesture perception and planning of gesture performance engage overlapping brain areas (ie, the inferior frontal gyrus).  However, gesture execution demonstrated hypoactivation within the cingulate motor areas in patients, which is in contrast to previous reports on gesture perception. Finally, previous work suggested hand gesture performance to be linked to general severity of positive or negative symptoms with some inconsistency.  However, we detected no such association in our study. In conclusion, the combined investigation of neural correlates during gesture perception and performance would be the next endeavor. Furthermore, we need to test whether aberrant neural activity in schizophrenia during gesture processing would indicate subjects with particularly poor social outcome. 


### Aberrant Limbic Activation in Patients 
  
Our main results extend previous findings by showing that patients activate amygdala and temporal pole not only in response to affective stimulation  but also during gesture planning. We may speculate that the pathological activation of key emotion processing areas may distract gesture performance. Likewise, amygdala activity may drive emotional interference on cognitive processing.  Furthermore, the limbic cluster of activity including amygdala was associated with delusion severity. Limbic brain areas are critical for incentive salience and the evolution of delusions in schizophrenia.  Thus, our findings suggest incentive salience even during planning of socially relevant action. Indeed, perception and interpretation of gestures may be biased by delusions of reference or hallucinatory experience, particularly in socially ambiguous situations. 

The aberrant activation of limbic brain areas in patients was exclusively correlated with delusion severity but unrelated to gesture performance. 


### Limitations 
  
In addition to patient status, other factors may have influenced brain activation in the current fMRI study including differences in task performance and medication effects. In order to account for performance differences, we excluded trials with major errors in both groups. Major errors comprised movements without temporal or spatial association with the requested gesture. Medication effects on the fMRI signal are equivocal, eg, antipsychotics may normalize limbic neural activity or have no effect at all.  In addition, medication may affect gesture performance. However, in our study gesture performance was not associated with dosage of antipsychotic medication (data not shown). 

The group of schizophrenia patients presented with typical neurocognitive impairments which may affect gesture performance.  However, introducing frontal lobe function as a covariate to our imaging analyses, yielded substantially the same results. Our task was designed to investigate action planning and the execution of hand gestures, but does not allow contrasting the 2 conditions, as the execution phase directly followed the planning phase without jittering interval. Therefore, we do not directly compare brain activation during planning and execution. In fact, hemodynamic response functions in the bilateral SMA as shown in the   indicate that both conditions may elicit a neural response at single-subject level regardless of the absent jittering interval between the 2 experimental conditions ( : Analysis S4, figure S3). 

Finally, our paradigm included a linguistic control task. While this control was useful to correct for unspecific semantic associations, it may at the same time hamper the detection of relevant neural signal in brain areas of the language network. In fact, some brain areas are active during both language and gesture processing, eg, the IFG.  Despite the linguistic control task, we detected brain activity during gesture planning in the IFG in both groups. 



## Conclusion 
  
In summary we demonstrated an aberrant pattern of brain activation during social action planning in schizophrenia, ie, gesture planning and execution. Patients’ gesture performance relied on IPL instead of DLPFC activity, which is in line with the association of poor gesture performance and frontal lobe dysfunction. Finally, we observed aberrant limbic activity in patients during gesture planning, which was linked to delusion severity. Thus, the pathophysiology of gesture performance in schizophrenia involves reduced DLPFC impact and limbic interference. These functional alterations may contribute to poor gesture performance, poor social interaction and poor functional outcome in schizophrenia. 


## Supplementary Material 
  
Supplementary data are available at   Schizophrenia Bulletin   online. 


## Funding 
  
This work was supported by the Bangerter-Rhyner Foundation (to S.W.) and the Swiss National Science Foundation (SNF grant 152619/1 to S.W., A.F., and S.B.). 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-71'>
<h2>71. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/28455517/' target='_blank'>28455517</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Neural Activity while Imitating Emotional Faces is Related to Both Lower and Higher-Level Social Cognitive Performance</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Sci Rep</p>
<p><strong>Publication Year:</strong> 2017</p>
<p><strong>DOI:</strong> 10.1038/s41598-017-01316-z</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/5430668/' target='_blank'>5430668</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study reports an fMRI experiment in healthy adults (n=20 analyzed; ages 18–55) performing a social task (imitate/observe emotional faces). Analyses are whole-brain (spatio-temporal PLS producing voxelwise maps and a complementary SPM8 GLM), not limited to ROIs. Results for the healthy participant group are reported separately. All inclusion criteria are met and no exclusion criteria apply.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Imitation and observation of actions and facial emotional expressions activates the human fronto-parietal mirror network. There is skepticism regarding the role of this low-level network in more complex high-level social behaviour. We sought to test whether neural activation during an observation/imitation task was related to both lower and higher level social cognition. We employed an established observe/imitate task of emotional faces during functional MRI in 28 healthy adults, with final analyses based on 20 individuals following extensive quality control. Partial least squares (PLS) identified patterns of relationships between spatial activation and a battery of objective out-of-scanner assessments that index lower and higher-level social cognitive performance, including the Penn emotion recognition task, reading the mind in the eyes, the awareness of social inference test (TASIT) parts 1, 2, and 3, and the relationships across domains (RAD) test. Strikingly, activity in limbic, right inferior frontal, and inferior parietal areas during imitation of emotional faces correlated with performance on emotion evaluation (TASIT1), social inference - minimal (TASIT2), social inference - enriched (TASIT3), and the RAD tests. These results show a role for this network in both lower-level and higher-level social cognitive processes which are collectively critical for social functioning in everyday life. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (34238 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Social interactions are complex processes which are built upon the perception and understanding of the actions, intentions, and mental state of others. Social cognitive neuroscience has suggested a dichotomy between low-level processes such as understanding motor actions or emotional processing and higher-level processes such as inferring the mental states of others (e.g. theory of mind) or detecting deception and sarcasm. This apparent dichotomy between lower level and higher level social cognitive processes is supported by behavioral , neuroimaging  and lesion studies . Neuroimaging studies have primarily examined these processes with two approaches: using tasks relevant to the perception of and interaction with other people’s actions (action observation and imitation), and using tasks relevant to infer the beliefs and desires of the other person (mentalizing). Lower level social cognitive processes such as action interpretation have been associated with activation of a lateral frontal-parietal network, the putative human analogue to the mirror neuron system observed in monkeys . Higher-level social cognitive processes, such as theory of mind, have been associated with activation of cortical midline regions, including the medial prefrontal cortex, posterior cingulate cortex, and precuneus, as well as temporoparietal junction and temporal pole. This network is also known as the ‘mentalizing’ system. Dual processing models have been proposed in which the lateral fronto-parietal network supports relatively automatic processes such as identifying motor actions while the mentalizing network supports controlled processes of attributing actions to complex social causes . 

Most neuroimaging studies examining the lateral fronto-parietal network have made use of hand actions or other forms of simple motor stimuli . As such, the role of this system has been mainly considered in the context of perceiving gross motor actions. Some have taken the concept of mirroring one step further, by arguing that the lateral fronto-parietal network is important for emotional empathy by permitting humans to feel what others feel, and potentially to assess or interpret emotional cues and social behaviour . Investigating this issue may be best served by paradigms utilizing socially relevant stimuli as opposed to simple motor acts. One such paradigm is the imitation and observation of emotional faces, which has been shown to activate the lateral fronto-parietal ‘mirror’ network . This is consistent with the notion that activation of this network can play a role in allowing people to empathize by imitating emotions . Activity in the right IFG has been positively correlated with self-report measures of empathy in healthy children , and has been shown to be more active in normally developing children than those with autism , with activity in autistic children inversely correlated with social impairment. However, the IFG has also been implicated in some higher level social cognitive processes, specifically the inhibiting self-perspective in social judgements . Recent work has also shown structural changes in right fronto-parietal cortex in more socially impaired people with schizophrenia , a group of individuals in whom higher-level social cognitive processes such as theory of mind are more prominently affected . These findings raise the question of whether neural activation during basic mirroring tasks is related to higher-level social cognitive abilities. 

Meta-analysis of fMRI data has shown little overlap between activity in the brain regions associated with the mirroring and mentalizing systems across a range of tasks , and brain lesion studies have suggested a dissociation between mirroring and mentalizing regions . As such, mirroring and mentalizing were initially thought to represent dichotomous systems which function relatively independently, and the role of mirroring in higher-level social cognition is a contentious issue . However, there is a growing body of evidence that the mentalizing and mirroring systems may interact during more complex social cognitive processing, such as watching social videos . Co-activation of mentalizing and mirroring regions has also been noted when viewing agents performing irrational actions, suggesting aspects of the mentalizing system may facilitate interpreting unexpected actions . The mirroring and mentalizing system may work together during social cognitive processing, although a specific role of the mirror system in higher-level cognitive processing has yet to be established. 

The purpose of this study is to determine whether brain regions activated during a facial emotion mirroring task are related to lower-level social cognitive performance, higher-level social cognitive performance, or both. We utilized a process specific social mirroring task (the facial imitate/observe task ) inside the fMRI, along with a battery of objective out-of-scanner social tests ranging from basic emotional-perception tasks to complex higher level social cognitive tasks such as detection of lies or sarcasm. Brain-behavior relationships were examined using the spatio-temporal partial least squares (PLS), a non-parametric multivariate approach . PLS identifies latent variables (LVs), linear combinations of fMRI signal amplitude at each voxel across time and a design matrix which can consist of either experimental conditions or correlations across conditions with behavioral scores. Each LV expresses a pattern of the common covariance between the design and the fMRI data. PLS is designed to handle data with high collinearity while simultaneously capturing essential non-redundant relationships among the data , overcoming the confounding influence of collinear variables in traditional multiple regression . This makes PLS an excellent approach to uncover relationships between brain activity and a set of social cognitive scores which are likely highly interrelated. We hypothesized that a) consistent with previous studies, imitating emotional faces would activate the mirroring network, more prominently in the imitate than the observe condition, and b) neural activity during imitation of emotional faces specifically (rather than imitating neutral faces or observing faces) would be associated with both lower-level and higher-level social cognitive performance. 


## Results 
  
### Task Effects 
  
Task PLS is a multivariate model-free approach to identify spatial patterns which share relationships across the experimental conditions. A task PLS was run on the data to replicate previous task-based analysis, and examine the underlying pattern of task task-evoked spatial activity. PLS generated 6 LVs (as there were three trial types, emotional faces, neutral faces, and fixation, and two conditions, Imitate and Observe). Permutation analysis (see methods below) showed significance (p < 0.05) in the first three LVs, which accounted for 61.6%, and 14.5%, and 12.9% of crossblock covariance respectively (Fig.  ). LV 1 was related to viewing faces as opposed to fixation trials, and showed a pattern related to the lateral frontal-parietal network similar to the results of previous studies . LV 1 was related to viewing faces in general rather than distinguishing between emotional and neutral faces, demonstrating that this pattern of faces >fixation in the mirroring network is the dominant pattern of neural activity within this task analysis. LVs 2 and 3 explain some of the remaining variance in the data not accounted for the pattern presented in LV 1, representing interaction effects showing different patterns of activity across the Imitate and Observe conditions. LV 2 shows a large amount of overlap with LV 1, suggesting some of the variance within those regions is explained by aspects of both LVs 1 and 2. The majority of the variance explained by LV 1, but some additional variance within those voxels is explained by the pattern of emotional faces >neutral and fixation in Imitate and increased activity in fixation trials for Observe, as seen in LV 2. LV 3 represents an interaction in which the relative effects of neutral faces and fixation are different in the Imitate and Observe tasks.   
Results from the first latent variable using task PLS analysis. Data is shown for LV1, 2 and 3. The top panel shows the design pattern (the contribution of each condition to the LV). Error bars are 95% confidence interval derived from the bootstrap analysis. The bottom panel shows the voxel pattern from the first lag of the PLS analysis rendered on the cortex. Sagittal slices are shown for X = −10 (left) and X = 10 (right). Voxel intensity is displayed as bootstrap ratio, a measure of reliability of voxels within the LV. Red-yellow regions show the pattern described by the design pattern, while blue regions show the opposite pattern. 
  

For consistency and replication of previous studies, we also ran a general linear model (GLM) in SPM8. The GLM showed a similar pattern as in previous studies and LV1 of the task PLS (see supplementary methods and Supplementary Figure 1). 


### Behavioral PLS 
  
Behavioral PLS examined the relationships between patterns of activity in the brain and social cognitive test scores. Scores from six social cognitive tasks were included: the Emotion Recognition (ER40) , the Reading the Mind in the Eyes Test, RMET , the Relationships Across Domains test (RAD) , and the three subtests of the Awareness of Social Inference Test Revised (TASIT-R) . TASIT1 can be considered a test of lower-level social cognitive functioning, while TASIT2 and TASIT3 are high-level tests. The behavioral PLS generated 36 LVs, as there were six experimental conditions (emotional faces, neutral faces, and fixation, separately for Imitate and Observe, and six social cognitive tests). Overall permutation analysis showed significance in the first two LVs, which accounted for 23% and 13.2% of crossblock covariance respectively. However, the split-half permutation reliability analysis (see methods) demonstrated that the relationship between the design pattern and brain pattern was not reliable within LV 1 and as such it was not considered further. In LV 2, neural activity during imitation of emotional faces was positively correlated with RAD, TASIT1, TASIT2, and TASIT3 (Fig.  , top panel). Neural activity for Fixation and Neutral faces during Imitate, as well as Neutral faces during Observe, was negatively correlated with those same test scores. As such, LV 2 shows a pattern of correlations during the imitation of emotional faces related to performance on TASIT1, TASIT2, TASIT3, and RAD.   
LV 2 of the behavioral PLS results. (  A  ) Design pattern showing the pattern of correlations between brain signal for each during event type and each behavioral score within the voxel pattern. Error bars represent 95% confidence interval based off a bootstrapping analysis of 1000 iterations. (  B  ) Voxel patterns for each lag, displayed as bootstrap ratio on the MNI152 brain. Data is shown for two sagittal views as well as rendered onto the cortex (8 mm search depth) to better visualize cortical activity. Red-yellow shows a correlation pattern matching the design pattern (  A  ), while blue regions show the opposite pattern. Each lag represents a time point (TR) following stimuli onset (which occurred during ‘Lag0’). 
  

The pattern of brain activity in LV 2 (Fig.  , bottom panel) when imitating emotional faces in lag 1 showed a positive relationship with performance on TASIT1 TASIT2, TASIT3, and RAD. Activity was present in right pars opercularis (within inferior frontal gyrus), right and left supramarginal gyrus, right motor cortex, bilateral anterior temporal regions, fusiform gyrus, and parahippocampal cortex. Activity was also noted in right anterior/mid cingulate, right rolandic operculum, right putamen, and the cerebellum. Activity in lags 4 and 5, which positively correlated with social cognitive performance, was notably present in anterior temporal regions as well as in posterior middle and inferior right temporal gyri. Several regions showed negative relationships to the design pattern (thus greater fMRI activity while imitating emotional faces in individuals with poorer social cognitive performance), including the left inferior frontal gyrus (pars operculum and pars triangularis), and bilaterally in the basal ganglia (greatest in left putamen and right globus pallidus). 



## Discussion 
  
The behavioral PLS results of this study showed a robust relationship between neural activity during a process-specific imitate-observe task and both lower-level and higher-level social cognitive performance. While a growing number of studies using complex stimuli have noted co-activation of mirroring and mentalizing regions , co-activity cannot be taken to conclude that mirroring has a strong role in higher level social cognition. The novelty of our study is that we showed complex relationships of neural activity during a simple and process-specific mirroring task with performance on objective out-of-scanner assessments of higher-level social cognitive performance. In addition, the PLS approach allowed us to include several assessments in a single analysis, providing data driven evidence of which assessments best capture these brain-behaviour relationships. These behavioral relationships were specific to imitation of emotional faces, rather than neutral faces. Several regions outside the right fronto-parietal circuit, including left IFG and some mentalizing regions (e.g. TPJ), also showed negative correlations with social cognitive performance, suggesting either compensatory responses or over-activation in participants with poorer social cognition. 

These findings of a relationship between activity in a simple mirroring task and higher level social cognitive processing scores suggest a relationship for the mirror network in higher-order social cognitive processing including complex tasks. Effective mentalizing in humans although likely primarily reliant on classic mentalizing regions may be further subserved by mirroring regions . Given that the relationships elicited were noted in assessments involving interpretation of dynamic interactive video tasks including human actors, it may be that such relationships are only evoked when we consider social cognition as a process involving integrating information from multiple processing levels. The mirroring network may not be solely for understanding the intentions and physical goals of motor acts . Our findings add to the debate regarding the role of this network in social cognition . Several authors have argued that this network is important not only for imitation or action perception, but also for emotional empathy and possibly even in cognitive empathy (sometimes used interchangeably with theory of mind) , consistent with the theory of embodied simulation , despite debate to the contrary . Through the combination of a process-specific in-scanner task, more naturalistic and objective social cognitive tests, and the PLS multivariate framework, we were able to uncover essential brain-behavior relationships for which traditional task contrasts or linear regression analyses may be less sensitive. 

Higher level social cognitive processing involves concepts related to both theory of mind and cognitive empathy, both complex constructs which likely encompass several mental processes. To date, there is only limited evidence of overlap in neural activity between high-level tasks related to the mentalizing network and low-level tasks related to the mirroring network . However, task based analysis is often performed by contrasting conditions, and many mirroring tasks have utilized stimuli with little or no direct social relevance, or tasks designed to evaluate highly specific social cognitive processes which may not be well suited to capturing overlap within these systems . By moving away from an ‘overlapping activity’ perspective into an approach focused on brain-behavior relationships, we were able to demonstrate that activity in the mirroring network is correlated with higher-level social cognitive abilities. This combination of pairing a process-specific task paradigm with dynamic social cognitive measures may be a powerful approach for probing relationships between social cognitive networks and real-life social cognitive abilities. 

The behavioral PLS LV correlating neural activation during imitation of emotional faces with TASIT and RAD scores also included some regions which are often considered part of the mentalizing network. While these regions did not robustly activate during the task PLS, their presence in the behavioural PLS reflects activation during the imitate task that is relevant for social cognitive performance. Positive relationships with social cognition and emotional faces were observed in the temporal pole bilaterally, a region implicated in mentalizing and theory of mind  as well as in processing deception . Activity was also noted in the posterior region of the superior temporal sulcus, which may be of particular interest as this area has been implicated in both the mirroring/imitation network  and the mentalizing network . The superior temporal sulcus may serve as an integrative region, sharing information between these two networks  and/or as serving as a relay point for high level visual information . The superior temporal sulcus has also been implicated in analyzing dynamic facial features , perceiving biological motion , and gaze perception . As such, this region is involved with perceptual processes necessary for both low-level and high-level social cognition. It remains to be seen if this region may serve as an integrative hub between the mentalizing and mirroring networks, though the posterior superior temporal sulcus shares connectivity within both networks  and has been implicated as an important region in social cognitive impairment in autism . 

Studies showing increased connectivity between the right IFG (a critical hub of the mirroring network) and the mentalizing network provide evidence for functional communications between these networks . This connectivity between mirroring and mentalizing regions has been shown to be disrupted in autism , raising the possibility that disrupted social cognition in autism may be driven not only by localized effects within one of these systems but also as a network level disruption in how these systems interact. Likewise, social cognitive deficits are increasingly recognized as a core feature of schizophrenia, strongly related to overall functional outcomes . People with schizophrenia have been noted to show reduced right IFG activity when imitating emotional faces as well as opposite relationships between self-reported empathy and right IFG activity compared to controls . As social cognitive impairment is present at, or potentially preceding the onset of psychosis , it is possible this relatively brief imitate/observe in-scanner task may be useful as a potential early risk marker of the disease. 

We found that increased activity in the left IFG was associated with poorer social cognitive performance, as well as in clusters in the left medial frontal cortex and the TPJ . One study examining resting state network connectivity noted over-connectivity of the left IFG in the mirroring network in participants with autism, consistent with our finding that over activity in the left IFG is associated with poorer social cognitive performance . A number of regions outside the mirroring or mentalizing networks also showed a negative relationship with social cognitive performance, including the basal ganglia, thalamus, occipital cortex and superior colliculus. These regions may be involved in emotional face processing . We propose three possible explanations for the negative correlations between this pattern of neural activity when imitating emotional faces and social cognitive performance: 1) prolonged neural activity related to less efficient processing resulting in a greater magnitude of hemodynamic signal, as may be suggested by increased activity in regions associated with visual and face processing; 2) compensatory activity in which individuals with less efficient processing make greater use of the left IFG to compensate for lack of activity on the right (the compensatory hypothesis); or 3) over activity in the left IFG resulting in competition with right IFG, resulting in interference or an decrease in network coherence and deficits in social cognitive test performance (the dedifferentiation hypothesis). One possible explanation is that participants with poor performance may be attempting to compensate by activating aspects of the mentalizing system during lower-level social cognitive processing. It has been suggested that the anterior cingulate cortex, a region noted in the behavioral PLS, is involved in biasing activity towards either mentalizing or simulation . 

We did not find reliable relationships between the ER40 and RMET with neural activity to emotional faces. The ER40 and RMET rely on static images which fail to capture the full complexity of social cognitive processing, unlike the TASIT which requires interpretation of video scenarios of complex human interactions and the RAD which involves interpreting stories. It may be that more complex and process-general tests are required to more fully elicit relationships between activity in the simulation and mentalizing networks . Supporting this assertion, correlations between TASIT test scores and the observed voxel pattern in the PLS analysis were as high as 0.8, indicating a very strong relationship between mirroring network activity and social cognitive performance measured by TASIT1 (a lower-level task), as well as higher-level tasks TASIT2, and TASIT3. Some recent studies using more naturalistic higher-level social-cognitive paradigms, such as videos, have implicated IFG activity , and a small number of recent studies involving more complex social interaction tasks have noted co-activation in mirroring and mentalizing regions . 

Here we provide evidence that neural activation while imitating emotional faces is related to performance on dynamic and objective ‘real-life’ assessments of even the most complex social cognitive tasks. Given the relatively small sample size, further research expanding into a larger sample would be worthwhile to replicate and extend these findings. However, our findings suggest that patterns of neural activation during basic imitative behaviour may be a surrogate marker for highly complex social function in humans. The paradigm demonstrated here may be particularly useful for early identification studies in neurologic and psychiatric disorders with social cognitive impairment, and in intervention studies using ‘target engagement’ as a marker of early treatment response. 


## Methods 
  
### Participants 
  
Twenty-eight healthy adult participants were initially included in this study. Average age of participants was 34.3 ± 11.7 years, with 18 men and 10 women, 23 right-handed participants, and an average level of education of 15.1 ± 2.22 years. Participants aged 18 to 55 were included in the study. All participants completed the Edinburgh handedness Inventory and were administered the Structured Clinical Interview for DSM-IV disorders (SCID) to rule out possible psychiatric illness. Urine toxicology screening was performed to further ensure that no participant with a current substance use disorder was included in the study. Additionally, exclusion criteria included a first degree relative with a history of psychotic mental disorder, a history of head trauma resulting in unconsciousness, or a history of seizure or other neurological disorders. The protocol was approved by the research ethics board of the Centre for Addiction and Mental Health, University of Toronto, all research was conducted in accordance with the declaration of Helsinki and the tri-council policy statement on Ethic Conduct for Research Involving Humans. All participants gave informed consent, and signed an institutionally approved informed consent form, prior to any research procedures. 


### Social Cognitive Assessments 
  
The Emotion Recognition (ER40) task consists of 40 images of whole faces making emotional expressions, with participants selecting from four possible emotional responses . The Reading the Mind in the Eyes Test (RMET)  consists of 36 trials showing only the eyes of a black and white face, with four possible choices to describe what the person is feeling (e.g. amused, irritated, cautious, contemplative). The RMET is considered a test of empathic abilities as it measures the ability to judge emotional states from looking at the eyes. The Relationships Across Domains (RAD) test  presents 25 written vignettes of 2–4 lines followed by three statements which describe the behaviour of the male-female dyad from each vignette in domains of social life different from that vignette. Participants indicate if the behavior described in each statement is likely or unlikely to occur based on what was learned from the vignettes. The Awareness of Social Inference Test, Revised (TASIT) uses short video vignettes to measure emotional perception and theory of mind . The TASIT is divided into three parts. Part 1 (TASIT1) consists of 24 short videos of actors portraying different emotional states (happy, sad, fear, disgust, surprise, and anger). Part 2 (TASIT2; social inference – minimal) consists of 15 videos showing sincere or sarcastic interactions between two actors, followed by four questions relating to what the actors were thinking, doing, meaning to say, and feeling. TASIT2 is considered a test of theory of mind. TASIT part 3 (TASIT3; social inference – enriched) consists of 15 vignettes in which the speaker is making an assertion which is literally untrue, but can represent either sarcasm or an attempt at deception. Success in TASIT3 requires the ability to detect deception in social encounters. In total, six social cognitive scores were derived from these tests (ER40 reaction time, RMET, RAD TASIT1, TASIT2, and TASIT3). Age was regressed out of all social cognitive test scores. 


### MRI Scanning 
  
MRI scanning was conducted on a Discovery 3 T MR750 machine from General Electric at the Centre for Addiction and Mental Health. The Imitate/Observe task was part of a longer multimodal MRI protocol to which each participant consented. Each block of the task (Imitate and Observe) was collected in counter-balanced order as a separate echo-planar imaging scan, with TRs = 3 sec, TE 30 ms, voxel size 3 mm isotropic, 50 slices, 64 × 64 matrix with FOV = 192 mm, flip angle = 77, and 110 TRs per scan. The first 5 TRs were excluded prior to any preprocessing to allow for magnetic steady-state. 


### Imitate/Observe Task 
  
The participants performed an imitate/observe task as previously described  while being scanned. Participants were shown full-color photographs from an ethnically diverse set of 16 individuals (eight males and eight females) expressing five different facial expressions (fearful, sad, happy, angry, or neutral). During one scanning session, participants were instructed to imitate the expression on the faces (the   Imitate   session), while in the other session participants were instructed to observe the face (the   Observe   session). Each run consisted of 80 faces (16 per facial expression) plus 16 fixation trials presented in a pseudorandomized order determined using Optimize Design 11  to maximize contrast efficiency. Each trial lasted three seconds, with the faces presented for two seconds and a jittered ISI (500 ms to 1500 ms). The order of sessions (Imitate or Observe) was counter-balanced across participants. Participants practiced the task prior to MRI scanning and were instructed to minimize motion during the imitation, only using their facial muscles when matching the expressions. A video recording during the scan confirmed that all participants were following instructions (i.e. imitating during the imitate session but not during observe). 


### fMRI data analysis - Preprocessing 
  
The initial preprocessing stages were slice time corrected and motion corrected in SPM8 (Wellcome Department of Cognitive Neurology, London, UK). Individual sessions were subjected to single-session independent components analysis (ICA, from the MELODIC module in FSL 5.0.6). ICA reports were visually examined, and any ICAs which were clear artifacts were removed based on a set of established criteria. On a case by case basis where some large motions contaminated the ICAs, data ‘scrubbing’ was performed using a spline interpolation. Generally, two TRs were removed for each motion spike, and no more than three TRs were permitted per motion spike and a maximum of three motion spikes were removed from any scan. Of the 56 sessions (Observe and Imitate for the 28 participants) scrubbing was performed in 16 sessions. In nine of these cases (four Observe sessions and five Imitate sessions) scrubbing was not successful. Possible reasons for unsuccessful ‘data scrubbing’ include large movements exceeding three TRs, more than three large movements, or over 90% of ICA components classified as artifact after data scrubbing. These sessions were subsequently excluded from further analysis, leaving neuroimaging data from 20 of the original 28 individuals for final analysis. Data were then de-noised based on the selected noise ICA components using FSL 5.0.6 (reg_filt). Normalization into MNI space was done using SPM8, and images were smoothed with an 8 mm Gaussian kernel. 


### Partial Least Squares Analysis 
  
Patterns of task related activity and relationships between social cognitive test scores and BOLD signal were examined using spatio-temporal PLS , a multivariate approach which allows for detection of spatial patterns and dependant variables across the brain without the need for a-priori selected contrasts across experimental conditions. PLS is designed to handle data with high collinearity while capturing essential non-redundant relationships among the data , overcoming the confounding influence of collinear variables (e.g. cognitive tests) in traditional multiple regression. Additionally, PLS is also well suited to studying the relationships between numerous variables even in the presence of a relatively small sample, which is ideal for our purposes as it allows us to examine a range of social cognitive batteries. PLS produces latent variables (  LVs  ) relating patterns of experiment task activity or behavioral measures with spatial patterns of neural activity across time points (scans, referred to as    lags   , normalized to the scan in which the stimuli was presented, labeled as lag0). As a model free non-parametric approach, PLS is ideal to examine complex relationships amongst the battery of social cognitive scores and neural activity when imitating and observing emotional faces. 

A task-PLS analysis was conducted to replicate the regions of activity in the SPM8 GLM. Brain data from an 18 second window (corresponding to 6 lags) was normalized to the first lag (lag0) to create a data matrix for each condition, stacked across participants. Cross covariance was calculated between the data matrix and a design matrix consisting of vector of experimental conditions (in the task PLS, emotional faces, neutral faces, and fixation crosses, separately for Imitate and Observe). The resulting cross-covariance matrix was then decomposed using singular value decomposition, which created a set of orthogonal latent variables (  LVs  ) which optimally represent spatio-temporal relationships between voxels and experimental conditions. For each LV, a pattern of voxels at each lag value (the ‘brain pattern’) demonstrates the relationship with activity in the voxel at that lag and the ‘design pattern’ (representing the weights of each experimental event). Voxel weight is expressed as salience, which is proportional to the covariance of activity in that voxel and the design pattern expressed by that LV. 

Behavioral PLS was used to examine relationships between social cognition and neural activity. Behavioral PLS examines patterns of covariance between scores and neural activity for each trial type across lags. As such the design pattern is the correlation between the overall pattern of neural activity in each condition and each social cognitive score. For the behavioral PLS, neural activity to emotional faces, neutral faces, and fixation (separately for imitate and observe) was related to the six social cognitive test scores from our battery, deterministically producing 36 LVs. 

Statistical evaluation of each LV was performed using split-half permutation testing. A total of 500 permutations were run, with 100 split-half permutations within each. The overall permutation score determines if the effect represented by the LV is sufficiently strong to be differentiated from random noise, while the split-half analysis provides a measure of the stability of relationships between voxel patterns and design patterns in the data for each latent variable. As the permutations are performed at the level of the entire PLS analysis (rather than on individual LVs), multiple comparisons for the number of LVs is not necessary. In the split-half, the ‘BrainCorr’ value tests the reliability of the voxel pattern for a given design pattern associated with an LV, while ‘DesignCorr’ tests the reliability of a given voxel pattern for the behavioral pattern associated with that LV. Results are expressed as p-values. LV’s were considered significant if the overall permutation and at least one of the BrainCorr or DesignCorr was less than 0.05. A bootstrapping procedure with 1000 iterations was used to test if specific voxels were reliably related to the LV. A bootstrap ratio for each voxel was calculated as the voxel salience divided by its bootstrap standard error. A bootstrap ratio of 2.5 (corresponding to >95% reliability) was used to threshold all voxel pattern maps in PLS. 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-72'>
<h2>72. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/32059228/' target='_blank'>32059228</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Hyperfunctioning of the right posterior superior temporal sulcus in response to neutral facial expressions presents an endophenotype of schizophrenia</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Neuropsychopharmacology</p>
<p><strong>Publication Year:</strong> 2020</p>
<p><strong>DOI:</strong> 10.1038/s41386-020-0637-8</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/7297989/' target='_blank'>7297989</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study reports task-based fMRI during social-related processing (neutral face processing, emotion recognition, affective theory-of-mind) in a sample of healthy adult participants (N=74). Results for healthy participants are reported separately. The authors conducted and report whole-brain analyses (one-sample t-tests, within-subject ANOVA, whole-brain threshold p<0.05 FWE-corrected, k=10) as well as ROI analyses; the presence of whole-brain results satisfies the inclusion criterion that whole-brain analyses be reported. No exclusion criteria are met (it is not limited to ROI-only analyses, and it does not report only clinical groups). Therefore the study meets all inclusion criteria for the review of fMRI studies of social-related processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Deficits in social cognition have been proposed as a marker of schizophrenia. Growing evidence suggests especially hyperfunctioning of the right posterior superior temporal sulcus (pSTS) in response to neutral social stimuli reflecting the neural correlates of social-cognitive impairments in schizophrenia. We characterized healthy participants according to schizotypy (  n   = 74) and the single-nucleotide polymorphism   rs1344706   in ZNF804A (  n   = 73), as they represent risk variants for schizophrenia from the perspectives of personality traits and genetics, respectively. A social-cognitive fMRI task was applied to investigate the association of right pSTS hyperfunctioning in response to neutral face stimuli with schizotypy and   rs1344706  . Higher right pSTS activation in response to neutral facial expressions was found in individuals with increased positive (trend) and disorganization symptoms, as well as in carriers of the risk allele of   rs1344706  . In addition, a positive association between right–left pSTS connectivity and disorganization symptoms during neutral face processing was revealed. Although these findings warrant replication, we suggest that right pSTS hyperfunctioning in response to neutral facial expressions presents an endophenotype of schizophrenia. We assume that right pSTS hyperfunctioning is a vulnerability to perceive neutral social stimuli as emotionally or intentionally salient, probably contributing to the emergence of symptoms of schizophrenia. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (28623 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Social-cognitive impairments have been proposed to present a marker of schizophrenia [ – ]. The impairments occur in different domains of social cognition, ranging from deficits in neutral face processing [ ,  ], emotion recognition [ ], up to complex social-cognitive processes [ ], like inferring others’ mental states, known as theory of mind (ToM) [ ], and are highly important for social functioning [ ]. The association of these deficits to enhanced activity and connectivity of the right posterior superior temporal sulcus (pSTS [ ,  ]) makes aberrant pSTS functioning during social cognition a highly promising endophenotype candidate for schizophrenia. 

Several regions of the brain are central to social-cognitive processing, including amygdala, medial and inferior frontal cortex, insula, fusiform gyrus, as well as pSTS [ ,  ]. Most of these regions have been both found to be affected structurally [ ], as well as functionally [ ,  ] in schizophrenia. For investigating the neural correlates of social-cognitive impairments in schizophrenia, we [ ] developed a social-cognitive task that assesses several aspects of social cognition (namely neutral face processing (NFP), emotion recognition (ER), and affective ToM (aToM)) using facial expressions as stimuli. Applying this task, we found activation in key regions of social-cognitive processing in healthy participants [ ]. In addition, hyperactivity in the right pSTS during NFP, but not during aToM, was revealed in two independent samples of patients with schizophrenia [ ,  ]. Furthermore, we found hypoconnectivity between the right and left pSTS for aToM, and a relative hyperconnectivity between the right and left pSTS for NFP [ ]. Other authors also [ ,  ] showed hyperconnectivity of the pSTS in emotionally and intentionally neutral conditions of social-cognitive paradigms. Since the pSTS is a core area of social cognition and prominently involved in inferring other’s intentions [ ] (also Schmidt et al., unpublished data), increased pSTS activation during NFP might be interpreted as a vulnerability for false-positive perceptions of intentions, also called hypermentalizing [ ]. 

Imaging genetics studies with healthy participants and with relatives of patients with schizophrenia provided further evidence for aberrant pSTS functioning during social cognition as an endophenotype of schizophrenia. ZNF804A, a zinc-finger protein, presents an odds ratio of 1.08 (0.92–1.26 95% CI) for schizophrenia samples [ ]. One of its single-nucleotide polymorphisms (SNPs,   rs1344706  ) [ ,  ] was identified in whole-genome association studies as the first common genetic variant associated with schizophrenia [ ,  ].   Rs1344706   is involved in regulating gene expression [ ], and has been linked to executive functioning [ ] and social cognition [ ]. Imaging genetics findings from two healthy samples suggest that activity and connectivity of the STS and adjacent temporoparietal junction are associated with variation in   rs1344706   in a mentalizing task with sketches [ ,  ]. Further, healthy relatives of patients with schizophrenia showed aberrant activation in this task. Family members had reduced activation in the medial prefrontal cortex during mentalizing, but increased activation in the posterior cingulate cortex and right middle temporal gyrus. Interestingly, activation in right middle temporal gyrus during mentalizing correlated positively with self-reported paranoid ideation [ ]. These findings are exemplary of the approach to identify endophenotypes by investigating variations of traits of a disease in healthy participants. 

Schizotypy as part of the schizophrenia spectrum is a valuable construct that refers to personality structures spreading dimensionally throughout the population [ ,  ], but can also present as a personality disorder [ ]. Schizotypy can be characterized by a three-factor model of sub-threshold psychotic symptoms, including positive (e.g., ideas of reference), negative (e.g., no close friends), and disorganization symptoms (e.g., eccentric behavior). Several studies have consistently revealed an association between schizotypy and the development of a psychotic disorder (for a review please see ref. [ ]). A longitudinal study reported that 9% of an at-risk sample had a transition to schizophrenia within 12 months, and suggested self-reported schizotypy presenting the most reliable scale-based predictor [ ]. In addition, accumulating evidence points to schizotypy and schizophrenia having common genetic [ ], neuroanatomical [ ], and neurocognitive [ ] abnormalities, which again highlights the strong associations between schizotypy and schizophrenia. Importantly, as in schizophrenia, schizotypy has been associated with different kinds of social-cognitive deficits [ ,  ]. 

To date, only two fMRI studies have investigated the association between neural correlates of mentalizing and schizotypy in healthy participants. Both studies found right pSTS activity for mentalizing varying with schizotypy [ ,  ]. However, whereas one [ ] revealed negative symptoms to be positively related to right pSTS activation during mentalizing, the other [ ] showed a positive association with positive symptoms. In these studies, different tasks and accordingly different stimulus materials were used to investigate ToM, possibly explaining the divergent results. An even more general and crucial aspect when comparing social-cognitive studies, however, is not only the selection of stimulus material but also of the control condition (ranging from emotionally neutral analogs of the experimental condition to completely nonsocial conditions), which is usually subtracted from the higher-order social-cognitive process. Therefore, divergent findings in prior studies might be explained by differences in brain activation in the control condition between participants with and without schizophrenia risk. 

To summarize, deficits in social cognition are proposed to present a marker for schizophrenia [ ], and aberrant pSTS functioning during social cognition is a promising endophenotype of schizophrenia [ ,  ]. In this imaging genetics study, we applied a social-cognitive fMRI task [ ,  ] that assesses different social-cognitive processes, and has consistently revealed right pSTS hyperactivation during NFP, but not during mentalizing, in patients with schizophrenia [ ,  ]. We aimed at investigating whether we find in healthy participants a comparable activation and connectivity pattern as in schizophrenia, depending on the   ZNF804A rs1344706   risk allele, and schizotypy. This allowed us to assess possible pSTS hyperfunctioning unconfounded of medication status, or chronicity of disease. For both   ZNF804A rs1344706   risk allele and schizotypy, previous studies found a relationship to aberrant pSTS activation during mentalizing [ ,  ,  ,  ], but the response to neutral facial expressions was not investigated. We hypothesized that activation and connectivity of the right pSTS in response to neutral facial expressions in healthy participants is positively associated with (1) the risk allele of the   rs1344706   genotype and (2) higher self-reported schizotypy. 


## Materials and methods 
  
### Participants 
  
Of 81 healthy participants, seven were excluded for the present analyses: five due to low fMRI data quality, one due to a BDI-II [ ] score >18, and one due to schizotypy scores >3 SD above the group mean. For the genetics analyses, one additional participant was excluded because genotyping for rs1344706 was not possible. Therefore, we included 74 participants (40 females, see Table  ) in the behavioral and imaging analyses and 73 participants (39 females) for the imaging genetic analyses. Participants were grouped for the imaging genetics analysis for the existence of the risk allele of schizophrenia [ ]; ZNF804A genotype groups: 62 AA/CA (risk-allele carriers and 11 CC non-risk-allele carriers). All participants were of German ancestry, had higher school certificate, were right-handed, had normal or corrected-to-normal vision and no self-reported background of mental or neurological disorders, or drug abuse. In addition, participants reported having no relatives with psychotic disorders.   
Characteristics of the sample. 
  
 SPQ   schizotypal personality questionnaire,   AA/CA   indicates the risk-allele carriers,   CC   indicates the non-risk-allele carriers. 
  

Prior to the study, participants were informed about study procedure and purpose and gave their written informed consent. The study was approved by the local ethics board of the Medical Faculty Mannheim, University of Heidelberg. The data reported here are part of a larger study on the human mirror neuron system that involved a measurement containing simultaneous EEG-fMRI with three tasks (including an imitation task, an empathy task, and the social-cognitive task presented here), blood-taking and a series of questionnaires, including the Schizotypal Personality Questionnaire (SPQ [ ], details are presented in the Supplementary Text  ), and a second measurement with transcranial magnetic stimulation prior to fMRI. The results reported in this paper are based on the fMRI data of the first appointment. 


### Experimental paradigm 
  
We applied a modified version of the social-cognitive task that was used in earlier studies with patients with schizophrenia [ ,  ]. The paradigm was extended to four conditions, including three levels of social cognition [lower-level social cognition (NFP), ER, and higher-level social cognition (aToM)], and a nonsocial control condition. In each trial of the social-cognitive conditions, a statement preceded a facial expression. These statements described the facial expressions referring to physical features (gender or age) for NFP, the emotional state (fear or anger) for ER, or the possible intention (running away or blustering) for aToM. For NFP, only neutral facial stimuli were shown, for ER and aToM only emotional facial expressions. The facial stimuli were taken from the Karolinska Directed Emotional Faces set [ ]. Half of the stimulus persons were male, and the same persons were used for each of the social-cognitive conditions. For the control condition, prior to a geometric figure (a triangle or a circle) a statement describing the figure (e.g., “This is a circle”) was displayed. Task duration was around 8 min (details of timing and presentation can be found in Fig.   and Supplementary Text  ).   
The social cognition fMRI task. 
  


### Genotyping 
  
Genotypes for   ZNF804A SNP rs1344706   were extracted from whole-genome genotype data obtained using Illumina Global Screening array and following stringent quality control (see Supplementary Text  ). 


### Imaging data acquisition and analyses 
  
The study was conducted with a 3-Tesla Siemens Tim TRIO whole-body magnetic resonance tomography (Siemens Medical Systems, Erlangen, Germany; acquisition protocol can be found in Supplementary Text  ). Brain activity and connectivity analyses were conducted with SPM8 (Wellcome Department of Imaging Neuroscience, Institute of Neurology, London, UK). Data preprocessing contained slice-time correction, realignment, co-registration to the structural image, spatial normalization (MNI template) with resampling to a 3 × 3 × 3 mm voxel size, and spatially smoothing with an 8 mm full-width half-maximum kernel. The first-level analyses were achieved by a general linear model with four regressors (aToM, ER, NFP, and control), and six motion parameters, derived from the realignment procedure, as covariates. The hemodynamic response function was modeled to the onset times of the pictures. The time series was high-pass filtered using a 128 Hz function. From the model, linear combinations of the regressors built the contrasts of interest, including effects of each higher against the lower social-cognitive condition (aToM > ER, ER > NFP), and each condition against control (aToM >control, ER > control, NFP > control). Connectivity analyses were applied using generalized psychophysiological interactions (gPPI [ ]), as implemented in the gPPI toolbox (  http://www.nitrc.org/projects/gppi  ) with a functional mask of right STS as seed region, produced from our previous comparison between aToM and ER in 40 undergraduate students [ ] (details of the gPPI analysis are reported in Supplementary Text  ). 

For second-level analyses, significance threshold for exploratory whole-brain analyses was   p   < 0.05 FWE-corrected,   k   = 10. We conducted one sample   t   tests to analyze the effect of each social-cognitive condition, and a within-subject one-way analysis of variance (ANOVA) to identify the neural correlates of increased social-cognitive processing (contrast: [aToM > control] > [ER > control] > [NFP > control]). Regression analyses were conducted to explore the associations between the factors related to schizophrenia (schizotypy and the rs1344706 risk allele) and right pSTS activation, and connectivity for the different social-cognitive conditions. Region of interests were right and left pSTS, as derived from an earlier study [ ]. These masks were also applied in our studies on patients with schizophrenia [ ,  ]. The significance threshold for the ROI analyses was set to   p   < 0.05 small volume corrected (svc),   k   = 10. Behavioral data were analyzed with SPSS version 23. Differences between the social-cognitive conditions in reaction times (RTs) or accuracy were analyzed with repeated measures ANOVA, post hoc tests were conducted with paired-samples   t   tests. Pearson correlation was applied to investigate possible associations among task conditions, and to test the associations between schizotypy and task performance. We conducted independent sample   t   tests to test genotype effects on task performance, as well as to investigate differences in self-reported schizotypy, depending on genotype. 



## Results 
  
### Behavior 
  
Similar to our previous studies [ ,  ,  ], RTs and accuracy differed significantly between conditions, with the control condition being the easiest and aToM being the most difficult task condition. Neither genotype nor schizotypy significantly affected task performance (detailed behavioral results are reported in Supplementary Text   and Supplementary Fig.  ). In addition, no significant differences in self-reported schizotypy were revealed, depending on the risk allele (see Table  ). 


### Imaging 
  
Replicating the results from our previous studies [ ,  ], activation increased linearly from NFP over ER to aToM in regions of the “social brain”, including bilateral superior temporal gyrus covering pSTS, bilateral inferior frontal gyrus covering BA44 (Fig.  ; detailed results of task effects are presented in Supplementary Table  ). Whole-brain analyses of right pSTS connectivity differences between conditions were not significant across participants. ROI analyses revealed greater pSTS connectivity between hemispheres for aToM compared with ER at the trend level (peak voxel: −57, −49, 7;   t   = 3.37,   p   = 0.069 svc,   k   = 10).    Neural correlates of distinct social-cognitive processes.  
 a)   neural correlates of increasing social-cognitive demands [with the contrast: (affective theory of mind > control) > (emotion recognition > control) > (neutral face processing > control)];   b)   affective theory of mind (> emotion recognition);   c)   emotion recognition (> neutral face processing);   d)   neutral face processing (> control condition). Significance threshold is   p   < 0.05, FWE-corrected,   k   = 10. 
  

#### rs1344706 
  
ROI analyses revealed that risk-allele carriers compared with non-risk-allele carriers had increased right pSTS activation during NFP (> control; peak voxel: 63, −58, 13;   t   = 3.19,   p   = 0.042 svc,   k   = 10, Fig.  ). No significant differences in pSTS activation were found for ER and aToM, and also right–left pSTS connectivity during all task conditions did not differ between risk-allele carriers and non-risk-allele carriers. In addition, whole-brain analyses with the given significance threshold revealed no significant group differences, neither in the activation nor in the connectivity analyses.    Associations between functioning of right posterior superior temporal sulcus for neutral face processing and schizotypy as well as rs1344706 genotype.  
The first two scatter plots show positive correlations between activation in the right posterior superior temporal sulcus (pSTS) for neutral face processing (> control) and   a)   disorganization, as well as   b)   positive symptoms;   c)   positive association of disorganization with right-to-left pSTS connectivity for neutral face processing (> control);   d)   genotype effect of increased activation in the right pSTS for neutral face processing (> control). Significance threshold for display purposes is   p   < 0.005 uncorrected,   k   = 10. Note: rpSTS stands for right posterior superior temporal sulcus, lpSTS stands for left posterior superior temporal sulcus. 
  


#### Schizotypy 
  
There was a trend for a positive association between right pSTS activation for NFP (> control) and schizotypy sum score (peak voxel: 63, −55, 10;   t   = 3.01,   p   = 0.065 svc,   k   = 10). There was also a significant positive association between activation in right pSTS and disorganization symptoms (peak voxel: 57, −55, 7;   t   = 3.54,   p   = 0.018 svc,   k   = 10, Fig.  ), and at the trend level with positive symptoms (peak voxel: 63, −55, 10;   t   = 3.94,   p   = 0.077 svc,   k   = 10, Fig.  ). ROI analysis also revealed a significant positive correlation between disorganization symptoms and right–left pSTS connectivity during NFP (> control; peak voxel: −45, −70, 22;   t   = 3.60,   p   = 0.038 svc,   k   = 10, see Fig.  ). Neither for ER nor for aToM were significant associations between schizotypy and pSTS activation, or connectivity found. In addition, whole-brain analyses with the given significance threshold did not reveal any significant associations of schizotypy with task-related brain activation and connectivity. 




## Discussion 
  
This study aimed at investigating whether pSTS functioning during social-cognitive processing is an endophenotype for schizophrenia. Confirming our hypothesis, we found a positive association of right pSTS activation for neutral face processing with schizotypy (in particular disorganization, and positive symptoms on a trend level), and also with a risk allele for schizophrenia. Furthermore, connectivity between the right and left pSTS during neutral face processing was positively associated with disorganization symptoms. 

The pSTS is consistently found to be involved in inferring goals and intentions [ ,  ,  ,  ]. Across participants, we replicated our previous findings showing decreased performance and increased activation in pSTS and BA44 with increasing social-cognitive demands. With this, our results again highlighted the role of pSTS functioning for inferring others’ intentions [ ]. Importantly, increased right pSTS functioning in our participants with schizophrenia risk allele and subclinical symptoms of schizophrenia was present only for neutral face processing, but not for higher-order social-cognitive conditions. This supports our previous findings and conclusions that impairments in higher-order social cognition in schizophrenia might originate in impaired basic social-cognitive processes [ ,  ]. Our results are also consistent with further previous findings with patients with schizophrenia. A recent study reported not only increased pSTS activation in response to the emotionally and intentionally neutral control condition in their social-cognitive task but also increased pSTS connectivity [ ]. These results add to the idea that pSTS dysfunction for neutral social stimuli might be regarded as neural basis for hypermentalizing, which may constitute a vulnerability to the emergence of delusion [ ]. 

But how could this pSTS hyperfunctioning in response to neutral facial expressions cause symptoms of schizophrenia? Kapur [ ,  ] proposed that psychosis, particularly delusions, result from aberrant attribution of novelty and salience to objects and associations, and that faulty attributions of salience arise due to chaotic, context-inappropriate firing of dopamine neurons. Delusions have been suggested to represent a deficit in encoding the precision of predictions and prediction errors [ ], indicating a bottom-up inappropriate perceptual input; i.e., aberrant salience. Supporting this idea, our results revealed a positive association between self-reported symptoms of schizotypy, as well as between the presence of a risk allele for schizophrenia, and activation in the right pSTS for neutral faces, and unveiled a positive association between disorganization and right-to-left pSTS connectivity. This might indicate that people with higher positive symptoms and a genetic risk for schizophrenia might be prone to perceive neutral faces as emotionally or intentionally salient. Whether these inappropriate perceptual inputs lead to delusions in turn could depend on how individuals interpret these false perceptions, pointing to the importance of a top-down cognitive explanation to delusions [ ,  ], and the impact of disorganization. When the cognitive explanation is interfered or interrupted due to executive dysfunction, the accumulating experiences of aberrant salience might gradually increase confusion and result in delusional ideas that are based on overinterpretation of emotions and intentions to neutral social stimuli. 

Together, our findings add to the perspective that delusions probably derive from dynamic interactions between bottom-up erroneous perception and top-down cognitive deficits, caused by increased responsiveness to emotionally and intentionally neutral social stimuli [ ]. Since all of our participants were without a history of mental disorders, we found alterations only on the level of neural functioning. Further studies with large patient samples that allow the analysis of subgroups are needed to investigate the validity of the proposed mechanisms in schizophrenia. 

Importantly, aberrantly high pSTS functioning in response to neutral social stimuli seems to be not “only” a marker of schizophrenia, but an endophenotype of schizophrenia according to the criteria characterizing an endophenotype proposed by Gottesman and Gould [ ]: (1) the endophenotype is associated with illness in the population: aberrant right pSTS functioning is consistently observed in patients with schizophrenia in response to stimuli and situations without emotional, or intentional meaning [ ,  ,  ,  ,  ,  ]. Our current results show a comparable neural pattern in healthy participants with increased proneness to schizophrenia, illustrating an association of right pSTS dysfunction with schizophrenia symptoms also in healthy participants. (2) The endophenotype is heritable: in line with previous studies showing aberrant pSTS functioning in schizophrenia risk-allele carriers [ ,  ], we found increased right pSTS activity in response to the neutral condition in   rs1344706   risk-allele carriers, possibly reflecting one aspect of the heredity of the right pSTS dysfunction. (3) The endophenotype should be state-independent: we found the neural pattern first in schizophrenia out-patients who were remitted from positive pathology [ ], then in in-patients with schizophrenia [ ], now even in healthy participants carrying the psychosis allele, suggesting that right pSTS dysfunction might represent a state-independent neural pattern for schizophrenia. (4) Within families, endophenotype and illness co-segregate: increased engagement of right pSTS varied with positive symptoms in patients with schizophrenia’ relatives [ ], suggesting that right pSTS dysfunction and schizophrenia symptoms co-segregate within families. However, studies systematically investigating differences in pSTS functioning between relatives of patients with schizophrenia are pending. (5) The endophenotype in affected family members is found at a higher rate in non-affected family members than in healthy participants: While hyperfunctioning was observed in relatives of patients with schizophrenia who reported positive symptoms, it is also found in non-affected family members at a higher rate than in healthy participants without familial risk for schizophrenia [ ]. In addition to the criteria initially proposed by Gottesman and Gould, a further criterion has been put forward [ ]: (6) the endophenotype should be a trait that can be measured reliably, and ideally is more strongly related with the disease of interest than with other psychiatric conditions: aberrant activation in the right pSTS was consistently revealed by our social-cognitive task in patients with schizophrenia [ ,  ] and also in the current study in healthy participants with increased schizophrenic proneness, but not in patients with borderline personality disorder [ ]. In addition, especially in patients with schizophrenia with paranoid symptoms, pSTS activity during a neutral condition was higher than in patients with autism [ ,  ], highlighting that dysfunction in right pSTS is not only a reliably assessable trait but might be specific to schizophrenia. Thus, there is extensive evidence supporting the idea that hyperfunctioning of pSTS to neutral social stimuli represents an endophenotype for schizophrenia. 

Despite the reported studies consistently finding genotype effects on brain activation and connectivity [ ,  ], they, like this study, tested only one risk SNP’s effect. In addition, since genetic penetrance is higher for endophenotypes than phenotypes [ ]; i.e., significant association between the risk allele and right pSTS functioning, but no significant association between the risk allele and schizotypy, several approaches would be of interest for future studies to validate our findings and to investigate the proposed mechanisms: (a) investigating the load of risk SNPs to reveal biological subcategories of schizophrenia [ ], (b) due to unequal distribution of risk-allele presence (only 11 participants homozygous for the non-risk allele), replication of the finding with pre-selection of participants depending on their genotype, (c) replicating the marginally significant association of positive symptoms and right pSTS activation with different approaches to assess schizotypy, such as the Oxford-Liverpool Inventory of Feelings and Experiences [ ], (d) targeting not only right pSTS activation and connectivity, but also of further regions that are central for social-cognitive processing (e.g., amygdala, MPFC). Besides, some previous studies only reported hypo-functioning in the pSTS with regard to schizophrenia in response to higher-level social cognition (such as ToM) [ ,  ]. Whether these studies would also reveal pSTS hyperfunctioning if the neutral condition was investigated remains an open question. However, investigating pSTS hyperactivation in participants with schizophrenia risk can be challenging, because no significant pSTS activation in response to the neutral conditions is found across all participants, pointing to small effect sizes that warrant moderate to large sample sizes to reveal the effects. Moreover, some studies suggest aberrations in left pSTS instead of the right pSTS presenting an intermediate phenotype for schizophrenia [ ,  ]. Perner et al. [ ] proposed that the left pSTS is linked to perspective differences for mental and nonmental objects, while the right pSTS is associated with mental states. Future studies should approach the question of laterality with a systematic variation of social-cognitive processing to clarify the functioning of this region in schizophrenia. 

Taken together, our findings point to right pSTS hyperfunctioning in response to neutral faces as an endophenotype of schizophrenia. We assume that right pSTS hyperfunctioning presents a vulnerability to perceive neutral social stimuli as emotionally or intentionally salient and suggest that bottom-up and top-down aberrations interact to cause delusions via deficient social perception. 


## Funding and disclosure 
  
This work was supported by the Heidelberg Academy of Science and Humanities. Zhimin Yan is supported by the Chinese Scholarship Council. The authors declare no conflict of interest. Open access funding provided by Projekt DEAL. 


## Supplementary information 
  




 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-73'>
<h2>73. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/31729105/' target='_blank'>31729105</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Getting into sync: Data‐driven analyses reveal patterns of neural coupling that distinguish among different social exchanges</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Hum Brain Mapp</p>
<p><strong>Publication Year:</strong> 2019</p>
<p><strong>DOI:</strong> 10.1002/hbm.24861</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/7268064/' target='_blank'>7268064</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This dual‑fMRI hyperscanning study acquired whole‑brain BOLD data in healthy adult participants (38 healthy individuals, mean age 22.4) performing an interactive social task (cooperative, competitive, control pattern game) directly addressing social processing. Analyses used whole‑brain approaches (group ICA and inter‑subject correlation across full brain volumes) and reported interaction‑specific whole‑brain spatial maps and statistics rather than ROI‑only results. Participants are within the 17–65 age range and results for healthy participants are reported separately. No exclusion criteria (ROI‑only analyses or clinical‑only samples) are met. Therefore the study meets all inclusion criteria for fMRI studies of social processing in healthy adults.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
In social interactions, each individual's brain drives an action that, in turn, elicits systematic neural responses in their partner that drive a reaction. Consequently, the brain responses of both interactants become temporally contingent upon one another through the actions they generate, and different interaction dynamics will be underpinned by distinct forms of between‐brain coupling. In this study, we investigated this by “performing functional magnetic resonance imaging on two individuals simultaneously (dual‐fMRI) while they competed or cooperated with one another in a turn‐based or concurrent fashion.” To assess whether distinct patterns of neural coupling were associated with these different interactions, we combined two data‐driven, model‐free analytical techniques: group‐independent component analysis and inter‐subject correlation. This revealed four distinct patterns of brain responses that were temporally aligned between interactants: one emerged during co‐operative exchanges and encompassed brain regions involved in social cognitive processing, such as the temporo‐parietal cortex. The other three were associated with competitive exchanges and comprised brain systems implicated in visuo‐motor processing and social decision‐making, including the cerebellum and anterior cingulate cortex. Interestingly, neural coupling was significantly stronger in concurrent relative to turn‐based exchanges. These results demonstrate the utility of data‐driven approaches applied to “dual‐fMRI” data in elucidating the interpersonal neural processes that give rise to the two‐in‐one dynamic characterizing social interaction. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (41944 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## INTRODUCTION 
  
Social interactions unfold as a two‐in‐one dynamic (Koike, Tanabe, & Sadato,  ; Redcay & Schilbach,  ), whereby each individual's behavior is simultaneously an antecedent to and a consequence of their interaction partners' actions. At the level of the brain, this emerges through an indirect chain of interpersonal neural events; one interactant's brain responses initiate an action that, in turn, elicits systematic neural responses in their partner to drive a reaction. In this light, the particular dynamic of an interaction emerges through a reciprocal process of between‐brain contingencies, or “neural coupling” (Hasson & Frith,  ). Elucidating the patterns of neural coupling that underlie different forms of social exchange might therefore provide an interpersonal neural substrate of interactive behavior, but this requires the development of new paradigms and analytical techniques for social neuroscience research (Hasson & Honey,  ; Schilbach et al.,  ; Zaki, Bolger, & Ochsner,  ). In response to this, a new wave of “two‐person” or “in situ” social neuroscience has emerged (Hari, Himberg, Nummenmaa, Hämäläinen, & Parkkonen,  ; Kasai, Fukuda, Yahata, Morita, & Fujii,  ; Redcay & Schilbach,  ; Schilbach et al.,  ), whereby the brains of two or more individuals are measured simultaneously while they interact with one another. Such “hyperscanning” allows researchers to explore how social interactions take shape through real‐time processes of interpersonal neural coupling. 

Hyperscanning has been performed successfully with functional magnetic resonance imaging (fMRI), electroencephalography (EEG), functional near‐infrared spectroscopy, and magnetoencephalography (for reviews, see Babiloni & Astolfi,  ; Scholkmann et al.,  ). With these techniques, studies have revealed various patterns of neural coupling elicited during social interaction; while temporally contingent brain responses are observed between interactants during verbal and non‐verbal communication (Ahn et al.,  ; Bilek et al.,  ; Pérez, Carreiras, & Duñabeitia,  ), between‐brain synchrony or “alignment” (Hasson & Frith,  ) is reported during cooperative and competitive joint‐action tasks (e.g., Cheng, Li, & Hu,  ; Sänger, Müller, & Lindenberger,  ; Shaw et al.,  ; Toppi et al.,  ). Interestingly, brain regions implicated in social cognitive processes feature frequently in patterns of neural coupling across various types of social interaction, presumably reflecting the mutual recruitment of mechanisms that permit the transmission and encoding of social information. Within the temporo‐parietal junction (TPJ), for example, brain responses become synchronized and/or contingent between interactants during economic exchanges (Jahng, Kralik, Hwang, & Jeong,  ; Tang et al.,  ; Zhang, Liu, Pelowski, Jia, & Yu,  ), verbal and non‐verbal communication (Bilek et al.,  ,  ; Kinreich, Djalovski, Kraus, Louzoun, & Feldman,  ; Rojiani, Zhang, Noah, & Hirsch,  ; Wilson, Molnar‐Szakacs, & Iacoboni,  ), and cooperative joint‐action tasks (Abe et al.,  ). This is perhaps unsurprising given the putative role of the TPJ in inferring the intentional and motivational states of others (Bardi, Six, & Brass,  ; Carlson, Koenig, & Harms,  ; Eddy,  ; Frith & Frith,  ), a process that is essential for interacting successfully with others. 

Experimental paradigms employed in hyperscanning studies often confound multiple forms of social exchange, however, making it impossible to identify the discrete patterns of neural coupling associated with different types of interactive behavior. In a theoretical framework proposed by Liu and Pelowski ( ), social interaction is suggested to comprise three distinct dimensions: interaction structure (concurrent or turn‐based actions), goal structure (cooperative or competitive goals), and task structure (tasks achieved independently or interdependently). As such, to advance our understanding of how different patterns of neural coupling give rise to interactive behavior, we must first delineate among these dissociable dimensions (Konvalinka & Roepstorff,  ). Recently, our team adapted for hyperscanning research, an interactive task capable of such delineation, in which pairs of players either co‐operate or compete with one another in a turn‐based or concurrent manner to reconstruct a geometric pattern (Špiláková, Shaw, Czekóová, & Brázdil,  ). Employing this task within a dual‐fMRI hyperscanning study, we revealed brain responses in both interactants that were contingent upon the immediately preceding behavior of their co‐player. Furthermore, these brain responses dissociated among discrete dimensions of the interaction; we observed greater inter‐reactive brain responses during co‐operative exchanges within regions implicated in social cognition, while competitive exchanges elicited stronger brain reactions within neural systems involved in motor planning and updating. This demonstrated the potential for hyperscanning to elucidate patterns of interpersonal brain events underlying different forms of social exchange. 

A number of questions emerged from these results; however, first, in an event‐related design, we applied general linear modeling to identify brain signals in each player that reflected direct reactions to a specific aspect of their co‐player's behavior—namely, the end point of their preceding action. As such, we observed interpersonal brain–  behavior   contingencies rather than brain‐to‐brain coupling. It remains to be seen, then, whether patterns of between‐brain coupling between co‐players on this task also differentiate between dissociable dimensions of social exchange. Second, by modeling brain responses to a discrete, predefined element of the players' behavior, we captured interpersonal brain–behavior relationships during an isolated snapshot of the entire social exchange. This offers limited insight into the interpersonal brain events that unfold dynamically throughout a sustained interaction, through which the nature of the exchange takes shape. 

Data‐driven techniques have been developed to provide an alternative way of analyzing hyperscanning data, offering a means to address these outstanding questions. By evaluating dual‐fMRI data in a model‐free, hypothesis‐free manner, whereby no a priori assumptions are made, these techniques are more appropriate for the non‐linear, unpredictable dynamic of naturalistic social exchange (Nastase, Gazzola, & Keysers,  ). Recently, Bilek et al. ( , 2017) demonstrated how two such data‐driven techniques can be combined to investigate neural coupling during social interaction. With group‐independent component analysis (gICA), one can extract spatio‐temporal patterns of brain responses from a set of continuous recordings acquired from multiple interacting dyads. By assessing the dyad‐specific time‐course along which a given pattern is expressed, it is then possible to identify the common element of all exchanges to which those brain responses are associated; for example, one pattern might represent brain responses elicited during all instantiations of co‐operative interactions, while another relates more closely to competitive exchanges. With a second model‐free analytical technique—inter‐subject correlation (ISC) analysis (Hasson, Nir, Levy, Fuhrmann, & Malach,  )—we can then investigate whether the time‐course of neural signals within these data‐defined patterns of interaction‐specific brain responses are correlated, or aligned, between pairs of interacting individuals throughout a sustained interaction. 

To examine whether dissociable patterns of neural coupling emerged during different forms of social exchange, in the present study, we applied gICA‐informed ISC analysis to dual‐fMRI data acquired from pairs of interactants performing our interactive task. Driven by our previous findings, we expected different patterns of neural alignment to delineate among co‐operative and competitive exchanges. Furthermore, we predicted stronger alignment during concurrent relative to turn‐based exchanges, given that players must monitor and adapt to their co‐players' behavior in real‐time during the former, giving rise to temporally coupled inter‐brain contingences. 


## METHODS 
  
### Participants 
  
The analyses presented below were applied to a subset of the data collected under Špiláková et al. ( ); specifically, 19 pairs of individuals who underwent the exact same dual‐fMRI protocol—a necessary requirement for the analytical procedure. These 38 healthy individuals were recruited from Brno, Czech Republic. The mean age of this sample was 22.44 (  SD   = 1.90) years. Participants were paired into 19 same‐sex dyads (11 male–male) matched on self‐evaluated handedness (34 right handers), age (mean difference = 5.79 [  SD   = 4.29] months) and education (highest qualification). The individuals comprising a pair met for first time at the scanning facility on the day of the experiment and were instructed together about the task and experimental procedure. The study was approved by the Research Ethics Committee of Masaryk University, and all participants gave their informed consent prior to the scanning procedure. Participation was rewarded with 200 CZK (approximately €8). 


### The pattern game 
  
The pattern game is an interactive task developed originally by Decety et al. ( ), which we have adapted recently for hyperscanning research (Špiláková et al.,  ). In this game, two players either cooperate or compete with one another over recursive rounds to recreate patterns made up of blue and yellow tokens. Each player is assigned the color blue or yellow, which identifies them throughout the entire game. Prior to each round, players are shown an instruction that allocates one to the role of Builder and the second to either Helper, Hinderer, or Observer (referred to collectively as Other; e.g., “Blue builds, Yellow helps”). While the task of the Builder is always to recreate the pattern as fast as possible, the characteristics of the patterns mean that they can do so more easily with assistance from the Other. The role assigned to the Other then defined one of three conditions: during   Cooperation   rounds, they work with the Builder to help them reconstruct the pattern; in   Competition   rounds, they must work against the Builder and attempt to hinder them from achieving this. In   Control   rounds, the Other is instructed to simply observe the Builder recreating the pattern. Players alternated between the role of Builder and Other on each round. 

Players made their moves by placing tokens sequentially into specific locations of a playing board. Each round began with one of the players' tokens presented on either side of the monitor above the playing board, and using a four‐button controller they moved it leftward or rightward to a desired columnar location before dropping it into the lowest empty row. On each round, both players could place up to five tokens within a time limit of 25 s. The round ended if (a) the pattern was recreated successfully, (b) both players had placed all of their tokens, or (c) 25 s had elapsed. The experiment consisted of two blocks of 48 pseudorandomized rounds: 16   Cooperative  , 16   Competitive  , and 16   Control  . In the first block, participants took turns to place their tokens sequentially (  Turn‐Based   condition). In the second, players were free to place their tokens simultaneously (  Concurrent   condition). Throughout a round, the Builder's token was always in the lower row, closer to the playing board; as such, if both players attempted to place their token at the same columnar position simultaneously, the Builder's token always dropped to the lowest row with the Other's token positioned above it. Figure   presents an overview of the task, which was programmed in MATLAB (v2018b, The MathWorks, Inc.) using the Cogent 2000 toolbox (developed by the Cogent 2000 team at the FIL and the ICN, and John Romaya at the LON at the Wellcome Department of Imaging Neuroscience; RRID:SCR_015672). 
  
Snapshots of stimuli during the Turn‐based Co‐operation (a) and Competition (b) rounds, and Concurrent Co‐operation (c) and Competition (d) rounds. In all examples, the Builder is assigned to the same color as the target pattern (i.e., yellow in a and d, blue in b and c), and scores by placing tokens in locations that recreate the pattern (indicated by solid red lines). The Other is assigned to the opposing color (blue in a and d, yellow in b and c), and scores by placing their tokens in locations that serve to help or hinder the Builder (dashed red lines); since the latter is achieved by placing tokens within the pattern space, thereby obstructing the Builder, the scoring location of Others and Builders are the same in Competitive rounds (solid red lines) 
  

### MRI data acquisition 
  
Brain imaging was performed using two identical 3T Siemens Prisma scanners located within the same facility, both equipped with a 64‐channel HeadNeck coil. First, we acquired high‐resolution whole‐brain T1‐weightened anatomical images (MPRAGE; TR/TE/TI = 2300/2.33/900 ms; flip angle = 8°; field of view = 252 mm × 224 mm; in‐plane matrix size = 252 × 224; slice thickness = 1 mm; 240 sagittal slices; iPAT GRAPPA accel. factor = 2; phase encoding = A>P; no fat suppression; acquisition time = 317 s). Functional time series were then recorded in two runs, each containing 570 volumes (approximately 20 min) acquired after four dummy scans—the turn‐based block was always followed by the Concurrent block. Blood‐oxygen‐level dependent (BOLD) images were obtained with T2*‐weighted echo planar imaging, with parallel acquisition (i‐PAT GRAPPA accel. factor = 2; 34 axial slices; TR/TE = 2000/35 ms; flip angle = 60°; field of view = 204 mm × 204 mm; in‐plane matrix size = 68 × 68; slice thickness = 4 mm; 34 axial slices; phase encoding = A>P). Axial slices were acquired in interleaved order, each one oriented parallel to a line connecting the base of the cerebellum to the base of orbitofrontal cortex to ensure whole‐brain coverage. A single external programmable signal generator (Siglent SDG1025,   http://www.siglent.com  ) initiated the acquisition sequence of both scanners to ensure maximal synchronization (mean asynchrony in volume acquisition = 1.69 [  SD   = 0.65] ms). Likewise, a single computer was used to present synchronized experimental stimuli to both scanners, and to record the timings of radio frequency pulses. 


### Neuroimaging data analysis 
  
The pre‐processing and analysis of functional and structural brain images was performed using various utilities within FMRIB's software library (Jenkinson et al.,  ; SCR_002823). gICA was performed using the GIFT toolbox for MATLAB (v2.0e;   http://mialab.mrn.org/software/gift  ; Calhoun, Adali, Pearlson & Pekar,  ), and ISC analyses were performed with in‐house scripts written and executed in MATLAB (v2018b, The MathWorks, Inc.). 

#### Pre‐processing 
  
For each pair, we obtained four time series (two for each participant—one acquired during the   Turn‐Based   block, the other during the   Concurrent   block) that were pre‐processed independently in the following manner: First, slice‐timing correction for interleaved slice acquisition was applied to the functional images, and each time‐series was detrended and high‐pass filtered across time (Gaussian‐weighted least‐squares straight‐line fitting; sigma = 50.0 s) and spatially smoothed with a 5‐mm full‐width half‐maximum Gaussian kernel. Motion correction was then performed with MCFLIRT (Jenkinson et al.,  ). To remove any residual motion artifacts, or signal caused by physiological noise (e.g., heart rate and respiration), we performed single‐session Independent Component Analysis with MELODIC (Beckmann & Smith,  ) to identify 50 spatio‐temporal components of the BOLD signal. Artifactual components were identified automatically using the Spatially Organized Component Klassifikator (SOCK; Bhaganagarapu et al.,  ), and any signals corresponding to these problematic components were regressed out of the time‐series using   fsl_regfilt  . Since these artifactual components were orthogonal to the signal removed previously by the high‐pass filter, there was no re‐introduction of noise (Lindquist, Geuter, Wager, & Caffo,  ). In our pre‐processing pipeline, the components returned by MELODIC that were identified as artifactual and subsequently regressed out of the time series (the set of nuisance covariates) were drawn from data that had been high‐pass filtered already. Finally, with FLIRT, the time‐series were registered to a corresponding high‐resolution structural image using Boundary‐based Registration, and this, in turn, was registered linearly to the Montreal Neurological Institute (MNI)‐152 template (12 degrees of freedom). 


#### Group‐independent component analysis 
  
We performed gICA to identify common aggregate spatial maps across the entire samples that are expressed through unique time‐courses for each subject. An alternative approach is to allow for unique spatial maps but common time courses, but this is less appropriate for fMRI data (see Calhoun et al.  ). 

The input consisted of 76 functional brain images (38 participants [19 pairs] × 2 blocks [  Turn‐based   and   Concurrent  ]), each containing 570 volumes. Two data reduction steps were first performed: principle component analysis (PCA) was applied initially to each individual time‐series, resulting in a set of 68 components from each of the 76 time‐series, and subsequently to all the resulting components concatenated into one matrix. The second PCA resulted in a set of 20 spatially orthogonal principal components. The optimal number of components to be extracted from each of these PCAs was determined by computing the minimum description length (MDL). The MDL principle is a formal version of Occam's razor, which determines an appropriate model complexity by extracting the maximum amount of information from the data without overfitting (Sammut & Webb,  ). Next, spatial gICA was performed on these reduced data using the INFOMAX algorithm to identify group‐level components that were independent of one another (Langlois, Chartier, & Gosselin,  ). To ascertain the reliability of these spatial components, gICA was run 20 times and the resulting estimates were compared using ICASSO: each estimated independent component occupies one point in the signal space, and if a component is reliable then each run of the algorithm should produce one point in the signal space that is very close to the “real” component. Thus, reliable independent components correspond to clusters that are small and well separated from the rest of the estimates. In contrast, unreliable components correspond to points which do not belong to any cluster. A cluster quality index,   I  , is then used to evaluate what clusters are the most compact and isolated; this index is computed as the difference between the average intra‐cluster and average extra‐cluster similarities. Eventually,   I   is equal to one for an ideal cluster (Himberg, Hyvärinen, & Esposito,  ). This ICASSO analysis revealed that all 20 components achieved very high cluster quality indices over all iterations (  I   = .97–.98). This part of the gICA pipeline is illustrated schematically in Figure  a. 
  
Group‐Independent Component Analysis (gICA) pipeline. (a) Two data reduction steps were performed on the pre‐processed data: PCA was first applied to each individual time‐series, and then to all the time‐series concatenated into one matrix. Next, gICA was performed on these reduced data using the INFOMAX algorithm, revealing 20 reliable components. (b) After the removal of five artifactual components, the remaining 15 components were back‐reconstructed to the individual input time‐series. Applying multiple regression to the subject‐specific time‐series revealed four components that were expressed along a time‐series aligned with interaction‐specific conditions. Note: Magnifying glasses represent stages of data reduction 
  
After visual inspection of the reliable components emerging from ICASSO, five were identified as artifactual and excluded from further analyses (e.g., components reflecting heartbeat, white matter, and cerebrospinal fluid; see Figure S1). Since the remaining 15 components were extracted from time‐series acquired during cooperative   and   competitive exchanges, and in both turn‐based   and   concurrent interactions, each one could express all dimensions of interaction equally or a specific dimension/combination of dimensions independently. To identify components that reflected brain responses associated with each condition (  Co‐operation, Competition  , and   Control  ), we used the results of the PCA data‐reduction steps to back‐reconstruct each component to the individual input time‐series. This resulted in a time‐course for each component specific to each subject in each block. Multiple regression analysis was then computed: For each participant, the explanatory variables were their subject‐specific back‐reconstructed time‐course for each independent component, and the outcome variable was their unique task design for each condition within each block. This resulted in subject‐specific   β  ‐values for each of the three conditions during the   Concurrent   or   Turn‐based   block (six   β  ‐values for each participant for each component). These   β  ‐values were then compared using paired‐samples   t  ‐tests to identify interaction‐specific components; that is, components for which the back‐reconstructed time‐course for each participant fit their task design of the experimental conditions more than the   Control   condition (  β   > 0 and   β   >   β  ; or   β   > 0 and   β   >   β  ), and showed greater fit for either the   Cooperation   or   Competition   condition. For components to be selected, this had to be true in both concurrent and turn‐based condition. This procedure, illustrated in Figure  b, identified four interaction‐specific components. 


#### Inter‐subject correlation analysis 
  
Next, to calculate the degree of neural alignment in each condition we computed matrices of cross‐correlations between the back‐reconstructed time‐series of interaction‐specific components for each interacting pair, separately for the   Turn‐based   and   Concurrent   block (e.g., correlation between the time‐series of component #1 in the Blue player and component #2 in their Yellow co‐player, in the   Turn‐based   block). For each component, Pearson correlations were applied to the entire back‐reconstructed time‐series from within each block (570 volumes). The resulting correlation coefficients were transformed to   z  ‐values, and the median was used as a coupling coefficient. To determine the significance of the resulting coefficients, we performed a randomization test with 10,000 permutations: in each iteration, we randomly selected 38 non‐interacting pairs (retaining the role of each participant; e.g., component #1 in the Blue player of one pair, and component #2 from the Yellow player of a different pair) and computed a median z‐transformed coefficient as above. This produced a null distribution of correlations among non‐interacting pairs for each interaction‐specific component, against which the significance of coupling between each interacting pair was then compared (see Figure 4a). Pairwise comparisons among the four non‐artifactual, interaction‐specific components revealed significantly higher correlations among interacting compared with non‐interacting pairs after Bonferroni correction (α = .05/4 ). Finally, to assess whether differences existed in the strength of neural coupling between the   Concurrent   and   Turn‐based   interactions, for each interaction‐specific component, we compared the within‐pair correlation coefficients using a Wilcoxon sign‐rank test (e.g., the coefficients calculated for all interacting pairs for Component #1 in the   Turn‐based   block were compared with those calculated for all interacting pairs for Component #1 in the   Concurrent   block). This analysis is illustrated in Figure  . 
  
Inter‐subject correlation (ISC) pipeline. For the seven non‐artifactual interaction‐specific components resulting from gICA, ISCs were computed for interacting pairs and compared with those between non‐interacting individuals. Finally, for each component, the ISCs between interacting pairs were compared between the Turn‐based and Concurrent blocks 
  
While   I   obtained from ICASSO was >0.9 for each cluster (component), to ensure that the individual back‐reconstructed time‐series were stable even with a slight change in the spatial configuration of the component, we ran the gICA and subsequent post‐processing analysis five times with the exactly same parameters. In the following section, we report only the results that were replicated in each of these five iterations. 




## RESULTS 
  
gICA revealed one component that was related more strongly to instances of the   Cooperative   compared with the   Control   rounds (component 10 in Figure S1; referred to herein as Coop#1), while three were associated more strongly with   Competitive   than   Control   rounds (components 13, 14, and 18; referred to herein as Comp#1, Comp#2, and Comp#3, respectively). The spatial pattern of brain regions comprising Coop#1 included bilateral precunei, bilateral clusters centered on the superior temporal sulci (STS) but extending dorsally to the TPJ and ventrally to the fusiform gyri, bilateral dorso‐lateral prefrontal cortices, and the cerebellum. Interestingly, Comp#1 consisted entirely of brain responses localized to the cerebellum. Those encompassed by Comp#2, however, included right precuneus, right superior frontal gyrus extending into prefrontal cortex, right caudate nucleus, right parietal inferior gyrus, and left cerebellum. In Comp#3, the brain responses were present bilaterally in superior frontal gyri, anterior cingulate cortex (ACC), anterior insulae (AI), precunei, the cerebellum, and left precentral gyrus. These results are presented in Figure  a. 
  
Results of gICA‐informed ISC analyses. (a) Spatial maps of four components identified by group‐Independent Component Analysis (gICA), which were expressed in individual brains along time‐series that corresponded to instances of cooperative or competitive interactions. (b) The randomization test revealed that the back‐reconstructed time‐series for each component were correlated significantly more strongly (  p   < .05, Bonferroni corrected) between interacting compared with non‐interacting players. Histograms show the null‐distribution of median correlation coefficients across all non‐interacting pairs—the frequency (y‐axis) with which correlations of different strengths (x‐axis) were identified across all permutations. The red line presents the median correlation coefficient across all interacting pairs. (c) Comparisons between the correlation coefficients (y‐axis) for all interacting pairs between the Concurrent (CN) and Turn‐based (TB) blocks. Note: Components emerging from gICA are overlaid onto the Colin27 template (Holmes et al.,  ) in MNI space 
  
For each of these components, ISC analyses revealed that the back‐reconstructed time‐courses were correlated more strongly between interacting than non‐interacting pairs after (  p   < .05, Bonferroni corrected; see Figure  b). Furthermore, this measure of neural alignment between interacting dyads was significantly stronger during the   Concurrent   relative to the   Turn‐based   block for Coop#1 (mean coupling coefficient: CN = .31 [range = −.05–.51] vs. TB = .14 [range = −.02–.27];   W   = 187,   Z   = 3.70,   p   < .001), Comp#1 (mean CN = .13 [range = −.01–.30] vs. TB = .03 [range = −.07–.15];   W   = 161,   Z   = 2.66,   p   = .008) and Comp#3 (CN = .35 [range = .04–.45] vs. TB = .25 [range = .01–.40];   W   = 176,   Z   = 3.26,   p   = .001). For Comp#2, however, neural coupling did not differ significantly between blocks (CN = .29 [range = .03–.48] vs. TB = .33 [range = −.15–.44];   W   = 54,   Z   = ‐1.65,   p   = .09). These results are illustrated in Figure  c, and detailed further in Table S1. 


## DISCUSSION 
  
To investigate whether different patterns of neural coupling between individuals emerge during dissociable types of interaction, we analyzed dual‐fMRI “hyperscanning” data acquired from dyads engaged in a variety of interactions using a combination of two techniques: a data‐driven gICA and subsequent ISC. This gICA‐informed ISC analysis revealed a distinct spatio‐temporal pattern of brain response that followed a time‐course associated with co‐operative exchanges, and three independent patterns that corresponded more closely to competitive interactions. More importantly, the time‐courses of all these components were correlated significantly between pairs of interactants, and these distinct patterns of interpersonal brain‐to‐brain alignment delineated among concurrent and turn‐based exchanges. These results demonstrate the utility of data‐driven approaches applied to hyperscanning data in elucidating the interpersonal neural processes that give rise to the two‐in‐one dynamic characterizing social interaction. 

Appreciating fully the ability of gICA‐informed ISC analysis to distinguish among different dimensions of interpersonal interactions requires an evaluation of the analytical process: The inputs were time‐series acquired during both cooperative   and   competitive conditions, and in both turn‐based   and   concurrent interactions. As such, components emerging from the gICA could express all interaction dimensions equally, or a specific dimension/combination of dimensions independently. Indeed, multiple regression applied to the back‐reconstructed time‐series revealed that only four of the 15 non‐artifactual components were specific to either cooperation   or   competition. By examining correlations in the time‐series of these patterns across all players—both interacting   and   non‐interacting pairs—we were then able to identify patterns of neural alignment that were both specific to real interactions and distinguished between co‐operative and competitive exchanges performed in a concurrent or turn‐based manner. 

The collection of brain regions expressing interpersonal neural coupling during co‐operative exchanges, Coop#1, encompassed bilateral precunei, STS, TPJ, and the cerebellum. A substantial body of research has shown that the precuneus, STS, and TPJ comprise a network of brain regions co‐activated during experimental tasks requiring the attribution of mental states to others, such as desires, intentions, and beliefs (Bardi et al.,  ; Carlson et al.,  ; Eddy,  ). Based on its engagement during visuo‐spatial mental imagery (e.g., Ghaem et al.,  ; Hanakawa et al.,  ), and both implicit and explicit metalizing (for meta‐analytic reviews, see Schilbach et al.,  ; Wolf, Dziobek, & Heekeren,  ), it is believed that the precuneus is involved in the representation of others' perspectives (Cavanna & Trimble,  ). Similarly, the TPJ responds when individuals are required to infer another person's perspective when it differs from their own (e.g., Dumontheil et al.,  ; Mazzarella et al.,  ); that is, when distinctions must be made between self‐ and other representations (Lamm, Bukowski, & Silani,  ; Uddin, Molnar‐Szakacs, Zaidel, & Iacoboni,  ). 

Since co‐operative interactions require both individuals to act in line with a common goal and in a manner that complements their interaction partner's behavior (Sebanz, Bekkering, & Knoblich,  ), it is perhaps unsurprising to observe neural alignment throughout these brain systems; both individuals must attempt to predict their co‐player's intentions and expectations in order to modify their own actions accordingly (Hampton, Bossaerts, & O'Doherty,  ; Jara‐Ettinger, Baker, & Tenenbaum,  ; Kestemont et al.,  ; Kestemont, Vandekerckhove, Ma, Van Hoeck, & Van Overwalle,  ). Indeed, brain‐to‐brain synchronization within the TPJ and STS has been reported during economic exchanges (Jahng et al.,  ; Tang et al.,  ; Zhang et al.,  ), cooperative joint‐action (Abe et al.,  ), and communicative tasks (Hirsch, Zhang, Noah, & Ono,  ; Kinreich et al.,  ; Rojiani et al.,  ; Wilson et al.,  ). What is surprising, however, is the ability of a data‐driven analysis to identify spatio‐temporal patterns of brain response that delineate among social interactions along the goal dimension, and within which the strength of neural alignment differentiates between exchanges along the interaction dimension. 

The first pattern of neural responses elicited during competitive exchanges, Comp#1, consisted exclusively of the bilateral cerebellum. An expansive corpus of research into the functions of the cerebellum points to its primary role in sensory prediction and the formation of expectations through interactions with the environment (Leggio & Molinari,  ; Nixon,  ). Within this pattern, neural alignment was significantly stronger during concurrent than turn‐based competitive interactions. We suggest this reflects greater inter‐brain contingencies in visuo‐spatial processing mechanisms during real‐time interaction, whereby each player must simultaneously predict and adapt to the behavior of their partner. 

The second spatio‐temporal pattern of brain responses elicited during competitive exchanges that were aligned between interacting players, Comp#2, comprised brain regions localized primarily to the right hemisphere, including lateral prefrontal cortex, caudate nucleus, inferior parietal cortex, and precuneus, but also the left cerebellum. The inferior parietal cortex is considered a higher‐order brain area involved in the visuo‐spatial control of motor behavior (Culham, Cavina‐Pratesi, & Singhal,  ; Gallivan & Culham,  ). Given the abovementioned putative role of the cerebellum in similar motor‐related spatial processing, this pattern of neural alignment might index temporally coupled dependencies in visuo‐motor processes during competitive interactions. Interestingly, the caudate nucleus has been implicated in response switching (Grahn, Parkinson, & Owen,  ), and the concerted engagement of the precuneus and the caudate nucleus has been observed during the planning and generation of strategic moves during competitive interactive games (Wan et al.,  ). Taken together, interpersonal neural coupling within this collection of brain regions might reflect the mutual recruitment of processes involved in the monitoring of a co‐players behavior and subsequent updating of one's own motor actions to allow for flexible co‐adaption during competitive interactions. Importantly, while all spatio‐temporal patterns were relatively unresponsive during the control condition, in which participants simply viewed the actions of their co‐player, within this collection of brain regions we observed no significant differences in the strength of inter‐player neural coupling between concurrent and turn‐based competitive exchanges. This might reveal a pattern of alignment common to both forms of competitive interaction, allowing individuals to plan their next move on the basis of their co‐player's preceding action. 

The third pattern of brain responses expressing neural alignment between players engaged in competitive interactions, Comp#3, encompassed the superior frontal cortices, ACC, AI, precuneus, and cerebellum. This converges with the findings of Wilson et al. ( ), who report ISCs of brain function during verbal communication within the ACC, lateral frontal cortices, and the precuneus. A network of frontal activations incorporating the dorsal ACC and AI constitute the so‐called salience network, which is thought to be responsible for identifying behaviorally relevant stimuli. In a previous study, we observed a similar pattern of neural alignment within the dorsal ACC and AI between players involved in an interactive game of economic exchange; more specifically, inter‐brain alignment in these regions was associated with the degree of reciprocity expressed between players (Shaw et al.,  ). We interpreted this to reflect the mutual effort of players to modify their own behavior according to that of their opponent, a process necessary to compete successfully in an inter‐dependent context. In this light, stronger alignment with a neural saliency‐detection system during concurrent compared with turn‐based competitive exchanges might index a greater effort of both players to process and react dynamically to their opponent's moves; during concurrent exchanges, each player's actions present a continuous flow of salient information to their opponent, demanding more flexible co‐adaptation. 

Interestingly, all but one of these patterns shared a common feature—neural alignment within the precuneus. This brain region is connected reciprocally to many other parts of the brain, and is considered a member of the so‐called “rich club”—a group of neural hubs that are interconnected among themselves (van den Heuvel & Sporns,  ). Our results suggest that the precuneus plays a central role in various forms of inter‐dependent social exchange; it may provide a channel through which social information is transmitted interpersonally and relayed to other brain systems to permit adaptive responses during social interaction. It is also interesting that no pattern. 

These distinct patterns of brain coupling provide unique insights into the interpersonal neural processes that unfold during dissociable forms of social exchange. In three of the components identified by gICA (Coop#1, Comp#2, and Comp#3), ISCs between interacting pairs were strongest during concurrent exchanges. This converges with the results from neuroscientific investigations that have employed dual‐EEG to investigate patterns of between‐brain alignment during unconstrained interpersonal behavior (Dumas, Martinerie, Soussignan, & Nadel,  ; Dumas, Nadel, Soussignan, Martinerie, & Garnero,  ); greater inter‐brain coherence is reported among interactants engaged in self‐initiated, spontaneous interactions compared with exchanges that are guided externally by an experimenter—a distinction paralleling that between turn‐based and concurrent exchanges. Importantly, these results do not simply reflect the degree of similarity in motoric‐ or sensory‐related brain responses: First, inter‐brain covariance was significantly stronger between pairs of interacting co‐players compared with pairs of non‐interacting players selected at random. Second, such interaction‐specific between‐brain covariance was observed in both concurrent and turn‐based exchanges—this index of neural coupling was present even when individuals took turns to observe the actions of their co‐player before making a reactive response, but more so when the players reacted to one another concurrently. Third, we only extracted this index of neural coupling from within spatio‐temporal patterns of brain response that followed a time‐course aligned more with experimental than control rounds. During control rounds, one individual (the Builder) recreated a pattern without any help or hindrance from the Other, while the Other observed the Builder passively. Hence, ISCs were extracted from patterns of brain response elicited during inter‐dependent interactions, whereby the moves of each individual were mutually dependent upon their co‐player's actions. As such, stronger ISCs during concurrent compared with turn‐based exchanges presumably reflects greater interpersonal neural alignment as both players monitor, evaluate, and adapt to the behavior of their co‐player in real‐time. 

It is important to acknowledge that the results of the present study must be reproduced in larger samples before we can evaluate properly the utility of gICA‐informed ISC for hyperscanning research. A more rigorous evaluation of this analytical technique also requires the present results to be reproduced with other interactive paradigms, and with designs that overcome any potential limitations of the current study. For example, dyads in our experiment always performed a block of turn‐based interactions before a block of concurrent exchanges; since the concurrent condition added a level of complexity to turn‐based interactions, our intention was to minimize fatigue and maximize motivation between the first‐ and second‐half of the procedure. In doing so, however, we may have introduced order effects, and so our results require reproduction in other procedures for which such influences cannot exist. 

Future research should also examine whether the interaction‐specific patterns of neural coupling revealed here extend to more real‐world social situations. Hyperscanning permits social neuroscience to be conducted in ecologically valid contexts; Toppi et al. ( ), for example, used dual‐EEG to investigate inter‐brain events among aircraft pilots during flight simulations, revealing patterns of between‐brain coherence that differentiated between various cooperative scenarios. It would be interesting to see whether the same patterns of neural coupling that we have observed with our interactive experimental task delineate among social exchanges with real‐world implications. Studies should also investigate if the patterns of interaction‐specific coupling observed in the present study are modulated by characteristics that have been shown to alter between‐brain events; should they truly reflect the social aspects of interpersonal exchanges; they should be influenced by the sex of interactants (Cheng et al.,  ) and the language used during verbal interaction (Pérez et al.,  ). 


## Supporting information 
  
 ## DATA AVAILABILITY STATEMENT

Data are not shared, but can be made available upon request. </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-74'>
<h2>74. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/23251653/' target='_blank'>23251653</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> fMRI Evidence of ‘Mirror’ Responses to Geometric Shapes</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2012</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0051934</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3522615/' target='_blank'>3522615</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study used fMRI in a sample of healthy adult participants (N=21, mean age 24) while they observed and executed others’ hand actions—an explicit social-related task falling under ‘Perception and Understanding of Others’/action understanding. The methods report both ROI and whole-brain analyses (a whole-brain analysis at p<0.001 uncorrected is described), so it is not ROI-only. All participants are healthy adults (17–65 criterion met), and results are reported for this healthy group. No exclusion criteria (e.g., patient-only samples or ROI-only reporting) are violated. Therefore the study meets all inclusion criteria for the review.</p>
<p><strong>Fulltext Confidence:</strong> 0.9</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Mirror neurons may be a genetic adaptation for social interaction  . Alternatively, the associative hypothesis  ,   proposes that the development of mirror neurons is driven by sensorimotor learning, and that, given suitable experience, mirror neurons will respond to any stimulus. This hypothesis was tested using fMRI adaptation to index populations of cells with mirror properties. After sensorimotor training, where geometric shapes were paired with hand actions, BOLD response was measured while human participants experienced runs of events in which shape observation alternated with action execution or observation. Adaptation from shapes to action execution, and critically, observation, occurred in ventral premotor cortex (PMv) and inferior parietal lobule (IPL). Adaptation from shapes to execution indicates that neuronal populations responding to the shapes had motor properties, while adaptation to observation demonstrates that these populations had mirror properties. These results indicate that sensorimotor training induced populations of cells with mirror properties in PMv and IPL to respond to the observation of arbitrary shapes. They suggest that the mirror system has not been shaped by evolution to respond in a mirror fashion to biological actions; instead, its development is mediated by stimulus-general processes of learning within a system adapted for visuomotor control. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (42515 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Mirror neurons discharge when a monkey executes an action and when it passively observes a similar action. They have been found in ventral premotor cortex (PMv), area F5  ,   and rostral inferior parietal lobule (IPL), area PF  ,  . Since their initial discovery, mirror neurons responsive, not only to object-directed, but also to pantomimed or intransitive actions, have been discovered in F5  . Mirror neurons have also been reported in F5 that appear tuned to the sight of actions executed with tools (e.g. grasping with pliers  ) and to the sounds associated with actions (e.g. plastic crumpling)  . 

Evidence consistent with the claim that humans also have populations of neurons with mirror properties (supporting mirror ‘representations’ of action) can be obtained from studies using functional magnetic resonance imaging (fMRI). These show that areas of the human cortex, homologous to those where mirror neurons have been found in monkeys, are active when we observe and execute similar actions  , and show characteristic patterns of adaptation. Specifically, these cortical areas are less active where an action event (‘A’; either the observation or execution of an action) is preceded by a similar action event (AA) than when preceded by a dissimilar action event (BA). Importantly, this adaptation is observed both when the two events are experienced within-modality (A −A  or A −A ) or across modalities (A −A , or A −A ). For example, in a study where participants either observed or executed a precision grip or ring pulling action in successive trials, there was less PMv activation when ring pulling observation was preceded by ring pulling execution than when it was preceded by precision grip execution   (references to PMv include BA44, a posterior portion of the inferior frontal gyrus, because it is thought to be the human homologue of monkey premotor region F5). This crossmodal (execution-observation and observation-execution) adaptation effect has been replicated in PMv   and also reported in IPL  . It provides evidence that common neural populations are active during the observation and execution of the same actions, suggestive of mirror representations of action: Whereas repeated activation of a common ‘mirror’ population will result in a decline in its responsivity, successive activation of independent sensory and motor populations will not  . 

According to the associative hypothesis  ,  , mirror neurons acquire their characteristic matching properties through sensorimotor learning. At birth, sensory neurons in the superior temporal sulcus and elsewhere in the cortex are weakly and unsystematically connected to motor neurons; for example in PMv. During infancy, individuals watch their own actions and are imitated by others  ,  . Both self-observation and being imitated cause correlated (i.e. contiguous and contingent) activation of sensory neurons and motor neurons that code similar actions. This correlated activation selectively strengthens connections between those sensory and motor neurons encoding similar actions (associative learning), giving the motor neurons ‘mirror’ properties, i.e. they discharge, not only when an action is executed, but also, by virtue of their connections with sensory neurons, when similar actions are observed. This account assumes that mirror neuron development is relatively unconstrained, as it is mediated by domain general processes of learning. Given the appropriate sensorimotor experience mirror neurons can emerge that respond to different actions in the observe and execute conditions (so-called ‘logically related’ mirror neurons  ) or to arbitrary sensory stimuli (e.g. the sight of actions executed with tools or action sounds  ,  ). This contrasts with the dominant view in the literature, which suggests that mirror neurons are a genetic adaptation for social interaction  ; that mirror neurons have been ‘programmed’ by evolution to promote action understanding, or other social cognitive functions. 

If the associative account is correct, it should be possible for mirror neurons in classic mirror areas (e.g. PMv and IPL) to become connected through sensorimotor learning, not only to visual neurons that code actions, but also to visual neurons that code non-action stimuli, such as geometric shapes. Connections of this kind would yield mirror neurons that are selectively responsive to the execution and observation of a particular action and to the observation of a shape that has been associated with performance of that action. In order to test this hypothesis, participants were given sensorimotor training in which they were required to perform distinct hand actions in response to different geometric shapes (see  ). It is difficult to measure the activity of single neurons in humans, and so in the current study fMRI adaptation was used to measure the activity of populations of neurons with mirror properties. After training, in the first fMRI session participants experienced runs of events in which shape observation alternated with action execution. We compared the blood-oxygen-level-dependent (BOLD) signal in ‘trained trials’, where the event was immediately preceded by an event with which it had been paired during training, and ‘untrained trials’, when it was preceded by an event with which it had not been paired (see  ). If sensorimotor training induces populations of neurons in mirror areas encoding motor properties of actions to respond to geometric shapes (see  ), one would expect a lower BOLD signal in trained than in untrained trials (due to BOLD adaptation). 
   Schematic illustration of the experimental design.  
a) An example set of trained shape-response mappings. The relationship between shape and action type was held constant for a given participant throughout training, but was varied between participants. b) Illustration of a sequence of trials in Session 1. Observation of shapes alternated with execution of actions. A trial was ‘trained’ if preceded by an event type with which it had been paired during training, and ‘untrained’ if preceded by a different event type. c) Illustration of a sequence of trials in Session 2. In this session, observation of shapes alternated with observation of actions, and ‘trained’ trials were those in which, if training induced   mirror   representations to respond to arbitrary shapes, both the preceding and current events should activate the same motor representation. See also  . 
     Schematic representation of the fMRI adaptation logic.  
Note that although reference is made to mirror   neurons  , fMRI data is driven by populations of neurons. Purple ovals denote populations of sensory neurons encoding visual properties of stimuli; blue ovals denote populations of motor neurons responsible for action execution. a) Before training, motor neurons are activated by observation of actions (top) but not by observation of shapes (bottom). These cells are therefore mirror neurons b) Training where participants respond to each arbitrary geometric shape with a distinctive action establishes novel excitatory links (broken arrow) between neurons encoding sensory properties of each shapes and motor neurons encoding the trained action. c) Session 1. Adaptation from shape observation to action execution (signified by paler flash on right), and vice versa, shows that, as a result of training, the shapes activate neuronal populations with motor properties. d) Session 2. Adaptation from shape observation to action observation, and vice versa, shows that shape and action observation activates common neuronal populations; i.e. cells with   mirror   properties. Session 2 adaptation would not have occurred if experimental training had linked visual neurons with i) purely motor neurons, ii) canonical neurons, or iii) logically related mirror neurons. The training must have linked neurons encoding the sensory properties of the geometric shapes with neurons that were already encoding both sensory and motor properties of action, i.e. congruent mirror neurons. 
     An example of 16 trials in a block, categorised according to their Transition Type and Trial Type with respect to the previous trial.        
To determine whether sensorimotor learning changed the responses, not merely of populations of motor or canonical neurons, but of populations of neurons coding the matching sensory and motor properties of action (i.e. mirror representations), participants completed a second fMRI session in which shapes alternated with action observation (see  ). It should be noted that participants could not observe their actions during training. Therefore, in this session, ‘trained’ trials were those in which both the preceding and current event could activate a common neuronal population encoding the same motor representation. Since in this session both events comprise only observation (of shapes or of actions), they could only activate the same motor representation if the training had induced responses to arbitrary shapes not only in populations of   motor   neurons but in populations of neurons with   mirror   properties. BOLD adaptation between shapes and observation of actions in mirror areas would indicate that sensorimotor training induced mirror representations – populations of neurons that were already coding both observation and execution of similar actions - to respond to arbitrary geometric shapes. For example, for a participant trained to associate ‘observe hexagon’ with ‘execute splay fingers’, both the observation of a hexagon and the observation of splayed fingers should activate neural populations coding for the execution of splay fingers, as long as this population has mirror properties; i.e. it responds to both observation and execution of splay fingers. 

Session 2 is crucial for the interpretation of any learning effects observed. If training altered the properties, not of populations of cells with mirror properties, but of other populations of neuron in the regions of interest (e.g. canonical neurons, motor neurons, or ‘logically-related’ mirror neurons), adaptation should not be observed in Session 2. That is, if sensorimotor training induced purely motor neurons to respond to geometric shapes, one would not expect shape and action observation to activate the same neural population during Session 2. In this case, although shape observation would activate the motor representation, observation of actions would not. Similarly, if training induces populations of canonical neurons to respond to observation of the shapes, adaptation would not be observed during Session 2, as one would again expect shape observation, but not action observation, to activate these populations. If training induced populations of ‘logically-related’ mirror neurons to respond to observed shapes, adaptation would not be expected during Session 2. Observation of the shapes could activate logically-related neurons coding for execution of action A, but, by definition, observation of action A would not. One would only expect adaptation in Session 2 if training induced populations of neurons coding for observation and execution of the   same   action (i.e. by definition, congruent mirror representations) to respond to the observation of the trained shape. 


## Materials and Methods 
  
### Participants 
  
Twenty-one paid healthy participants took part in this study (8 male, mean age 24.0 years, standard deviation 4.4 years). All were right handed, assessed using the Edinburgh Handedness Inventory (EHI)  . One participant had an EHI score of 55 which is in the 1  right-handed decile, all other participants had scores of 70 or greater. Participants had normal or corrected-to-normal vision, were naïve with respect to the purpose of the experiment, and all gave written informed consent. The experiment was performed with the approval of the Birkbeck Psychology Research Ethics Committee and performed in accordance with the ethical standards laid down in the 1964 Declaration of Helsinki. 


### Stimuli 
  
The action stimuli were generated by video recording each of four models (two male and two female) performing four different gestures with the right hand. The gestures were filmed from a first-person perspective and all started from a relaxed position with the hand supine on a featureless background. From this starting position the four gestures were: 1) point finger - curling the thumb, middle, ring and little fingers under the palm and extending the index finger so that it pointed; 2) splay fingers - extending all of the fingers and the thumb as far as possible away from the palm; 3) extend thumb - curling all fingers under the palm and extending the thumb to the side, and 4) make fist - curling the thumb and all fingers under the palm to make a fist. These gestures were used because they had previously been shown to produce robust adaptation when executed  . The shape stimuli consisted of a green circle, yellow hexagon, red square and blue triangle. Execution trials were cued by the words, ‘point’, ‘stretch’, ‘thumb’, and ‘fist’ presented uppercase, in white Helvetica font on a black background. 


### Procedure 
  
#### Training 
  
During training participants were initially instructed in the correct execution of each of the four gestures. When the participant was consistently executing the correct gestures, they were asked to put their hand behind a screen so that it was invisible to the participant but visible to the experimenter. Participants were seated in front of a computer monitor where the shape stimuli were to be displayed. They were instructed that they would be asked to perform the appropriate gesture in response to a shape and that each of the four shapes cued one of the four gestures. They were also told that they would have to discover for themselves which gesture was appropriate for each shape. Thus, participants were not explicitly instructed about the shape-gesture mappings (e.g. they were not told to respond to green circles by pointing), or to make a particular gesture in any given trial. In the first eight training trials each of the shapes was presented twice. Subsequently, the order of shape presentation was randomized within each block. In each trial a shape was presented and the participant made a response. If the gesture was correct, the next trial was presented. If the participant executed the wrong gesture, a warning tone sounded and the word ‘Wrong!’ appeared on the screen. The same stimulus was then presented in successive trials until the participant made the correct response. Accuracy was monitored by the experimenter, who could see both the stimulus presented to the participant and the participant’s response. Eleven of the participants were trained with the following stimulus-response mappings: circle −point finger ; square −extend thumb ; hexagon −splay fingers ; triangle −make fist  (see  ). The remaining ten participants were trained: circle −splay fingers ; square −make fist ; hexagon −point finger ; triangle −extend thumb . Using different arbitrary pairings for different participants ensured that it could not have been pre-existing associations between the actions and shapes, rather than the training, which produced the observed effects. The initial period of training was completed a day before the scanning session and consisted of eight blocks of 150 trials each (lasting approximately one hour in total). A refresher period of training was completed immediately before the scanning session and consisted of four blocks of 150 trials. 


#### Scanning procedure 
  
All participants completed two sessions. During Session 1, shape observation alternated with gesture execution (see  ). Execution events were cued by the words, ‘point’, ‘stretch’, ‘thumb’, and ‘fist’. Participants were required to perform the gesture that corresponded to the word cue. Whether the first event involved shape observation or action execution was counterbalanced across participants. During Session 2, shape observation alternated with action observation ( ). Session 2 was structurally identical to Session 1; the only difference between them was that participants were required to execute actions in Session 1 and to observe actions in Session 2. Each stimulus (shape, word, or action video) was presented for 800 ms. 

Each session was split into eight mini-blocks of 33 events (264 events in total). Each event was characterized as a trained or untrained trial with respect to the preceding event (i.e. using the methodology employed by Hamilton and Grafton  ; see   and  . The first event in each mini-block was therefore discarded, resulting in an effective design of eight mini-blocks of 32 trials each (256 trials in total). Each mini-block comprised a factorial design with factors of Trial Type (trained or untrained), ISI (short or long), and Transition Type (observation - execution, or execution - observation). Adaptation was assessed over both short and long trial-to-trial and session timescales: ISI between stimuli was fixed at 250 ms (‘short’), or was randomly jittered between 2 and 4 seconds (mean 3 seconds, ‘long’). In addition, mini-blocks 5–8 were an exact replication of mini-blocks 1–4, enabling adaptation to be assessed during a short session (mini-blocks 1–4), and across a longer session (comparison with mini-blocks 5–8). Four repetitions of each combination of the ISI, Trial Type, and Transition Type factors made up each mini-block. The trial order within mini-blocks was randomly determined. Each mini-block contained only two examples of the four shape-gesture pairings (e.g. in a particular mini-block participants may have only observed circle and square stimuli and only executed point finger and extend thumb). This ensured that the number of specific combinations of shape and gestures presented in a mini-block did not differ between trained and untrained trials, and therefore that the opportunity to learn new associations did not differ between trained and untrained trials during the fMRI sessions. The two examples were chosen randomly in each of mini-blocks 1–4, and replicated in mini-blocks 5–8. 

Participants were filmed throughout Session 1 so that the experimenter could ensure online, and subsequently offline, that they were executing 1) the actions they were instructed to perform, and 2) during execution periods only. Participants made very few errors. They omitted a cued response in 0.69% of trials, made an incorrect response in 0.39% of trials, and made an uncued response in 0.49% of trials. Given the low rate of errors, the behavioral data were not analysed further. 



### Data Acquisition and Analysis 
  
We acquired T2*-weighted echo-planar images (EPI) with BOLD contrast on a 1.5T whole-body MRI scanner (Siemens AG, Erlangen, Germany) in two sessions (TR = 2.556s, TA = 2.556s, 30 axial slices, 4 mm×4 mm×4 mm in-plane resolution) operated with a 32-channel head coil. A total of 252 volumes were collected for each of the two sessions, including 6 dummy volumes at the start of each session to allow for T1 equilibration. High-resolution T1-weighted structural scans were collected for all but one participant and were co-registered to their mean EPI images. For the participant where it was not possible to collect a T1 scan, we co-registered functional scans to the Montreal Neurological Institute (MNI) EPI template. 

Data pre-processing of the EPI functional scans, including spatial realignment, unwarping, normalization to the standard MNI template, and smoothing with a 4 mm (full-width half-maximum, FWHM) Gaussian kernel, was completed using SPM8 (  www.fil.ion.ucl.ac.uk/spm  ). The event-related fMRI data were then analysed using a linear convolution model. We included 32 regressors of interest, which were regressed against the EPI data and high-pass filtered at 128 seconds to remove low-frequency drift. These regressors were derived by convolving a canonical hemodynamic response function and its temporal derivative with delta functions representing stimulus onset of each unique combination of the levels of the factors. The factors were Trial Type (trained, untrained), Transition Type (observation - execution, execution - observation), ISI (short, long) and Session Half (miniblocks 1–4, miniblocks 5–8) factors). The resulting beta images for each condition were combined to form magnitude images as described in Steffener et al.  . These subject (first) level magnitude images were used to generate contrast images, which were smoothed with a 4 mm FWHM Gaussian kernel, and entered into a random effects (second-level) analysis to investigate group-level responses. All co-ordinates are reported in MNI space. 

Two analyses were performed. The first was performed within regions of interest (ROIs) that corresponded to 10 mm spheres around the peak voxels within PMv and parietal cortex where previous studies have found crossmodal (observation – execution or execution – observation) action adaptation effects. These voxels were taken from the studies of Chong et al.  , Lingnau et al.  , Kilner et al.  , and Press et al.  . We generated two ROIs; one for cross-modal effects within PMv and IFG, consisting of spheres around [−50,−2,12]  , [−56,2,20] and  ,  ,  , and another for effects within parietal cortex; consisting of spheres around [58,−56,34] (IPL  ), [−46,−37,27] (intraparietal sulcus  ), and [−28,−59,46] (superior parietal lobule  ). Significance levels within this analysis were family-wise error corrected for the ROI volume at a voxel-level of   p  <0.05 and a cluster extent threshold of four voxels. The second analysis investigated responses across the whole brain at a threshold of   p  <0.001 uncorrected, with a cluster extent of four voxels. 



## Results 
  
fMRI adaptation was calculated by contrasting trained and untrained trials (untrained - trained). In Session 1, ‘trained’ trials were those in which the preceding event had been paired with the current event during training ( ). Thus, for a participant trained to associate ‘observe circle’ with ‘execute point’, a trained trial would consist of either observation of a circle preceded by execution of a point action, or execution of a point action preceded by observation of a circle. In ‘untrained’ trials the previous and current events had not been paired (e.g. observation of a circle following execution of a ‘fist’ action). Adaptation from shape observation to action execution, or vice versa, would indicate that as a result of training, neuronal populations responsive to action execution are also responsive to shape observation. An adaptation effect surviving family-wise error correction (FWE) was found within the PMv ROI, with a peak at  ,  ,  ,   t   = 4.5,   p  <0.05 FWE (see  ). In Session 1 there were no voxels surviving FWE correction within the Parietal ROI, but there was a cluster at   p  <0.001 uncorrected, with a peak at [54,−28,22]. Peak voxels demonstrating a main effect of adaptation are reported in  . 
   Statistical parametric maps (SPM) of the main effects of adaptation in Session 1.  
The SPM is thresholded for display at   p  <0.001 uncorrected with a cluster extent of 4 voxels. Results are rendered upon the smoothed average brain provided in SPM8. 
     All peak coordinates for the main effect of adaptation in Session 1, at   p  <0.001 uncorrected, with a cluster extent of four voxels.        
In Session 2, shape observation alternated with action observation. Thus ‘trained’ trials ( ) were those in which, if training induced   mirror   representations to respond to arbitrary shapes, both the preceding and current events should activate a neuronal population coding the same motor representation. ‘Untrained’ trials were those in which the preceding and current events were not predicted to share a motor representation. Adaptation from shape observation to action observation, or vice versa, would therefore indicate that as a result of training, shape observation activates a neural population responsive to observation and execution of the same action: that is, a population of neurons with mirror properties. Adaptation effects were observed both within the PMv (peak at  ,  ,  ,   t   = 4.4,   p  <0.05 FWE) and Parietal (peak at [−54,−36,30],   t   = 4.2,   p  <0.05 FWE) ROIs (see  ). Additionally, there was a right parietal adaptation effect at   p  <0.001 uncorrected, with a peak at [54,−44,38]. Peak voxels demonstrating a main effect of adaptation in Session 2 are reported in  . 
   Statistical parametric maps (SPM) of the main effects of adaptation in Session 2.  
The SPM is thresholded for display at   p  <0.001 uncorrected with a cluster extent of 4 voxels. Results are rendered upon the smoothed average brain provided in SPM8. 
     All peak coordinates for the main effect of adaptation in Session 2, at   p  <0.001 uncorrected, with a cluster extent of four voxels.        
We also investigated whether adaptation interacted with any of the other variables (Inter Stimulus Interval (ISI), Session Half, or Transition Type). In Session 1, we found an area where adaptation was modulated by ISI within the PMv ROI, at two peak coordinates ([−58,8,26],   t   = 4.4,   p  <0.05 FWE; [−62,4,22],   t   = 4.1,   p  <0.05 FWE). At these coordinates, the adaptation effect was greater at short ISIs. Previous studies have also found greater adaptation effects at shorter ISIs  ,  , suggesting that adaptation effects within certain regions, including left PMv, may be short-lived. There were no areas within the Parietal ROI in Session 1, or in either ROI in Session 2, where adaptation was modulated by ISI, Transition Type or Session Half. 


## Discussion 
  
The present experiment set out to test a specific prediction of the associative account of the development of mirror neurons: If mirror neurons acquire their properties through domain general processes of sensorimotor learning, it should be possible for human mirror neurons to respond to arbitrary non-action stimuli following exposure to appropriate sensorimotor contingencies. While a test of this hypothesis would ideally involve single-cell recording in humans, due to the difficulties in obtaining these data the present study utilised fMRI adaptation in order to record the BOLD signal from populations of neurons with properties consistent with mirror neurons. To test the associative hypothesis, participants were trained to execute different responses (point, splay fingers, make fist, extend thumb) to the onset of different geometric shapes (green circle, red square, yellow hexagon, blue triangle). After training participants completed two scanning sessions where the observation of either shapes or actions alternated with action execution (Session 1) or where observation of shapes alternated with observation of actions (Session 2). This procedure, particularly the inclusion of Session 2, allowed us to use the fMRI adaptation technique to provide evidence of the activation of populations of neurons with mirror properties. 

The results confirmed the prediction of the associative account. When shape observation alternated with action execution (Session 1), adaptation was observed in PMv: for both shapes and actions, the BOLD signal associated with an event was lower when that event was preceded by an event with which it had been paired during training than when it followed an untrained event. PMv is an area in which mirror neurons have been found in the macaque  ,  , and where adaptation effects indicative of populations of neurons with mirror properties have been found when humans observe and execute similar actions  ,  . Therefore, consistent with the associative account of the development of mirror neurons  ,  , the findings from Session 1 suggest that the sensorimotor training at the beginning of the experiment strengthened connections between visual neurons coding the colour and/or shape of geometric stimuli and neurons in a classical mirror area encoding the motor properties of action. 

The above interpretation of the results of Session 1 is supported and strengthened by the findings from Session 2: When observation of shapes alternated with observation of actions, we found an adaptation effect in PMv and in another classical mirror area, IPL  ,  . For both shapes and actions, the BOLD signal associated with observing an event was lower when that event was preceded by observation of an event with which it shared a motor representation, through training, than when it was preceded by observation of an event with which it did not share a motor representation. Even without data from Session 1, these results provide evidence that training induced populations of neurons with mirror properties, rather than any other population, to respond to geometric shapes. The adaptation effects seen in Session 2 show that common neural populations were coding the visual properties of the actions used during training and also the shapes. These populations could not have acquired the capacity to map visual properties of the shapes onto visual properties of the actions during training, because participants were not allowed to see their own actions at any stage in the experiment. Therefore, the adaptation effect in Session 2 implies that the sensorimotor training at the beginning of the experiment induced mirror representations – populations of neurons in the PMv and IPL that were already coding both observation and execution of similar actions – to respond to arbitrary geometric shapes. 

These results are consistent with research showing that activation in mirror areas varies with expertise   and training  ,  , and with previous reports that sensorimotor learning can induce  ,  , enhance  , abolish  ,  ,  ,  ,   and even reverse  ,  ,   ‘mirror effects’, i.e. effects of action observation on overt behaviour, motor evoked potentials (MEPs), and BOLD responses in mirror areas. For example, Catmur et al.   showed that sensorimotor training can reverse a ‘Fadiga effect’   in which transcranial magnetic stimulation (TMS)-induced MEPs are larger in the index finger muscle when observing index finger than little finger actions, and larger in the little finger when observing little finger than index finger actions. After incompatible sensorimotor training, in which participants executed little finger actions when observing index finger actions, and vice versa, observation of index finger actions induced greater MEPs in little finger muscles, and observation of little finger actions induced greater MEPs in index finger muscles. Indeed, in a closely-related study Petroni et al.   found that, following training where an arbitrary shape cue was paired with an action, passive observation of the shape cue activated motor representations of action, presumably via mirror areas. Evidence of plasticity observed in previous studies of expertise and sensorimotor training, and in the present study, accords with the predictions of the associative hypothesis  ,  . Moreover, the present findings contribute to growing evidence that the effects of sensorimotor training modulate mirror effects by modifying mirror representations in classical mirror areas  ,  . 

Contrary to the view that mirror neurons were specifically designed   or ‘canalised’   by genetic evolution to mirror observed actions, the associative account implies that there is nothing intrinsically ‘mirror’ about mirror neurons. The associative account predicts that sensorimotor learning can readily cause populations of motor neurons, responsible for the performance of both transitive and intransitive actions  , to become associated with the observation of similar actions (strictly and broadly congruent mirror neurons  ), dissimilar observed actions (logically related mirror neurons  ), actions performed with tools (tool-use mirror neurons  ), characteristic action sounds (audiovisual mirror neurons  ), and action-appropriate objects (canonical neurons  ). For example, audiovisual mirror neurons respond to action sounds such as plastic crumpling and metal striking metal  . Under the associative account, these cells acquire their properties through experience of performing actions while hearing these sounds, but are harder to accord with evolutionary hypotheses  . The present study confirms that geometric shapes - a class of arbitrary non-action stimuli that have neither the morphological or dynamic properties characteristic of body movements - should be included in the list of sensory stimuli that can elicit excitation of populations of cells with mirror properties following contingent sensorimotor experience. The present findings suggest that differences in response patterns among these different neurons (broadly and strictly congruent mirror neurons, logically-related mirror neurons, tool-use mirror neurons, audiovisual mirror neurons, canonical neurons, geometric-shape mirror neurons) may not reflect different cell types, but rather the fact that motor neurons may become associated with different eliciting stimuli. Consequently, the particular ‘class’ of observed stimuli that causes the cell to fire may not be a normative, intrinsic property of the cell itself, but may instead be a consequence of the individual’s learning history  ,  . 

An alternative interpretation of the present data could be advanced whereby the matching property of mirror representations has been designed by evolution to promote action understanding or social interaction, but these representations will additionally encode arbitrary stimuli following appropriate learning. There are at least two versions of this hypothesis. First, mirror representations are present at birth  , but these representations are not buffered against becoming responsive to other stimuli through learning. Second, the development of mirror representations may be incompletely canalised, such that these representations are acquired more readily in this population of cells, but not to the exclusion of other response properties. These hybrid models, along with a wide range of additional recent hybrids, represent interesting potential advances on the two accounts contrasted historically and in the present study, but there is currently no independent data to support them. 

fMRI adaptation effects provide evidence that common neural populations code both events  ,  . However, the neural mechanism underlying BOLD adaptation at the single-cell level is a topic of debate. While it may reflect reduced firing rate of single cells, it may also reflect firing of fewer cells, or faster, more efficient, processing of the stimulus and its ‘downstream’ effects (the ‘facilitation model’,  ,  ). Here, we have used BOLD adaptation solely as an index of neural specialisation, i.e. to identify the presence of a common neural population encoding actions and events with which they have been paired in training, rather than to investigate the mechanism by which that reduction occurs (see also  ). Therefore, the interpretation of our BOLD adaptation results is appropriate irrespective of whether individual mirror neurons show reduced firing rates with repeated stimulus presentation. 

### Alternative Accounts 
  
We have argued that the sensorimotor training completed before the scanning session induced associations between sensory populations of neurons encoding geometric shapes, and populations of neurons with mirror properties which were already responsive to the observation and execution of actions. In this section, we will consider a number of alternative accounts, and explain why we believe these to be unlikely explanations of our findings. 

First, rather than reflect novel   sensorimotor   associations, it could be argued that the observed adaptation effects could be caused by associations between the sensory descriptions of shapes and actions. Such   sensory-sensory   associations might allow shape observation to activate motor representations (Session 1) indirectly, via sensory representations of action, and sensory descriptions of action (Session 2) directly. However, this account is unlikely. Crucially, participants’ hands were occluded from view throughout both training and scanning phases. Consequently the sensory descriptions of the shapes and actions were never paired (i.e. temporally contiguous and contingent), thus the necessary conditions for sensory-sensory associative learning were not met. A related alternative account might hold that if participants imagined the sensory consequences of their actions during training   this may have yielded enough pairings to produce weak sensory-sensory associations. However, for either of these alternative accounts to be true, it would have to be the case that execution of the action caused the sensory description of that action to be activated. Thus, the sensory description of the shape would activate populations of neurons coding for both action execution and the sensory description of that action i.e. populations of neurons coding for mirror representations. 

Second, classical mirror areas do not only contain mirror representations of action; they also contain substantial populations of canonical neurons  ,  , thought to mediate object affordances. Could the adaptation effects observed be the product of canonical populations acquired long before the experiment? While geometric shapes lack the three-dimensional properties of the objects on which transitive actions are typically performed, it is possible that geometric shapes prime object properties – for example, a circle may activate neurons sensitive to the properties of spheres. However, this account is also implausible. Our training regime paired actions with shapes in a way that was both arbitrary with respect to any priming of this sort, and different between participants. For example, the observation of a circle (or sphere) no more ‘affords’ pointing than the observation of a square (or block), and does not do so more for the participants trained with this pair compared to those trained with the circle-splay finger pairing. The reliable motor activations during shape observation, seen in both sessions, are therefore unlikely to be the product of canonical neurons shaped before the experiment. Moreover, populations of canonical neurons could not produce the adaptation seen in Session 2 to the alternating observation of shapes and actions, as canonical neurons, by definition, are not responsive to the sight of actions. 

Third, it has been well-established using behavioural   and neurophysiological methods  ,   that both human and non-human animals show associative learning when they experience a contiguous and contingent relationship between an arbitrary stimulus and a motor response. It could be argued that the adaptation effects seen in Session 1 are the product of novel stimulus-response associations between the sensory representations of the geometric shapes and purely motor (i.e. non-mirror) representations. However, the results of Session 2 cannot be explained by this type of learning. Crucially, in Session 2, common motor populations were excited by both shape and action observation. This finding demonstrates that shapes were associated with motor populations that were already responsive to the sight of the same actions; i.e. mirror representations of action. Interestingly, previous research has found effects of associative learning in dorsal premotor cortex (PMd)  ,  , whereas mirror neurons have been found in the monkey PMv. However, the results of the present study, together with the results of Cisek and Kalaska   who found neurons with mirror properties in PMd, indicate that the loci of mirror representations and of training effects are not, in fact, dissociable (see also  ). 

Fourth, could the adaptation effects observed be due to adaptation of neurons coding for verbal or semantic representations of action, rather than populations of neurons with mirror representations? Such representations are thought to depend on regions of IFG  ,  . Under this interpretation, shapes become associated not with mirror representations but with verbal or semantic representations of the trained actions. Thereafter, neural populations encoding semantic or verbal descriptions of action may be excited both during observation and performance, via pre-experimental learning, and also during the observation of shapes, through associations acquired during training. However, if a population of neurons fires during the execution and observation of the same action - as is required in order to explain the adaptation in Session 2 - then that population meets the functional definition of a mirror representation, irrespective of whether that population also responds to verbal descriptions/semantic representations of actions. A ‘semantic account’ is therefore an extension of, and perfectly compatible with, the idea that the properties of mirror representations have been changed by training. Elucidating the nature of the information encoded by populations of neurons firing during observation and execution of action in different regions is a research aim common to all those researching the functions and origins of the human mirror system (e.g.  ). However, the observation that regions containing mirror neurons are considered to be the same as those involved in language processing is precisely what has prompted some authors to speculate that mirroring and language processes are closely related  . 

In conclusion, the results of the present study is consistent with the idea that mirror neurons are not ‘specialists’; i.e. they have not been shaped by evolution   or ‘canalised’   to respond in a mirror fashion to biological actions. One would expect the development of an adaptation to be buffered against such short-lived variations in the environment  ,  ,  . In contrast, evidence that populations of cells with mirror properties can become responsive to static, non-biological stimuli after a relatively short training period supports the associative account of the origin of mirror neurons. This account proposes that the development of mirror neurons is mediated by stimulus-general processes of learning within a system that is adapted for basic visuomotor control. Under this account, mirror neurons may contribute to social interaction, but they are not specialised for this role. 


 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-75'>
<h2>75. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/21709175/' target='_blank'>21709175</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Direction-Sensitive Codes for Observed Head Turns in Human Superior Temporal Sulcus</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> Cereb Cortex</p>
<p><strong>Publication Year:</strong> 2011</p>
<p><strong>DOI:</strong> 10.1093/cercor/bhr061</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/3306570/' target='_blank'>3306570</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> This study reports fMRI in healthy adult participants (N=21 initial, final sample within age range 22–38) performing a social-related task (perception of others’ head turns, a social attention/gaze processing paradigm). The analysis includes both hypothesis-driven ROI MVPA and exploratory whole-brain analyses (full gray-matter volume and whole-brain univariate results are reported), so results are not limited to ROI-only. Participants were healthy and results for healthy participants are reported separately. Therefore it meets all inclusion criteria (social fMRI task; healthy adults 17–65; whole-brain analyses reported). No exclusion criteria are met.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Humans and other primates are adept at using the direction of another's gaze or head turn to infer where that individual is attending. Research in macaque neurophysiology suggests that anterior superior temporal sulcus (STS) contains a direction-sensitive code for such social attention cues. By contrast, most human functional Magnetic resonance imaging (fMRI) studies report that posterior STS is responsive to social attention cues. It is unclear whether this functional discrepancy is caused by a species difference or by experimental design differences. Furthermore, social attention cues are dynamic in naturalistic social interaction, but most studies to date have been restricted to static displays. In order to address these issues, we used multivariate pattern analysis of fMRI data to test whether response patterns in human right STS distinguish between leftward and rightward dynamic head turns. Such head turn discrimination was observed in right anterior STS/superior temporal gyrus (STG). Response patterns in this region were also significantly more discriminable for head turn direction than for rotation direction in physically matched ellipsoid control stimuli. Our findings suggest a role for right anterior STS/STG in coding the direction of motion in dynamic social attention cues. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (44493 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
  
Humans and other primates share a remarkable ability to accurately perceive where other individuals are attending and use this information to change their own attentional state ( ). Many higher order social cognitive processes depend on such gaze following behaviors ( ;  ). Although changes to gaze direction and head view are inherently dynamic, to date the majority of human neuroimaging research has used static facial stimuli to study the neural representation of such social cues ( ). In view of macaque neurophysiology evidence that neurons responsive to dynamic head turns do not respond to static views of the same head ( ), it is vital to explore the neural coding of dynamic social stimuli. Here, we demonstrate that a region in human superior temporal sulcus (STS)/superior temporal gyrus (STG) contains a distributed representation of perceived head turn direction, thus supplying a necessary perceptual component to support a range of social behaviors. 

Neurons in macaque anterior STS play a well-established role in representing the perceived direction of others' social attention cues, as conveyed by head orientation, gaze direction, and body posture ( ,  ;  ;  ). However, these constitute only a minority of visually responsive STS neurons and are either spatially distributed ( ) or are organized into fine-grained patches well beyond the resolution of conventional functional MRI (fMRI;  ). This distributed representation poses a significant signal-to-noise challenge for attempts to study similar effects with human fMRI, where each voxel likely samples millions of neurons in ways that are only indirectly related to the neuronal spike trains commonly measured in macaque neurophysiology ( ;  ). 

Unlike the typical anterior STS region identified by research in the macaque, most human fMRI studies report that social attention cues activate posterior STS and regions of adjacent STG and middle temporal gyrus (MTG;  ;  ). Similar posterior temporal regions are also more responsive to faces than to control stimuli ( ;  ). Most of these studies find that posterior STS is more responsive to averted than to direct gaze ( ), but the opposite pattern has also been observed (e.g.,  ;  ). Furthermore, posterior STS responds more when an actor gazes away from a target than when the gaze direction is congruent with the target location ( ), suggesting that posterior STS is influenced by contextual effects, rather than by the direction of the social attention cue as such. Even in the absence of overt contextual manipulations, comparisons between direct and averted gaze may indirectly manipulate the engagement of approach/avoidance mechanisms and other higher order social cognitive functions associated with direct and averted gaze, such as theory of mind responses to eye contact ( ;  ;  ). Thus, the litmus test for direction sensitivity is whether brain responses to different averted social attention cues can be distinguished in the absence of other contextual manipulations. 

When such tests for direction sensitivity between different averted cues were carried out, one study found direction-sensitive fMRI adaptation to static images of gaze cues in right anterior, rather than posterior, STS ( ). Another study that applied multivariate pattern analysis (MVPA) to a posterior STS region of interest (ROI) observed no distinction between different averted views of static heads ( ) but did find that this ROI distinguished direct from averted head views across different head identities, suggesting an identity-invariant representation. These head view effects are consistent with the pattern of univariate sensitivity for direct against averted gaze observed in previous univariate research ( ). Considered collectively, this literature suggests a broad role for posterior STS in representing social attention cues, but unlike the evidence from macaque anterior STS, there is little indication that posterior STS represents such cues in a direction-sensitive manner. 

Outside the laboratory, cues to another's focus of attention are intrinsically dynamic in nature, but this issue has received limited attention in controlled experiments. There is initial evidence that a small subset of neurons in macaque anterior STS are tuned to dynamic changes in head turn direction ( ;  ), but it remains unclear how the human brain codes such stimuli. In humans, posterior STS responds more to dynamic head turns than to both scrambled controls and static head views. However, neither anterior nor posterior STS has been found to show direction-sensitive coding of head turn direction, as measured by standard univariate fMRI ( ). This absence of direction sensitivity is unsurprising, since neurons with such responses are unlikely to be clustered at a sufficiently large spatial scale to be detectable with univariate fMRI ( ;  ). 

MVPA has recently been applied to detect representations thought to be coded in fine-grained patterns beyond the resolution of standard fMRI ( ;  ;  ). In the current study, we apply this method to determine whether distributed response patterns in the human STS region contain distinct direction-sensitive codes for observed head turns. If a classifier can use response patterns from the STS region to distinguish between leftward and rightward head turns, this would suggest that the underlying response patterns code head turn direction. However, leftward and rightward motion can also produce classification effects in regions without selectivity for social attention cues ( ). In order to avoid such confounding contributions of low-level motion, we included a set of rotating ellipsoid control videos. Previous work investigating head turn responses in macaque neurophysiology ( ;  ) or direction-specific responses to static gaze ( ) did not include such nonsocial controls, so an important aim of the current study was to establish that any direction-sensitive effects are specific to the social stimuli. Furthermore, we aimed to localize pattern effects to specific regions through the use of a searchlight algorithm that operated within the anatomically defined STS region. The STS region in this study included STG and MTG, in line with previous findings that social perception and gaze stimuli produce peaks that sometimes fall outside the STS proper ( ;  ). 


## Materials and Methods 
  
### Participants 
  
Twenty-one right-handed healthy volunteers with normal or corrected to normal vision participated in the study (12 males, mean age 29 years, age range 22–38). Volunteers provided informed consent as part of a protocol approved by the Cambridge Psychology Research Ethics Committee. Four volunteers were removed from further analysis: Two due to poor performance at the behavioral task whilst in the scanner (accuracy of less than 50%) and 2 due to fatigue and excessive head movements. 


### Experimental Design 
  
Volunteers viewed 1000-ms video clips of 45° leftward and rightward head turns and comparable ellipsoid rotations ( ; e.g., videos, see   Supplementary Material  ). Volunteers were instructed to monitor the stimulus set for infrequent deviant response trials (1 of the 8 experimental videos, rotated 4° from the upright position) and responded to detected deviants with a button press. The deviant response trials were drawn from all experimental conditions, and the degree of rotation was chosen after behavioral pilot tests to produce an attentionally demanding task without ceiling effects. 
  
Example video frames for turning heads (  A  –  B  ) and rotating ellipsoids (  C  –  D  ). The stimuli were full color but are presented in grayscale for printing purposes (for full color stimuli, see   Supplementary Videos  ). The videos were presented at 24 frames per second. All video frames are from leftward motion conditions. Rightward conditions were created through mirror reversal of the same video clips. The 2 ellipsoid identities (  C  –  D  ) were created by Fourier-scrambling face textures from the first frame of the 2 head videos (  A  –  B  ). 
  
Two actors with matched head motion patterns were selected for the head turn videos. The ellipsoid control stimuli were rendered and animated in Matlab (Mathworks) and were texture mapped with the Fourier-scrambled face textures from the 2 head identities. The 2 motion directions were created by mirror reversing video clips with a single direction, thus ensuring that the stimulus set was physically matched across motion directions. This produced a total of 8 stimuli (2 heads, 2 ellipsoids, each rotating leftward or rightward), which were treated as individual conditions. 

The stimuli were back-projected onto a screen in the scanner, which volunteers viewed via a tilted mirror. The stimuli were presented on a black background within a circular aperture (7° visual angle in diameter). The experiment was controlled using Matlab and the Psychophysics toolbox ( ). 

The experiment was divided into sets of 240 trials, each of which was independently randomized. Parameter estimates from each set formed an independent set of training examples for classification. The trials were presented within a rapid event-related design. Four volunteers completed a 6-set version of the experiment (approximately 40 min effective time) and 13 completed a 12-set version (80 min). Each set contained 240 trials: 80 null trials, where a fixation cross remained on the screen throughout the trial (1500 ms) and 160 experimental trials (80 heads, 80 ellipsoids), where each trial consisted of a video clip (1000 ms) followed by fixation (500 ms). Each condition was repeated 18 times in a set. Sixteen deviant response trials were randomly sampled from the experimental conditions and responses to these trials were modeled with a separate nuisance regressor of no interest. The trials within the set were presented in a pseudorandomized order, where repeats of the same trial were slightly clustered in order to increase design efficiency ( ). Every second set was followed by a 15-s rest period, which was cued by a text prompt on the screen. The scan acquisition continued during the rest periods, and volunteers were instructed to remain still. 


### Imaging Acquisition 
  
Scanning was carried out at the MRC Cognition and Brain Sciences Unit, Cambridge, United Kingdom, using a 3-T TIM Trio Magnetic Resonance Imaging scanner (Siemens), with a head coil gradient set. Functional data were collected using high-resolution echo planar   T  -weighted imaging (EPI, 40 oblique axial slices, time repetition [TR] 2490 ms, time echo [TE] 30 ms, in-plane resolution 2 × 2 mm, slice thickness 2 mm plus a 25% slice gap, 192 × 192 mm field of view). The acquisition window was tilted up approximately 30° from the horizontal plane to provide complete coverage of the occipital and temporal lobes. Preliminary pilot tests suggested that the use of this high-resolution EPI sequence resulted in reduced signal dropout in the anterior STS region, relative to a standard resolution sequence (3 × 3 × 3.75 mm voxels). All volumes were collected in a single continuous run for each volunteer. The initial 6 volumes from each run were discarded to allow for   T   equilibration effects.   T  -weighted structural images were also acquired (magnetization prepared rapid gradient echo, 1 mm isotropic voxels). 


### Imaging Analysis 
  
Imaging data were processed using statistical parametric mapping 5 (SPM5;   www.fil.ion.ucl.ac.uk/spm  ). All functional volumes were realigned to the first nondiscarded volume, slice time corrected, and coregistered to the   T   structural volume. The processing pathways for univariate analysis and MVPA diverged after these common steps ( ). 
  
Processing pathways for fMRI analysis. All processing nodes take the result of the previous node in the hierarchy as input. With the exception of the searchlight classification analysis, all processing steps were implemented using standard SPM5 functionality. 
  
Univariate analysis was carried out using standard processing steps in SPM5. Structural volumes were segmented into gray and white matter partitions and spatially normalized to the Montreal Neurological Institute (MNI) template using combined segmentation and normalization routines. Functional volumes were normalized according to the parameters of this transformation, smoothed (10-mm full width at half mean Gaussian kernel, FWHM), and high pass filtered to remove low frequency drift (128-s cutoff period). 

Subject-specific generalized linear models were used to analyze the data. The models included one regressor per condition and nuisance regressors for deviant response trials, volunteer responses to nondeviant trials, and for nulling scans that contained excessive noise or movement ( ;  ; greater than 10 units intensity difference from the mean scaled image variance or more than 0.3 mm translational or 0.035 radians rotational movement relative to the previous volume). The volunteer-specific models included 0–135 such scan nulling regressors (mean 35). The experimental predictors were convolved with a canonical hemodynamic response function, and contrast images were generated based on the fitted responses. These contrast images were then entered into second-level permutation-based random effects models using statistical nonparametric mapping (SnPM;  ; 10 000 permutations, 10-mm FWHM variance smoothing). 

Multivariate pattern analyses were carried out using functional volumes that had been realigned and slice timing corrected but had not been spatially normalized to the MNI template ( ). Each volunteer's data were modeled using a generalized linear model with similar regressors as in the univariate analysis, with the exception that each set of trials was modeled using a separate set of regressors. Individual parameter volumes from the first half of the data set was then averaged pairwise with the corresponding volume from the second half of the data set, thus reducing session effects at the expense of halving the number of training examples. This produced 3 or 6 final sets of examples to be used for classification, depending on the number of available sets before averaging. The example volumes were   z  -scored so that each voxel within a set had a mean of 0 and a standard deviation of 1 across examples in that set. Finally, each example was gray matter masked using the tissue probability maps generated by the segmentation processing stage. 

The resulting example volumes were used as input to a linear support vector machine classifier (as implemented in PyMVPA;  ). All MVPA used a searchlight algorithm ( ), in which classification is carried out within a spherical region (5 mm radius) that is moved through the volume. Leave-one-out cross-validated classification accuracy estimates (percent correct) were mapped back to the center of each searchlight, thus producing a classification accuracy map. 

The classification accuracy maps for each volunteer were normalized to MNI space, smoothed (10-mm FWHM), and entered into second-level nonparametric random effects models in SnPM. We used nonparametric tests because the discontinuous nature of the gray matter–masked data means that conventional familywise error (FWE) correction for multiple comparisons using random field theory in SPM5 would be inappropriate. We also wished to avoid making distributional assumptions about the first-level classification accuracy maps. 

In line with the hypothesized site of our effects, we restricted our primary analysis to the right STS region, which was defined anatomically by the first author based on the mean   T   volume for the sample. In line with previous evidence that social perception and eye gaze effects in the STS region extend into STG and MTG ( ;  ), the mask included these gyri, whilst leaving out voxels in inferior temporal sulcus (inferior) or lateral fissure (superior) (  Supplementary Fig. 1  ). We report   P   values corrected for multiple comparisons (FWE,   P   < 0.05) within this ROI (5162 voxels,   y   −58 to 22 mm MNI). We also carried out an exploratory analysis in a mirror-reversed version of the STS mask to test for effects in left STS. The use of a mirror-reversed mask sacrifices some anatomical precision in left STS but preserves the same voxel count and spatial structure in both masks. Visual inspection of the relation between the left STS mask and the mean   T   volume suggested that the mask followed the anatomy of the sulcus in a comparable manner to the right STS mask. Finally, effects that survived correction for the full volume are also reported (FWE,   P   < 0.05). All analyses were restricted to a group gray matter mask, which was formed by the union of each volunteer's normalized individual gray matter mask. This mask ensured that we only considered effects in regions actually covered by the searchlight analysis. 



## Results 
  
### Behavioral Task 
  
Volunteers were asked to detect the occasional 4° rotation of the video stimuli and were able to detect such deviant response trials adequately (mean accuracy 71%, standard error 4%). A repeated measures analysis of variance (ANOVA) of accuracy scores with the factors of stimulus type (head, ellipsoid) and motion direction (leftward, rightward) yielded no main effects and no interaction (  F   < 2.4,   P   > 0.14 for all effects), suggesting that volunteers did not assign attention differently to the heads and ellipsoids or to the 2 motion directions. 


### Multivariate Pattern Analysis 
  
#### Superior Temporal Sulcus 
  
Our primary hypothesis was that the right anterior STS region distinguishes between leftward and rightward perceived head turns. In line with this prediction, a group analysis of the MVPA searchlight results for the right STS region showed that classification of head turn direction was significantly more accurate than expected by chance in a right anterior STS/STG site (  P   = 0.005 FWE, 50 4 −14 mm MNI,  ; for individual subject results, see   Supplementary Fig. 2  ). By comparison, left–right classification of rotation direction in the ellipsoid control stimuli exceeded chance in middle STS (  P   = 0.037 FWE, 50 −14 −10 mm MNI,  ). 
  
Group results for MVPA, displayed on the mean   T   volume for the sample. Effects are displayed corrected for multiple comparisons within the right STS region (panels   A  –  C  ; hypothesis-driven analysis,   P   < 0.05 FWE) or the full gray matter volume (panels   D  –  F  ; exploratory analysis,   P   < 0.05 FWE). The highlighted portion of each panel shows the extent of the mask. (  A  ) Classification of left–right head turns in the right STS/STG region. (  B  ) Classification of left–right ellipsoid rotations in the right STS region. (  C  ) Right STS regions where left–right classification of head turns was more accurate than classification of ellipsoid rotations. (  D  ) Classification of left–right head turns in the full gray matter volume. (  E  ): Gray matter regions where left–right classification of head turns was more accurate than classification of ellipsoid rotations. (  F  ) Gray matter regions where the weights acquired by training the classifier on left–right head turns for one head identity generalized to left–right head turns in the other head identity. 
  
The peaks of these head turn and ellipsoid rotation effects were approximately 18 mm apart and the activated regions did not overlap, which raises the question of how distinct the 2 effects are. We addressed this by computing the difference between the classification maps for head turn and ellipsoid rotation in each volunteer. These difference maps were entered into a group analysis, which showed that left–right classification was more accurate for head turns than for ellipsoid rotations in right anterior STS/STG (  P   = 0.027 FWE, 52 12 −12 mm MNI,  ). This effect overlapped with the head turn classification effect (8 mm distance between peaks, 40% overlap), suggesting a common origin. No STS region showed significantly more accurate direction classification for ellipsoid rotations than for head turns. 

We tested whether the left–right head turn codes were invariant to head identity by training the classifier on the left–right turns of one head and applying the learned weights to left–right turns of the other head. Left–right classification did not generalize across head identity at any site in right STS. Similarly, there was no significant left–right generalization across ellipsoid identities and no left–right generalization across stimulus type (head and ellipsoid). 

We also carried out an exploratory analysis of effects in the left anatomically defined STS region. No left STS regions showed above-chance classification of observed head turn direction. However, a region in left anterior STS distinguished ellipsoid rotation direction with above-chance accuracy (  P   = 0.01 FWE, −56 −8 −16 mm MNI,   Supplementary Fig. 3  A   ). Direction classification accuracy was significantly higher for ellipsoid rotation than for head turns in a similar region (  P   = 0.041 FWE, −58 −4 −16 mm MNI,   Supplementary Fig. 3  B   ). No other classification effects were significant in this ROI. 


#### Whole-Brain Analysis 
  
Beyond our hypothesis-driven search within the anatomically defined right STS region, we also carried out an exploratory analysis within the full gray matter–masked volume to identify other effects of interest. Classification of left–right head turns exceeded chance in a region including calcarine sulcus and occipital pole (  P   < 0.001 FWE, 16 −96 0 mm MNI,  ). This region is likely to include visual areas V1, V2, and V3, but in the absence of a retinotopic localizer, we use the general term early visual cortex to describe this region. Left–right ellipsoid classification did not produce significant effects in any region. Left–right classification was significantly more accurate for head turns than for ellipsoid rotations in a similar early visual region (  P   < 0.001 FWE, 14 −96 2 mm MNI,  ). A similar region in early visual cortex also allowed left–right classification to generalize across head identities (  P   < 0.001 FWE, 14 −96 2 mm MNI,  ) but not across stimulus types. No regions outside of early visual cortex showed significant effects for any of these comparisons. 



### Univariate Analysis 
  
We used a conventional univariate analysis in SPM5 to address whether the observed classification effects could be attributed to large-scale response level differences between the conditions. To make comparisons between MVPA and univariate results simpler, the univariate analysis also used nonparametric permutation-based random effects analysis of group effects (SnPM, for details, see Materials and Methods). We also explored whether direction classification of head turns colocalized with greater univariate responses to heads than to ellipsoids. 

#### Superior Temporal Sulcus 
  
No regions inside the anatomically defined right STS ROI responded selectively to one head turn direction over the other or to one ellipsoid rotation direction over the other, suggesting that the left–right classification effects in this region did not co-occur with large-scale univariate direction sensitivity. 

Collapsing across motion direction, right posterior STS responded significantly more to heads than to ellipsoids (  P   < 0.002 FWE, 48 −44 16 mm MNI,  ), while a region in middle STG bordering on the edge of the ROI responded more to ellipsoids than to heads (  P   = 0.004 FWE, 60 0 0 mm MNI,  ). Thus, univariate selectivity for heads over ellipsoids occurred in posterior STS, 57 mm from the left–right head turn classification peak in anterior STS/STG. The peaks for univariate selectivity for ellipsoids over heads and for left–right ellipsoid rotation classification were separated by 20 mm. Neither of the univariate effects overlapped with the classification effects. 
  
Group results for the univariate analysis, displayed on the mean   T   volume for the sample. Effects are displayed corrected for multiple comparisons within the right STS region (panels   A  –  B  ; hypothesis-driven analysis,   P   < 0.05 FWE) or the full gray matter volume (panels   C  –  D  ; exploratory analysis,   P   < 0.05 FWE). The highlighted portion of each panel shows the extent of the mask. (  A  ) Greater univariate responses to heads than to ellipsoids in the right STS region. (  B  ) Greater univariate responses to ellipsoids than to heads in the right STS region. (  C  ) Gray matter regions with greater univariate responses to left than to right head turns (warm colors) or with greater univariate responses to right than to left head turns (cool colors). The effects do not overlap at any site. (  D  ) Gray matter regions with greater univariate responses to heads than to ellipsoids. 
  
Within the left STS ROI, a posterior region responded more to heads than to ellipsoids (  P   = 0.004 FWE, −52 −58 14 mm MNI,   Supplementary Fig. 3  C   ) and left middle STS responded more to ellipsoids than to heads (  P   = 0.014, −66 −18 −14 mm MNI,   Supplementary Fig. 3  D   ), mirroring the results obtained in the right STS region. No left STS regions responded preferentially to head turn or ellipsoid rotation in one direction relative to another. No other comparisons reported above were significant in the left STS analysis. 


#### Whole-Brain Analysis 
  
A univariate analysis of the gray matter–masked full volume revealed significant univariate selectivity for left over right head turns that was restricted to left early visual cortex (  P   < 0.001 FWE, −12 −94 0 mm MNI), and conversely, selectivity for right over left head turns restricted to right early visual cortex (  P   < 0.001 FWE, 14 −92 4 mm MNI,  ). These effects almost completely overlapped the left–right head turn classification effect in early visual cortex (100% overlap for left over right, 91% overlap for right over left), suggesting that the classification effects co-occurred with large-scale univariate effects. Note that the laterality of these early visual effects is opposite to what would be expected for a stimulus that moves into the right and left visual hemifields, a point we return to below. No regions showed a preference for one ellipsoid rotation direction over the other in the whole-brain analysis. 

A comparison of univariate responses to heads over ellipsoids and ellipsoids over heads revealed a network of activations (  Supplementary Table 1  ). Of primary interest to the current study, bilateral early visual cortex responded more to heads than to ellipsoids (  P   < 0.001 FWE, 18 −96 −4 mm MNI,  ), and this early visual effect overlapped the left–right head turn classification effect (91% overlap). Thus, the left–right head turn classification effects occurred in a region where we also observed univariate selectivity for head turn direction and preferential responses to heads over ellipsoids. Bilateral regions in posterior MTG also responded more to heads than to ellipsoids (right:   P   = 0.001 FWE, 52 −74 2 mm MNI. Left:   P   = 0.001 FWE, −50 −72 14 mm MNI). These coordinates are close to those previously reported for motion area MT ( ; conversion from Talairach to MNI coordinates with tools from  ). Because we did not include a specific localizer scan to distinguish MT from MST or other motion areas, we refer to this region as MT+. The MT+ regions showed no direction-sensitive responses in the univariate or classification analyses, even at reduced thresholds (  P   < 0.01, uncorrected). 



### Follow-up Experiments 
  
The pattern of univariate effects in early visual cortex suggested to us the presence of eye movements in the experiment. If volunteers tracked the heads as they turned, this would have placed the stimulus primarily in the hemifield ipsilateral to the direction of motion, which could explain the ipsilateral univariate activations in early visual cortex. Eye tracking was not available when the main experiment was undertaken, so we carried out follow-up eye tracking and fMRI experiments with 3 principal aims: First, to test whether the head turns used in the main experiment elicit eye movements; second, to assess whether the eye movement effects could be removed with a revised experimental paradigm; and finally, to test whether the fMRI effects reported in the main text remained in the absence of statistically significant eye movement effects. 


### Follow-up Materials and Methods 
  
Five volunteers from the final sample used in the main experiment returned to participate in additional experiments. Eye movements were monitored using a video-based infrared eye tracker (500 Hz acquisition outside the scanner, 50 Hz acquisition inside the scanner; Sensomotoric Instruments). We analyzed the change in horizontal fixation position at the end relative to the start of each trial using custom code developed in Matlab. 

Imaging data were acquired and analyzed using identical parameters as in the main experiment, with the exception that no averaging of the first and second half of the experiment was carried out, since this would have yielded an unacceptably small number of observations for first-level statistics. Furthermore, each set was scanned in a separate run to allow recalibration of the eye tracker between sets. As in the main fMRI experiment, we used a searchlight analysis. We based single-volunteer inference on binomial tests at each voxel in the ROI. 


### Follow-up Eye Tracking with the Original Design 
  
Five volunteers carried out an abbreviated version of the main experiment outside the scanner (3 sets, 540 trials), while their eye position was monitored. First-level ANOVAs revealed that each volunteer showed a significant stimulus type (head, ellipsoid) by motion direction (leftward, rightward) interaction (  Supplementary Table 2  ). This interaction reflected consistent fixation shifts in the direction of the head turns, with nonsignificant or weaker fixation shifts in the direction of the ellipsoid rotations. 


### Follow-up Eye Tracking with Revised Design 
  
We carried out a second eye tracking experiment with a revised paradigm that included a fixation cross during the presentation of the video clips. Volunteers were also strongly instructed to maintain fixation at all times. We included only the head turn conditions in order to obtain a maximal number of trials for the head left–right comparison whilst minimizing volunteer fatigue. In this second experiment, the head turn left–right eye movement effect was reduced to nonsignificance in 4 of 5 volunteers ( ). 
  
Follow-up eye tracking and fMRI experiments. (  A  –  C  ) Mean horizontal fixation change plotted separately for the 3 volunteers selected for the final analysis in the revised fMRI experiment. Positive values reflect a leftward shift in fixation over the trial, while negative values reflect a rightward shift. The horizontal axis gives fixation performance in the original task, the revised task, and the revised task as measured during the fMRI experiment. The error bars give ±1 standard error of the mean. Comparisons with significant differences between the head turn directions are highlighted by asterisks (  t  -tests,   P   < 0.05). It can be seen that the revised design abolished the eye movement effect in these volunteers. (  D  –  F  ) Left–right head turn classification results for the 3 volunteers in the final sample of the fMRI experiment. The volunteers are shown in the same order as in   A  –  C  . Results are overlaid on each volunteer's   T   volume and are masked to only include effects within the highlighted right STS region (  P   < 0.001, uncorrected). It can be seen that even in the absence of eye movement effects, anterior STS/STG codes head turn direction. (  G  –  I  ) Results as in   D  –  F   but masked to show effects within a 20 mm radius of the peak early visual head turn classification effect from the main study. It can be seen that the effects in early visual cortex also remain when eye movements are controlled. 
  

### Follow-up fMRI Experiment with Revised Design 
  
We tested whether our main classification findings in STS/STG and early visual cortex survived in the absence of eye movements by carrying out a second fMRI experiment with the revised experimental paradigm. We recruited the 4 volunteers who showed no significant eye movement effects in the eye tracking test outside the scanner. Volunteers completed a full 6-set version of the revised experiment (1080 trials, for details, see Material and Methods), while their eye position was monitored. One of the 4 scanned volunteers showed a significant fixation shift in response to the head turns whilst being scanned (  t   = 8.72,   P   = 0.003). This volunteer was removed from further analysis. 

Although the 3 remaining volunteers showed no significant eye movement effects (as observed in separate tests before and during scanning), left–right classification of head turns in the right anterior STS region was greater than chance in 2 volunteers (  P   < 0.05, Bonferroni FWE corrected for the right STS mask) and at reduced thresholds in the third (  P   < 0.001, uncorrected,  ). The final volunteer also showed an effect in posterior STS (  P   < 0.05, FWE). 

All 3 volunteers showed significant left–right head turn classification effects in early visual cortex (  P   < 0.05 Bonferroni FWE corrected for a 20 mm radius sphere centered on the peak head turn classification effect in the main experiment,  ). However, unlike the main experiment, where this effect was joined by univariate response preferences for head turns in a direction ipsilateral to the visual hemifield (  Supplementary Fig. 4  A   ), we now observed preferentially contralateral responses to head turn direction (  P   < 0.001, uncorrected,   Supplementary Fig. 4  B   ). Thus, although the classification effects in early visual cortex were accompanied by univariate effects also in the revised experiment, laterality of these univariate effects was reversed. 



## Discussion 
  
Appropriate social behavior is dependent on accurately inferring where others are attending. In the visual domain, this inferential process is likely to involve direction-sensitive coding of social attention cues, such as head turns. In experiments, these stimuli are often abstracted to static views, which fails to capture their dynamic character in natural social interaction. Here, we demonstrate that response patterns in human right anterior STS/STG distinguish between leftward and rightward dynamic head turns. Furthermore, left–right head turns were significantly more discriminable in this region than left–right ellipsoid control stimuli. A similar analysis of the left STS region revealed no left–right classification of head turn direction at any site in the ROI. 

The peak coordinates for left–right classification of head turn direction in the current study are in close proximity to a previous demonstration of direction-sensitive fMRI adaptation to static gaze ( ; 16 mm distance between peaks). Considered collectively, these results suggest a general role for right anterior STS/STG in supplying higher order social cognitive processes with important information about the direction of another's attentional shifts, whether these are conveyed by static gaze in a front-facing head or dynamic head turns. Consistent with this social role, we also demonstrate that direction sensitivity does not extend to nonsocial control stimulus motion in this region. An important question is whether such direction-sensitive responses to dynamic and static social cues are driven by a single representation of the direction of another's social attention ( ) or whether dynamic information is coded separately, as indicated by the finding that STS neurons tuned to head turn motion do not respond to static head view displays ( ;  ). 

Neurons in macaque anterior STS are tuned to the direction of social attention cues ( ;  ). However, most human fMRI studies have reported gaze or head turn effects in posterior rather than anterior STS regions ( ). Our classification effects appear more consistent with the typical recording site in macaque anterior STS than with previous univariate fMRI effects in human posterior STS. Compared with standard univariate analysis, MVPA and fMRI adaptation techniques confer greater sensitivity ( ). This increased sensitivity makes more rigorous comparisons possible, for instance between left and right averted social attention cues. Accordingly, we also observed greater consistency between human fMRI and single unit evidence from the macaque (see also  ,  ;  ). Known human–macaque discrepancies in the function of posterior STS and surrounding areas suggest that a simple correspondence between human and macaque may not apply to all high-level visual areas ( ), but such a simple correspondence nevertheless offers a useful working model for the representation of social attention cues. 

The pattern of results we observed in posterior and anterior portions of the right STS region also highlights how large-scale univariate response level differences can dissociate from multivariate classification performance ( ;  ;  ). Similar to previous studies ( ), we found that right posterior STS responded more to heads than to ellipsoids, while no such preferential responding was observed in anterior STS/STG. The left–right head turn classification effects showed the opposite pattern, with significant effects in anterior but not posterior regions. There are clear parallels between this pattern of effects and a recent report where face identity classification was possible in an anterior inferotemporal region, which did not respond preferentially to faces over places, while no such face identity effects appeared in the more posterior fusiform face area, even though this region responded more to faces than to places ( ). Face identity and head turn direction are both important dimensions for face processing, yet multivariate sensitivity for manipulations along these dimensions does not appear to colocalize with univariate selectivity for faces over other object categories. Although more systematic studies of these within- and between-category dissociations are needed before their theoretical implications for face perception can be fully considered, the current results indicate that studies where data analysis is restricted to functional ROIs defined by face selectivity are at risk of missing potentially important effects ( ;  ). 

Neurons with social attention responses in macaque STS are often invariant to the identity of the individual conveying the cue ( ). In this study, we observed no generalization between response patterns evoked by left–right head turns across the 2 identities. Although there is some initial evidence to suggest that STS neurons can code both head view and head identity ( ), it is in our view unlikely that the representation across STS is identity-specific. For instance, it has previously been shown that direct and averted static head views can be distinguished across identity in posterior STS ( ). Given that separate training of left–right classification for each identity involves half as much data as compared with when this dimension is collapsed, it is more likely that our experiment was not sufficiently sensitive to detect any such identity-invariant head turn representations. 

Our results suggest that the anterior STS region distinguishes the direction of perceived head turns. The follow-up eye-tracking experiment suggested that volunteers' eye movements tended to follow the direction of head turns, thus presenting a potential confound to the interpretation of our results. To rule out an eye movement account of our reported classification effects, we demonstrated in a revised fMRI experiment that a subset of volunteers from the main experiment showed significant left–right head turn classification in the right STS region, even though these volunteers showed no significant eye movement effects during pretests or whilst in the scanner. Thus, even though our main analysis is potentially limited by an eye movement confound, the head turn direction codes in the right anterior STS region remain when this confound is removed. The absence of prior reports of eye movement responses in the anterior STS region is also consistent with this interpretation ( ;  ). By contrast, even minute eye movements elicit responses in early visual cortex ( ), and an eye movement account would seem to account well for the pattern of ipsilateral univariate selectivity we observed in the main experiment, with leftward and rightward head turns producing responses in left and right early visual cortex, respectively. Notably, this ipsilateral pattern of effects reverted to the expected contralateral response preference in the univariate analysis of the follow-up experiment, even though left–right head turn classification in early visual cortex was significant in both the original and the follow-up experiments. These results suggest that the classification effects in the 2 data sets were driven by distinct large-scale univariate effects: a primarily eye movement-related response in the main experiment and a visually-evoked response in the follow-up experiment. 

The pervasive tendency for volunteers to follow social attention cues points to an intriguingly close link between action and perception in this system, which is worthy of further enquiry. Previous investigators found that static gaze cues also evoke small eye movements in the perceived gaze direction ( ). Indeed, 2 of the 5 volunteers who were tested with eye tracking in the current study were unable to consistently suppress eye movements in response to the head turns, even in the presence of a fixation cross and strong instructions to maintain fixation. Although interesting in their own right, these eye movement effects also suggest that investigators who seek to isolate effects of perceived gaze direction would be well advised to monitor the volunteer's own gaze. 

Previous studies have found that socially relevant motion engages MT ( ;  ). Consistent with this literature, we observed a univariate response preference for heads relative to ellipsoids in bilateral superior temporal regions likely corresponding to MT+. Despite this category preference for heads relative to ellipsoids, we obtained no evidence that response patterns in this region distinguish head turn direction. In previous studies that attempted to decode motion directions, direction sensitivity was weaker in MT than in earlier visual areas ( ;  ), which the authors attribute to MT's smaller anatomical size compared with earlier visual areas. Although neurophysiological data suggest considerable direction sensitivity in both MT and early visual cortex ( ), such response properties may interact with area size when measured with coarse-grained methods such as fMRI, thus producing apparently weaker or nonsignificant effects in smaller areas ( ). Note also that both the absence of a functional MT localizer and the use of weaker, more transient motion stimuli may have rendered our analysis less sensitive to direction-sensitive responses in MT+, compared with previous studies ( ;  ). Thus, we do not exclude the possibility that head turns produce direction-sensitive MT+ responses, although we were unable to find evidence for this. 

In conclusion, we have presented evidence that response patterns in human right anterior STS/STG distinguish between leftward and rightward dynamic head turns. Such direction sensitivity was not detected for physically matched ellipsoid control stimuli. The anterior site of this effect is consistent with evidence from macaque neurophysiology ( ;  ) but does not colocalize with regions showing greater univariate responses to heads than to ellipsoids. In this respect, multivariate pattern approaches show great promise in linking evidence from single neurons in the macaque to large-scale response patterns in human fMRI. 


## Supplementary Material 
  
 Supplementary material   can be found at:   http://www.cercor.oxfordjournals.org/  


## Funding 
  
 (grant   to A.J.C.;   to J.B.R); Wellcome Trust (  to J.B.R.). 


## Supplementary Material 
  
 </div>
</div>
</div>
</div>
</div>
<div class='study' id='study-76'>
<h2>76. PMID: <a href='https://pubmed.ncbi.nlm.nih.gov/25946306/' target='_blank'>25946306</a></h2>
<div class='metadata'>
<h3>Metadata</h3>
<p><strong>Title:</strong> Reading a Suspenseful Literary Text Activates Brain Areas Related to Social Cognition and Predictive Inference</p>
<p><strong>Authors:</strong> N/A</p>
<p><strong>Journal:</strong> PLoS One</p>
<p><strong>Publication Year:</strong> 2015</p>
<p><strong>DOI:</strong> 10.1371/journal.pone.0124550</p>
<p><strong>PMCID:</strong> <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/4422438/' target='_blank'>4422438</a></p>
</div>
<div class='screening'>
<h3>Screening Results</h3>
<p><strong>Fulltext Decision:</strong> included</p>
<p><strong>Fulltext Reasoning:</strong> The study used functional MRI while healthy adult participants (N=23, ages 19–32) read a narrative and rated suspense. The task explicitly evokes and the authors interpret activations in medial frontal cortex and temporo-parietal junction as social-cognitive/theory-of-mind processes (Perception and Understanding of Others). Whole-brain GLM analyses with second-level random-effects and cluster-level FWE correction are reported (in addition to an ROI amygdala analysis), so results are not ROI-only. Participants are within the 17–65 healthy adult range and results for healthy subjects are reported separately. Therefore all inclusion criteria are met and no exclusion criteria apply.</p>
<p><strong>Fulltext Confidence:</strong> 0.95</p>
</div>
<div class='content'>
<h3>Fulltext Content</h3>
<p><strong>Abstract:</strong>  
Stories can elicit powerful emotions. A key emotional response to narrative plots (e.g., novels, movies, etc.) is suspense. Suspense appears to build on basic aspects of human cognition such as processes of expectation, anticipation, and prediction. However, the neural processes underlying emotional experiences of suspense have not been previously investigated. We acquired functional magnetic resonance imaging (fMRI) data while participants read a suspenseful literary text (E.T.A. Hoffmann's “The Sandman”) subdivided into short text passages. Individual ratings of experienced suspense obtained after each text passage were found to be related to activation in the medial frontal cortex, bilateral frontal regions (along the inferior frontal sulcus), lateral premotor cortex, as well as posterior temporal and temporo-parietal areas. The results indicate that the emotional experience of suspense depends on brain areas associated with social cognition and predictive inference. 
 </p>
<button class='accordion' onclick='toggleAccordion(this)'>Full Text Content (41594 characters)</button>
<div class='panel'>
<div class='panel-content'>
<div class='fulltext-content'> 
## Introduction 
   
I could a tale unfold whose lightest word 

Would harrow up thy soul, freeze thy young blood, 

Make thy two eyes, like stars, start from their spheres, 

Thy knotted and combined locks to part 

And each particular hair to stand on end, 

Like quills upon the fretful porpentine. 
  
William Shakespeare,   Hamlet   (1.5.15–20) 
 
Spoken or written words can evoke powerful emotional responses. A prime example of this are stories. For millennia, generations of humans around the world have been moved, fascinated and entertained by stories, and oral traditions of storytelling may be as old as human language itself. Stories—factual or fictional—are omnipresent in human culture: Apart from their artfully refined role in literature (e.g., in novels, short stories, and many forms of poetry and drama), stories are told in a variety of other contexts, and the appeal of movies, songs, speeches, jokes, newspaper articles—and perhaps even scientific papers—often depends on their capacity “to tell a good story”. The human ability to understand, tell, and enjoy stories involves a multitude of cognitive and affective mechanisms including perception, attention, memory, reasoning, simulation of actions, emotion, and, naturally, language. Investigating story processing with modern neuroimaging methods can therefore provide insights into the neural signature of these mechanisms. 

Various neuroimaging studies have begun to tap into the brain mechanisms associated with story processing (for meta-analyses of story and text comprehension studies see [ ,  ]). Most of these studies focus on cognitive aspects of story processing, investigating, for example, neural activations in response to coherent narratives as opposed to unrelated sentences or words [ – ], comparing neural responses to written and auditory text presentations [ ], or probing memory encoding during story processing [ ]. 

Neuroscientific research on emotional responses to stories, however, is scarce, and only a few studies have specifically investigated the neuroaffective processes underlying story processing. An fMRI study by Wallentin et al. [ ] found that the emotional intensity experienced during auditory presentation of a story correlates with heart rate variability, activation of temporal cortices, the thalamus, as well as the amygdala, and that passages associated with positive valence are related to orbitofrontal cortex activations. Investigating emotional valence for short narratives, Altmann et al. [ ] showed that negative story valence is associated with increased activation of theory-of-mind-related brain regions (such as the medial frontal cortex and the temporo-parietal junction). More recently, Hsu et al. [ ,  ,  ,  ] provided fMRI evidence for the fiction feeling hypothesis [ ] stating that narratives with emotional content (in contrast to stories with neutral content) invite readers to empathize to a stronger degree with the protagonists, thus engaging the affective empathy network of the brain. These studies provide first evidence that investigating emotions evoked by narrative plots can offer new insights into neuroaffective brain processes. 

One component of emotional experience that is particularly relevant to story processing is suspense. Suspense is experienced in a huge variety of different contexts ranging from everyday life situations, sports, or gambling to different forms of media entertainment (e.g., film, television, literature, or music). Accordingly, suspense has been discussed by scholars from different disciplines such as literary science, film studies, or media psychology (for introductions, see [ – ]). Creating “the force that draws us through a narrative” [ ], suspense is the predominant emotional response elicited by many types of literary genres (e.g., thrillers, detective stories, spy novels, etc.), and the broad popularity of these genres illustrates the power of suspense to attract audiences and excite emotional responses. Suspense in narrative plots is closely intertwined with processes of prediction and anticipation which are triggered by explicit or implicit questions in the minds of the audience [ ], and which arise from the uncertainty regarding the outcome of the plot (cf. [ ,  ]). Plots of suspenseful novels or movies, for example, often involve conflicts and obstacles that the protagonists have to overcome, making the audience ponder over possible solutions to these conflicts and anticipate their eventual resolution. Predictive inferences during story processing have been found to be related to activation in inferior frontal and posterior temporal regions [ – ], and more generally, action and event prediction have been proposed to be supported by motor-related regions of the brain, in particular the lateral premotor cortex [ ]. Apart from adding to research on affective mechanisms involved in story processing, investigating neural responses to suspenseful narrative plots thus also promises insights into the brain structures associated with predictive inference. Moreover, suspense is closely related to processes of immersion, transportation, or absorption in media reception, such as reading [ ,  ,  ] or computer games [ ], which can be explained by the neurocognitive poetics model of literary reading [ ,  ]. 

At the text level, a suspense discourse organization involves an initiating event or situation, i.e., an event which potentially leads to significant consequences (either good or bad) for one of the characters in the narrative. The structural-affect theory of stories by Brewer and Lichtenstein [ ] states that the event structure must also contain the outcome of the initiating event, allowing to resolve the reader’s suspense. According to the model by Jacobs, the core affect systems “FEAR”, “ANGER”, or “CARE” described in Panksepp’s emotion theory [ ] are likely to be involved in this suspense building process, e.g., when a reader experiences suspense through vicarious fear, because a protagonist is in danger (especially when this danger is only known to the reader), which is mediated by processes of empathy and sympathy. Findings by Altmann et al. [ ] provided initial support for this assumption, indicating that short stories with negative content induce more affective empathy with the described characters in readers than neutral stories, as evidenced by increased brain activity in theory-of-mind and empathy-related areas (i.e., the medial frontal cortex, superior temporal sulcus, and temporo-parietal junction). Hsu et al. [ ] directly tested the model’s assumption and found that immersion (which at the experiential level is related to suspense; [ ]) is associated with activation of the mid-cingulate cortex and is higher for fear-inducing text passages describing protagonists’ pain or personal distress than for neutral passages. 

Although suspense can be measured at both the subjective-experiential (through questionnaires) and more objective behavioral and physiological levels, such as facial expressions, heart rate, or skin temperature [ ], at present, there are no neuroimaging results speaking directly to the issue of suspense in literary reading contexts. 

In the current study, we investigated the neural correlates of suspense experienced by readers during their first reading of a literary text. To this end, we acquired fMRI data while participants read a narrative (E.T.A. Hoffmann's “The Sandman”) subdivided into short text segments. After each segment, participants rated the level of suspense they had experienced while reading the segment. We then identified brain areas in which activation was related to the level of subjectively experienced suspense. Due to the dearth of previous research on neural correlates of subjectively experienced suspense, it was difficult to make specific predictions about brain regions involved in the experience of suspense. However, we were particularly interested in neuroaffective responses to suspenseful text segments. Previous fMRI research from the music domain has found ratings of musical tension—the musical “equivalent” of narrative suspense (cf. [ ,  ])—to be associated with activity changes in the lateral orbitofrontal cortex and the amygdala [ ]. Similarly, the violation, anticipation, and fulfillment of musical expectancies that mediate feelings of tension have been associated with amygdala [ ] as well as dorsal and ventral striatum activations [ ]. We expected suspense to be related to increased activity in similar brain structures associated with affective processing. In addition, based on the results reported by Altmann et al. [ ] and Hsu et al. [ ,  ], we explored whether suspense is related to activation in areas associated with theory-of-mind processing and mentalizing, i.e., the medial frontal cortex and the temporo-parietal junction [ – ]. Furthermore, based on the connection between suspense and predictive processes discussed above, we expected suspense to correlate with activation in brain areas associated with prediction (e.g., lateral premotor cortex). 


## Methods 
  
### Participants 
  
Right-handed German native speakers who were unfamiliar with the story and who enjoyed reading literature (according to self-reports) were recruited as participants for the experiment. Data from 23 participants (12 female, age range: 19–32 years,   M   = 24.1,   SD   = 3.9) were included in the analysis. Data from five additional participants were excluded because they did not finish reading within scanning time (four participants) or answered fewer than two of five control questions that were asked after the experiment correctly (one participant). All participants gave written consent and were compensated with 15 euros or course credit. The study was approved by the ethics committee of the Department for Educational Sciences and Psychology of the Freie Universität Berlin and was conducted in accordance with the Declaration of Helsinki. 


### Stimuli 
  
The narrative “Der Sandmann” (“The Sandman”) by E.T.A. Hoffmann was used as stimulus material. A prominent example of a Romantic narrative devoted to the darker sides of emotional life, the story relates events in the life of the student Nathaniel who—traumatized by the early death of his father—is haunted since childhood by the mysterious Sandman. The story was chosen because of its suspenseful character and uncanny atmosphere (famously discussed in Sigmund Freud's essay”The Uncanny”; [ ]). Importantly, the story features text passages inducing high as well as low suspense (as determined in a preceding pilot rating study), thus ensuring sufficient variability in the suspense ratings to use them as parametric regressor in the fMRI data analysis (see  ). The story was presented in German. To make it suitable for the experiment, the text was shortened (from 12,232 to 6,859 words) and some words that are now out of use and hence unfamiliar were replaced by more common ones to guarantee that participants comprehended the text. Special care was taken to ensure that the shortening of the text did not modify the plot or make the story less comprehensible. For the presentation in the MRI scanner, the story was partitioned into 65 segments of approximately equal length (  M   = 105.5 words per segment;   SD   = 26.1 words). Segmentation was done in such a way that the level of suspense varied across text segments but remained relatively constant within one text segment (  shows the segmented text used in the study). 


### Experimental procedure 
  
Participants read the story, segment by segment, while functional imaging data were recorded. The text was presented on a screen above participants' head via a magnet-compatible projection mirror system (the text was shown in a black font against a gray background). To make the reading experience as natural as possible, reading time was self-paced, i.e., participants decided how long each text segment was presented by pressing a button whenever they wanted to proceed (however, to avoid fatigue, scanning was stopped after a maximum of 60 minutes, and four participants who had not finished reading within this time were excluded from the analysis). After each text segment, participants rated how much suspense they had experienced during the preceding segment on a 10-point scale (ranging from “not suspenseful” to “very suspenseful”) using two buttons of an MRI-compatible response box. The rating screen was presented with a temporal jitter of 1.0–4.2 seconds after participants had finished reading the text segment. At the initial presentation of each rating screen, a random rating value was selected that had to be adjusted according to the experienced suspense using the two buttons (the initial random rating value was chosen to de-correlate the level of experienced suspense from the button presses during the rating). Using a third button, participants confirmed the rating and proceeded to the next text segment (the same button was used to proceed from the text segment to the rating; see  ). Participants were explicitly instructed to rate the suspense they subjectively experienced (not the suspense they thought the segment was supposed to evoke). To become familiar with the experimental task, participants completed a short practice trial (with a different text) before the actual experiment. Due to the self-paced reading times, the scanning duration varied between 28:05 and 53:52 min across participants (  M   = 42:55 min;   SD   = 7:33 min). 
   One trial of the experiment: a segment of the text was presented, followed by a rating screen on which the suspense experienced while reading the text segment was selected on a 10-point scale using two buttons (for moving the selected point on the rating scale to the left or right).  
Timing was self-paced, i.e., participants pressed a button in order to proceed to the next text segment / rating screen. A total of 65 text segments was presented during the experiment. 
  
To assess whether participants had read the text attentively, five multiple-choice control questions were asked after the experiment (in order not to influence the natural reading process, participants were not informed about this before the experiment). We also assessed participants' general reading habits (e.g., how many books they usually read per year, and what type of literature genres). We moreover acquired heart rate and respiration rate of the participants; however, due to technical failure, the heart and respiration data of some participants were not usable, and we therefore could not include them as control regressors in our fMRI analysis. 


### Image acquisition 
  
MRI data were acquired at the Dahlem Institute for Neuroimaging of Emotion at the Freie Universität Berlin using a 3 Tesla Siemens Magnetom TrioTim MRI scanner (Siemens AG, Erlangen, Germany). Before functional scanning, a high-resolution (1x1x1 mm) T1-weighted anatomical reference image was obtained using a rapid acquisition gradient echo (MP-RAGE) sequence. For the acquisition of functional data, a continuous echo planar imaging (EPI) sequence was used (37 slices; slice thickness: 3 mm; interslice gap: 0.6 mm; echo time: 30 ms; repetition time: 2 s; flip angle: 70°; 64x64 voxel matrix; field of view: 192x192 mm) with slice acquisition interleaved within the TR interval. To reduce susceptibility-induced image distortions and signal losses in areas such as the orbitofrontal cortex and the temporal lobes, the acquisition window was tilted at an angle of 30° to the intercommissural (AC-PC) line [ ,  ]. 


### Image processing and statistical analysis 
  
Data were analyzed using Matlab (MathWorks, Natick, USA) and SPM8 (Wellcome Trust Centre for Neuroimaging, London, UK). Prior to the statistical analysis of the data, functional images were realigned using a 6-parameter rigid body transformation, co-registered to the anatomical reference image, normalized to standard Montreal Neurological Institute (MNI) stereotaxic space using a 12-parameter affine transformation, and spatially smoothed with a Gaussian kernel of 6 mm full-width at half-maximum. Low-frequency noise and signal drifts were removed using a high-pass filter with a cut-off frequency of 1/256 Hz. We deliberately opted for this comparatively low cut-off frequency to avoid filtering out parts of the signal of interest (because readers' experience of suspense changes relatively slowly). Serial correlations between scans were accounted for using an autoregressive AR(1) model. 

A standard general linear model (GLM) approach was used for statistical analysis. Potential confounding factors were added as control variables to the model. The control variables included were “action”, “imageability”, arousal, valence, and average sentence length of each text segment. To determine the amount of action described in the text segments we acquired additional ratings from a different group of participants (  N   = 20, 13 female, age range: 20–33 years,   M   = 23.5,   SD   = 3.8) asking how eventful each segment was experienced during reading (ratings were given on a 7-point scale). The Berlin Affective Word List (BAWL-R; [ ]) was used to estimate imageability, arousal, and valence based on values of single words which were then averaged over all words from one text segment. Average sentence length (in words) of each text segment was added to control effects of working memory, assuming that longer sentences generally impose higher demands on working memory. Thus, the model included the following regressors: reading periods were modeled as block regressor; control variables (action, imageability, arousal, valence, and average sentence length) and individual suspense ratings were modeled as a parametric modulator [ ,  ] of the reading periods (suspense ratings were orthogonalized to the control variables); rating periods were modeled as block regressor; estimates of the motion correction parameters obtained during the realignment were added as regressors of no interest. All regressors (except for the motion correction parameters) were convolved with the standard hemodynamic response function, and model parameters were estimated using the restricted maximum likelihood approach implemented in SPM8. After model estimation, whole-brain statistical parametric maps (SPMs) were calculated for the contrasts   reading > rating   (assuming that it would be associated with typical activations of the reading network, this contrast mainly served as a sanity check of the data) and the parametric regressor   suspense   (and its inverse—  suspense  ). To obtain group level results, the contrast images of individual participants were entered into a second-level random effects analysis. To account for differences in reading times as well as in the general experienced suspensefulness of the text, total reading times and average suspense ratings of each participant over the complete text were added as control regressors into the second-level model. Activations with a   p-  value smaller than. 05 corrected for family-wise errors (FWE) at the cluster level (with a cluster-forming threshold of   p   <. 005) were considered significant (FWE-corrected cluster extent threshold: 210 voxels). Because this cluster thresholding procedure may miss smaller activation clusters, in particular activations in the amygdala which we expected to be related to suspense (see  ), we also performed a region of interest analysis in the left and right amygdala. The region of interest was defined using the probability maps of the amygdala as implemented in the SPM anatomy toolbox [ ,  ]; a statistical threshold of   p   <. 05 (FWE-corrected) was used for the region of interest analysis. 



## Results 
  
### Behavioral data 
  
 shows average suspense ratings for the story. Pearson's product-moment correlation coefficients between individual suspense profiles, averaged over all possible pairs of participants, revealed a moderate inter-participant agreement (  r   =. 31,   p   <. 05; because Pearson's correlation coefficients are not additive, a Fisher z-transformation was applied before averaging over correlation coefficients and the resulting z-value was then converted back into a correlation coefficient). Average reading time for one text segment was 29.98 s (  SD   = 12.04 s). No correlation between reading speed and suspense ratings (averaged over participants) was observed (  r   =. 08,   p   =. 55). Moreover, suspense ratings did not correlate with the lengths of the text segments (  r   = –.04,   p   =. 74). Correlation coefficients between suspense ratings and the control measures (i.e., action, imageability, arousal, valence, and sentence length) are reported in  . 
   Average suspense ratings (  N   = 23) and standard errors for each segment of the text.    

### Functional MRI data 
  
Comparing reading periods with rating periods (  reading > rating  ,  ) revealed bilateral activations in visual cortices, the entire superior temporal sulcus (with left hemispheric dominance), and anterior hippocampus (cornu ammonis). Moreover, left-hemispheric activations were observed in the precentral gyrus and fusiform gyrus. 
   Statistical parametric maps (  p   <. 05, cluster-level FWE-corrected, shown in neurological convention) for (A) the contrast   reading > rating   and (B) the parametric   suspense   regressor capturing participants' experience of suspense during reading.    
The suspense regressor (reflecting participants' individual experience of suspense) showed a medial frontal activation cluster, as well as in each hemisphere a lateral frontal and a posterior temporal cluster of activation ( ). More specifically, the lateral frontal activation clusters extended anteriorly along the IFS into the inferior frontal gyrus (IFG), and posterior-superiorly into the precentral sulcus and precentral gyrus (lateral premotor cortex). The temporal clusters covered the posterior part of the superior temporal sulcus (STS), extending into the temporo-parietal junction (TPJ). These temporal and temporo-parietal activations were more pronounced in the left than in the right hemisphere. No negative correlations with suspense were observed, and none of the analyses showed activity changes in the amygdala, nor the orbitofrontal cortex. For a complete list of activations see  . Significant activations for the parametric control regressors (action, imageability, arousal, valence, and sentence length) are reported in   and  . 
   GLM analysis: anatomical locations, peak MNI coordinates, T-values, and cluster sizes (number of voxels) of significant clusters for the   reading > rating   contrast and the parametric   suspense   regressor.        
The region of interest analysis for the suspense regressor in the left and right amygdala did not yield any significant activations. 


### Psychophysiological interactions (PPI) 
  
To investigate whether there is a relationship between suspense ratings and the functional connectivity patterns of brain areas associated with suspense, we also performed a   post hoc   PPI analysis [ ]. For this, we used the upper and lower quartiles of individual suspense ratings to dichotomize suspense ratings into high and low values which were used to test the interaction of suspense with the functional connectivity of voxels around the maxima of the five activation clusters reported above (i.e., left posterior STS, right IFS, left IFG, MFC, and right TPJ; for exact locations, see peak MNI coordinates of  ). The contrast high vs. low suspense was multiplied with the eigenvariate of the voxels within a sphere with the radius 3 mm around the peak activation voxel of each cluster to obtain the interaction term. We expected psychophysiological interactions of the regions related to suspense with limbic/paralimbic regions implicated in emotion (such as the amygdala and the orbitofrontal cortex, see  ). For the left IFG region, the PPI analysis showed significant activations in cerebellar and occipital regions as well as the posterior inferior temporal gyrus and premotor cortex. Moreover, suspense significantly modulated the functional connectivity between the MFC and bilateral occipital areas as well as parietal areas including the postcentral gyrus (see   and  ). For the other seed regions (left posterior STS, right IFS, and left TPJ), the PPI analysis did not yield significant results. 
   PPI analysis: anatomical locations, peak MNI coordinates, T-values, and cluster sizes (number of voxels) of brain areas in which suspense (high vs. low) significantly modulated the functional connectivity to the seed region.        


## Discussion 
  
In the present study, we investigated the neural correlates of suspense evoked by a literary text. For this, we acquired functional imaging data while participants read a suspenseful story subdivided into short text passages. After each text passage, a rating of subjectively experienced suspense was obtained. Suspense ratings correlated with blood oxygen level-dependent (BOLD) signal intensity in the medial frontal cortex, bilateral frontal regions along the inferior frontal sulcus (extending into the inferior frontal gyrus and premotor cortex) as well as posterior temporal and temporo-parietal regions bilaterally. 

Comparing reading periods with rating periods yielded activations in the left (and to a lesser degree right) superior temporal sulcus. Activation of these areas has previously been associated with semantic processing of written and spoken language in general (see [ ], for an overview) and story processing in particular [ ,  ]. Reading also activated the left fusiform gyrus or what has been termed the “visual word form area” which has previously been ascribed a specialized role in the processing of written words [ ,  ]. As could be expected, reading of the story thus evoked typical brain activations of a left-lateralized language and reading network. Moreover, reading was associated with increased activation in visual cortices, possibly reflecting the higher visual input during reading periods compared with rating periods. 

Suspense—as subjectively experienced by individual participants—was related to bilateral clusters of activation in the medial and dorsolateral prefrontal cortex, in particular the inferior frontal sulcus, the inferior frontal gyrus, and the precentral gyrus (lateral premotor cortex), as well as posterior temporal areas extending into the TPJ. Activations of posterior temporal regions, in particular the TPJ, have previously been related to social cognitive tasks such as perspective taking [ ] or theory-of-mind processing [ ,  ]. A meta-analysis investigating neural correlates of social cognition associated the TPJ with the inference of other people's goals and actions [ ], and TPJ activations have been repeatedly observed for story processing (e.g., [ ]; for a meta-analysis, see [ ]). Likewise, the medial frontal cortex, which also showed activation related to suspense, has been discussed as a key area associated with social cognition and theory-of-mind [ ]. For example, a study comparing theory-of-mind processing in cartoon tasks and story tasks found overlapping activity for both tasks in the medial frontal cortex [ ], coinciding with the activation found in the present study. Similarly, a study by Steinbeis and Koelsch [ ] reports medial frontal cortex activation when participants believed they were listening to music written by a composer as opposed to computer-generated music, underlining the role of the MFC in theory-of-mind processing and mental state attribution. As hypothesized in the aforementioned neurocognitive poetics model of literary reading [ ,  ], and supported by Hsu et al. [ ], activation of temporo-parietal and medial frontal areas could thus be due to readers adopting the perspective and inferring the mental states of the main characters of the story during emotionally engaging and suspenseful text segments. Suspenseful parts of a narrative plot (in particular the suspenseful text segments of the current experiment) often involve situations in which a main character of the story is facing situations of potential danger or threat. Following Zillmann's definition “that the experience of suspense in dramatic presentations derives characteristically from the respondent's acute, fearful apprehension about deplorable events that threaten liked protagonists” ([ ], p. 140), activation of the TPJ and MFC may reflect these fearful anticipations of upcoming events that depend on the ability to infer the mental states, goals, and actions of characters of the story. This is in line with connectivity studies indicating that the MFC (in particular its dorsal parts) and its connectivity with the TPJ are associated with the understanding of others' mental states [ ] (however, note that we did not find such a connectivity in our PPI analysis). Furthermore, suspense has been proposed to build on a disparity between the knowledge of a character and the knowledge of the reader or viewer (most notably discussed by Alfred Hitchcock [ ]; see also [ ]). This disparity of knowledge is often based on theory-of-mind processing (e.g., knowing that the characters don't know what one oneself knows) and could therefore account for the activation of theory-of-mind-related brain areas during suspenseful texts (however, this is rather speculative because the disparity of knowledge between characters and readers appears to be less relevant for building suspense in the specific text used in the present experiment). 

The posterior temporal activations associated with suspense (particularly the ones in the left hemisphere) also suggest that neural activity in lower-level language areas is influenced by suspense, as these areas have been associated with the cognitive processing of written words and texts, e.g., word recognition [ ,  ,  ], acoustic-phonetic processing [ ], mapping of orthographic to phonological representations [ ], and the integration of semantic information [ ]. However, whether suspense directly modulates lower-level language areas or whether suspenseful text segments tend to covary with linguistic features that could influence neural activation in lower-level language areas remains to be investigated more closely (see  ). 

In addition to the TPJ and MFC activations, suspense was associated with bilateral activations in inferior frontal regions extending into lateral premotor cortex in the precentral gyrus. The activation of premotor areas during the experience of suspense suggests a connection between suspense and neural processes of prediction and anticipation. As described previously, premotor cortex activations (particularly in ventrolateral parts) have consistently been reported for tasks involving action and event prediction (for reviews, see [ ,  ]), which is corroborated by studies showing that predictive processing of sequential information is impaired in patients with premotor lesions [ ], and that ventrolateral premotor activations are associated with the processing of biological as well as abstract non-biological stimulus sequences [ ]. Our results point to a possible role of the premotor cortex in predictive processes concerning upcoming events in a suspenseful narrative plot, thus supporting the conjecture that the premotor cortex is involved in general aspects of event prediction (regardless of whether these predictions require motor control or planning; see [ ]). Moreover, predictive inferences in the context of story processing have been associated with inferior frontal and posterior temporal activation: In a study by Jin et al. [ ], short “mini-stories” provoking predictive inferences (compared with non-predictive counterparts) were related to left IFG activations, and Virtue et al. [ ] found story passages that required active inferences (based on previous information given in the story) to be associated with activation in the right posterior STG and bilateral IFG. The inferior frontal and posterior temporal activations observed for suspense could therefore reflect predictive processes associated with inferences about the unfolding of events of the story. The involvement of predictive processes during suspenseful text segments could also provide an alternative explanation to the TPJ and MFC activations discussed above: Decety and Lamm [ ] argue that TPJ activations are not specific to theory-of-mind processing but reflect more domain-general mechanisms “involved in generating, testing, and correcting internal predictions about external sensory events” ([ ], p. 583), and similarly, MFC activations have been implicated in predictive inferences during text comprehension [ ,  ,  ,  ]. 

The close link between suspense and prediction is particularly interesting in light of Bayesian accounts of brain functioning such as predictive coding and free energy [ ,  ]. From the perspective of these theories—which postulate that perception, action, learning, and emotion [ ] are essentially based on the minimization of prediction errors, surprise, and uncertainty—suspense can be viewed as the emotional component reflecting this urge for uncertainty reduction. Novels, movies, television series and various other forms of media entertainment appear to take advantage of this fundamental principle of human cognition, thus accounting for their general appeal and popularity. However, apart from reflecting an urge for uncertainty reduction, suspense may involve other (neuro-)cognitive mechanisms. From a biological perspective, uncertainty should be associated with negative emotion (because an organism that is able to make accurate predictions about its environment should have an evolutionary advantage over organisms that are unable to make such predictions), and suspense should therefore primarily be experienced as negative (and only the resolution of suspense should have a positive valence). Yet, suspense—in particular in forms of media entertainment such as film, music, or literature—is often experienced as positive, and the emotional “thrill” associated with suspense experiences may be enjoyed for its own sake (especially when the context in which suspense is elicited is devoid of potentially negative real-life consequences, as in literature, film, or music; cf. [ ,  ]). This indicates that, apart from uncertainty, other factors may also play a role in suspense and determine whether it is experienced as positive or negative (for a more detailed discussion of this point, see [ ]). 

The bilateral activation clusters of the inferior frontal sulcus included the so-called inferior frontal junction (IFJ, cf. [ ,  ]). Located at the intersection of premotor, language, and memory areas, activations in this area have previously been reported in experiments involving cognitive control, task switching, or updating processes [ – ]. For example, a meta-analysis by Derrfuss et al. [ ] reports activation of the IFJ in experimental paradigms requiring the updating of task representations (e.g., task-switching paradigms, Stroop tasks, or n-back tasks). With regard to language processing, left inferior frontal regions have been associated with semantic encoding [ ,  ], semantic working memory [ ], semantic retrieval [ ,  ], or selection of information from semantic memory [ ]. On a more speculative note, the frontal activation clusters observed for suspense may therefore reflect the recruitment of cognitive control structures during suspenseful text segments, i.e., during passages when the reader's interest about the unfolding of events of the story is highest. Being “captured” by the story during episodes of high suspense may lead to the engagement of top-down control mechanisms that rely on the IFJ and that may optimize semantic processing of the content of the story. This is in line with dynamic causal modeling (DCM) studies showing that IFG regions coordinate temporal and parietal regions associated with lower-level language processing [ ,  ,  ]. 

The brain activations related to participants' experience of suspense partially overlap with brain activations associated with the emotional intensity of a story reported in the study by Wallentin et al. [ ]. Both suspense and emotional intensity appear to be related to bilateral inferior frontal and (posterior) temporal activations. However, there were also differences in activation patterns between the two studies: for emotional intensity, Wallentin et al. [ ] report activations of the right amygdala as well as the thalamus which we did not find for suspense; conversely, the medial frontal activations related to suspense were not found in the study by Wallentin et al. [ ]. Apart from differences between the concepts investigated (i.e., suspense vs. emotional intensity), the different activations may be due to other differences between the two studies. Whereas the study by Wallentin et al. [ ] relied on auditory presentation of the story, the present study made use of a self-paced reading paradigm. Moreover, the present study used individual suspense ratings acquired while participants read the story in the fMRI scanner, which came at the cost of repeatedly interrupting the story to collect the ratings, which may have impeded participants' full immersion into the fictional world of the story (see also  ). Last, the participants of the study by Wallentin et al. [ ] were familiar with the plot of the study, whereas they did not know the plot in the present study. 

### Limitations and outlook 
  
We also had expected suspense to be related to neural activity in limbic brain structures associated with emotional processing such as the amygdala or the striatum. This hypothesis was not confirmed. One aspect of our experiment that may have compromised the evocation of strong emotional responses was that participants had to shortly interrupt reading after each text segment to give the suspense ratings, which may have disrupted the immersive reading experience usually associated with natural reading of suspenseful texts. We had deliberately opted for these online suspense ratings to capture the suspense experience of each individual participant as accurately as possible (alternative methods of acquiring suspense ratings after participants have read the complete text—and hence without interrupting the reading process—or of using average suspense ratings of a different group of participants might have reflected individual suspense experiences during reading less accurately, thus decreasing the sensitivity of the statistical analysis). However, it remains to be investigated whether uninterrupted reading of a suspenseful text engages limbic brain structures associated with emotional processing. Using “stronger” stimulus material—for example, suspenseful movie scenes—may further facilitate the measurement of neural substrates of emotional responses related to suspense. 

Moreover, it may be objected that lower-level stimulus features may have confounded the brain activations observed for suspense. We accounted for possible confounds by including action, imageability, arousal, valence, and average sentence length of each text segment as control variables in the model. However, when investigating a high-level concept like suspense in a relatively naturalistic setting using a real text, controlling all possible low-level stimulus properties is unfeasible, and the possibility that results are influenced by these stimulus features can never be entirely excluded. For example, the IFG activations observed for suspenseful text segments could also be interpreted as reflecting effects of syntactic processing (cf. [ ]). We did not include syntactic complexity as a control variable because there is no straightforward measure quantifying syntactic complexity in natural language texts. However, increased syntactic processing during suspenseful text segments seems unlikely because the relationship between syntactic complexity and suspense in the text of the present experiment is rather negative, i.e., suspenseful text segments tended to feature more simple sentences (often a concatenation of simple main clauses with few embedded sentences) than less suspenseful segments. Nevertheless, controlling as many confounding variables as possible in future neuroimaging studies on suspense is highly desirable. This includes physiological parameters such as heart or respiration rate. 

Finally, we used only one text as experimental stimulus. Whether the results reported here generalize to other texts and domains (e.g., film) remains to be clarified by future research. 



## Conclusion 
  
Suspense is an important component of the emotional experience evoked by narrative plots (e.g., in literature, film, etc.). To our knowledge, this is the first study exploring the neural correlates of suspense during the reading of a literary text. Recording functional imaging data while participants read a suspenseful piece of literature, we found that individual ratings of suspense were related to activity in the medial frontal cortex, posterior temporal and temporo-parietal regions, as well as the dorsolateral prefrontal cortex along the inferior frontal sulcus including the IFG and premotor cortex. Our results indicate that text passages that are experienced as suspenseful engage brain areas associated with mentalizing, predictive inference, and possibly cognitive control. 


## Supporting Information 
  
 </div>
</div>
</div>
</div>
</div>
</div>

<footer>
    <p>Generated by Qualitative Review Tool for Meta-Analysis Pipeline</p>
</footer>
</body>
</html>
